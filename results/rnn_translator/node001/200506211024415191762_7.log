Beginning trial 7 of 10
Gathering sys log on node001
:::MLL 1588818132.228 submission_benchmark: {"value": "gnmt", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1588818132.229 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known gnmt keys.
:::MLL 1588818132.230 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1588818132.231 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1588818132.232 submission_platform: {"value": "1xPowerEdge R7525", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1588818132.233 submission_entry: {"value": "{'hardware': 'PowerEdge R7525', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': ' ', 'os': '\\\\S / ', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.0-0', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '1', 'cpu': '4x AMD EPYC 7502 32-Core Processor', 'num_cores': '128', 'num_vcpus': '128', 'accelerator': 'Tesla V100S-PCIE-32GB', 'num_accelerators': '3', 'sys_mem_size': '251 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '1x 931.5G', 'cpu_accel_interconnect': 'QPI', 'network_card': '', 'num_network_cards': '0', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1588818132.233 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1588818132.234 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
:::MLL 1588818132.912 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node node001
+ pids+=($!)
+ set +x
++ eval echo
+++ echo
+ docker exec -e DGXSYSTEM=DGX1 -e 'MULTI_NODE= --master_port=4973' -e LR=2.0e-3 -e TRAIN_BATCH_SIZE=768 -e TEST_BATCH_SIZE=128 -e WARMUP_STEPS=200 -e REMAIN_STEPS=5270 -e DECAY_INTERVAL=720 -e TARGET=24.0 -e NUMEPOCHS=5 -e MAX_SEQ_LEN=75 -e 'EXTRA_OPTS=   --fused-attention    --fused-xentropy    --no-log-all-ranks    ' -e SLURM_JOB_ID=200506211024415191762 -e SLURM_NTASKS_PER_NODE= -e SLURM_NNODES=1 cont_200506211024415191762 ./run_and_time.sh
Run vars: id 200506211024415191762 gpus 3 mparams  --master_port=4973
NCCL_SOCKET_NTHREADS=2
NCCL_NSOCKS_PERTHREAD=8
STARTING TIMING RUN AT 2020-05-07 02:22:13 AM
+ DATASET_DIR=/data
+ PREPROC_DATADIR=/preproc_data
+ RESULTS_DIR=gnmt_wmt16
+ LR=2.0e-3
+ TRAIN_BATCH_SIZE=768
+ TEST_BATCH_SIZE=128
+ WARMUP_STEPS=200
+ REMAIN_STEPS=5270
+ DECAY_INTERVAL=720
+ TARGET=24.0
+ MAX_SEQ_LEN=75
+ NUMEPOCHS=5
+ EXTRA_OPTS='   --fused-attention    --fused-xentropy    --no-log-all-ranks    '
+ BIND_LAUNCH=0
+ MATH=amp_fp16
+ [[ 0 -eq 1 ]]
+ LAUNCH_OPT='torch.distributed.launch --nproc_per_node 3  --master_port=4973'
+ echo 'running benchmark'
running benchmark
+ python -m torch.distributed.launch --nproc_per_node 3 --master_port=4973 train.py --save gnmt_wmt16 --dataset-dir /data --preproc-data-dir /preproc_data --target-bleu 24.0 --epochs 5 --math amp_fp16 --max-length-train 75 --print-freq 10 --train-batch-size 768 --test-batch-size 128 --optimizer FusedAdam --lr 2.0e-3 --warmup-steps 200 --remain-steps 5270 --decay-interval 720 --fused-attention --fused-xentropy --no-log-all-ranks
:::MLL 1588818136.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 288}}
:::MLL 1588818136.175 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 288}}
:::MLL 1588818136.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 288}}
0: Saving results to: results/gnmt_wmt16
0: Run arguments: Namespace(apex_message_size=10000000.0, apex_num_allreduce_streams=1, batching='bucketing', beam_size=5, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', decay_factor=0.5, decay_interval=720, decay_steps=8, dropout=0.2, enable_apex_allreduce_overlap=False, env=False, epochs=5, eval=True, fused_attention=True, fused_xentropy=True, grad_clip=5.0, hidden_size=1024, init_scale=1024, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, log_all_ranks=False, lr=0.002, math='amp_fp16', max_length_test=150, max_length_train=75, max_size=None, min_length_test=0, min_length_train=0, num_buckets=5, num_layers=4, optimizer='FusedAdam', optimizer_extra='{}', prealloc_mode='always', preproc_data_dir='/preproc_data', print_freq=10, rank=0, remain_steps=5270, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', seed=None, shard_size=80, share_embedding=True, smoothing=0.1, start_epoch=0, target_bleu=24.0, test_batch_size=128, test_loader_workers=0, train_batch_size=768, train_global_batch_size=None, train_iter_size=1, train_loader_workers=1, upscale_interval=128, use_preproc_data=True, warmup_steps=200)
0: L2 promotion: 128B
0: Using random master seed: 3403263790
node001:2465:2465 [0] NCCL INFO Bootstrap : Using [0]eth0:10.141.0.1<0>
node001:2465:2465 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node001:2465:2465 [0] NCCL INFO NET/IB : No device found.
node001:2465:2465 [0] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.1<0>
node001:2465:2465 [0] NCCL INFO Using network Socket
NCCL version 2.6.4+cuda10.2
node001:2467:2467 [2] NCCL INFO Bootstrap : Using [0]eth0:10.141.0.1<0>
node001:2466:2466 [1] NCCL INFO Bootstrap : Using [0]eth0:10.141.0.1<0>
node001:2467:2467 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node001:2466:2466 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node001:2467:2467 [2] NCCL INFO NET/IB : No device found.
node001:2466:2466 [1] NCCL INFO NET/IB : No device found.
node001:2467:2467 [2] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.1<0>
node001:2467:2467 [2] NCCL INFO Using network Socket
node001:2466:2466 [1] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.1<0>
node001:2466:2466 [1] NCCL INFO Using network Socket
node001:2467:2674 [2] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/64
node001:2467:2674 [2] NCCL INFO Trees [0] -1/-1/-1->2->1|1->2->-1/-1/-1 [1] -1/-1/-1->2->1|1->2->-1/-1/-1
node001:2467:2674 [2] NCCL INFO Setting affinity for GPU 2 to ffff,00000000
node001:2465:2676 [0] NCCL INFO Channel 00/02 :    0   1   2
node001:2466:2675 [1] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/64
node001:2465:2676 [0] NCCL INFO Channel 01/02 :    0   1   2
node001:2466:2675 [1] NCCL INFO Trees [0] 2/-1/-1->1->0|0->1->2/-1/-1 [1] 2/-1/-1->1->0|0->1->2/-1/-1
node001:2466:2675 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000
node001:2465:2676 [0] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/64
node001:2465:2676 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1|-1->0->1/-1/-1
node001:2465:2676 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000
node001:2466:2675 [1] NCCL INFO Ring 00 : 1[81000] -> 2[e2000] via direct shared memory
node001:2467:2674 [2] NCCL INFO Ring 00 : 2[e2000] -> 0[21000] via direct shared memory
node001:2465:2676 [0] NCCL INFO Ring 00 : 0[21000] -> 1[81000] via direct shared memory
node001:2467:2674 [2] NCCL INFO Ring 00 : 2[e2000] -> 1[81000] via direct shared memory
node001:2466:2675 [1] NCCL INFO Ring 00 : 1[81000] -> 0[21000] via direct shared memory
node001:2465:2676 [0] NCCL INFO Ring 01 : 0[21000] -> 1[81000] via direct shared memory
node001:2467:2674 [2] NCCL INFO Ring 01 : 2[e2000] -> 0[21000] via direct shared memory
node001:2466:2675 [1] NCCL INFO Ring 01 : 1[81000] -> 2[e2000] via direct shared memory
node001:2467:2674 [2] NCCL INFO Ring 01 : 2[e2000] -> 1[81000] via direct shared memory
node001:2466:2675 [1] NCCL INFO Ring 01 : 1[81000] -> 0[21000] via direct shared memory
node001:2465:2676 [0] NCCL INFO comm 0x7fff10006620 rank 0 nranks 3 cudaDev 0 busId 21000 - Init COMPLETE
node001:2465:2465 [0] NCCL INFO Launch mode Parallel
node001:2467:2674 [2] NCCL INFO comm 0x7ffefc006620 rank 2 nranks 3 cudaDev 2 busId e2000 - Init COMPLETE
node001:2466:2675 [1] NCCL INFO comm 0x7ffef0006620 rank 1 nranks 3 cudaDev 1 busId 81000 - Init COMPLETE
0: Worker 0 is using worker seed: 267407497
0: Building vocabulary from /data/vocab.bpe.32000
Traceback (most recent call last):
  File "train.py", line 573, in <module>
    main()
  File "train.py", line 349, in main
    pad_vocab)
  File "/workspace/rnn_translator/seq2seq/data/tokenizer.py", line 27, in __init__
    with open(vocab_fname) as vfile:
FileNotFoundError: [Errno 2] No such file or directory: '/data/vocab.bpe.32000'
Traceback (most recent call last):
  File "train.py", line 573, in <module>
    main()
  File "train.py", line 349, in main
Traceback (most recent call last):
  File "train.py", line 573, in <module>
    pad_vocab)
  File "/workspace/rnn_translator/seq2seq/data/tokenizer.py", line 27, in __init__
    with open(vocab_fname) as vfile:
FileNotFoundError: [Errno 2] No such file or directory: '/data/vocab.bpe.32000'
    main()
  File "train.py", line 349, in main
    pad_vocab)
  File "/workspace/rnn_translator/seq2seq/data/tokenizer.py", line 27, in __init__
    with open(vocab_fname) as vfile:
FileNotFoundError: [Errno 2] No such file or directory: '/data/vocab.bpe.32000'
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py", line 235, in <module>
    main()
  File "/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py", line 231, in main
    cmd=process.args)
subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--save', 'gnmt_wmt16', '--dataset-dir', '/data', '--preproc-data-dir', '/preproc_data', '--target-bleu', '24.0', '--epochs', '5', '--math', 'amp_fp16', '--max-length-train', '75', '--print-freq', '10', '--train-batch-size', '768', '--test-batch-size', '128', '--optimizer', 'FusedAdam', '--lr', '2.0e-3', '--warmup-steps', '200', '--remain-steps', '5270', '--decay-interval', '720', '--fused-attention', '--fused-xentropy', '--no-log-all-ranks']' returned non-zero exit status 1.
