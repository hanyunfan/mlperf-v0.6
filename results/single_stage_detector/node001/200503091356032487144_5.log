Beginning trial 5 of 5
Gathering sys log on node001
:::MLL 1588529660.831 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1588529660.832 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1588529660.832 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1588529660.833 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1588529660.834 submission_platform: {"value": "1xPowerEdge R7525", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1588529660.835 submission_entry: {"value": "{'hardware': 'PowerEdge R7525', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': ' ', 'os': '\\\\S / ', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.0-0', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '1', 'cpu': '8x AMD EPYC 7502 32-Core Processor', 'num_cores': '256', 'num_vcpus': '256', 'accelerator': 'Tesla V100S-PCIE-32GB', 'num_accelerators': '3', 'sys_mem_size': '251 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '1x 931.5G', 'cpu_accel_interconnect': 'QPI', 'network_card': '', 'num_network_cards': '0', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1588529660.835 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1588529660.836 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
:::MLL 1588529663.869 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node node001
+ pids+=($!)
+ set +x
++ eval echo
+++ echo
+ docker exec -e DGXSYSTEM=DGX1 -e 'MULTI_NODE= --master_port=5004' -e SLURM_JOB_ID=200503091356032487144 -e SLURM_NTASKS_PER_NODE= cont_200503091356032487144 ./run_and_time.sh
Run vars: id 200503091356032487144 gpus 3 mparams  --master_port=5004
STARTING TIMING RUN AT 2020-05-03 06:14:24 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 32 --nproc_per_node 3 --master_port=5004 --no_hyperthreads --no_membind train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 256 --eval-batch-size 160 --warmup 650 --lr 2.92e-3 --wd 1.6e-4 --use-nvjpeg --use-roi-decode
:::MLL 1588529666.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1588529666.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1588529666.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
2 Using seed = 2510263632
0 Using seed = 2510263630
1 Using seed = 2510263631
:::MLL 1588529671.626 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1588529672.506 model_bn_span: {"value": 256, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1588529672.506 global_batch_size: {"value": 768, "metadata": {"file": "train.py", "lineno": 481}}
:::MLL 1588529672.514 opt_base_learning_rate: {"value": 0.07, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1588529672.515 opt_weight_decay: {"value": 0.00016, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1588529672.515 opt_learning_rate_warmup_steps: {"value": 650, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1588529672.516 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
epoch nbatch loss
:::MLL 1588529679.181 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1588529679.182 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=1.26s)
creating index...
Done (t=1.27s)
creating index...
Done (t=1.27s)
creating index...
time_check a: 1588529682.011635780
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
time_check b: 1588529686.726688147
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
[/opt/dali/dali/util/nvml.h:114] Setting affinity failed! Error code: 22
:::MLL 1588529687.534 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1588529687.537 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 23.078, Average Loss: 0.023, avg. samples / sec: 48.88
Iteration:     20, Loss function: 20.679, Average Loss: 0.448, avg. samples / sec: 1353.56
Iteration:     40, Loss function: 19.559, Average Loss: 0.841, avg. samples / sec: 1460.35
Iteration:     60, Loss function: 13.451, Average Loss: 1.128, avg. samples / sec: 1608.87
Iteration:     80, Loss function: 10.432, Average Loss: 1.336, avg. samples / sec: 1602.14
Iteration:    100, Loss function: 9.633, Average Loss: 1.507, avg. samples / sec: 1605.41
Iteration:    120, Loss function: 9.045, Average Loss: 1.659, avg. samples / sec: 1616.18
Iteration:    140, Loss function: 8.769, Average Loss: 1.803, avg. samples / sec: 1617.72
:::MLL 1588529764.455 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1588529764.456 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:    160, Loss function: 8.543, Average Loss: 1.938, avg. samples / sec: 1620.24
Iteration:    180, Loss function: 8.557, Average Loss: 2.070, avg. samples / sec: 1613.46
Iteration:    200, Loss function: 8.543, Average Loss: 2.198, avg. samples / sec: 1651.21
Iteration:    220, Loss function: 8.000, Average Loss: 2.318, avg. samples / sec: 1630.86
Iteration:    240, Loss function: 7.789, Average Loss: 2.430, avg. samples / sec: 1664.40
Iteration:    260, Loss function: 7.613, Average Loss: 2.537, avg. samples / sec: 1615.46
Iteration:    280, Loss function: 8.030, Average Loss: 2.644, avg. samples / sec: 1619.19
Iteration:    300, Loss function: 7.718, Average Loss: 2.744, avg. samples / sec: 1640.91
:::MLL 1588529836.390 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1588529836.391 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    320, Loss function: 7.173, Average Loss: 2.836, avg. samples / sec: 1643.24
Iteration:    340, Loss function: 7.237, Average Loss: 2.923, avg. samples / sec: 1643.29
Iteration:    360, Loss function: 7.275, Average Loss: 3.007, avg. samples / sec: 1650.57
Iteration:    380, Loss function: 7.255, Average Loss: 3.091, avg. samples / sec: 1653.53
Iteration:    400, Loss function: 6.888, Average Loss: 3.169, avg. samples / sec: 1653.35
Iteration:    420, Loss function: 6.804, Average Loss: 3.241, avg. samples / sec: 1659.10
Iteration:    440, Loss function: 7.339, Average Loss: 3.313, avg. samples / sec: 1622.17
:::MLL 1588529907.931 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1588529907.932 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    460, Loss function: 6.794, Average Loss: 3.385, avg. samples / sec: 1617.21
Iteration:    480, Loss function: 6.829, Average Loss: 3.449, avg. samples / sec: 1623.22
Iteration:    500, Loss function: 6.607, Average Loss: 3.511, avg. samples / sec: 1657.89
Iteration:    520, Loss function: 6.493, Average Loss: 3.569, avg. samples / sec: 1646.72
Iteration:    540, Loss function: 5.978, Average Loss: 3.623, avg. samples / sec: 1627.17
Iteration:    560, Loss function: 6.044, Average Loss: 3.674, avg. samples / sec: 1618.30
Iteration:    580, Loss function: 6.185, Average Loss: 3.725, avg. samples / sec: 1634.07
Iteration:    600, Loss function: 6.035, Average Loss: 3.775, avg. samples / sec: 1667.48
:::MLL 1588529979.140 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1588529979.141 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    620, Loss function: 5.835, Average Loss: 3.820, avg. samples / sec: 1640.43
Iteration:    640, Loss function: 6.464, Average Loss: 3.866, avg. samples / sec: 1625.61
Iteration:    660, Loss function: 6.033, Average Loss: 3.909, avg. samples / sec: 1672.84
Iteration:    680, Loss function: 6.029, Average Loss: 3.949, avg. samples / sec: 1670.57
Iteration:    700, Loss function: 5.714, Average Loss: 3.984, avg. samples / sec: 1666.24
Iteration:    720, Loss function: 5.736, Average Loss: 4.019, avg. samples / sec: 1621.63
Iteration:    740, Loss function: 5.715, Average Loss: 4.052, avg. samples / sec: 1642.90
Iteration:    760, Loss function: 5.584, Average Loss: 4.083, avg. samples / sec: 1651.72
:::MLL 1588530050.402 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1588530050.402 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 5.501, Average Loss: 4.111, avg. samples / sec: 1612.65
Iteration:    800, Loss function: 5.212, Average Loss: 4.137, avg. samples / sec: 1642.38
Iteration:    820, Loss function: 5.566, Average Loss: 4.162, avg. samples / sec: 1675.33
Iteration:    840, Loss function: 5.497, Average Loss: 4.187, avg. samples / sec: 1671.65
Iteration:    860, Loss function: 5.294, Average Loss: 4.212, avg. samples / sec: 1677.70
Iteration:    880, Loss function: 5.299, Average Loss: 4.233, avg. samples / sec: 1654.63
Iteration:    900, Loss function: 5.230, Average Loss: 4.254, avg. samples / sec: 1673.68
:::MLL 1588530121.410 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1588530121.411 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 5.125, Average Loss: 4.275, avg. samples / sec: 1619.18
Iteration:    940, Loss function: 5.088, Average Loss: 4.292, avg. samples / sec: 1652.03
Iteration:    960, Loss function: 5.197, Average Loss: 4.309, avg. samples / sec: 1667.85
Iteration:    980, Loss function: 5.079, Average Loss: 4.326, avg. samples / sec: 1678.91
Iteration:   1000, Loss function: 5.177, Average Loss: 4.342, avg. samples / sec: 1674.79
Iteration:   1020, Loss function: 5.208, Average Loss: 4.360, avg. samples / sec: 1672.17
Iteration:   1040, Loss function: 4.845, Average Loss: 4.373, avg. samples / sec: 1643.67
Iteration:   1060, Loss function: 4.794, Average Loss: 4.386, avg. samples / sec: 1660.58
:::MLL 1588530191.650 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1588530191.651 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:   1080, Loss function: 5.099, Average Loss: 4.399, avg. samples / sec: 1645.17
Iteration:   1100, Loss function: 5.074, Average Loss: 4.413, avg. samples / sec: 1657.12
Iteration:   1120, Loss function: 5.012, Average Loss: 4.425, avg. samples / sec: 1640.14
Iteration:   1140, Loss function: 4.896, Average Loss: 4.436, avg. samples / sec: 1675.69
Iteration:   1160, Loss function: 4.867, Average Loss: 4.445, avg. samples / sec: 1639.67
Iteration:   1180, Loss function: 4.740, Average Loss: 4.454, avg. samples / sec: 1658.98
Iteration:   1200, Loss function: 5.192, Average Loss: 4.463, avg. samples / sec: 1624.84
Iteration:   1220, Loss function: 4.777, Average Loss: 4.472, avg. samples / sec: 1648.35
:::MLL 1588530262.972 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1588530262.972 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:   1240, Loss function: 4.910, Average Loss: 4.478, avg. samples / sec: 1641.79
Iteration:   1260, Loss function: 4.633, Average Loss: 4.485, avg. samples / sec: 1649.47
Iteration:   1280, Loss function: 4.821, Average Loss: 4.492, avg. samples / sec: 1635.04
Iteration:   1300, Loss function: 4.859, Average Loss: 4.498, avg. samples / sec: 1638.85
Iteration:   1320, Loss function: 4.548, Average Loss: 4.504, avg. samples / sec: 1659.37
Iteration:   1340, Loss function: 4.951, Average Loss: 4.509, avg. samples / sec: 1676.37
Iteration:   1360, Loss function: 4.927, Average Loss: 4.515, avg. samples / sec: 1651.66
:::MLL 1588530334.284 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1588530334.285 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:   1380, Loss function: 4.622, Average Loss: 4.519, avg. samples / sec: 1611.17
Iteration:   1400, Loss function: 4.816, Average Loss: 4.524, avg. samples / sec: 1636.50
Iteration:   1420, Loss function: 4.589, Average Loss: 4.527, avg. samples / sec: 1670.68
Iteration:   1440, Loss function: 4.632, Average Loss: 4.530, avg. samples / sec: 1656.21
Iteration:   1460, Loss function: 4.668, Average Loss: 4.534, avg. samples / sec: 1600.14
Iteration:   1480, Loss function: 4.640, Average Loss: 4.537, avg. samples / sec: 1655.05
Iteration:   1500, Loss function: 4.611, Average Loss: 4.539, avg. samples / sec: 1626.12
Iteration:   1520, Loss function: 4.701, Average Loss: 4.541, avg. samples / sec: 1632.41
:::MLL 1588530405.524 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1588530405.524 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.707, Average Loss: 4.543, avg. samples / sec: 1664.90
Iteration:   1560, Loss function: 4.629, Average Loss: 4.545, avg. samples / sec: 1643.27
Iteration:   1580, Loss function: 4.368, Average Loss: 4.546, avg. samples / sec: 1648.25
Iteration:   1600, Loss function: 4.367, Average Loss: 4.547, avg. samples / sec: 1658.05
Iteration:   1620, Loss function: 4.673, Average Loss: 4.549, avg. samples / sec: 1653.18
Iteration:   1640, Loss function: 4.651, Average Loss: 4.550, avg. samples / sec: 1670.09
Iteration:   1660, Loss function: 4.364, Average Loss: 4.549, avg. samples / sec: 1677.23
:::MLL 1588530476.321 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1588530476.322 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 4.576, Average Loss: 4.550, avg. samples / sec: 1667.12
Iteration:   1700, Loss function: 4.362, Average Loss: 4.548, avg. samples / sec: 1643.78
Iteration:   1720, Loss function: 4.560, Average Loss: 4.548, avg. samples / sec: 1674.05
Iteration:   1740, Loss function: 4.626, Average Loss: 4.547, avg. samples / sec: 1667.45
Iteration:   1760, Loss function: 4.694, Average Loss: 4.547, avg. samples / sec: 1643.09
Iteration:   1780, Loss function: 4.482, Average Loss: 4.544, avg. samples / sec: 1641.07
Iteration:   1800, Loss function: 4.581, Average Loss: 4.543, avg. samples / sec: 1669.46
Iteration:   1820, Loss function: 4.744, Average Loss: 4.542, avg. samples / sec: 1673.27
:::MLL 1588530547.150 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1588530547.150 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:   1840, Loss function: 4.466, Average Loss: 4.540, avg. samples / sec: 1653.33
Iteration:   1860, Loss function: 4.409, Average Loss: 4.538, avg. samples / sec: 1676.24
Iteration:   1880, Loss function: 4.531, Average Loss: 4.536, avg. samples / sec: 1680.42
Iteration:   1900, Loss function: 4.231, Average Loss: 4.535, avg. samples / sec: 1675.85
Iteration:   1920, Loss function: 4.583, Average Loss: 4.533, avg. samples / sec: 1667.70
Iteration:   1940, Loss function: 4.257, Average Loss: 4.531, avg. samples / sec: 1676.94
Iteration:   1960, Loss function: 4.418, Average Loss: 4.530, avg. samples / sec: 1625.31
Iteration:   1980, Loss function: 4.304, Average Loss: 4.526, avg. samples / sec: 1670.86
:::MLL 1588530617.231 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1588530617.232 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:   2000, Loss function: 4.284, Average Loss: 4.524, avg. samples / sec: 1633.22
Iteration:   2020, Loss function: 4.399, Average Loss: 4.521, avg. samples / sec: 1629.11
Iteration:   2040, Loss function: 4.269, Average Loss: 4.518, avg. samples / sec: 1661.50
Iteration:   2060, Loss function: 4.367, Average Loss: 4.515, avg. samples / sec: 1639.58
Iteration:   2080, Loss function: 4.395, Average Loss: 4.512, avg. samples / sec: 1636.80
Iteration:   2100, Loss function: 4.286, Average Loss: 4.510, avg. samples / sec: 1650.46
Iteration:   2120, Loss function: 4.180, Average Loss: 4.506, avg. samples / sec: 1679.93
:::MLL 1588530688.459 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1588530688.460 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:   2140, Loss function: 4.268, Average Loss: 4.503, avg. samples / sec: 1658.66
Iteration:   2160, Loss function: 4.526, Average Loss: 4.499, avg. samples / sec: 1669.60
Iteration:   2180, Loss function: 4.475, Average Loss: 4.495, avg. samples / sec: 1650.39
Iteration:   2200, Loss function: 4.506, Average Loss: 4.492, avg. samples / sec: 1629.34
Iteration:   2220, Loss function: 4.525, Average Loss: 4.488, avg. samples / sec: 1610.67
Iteration:   2240, Loss function: 4.244, Average Loss: 4.486, avg. samples / sec: 1641.07
Iteration:   2260, Loss function: 4.355, Average Loss: 4.483, avg. samples / sec: 1675.73
Iteration:   2280, Loss function: 4.561, Average Loss: 4.479, avg. samples / sec: 1659.64
:::MLL 1588530759.886 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1588530759.886 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   2300, Loss function: 4.187, Average Loss: 4.475, avg. samples / sec: 1629.72
Iteration:   2320, Loss function: 4.398, Average Loss: 4.470, avg. samples / sec: 1641.22
Iteration:   2340, Loss function: 4.388, Average Loss: 4.466, avg. samples / sec: 1649.32
Iteration:   2360, Loss function: 4.430, Average Loss: 4.462, avg. samples / sec: 1646.82
Iteration:   2380, Loss function: 4.213, Average Loss: 4.459, avg. samples / sec: 1654.74
Iteration:   2400, Loss function: 4.040, Average Loss: 4.455, avg. samples / sec: 1665.48
Iteration:   2420, Loss function: 4.354, Average Loss: 4.450, avg. samples / sec: 1681.85
Iteration:   2440, Loss function: 4.245, Average Loss: 4.447, avg. samples / sec: 1673.46
:::MLL 1588530830.802 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1588530830.802 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 3.998, Average Loss: 4.443, avg. samples / sec: 1627.73
Iteration:   2480, Loss function: 4.128, Average Loss: 4.439, avg. samples / sec: 1665.79
Iteration:   2500, Loss function: 4.174, Average Loss: 4.435, avg. samples / sec: 1640.15
Iteration:   2520, Loss function: 4.238, Average Loss: 4.431, avg. samples / sec: 1655.44
Iteration:   2540, Loss function: 4.337, Average Loss: 4.428, avg. samples / sec: 1672.51
Iteration:   2560, Loss function: 4.147, Average Loss: 4.424, avg. samples / sec: 1649.57
Iteration:   2580, Loss function: 4.247, Average Loss: 4.420, avg. samples / sec: 1668.60
:::MLL 1588530901.307 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1588530901.307 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 4.152, Average Loss: 4.417, avg. samples / sec: 1661.18
Iteration:   2620, Loss function: 4.198, Average Loss: 4.413, avg. samples / sec: 1668.75
Iteration:   2640, Loss function: 4.196, Average Loss: 4.408, avg. samples / sec: 1677.44
Iteration:   2660, Loss function: 4.319, Average Loss: 4.404, avg. samples / sec: 1678.00
Iteration:   2680, Loss function: 4.115, Average Loss: 4.400, avg. samples / sec: 1662.51
Iteration:   2700, Loss function: 4.189, Average Loss: 4.396, avg. samples / sec: 1648.70
Iteration:   2720, Loss function: 4.160, Average Loss: 4.392, avg. samples / sec: 1669.38
Iteration:   2740, Loss function: 4.349, Average Loss: 4.388, avg. samples / sec: 1678.02
:::MLL 1588530971.761 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1588530971.762 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   2760, Loss function: 4.159, Average Loss: 4.384, avg. samples / sec: 1658.87
Iteration:   2780, Loss function: 4.159, Average Loss: 4.380, avg. samples / sec: 1669.24
Iteration:   2800, Loss function: 4.217, Average Loss: 4.376, avg. samples / sec: 1665.85
Iteration:   2820, Loss function: 4.027, Average Loss: 4.371, avg. samples / sec: 1671.26
Iteration:   2840, Loss function: 4.250, Average Loss: 4.366, avg. samples / sec: 1670.64
Iteration:   2860, Loss function: 4.331, Average Loss: 4.362, avg. samples / sec: 1671.14
Iteration:   2880, Loss function: 3.960, Average Loss: 4.357, avg. samples / sec: 1671.48
Iteration:   2900, Loss function: 4.251, Average Loss: 4.354, avg. samples / sec: 1656.82
:::MLL 1588531042.277 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1588531042.277 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   2920, Loss function: 4.182, Average Loss: 4.350, avg. samples / sec: 1623.10
Iteration:   2940, Loss function: 3.964, Average Loss: 4.344, avg. samples / sec: 1630.28
Iteration:   2960, Loss function: 4.052, Average Loss: 4.339, avg. samples / sec: 1672.28
Iteration:   2980, Loss function: 4.241, Average Loss: 4.336, avg. samples / sec: 1675.63
Iteration:   3000, Loss function: 4.241, Average Loss: 4.331, avg. samples / sec: 1660.07
Iteration:   3020, Loss function: 4.053, Average Loss: 4.327, avg. samples / sec: 1674.19
Iteration:   3040, Loss function: 4.066, Average Loss: 4.323, avg. samples / sec: 1677.07
:::MLL 1588531112.598 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1588531112.598 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   3060, Loss function: 3.869, Average Loss: 4.318, avg. samples / sec: 1651.99
Iteration:   3080, Loss function: 4.147, Average Loss: 4.313, avg. samples / sec: 1627.76
Iteration:   3100, Loss function: 4.092, Average Loss: 4.308, avg. samples / sec: 1640.13
Iteration:   3120, Loss function: 4.029, Average Loss: 4.304, avg. samples / sec: 1672.33
Iteration:   3140, Loss function: 4.114, Average Loss: 4.300, avg. samples / sec: 1645.97
Iteration:   3160, Loss function: 4.067, Average Loss: 4.296, avg. samples / sec: 1675.26
Iteration:   3180, Loss function: 4.085, Average Loss: 4.293, avg. samples / sec: 1666.34
Iteration:   3200, Loss function: 4.124, Average Loss: 4.289, avg. samples / sec: 1674.38
:::MLL 1588531183.553 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1588531183.553 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 3.895, Average Loss: 4.284, avg. samples / sec: 1635.53
Iteration:   3240, Loss function: 4.157, Average Loss: 4.279, avg. samples / sec: 1671.62
Iteration:   3260, Loss function: 4.195, Average Loss: 4.275, avg. samples / sec: 1673.19
Iteration:   3280, Loss function: 4.116, Average Loss: 4.271, avg. samples / sec: 1677.22
Iteration:   3300, Loss function: 4.089, Average Loss: 4.267, avg. samples / sec: 1662.06
Iteration:   3320, Loss function: 3.830, Average Loss: 4.263, avg. samples / sec: 1655.65
Iteration:   3340, Loss function: 4.073, Average Loss: 4.260, avg. samples / sec: 1643.51
:::MLL 1588531254.372 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1588531254.372 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 4.278, Average Loss: 4.256, avg. samples / sec: 1663.88
Iteration:   3380, Loss function: 4.067, Average Loss: 4.253, avg. samples / sec: 1610.71
Iteration:   3400, Loss function: 4.040, Average Loss: 4.249, avg. samples / sec: 1655.76
Iteration:   3420, Loss function: 4.321, Average Loss: 4.244, avg. samples / sec: 1672.52
Iteration:   3440, Loss function: 3.754, Average Loss: 4.240, avg. samples / sec: 1658.20
Iteration:   3460, Loss function: 3.989, Average Loss: 4.237, avg. samples / sec: 1648.48
Iteration:   3480, Loss function: 3.945, Average Loss: 4.232, avg. samples / sec: 1629.80
Iteration:   3500, Loss function: 4.042, Average Loss: 4.227, avg. samples / sec: 1650.75
:::MLL 1588531325.173 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1588531325.173 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   3520, Loss function: 3.985, Average Loss: 4.222, avg. samples / sec: 1664.40
Iteration:   3540, Loss function: 4.027, Average Loss: 4.218, avg. samples / sec: 1625.80
Iteration:   3560, Loss function: 3.859, Average Loss: 4.214, avg. samples / sec: 1631.07
Iteration:   3580, Loss function: 4.127, Average Loss: 4.209, avg. samples / sec: 1625.76
Iteration:   3600, Loss function: 4.186, Average Loss: 4.206, avg. samples / sec: 1661.79
Iteration:   3620, Loss function: 3.833, Average Loss: 4.202, avg. samples / sec: 1665.55
Iteration:   3640, Loss function: 4.174, Average Loss: 4.199, avg. samples / sec: 1636.45
Iteration:   3660, Loss function: 4.033, Average Loss: 4.197, avg. samples / sec: 1663.73
:::MLL 1588531396.605 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1588531396.605 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   3680, Loss function: 3.853, Average Loss: 4.192, avg. samples / sec: 1623.36
Iteration:   3700, Loss function: 3.863, Average Loss: 4.187, avg. samples / sec: 1633.14
Iteration:   3720, Loss function: 3.671, Average Loss: 4.183, avg. samples / sec: 1669.20
Iteration:   3740, Loss function: 3.841, Average Loss: 4.179, avg. samples / sec: 1676.28
Iteration:   3760, Loss function: 3.819, Average Loss: 4.176, avg. samples / sec: 1658.46
Iteration:   3780, Loss function: 4.227, Average Loss: 4.173, avg. samples / sec: 1671.85
Iteration:   3800, Loss function: 3.961, Average Loss: 4.169, avg. samples / sec: 1667.15
:::MLL 1588531467.471 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1588531467.471 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   3820, Loss function: 3.995, Average Loss: 4.165, avg. samples / sec: 1655.82
Iteration:   3840, Loss function: 4.114, Average Loss: 4.161, avg. samples / sec: 1634.41
Iteration:   3860, Loss function: 3.765, Average Loss: 4.157, avg. samples / sec: 1670.08
Iteration:   3880, Loss function: 4.283, Average Loss: 4.153, avg. samples / sec: 1657.96
Iteration:   3900, Loss function: 3.975, Average Loss: 4.149, avg. samples / sec: 1620.86
Iteration:   3920, Loss function: 4.053, Average Loss: 4.147, avg. samples / sec: 1670.18
Iteration:   3940, Loss function: 3.817, Average Loss: 4.143, avg. samples / sec: 1625.76
Iteration:   3960, Loss function: 3.959, Average Loss: 4.139, avg. samples / sec: 1625.42
:::MLL 1588531538.509 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1588531538.509 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 4.126, Average Loss: 4.135, avg. samples / sec: 1636.17
Iteration:   4000, Loss function: 3.823, Average Loss: 4.131, avg. samples / sec: 1628.90
Iteration:   4020, Loss function: 4.014, Average Loss: 4.126, avg. samples / sec: 1635.69
Iteration:   4040, Loss function: 4.199, Average Loss: 4.123, avg. samples / sec: 1662.63
Iteration:   4060, Loss function: 4.052, Average Loss: 4.120, avg. samples / sec: 1668.53
Iteration:   4080, Loss function: 4.040, Average Loss: 4.116, avg. samples / sec: 1651.63
Iteration:   4100, Loss function: 3.977, Average Loss: 4.113, avg. samples / sec: 1643.38
Iteration:   4120, Loss function: 3.934, Average Loss: 4.110, avg. samples / sec: 1629.90
:::MLL 1588531610.014 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1588531610.014 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   4140, Loss function: 3.897, Average Loss: 4.106, avg. samples / sec: 1634.71
Iteration:   4160, Loss function: 3.903, Average Loss: 4.102, avg. samples / sec: 1661.92
Iteration:   4180, Loss function: 4.110, Average Loss: 4.100, avg. samples / sec: 1649.47
Iteration:   4200, Loss function: 3.907, Average Loss: 4.095, avg. samples / sec: 1636.99
Iteration:   4220, Loss function: 4.027, Average Loss: 4.093, avg. samples / sec: 1634.43
Iteration:   4240, Loss function: 3.859, Average Loss: 4.090, avg. samples / sec: 1651.94
Iteration:   4260, Loss function: 3.917, Average Loss: 4.087, avg. samples / sec: 1657.73
:::MLL 1588531681.264 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1588531681.264 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   4280, Loss function: 3.870, Average Loss: 4.084, avg. samples / sec: 1655.06
Iteration:   4300, Loss function: 3.962, Average Loss: 4.079, avg. samples / sec: 1658.28
Iteration:   4320, Loss function: 3.932, Average Loss: 4.076, avg. samples / sec: 1651.76
Iteration:   4340, Loss function: 4.029, Average Loss: 4.072, avg. samples / sec: 1633.08
Iteration:   4360, Loss function: 3.764, Average Loss: 4.068, avg. samples / sec: 1651.24
Iteration:   4380, Loss function: 3.814, Average Loss: 4.064, avg. samples / sec: 1650.55
Iteration:   4400, Loss function: 4.039, Average Loss: 4.061, avg. samples / sec: 1661.37
Iteration:   4420, Loss function: 4.054, Average Loss: 4.059, avg. samples / sec: 1622.21
:::MLL 1588531752.619 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1588531752.619 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   4440, Loss function: 3.891, Average Loss: 4.056, avg. samples / sec: 1660.28
Iteration:   4460, Loss function: 3.962, Average Loss: 4.053, avg. samples / sec: 1657.97
Iteration:   4480, Loss function: 3.948, Average Loss: 4.050, avg. samples / sec: 1666.09
Iteration:   4500, Loss function: 3.873, Average Loss: 4.047, avg. samples / sec: 1657.68
Iteration:   4520, Loss function: 3.866, Average Loss: 4.042, avg. samples / sec: 1671.06
Iteration:   4540, Loss function: 3.752, Average Loss: 4.040, avg. samples / sec: 1665.98
Iteration:   4560, Loss function: 3.925, Average Loss: 4.037, avg. samples / sec: 1653.76
Iteration:   4580, Loss function: 3.790, Average Loss: 4.035, avg. samples / sec: 1668.30
:::MLL 1588531822.868 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1588531822.868 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   4600, Loss function: 3.859, Average Loss: 4.031, avg. samples / sec: 1626.67
Iteration:   4620, Loss function: 3.891, Average Loss: 4.027, avg. samples / sec: 1630.32
Iteration:   4640, Loss function: 3.673, Average Loss: 4.024, avg. samples / sec: 1653.63
Iteration:   4660, Loss function: 3.871, Average Loss: 4.022, avg. samples / sec: 1660.71
Iteration:   4680, Loss function: 3.925, Average Loss: 4.019, avg. samples / sec: 1681.56
Iteration:   4700, Loss function: 4.004, Average Loss: 4.017, avg. samples / sec: 1674.28
Iteration:   4720, Loss function: 3.892, Average Loss: 4.014, avg. samples / sec: 1670.10
:::MLL 1588531893.745 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1588531893.745 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   4740, Loss function: 4.026, Average Loss: 4.011, avg. samples / sec: 1662.22
Iteration:   4760, Loss function: 3.961, Average Loss: 4.008, avg. samples / sec: 1668.48
Iteration:   4780, Loss function: 4.073, Average Loss: 4.006, avg. samples / sec: 1666.58
Iteration:   4800, Loss function: 4.122, Average Loss: 4.004, avg. samples / sec: 1678.70
Iteration:   4820, Loss function: 3.830, Average Loss: 4.001, avg. samples / sec: 1663.07
Iteration:   4840, Loss function: 3.865, Average Loss: 3.997, avg. samples / sec: 1671.61
Iteration:   4860, Loss function: 3.758, Average Loss: 3.994, avg. samples / sec: 1676.56
Iteration:   4880, Loss function: 3.759, Average Loss: 3.992, avg. samples / sec: 1674.52
:::MLL 1588531964.132 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1588531964.132 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   4900, Loss function: 3.775, Average Loss: 3.990, avg. samples / sec: 1648.54
Iteration:   4920, Loss function: 3.751, Average Loss: 3.986, avg. samples / sec: 1673.12
Iteration:   4940, Loss function: 3.589, Average Loss: 3.981, avg. samples / sec: 1657.79
Iteration:   4960, Loss function: 3.799, Average Loss: 3.978, avg. samples / sec: 1667.52
Iteration:   4980, Loss function: 3.865, Average Loss: 3.975, avg. samples / sec: 1671.81
Iteration:   5000, Loss function: 3.906, Average Loss: 3.973, avg. samples / sec: 1667.19
:::MLL 1588532016.737 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/11Parsing batch: 0/11Parsing batch: 0/11Parsing batch: 1/11Parsing batch: 1/11Parsing batch: 1/11Parsing batch: 2/11Parsing batch: 2/11Parsing batch: 2/11Parsing batch: 3/11Parsing batch: 3/11Parsing batch: 3/11Parsing batch: 4/11Parsing batch: 4/11Parsing batch: 4/11Parsing batch: 5/11Parsing batch: 5/11Parsing batch: 5/11Parsing batch: 6/11Parsing batch: 6/11Parsing batch: 6/11Parsing batch: 7/11Parsing batch: 7/11Parsing batch: 7/11Parsing batch: 8/11Parsing batch: 8/11Parsing batch: 8/11Parsing batch: 9/11Parsing batch: 9/11Parsing batch: 9/11Parsing batch: 10/11Parsing batch: 10/11Parsing batch: 10/11Predicting Ended, total time: 13.01 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.71s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.35s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17447
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32571
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04631
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.27917
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26982
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30446
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.44209
Current AP: 0.17447 AP goal: 0.23000
:::MLL 1588532032.890 eval_accuracy: {"value": 0.17446816071131058, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1588532032.891 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1588532032.899 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1588532032.899 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   5020, Loss function: 4.016, Average Loss: 3.970, avg. samples / sec: 600.61
:::MLL 1588532050.575 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1588532050.575 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   5040, Loss function: 3.806, Average Loss: 3.969, avg. samples / sec: 1663.22
Iteration:   5060, Loss function: 3.995, Average Loss: 3.966, avg. samples / sec: 1669.51
Iteration:   5080, Loss function: 3.932, Average Loss: 3.962, avg. samples / sec: 1672.04
Iteration:   5100, Loss function: 3.915, Average Loss: 3.960, avg. samples / sec: 1651.29
Iteration:   5120, Loss function: 3.808, Average Loss: 3.956, avg. samples / sec: 1658.91
Iteration:   5140, Loss function: 3.755, Average Loss: 3.954, avg. samples / sec: 1673.12
Iteration:   5160, Loss function: 3.683, Average Loss: 3.951, avg. samples / sec: 1649.99
Iteration:   5180, Loss function: 3.891, Average Loss: 3.949, avg. samples / sec: 1642.76
:::MLL 1588532121.504 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1588532121.505 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   5200, Loss function: 3.821, Average Loss: 3.946, avg. samples / sec: 1628.96
Iteration:   5220, Loss function: 3.683, Average Loss: 3.943, avg. samples / sec: 1663.00
Iteration:   5240, Loss function: 3.763, Average Loss: 3.940, avg. samples / sec: 1657.32
Iteration:   5260, Loss function: 3.834, Average Loss: 3.937, avg. samples / sec: 1668.69
Iteration:   5280, Loss function: 3.834, Average Loss: 3.935, avg. samples / sec: 1668.17
Iteration:   5300, Loss function: 3.749, Average Loss: 3.932, avg. samples / sec: 1665.79
Iteration:   5320, Loss function: 3.684, Average Loss: 3.931, avg. samples / sec: 1671.18
Iteration:   5340, Loss function: 3.693, Average Loss: 3.927, avg. samples / sec: 1652.30
:::MLL 1588532192.190 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1588532192.191 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   5360, Loss function: 3.610, Average Loss: 3.925, avg. samples / sec: 1628.07
Iteration:   5380, Loss function: 3.684, Average Loss: 3.922, avg. samples / sec: 1650.76
Iteration:   5400, Loss function: 3.824, Average Loss: 3.919, avg. samples / sec: 1670.84
Iteration:   5420, Loss function: 3.811, Average Loss: 3.918, avg. samples / sec: 1670.99
Iteration:   5440, Loss function: 3.770, Average Loss: 3.915, avg. samples / sec: 1646.08
Iteration:   5460, Loss function: 3.455, Average Loss: 3.913, avg. samples / sec: 1670.41
Iteration:   5480, Loss function: 3.941, Average Loss: 3.912, avg. samples / sec: 1677.46
:::MLL 1588532262.658 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1588532262.658 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   5500, Loss function: 3.871, Average Loss: 3.910, avg. samples / sec: 1634.51
Iteration:   5520, Loss function: 3.690, Average Loss: 3.908, avg. samples / sec: 1660.68
Iteration:   5540, Loss function: 3.671, Average Loss: 3.904, avg. samples / sec: 1667.38
Iteration:   5560, Loss function: 3.843, Average Loss: 3.901, avg. samples / sec: 1672.18
Iteration:   5580, Loss function: 3.889, Average Loss: 3.898, avg. samples / sec: 1670.10
Iteration:   5600, Loss function: 3.846, Average Loss: 3.897, avg. samples / sec: 1631.18
Iteration:   5620, Loss function: 3.923, Average Loss: 3.895, avg. samples / sec: 1629.53
Iteration:   5640, Loss function: 3.861, Average Loss: 3.893, avg. samples / sec: 1650.21
:::MLL 1588532333.707 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1588532333.708 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   5660, Loss function: 3.627, Average Loss: 3.891, avg. samples / sec: 1662.67
Iteration:   5680, Loss function: 3.708, Average Loss: 3.888, avg. samples / sec: 1667.77
Iteration:   5700, Loss function: 3.685, Average Loss: 3.886, avg. samples / sec: 1655.35
Iteration:   5720, Loss function: 3.596, Average Loss: 3.884, avg. samples / sec: 1660.59
Iteration:   5740, Loss function: 3.778, Average Loss: 3.883, avg. samples / sec: 1636.96
Iteration:   5760, Loss function: 3.743, Average Loss: 3.880, avg. samples / sec: 1639.71
Iteration:   5780, Loss function: 3.840, Average Loss: 3.879, avg. samples / sec: 1641.43
Iteration:   5800, Loss function: 3.781, Average Loss: 3.877, avg. samples / sec: 1656.26
:::MLL 1588532404.880 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1588532404.880 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   5820, Loss function: 3.770, Average Loss: 3.874, avg. samples / sec: 1650.72
Iteration:   5840, Loss function: 3.903, Average Loss: 3.872, avg. samples / sec: 1651.77
Iteration:   5860, Loss function: 3.609, Average Loss: 3.869, avg. samples / sec: 1673.72
Iteration:   5880, Loss function: 3.648, Average Loss: 3.866, avg. samples / sec: 1659.72
Iteration:   5900, Loss function: 3.661, Average Loss: 3.864, avg. samples / sec: 1668.57
Iteration:   5920, Loss function: 3.914, Average Loss: 3.863, avg. samples / sec: 1676.25
Iteration:   5940, Loss function: 3.656, Average Loss: 3.861, avg. samples / sec: 1659.33
:::MLL 1588532475.140 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1588532475.140 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   5960, Loss function: 3.764, Average Loss: 3.859, avg. samples / sec: 1630.02
Iteration:   5980, Loss function: 3.777, Average Loss: 3.857, avg. samples / sec: 1660.32
Iteration:   6000, Loss function: 3.653, Average Loss: 3.854, avg. samples / sec: 1677.71
Iteration:   6020, Loss function: 3.940, Average Loss: 3.852, avg. samples / sec: 1644.18
Iteration:   6040, Loss function: 3.837, Average Loss: 3.850, avg. samples / sec: 1650.12
Iteration:   6060, Loss function: 3.906, Average Loss: 3.849, avg. samples / sec: 1642.94
Iteration:   6080, Loss function: 3.733, Average Loss: 3.847, avg. samples / sec: 1677.87
Iteration:   6100, Loss function: 3.838, Average Loss: 3.846, avg. samples / sec: 1657.25
:::MLL 1588532546.077 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1588532546.078 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   6120, Loss function: 3.747, Average Loss: 3.844, avg. samples / sec: 1633.30
Iteration:   6140, Loss function: 3.755, Average Loss: 3.842, avg. samples / sec: 1645.26
Iteration:   6160, Loss function: 3.554, Average Loss: 3.840, avg. samples / sec: 1665.52
Iteration:   6180, Loss function: 3.598, Average Loss: 3.838, avg. samples / sec: 1661.34
Iteration:   6200, Loss function: 3.619, Average Loss: 3.837, avg. samples / sec: 1675.71
Iteration:   6220, Loss function: 3.682, Average Loss: 3.835, avg. samples / sec: 1660.28
Iteration:   6240, Loss function: 3.844, Average Loss: 3.834, avg. samples / sec: 1670.76
Iteration:   6260, Loss function: 4.032, Average Loss: 3.833, avg. samples / sec: 1657.38
:::MLL 1588532616.936 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1588532616.938 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   6280, Loss function: 3.811, Average Loss: 3.831, avg. samples / sec: 1619.44
Iteration:   6300, Loss function: 3.843, Average Loss: 3.829, avg. samples / sec: 1653.13
Iteration:   6320, Loss function: 3.591, Average Loss: 3.827, avg. samples / sec: 1663.79
Iteration:   6340, Loss function: 3.690, Average Loss: 3.825, avg. samples / sec: 1663.14
Iteration:   6360, Loss function: 3.751, Average Loss: 3.823, avg. samples / sec: 1636.72
Iteration:   6380, Loss function: 3.938, Average Loss: 3.821, avg. samples / sec: 1670.63
Iteration:   6400, Loss function: 3.689, Average Loss: 3.820, avg. samples / sec: 1643.49
:::MLL 1588532687.717 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1588532687.717 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   6420, Loss function: 3.773, Average Loss: 3.818, avg. samples / sec: 1619.15
Iteration:   6440, Loss function: 3.629, Average Loss: 3.816, avg. samples / sec: 1656.70
Iteration:   6460, Loss function: 3.884, Average Loss: 3.814, avg. samples / sec: 1661.64
Iteration:   6480, Loss function: 3.730, Average Loss: 3.811, avg. samples / sec: 1674.40
Iteration:   6500, Loss function: 3.586, Average Loss: 3.808, avg. samples / sec: 1612.79
Iteration:   6520, Loss function: 3.734, Average Loss: 3.807, avg. samples / sec: 1672.44
Iteration:   6540, Loss function: 3.539, Average Loss: 3.805, avg. samples / sec: 1666.05
Iteration:   6560, Loss function: 3.766, Average Loss: 3.804, avg. samples / sec: 1665.20
:::MLL 1588532758.708 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1588532758.708 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   6580, Loss function: 3.642, Average Loss: 3.802, avg. samples / sec: 1665.07
Iteration:   6600, Loss function: 3.575, Average Loss: 3.799, avg. samples / sec: 1675.74
Iteration:   6620, Loss function: 3.725, Average Loss: 3.797, avg. samples / sec: 1670.15
Iteration:   6640, Loss function: 3.674, Average Loss: 3.795, avg. samples / sec: 1677.80
Iteration:   6660, Loss function: 3.521, Average Loss: 3.793, avg. samples / sec: 1663.10
lr decay step #1
:::MLL 1588532805.188 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/11Parsing batch: 0/11Parsing batch: 0/11Parsing batch: 1/11Parsing batch: 1/11Parsing batch: 1/11Parsing batch: 2/11Parsing batch: 2/11Parsing batch: 2/11Parsing batch: 3/11Parsing batch: 3/11Parsing batch: 3/11Parsing batch: 4/11Parsing batch: 4/11Parsing batch: 4/11Parsing batch: 5/11Parsing batch: 5/11Parsing batch: 5/11Parsing batch: 6/11Parsing batch: 6/11Parsing batch: 6/11Parsing batch: 7/11Parsing batch: 7/11Parsing batch: 7/11Parsing batch: 8/11Parsing batch: 8/11Parsing batch: 9/11Parsing batch: 8/11Parsing batch: 9/11Parsing batch: 9/11Parsing batch: 10/11Parsing batch: 10/11Parsing batch: 10/11Predicting Ended, total time: 12.98 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.75s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.24s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17930
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32680
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17993
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04579
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.19228
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.29450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18739
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27216
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08079
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30518
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.45029
Current AP: 0.17930 AP goal: 0.23000
:::MLL 1588532821.243 eval_accuracy: {"value": 0.17929709059238194, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1588532821.244 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1588532821.253 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1588532821.253 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   6680, Loss function: 3.549, Average Loss: 3.790, avg. samples / sec: 605.61
Iteration:   6700, Loss function: 3.591, Average Loss: 3.785, avg. samples / sec: 1657.81
:::MLL 1588532845.271 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1588532845.272 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   6720, Loss function: 3.393, Average Loss: 3.778, avg. samples / sec: 1665.36
Iteration:   6740, Loss function: 3.299, Average Loss: 3.771, avg. samples / sec: 1654.23
Iteration:   6760, Loss function: 3.461, Average Loss: 3.763, avg. samples / sec: 1626.02
Iteration:   6780, Loss function: 3.242, Average Loss: 3.755, avg. samples / sec: 1640.83
Iteration:   6800, Loss function: 3.468, Average Loss: 3.748, avg. samples / sec: 1643.93
Iteration:   6820, Loss function: 3.183, Average Loss: 3.740, avg. samples / sec: 1625.34
Iteration:   6840, Loss function: 3.331, Average Loss: 3.732, avg. samples / sec: 1623.72
Iteration:   6860, Loss function: 3.233, Average Loss: 3.725, avg. samples / sec: 1662.85
:::MLL 1588532916.945 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1588532916.945 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   6880, Loss function: 3.316, Average Loss: 3.719, avg. samples / sec: 1654.50
Iteration:   6900, Loss function: 3.469, Average Loss: 3.710, avg. samples / sec: 1654.41
Iteration:   6920, Loss function: 3.245, Average Loss: 3.702, avg. samples / sec: 1655.36
Iteration:   6940, Loss function: 3.330, Average Loss: 3.695, avg. samples / sec: 1661.59
Iteration:   6960, Loss function: 3.301, Average Loss: 3.688, avg. samples / sec: 1679.31
Iteration:   6980, Loss function: 3.437, Average Loss: 3.680, avg. samples / sec: 1660.64
Iteration:   7000, Loss function: 3.265, Average Loss: 3.673, avg. samples / sec: 1674.71
Iteration:   7020, Loss function: 3.348, Average Loss: 3.666, avg. samples / sec: 1670.60
:::MLL 1588532987.078 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1588532987.078 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   7040, Loss function: 3.358, Average Loss: 3.659, avg. samples / sec: 1624.60
Iteration:   7060, Loss function: 3.178, Average Loss: 3.652, avg. samples / sec: 1643.89
Iteration:   7080, Loss function: 3.495, Average Loss: 3.646, avg. samples / sec: 1669.04
Iteration:   7100, Loss function: 3.281, Average Loss: 3.638, avg. samples / sec: 1647.26
Iteration:   7120, Loss function: 3.148, Average Loss: 3.631, avg. samples / sec: 1635.15
Iteration:   7140, Loss function: 3.315, Average Loss: 3.625, avg. samples / sec: 1671.14
Iteration:   7160, Loss function: 3.210, Average Loss: 3.618, avg. samples / sec: 1663.44
:::MLL 1588533058.181 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1588533058.182 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   7180, Loss function: 3.143, Average Loss: 3.612, avg. samples / sec: 1658.14
Iteration:   7200, Loss function: 3.313, Average Loss: 3.605, avg. samples / sec: 1667.72
Iteration:   7220, Loss function: 3.349, Average Loss: 3.599, avg. samples / sec: 1675.43
Iteration:   7240, Loss function: 3.502, Average Loss: 3.594, avg. samples / sec: 1666.58
Iteration:   7260, Loss function: 3.243, Average Loss: 3.587, avg. samples / sec: 1670.17
Iteration:   7280, Loss function: 3.119, Average Loss: 3.581, avg. samples / sec: 1678.74
Iteration:   7300, Loss function: 3.242, Average Loss: 3.574, avg. samples / sec: 1666.58
Iteration:   7320, Loss function: 3.365, Average Loss: 3.568, avg. samples / sec: 1645.74
:::MLL 1588533128.724 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1588533128.725 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   7340, Loss function: 3.161, Average Loss: 3.562, avg. samples / sec: 1640.74
Iteration:   7360, Loss function: 3.293, Average Loss: 3.556, avg. samples / sec: 1644.28
Iteration:   7380, Loss function: 3.201, Average Loss: 3.550, avg. samples / sec: 1646.31
Iteration:   7400, Loss function: 3.294, Average Loss: 3.544, avg. samples / sec: 1665.23
Iteration:   7420, Loss function: 3.071, Average Loss: 3.538, avg. samples / sec: 1631.42
Iteration:   7440, Loss function: 3.258, Average Loss: 3.533, avg. samples / sec: 1651.42
Iteration:   7460, Loss function: 3.047, Average Loss: 3.528, avg. samples / sec: 1636.36
Iteration:   7480, Loss function: 3.409, Average Loss: 3.523, avg. samples / sec: 1673.38
:::MLL 1588533199.589 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1588533199.590 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   7500, Loss function: 3.255, Average Loss: 3.517, avg. samples / sec: 1618.83
:::MLL 1588533208.629 eval_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 276}}
Parsing batch: 0/11Parsing batch: 0/11Parsing batch: 0/11Parsing batch: 1/11Parsing batch: 1/11Parsing batch: 1/11Parsing batch: 2/11Parsing batch: 2/11Parsing batch: 2/11Parsing batch: 3/11Parsing batch: 3/11Parsing batch: 3/11Parsing batch: 4/11Parsing batch: 4/11Parsing batch: 4/11Parsing batch: 5/11Parsing batch: 5/11Parsing batch: 5/11Parsing batch: 6/11Parsing batch: 6/11Parsing batch: 6/11Parsing batch: 7/11Parsing batch: 7/11Parsing batch: 7/11Parsing batch: 8/11Parsing batch: 8/11Parsing batch: 8/11Parsing batch: 9/11Parsing batch: 9/11Parsing batch: 9/11Parsing batch: 10/11Parsing batch: 10/11Parsing batch: 10/11Predicting Ended, total time: 12.49 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.53s)
DONE (t=0.77s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.81s)
DONE (t=2.31s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23302
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39692
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.24069
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06310
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37792
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22462
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34274
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37321
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53558
Current AP: 0.23302 AP goal: 0.23000
:::MLL 1588533224.274 eval_accuracy: {"value": 0.23301730828572872, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 389}}
:::MLL 1588533224.319 eval_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 392}}
:::MLL 1588533224.328 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1588533224.830 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-05-03 07:13:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,3565,nvidia,2020-05-03 06:14:24 PM
