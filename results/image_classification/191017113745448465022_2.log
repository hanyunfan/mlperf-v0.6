Beginning trial 2 of 3
Run vars: id 191017113745448465022
Gathering sys log on dss01
:::MLL 1571338121.767 submission_benchmark: {"value": "resnet", "metadata": {"lineno": 226, "file": "mlperf_log_utils.py"}}
:::MLL 1571338121.768 submission_org: {"value": "NVIDIA", "metadata": {"lineno": 231, "file": "mlperf_log_utils.py"}}
WARNING: Log validation: Key "submission_division" is not in known resnet keys.
:::MLL 1571338121.769 submission_division: {"value": "closed", "metadata": {"lineno": 235, "file": "mlperf_log_utils.py"}}
:::MLL 1571338121.769 submission_status: {"value": "onprem", "metadata": {"lineno": 239, "file": "mlperf_log_utils.py"}}
:::MLL 1571338121.770 submission_platform: {"value": "1xDSS8440", "metadata": {"lineno": 243, "file": "mlperf_log_utils.py"}}
:::MLL 1571338121.770 submission_entry: {"value": "{'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'power': 'N/A', 'framework': 'MXNet NVIDIA Release 19.05', 'hardware': 'DSS8440', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'libraries': \"{'trt_version': '5.1.5.0', 'cudnn_version': '7.6.0.64', 'dali_version': '0.9.1', 'nccl_version': '2.4.6', 'container_base': 'Ubuntu-16.04', 'mofed_version': '5.0-0', 'cublas_version': '10.2.0.163', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'openmpi_version': '3.1.3'}\", 'nodes': \"{'sys_storage_type': 'SATA SSD', 'num_vcpus': '40', 'num_cores': '40', 'num_nodes': '1', 'network_card': 'Mellanox Technologies MT27700 Family [ConnectX-4]', 'sys_mem_size': '754 GB', 'sys_storage_size': '1x 931.5G + 1x 447.1G', 'notes': '', 'cpu_accel_interconnect': 'UPI', 'num_accelerators': '8', 'accelerator': 'Tesla V100-PCIE-32GB', 'cpu': '2x Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz', 'num_network_cards': '1'}\", 'notes': 'N/A', 'os': '\\\\S / '}", "metadata": {"lineno": 247, "file": "mlperf_log_utils.py"}}
:::MLL 1571338121.771 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"lineno": 251, "file": "mlperf_log_utils.py"}}
:::MLL 1571338121.771 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"lineno": 255, "file": "mlperf_log_utils.py"}}
Clearing cache on dss01
:::MLL 1571338142.444 cache_clear: {"metadata": {"lineno": 1, "file": "<string>"}, "value": true}

Launching user script on master node:
[1,0]<stdout>:STARTING TIMING RUN AT 2019-10-17 06:49:03 PM
[1,0]<stdout>:running benchmark
[1,1]<stdout>:STARTING TIMING RUN AT 2019-10-17 06:49:03 PM
[1,1]<stdout>:running benchmark
[1,2]<stdout>:STARTING TIMING RUN AT 2019-10-17 06:49:03 PM
[1,2]<stdout>:running benchmark
[1,3]<stdout>:STARTING TIMING RUN AT 2019-10-17 06:49:03 PM
[1,3]<stdout>:running benchmark
[1,4]<stdout>:STARTING TIMING RUN AT 2019-10-17 06:49:03 PM
[1,4]<stdout>:running benchmark
[1,5]<stdout>:STARTING TIMING RUN AT 2019-10-17 06:49:03 PM
[1,5]<stdout>:running benchmark
[1,6]<stdout>:STARTING TIMING RUN AT 2019-10-17 06:49:03 PM
[1,6]<stdout>:running benchmark
[1,7]<stdout>:STARTING TIMING RUN AT 2019-10-17 06:49:03 PM
[1,7]<stdout>:running benchmark
[1,7]<stderr>:[18:49:03] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,0]<stderr>:[18:49:03] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,1]<stderr>:[18:49:03] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,2]<stderr>:[18:49:03] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,3]<stderr>:[18:49:03] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,4]<stderr>:[18:49:03] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,5]<stderr>:[18:49:03] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,6]<stderr>:[18:49:03] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
--------------------------------------------------------------------------
WARNING: One or more nonexistent OpenFabrics devices/ports were
specified:

  Host:                 dss01
  MCA parameter:        mca_btl_if_include
  Nonexistent entities: mlx5_3

These entities will be ignored.  You can disable this warning by
setting the btl_openib_warn_nonexistent_if MCA parameter to 0.
--------------------------------------------------------------------------
[1,7]<stdout>::::MLL 1571338151.506 init_start: {"value": null, "metadata": {"file": "train_imagenet.py", "lineno": 83}}
[1,0]<stdout>::::MLL 1571338151.506 init_start: {"metadata": {"file": "train_imagenet.py", "lineno": 83}, "value": null}
[1,1]<stdout>::::MLL 1571338151.506 init_start: {"metadata": {"file": "train_imagenet.py", "lineno": 83}, "value": null}
[1,2]<stdout>::::MLL 1571338151.506 init_start: {"value": null, "metadata": {"lineno": 83, "file": "train_imagenet.py"}}
[1,3]<stdout>::::MLL 1571338151.506 init_start: {"value": null, "metadata": {"file": "train_imagenet.py", "lineno": 83}}
[1,4]<stdout>::::MLL 1571338151.506 init_start: {"metadata": {"lineno": 83, "file": "train_imagenet.py"}, "value": null}
[1,5]<stdout>::::MLL 1571338151.506 init_start: {"value": null, "metadata": {"file": "train_imagenet.py", "lineno": 83}}
[1,6]<stdout>::::MLL 1571338151.507 init_start: {"value": null, "metadata": {"lineno": 83, "file": "train_imagenet.py"}}
[dss01:00877] 7 more processes have sent help message help-mpi-btl-openib.txt / nonexistent port
[dss01:00877] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_initial_shape" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.912 model_hp_initial_shape: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 266}, "value": [4, 224, 224]}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.913 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.914 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.915 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.916 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.917 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.918 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.919 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.920 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.921 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.921 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.922 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.924 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.924 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.925 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.926 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.927 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_final_shape" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.928 model_hp_final_shape: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 309}, "value": 1000}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_loss_fn" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338163.928 model_hp_loss_fn: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 320}, "value": "categorical_cross_entropy"}
[1,0]<stdout>::::MLL 1571338163.931 model_bn_span: {"metadata": {"file": "common/dali.py", "lineno": 229}, "value": 208}
[1,4]<stdout>:WARNING: `nvJPEGDecoderRandomCrop` is now deprecated. Use `ImageDecoderRandomCrop` instead
[1,1]<stdout>:WARNING: `nvJPEGDecoderRandomCrop` is now deprecated. Use `ImageDecoderRandomCrop` instead
[1,0]<stdout>:WARNING: `nvJPEGDecoderRandomCrop` is now deprecated. Use `ImageDecoderRandomCrop` instead
[1,5]<stdout>:WARNING: `nvJPEGDecoderRandomCrop` is now deprecated. Use `ImageDecoderRandomCrop` instead
[1,3]<stdout>:WARNING: `nvJPEGDecoderRandomCrop` is now deprecated. Use `ImageDecoderRandomCrop` instead
[1,2]<stdout>:WARNING: `nvJPEGDecoderRandomCrop` is now deprecated. Use `ImageDecoderRandomCrop` instead
[1,6]<stdout>:WARNING: `nvJPEGDecoderRandomCrop` is now deprecated. Use `ImageDecoderRandomCrop` instead
[1,7]<stdout>:WARNING: `nvJPEGDecoderRandomCrop` is now deprecated. Use `ImageDecoderRandomCrop` instead
[1,4]<stdout>:WARNING: `nvJPEGDecoder` is now deprecated. Use `ImageDecoder` instead
[1,1]<stdout>:WARNING: `nvJPEGDecoder` is now deprecated. Use `ImageDecoder` instead
[1,0]<stdout>:WARNING: `nvJPEGDecoder` is now deprecated. Use `ImageDecoder` instead
[1,5]<stdout>:WARNING: `nvJPEGDecoder` is now deprecated. Use `ImageDecoder` instead
[1,2]<stdout>:WARNING: `nvJPEGDecoder` is now deprecated. Use `ImageDecoder` instead
[1,3]<stdout>:WARNING: `nvJPEGDecoder` is now deprecated. Use `ImageDecoder` instead
[1,6]<stdout>:WARNING: `nvJPEGDecoder` is now deprecated. Use `ImageDecoder` instead
[1,7]<stdout>:WARNING: `nvJPEGDecoder` is now deprecated. Use `ImageDecoder` instead
[1,0]<stdout>::::MLL 1571338173.379 init_stop: {"metadata": {"file": "train_imagenet.py", "lineno": 187}, "value": null}
[1,0]<stdout>::::MLL 1571338173.380 run_start: {"metadata": {"file": "train_imagenet.py", "lineno": 190}, "value": null}
[1,0]<stderr>:2019-10-17 18:49:33,380 Node[0] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=440, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,6]<stderr>:2019-10-17 18:49:33,380 Node[6] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31987, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,5]<stderr>:2019-10-17 18:49:33,380 Node[5] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=35553, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,7]<stderr>:2019-10-17 18:49:33,380 Node[7] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=62326, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,1]<stderr>:2019-10-17 18:49:33,380 Node[1] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=44279, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,3]<stderr>:2019-10-17 18:49:33,380 Node[3] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=51453, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,4]<stderr>:2019-10-17 18:49:33,380 Node[4] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=25383, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,2]<stderr>:2019-10-17 18:49:33,380 Node[2] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=44723, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,7]<stderr>:2019-10-17 18:49:35,992 Node[7] Already bound, ignoring bind()
[1,3]<stderr>:2019-10-17 18:49:36,022 Node[3] Already bound, ignoring bind()
[1,2]<stderr>:2019-10-17 18:49:36,064 Node[2] Already bound, ignoring bind()
[1,5]<stderr>:2019-10-17 18:49:36,065 Node[5] Already bound, ignoring bind()
[1,0]<stdout>::::MLL 1571338176.114 opt_base_learning_rate: {"metadata": {"file": "common/fit.py", "lineno": 651}, "value": 5.0}
[1,0]<stdout>::::MLL 1571338176.114 opt_learning_rate_warmup_epochs: {"metadata": {"file": "common/fit.py", "lineno": 652}, "value": 5}
[1,0]<stdout>::::MLL 1571338176.114 lars_opt_learning_rate_decay_steps: {"metadata": {"file": "common/fit.py", "lineno": 662}, "value": 51590}
[1,0]<stdout>::::MLL 1571338176.115 lars_opt_learning_rate_decay_poly_power: {"metadata": {"file": "common/fit.py", "lineno": 698}, "value": 2}
[1,0]<stdout>::::MLL 1571338176.115 lars_opt_end_learning_rate: {"metadata": {"file": "common/fit.py", "lineno": 699}, "value": 0.0001}
[1,0]<stdout>::::MLL 1571338176.115 opt_name: {"metadata": {"file": "common/fit.py", "lineno": 1075}, "value": "lars"}
[1,0]<stdout>::::MLL 1571338176.116 lars_epsilon: {"metadata": {"file": "common/fit.py", "lineno": 1077}, "value": 0}
[1,0]<stdout>:WARNING: Log validation: Key "lars_opt_weight_decay" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571338176.116 lars_opt_weight_decay: {"metadata": {"file": "common/fit.py", "lineno": 1079}, "value": 0.0002}
[1,0]<stdout>:using wd on conv0_weight
[1,0]<stdout>:skipping wd on bn0_gamma
[1,0]<stdout>:skipping wd on bn0_beta
[1,0]<stdout>:using wd on stage1_unit1_conv1_weight
[1,0]<stdout>:skipping wd on stage1_unit1_bn1_gamma
[1,0]<stdout>:skipping wd on stage1_unit1_bn1_beta
[1,0]<stdout>:using wd on stage1_unit1_conv2_weight
[1,0]<stdout>:skipping wd on stage1_unit1_bn2_gamma
[1,0]<stdout>:skipping wd on stage1_unit1_bn2_beta
[1,0]<stdout>:using wd on stage1_unit1_conv3_weight
[1,0]<stdout>:skipping wd on stage1_unit1_bn3_gamma
[1,0]<stdout>:skipping wd on stage1_unit1_bn3_beta
[1,0]<stdout>:using wd on stage1_unit1_conv1sc_weight
[1,0]<stdout>:skipping wd on stage1_unit1_bn_sc_gamma
[1,0]<stdout>:skipping wd on stage1_unit1_bn_sc_beta
[1,0]<stdout>:using wd on stage1_unit2_conv1_weight
[1,0]<stdout>:skipping wd on stage1_unit2_bn1_gamma
[1,0]<stdout>:skipping wd on stage1_unit2_bn1_beta
[1,0]<stdout>:using wd on stage1_unit2_conv2_weight
[1,0]<stdout>:skipping wd on stage1_unit2_bn2_gamma
[1,0]<stdout>:skipping wd on stage1_unit2_bn2_beta
[1,0]<stdout>:using wd on stage1_unit2_conv3_weight
[1,0]<stdout>:skipping wd on stage1_unit2_bn3_gamma
[1,0]<stdout>:skipping wd on stage1_unit2_bn3_beta
[1,0]<stdout>:using wd on stage1_unit3_conv1_weight
[1,0]<stdout>:skipping wd on stage1_unit3_bn1_gamma
[1,0]<stdout>:skipping wd on stage1_unit3_bn1_beta
[1,0]<stdout>:using wd on stage1_unit3_conv2_weight
[1,0]<stdout>:skipping wd on stage1_unit3_bn2_gamma
[1,0]<stdout>:skipping wd on stage1_unit3_bn2_beta
[1,0]<stdout>:using wd on stage1_unit3_conv3_weight
[1,0]<stdout>:skipping wd on stage1_unit3_bn3_gamma
[1,0]<stdout>:skipping wd on stage1_unit3_bn3_beta
[1,0]<stdout>:using wd on stage2_unit1_conv1_weight
[1,0]<stdout>:skipping wd on stage2_unit1_bn1_gamma
[1,0]<stdout>:skipping wd on stage2_unit1_bn1_beta
[1,0]<stdout>:using wd on stage2_unit1_conv2_weight
[1,0]<stdout>:skipping wd on stage2_unit1_bn2_gamma
[1,0]<stdout>:skipping wd on stage2_unit1_bn2_beta
[1,0]<stdout>:using wd on stage2_unit1_conv3_weight
[1,0]<stdout>:skipping wd on stage2_unit1_bn3_gamma
[1,0]<stdout>:skipping wd on stage2_unit1_bn3_beta
[1,0]<stdout>:using wd on stage2_unit1_conv1sc_weight
[1,0]<stdout>:skipping wd on stage2_unit1_bn_sc_gamma
[1,0]<stdout>:skipping wd on stage2_unit1_bn_sc_beta
[1,0]<stdout>:using wd on stage2_unit2_conv1_weight
[1,0]<stdout>:skipping wd on stage2_unit2_bn1_gamma
[1,0]<stdout>:skipping wd on stage2_unit2_bn1_beta
[1,0]<stdout>:using wd on stage2_unit2_conv2_weight
[1,0]<stdout>:skipping wd on stage2_unit2_bn2_gamma
[1,0]<stdout>:skipping wd on stage2_unit2_bn2_beta
[1,0]<stdout>:using wd on stage2_unit2_conv3_weight
[1,0]<stdout>:skipping wd on stage2_unit2_bn3_gamma
[1,0]<stdout>:skipping wd on stage2_unit2_bn3_beta
[1,0]<stdout>:using wd on stage2_unit3_conv1_weight
[1,0]<stdout>:skipping wd on stage2_unit3_bn1_gamma
[1,0]<stdout>:skipping wd on stage2_unit3_bn1_beta
[1,0]<stdout>:using wd on stage2_unit3_conv2_weight
[1,0]<stdout>:skipping wd on stage2_unit3_bn2_gamma
[1,0]<stdout>:skipping wd on stage2_unit3_bn2_beta
[1,0]<stdout>:using wd on stage2_unit3_conv3_weight
[1,0]<stdout>:skipping wd on stage2_unit3_bn3_gamma
[1,0]<stdout>:skipping wd on stage2_unit3_bn3_beta
[1,0]<stdout>:using wd on stage2_unit4_conv1_weight
[1,0]<stdout>:skipping wd on stage2_unit4_bn1_gamma
[1,0]<stdout>:skipping wd on stage2_unit4_bn1_beta
[1,0]<stdout>:using wd on stage2_unit4_conv2_weight
[1,0]<stdout>:skipping wd on stage2_unit4_bn2_gamma
[1,0]<stdout>:skipping wd on stage2_unit4_bn2_beta
[1,0]<stdout>:using wd on stage2_unit4_conv3_weight
[1,0]<stdout>:skipping wd on stage2_unit4_bn3_gamma
[1,0]<stdout>:skipping wd on stage2_unit4_bn3_beta
[1,0]<stdout>:using wd on stage3_unit1_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit1_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit1_bn1_beta
[1,0]<stdout>:using wd on stage3_unit1_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit1_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit1_bn2_beta
[1,0]<stdout>:using wd on stage3_unit1_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit1_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit1_bn3_beta
[1,0]<stdout>:using wd on stage3_unit1_conv1sc_weight
[1,0]<stdout>:skipping wd on stage3_unit1_bn_sc_gamma
[1,0]<stdout>:skipping wd on stage3_unit1_bn_sc_beta
[1,0]<stdout>:using wd on stage3_unit2_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit2_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit2_bn1_beta
[1,0]<stdout>:using wd on stage3_unit2_conv2_weight
[1,0]<stdout>:skipping wd[1,0]<stdout>: on stage3_unit2_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit2_bn2_beta
[1,0]<stdout>:using wd on stage3_unit2_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit2_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit2_bn3_beta
[1,0]<stdout>:using wd on stage3_unit3_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit3_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit3_bn1_beta
[1,0]<stdout>:using wd on stage3_unit3_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit3_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit3_bn2_beta
[1,0]<stdout>:using wd on stage3_unit3_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit3_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit3_bn3_beta
[1,0]<stdout>:using wd on stage3_unit4_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit4_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit4_bn1_beta
[1,0]<stdout>:using wd on stage3_unit4_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit4_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit4_bn2_beta
[1,0]<stdout>:using wd on stage3_unit4_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit4_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit4_bn3_beta
[1,0]<stdout>:using wd on stage3_unit5_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit5_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit5_bn1_beta
[1,0]<stdout>:using wd on stage3_unit5_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit5_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit5_bn2_beta
[1,0]<stdout>:using wd on stage3_unit5_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit5_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit5_bn3_beta
[1,0]<stdout>:using wd on stage3_unit6_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit6_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit6_bn1_beta
[1,0]<stdout>:using wd on stage3_unit6_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit6_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit6_bn2_beta
[1,0]<stdout>:using wd on stage3_unit6_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit6_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit6_bn3_beta
[1,0]<stdout>:using wd on stage4_unit1_conv1_weight
[1,0]<stdout>:skipping wd on stage4_unit1_bn1_gamma
[1,0]<stdout>:skipping wd on stage4_unit1_bn1_beta
[1,0]<stdout>:using wd on stage4_unit1_conv2_weight
[1,0]<stdout>:skipping wd on stage4_unit1_bn2_gamma
[1,0]<stdout>:skipping wd on stage4_unit1_bn2_beta
[1,0]<stdout>:using wd on stage4_unit1_conv3_weight
[1,0]<stdout>:skipping wd on stage4_unit1_bn3_gamma
[1,0]<stdout>:skipping wd on stage4_unit1_bn3_beta
[1,0]<stdout>:using wd on stage4_unit1_conv1sc_weight
[1,0]<stdout>:skipping wd on stage4_unit1_bn_sc_gamma
[1,0]<stdout>:skipping wd on stage4_unit1_bn_sc_beta
[1,0]<stdout>:using wd on stage4_unit2_conv1_weight
[1,0]<stdout>:skipping wd on stage4_unit2_bn1_gamma
[1,0]<stdout>:skipping wd on stage4_unit2_bn1_beta
[1,0]<stdout>:using wd on stage4_unit2_conv2_weight
[1,0]<stdout>:skipping wd on stage4_unit2_bn2_gamma
[1,0]<stdout>:skipping wd on stage4_unit2_bn2_beta
[1,0]<stdout>:using wd on stage4_unit2_conv3_weight
[1,0]<stdout>:skipping wd on stage4_unit2_bn3_gamma
[1,0]<stdout>:skipping wd on stage4_unit2_bn3_beta
[1,0]<stdout>:using wd on stage4_unit3_conv1_weight
[1,0]<stdout>:skipping wd on stage4_unit3_bn1_gamma
[1,0]<stdout>:skipping wd on stage4_unit3_bn1_beta
[1,0]<stdout>:using wd on stage4_unit3_conv2_weight
[1,0]<stdout>:skipping wd on stage4_unit3_bn2_gamma
[1,0]<stdout>:skipping wd on stage4_unit3_bn2_beta
[1,0]<stdout>:using wd on stage4_unit3_conv3_weight
[1,0]<stdout>:skipping wd on stage4_unit3_bn3_gamma
[1,0]<stdout>:skipping wd on stage4_unit3_bn3_beta
[1,0]<stdout>:using wd on fc1_weight
[1,0]<stdout>:using wd on fc1_bias
[1,0]<stdout>::::MLL 1571338176.117 global_batch_size: {"metadata": {"file": "common/fit.py", "lineno": 1112}, "value": 1664}
[1,0]<stderr>:2019-10-17 18:49:36,117 Node[0] Already bound, ignoring bind()
[1,0]<stdout>::::MLL 1571338176.118 block_start: {"metadata": {"file": "common/fit.py", "lineno": 888, "first_epoch_num": 1, "epoch_count": 4}, "value": null}
[1,0]<stdout>::::MLL 1571338176.118 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 1, "lineno": 893}, "value": null}
[1,6]<stderr>:2019-10-17 18:49:36,125 Node[6] Already bound, ignoring bind()
[1,1]<stderr>:2019-10-17 18:49:36,155 Node[1] Already bound, ignoring bind()
[1,4]<stderr>:2019-10-17 18:49:36,240 Node[4] Already bound, ignoring bind()
[1,0]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,0]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,0]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,0]<stderr>:  optimizer_params=optimizer_params)
[1,0]<stderr>:2019-10-17 18:49:46,079 Node[0] Epoch[0] Batch [0-20]	Speed: 8993.00 samples/sec	accuracy=0.001603
[1,0]<stderr>:2019-10-17 18:49:49,554 Node[0] Epoch[0] Batch [20-40]	Speed: 9580.76 samples/sec	accuracy=0.001202
[1,0]<stderr>:2019-10-17 18:49:52,971 Node[0] Epoch[0] Batch [40-60]	Speed: 9741.37 samples/sec	accuracy=0.000962
[1,0]<stderr>:2019-10-17 18:49:56,383 Node[0] Epoch[0] Batch [60-80]	Speed: 9753.20 samples/sec	accuracy=0.002404
[1,0]<stderr>:2019-10-17 18:49:59,782 Node[0] Epoch[0] Batch [80-100]	Speed: 9794.22 samples/sec	accuracy=0.001683
[1,0]<stderr>:2019-10-17 18:50:03,220 Node[0] Epoch[0] Batch [100-120]	Speed: 9679.22 samples/sec	accuracy=0.003125
[1,0]<stderr>:2019-10-17 18:50:06,621 Node[0] Epoch[0] Batch [120-140]	Speed: 9787.50 samples/sec	accuracy=0.003846
[1,0]<stderr>:2019-10-17 18:50:09,979 Node[0] Epoch[0] Batch [140-160]	Speed: 9912.30 samples/sec	accuracy=0.005529
[1,0]<stderr>:2019-10-17 18:50:13,418 Node[0] Epoch[0] Batch [160-180]	Speed: 9678.83 samples/sec	accuracy=0.004808
[1,0]<stderr>:2019-10-17 18:50:16,830 Node[0] Epoch[0] Batch [180-200]	Speed: 9756.89 samples/sec	accuracy=0.007933
[1,0]<stderr>:2019-10-17 18:50:20,251 Node[0] Epoch[0] Batch [200-220]	Speed: 9729.09 samples/sec	accuracy=0.006250
[1,0]<stderr>:2019-10-17 18:50:23,623 Node[0] Epoch[0] Batch [220-240]	Speed: 9870.15 samples/sec	accuracy=0.010577
[1,0]<stderr>:2019-10-17 18:50:27,066 Node[0] Epoch[0] Batch [240-260]	Speed: 9667.20 samples/sec	accuracy=0.011538
[1,0]<stderr>:2019-10-17 18:50:30,509 Node[0] Epoch[0] Batch [260-280]	Speed: 9666.68 samples/sec	accuracy=0.015144
[1,0]<stderr>:2019-10-17 18:50:33,977 Node[0] Epoch[0] Batch [280-300]	Speed: 9601.77 samples/sec	accuracy=0.013462
[1,0]<stderr>:2019-10-17 18:50:37,368 Node[0] Epoch[0] Batch [300-320]	Speed: 9814.98 samples/sec	accuracy=0.015144
[1,0]<stderr>:2019-10-17 18:50:40,781 Node[0] Epoch[0] Batch [320-340]	Speed: 9752.54 samples/sec	accuracy=0.022837
[1,0]<stderr>:2019-10-17 18:50:44,145 Node[0] Epoch[0] Batch [340-360]	Speed: 9893.21 samples/sec	accuracy=0.026202
[1,0]<stderr>:2019-10-17 18:50:47,552 Node[0] Epoch[0] Batch [360-380]	Speed: 9769.09 samples/sec	accuracy=0.025240
[1,0]<stderr>:2019-10-17 18:50:50,938 Node[0] Epoch[0] Batch [380-400]	Speed: 9831.84 samples/sec	accuracy=0.028846
[1,0]<stderr>:2019-10-17 18:50:54,340 Node[0] Epoch[0] Batch [400-420]	Speed: 9781.12 samples/sec	accuracy=0.033654
[1,0]<stderr>:2019-10-17 18:50:57,679 Node[0] Epoch[0] Batch [420-440]	Speed: 9968.36 samples/sec	accuracy=0.029087
[1,0]<stderr>:2019-10-17 18:51:01,062 Node[0] Epoch[0] Batch [440-460]	Speed: 9838.31 samples/sec	accuracy=0.035577
[1,0]<stderr>:2019-10-17 18:51:04,511 Node[0] Epoch[0] Batch [460-480]	Speed: 9651.68 samples/sec	accuracy=0.040625
[1,0]<stderr>:2019-10-17 18:51:07,967 Node[0] Epoch[0] Batch [480-500]	Speed: 9629.19 samples/sec	accuracy=0.046635
[1,0]<stderr>:2019-10-17 18:51:11,338 Node[0] Epoch[0] Batch [500-520]	Speed: 9873.84 samples/sec	accuracy=0.046875
[1,0]<stderr>:2019-10-17 18:51:14,744 Node[0] Epoch[0] Batch [520-540]	Speed: 9770.91 samples/sec	accuracy=0.052404
[1,0]<stderr>:2019-10-17 18:51:18,173 Node[0] Epoch[0] Batch [540-560]	Speed: 9706.82 samples/sec	accuracy=0.054567
[1,0]<stderr>:2019-10-17 18:51:21,553 Node[0] Epoch[0] Batch [560-580]	Speed: 9846.84 samples/sec	accuracy=0.058654
[1,0]<stderr>:2019-10-17 18:51:24,912 Node[0] Epoch[0] Batch [580-600]	Speed: 9908.54 samples/sec	accuracy=0.057212
[1,0]<stderr>:2019-10-17 18:51:28,318 Node[0] Epoch[0] Batch [600-620]	Speed: 9772.41 samples/sec	accuracy=0.064183
[1,0]<stderr>:2019-10-17 18:51:31,641 Node[0] Epoch[0] Batch [620-640]	Speed: 10015.21 samples/sec	accuracy=0.068269
[1,0]<stderr>:2019-10-17 18:51:35,100 Node[0] Epoch[0] Batch [640-660]	Speed: 9622.02 samples/sec	accuracy=0.066827
[1,0]<stderr>:2019-10-17 18:51:38,499 Node[0] Epoch[0] Batch [660-680]	Speed: 9791.02 samples/sec	accuracy=0.069231
[1,0]<stderr>:2019-10-17 18:51:41,865 Node[0] Epoch[0] Batch [680-700]	Speed: 9888.74 samples/sec	accuracy=0.079567
[1,0]<stderr>:2019-10-17 18:51:45,336 Node[0] Epoch[0] Batch [700-720]	Speed: 9588.57 samples/sec	accuracy=0.084135
[1,0]<stderr>:2019-10-17 18:51:48,799 Node[0] Epoch[0] Batch [720-740]	Speed: 9610.80 samples/sec	accuracy=0.080529
[1,0]<stderr>:2019-10-17 18:51:52,169 Node[0] Epoch[0] Batch [740-760]	Speed: 9876.10 samples/sec	accuracy=0.088462
[1,0]<stderr>:2019-10-17 18:51:53,652 Node[0] Epoch[0] Time cost=137.534
[1,0]<stdout>::::MLL 1571338313.652 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 1, "lineno": 932}, "value": null}
[1,0]<stdout>::::MLL 1571338313.653 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 2, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 18:51:57,132 Node[0] Epoch[1] Batch [0-20]	Speed: 10044.72 samples/sec	accuracy=0.095009
[1,0]<stderr>:2019-10-17 18:52:00,460 Node[0] Epoch[1] Batch [20-40]	Speed: 10001.42 samples/sec	accuracy=0.098798
[1,0]<stderr>:2019-10-17 18:52:03,798 Node[0] Epoch[1] Batch [40-60]	Speed: 9971.12 samples/sec	accuracy=0.098558
[1,0]<stderr>:2019-10-17 18:52:07,084 Node[0] Epoch[1] Batch [60-80]	Speed: 10127.93 samples/sec	accuracy=0.103846
[1,0]<stderr>:2019-10-17 18:52:10,386 Node[0] Epoch[1] Batch [80-100]	Speed: 10078.89 samples/sec	accuracy=0.111779
[1,0]<stderr>:2019-10-17 18:52:13,690 Node[0] Epoch[1] Batch [100-120]	Speed: 10074.58 samples/sec	accuracy=0.111298
[1,0]<stderr>:2019-10-17 18:52:17,025 Node[0] Epoch[1] Batch [120-140]	Speed: 9980.59 samples/sec	accuracy=0.112981
[1,0]<stderr>:2019-10-17 18:52:20,324 Node[0] Epoch[1] Batch [140-160]	Speed: 10087.35 samples/sec	accuracy=0.124519
[1,0]<stderr>:2019-10-17 18:52:23,682 Node[0] Epoch[1] Batch [160-180]	Speed: 9910.93 samples/sec	accuracy=0.121154
[1,0]<stderr>:2019-10-17 18:52:27,009 Node[0] Epoch[1] Batch [180-200]	Speed: 10004.26 samples/sec	accuracy=0.122356
[1,0]<stderr>:2019-10-17 18:52:30,332 Node[0] Epoch[1] Batch [200-220]	Speed: 10017.88 samples/sec	accuracy=0.131010
[1,0]<stderr>:2019-10-17 18:52:33,632 Node[0] Epoch[1] Batch [220-240]	Speed: 10085.65 samples/sec	accuracy=0.126442
[1,0]<stderr>:2019-10-17 18:52:37,010 Node[0] Epoch[1] Batch [240-260]	Speed: 9851.42 samples/sec	accuracy=0.139183
[1,0]<stderr>:2019-10-17 18:52:40,323 Node[0] Epoch[1] Batch [260-280]	Speed: 10046.52 samples/sec	accuracy=0.154808
[1,0]<stderr>:2019-10-17 18:52:43,651 Node[0] Epoch[1] Batch [280-300]	Speed: 10002.84 samples/sec	accuracy=0.142548
[1,0]<stderr>:2019-10-17 18:52:46,976 Node[0] Epoch[1] Batch [300-320]	Speed: 10009.19 samples/sec	accuracy=0.154808
[1,0]<stderr>:2019-10-17 18:52:50,293 Node[0] Epoch[1] Batch [320-340]	Speed: 10031.82 samples/sec	accuracy=0.149760
[1,0]<stderr>:2019-10-17 18:52:53,664 Node[0] Epoch[1] Batch [340-360]	Speed: 9874.39 samples/sec	accuracy=0.153365
[1,0]<stderr>:2019-10-17 18:52:56,969 Node[0] Epoch[1] Batch [360-380]	Speed: 10070.51 samples/sec	accuracy=0.158173
[1,0]<stderr>:2019-10-17 18:53:00,302 Node[0] Epoch[1] Batch [380-400]	Speed: 9985.04 samples/sec	accuracy=0.158173
[1,0]<stderr>:2019-10-17 18:53:03,589 Node[0] Epoch[1] Batch [400-420]	Speed: 10126.57 samples/sec	accuracy=0.172115
[1,0]<stderr>:2019-10-17 18:53:06,888 Node[0] Epoch[1] Batch [420-440]	Speed: 10090.42 samples/sec	accuracy=0.156731
[1,0]<stderr>:2019-10-17 18:53:10,218 Node[0] Epoch[1] Batch [440-460]	Speed: 9992.69 samples/sec	accuracy=0.169712
[1,0]<stderr>:2019-10-17 18:53:13,516 Node[0] Epoch[1] Batch [460-480]	Speed: 10092.94 samples/sec	accuracy=0.191346
[1,0]<stderr>:2019-10-17 18:53:16,810 Node[0] Epoch[1] Batch [480-500]	Speed: 10104.83 samples/sec	accuracy=0.182452
[1,0]<stderr>:2019-10-17 18:53:20,184 Node[0] Epoch[1] Batch [500-520]	Speed: 9864.00 samples/sec	accuracy=0.179567
[1,0]<stderr>:2019-10-17 18:53:23,481 Node[0] Epoch[1] Batch [520-540]	Speed: 10094.86 samples/sec	accuracy=0.192067
[1,0]<stderr>:2019-10-17 18:53:26,781 Node[0] Epoch[1] Batch [540-560]	Speed: 10086.19 samples/sec	accuracy=0.186538
[1,0]<stderr>:2019-10-17 18:53:30,088 Node[0] Epoch[1] Batch [560-580]	Speed: 10065.51 samples/sec	accuracy=0.201202
[1,0]<stderr>:2019-10-17 18:53:33,409 Node[0] Epoch[1] Batch [580-600]	Speed: 10019.69 samples/sec	accuracy=0.200240
[1,0]<stderr>:2019-10-17 18:53:36,707 Node[0] Epoch[1] Batch [600-620]	Speed: 10094.64 samples/sec	accuracy=0.206490
[1,0]<stderr>:2019-10-17 18:53:40,027 Node[0] Epoch[1] Batch [620-640]	Speed: 10022.75 samples/sec	accuracy=0.210096
[1,0]<stderr>:2019-10-17 18:53:43,373 Node[0] Epoch[1] Batch [640-660]	Speed: 9947.54 samples/sec	accuracy=0.205048
[1,0]<stderr>:2019-10-17 18:53:46,707 Node[0] Epoch[1] Batch [660-680]	Speed: 9983.82 samples/sec	accuracy=0.218029
[1,0]<stderr>:2019-10-17 18:53:49,995 Node[0] Epoch[1] Batch [680-700]	Speed: 10121.80 samples/sec	accuracy=0.226683
[1,0]<stderr>:2019-10-17 18:53:53,297 Node[0] Epoch[1] Batch [700-720]	Speed: 10080.79 samples/sec	accuracy=0.210337
[1,0]<stderr>:2019-10-17 18:53:56,581 Node[0] Epoch[1] Batch [720-740]	Speed: 10133.84 samples/sec	accuracy=0.228125
[1,0]<stderr>:2019-10-17 18:53:59,935 Node[0] Epoch[1] Batch [740-760]	Speed: 9924.00 samples/sec	accuracy=0.228606
[1,0]<stdout>::::MLL 1571338441.432 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 2, "lineno": 932}, "value": null}
[1,0]<stderr>:2019-10-17 18:54:01,432 Node[0] Epoch[1] Time cost=127.779
[1,0]<stdout>::::MLL 1571338441.433 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 3, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 18:54:04,906 Node[0] Epoch[2] Batch [0-20]	Speed: 10065.73 samples/sec	accuracy=0.217262
[1,0]<stderr>:2019-10-17 18:54:08,198 Node[0] Epoch[2] Batch [20-40]	Speed: 10110.37 samples/sec	accuracy=0.232212
[1,0]<stderr>:2019-10-17 18:54:11,524 Node[0] Epoch[2] Batch [40-60]	Speed: 10005.59 samples/sec	accuracy=0.240865
[1,0]<stderr>:2019-10-17 18:54:14,799 Node[0] Epoch[2] Batch [60-80]	Speed: 10162.65 samples/sec	accuracy=0.234135
[1,0]<stderr>:2019-10-17 18:54:18,105 Node[0] Epoch[2] Batch [80-100]	Speed: 10066.52 samples/sec	accuracy=0.250000
[1,0]<stderr>:2019-10-17 18:54:21,438 Node[0] Epoch[2] Batch [100-120]	Speed: 9985.99 samples/sec	accuracy=0.245913
[1,0]<stderr>:2019-10-17 18:54:24,755 Node[0] Epoch[2] Batch [120-140]	Speed: 10036.78 samples/sec	accuracy=0.258173
[1,0]<stderr>:2019-10-17 18:54:28,047 Node[0] Epoch[2] Batch [140-160]	Speed: 10107.43 samples/sec	accuracy=0.248798
[1,0]<stderr>:2019-10-17 18:54:31,365 Node[0] Epoch[2] Batch [160-180]	Speed: 10031.45 samples/sec	accuracy=0.264904
[1,0]<stderr>:2019-10-17 18:54:34,682 Node[0] Epoch[2] Batch [180-200]	Speed: 10033.66 samples/sec	accuracy=0.257933
[1,0]<stderr>:2019-10-17 18:54:37,995 Node[0] Epoch[2] Batch [200-220]	Speed: 10048.29 samples/sec	accuracy=0.257452
[1,0]<stderr>:2019-10-17 18:54:41,379 Node[0] Epoch[2] Batch [220-240]	Speed: 9836.09 samples/sec	accuracy=0.264183
[1,0]<stderr>:2019-10-17 18:54:44,664 Node[0] Epoch[2] Batch [240-260]	Speed: 10130.06 samples/sec	accuracy=0.268750
[1,0]<stderr>:2019-10-17 18:54:47,976 Node[0] Epoch[2] Batch [260-280]	Speed: 10049.48 samples/sec	accuracy=0.258894
[1,0]<stderr>:2019-10-17 18:54:51,284 Node[0] Epoch[2] Batch [280-300]	Speed: 10061.16 samples/sec	accuracy=0.270913
[1,0]<stderr>:2019-10-17 18:54:54,571 Node[0] Epoch[2] Batch [300-320]	Speed: 10126.23 samples/sec	accuracy=0.270192
[1,0]<stderr>:2019-10-17 18:54:57,877 Node[0] Epoch[2] Batch [320-340]	Speed: 10066.29 samples/sec	accuracy=0.278365
[1,0]<stderr>:2019-10-17 18:55:01,230 Node[0] Epoch[2] Batch [340-360]	Speed: 9928.46 samples/sec	accuracy=0.262740
[1,0]<stderr>:2019-10-17 18:55:04,515 Node[0] Epoch[2] Batch [360-380]	Speed: 10130.79 samples/sec	accuracy=0.277404
[1,0]<stderr>:2019-10-17 18:55:07,819 Node[0] Epoch[2] Batch [380-400]	Speed: 10074.08 samples/sec	accuracy=0.287981
[1,0]<stderr>:2019-10-17 18:55:11,141 Node[0] Epoch[2] Batch [400-420]	Speed: 10019.52 samples/sec	accuracy=0.270192
[1,0]<stderr>:2019-10-17 18:55:14,445 Node[0] Epoch[2] Batch [420-440]	Speed: 10073.26 samples/sec	accuracy=0.281971
[1,0]<stderr>:2019-10-17 18:55:17,726 Node[0] Epoch[2] Batch [440-460]	Speed: 10144.85 samples/sec	accuracy=0.285337
[1,0]<stderr>:2019-10-17 18:55:21,047 Node[0] Epoch[2] Batch [460-480]	Speed: 10019.21 samples/sec	accuracy=0.297356
[1,0]<stderr>:2019-10-17 18:55:24,383 Node[0] Epoch[2] Batch [480-500]	Speed: 9977.85 samples/sec	accuracy=0.286298
[1,0]<stderr>:2019-10-17 18:55:27,707 Node[0] Epoch[2] Batch [500-520]	Speed: 10014.19 samples/sec	accuracy=0.282933
[1,0]<stderr>:2019-10-17 18:55:31,037 Node[0] Epoch[2] Batch [520-540]	Speed: 9993.64 samples/sec	accuracy=0.297596
[1,0]<stderr>:2019-10-17 18:55:34,337 Node[0] Epoch[2] Batch [540-560]	Speed: 10085.14 samples/sec	accuracy=0.304087
[1,0]<stderr>:2019-10-17 18:55:37,641 Node[0] Epoch[2] Batch [560-580]	Speed: 10074.22 samples/sec	accuracy=0.298798
[1,0]<stderr>:2019-10-17 18:55:40,943 Node[0] Epoch[2] Batch [580-600]	Speed: 10080.65 samples/sec	accuracy=0.305048
[1,0]<stderr>:2019-10-17 18:55:44,264 Node[0] Epoch[2] Batch [600-620]	Speed: 10021.38 samples/sec	accuracy=0.305769
[1,0]<stderr>:2019-10-17 18:55:47,560 Node[0] Epoch[2] Batch [620-640]	Speed: 10097.39 samples/sec	accuracy=0.303846
[1,0]<stderr>:2019-10-17 18:55:50,902 Node[0] Epoch[2] Batch [640-660]	Speed: 9961.31 samples/sec	accuracy=0.309856
[1,0]<stderr>:2019-10-17 18:55:54,204 Node[0] Epoch[2] Batch [660-680]	Speed: 10079.61 samples/sec	accuracy=0.312260
[1,0]<stderr>:2019-10-17 18:55:57,477 Node[0] Epoch[2] Batch [680-700]	Speed: 10169.20 samples/sec	accuracy=0.308654
[1,0]<stderr>:2019-10-17 18:56:00,820 Node[0] Epoch[2] Batch [700-720]	Speed: 9955.23 samples/sec	accuracy=0.311058
[1,0]<stderr>:2019-10-17 18:56:04,135 Node[0] Epoch[2] Batch [720-740]	Speed: 10040.17 samples/sec	accuracy=0.321154
[1,0]<stderr>:2019-10-17 18:56:07,434 Node[0] Epoch[2] Batch [740-760]	Speed: 10088.28 samples/sec	accuracy=0.308654
[1,0]<stderr>:2019-10-17 18:56:08,944 Node[0] Epoch[2] Time cost=127.511
[1,0]<stdout>::::MLL 1571338568.944 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 3, "lineno": 932}, "value": null}
[1,0]<stdout>::::MLL 1571338568.945 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 4, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 18:56:12,458 Node[0] Epoch[3] Batch [0-20]	Speed: 9973.45 samples/sec	accuracy=0.328068
[1,0]<stderr>:2019-10-17 18:56:15,778 Node[0] Epoch[3] Batch [20-40]	Speed: 10022.50 samples/sec	accuracy=0.309135
[1,0]<stderr>:2019-10-17 18:56:19,090 Node[0] Epoch[3] Batch [40-60]	Speed: 10049.71 samples/sec	accuracy=0.335337
[1,0]<stderr>:2019-10-17 18:56:22,419 Node[0] Epoch[3] Batch [60-80]	Speed: 9997.37 samples/sec	accuracy=0.321394
[1,0]<stderr>:2019-10-17 18:56:25,729 Node[0] Epoch[3] Batch [80-100]	Speed: 10055.77 samples/sec	accuracy=0.332933
[1,0]<stderr>:2019-10-17 18:56:29,037 Node[0] Epoch[3] Batch [100-120]	Speed: 10061.77 samples/sec	accuracy=0.327885
[1,0]<stderr>:2019-10-17 18:56:32,371 Node[0] Epoch[3] Batch [120-140]	Speed: 9983.29 samples/sec	accuracy=0.320192
[1,0]<stderr>:2019-10-17 18:56:35,684 Node[0] Epoch[3] Batch [140-160]	Speed: 10046.46 samples/sec	accuracy=0.327644
[1,0]<stderr>:2019-10-17 18:56:38,978 Node[0] Epoch[3] Batch [160-180]	Speed: 10105.19 samples/sec	accuracy=0.339183
[1,0]<stderr>:2019-10-17 18:56:42,268 Node[0] Epoch[3] Batch [180-200]	Speed: 10115.88 samples/sec	accuracy=0.331731
[1,0]<stderr>:2019-10-17 18:56:45,592 Node[0] Epoch[3] Batch [200-220]	Speed: 10011.81 samples/sec	accuracy=0.332212
[1,0]<stderr>:2019-10-17 18:56:48,926 Node[0] Epoch[3] Batch [220-240]	Speed: 9985.82 samples/sec	accuracy=0.321154
[1,0]<stderr>:2019-10-17 18:56:52,222 Node[0] Epoch[3] Batch [240-260]	Speed: 10097.04 samples/sec	accuracy=0.337740
[1,0]<stderr>:2019-10-17 18:56:55,540 Node[0] Epoch[3] Batch [260-280]	Speed: 10029.88 samples/sec	accuracy=0.338942
[1,0]<stderr>:2019-10-17 18:56:58,814 Node[0] Epoch[3] Batch [280-300]	Speed: 10167.15 samples/sec	accuracy=0.336779
[1,0]<stderr>:2019-10-17 18:57:02,129 Node[0] Epoch[3] Batch [300-320]	Speed: 10039.69 samples/sec	accuracy=0.340144
[1,0]<stderr>:2019-10-17 18:57:05,456 Node[0] Epoch[3] Batch [320-340]	Speed: 10003.62 samples/sec	accuracy=0.339423
[1,0]<stderr>:2019-10-17 18:57:08,753 Node[0] Epoch[3] Batch [340-360]	Speed: 10094.33 samples/sec	accuracy=0.343510
[1,0]<stderr>:2019-10-17 18:57:12,100 Node[0] Epoch[3] Batch [360-380]	Speed: 9946.28 samples/sec	accuracy=0.354327
[1,0]<stderr>:2019-10-17 18:57:15,468 Node[0] Epoch[3] Batch [380-400]	Speed: 9880.21 samples/sec	accuracy=0.334856
[1,0]<stderr>:2019-10-17 18:57:18,759 Node[0] Epoch[3] Batch [400-420]	Speed: 10114.20 samples/sec	accuracy=0.353365
[1,0]<stderr>:2019-10-17 18:57:22,073 Node[0] Epoch[3] Batch [420-440]	Speed: 10043.08 samples/sec	accuracy=0.346875
[1,0]<stderr>:2019-10-17 18:57:25,377 Node[0] Epoch[3] Batch [440-460]	Speed: 10073.57 samples/sec	accuracy=0.342067
[1,0]<stderr>:2019-10-17 18:57:28,686 Node[0] Epoch[3] Batch [460-480]	Speed: 10059.20 samples/sec	accuracy=0.363462
[1,0]<stderr>:2019-10-17 18:57:32,004 Node[0] Epoch[3] Batch [480-500]	Speed: 10030.53 samples/sec	accuracy=0.358413
[1,0]<stderr>:2019-10-17 18:57:35,334 Node[0] Epoch[3] Batch [500-520]	Speed: 9996.08 samples/sec	accuracy=0.349038
[1,0]<stderr>:2019-10-17 18:57:38,643 Node[0] Epoch[3] Batch [520-540]	Speed: 10056.73 samples/sec	accuracy=0.356250
[1,0]<stderr>:2019-10-17 18:57:41,966 Node[0] Epoch[3] Batch [540-560]	Speed: 10016.74 samples/sec	accuracy=0.346394
[1,0]<stderr>:2019-10-17 18:57:45,290 Node[0] Epoch[3] Batch [560-580]	Speed: 10013.92 samples/sec	accuracy=0.357933
[1,0]<stderr>:2019-10-17 18:57:48,585 Node[0] Epoch[3] Batch [580-600]	Speed: 10100.92 samples/sec	accuracy=0.364663
[1,0]<stderr>:2019-10-17 18:57:51,914 Node[0] Epoch[3] Batch [600-620]	Speed: 9999.06 samples/sec	accuracy=0.368990
[1,0]<stderr>:2019-10-17 18:57:55,242 Node[0] Epoch[3] Batch [620-640]	Speed: 10001.31 samples/sec	accuracy=0.365865
[1,0]<stderr>:2019-10-17 18:57:58,611 Node[0] Epoch[3] Batch [640-660]	Speed: 9878.67 samples/sec	accuracy=0.368750
[1,0]<stderr>:2019-10-17 18:58:01,925 Node[0] Epoch[3] Batch [660-680]	Speed: 10043.20 samples/sec	accuracy=0.359135
[1,0]<stderr>:2019-10-17 18:58:05,248 Node[0] Epoch[3] Batch [680-700]	Speed: 10014.52 samples/sec	accuracy=0.370913
[1,0]<stderr>:2019-10-17 18:58:08,595 Node[0] Epoch[3] Batch [700-720]	Speed: 9945.39 samples/sec	accuracy=0.369231
[1,0]<stderr>:2019-10-17 18:58:11,935 Node[0] Epoch[3] Batch [720-740]	Speed: 9965.05 samples/sec	accuracy=0.374279
[1,0]<stderr>:2019-10-17 18:58:15,237 Node[0] Epoch[3] Batch [740-760]	Speed: 10079.29 samples/sec	accuracy=0.364183
[1,5]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,5]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,5]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,5]<stderr>:  optimizer_params=optimizer_params)
[1,5]<stderr>:2019-10-17 18:58:16,736 Node[5] DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,3]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,3]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,3]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,3]<stderr>:  optimizer_params=optimizer_params)
[1,3]<stderr>:2019-10-17 18:58:16,737 Node[3] DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2019-10-17 18:58:16,737 Node[0] Epoch[3] Time cost=127.793
[1,0]<stderr>:2019-10-17 18:58:16,738 Node[0] DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,7]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,7]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,7]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,7]<stderr>:  optimizer_params=optimizer_params)
[1,7]<stderr>:2019-10-17 18:58:16,737 Node[7] DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stdout>::::MLL 1571338696.738 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 4, "lineno": 932}, "value": null}
[1,0]<stdout>::::MLL 1571338696.738 eval_start: {"metadata": {"file": "common/fit.py", "epoch_num": 4, "lineno": 956}, "value": null}
[1,1]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,1]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,1]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,1]<stderr>:  optimizer_params=optimizer_params)
[1,1]<stderr>:2019-10-17 18:58:16,738 Node[1] DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,6]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,6]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,6]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,6]<stderr>:  optimizer_params=optimizer_params)
[1,6]<stderr>:2019-10-17 18:58:16,738 Node[6] DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,4]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,4]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,4]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,4]<stderr>:  optimizer_params=optimizer_params)
[1,4]<stderr>:2019-10-17 18:58:16,741 Node[4] DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,2]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,2]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,2]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,2]<stderr>:  optimizer_params=optimizer_params)
[1,2]<stderr>:2019-10-17 18:58:16,749 Node[2] DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2019-10-17 18:58:20,599 Node[0] Epoch[3] Validation-accuracy=0.356480
[1,0]<stderr>:2019-10-17 18:58:20,600 Node[0] Epoch[3] Validation-correct-count=2228.000000
[1,0]<stderr>:2019-10-17 18:58:20,600 Node[0] Epoch[3] Validation-total-count=6250.000000
[1,0]<stdout>::::MLL 1571338700.659 eval_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 4, "lineno": 977}, "value": null}
[1,0]<stdout>::::MLL 1571338700.660 eval_accuracy: {"metadata": {"file": "common/fit.py", "epoch_num": 4, "lineno": 980}, "value": 0.3549}
[1,0]<stdout>::::MLL 1571338700.660 block_stop: {"metadata": {"file": "common/fit.py", "lineno": 984, "first_epoch_num": 1}, "value": null}
[1,0]<stdout>::::MLL 1571338700.660 block_start: {"metadata": {"file": "common/fit.py", "lineno": 997, "first_epoch_num": 5, "epoch_count": 4}, "value": null}
[1,0]<stdout>::::MLL 1571338700.661 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 5, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 18:58:24,687 Node[0] Epoch[4] Batch [0-20]	Speed: 8502.73 samples/sec	accuracy=0.354167
[1,0]<stderr>:2019-10-17 18:58:27,976 Node[0] Epoch[4] Batch [20-40]	Speed: 10119.55 samples/sec	accuracy=0.360817
[1,0]<stderr>:2019-10-17 18:58:31,271 Node[0] Epoch[4] Batch [40-60]	Speed: 10099.91 samples/sec	accuracy=0.359615
[1,0]<stderr>:2019-10-17 18:58:34,593 Node[0] Epoch[4] Batch [60-80]	Speed: 10019.30 samples/sec	accuracy=0.372837
[1,0]<stderr>:2019-10-17 18:58:37,935 Node[0] Epoch[4] Batch [80-100]	Speed: 9957.96 samples/sec	accuracy=0.372356
[1,0]<stderr>:2019-10-17 18:58:41,244 Node[0] Epoch[4] Batch [100-120]	Speed: 10059.29 samples/sec	accuracy=0.374760
[1,0]<stderr>:2019-10-17 18:58:44,523 Node[0] Epoch[4] Batch [120-140]	Speed: 10152.39 samples/sec	accuracy=0.370192
[1,0]<stderr>:2019-10-17 18:58:47,858 Node[0] Epoch[4] Batch [140-160]	Speed: 9977.48 samples/sec	accuracy=0.354808
[1,0]<stderr>:2019-10-17 18:58:51,158 Node[0] Epoch[4] Batch [160-180]	Speed: 10087.84 samples/sec	accuracy=0.372596
[1,0]<stderr>:2019-10-17 18:58:54,486 Node[0] Epoch[4] Batch [180-200]	Speed: 9999.05 samples/sec	accuracy=0.374519
[1,0]<stderr>:2019-10-17 18:58:57,821 Node[0] Epoch[4] Batch [200-220]	Speed: 9979.98 samples/sec	accuracy=0.373317
[1,0]<stderr>:2019-10-17 18:59:01,123 Node[0] Epoch[4] Batch [220-240]	Speed: 10081.45 samples/sec	accuracy=0.373798
[1,0]<stderr>:2019-10-17 18:59:04,484 Node[0] Epoch[4] Batch [240-260]	Speed: 9901.43 samples/sec	accuracy=0.381971
[1,0]<stderr>:2019-10-17 18:59:07,799 Node[0] Epoch[4] Batch [260-280]	Speed: 10042.59 samples/sec	accuracy=0.372596
[1,0]<stderr>:2019-10-17 18:59:11,065 Node[0] Epoch[4] Batch [280-300]	Speed: 10189.01 samples/sec	accuracy=0.380769
[1,0]<stderr>:2019-10-17 18:59:14,399 Node[0] Epoch[4] Batch [300-320]	Speed: 9982.83 samples/sec	accuracy=0.379567
[1,0]<stderr>:2019-10-17 18:59:17,691 Node[0] Epoch[4] Batch [320-340]	Speed: 10111.51 samples/sec	accuracy=0.373798
[1,0]<stderr>:2019-10-17 18:59:21,002 Node[0] Epoch[4] Batch [340-360]	Speed: 10053.19 samples/sec	accuracy=0.366346
[1,0]<stderr>:2019-10-17 18:59:24,309 Node[0] Epoch[4] Batch [360-380]	Speed: 10062.94 samples/sec	accuracy=0.373558
[1,0]<stderr>:2019-10-17 18:59:27,622 Node[0] Epoch[4] Batch [380-400]	Speed: 10047.42 samples/sec	accuracy=0.384375
[1,0]<stderr>:2019-10-17 18:59:30,928 Node[0] Epoch[4] Batch [400-420]	Speed: 10067.33 samples/sec	accuracy=0.395433
[1,0]<stderr>:2019-10-17 18:59:34,250 Node[0] Epoch[4] Batch [420-440]	Speed: 10019.72 samples/sec	accuracy=0.388942
[1,0]<stderr>:2019-10-17 18:59:37,541 Node[0] Epoch[4] Batch [440-460]	Speed: 10112.59 samples/sec	accuracy=0.378365
[1,0]<stderr>:2019-10-17 18:59:40,862 Node[0] Epoch[4] Batch [460-480]	Speed: 10023.65 samples/sec	accuracy=0.376923
[1,0]<stderr>:2019-10-17 18:59:44,191 Node[0] Epoch[4] Batch [480-500]	Speed: 9999.29 samples/sec	accuracy=0.384615
[1,0]<stderr>:2019-10-17 18:59:47,522 Node[0] Epoch[4] Batch [500-520]	Speed: 9994.24 samples/sec	accuracy=0.385337
[1,0]<stderr>:2019-10-17 18:59:50,794 Node[0] Epoch[4] Batch [520-540]	Speed: 10173.51 samples/sec	accuracy=0.380048
[1,0]<stderr>:2019-10-17 18:59:54,115 Node[0] Epoch[4] Batch [540-560]	Speed: 10024.83 samples/sec	accuracy=0.382452
[1,0]<stderr>:2019-10-17 18:59:57,447 Node[0] Epoch[4] Batch [560-580]	Speed: 9989.88 samples/sec	accuracy=0.392788
[1,0]<stderr>:2019-10-17 19:00:00,777 Node[0] Epoch[4] Batch [580-600]	Speed: 9995.53 samples/sec	accuracy=0.395192
[1,0]<stderr>:2019-10-17 19:00:04,100 Node[0] Epoch[4] Batch [600-620]	Speed: 10014.88 samples/sec	accuracy=0.383413
[1,0]<stderr>:2019-10-17 19:00:07,380 Node[0] Epoch[4] Batch [620-640]	Speed: 10147.20 samples/sec	accuracy=0.391346
[1,0]<stderr>:2019-10-17 19:00:10,685 Node[0] Epoch[4] Batch [640-660]	Speed: 10072.64 samples/sec	accuracy=0.387260
[1,0]<stderr>:2019-10-17 19:00:14,027 Node[0] Epoch[4] Batch [660-680]	Speed: 9959.69 samples/sec	accuracy=0.396875
[1,0]<stderr>:2019-10-17 19:00:17,332 Node[0] Epoch[4] Batch [680-700]	Speed: 10070.53 samples/sec	accuracy=0.394231
[1,0]<stderr>:2019-10-17 19:00:20,653 Node[0] Epoch[4] Batch [700-720]	Speed: 10020.43 samples/sec	accuracy=0.393510
[1,0]<stderr>:2019-10-17 19:00:23,970 Node[0] Epoch[4] Batch [720-740]	Speed: 10033.36 samples/sec	accuracy=0.390865
[1,0]<stderr>:2019-10-17 19:00:27,272 Node[0] Epoch[4] Batch [740-760]	Speed: 10082.47 samples/sec	accuracy=0.399760
[1,0]<stderr>:2019-10-17 19:00:28,766 Node[0] Epoch[4] Time cost=128.106
[1,0]<stdout>::::MLL 1571338828.766 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 5, "lineno": 932}, "value": null}
[1,0]<stdout>::::MLL 1571338828.767 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 6, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 19:00:32,236 Node[0] Epoch[5] Batch [0-20]	Speed: 10070.63 samples/sec	accuracy=0.391255
[1,0]<stderr>:2019-10-17 19:00:35,560 Node[0] Epoch[5] Batch [20-40]	Speed: 10014.11 samples/sec	accuracy=0.394952
[1,0]<stderr>:2019-10-17 19:00:38,857 Node[0] Epoch[5] Batch [40-60]	Speed: 10094.26 samples/sec	accuracy=0.401202
[1,0]<stderr>:2019-10-17 19:00:42,138 Node[0] Epoch[5] Batch [60-80]	Speed: 10144.52 samples/sec	accuracy=0.396635
[1,0]<stderr>:2019-10-17 19:00:45,459 Node[0] Epoch[5] Batch [80-100]	Speed: 10021.53 samples/sec	accuracy=0.402404
[1,0]<stderr>:2019-10-17 19:00:48,794 Node[0] Epoch[5] Batch [100-120]	Speed: 9980.79 samples/sec	accuracy=0.411538
[1,0]<stderr>:2019-10-17 19:00:52,092 Node[0] Epoch[5] Batch [120-140]	Speed: 10093.59 samples/sec	accuracy=0.396875
[1,0]<stderr>:2019-10-17 19:00:55,412 Node[0] Epoch[5] Batch [140-160]	Speed: 10024.55 samples/sec	accuracy=0.400000
[1,0]<stderr>:2019-10-17 19:00:58,742 Node[0] Epoch[5] Batch [160-180]	Speed: 9993.26 samples/sec	accuracy=0.397596
[1,0]<stderr>:2019-10-17 19:01:02,057 Node[0] Epoch[5] Batch [180-200]	Speed: 10041.51 samples/sec	accuracy=0.396875
[1,0]<stderr>:2019-10-17 19:01:05,375 Node[0] Epoch[5] Batch [200-220]	Speed: 10030.98 samples/sec	accuracy=0.407692
[1,0]<stderr>:2019-10-17 19:01:08,680 Node[0] Epoch[5] Batch [220-240]	Speed: 10071.85 samples/sec	accuracy=0.418750
[1,0]<stderr>:2019-10-17 19:01:11,973 Node[0] Epoch[5] Batch [240-260]	Speed: 10105.22 samples/sec	accuracy=0.418750
[1,0]<stderr>:2019-10-17 19:01:15,284 Node[0] Epoch[5] Batch [260-280]	Speed: 10052.25 samples/sec	accuracy=0.413462
[1,0]<stderr>:2019-10-17 19:01:18,594 Node[0] Epoch[5] Batch [280-300]	Speed: 10058.13 samples/sec	accuracy=0.401202
[1,0]<stderr>:2019-10-17 19:01:21,897 Node[0] Epoch[5] Batch [300-320]	Speed: 10075.12 samples/sec	accuracy=0.398077
[1,0]<stderr>:2019-10-17 19:01:25,197 Node[0] Epoch[5] Batch [320-340]	Speed: 10087.74 samples/sec	accuracy=0.400721
[1,0]<stderr>:2019-10-17 19:01:28,525 Node[0] Epoch[5] Batch [340-360]	Speed: 10000.16 samples/sec	accuracy=0.406731
[1,0]<stderr>:2019-10-17 19:01:31,865 Node[0] Epoch[5] Batch [360-380]	Speed: 9965.64 samples/sec	accuracy=0.401683
[1,0]<stderr>:2019-10-17 19:01:35,202 Node[0] Epoch[5] Batch [380-400]	Speed: 9974.26 samples/sec	accuracy=0.409375
[1,0]<stderr>:2019-10-17 19:01:38,491 Node[0] Epoch[5] Batch [400-420]	Speed: 10117.39 samples/sec	accuracy=0.412500
[1,0]<stderr>:2019-10-17 19:01:41,814 Node[0] Epoch[5] Batch [420-440]	Speed: 10016.74 samples/sec	accuracy=0.398558
[1,0]<stderr>:2019-10-17 19:01:45,100 Node[0] Epoch[5] Batch [440-460]	Speed: 10129.21 samples/sec	accuracy=0.412740
[1,0]<stderr>:2019-10-17 19:01:48,437 Node[0] Epoch[5] Batch [460-480]	Speed: 9975.01 samples/sec	accuracy=0.412260
[1,0]<stderr>:2019-10-17 19:01:51,745 Node[0] Epoch[5] Batch [480-500]	Speed: 10059.06 samples/sec	accuracy=0.410337
[1,0]<stderr>:2019-10-17 19:01:55,037 Node[0] Epoch[5] Batch [500-520]	Speed: 10110.79 samples/sec	accuracy=0.425481
[1,0]<stderr>:2019-10-17 19:01:58,373 Node[0] Epoch[5] Batch [520-540]	Speed: 9978.34 samples/sec	accuracy=0.403365
[1,0]<stderr>:2019-10-17 19:02:01,671 Node[0] Epoch[5] Batch [540-560]	Speed: 10092.28 samples/sec	accuracy=0.416587
[1,0]<stderr>:2019-10-17 19:02:04,975 Node[0] Epoch[5] Batch [560-580]	Speed: 10075.21 samples/sec	accuracy=0.417308
[1,0]<stderr>:2019-10-17 19:02:08,278 Node[0] Epoch[5] Batch [580-600]	Speed: 10076.47 samples/sec	accuracy=0.412981
[1,0]<stderr>:2019-10-17 19:02:11,642 Node[0] Epoch[5] Batch [600-620]	Speed: 9894.58 samples/sec	accuracy=0.413702
[1,0]<stderr>:2019-10-17 19:02:14,916 Node[0] Epoch[5] Batch [620-640]	Speed: 10167.22 samples/sec	accuracy=0.417067
[1,0]<stderr>:2019-10-17 19:02:18,240 Node[0] Epoch[5] Batch [640-660]	Speed: 10012.82 samples/sec	accuracy=0.416587
[1,0]<stderr>:2019-10-17 19:02:21,545 Node[0] Epoch[5] Batch [660-680]	Speed: 10068.73 samples/sec	accuracy=0.425721
[1,0]<stderr>:2019-10-17 19:02:24,867 Node[0] Epoch[5] Batch [680-700]	Speed: 10020.87 samples/sec	accuracy=0.425481
[1,0]<stderr>:2019-10-17 19:02:28,152 Node[0] Epoch[5] Batch [700-720]	Speed: 10131.76 samples/sec	accuracy=0.416827
[1,0]<stderr>:2019-10-17 19:02:31,522 Node[0] Epoch[5] Batch [720-740]	Speed: 9876.17 samples/sec	accuracy=0.425000
[1,0]<stderr>:2019-10-17 19:02:34,826 Node[0] Epoch[5] Batch [740-760]	Speed: 10074.56 samples/sec	accuracy=0.434375
[1,0]<stderr>:2019-10-17 19:02:36,312 Node[0] Epoch[5] Time cost=127.546
[1,0]<stdout>::::MLL 1571338956.313 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 6, "lineno": 932}, "value": null}
[1,0]<stdout>::::MLL 1571338956.313 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 7, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 19:02:39,803 Node[0] Epoch[6] Batch [0-20]	Speed: 10057.29 samples/sec	accuracy=0.422619
[1,0]<stderr>:2019-10-17 19:02:43,122 Node[0] Epoch[6] Batch [20-40]	Speed: 10027.20 samples/sec	accuracy=0.440625
[1,0]<stderr>:2019-10-17 19:02:46,400 Node[0] Epoch[6] Batch [40-60]	Speed: 10155.43 samples/sec	accuracy=0.441106
[1,0]<stderr>:2019-10-17 19:02:49,730 Node[0] Epoch[6] Batch [60-80]	Speed: 9993.61 samples/sec	accuracy=0.423798
[1,0]<stderr>:2019-10-17 19:02:53,055 Node[0] Epoch[6] Batch [80-100]	Speed: 10011.82 samples/sec	accuracy=0.427644
[1,0]<stderr>:2019-10-17 19:02:56,353 Node[0] Epoch[6] Batch [100-120]	Speed: 10090.32 samples/sec	accuracy=0.417788
[1,0]<stderr>:2019-10-17 19:02:59,679 Node[0] Epoch[6] Batch [120-140]	Speed: 10008.50 samples/sec	accuracy=0.427163
[1,0]<stderr>:2019-10-17 19:03:02,970 Node[0] Epoch[6] Batch [140-160]	Speed: 10113.33 samples/sec	accuracy=0.413702
[1,0]<stderr>:2019-10-17 19:03:06,276 Node[0] Epoch[6] Batch [160-180]	Speed: 10067.34 samples/sec	accuracy=0.419952
[1,0]<stderr>:2019-10-17 19:03:09,586 Node[0] Epoch[6] Batch [180-200]	Speed: 10056.35 samples/sec	accuracy=0.430048
[1,0]<stderr>:2019-10-17 19:03:12,895 Node[0] Epoch[6] Batch [200-220]	Speed: 10060.34 samples/sec	accuracy=0.426923
[1,0]<stderr>:2019-10-17 19:03:16,214 Node[0] Epoch[6] Batch [220-240]	Speed: 10028.22 samples/sec	accuracy=0.430529
[1,0]<stderr>:2019-10-17 19:03:19,526 Node[0] Epoch[6] Batch [240-260]	Speed: 10048.19 samples/sec	accuracy=0.428606
[1,0]<stderr>:2019-10-17 19:03:22,841 Node[0] Epoch[6] Batch [260-280]	Speed: 10039.78 samples/sec	accuracy=0.449279
[1,0]<stderr>:2019-10-17 19:03:26,138 Node[0] Epoch[6] Batch [280-300]	Speed: 10096.98 samples/sec	accuracy=0.427644
[1,0]<stderr>:2019-10-17 19:03:29,457 Node[0] Epoch[6] Batch [300-320]	Speed: 10026.91 samples/sec	accuracy=0.448317
[1,0]<stderr>:2019-10-17 19:03:32,779 Node[0] Epoch[6] Batch [320-340]	Speed: 10019.07 samples/sec	accuracy=0.421875
[1,0]<stderr>:2019-10-17 19:03:36,098 Node[0] Epoch[6] Batch [340-360]	Speed: 10029.90 samples/sec	accuracy=0.435817
[1,0]<stderr>:2019-10-17 19:03:39,389 Node[0] Epoch[6] Batch [360-380]	Speed: 10113.32 samples/sec	accuracy=0.428365
[1,0]<stderr>:2019-10-17 19:03:42,718 Node[0] Epoch[6] Batch [380-400]	Speed: 9996.81 samples/sec	accuracy=0.409135
[1,0]<stderr>:2019-10-17 19:03:46,039 Node[0] Epoch[6] Batch [400-420]	Speed: 10022.18 samples/sec	accuracy=0.430529
[1,0]<stderr>:2019-10-17 19:03:49,344 Node[0] Epoch[6] Batch [420-440]	Speed: 10071.48 samples/sec	accuracy=0.434135
[1,0]<stderr>:2019-10-17 19:03:52,661 Node[0] Epoch[6] Batch [440-460]	Speed: 10032.42 samples/sec	accuracy=0.432212
[1,0]<stderr>:2019-10-17 19:03:55,972 Node[0] Epoch[6] Batch [460-480]	Speed: 10053.93 samples/sec	accuracy=0.422837
[1,0]<stderr>:2019-10-17 19:03:59,318 Node[0] Epoch[6] Batch [480-500]	Speed: 9948.84 samples/sec	accuracy=0.433173
[1,0]<stderr>:2019-10-17 19:04:02,624 Node[0] Epoch[6] Batch [500-520]	Speed: 10066.82 samples/sec	accuracy=0.448558
[1,0]<stderr>:2019-10-17 19:04:05,940 Node[0] Epoch[6] Batch [520-540]	Speed: 10036.18 samples/sec	accuracy=0.442067
[1,0]<stderr>:2019-10-17 19:04:09,272 Node[0] Epoch[6] Batch [540-560]	Speed: 9991.11 samples/sec	accuracy=0.445673
[1,0]<stderr>:2019-10-17 19:04:12,606 Node[0] Epoch[6] Batch [560-580]	Speed: 9983.20 samples/sec	accuracy=0.445913
[1,0]<stderr>:2019-10-17 19:04:15,904 Node[0] Epoch[6] Batch [580-600]	Speed: 10091.96 samples/sec	accuracy=0.442308
[1,0]<stderr>:2019-10-17 19:04:19,200 Node[0] Epoch[6] Batch [600-620]	Speed: 10096.24 samples/sec	accuracy=0.446875
[1,0]<stderr>:2019-10-17 19:04:22,517 Node[0] Epoch[6] Batch [620-640]	Speed: 10034.73 samples/sec	accuracy=0.426442
[1,0]<stderr>:2019-10-17 19:04:25,835 Node[0] Epoch[6] Batch [640-660]	Speed: 10030.71 samples/sec	accuracy=0.436538
[1,0]<stderr>:2019-10-17 19:04:29,153 Node[0] Epoch[6] Batch [660-680]	Speed: 10032.39 samples/sec	accuracy=0.453846
[1,0]<stderr>:2019-10-17 19:04:32,443 Node[0] Epoch[6] Batch [680-700]	Speed: 10116.46 samples/sec	accuracy=0.443029
[1,0]<stderr>:2019-10-17 19:04:35,723 Node[0] Epoch[6] Batch [700-720]	Speed: 10147.63 samples/sec	accuracy=0.441346
[1,0]<stderr>:2019-10-17 19:04:39,052 Node[0] Epoch[6] Batch [720-740]	Speed: 9997.91 samples/sec	accuracy=0.445433
[1,0]<stderr>:2019-10-17 19:04:42,363 Node[0] Epoch[6] Batch [740-760]	Speed: 10056.01 samples/sec	accuracy=0.432933
[1,0]<stdout>::::MLL 1571339083.832 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 7, "lineno": 932}, "value": null}
[1,0]<stdout>::::MLL 1571339083.833 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 8, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 19:04:43,832 Node[0] Epoch[6] Time cost=127.520
[1,0]<stderr>:2019-10-17 19:04:47,307 Node[0] Epoch[7] Batch [0-20]	Speed: 10093.67 samples/sec	accuracy=0.446200
[1,0]<stderr>:2019-10-17 19:04:50,596 Node[0] Epoch[7] Batch [20-40]	Speed: 10120.57 samples/sec	accuracy=0.447115
[1,0]<stderr>:2019-10-17 19:04:53,905 Node[0] Epoch[7] Batch [40-60]	Speed: 10058.17 samples/sec	accuracy=0.443510
[1,0]<stderr>:2019-10-17 19:04:57,227 Node[0] Epoch[7] Batch [60-80]	Speed: 10019.01 samples/sec	accuracy=0.443750
[1,0]<stderr>:2019-10-17 19:05:00,555 Node[0] Epoch[7] Batch [80-100]	Speed: 10005.02 samples/sec	accuracy=0.439663
[1,0]<stderr>:2019-10-17 19:05:03,858 Node[0] Epoch[7] Batch [100-120]	Speed: 10079.39 samples/sec	accuracy=0.437019
[1,0]<stderr>:2019-10-17 19:05:07,173 Node[0] Epoch[7] Batch [120-140]	Speed: 10039.46 samples/sec	accuracy=0.455048
[1,0]<stderr>:2019-10-17 19:05:10,484 Node[0] Epoch[7] Batch [140-160]	Speed: 10052.59 samples/sec	accuracy=0.445913
[1,0]<stderr>:2019-10-17 19:05:13,805 Node[0] Epoch[7] Batch [160-180]	Speed: 10022.17 samples/sec	accuracy=0.460577
[1,0]<stderr>:2019-10-17 19:05:17,080 Node[0] Epoch[7] Batch [180-200]	Speed: 10162.62 samples/sec	accuracy=0.437981
[1,0]<stderr>:2019-10-17 19:05:20,363 Node[0] Epoch[7] Batch [200-220]	Speed: 10137.92 samples/sec	accuracy=0.446154
[1,0]<stderr>:2019-10-17 19:05:23,682 Node[0] Epoch[7] Batch [220-240]	Speed: 10027.81 samples/sec	accuracy=0.445673
[1,0]<stderr>:2019-10-17 19:05:26,979 Node[0] Epoch[7] Batch [240-260]	Speed: 10097.07 samples/sec	accuracy=0.440625
[1,0]<stderr>:2019-10-17 19:05:30,306 Node[0] Epoch[7] Batch [260-280]	Speed: 10004.60 samples/sec	accuracy=0.457452
[1,0]<stderr>:2019-10-17 19:05:33,617 Node[0] Epoch[7] Batch [280-300]	Speed: 10051.32 samples/sec	accuracy=0.463702
[1,0]<stderr>:2019-10-17 19:05:36,934 Node[0] Epoch[7] Batch [300-320]	Speed: 10033.03 samples/sec	accuracy=0.457452
[1,0]<stderr>:2019-10-17 19:05:40,252 Node[0] Epoch[7] Batch [320-340]	Speed: 10033.62 samples/sec	accuracy=0.452404
[1,0]<stderr>:2019-10-17 19:05:43,548 Node[0] Epoch[7] Batch [340-360]	Speed: 10097.88 samples/sec	accuracy=0.456250
[1,0]<stderr>:2019-10-17 19:05:46,860 Node[0] Epoch[7] Batch [360-380]	Speed: 10048.91 samples/sec	accuracy=0.455769
[1,0]<stderr>:2019-10-17 19:05:50,185 Node[0] Epoch[7] Batch [380-400]	Speed: 10010.50 samples/sec	accuracy=0.449760
[1,0]<stderr>:2019-10-17 19:05:53,518 Node[0] Epoch[7] Batch [400-420]	Speed: 9985.12 samples/sec	accuracy=0.445192
[1,0]<stderr>:2019-10-17 19:05:56,837 Node[0] Epoch[7] Batch [420-440]	Speed: 10030.05 samples/sec	accuracy=0.440865
[1,0]<stderr>:2019-10-17 19:06:00,174 Node[0] Epoch[7] Batch [440-460]	Speed: 9974.40 samples/sec	accuracy=0.449038
[1,0]<stderr>:2019-10-17 19:06:03,497 Node[0] Epoch[7] Batch [460-480]	Speed: 10015.52 samples/sec	accuracy=0.444471
[1,0]<stderr>:2019-10-17 19:06:06,817 Node[0] Epoch[7] Batch [480-500]	Speed: 10024.45 samples/sec	accuracy=0.461058
[1,0]<stderr>:2019-10-17 19:06:10,106 Node[0] Epoch[7] Batch [500-520]	Speed: 10118.44 samples/sec	accuracy=0.446875
[1,0]<stderr>:2019-10-17 19:06:13,410 Node[0] Epoch[7] Batch [520-540]	Speed: 10075.77 samples/sec	accuracy=0.457212
[1,0]<stderr>:2019-10-17 19:06:16,709 Node[0] Epoch[7] Batch [540-560]	Speed: 10089.89 samples/sec	accuracy=0.466346
[1,0]<stderr>:2019-10-17 19:06:19,981 Node[0] Epoch[7] Batch [560-580]	Speed: 10170.74 samples/sec	accuracy=0.458413
[1,0]<stderr>:2019-10-17 19:06:23,280 Node[0] Epoch[7] Batch [580-600]	Speed: 10088.33 samples/sec	accuracy=0.465144
[1,0]<stderr>:2019-10-17 19:06:26,589 Node[0] Epoch[7] Batch [600-620]	Speed: 10058.38 samples/sec	accuracy=0.454808
[1,0]<stderr>:2019-10-17 19:06:29,879 Node[0] Epoch[7] Batch [620-640]	Speed: 10119.37 samples/sec	accuracy=0.451923
[1,0]<stderr>:2019-10-17 19:06:33,188 Node[0] Epoch[7] Batch [640-660]	Speed: 10058.60 samples/sec	accuracy=0.461779
[1,0]<stderr>:2019-10-17 19:06:36,489 Node[0] Epoch[7] Batch [660-680]	Speed: 10081.42 samples/sec	accuracy=0.459856
[1,0]<stderr>:2019-10-17 19:06:39,815 Node[0] Epoch[7] Batch [680-700]	Speed: 10007.40 samples/sec	accuracy=0.460817
[1,0]<stderr>:2019-10-17 19:06:43,109 Node[0] Epoch[7] Batch [700-720]	Speed: 10105.89 samples/sec	accuracy=0.464183
[1,0]<stderr>:2019-10-17 19:06:46,408 Node[0] Epoch[7] Batch [720-740]	Speed: 10088.59 samples/sec	accuracy=0.468029
[1,0]<stderr>:2019-10-17 19:06:49,714 Node[0] Epoch[7] Batch [740-760]	Speed: 10066.39 samples/sec	accuracy=0.452163
[1,0]<stderr>:2019-10-17 19:06:51,205 Node[0] Epoch[7] Time cost=127.372
[1,0]<stdout>::::MLL 1571339211.205 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 8, "lineno": 932}, "value": null}
[1,0]<stdout>::::MLL 1571339211.206 eval_start: {"metadata": {"file": "common/fit.py", "epoch_num": 8, "lineno": 956}, "value": null}
[1,0]<stderr>:2019-10-17 19:06:54,968 Node[0] Epoch[7] Validation-accuracy=0.479840
[1,0]<stderr>:2019-10-17 19:06:54,968 Node[0] Epoch[7] Validation-correct-count=2999.000000
[1,0]<stderr>:2019-10-17 19:06:54,968 Node[0] Epoch[7] Validation-total-count=6250.000000
[1,0]<stdout>::::MLL 1571339215.105 eval_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 8, "lineno": 977}, "value": null}
[1,0]<stdout>::::MLL 1571339215.106 eval_accuracy: {"metadata": {"file": "common/fit.py", "epoch_num": 8, "lineno": 980}, "value": 0.47884}
[1,0]<stdout>::::MLL 1571339215.106 block_stop: {"metadata": {"file": "common/fit.py", "lineno": 984, "first_epoch_num": 5}, "value": null}
[1,0]<stdout>::::MLL 1571339215.106 block_start: {"metadata": {"file": "common/fit.py", "lineno": 997, "first_epoch_num": 9, "epoch_count": 4}, "value": null}
[1,0]<stdout>::::MLL 1571339215.107 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 9, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 19:06:59,078 Node[0] Epoch[8] Batch [0-20]	Speed: 8569.52 samples/sec	accuracy=0.476190
[1,0]<stderr>:2019-10-17 19:07:02,364 Node[0] Epoch[8] Batch [20-40]	Speed: 10129.23 samples/sec	accuracy=0.462500
[1,0]<stderr>:2019-10-17 19:07:05,677 Node[0] Epoch[8] Batch [40-60]	Speed: 10046.10 samples/sec	accuracy=0.462740
[1,0]<stderr>:2019-10-17 19:07:09,006 Node[0] Epoch[8] Batch [60-80]	Speed: 9995.57 samples/sec	accuracy=0.459135
[1,0]<stderr>:2019-10-17 19:07:12,318 Node[0] Epoch[8] Batch [80-100]	Speed: 10050.34 samples/sec	accuracy=0.473317
[1,0]<stderr>:2019-10-17 19:07:15,620 Node[0] Epoch[8] Batch [100-120]	Speed: 10080.16 samples/sec	accuracy=0.456250
[1,0]<stderr>:2019-10-17 19:07:18,921 Node[0] Epoch[8] Batch [120-140]	Speed: 10082.23 samples/sec	accuracy=0.468029
[1,0]<stderr>:2019-10-17 19:07:22,240 Node[0] Epoch[8] Batch [140-160]	Speed: 10029.54 samples/sec	accuracy=0.471875
[1,0]<stderr>:2019-10-17 19:07:25,530 Node[0] Epoch[8] Batch [160-180]	Speed: 10118.51 samples/sec	accuracy=0.456490
[1,0]<stderr>:2019-10-17 19:07:28,837 Node[0] Epoch[8] Batch [180-200]	Speed: 10063.98 samples/sec	accuracy=0.479327
[1,0]<stderr>:2019-10-17 19:07:32,165 Node[0] Epoch[8] Batch [200-220]	Speed: 10001.06 samples/sec	accuracy=0.463462
[1,0]<stderr>:2019-10-17 19:07:35,459 Node[0] Epoch[8] Batch [220-240]	Speed: 10102.73 samples/sec	accuracy=0.461538
[1,0]<stderr>:2019-10-17 19:07:38,775 Node[0] Epoch[8] Batch [240-260]	Speed: 10039.90 samples/sec	accuracy=0.476442
[1,0]<stderr>:2019-10-17 19:07:42,072 Node[0] Epoch[8] Batch [260-280]	Speed: 10094.37 samples/sec	accuracy=0.466106
[1,0]<stderr>:2019-10-17 19:07:45,391 Node[0] Epoch[8] Batch [280-300]	Speed: 10027.39 samples/sec	accuracy=0.444952
[1,0]<stderr>:2019-10-17 19:07:48,688 Node[0] Epoch[8] Batch [300-320]	Speed: 10096.49 samples/sec	accuracy=0.462260
[1,0]<stderr>:2019-10-17 19:07:52,027 Node[0] Epoch[8] Batch [320-340]	Speed: 9966.52 samples/sec	accuracy=0.462260
[1,0]<stderr>:2019-10-17 19:07:55,352 Node[0] Epoch[8] Batch [340-360]	Speed: 10010.79 samples/sec	accuracy=0.481731
[1,0]<stderr>:2019-10-17 19:07:58,667 Node[0] Epoch[8] Batch [360-380]	Speed: 10041.40 samples/sec	accuracy=0.474760
[1,0]<stderr>:2019-10-17 19:08:01,995 Node[0] Epoch[8] Batch [380-400]	Speed: 10000.18 samples/sec	accuracy=0.471154
[1,0]<stderr>:2019-10-17 19:08:05,316 Node[0] Epoch[8] Batch [400-420]	Speed: 10023.01 samples/sec	accuracy=0.481731
[1,0]<stderr>:2019-10-17 19:08:08,639 Node[0] Epoch[8] Batch [420-440]	Speed: 10016.19 samples/sec	accuracy=0.461779
[1,0]<stderr>:2019-10-17 19:08:11,973 Node[0] Epoch[8] Batch [440-460]	Speed: 9981.10 samples/sec	accuracy=0.480288
[1,0]<stderr>:2019-10-17 19:08:15,254 Node[0] Epoch[8] Batch [460-480]	Speed: 10145.24 samples/sec	accuracy=0.470433
[1,0]<stderr>:2019-10-17 19:08:18,593 Node[0] Epoch[8] Batch [480-500]	Speed: 9967.72 samples/sec	accuracy=0.465865
[1,0]<stderr>:2019-10-17 19:08:21,911 Node[0] Epoch[8] Batch [500-520]	Speed: 10033.83 samples/sec	accuracy=0.455288
[1,0]<stderr>:2019-10-17 19:08:25,247 Node[0] Epoch[8] Batch [520-540]	Speed: 9975.52 samples/sec	accuracy=0.484135
[1,0]<stderr>:2019-10-17 19:08:28,551 Node[0] Epoch[8] Batch [540-560]	Speed: 10075.18 samples/sec	accuracy=0.475721
[1,0]<stderr>:2019-10-17 19:08:31,849 Node[0] Epoch[8] Batch [560-580]	Speed: 10090.19 samples/sec	accuracy=0.462260
[1,0]<stderr>:2019-10-17 19:08:35,164 Node[0] Epoch[8] Batch [580-600]	Speed: 10041.01 samples/sec	accuracy=0.476683
[1,0]<stderr>:2019-10-17 19:08:38,465 Node[0] Epoch[8] Batch [600-620]	Speed: 10082.76 samples/sec	accuracy=0.466346
[1,0]<stderr>:2019-10-17 19:08:41,754 Node[0] Epoch[8] Batch [620-640]	Speed: 10121.14 samples/sec	accuracy=0.488462
[1,0]<stderr>:2019-10-17 19:08:45,065 Node[0] Epoch[8] Batch [640-660]	Speed: 10050.36 samples/sec	accuracy=0.463462
[1,0]<stderr>:2019-10-17 19:08:48,370 Node[0] Epoch[8] Batch [660-680]	Speed: 10071.61 samples/sec	accuracy=0.479327
[1,0]<stderr>:2019-10-17 19:08:51,691 Node[0] Epoch[8] Batch [680-700]	Speed: 10022.00 samples/sec	accuracy=0.459856
[1,0]<stderr>:2019-10-17 19:08:55,016 Node[0] Epoch[8] Batch [700-720]	Speed: 10011.99 samples/sec	accuracy=0.471875
[1,0]<stderr>:2019-10-17 19:08:58,347 Node[0] Epoch[8] Batch [720-740]	Speed: 9990.65 samples/sec	accuracy=0.476202
[1,0]<stderr>:2019-10-17 19:09:01,641 Node[0] Epoch[8] Batch [740-760]	Speed: 10104.92 samples/sec	accuracy=0.474519
[1,0]<stdout>::::MLL 1571339343.110 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 9, "lineno": 932}, "value": null}
[1,0]<stderr>:2019-10-17 19:09:03,110 Node[0] Epoch[8] Time cost=128.003
[1,0]<stdout>::::MLL 1571339343.111 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 10, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 19:09:06,627 Node[0] Epoch[9] Batch [0-20]	Speed: 9972.49 samples/sec	accuracy=0.481456
[1,0]<stderr>:2019-10-17 19:09:09,928 Node[0] Epoch[9] Batch [20-40]	Speed: 10082.99 samples/sec	accuracy=0.473558
[1,0]<stderr>:2019-10-17 19:09:13,260 Node[0] Epoch[9] Batch [40-60]	Speed: 9990.79 samples/sec	accuracy=0.468510
[1,0]<stderr>:2019-10-17 19:09:16,560 Node[0] Epoch[9] Batch [60-80]	Speed: 10084.58 samples/sec	accuracy=0.462981
[1,0]<stderr>:2019-10-17 19:09:19,890 Node[0] Epoch[9] Batch [80-100]	Speed: 9995.78 samples/sec	accuracy=0.482452
[1,0]<stderr>:2019-10-17 19:09:23,221 Node[0] Epoch[9] Batch [100-120]	Speed: 9992.70 samples/sec	accuracy=0.472596
[1,0]<stderr>:2019-10-17 19:09:26,514 Node[0] Epoch[9] Batch [120-140]	Speed: 10106.89 samples/sec	accuracy=0.490144
[1,0]<stderr>:2019-10-17 19:09:29,805 Node[0] Epoch[9] Batch [140-160]	Speed: 10114.86 samples/sec	accuracy=0.478125
[1,0]<stderr>:2019-10-17 19:09:33,106 Node[0] Epoch[9] Batch [160-180]	Speed: 10081.01 samples/sec	accuracy=0.487500
[1,0]<stderr>:2019-10-17 19:09:36,398 Node[0] Epoch[9] Batch [180-200]	Speed: 10110.38 samples/sec	accuracy=0.487019
[1,0]<stderr>:2019-10-17 19:09:39,697 Node[0] Epoch[9] Batch [200-220]	Speed: 10091.65 samples/sec	accuracy=0.482212
[1,0]<stderr>:2019-10-17 19:09:43,001 Node[0] Epoch[9] Batch [220-240]	Speed: 10071.51 samples/sec	accuracy=0.474519
[1,0]<stderr>:2019-10-17 19:09:46,330 Node[0] Epoch[9] Batch [240-260]	Speed: 9998.81 samples/sec	accuracy=0.471394
[1,0]<stderr>:2019-10-17 19:09:49,625 Node[0] Epoch[9] Batch [260-280]	Speed: 10103.10 samples/sec	accuracy=0.474038
[1,0]<stderr>:2019-10-17 19:09:52,932 Node[0] Epoch[9] Batch [280-300]	Speed: 10062.91 samples/sec	accuracy=0.482212
[1,0]<stderr>:2019-10-17 19:09:56,241 Node[0] Epoch[9] Batch [300-320]	Speed: 10058.10 samples/sec	accuracy=0.483654
[1,0]<stderr>:2019-10-17 19:09:59,559 Node[0] Epoch[9] Batch [320-340]	Speed: 10031.40 samples/sec	accuracy=0.468029
[1,0]<stderr>:2019-10-17 19:10:02,888 Node[0] Epoch[9] Batch [340-360]	Speed: 10000.46 samples/sec	accuracy=0.480769
[1,0]<stderr>:2019-10-17 19:10:06,222 Node[0] Epoch[9] Batch [360-380]	Speed: 9982.48 samples/sec	accuracy=0.483894
[1,0]<stderr>:2019-10-17 19:10:09,520 Node[0] Epoch[9] Batch [380-400]	Speed: 10092.36 samples/sec	accuracy=0.489663
[1,0]<stderr>:2019-10-17 19:10:12,822 Node[0] Epoch[9] Batch [400-420]	Speed: 10079.21 samples/sec	accuracy=0.485577
[1,0]<stderr>:2019-10-17 19:10:16,126 Node[0] Epoch[9] Batch [420-440]	Speed: 10073.38 samples/sec	accuracy=0.481250
[1,0]<stderr>:2019-10-17 19:10:19,419 Node[0] Epoch[9] Batch [440-460]	Speed: 10109.22 samples/sec	accuracy=0.480048
[1,0]<stderr>:2019-10-17 19:10:22,759 Node[0] Epoch[9] Batch [460-480]	Speed: 9965.49 samples/sec	accuracy=0.482692
[1,0]<stderr>:2019-10-17 19:10:26,083 Node[0] Epoch[9] Batch [480-500]	Speed: 10012.26 samples/sec	accuracy=0.482212
[1,0]<stderr>:2019-10-17 19:10:29,384 Node[0] Epoch[9] Batch [500-520]	Speed: 10083.29 samples/sec	accuracy=0.477404
[1,0]<stderr>:2019-10-17 19:10:32,685 Node[0] Epoch[9] Batch [520-540]	Speed: 10080.80 samples/sec	accuracy=0.471394
[1,0]<stderr>:2019-10-17 19:10:36,032 Node[0] Epoch[9] Batch [540-560]	Speed: 9947.27 samples/sec	accuracy=0.490865
[1,0]<stderr>:2019-10-17 19:10:39,339 Node[0] Epoch[9] Batch [560-580]	Speed: 10064.92 samples/sec	accuracy=0.500481
[1,0]<stderr>:2019-10-17 19:10:42,659 Node[0] Epoch[9] Batch [580-600]	Speed: 10024.47 samples/sec	accuracy=0.479567
[1,0]<stderr>:2019-10-17 19:10:45,968 Node[0] Epoch[9] Batch [600-620]	Speed: 10058.83 samples/sec	accuracy=0.487500
[1,0]<stderr>:2019-10-17 19:10:49,273 Node[0] Epoch[9] Batch [620-640]	Speed: 10070.37 samples/sec	accuracy=0.487019
[1,0]<stderr>:2019-10-17 19:10:52,581 Node[0] Epoch[9] Batch [640-660]	Speed: 10063.95 samples/sec	accuracy=0.483894
[1,0]<stderr>:2019-10-17 19:10:55,889 Node[0] Epoch[9] Batch [660-680]	Speed: 10060.19 samples/sec	accuracy=0.486538
[1,0]<stderr>:2019-10-17 19:10:59,194 Node[0] Epoch[9] Batch [680-700]	Speed: 10072.47 samples/sec	accuracy=0.478606
[1,0]<stderr>:2019-10-17 19:11:02,494 Node[0] Epoch[9] Batch [700-720]	Speed: 10085.67 samples/sec	accuracy=0.481250
[1,0]<stderr>:2019-10-17 19:11:05,800 Node[0] Epoch[9] Batch [720-740]	Speed: 10066.97 samples/sec	accuracy=0.502404
[1,0]<stderr>:2019-10-17 19:11:09,141 Node[0] Epoch[9] Batch [740-760]	Speed: 9963.66 samples/sec	accuracy=0.489904
[1,0]<stderr>:2019-10-17 19:11:10,636 Node[0] Epoch[9] Time cost=127.526
[1,0]<stdout>::::MLL 1571339470.636 epoch_stop: {"metadata": {"file": "common/fit.py", "epoch_num": 10, "lineno": 932}, "value": null}
[1,0]<stdout>::::MLL 1571339470.637 epoch_start: {"metadata": {"file": "common/fit.py", "epoch_num": 11, "lineno": 893}, "value": null}
[1,0]<stderr>:2019-10-17 19:11:14,131 Node[0] Epoch[10] Batch [0-20]	Speed: 10023.86 samples/sec	accuracy=0.479396
[1,0]<stderr>:2019-10-17 19:11:17,437 Node[0] Epoch[10] Batch [20-40]	Speed: 10067.12 samples/sec	accuracy=0.475240
[1,0]<stderr>:2019-10-17 19:11:20,732 Node[0] Epoch[10] Batch [40-60]	Speed: 10098.98 samples/sec	accuracy=0.494952
[1,0]<stderr>:2019-10-17 19:11:24,058 Node[0] Epoch[10] Batch [60-80]	Speed: 10008.54 samples/sec	accuracy=0.470433
[1,0]<stderr>:2019-10-17 19:11:27,359 Node[0] Epoch[10] Batch [80-100]	Speed: 10082.41 samples/sec	accuracy=0.479327
[1,0]<stderr>:2019-10-17 19:11:30,651 Node[0] Epoch[10] Batch [100-120]	Speed: 10111.40 samples/sec	accuracy=0.488702
[1,0]<stderr>:2019-10-17 19:11:33,977 Node[0] Epoch[10] Batch [120-140]	Speed: 10007.91 samples/sec	accuracy=0.499038
[1,0]<stderr>:2019-10-17 19:11:37,282 Node[0] Epoch[10] Batch [140-160]	Speed: 10069.81 samples/sec	accuracy=0.489904
[1,0]<stderr>:2019-10-17 19:11:40,644 Node[0] Epoch[10] Batch [160-180]	Speed: 9899.10 samples/sec	accuracy=0.493029
[1,0]<stderr>:2019-10-17 19:11:43,940 Node[0] Epoch[10] Batch [180-200]	Speed: 10099.70 samples/sec	accuracy=0.494471
[1,0]<stderr>:2019-10-17 19:11:47,259 Node[0] Epoch[10] Batch [200-220]	Speed: 10028.11 samples/sec	accuracy=0.483413
[1,0]<stderr>:2019-10-17 19:11:50,573 Node[0] Epoch[10] Batch [220-240]	Speed: 10043.99 samples/sec	accuracy=0.494471
[1,0]<stderr>:2019-10-17 19:11:53,874 Node[0] Epoch[10] Batch [240-260]	Speed: 10081.99 samples/sec	accuracy=0.478125
[1,0]<stderr>:2019-10-17 19:11:57,174 Node[0] Epoch[10] Batch [260-280]	Speed: 10086.00 samples/sec	accuracy=0.483173
[1,0]<stderr>:2019-10-17 19:12:00,512 Node[0] Epoch[10] Batch [280-300]	Speed: 9972.94 samples/sec	accuracy=0.498558
[1,0]<stderr>:2019-10-17 19:12:03,813 Node[0] Epoch[10] Batch [300-320]	Speed: 10080.77 samples/sec	accuracy=0.491106
[1,0]<stderr>:2019-10-17 19:12:07,138 Node[0] Epoch[10] Batch [320-340]	Speed: 10009.81 samples/sec	accuracy=0.492308
[1,0]<stderr>:2019-10-17 19:12:10,469 Node[0] Epoch[10] Batch [340-360]	Speed: 9992.15 samples/sec	accuracy=0.477163
[1,0]<stderr>:2019-10-17 19:12:13,816 Node[0] Epoch[10] Batch [360-380]	Speed: 9946.03 samples/sec	accuracy=0.496154
[1,0]<stderr>:2019-10-17 19:12:17,158 Node[0] Epoch[10] Batch [380-400]	Speed: 9958.21 samples/sec	accuracy=0.484135
