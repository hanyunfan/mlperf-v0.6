Beginning trial 1 of 3
Run vars: id 191017113422633260440
Gathering sys log on dss01
:::MLL 1571330100.991 submission_benchmark: {"value": "resnet", "metadata": {"lineno": 226, "file": "mlperf_log_utils.py"}}
:::MLL 1571330100.991 submission_org: {"value": "NVIDIA", "metadata": {"lineno": 231, "file": "mlperf_log_utils.py"}}
WARNING: Log validation: Key "submission_division" is not in known resnet keys.
:::MLL 1571330100.992 submission_division: {"value": "closed", "metadata": {"lineno": 235, "file": "mlperf_log_utils.py"}}
:::MLL 1571330100.992 submission_status: {"value": "onprem", "metadata": {"lineno": 239, "file": "mlperf_log_utils.py"}}
:::MLL 1571330100.993 submission_platform: {"value": "1xDSS8440", "metadata": {"lineno": 243, "file": "mlperf_log_utils.py"}}
:::MLL 1571330100.993 submission_entry: {"value": "{'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'power': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'nodes': \"{'sys_storage_size': '1x 931.5G + 1x 447.1G', 'network_card': 'Mellanox Technologies MT27700 Family [ConnectX-4]', 'cpu': '2x Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz', 'num_cores': '40', 'notes': '', 'sys_mem_size': '754 GB', 'accelerator': 'Tesla V100-PCIE-32GB', 'num_nodes': '1', 'sys_storage_type': 'SATA SSD', 'num_vcpus': '40', 'num_network_cards': '1', 'num_accelerators': '8', 'cpu_accel_interconnect': 'UPI'}\", 'hardware': 'DSS8440', 'os': '\\\\S / ', 'notes': 'N/A', 'libraries': \"{'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'openmpi_version': '3.1.3', 'mofed_version': '5.0-0', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'container_base': 'Ubuntu-16.04', 'dali_version': '0.9.1'}\", 'framework': 'MXNet NVIDIA Release 19.05'}", "metadata": {"lineno": 247, "file": "mlperf_log_utils.py"}}
:::MLL 1571330100.994 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"lineno": 251, "file": "mlperf_log_utils.py"}}
:::MLL 1571330100.995 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"lineno": 255, "file": "mlperf_log_utils.py"}}
Clearing cache on dss01
:::MLL 1571330121.303 cache_clear: {"metadata": {"lineno": 1, "file": "<string>"}, "value": true}

Launching user script on master node:
[1,0]<stdout>:STARTING TIMING RUN AT 2019-10-17 04:35:21 PM
[1,0]<stdout>:running benchmark
[1,1]<stdout>:STARTING TIMING RUN AT 2019-10-17 04:35:21 PM
[1,1]<stdout>:running benchmark
[1,2]<stdout>:STARTING TIMING RUN AT 2019-10-17 04:35:21 PM
[1,2]<stdout>:running benchmark
[1,3]<stdout>:STARTING TIMING RUN AT 2019-10-17 04:35:21 PM
[1,3]<stdout>:running benchmark
[1,4]<stdout>:STARTING TIMING RUN AT 2019-10-17 04:35:21 PM
[1,4]<stdout>:running benchmark
[1,5]<stdout>:STARTING TIMING RUN AT 2019-10-17 04:35:21 PM
[1,5]<stdout>:running benchmark
[1,6]<stdout>:STARTING TIMING RUN AT 2019-10-17 04:35:21 PM
[1,6]<stdout>:running benchmark
[1,7]<stdout>:STARTING TIMING RUN AT 2019-10-17 04:35:21 PM
[1,7]<stdout>:running benchmark
[1,7]<stderr>:[16:35:22] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,0]<stderr>:[16:35:22] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,1]<stderr>:[16:35:22] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,2]<stderr>:[16:35:22] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,3]<stderr>:[16:35:22] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,4]<stderr>:[16:35:22] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,5]<stderr>:[16:35:22] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
[1,6]<stderr>:[16:35:22] src/operator/nn/cudnn/cudnn_algoreg.cc:53: cuDNN library mismatch: linked-against version 7604 != compiled-against version 7600
--------------------------------------------------------------------------
WARNING: One or more nonexistent OpenFabrics devices/ports were
specified:

  Host:                 dss01
  MCA parameter:        mca_btl_if_include
  Nonexistent entities: mlx5_2

These entities will be ignored.  You can disable this warning by
setting the btl_openib_warn_nonexistent_if MCA parameter to 0.
--------------------------------------------------------------------------
[1,7]<stdout>::::MLL 1571330130.802 init_start: {"metadata": {"lineno": 83, "file": "train_imagenet.py"}, "value": null}
[1,0]<stdout>::::MLL 1571330130.802 init_start: {"metadata": {"file": "train_imagenet.py", "lineno": 83}, "value": null}
[1,1]<stdout>::::MLL 1571330130.802 init_start: {"value": null, "metadata": {"file": "train_imagenet.py", "lineno": 83}}
[1,2]<stdout>::::MLL 1571330130.802 init_start: {"metadata": {"file": "train_imagenet.py", "lineno": 83}, "value": null}
[1,3]<stdout>::::MLL 1571330130.802 init_start: {"value": null, "metadata": {"lineno": 83, "file": "train_imagenet.py"}}
[1,4]<stdout>::::MLL 1571330130.802 init_start: {"metadata": {"file": "train_imagenet.py", "lineno": 83}, "value": null}
[1,5]<stdout>::::MLL 1571330130.802 init_start: {"metadata": {"lineno": 83, "file": "train_imagenet.py"}, "value": null}
[1,6]<stdout>::::MLL 1571330130.802 init_start: {"value": null, "metadata": {"file": "train_imagenet.py", "lineno": 83}}
[dss01:00167] 7 more processes have sent help message help-mpi-btl-openib.txt / nonexistent port
[dss01:00167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_initial_shape" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.698 model_hp_initial_shape: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 266}, "value": [4, 224, 224]}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.700 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.701 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.702 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.703 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.704 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.705 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.706 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.707 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.707 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.708 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.709 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.710 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.711 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.711 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.712 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_shorcut_add" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.713 model_hp_shorcut_add: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 192}, "value": null}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_final_shape" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.714 model_hp_final_shape: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 309}, "value": 1000}
[1,0]<stdout>:WARNING: Log validation: Key "model_hp_loss_fn" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330143.714 model_hp_loss_fn: {"metadata": {"file": "symbols/resnet-v1b-normconv-fl.py", "lineno": 320}, "value": "categorical_cross_entropy"}
[1,0]<stdout>::::MLL 1571330143.716 model_bn_span: {"metadata": {"file": "common/dali.py", "lineno": 229}, "value": 208}
[1,0]<stdout>::::MLL 1571330153.748 init_stop: {"metadata": {"file": "train_imagenet.py", "lineno": 187}, "value": null}
[1,0]<stdout>::::MLL 1571330153.749 run_start: {"metadata": {"file": "train_imagenet.py", "lineno": 190}, "value": null}
[1,0]<stderr>:2019-10-17 16:35:53,748 Node[0] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=65190, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,3]<stderr>:2019-10-17 16:35:53,749 Node[3] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=39033, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,6]<stderr>:2019-10-17 16:35:53,749 Node[6] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=29070, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,1]<stderr>:2019-10-17 16:35:53,749 Node[1] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=16998, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,2]<stderr>:2019-10-17 16:35:53,749 Node[2] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=24142, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,4]<stderr>:2019-10-17 16:35:53,749 Node[4] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=10743, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,5]<stderr>:2019-10-17 16:35:53,749 Node[5] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=63438, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,7]<stderr>:2019-10-17 16:35:53,749 Node[7] start with arguments Namespace(accuracy_threshold=0.759, batch_size=208, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_cache_size=0, dali_nvjpeg_memory_padding=256, dali_prefetch_queue=8, dali_roi_decode=True, dali_threads=3, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', epoch_size=0, eval_offset=3, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, log='', logging_dir='logs', lr=5.0, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-normconv-fl', num_classes=1000, num_epochs=72, num_examples=1281167, num_layers=50, optimizer='sgdwfastlars', pooling_layout='NHWC', profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=55278, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0002)
[1,5]<stderr>:2019-10-17 16:35:56,112 Node[5] Already bound, ignoring bind()
[1,4]<stderr>:2019-10-17 16:35:56,233 Node[4] Already bound, ignoring bind()
[1,0]<stdout>::::MLL 1571330156.264 opt_base_learning_rate: {"metadata": {"file": "common/fit.py", "lineno": 651}, "value": 5.0}
[1,0]<stdout>::::MLL 1571330156.265 opt_learning_rate_warmup_epochs: {"metadata": {"file": "common/fit.py", "lineno": 652}, "value": 5}
[1,0]<stdout>::::MLL 1571330156.265 lars_opt_learning_rate_decay_steps: {"metadata": {"file": "common/fit.py", "lineno": 662}, "value": 51590}
[1,0]<stdout>::::MLL 1571330156.265 lars_opt_learning_rate_decay_poly_power: {"metadata": {"file": "common/fit.py", "lineno": 698}, "value": 2}
[1,0]<stdout>::::MLL 1571330156.266 lars_opt_end_learning_rate: {"metadata": {"file": "common/fit.py", "lineno": 699}, "value": 0.0001}
[1,0]<stdout>::::MLL 1571330156.266 opt_name: {"metadata": {"file": "common/fit.py", "lineno": 1075}, "value": "lars"}
[1,0]<stderr>:2019-10-17 16:35:56,267 Node[0] Already bound, ignoring bind()
[1,0]<stdout>::::MLL 1571330156.266 lars_epsilon: {"metadata": {"file": "common/fit.py", "lineno": 1077}, "value": 0}
[1,0]<stdout>:WARNING: Log validation: Key "lars_opt_weight_decay" is not in known resnet keys.
[1,0]<stdout>::::MLL 1571330156.267 lars_opt_weight_decay: {"metadata": {"file": "common/fit.py", "lineno": 1079}, "value": 0.0002}
[1,0]<stdout>:using wd on conv0_weight
[1,0]<stdout>:skipping wd on bn0_gamma
[1,0]<stdout>:skipping wd on bn0_beta
[1,0]<stdout>:using wd on stage1_unit1_conv1_weight
[1,0]<stdout>:skipping wd on stage1_unit1_bn1_gamma
[1,0]<stdout>:skipping wd on stage1_unit1_bn1_beta
[1,0]<stdout>:using wd on stage1_unit1_conv2_weight
[1,0]<stdout>:skipping wd on stage1_unit1_bn2_gamma
[1,0]<stdout>:skipping wd on stage1_unit1_bn2_beta
[1,0]<stdout>:using wd on stage1_unit1_conv3_weight
[1,0]<stdout>:skipping wd on stage1_unit1_bn3_gamma
[1,0]<stdout>:skipping wd on stage1_unit1_bn3_beta
[1,0]<stdout>:using wd on stage1_unit1_conv1sc_weight
[1,0]<stdout>:skipping wd on stage1_unit1_bn_sc_gamma
[1,0]<stdout>:skipping wd on stage1_unit1_bn_sc_beta
[1,0]<stdout>:using wd on stage1_unit2_conv1_weight
[1,0]<stdout>:skipping wd on stage1_unit2_bn1_gamma
[1,0]<stdout>:skipping wd on stage1_unit2_bn1_beta
[1,0]<stdout>:using wd on stage1_unit2_conv2_weight
[1,0]<stdout>:skipping wd on stage1_unit2_bn2_gamma
[1,0]<stdout>:skipping wd on stage1_unit2_bn2_beta
[1,0]<stdout>:using wd on stage1_unit2_conv3_weight
[1,0]<stdout>:skipping wd on stage1_unit2_bn3_gamma
[1,0]<stdout>:skipping wd on stage1_unit2_bn3_beta
[1,0]<stdout>:using wd on stage1_unit3_conv1_weight
[1,0]<stdout>:skipping wd on stage1_unit3_bn1_gamma
[1,0]<stdout>:skipping wd on stage1_unit3_bn1_beta
[1,0]<stdout>:using wd on stage1_unit3_conv2_weight
[1,0]<stdout>:skipping wd on stage1_unit3_bn2_gamma
[1,0]<stdout>:skipping wd on stage1_unit3_bn2_beta
[1,0]<stdout>:using wd on stage1_unit3_conv3_weight
[1,0]<stdout>:skipping wd on stage1_unit3_bn3_gamma
[1,0]<stdout>:skipping wd on stage1_unit3_bn3_beta
[1,0]<stdout>:using wd on stage2_unit1_conv1_weight
[1,0]<stdout>:skipping wd on stage2_unit1_bn1_gamma
[1,0]<stdout>:skipping wd on stage2_unit1_bn1_beta
[1,0]<stdout>:using wd on stage2_unit1_conv2_weight
[1,0]<stdout>:skipping wd on stage2_unit1_bn2_gamma
[1,0]<stdout>:skipping wd on stage2_unit1_bn2_beta
[1,0]<stdout>:using wd on stage2_unit1_conv3_weight
[1,0]<stdout>:skipping wd on stage2_unit1_bn3_gamma
[1,0]<stdout>:skipping wd on stage2_unit1_bn3_beta
[1,0]<stdout>:using wd on stage2_unit1_conv1sc_weight
[1,0]<stdout>:skipping wd on stage2_unit1_bn_sc_gamma
[1,0]<stdout>:skipping wd on stage2_unit1_bn_sc_beta
[1,0]<stdout>:using wd on stage2_unit2_conv1_weight
[1,0]<stdout>:skipping wd on stage2_unit2_bn1_gamma
[1,0]<stdout>:skipping wd on stage2_unit2_bn1_beta
[1,0]<stdout>:using wd on stage2_unit2_conv2_weight
[1,0]<stdout>:skipping wd on stage2_unit2_bn2_gamma
[1,0]<stdout>:skipping wd on stage2_unit2_bn2_beta
[1,0]<stdout>:using wd on stage2_unit2_conv3_weight
[1,0]<stdout>:skipping wd on stage2_unit2_bn3_gamma
[1,0]<stdout>:skipping wd on stage2_unit2_bn3_beta
[1,0]<stdout>:using wd on stage2_unit3_conv1_weight
[1,0]<stdout>:skipping wd on stage2_unit3_bn1_gamma
[1,0]<stdout>:skipping wd on stage2_unit3_bn1_beta
[1,0]<stdout>:using wd on stage2_unit3_conv2_weight
[1,0]<stdout>:skipping wd on stage2_unit3_bn2_gamma
[1,0]<stdout>:skipping wd on stage2_unit3_bn2_beta
[1,0]<stdout>:using wd on stage2_unit3_conv3_weight
[1,0]<stdout>:skipping wd on stage2_unit3_bn3_gamma
[1,0]<stdout>:skipping wd on stage2_unit3_bn3_beta
[1,0]<stdout>:using wd on stage2_unit4_conv1_weight
[1,0]<stdout>:skipping wd on stage2_unit4_bn1_gamma
[1,0]<stdout>:skipping wd on stage2_unit4_bn1_beta
[1,0]<stdout>:using wd on stage2_unit4_conv2_weight
[1,0]<stdout>:skipping wd on stage2_unit4_bn2_gamma
[1,0]<stdout>:skipping wd on stage2_unit4_bn2_beta
[1,0]<stdout>:using wd on stage2_unit4_conv3_weight
[1,0]<stdout>:skipping wd on stage2_unit4_bn3_gamma
[1,0]<stdout>:skipping wd on stage2_unit4_bn3_beta
[1,0]<stdout>:using wd on stage3_unit1_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit1_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit1_bn1_beta
[1,0]<stdout>:using wd on stage3_unit1_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit1_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit1_bn2_beta
[1,0]<stdout>:using wd on stage3_unit1_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit1_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit1_bn3_beta
[1,0]<stdout>:using wd on stage3_unit1_conv1sc_weight
[1,0]<stdout>:skipping wd on stage3_unit1_bn_sc_gamma
[1,0]<stdout>:skipping wd on stage3_unit1_bn_sc_beta
[1,0]<stdout>:using wd on stage3_unit2_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit2_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit2_bn1_beta
[1,0]<stdout>:using wd on stage3_unit2_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit2_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit2_bn2_beta
[1,0]<stdout>:using wd on stage3_unit2_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit2_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit2_bn3_beta
[1,0]<stdout>:using wd on stage3_unit3_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit3_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit3_bn1_beta
[1,0]<stdout>:using wd on stage3_unit3_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit3_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit3_bn2_beta
[1,0]<stdout>:using wd on stage3_unit3_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit3_bn3_gamma
[1,0]<stdout>:skippin[1,0]<stdout>:g wd on stage3_unit3_bn3_beta
[1,0]<stdout>:using wd on stage3_unit4_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit4_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit4_bn1_beta
[1,0]<stdout>:using wd on stage3_unit4_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit4_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit4_bn2_beta
[1,0]<stdout>:using wd on stage3_unit4_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit4_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit4_bn3_beta
[1,0]<stdout>:using wd on stage3_unit5_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit5_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit5_bn1_beta
[1,0]<stdout>:using wd on stage3_unit5_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit5_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit5_bn2_beta
[1,0]<stdout>:using wd on stage3_unit5_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit5_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit5_bn3_beta
[1,0]<stdout>:using wd on stage3_unit6_conv1_weight
[1,0]<stdout>:skipping wd on stage3_unit6_bn1_gamma
[1,0]<stdout>:skipping wd on stage3_unit6_bn1_beta
[1,0]<stdout>:using wd on stage3_unit6_conv2_weight
[1,0]<stdout>:skipping wd on stage3_unit6_bn2_gamma
[1,0]<stdout>:skipping wd on stage3_unit6_bn2_beta
[1,0]<stdout>:using wd on stage3_unit6_conv3_weight
[1,0]<stdout>:skipping wd on stage3_unit6_bn3_gamma
[1,0]<stdout>:skipping wd on stage3_unit6_bn3_beta
[1,0]<stdout>:using wd on stage4_unit1_conv1_weight
[1,0]<stdout>:skipping wd on stage4_unit1_bn1_gamma
[1,0]<stdout>:skipping wd on stage4_unit1_bn1_beta
[1,0]<stdout>:using wd on stage4_unit1_conv2_weight
[1,0]<stdout>:skipping wd on stage4_unit1_bn2_gamma
[1,0]<stdout>:skipping wd on stage4_unit1_bn2_beta
[1,0]<stdout>:using wd on stage4_unit1_conv3_weight
[1,0]<stdout>:skipping wd on stage4_unit1_bn3_gamma
[1,0]<stdout>:skipping wd on stage4_unit1_bn3_beta
[1,0]<stdout>:using wd on stage4_unit1_conv1sc_weight
[1,0]<stdout>:skipping wd on stage4_unit1_bn_sc_gamma
[1,0]<stdout>:skipping wd on stage4_unit1_bn_sc_beta
[1,0]<stdout>:using wd on stage4_unit2_conv1_weight
[1,0]<stdout>:skipping wd on stage4_unit2_bn1_gamma
[1,0]<stdout>:skipping wd on stage4_unit2_bn1_beta
[1,0]<stdout>:using wd on stage4_unit2_conv2_weight
[1,0]<stdout>:skipping wd on stage4_unit2_bn2_gamma
[1,0]<stdout>:skipping wd on stage4_unit2_bn2_beta
[1,0]<stdout>:using wd on stage4_unit2_conv3_weight
[1,0]<stdout>:skipping wd on stage4_unit2_bn3_gamma
[1,0]<stdout>:skipping wd on stage4_unit2_bn3_beta
[1,0]<stdout>:using wd on stage4_unit3_conv1_weight
[1,0]<stdout>:skipping wd on stage4_unit3_bn1_gamma
[1,0]<stdout>:skipping wd on stage4_unit3_bn1_beta
[1,0]<stdout>:using wd on stage4_unit3_conv2_weight
[1,0]<stdout>:skipping wd on stage4_unit3_bn2_gamma
[1,0]<stdout>:skipping wd on stage4_unit3_bn2_beta
[1,0]<stdout>:using wd on stage4_unit3_conv3_weight
[1,0]<stdout>:skipping wd on stage4_unit3_bn3_gamma
[1,0]<stdout>:skipping wd on stage4_unit3_bn3_beta
[1,0]<stdout>:using wd on fc1_weight
[1,0]<stdout>:using wd on fc1_bias
[1,0]<stdout>::::MLL 1571330156.268 global_batch_size: {"metadata": {"file": "common/fit.py", "lineno": 1112}, "value": 1664}
[1,0]<stdout>::::MLL 1571330156.269 block_start: {"metadata": {"file": "common/fit.py", "lineno": 888, "first_epoch_num": 1, "epoch_count": 4}, "value": null}
[1,0]<stdout>::::MLL 1571330156.269 epoch_start: {"metadata": {"file": "common/fit.py", "lineno": 893, "epoch_num": 1}, "value": null}
[1,1]<stderr>:2019-10-17 16:35:56,408 Node[1] Already bound, ignoring bind()
[1,3]<stderr>:2019-10-17 16:35:56,504 Node[3] Already bound, ignoring bind()
[1,2]<stderr>:2019-10-17 16:35:56,514 Node[2] Already bound, ignoring bind()
[1,7]<stderr>:2019-10-17 16:35:56,561 Node[7] Already bound, ignoring bind()
[1,6]<stderr>:2019-10-17 16:35:56,576 Node[6] Already bound, ignoring bind()
[1,0]<stderr>:/workspace/image_classification/common/fit.py:858: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.
[1,0]<stderr>:  allow_missing=allow_missing, force_init=force_init)
[1,0]<stderr>:/workspace/image_classification/common/fit.py:860: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.0006009615384615385 vs. 0.004807692307692308). Is this intended?
[1,0]<stderr>:  optimizer_params=optimizer_params)
[1,0]<stderr>:2019-10-17 16:36:06,491 Node[0] Epoch[0] Batch [0-20]	Speed: 8755.03 samples/sec	accuracy=0.000687
[1,0]<stderr>:2019-10-17 16:36:09,923 Node[0] Epoch[0] Batch [20-40]	Speed: 9700.74 samples/sec	accuracy=0.000962
[1,0]<stderr>:2019-10-17 16:36:13,321 Node[0] Epoch[0] Batch [40-60]	Speed: 9797.26 samples/sec	accuracy=0.001202
[1,0]<stderr>:2019-10-17 16:36:16,739 Node[0] Epoch[0] Batch [60-80]	Speed: 9736.95 samples/sec	accuracy=0.003365
[1,0]<stderr>:2019-10-17 16:36:20,160 Node[0] Epoch[0] Batch [80-100]	Speed: 9729.71 samples/sec	accuracy=0.003125
[1,0]<stderr>:2019-10-17 16:36:23,550 Node[0] Epoch[0] Batch [100-120]	Speed: 9817.55 samples/sec	accuracy=0.004567
[1,0]<stderr>:2019-10-17 16:36:26,876 Node[0] Epoch[0] Batch [120-140]	Speed: 10006.13 samples/sec	accuracy=0.002644
[1,0]<stderr>:2019-10-17 16:36:30,301 Node[0] Epoch[0] Batch [140-160]	Speed: 9719.93 samples/sec	accuracy=0.001923
[1,0]<stderr>:2019-10-17 16:36:33,689 Node[0] Epoch[0] Batch [160-180]	Speed: 9822.33 samples/sec	accuracy=0.003846
