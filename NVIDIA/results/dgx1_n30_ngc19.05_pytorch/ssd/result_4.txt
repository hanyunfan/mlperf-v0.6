Beginning trial 2 of 5
Gathering sys log on sc-sdgx-344
:::MLL 1558640178.979 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558640178.979 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558640178.980 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558640178.981 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558640178.982 submission_platform: {"value": "30xDGX-1 with V100", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558640178.982 submission_entry: {"value": "{'hardware': 'DGX-1 with V100', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.2 LTS / NVIDIA DGX Server 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz', 'num_cores': '40', 'num_vcpus': '80', 'accelerator': 'Tesla V100-SXM2-16GB', 'num_accelerators': '8', 'sys_mem_size': '503 GB', 'sys_storage_type': 'SATA SSD', 'sys_storage_size': '1x 7T + 1x 446.6G', 'cpu_accel_interconnect': 'QPI', 'network_card': 'Mellanox Technologies MT27700 Family [ConnectX-4]', 'num_network_cards': '4', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558640178.983 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558640178.984 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558640231.137 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640228.772 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640226.656 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640224.986 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640226.773 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640227.894 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640230.858 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640227.313 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640226.516 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640227.955 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640227.107 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640232.692 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640228.990 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640227.514 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640227.623 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640229.902 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640234.400 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640233.804 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640230.247 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640238.515 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640236.931 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640236.951 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640232.370 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640231.234 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640244.645 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640239.536 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640239.196 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640238.045 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640240.187 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640248.739 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node sc-sdgx-344
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-345
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-346
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-344
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-345
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-352
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-344 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-345 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-353
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-346
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-352
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-346 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-354
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-353
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-352 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-355
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-360
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-353 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-354
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-355
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-361
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-354 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-355 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-362
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-360
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-360 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-361
+ set +x
Launching on node sc-sdgx-363
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-361 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ set +x
Launching on node sc-sdgx-364
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-362
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-363
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-369
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-362 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-363 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-370
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-364
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-371
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-369
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-364 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-372
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-370
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-369 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-377
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-371
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-370 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-372
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-378
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-371 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-379
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-377
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-372 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-378
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-380
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-377 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-379
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-378 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ set +x
Launching on node sc-sdgx-385
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-379 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-380
Launching on node sc-sdgx-386
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-387
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-380 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-385
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-386
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-388
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-385 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-386 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-394
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-387
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-388
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-395
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-387 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-388 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-394
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-396
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-395
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-394 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-397
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-395 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-396
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-398
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-396 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-397
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-405
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-398
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-397 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-398 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-405
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-405 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:37:29 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:37:24 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:37:23 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2019-05-23 07:37:24 PM
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:37:27 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:25 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:37:29 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:23 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:26 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:37:26 PM
+ DATASET_DIR=/data/coco2017
running benchmark
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:22 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:24 PM
STARTING TIMING RUN AT 2019-05-23 07:37:24 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:37:26 PM
STARTING TIMING RUN AT 2019-05-23 07:37:29 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:37:31 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:37:28 PM
running benchmark
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:37:23 PM
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2019-05-23 07:37:30 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:23 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:37:24 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2019-05-23 07:37:25 PM
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
running benchmark
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:23 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:24 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:22 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:22 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:24 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:37:29 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:37:25 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:37:23 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558640247.855 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.855 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.855 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.856 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.857 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.857 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.857 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.857 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640249.849 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.849 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.849 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.849 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.851 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.851 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.851 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640249.853 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640247.918 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.918 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.920 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640247.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640248.047 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.047 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.047 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.047 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.048 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.048 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.048 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.048 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640253.063 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.063 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.063 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.065 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640247.805 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640247.806 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.806 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640247.807 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.807 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.807 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.808 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640247.808 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640251.761 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640251.761 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640251.761 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640251.763 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640251.763 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640251.763 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640251.763 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640251.763 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640254.699 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640254.699 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640254.700 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640254.701 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640254.701 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640254.701 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640254.702 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640254.702 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640253.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.061 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.061 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.061 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.061 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.061 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.061 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640255.018 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640255.018 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640255.018 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640255.019 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640255.020 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640255.020 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640255.020 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640255.021 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640246.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.425 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.426 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.426 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640246.427 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640250.880 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.880 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.880 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.881 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.881 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.881 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.882 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640250.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640252.471 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640252.471 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640252.471 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640252.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640252.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640252.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640252.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640252.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640248.498 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.498 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.498 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.498 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640249.492 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.492 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.492 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.492 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.500 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.500 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640249.493 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.493 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.501 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.494 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640249.494 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640248.502 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640249.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.878 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.879 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.879 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.879 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.246 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.246 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.246 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.246 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.512 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.512 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.512 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.513 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.880 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.513 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.513 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.513 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.514 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640250.248 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640250.248 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640250.248 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640250.250 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640246.686 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.686 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.687 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.688 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.688 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.688 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640246.689 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.689 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640248.977 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.977 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.977 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.977 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640248.978 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.978 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.978 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640248.980 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640248.344 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.344 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.013 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.013 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.013 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.013 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.346 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640248.346 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.347 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.347 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640249.015 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.015 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640249.016 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.673 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.673 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.673 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640253.674 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.674 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.674 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.674 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.018 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640253.675 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640253.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640253.254 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640247.730 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.730 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.730 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.730 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.731 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.731 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.731 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.732 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640246.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.275 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640246.275 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640246.278 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640248.012 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.012 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.012 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.012 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.012 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.012 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.013 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640248.014 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.366 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.366 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.366 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.366 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640247.367 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.367 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640247.367 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640247.367 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640249.170 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.170 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.170 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.170 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.170 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.170 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.171 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640249.172 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640249.838 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.838 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.840 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.840 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.840 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.840 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640249.840 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640249.840 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
5 Using seed = 3950660333
1 Using seed = 3950660329
0 Using seed = 3950660328
:::MLL 1558640258.554 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
3 Using seed = 3950660331
7 Using seed = 3950660335
6 Using seed = 3950660334
4 Using seed = 3950660332
10 Using seed = 3950660338
11 Using seed = 3950660339
8 Using seed = 3950660336
9 Using seed = 3950660337
14 Using seed = 3950660342
13 Using seed = 3950660341
15 Using seed = 3950660343
12 Using seed = 3950660340
21 Using seed = 3950660349
16 Using seed = 3950660344
18 Using seed = 3950660346
17 Using seed = 3950660345
19 Using seed = 3950660347
22 Using seed = 3950660350
23 Using seed = 3950660351
20 Using seed = 3950660348
25 Using seed = 3950660353
26 Using seed = 3950660354
24 Using seed = 3950660352
29 Using seed = 3950660357
30 Using seed = 3950660358
31 Using seed = 3950660359
27 Using seed = 3950660355
28 Using seed = 3950660356
36 Using seed = 3950660364
37 Using seed = 3950660365
38 Using seed = 3950660366
39 Using seed = 3950660367
33 Using seed = 3950660361
34 Using seed = 3950660362
32 Using seed = 3950660360
35 Using seed = 3950660363
42 Using seed = 3950660370
40 Using seed = 3950660368
41 Using seed = 3950660369
45 Using seed = 3950660373
43 Using seed = 3950660371
46 Using seed = 3950660374
47 Using seed = 3950660375
44 Using seed = 3950660372
49 Using seed = 3950660377
51 Using seed = 3950660379
48 Using seed = 3950660376
50 Using seed = 3950660378
53 Using seed = 3950660381
54 Using seed = 3950660382
55 Using seed = 3950660383
52 Using seed = 3950660380
62 Using seed = 3950660390
61 Using seed = 3950660389
60 Using seed = 3950660388
63 Using seed = 3950660391
58 Using seed = 3950660386
59 Using seed = 3950660387
57 Using seed = 3950660385
56 Using seed = 3950660384
70 Using seed = 3950660398
71 Using seed = 3950660399
69 Using seed = 3950660397
68 Using seed = 3950660396
66 Using seed = 3950660394
65 Using seed = 3950660393
67 Using seed = 3950660395
64 Using seed = 3950660392
78 Using seed = 3950660406
79 Using seed = 3950660407
77 Using seed = 3950660405
76 Using seed = 3950660404
73 Using seed = 3950660401
75 Using seed = 3950660403
72 Using seed = 3950660400
74 Using seed = 3950660402
87 Using seed = 3950660415
85 Using seed = 3950660413
84 Using seed = 3950660412
86 Using seed = 3950660414
83 Using seed = 3950660411
82 Using seed = 3950660410
81 Using seed = 3950660409
80 Using seed = 3950660408
90 Using seed = 3950660418
89 Using seed = 3950660417
88 Using seed = 3950660416
93 Using seed = 3950660421
95 Using seed = 3950660423
94 Using seed = 3950660422
91 Using seed = 3950660419
92 Using seed = 3950660420
96 Using seed = 3950660424
99 Using seed = 3950660427
97 Using seed = 3950660425
98 Using seed = 3950660426
102 Using seed = 3950660430
101 Using seed = 3950660429
103 Using seed = 3950660431
100 Using seed = 3950660428
109 Using seed = 3950660437
110 Using seed = 3950660438
108 Using seed = 3950660436
111 Using seed = 3950660439
105 Using seed = 3950660433
107 Using seed = 3950660435
106 Using seed = 3950660434
104 Using seed = 3950660432
117 Using seed = 3950660445
119 Using seed = 3950660447
118 Using seed = 3950660446
116 Using seed = 3950660444
114 Using seed = 3950660442
112 Using seed = 3950660440
115 Using seed = 3950660443
113 Using seed = 3950660441
121 Using seed = 3950660449
122 Using seed = 3950660450
123 Using seed = 3950660451
120 Using seed = 3950660448
127 Using seed = 3950660455
125 Using seed = 3950660453
126 Using seed = 3950660454
124 Using seed = 3950660452
134 Using seed = 3950660462
133 Using seed = 3950660461
132 Using seed = 3950660460
135 Using seed = 3950660463
128 Using seed = 3950660456
131 Using seed = 3950660459
130 Using seed = 3950660458
129 Using seed = 3950660457
141 Using seed = 3950660469
143 Using seed = 3950660471
142 Using seed = 3950660470
140 Using seed = 3950660468
139 Using seed = 3950660467
136 Using seed = 3950660464
138 Using seed = 3950660466
137 Using seed = 3950660465
144 Using seed = 3950660472
145 Using seed = 3950660473
148 Using seed = 3950660476
147 Using seed = 3950660475
146 Using seed = 3950660474
151 Using seed = 3950660479
149 Using seed = 3950660477
150 Using seed = 3950660478
157 Using seed = 3950660485
159 Using seed = 3950660487
158 Using seed = 3950660486
156 Using seed = 3950660484
153 Using seed = 3950660481
154 Using seed = 3950660482
152 Using seed = 3950660480
155 Using seed = 3950660483
166 Using seed = 3950660494
165 Using seed = 3950660493
164 Using seed = 3950660492
167 Using seed = 3950660495
160 Using seed = 3950660488
161 Using seed = 3950660489
162 Using seed = 3950660490
163 Using seed = 3950660491
175 Using seed = 3950660503
172 Using seed = 3950660500
173 Using seed = 3950660501
174 Using seed = 3950660502
169 Using seed = 3950660497
170 Using seed = 3950660498
171 Using seed = 3950660499
168 Using seed = 3950660496
181 Using seed = 3950660509
183 Using seed = 3950660511
182 Using seed = 3950660510
180 Using seed = 3950660508
176 Using seed = 3950660504
179 Using seed = 3950660507
178 Using seed = 3950660506
177 Using seed = 3950660505
190 Using seed = 3950660518
191 Using seed = 3950660519
189 Using seed = 3950660517
188 Using seed = 3950660516
186 Using seed = 3950660514
185 Using seed = 3950660513
184 Using seed = 3950660512
187 Using seed = 3950660515
198 Using seed = 3950660526
196 Using seed = 3950660524
199 Using seed = 3950660527
197 Using seed = 3950660525
193 Using seed = 3950660521
192 Using seed = 3950660520
194 Using seed = 3950660522
195 Using seed = 3950660523
201 Using seed = 3950660529
200 Using seed = 3950660528
202 Using seed = 3950660530
203 Using seed = 3950660531
207 Using seed = 3950660535
206 Using seed = 3950660534
204 Using seed = 3950660532
205 Using seed = 3950660533
214 Using seed = 3950660542
212 Using seed = 3950660540
213 Using seed = 3950660541
215 Using seed = 3950660543
210 Using seed = 3950660538
211 Using seed = 3950660539
209 Using seed = 3950660537
208 Using seed = 3950660536
223 Using seed = 3950660551
222 Using seed = 3950660550
221 Using seed = 3950660549
220 Using seed = 3950660548
219 Using seed = 3950660547
216 Using seed = 3950660544
217 Using seed = 3950660545
218 Using seed = 3950660546
231 Using seed = 3950660559
228 Using seed = 3950660556
229 Using seed = 3950660557
230 Using seed = 3950660558
224 Using seed = 3950660552
226 Using seed = 3950660554
227 Using seed = 3950660555
225 Using seed = 3950660553
238 Using seed = 3950660566
237 Using seed = 3950660565
236 Using seed = 3950660564
239 Using seed = 3950660567
233 Using seed = 3950660561
234 Using seed = 3950660562
232 Using seed = 3950660560
235 Using seed = 3950660563
2 Using seed = 3950660330
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558640263.354 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558640263.354 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558640263.362 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1558640263.362 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1558640263.363 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558640263.363 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558640271.217 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558640271.217 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
Done (t=0.46s)
creating index...
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
Done (t=0.48s)
creating index...
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
Done (t=0.48s)
creating index...
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
Done (t=0.49s)
creating index...
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.55s)
creating index...
Done (t=0.55s)
creating index...
Done (t=0.56s)
creating index...
time_check a: 1558640279.609800339
time_check a: 1558640277.723984480
time_check a: 1558640274.407107115
time_check a: 1558640272.714042187
time_check a: 1558640274.647623062
time_check a: 1558640278.167788744
time_check a: 1558640271.012994289
time_check a: 1558640274.781189919
time_check a: 1558640272.047606707
time_check a: 1558640277.715521812
time_check a: 1558640275.455035686
time_check a: 1558640271.199859619
time_check a: 1558640274.181414127
time_check a: 1558640273.550494432
time_check a: 1558640277.035837412
time_check a: 1558640276.420475960
time_check a: 1558640279.343865871
time_check a: 1558640270.720525026
time_check a: 1558640271.763545275
time_check a: 1558640272.855915070
time_check a: 1558640272.414869070
time_check a: 1558640272.486204386
time_check a: 1558640274.064051867
time_check a: 1558640273.534518719
time_check a: 1558640272.622349977
time_check a: 1558640273.508557081
time_check a: 1558640272.896138191
time_check a: 1558640277.707444906
time_check a: 1558640273.088995218
time_check a: 1558640272.253568172
time_check b: 1558640281.824779272
time_check b: 1558640281.374512672
time_check b: 1558640281.391483307
time_check b: 1558640277.214614153
time_check b: 1558640278.459656715
time_check b: 1558640283.299746752
time_check b: 1558640275.729478121
time_check b: 1558640276.422651052
time_check b: 1558640274.906964779
time_check b: 1558640280.740340710
time_check b: 1558640276.320966244
time_check b: 1558640277.903445721
time_check b: 1558640276.137830734
time_check b: 1558640277.249414921
time_check b: 1558640276.582513332
time_check b: 1558640275.503464222
time_check b: 1558640283.088016748
time_check b: 1558640278.406011105
time_check b: 1558640277.805078506
time_check b: 1558640276.834955454
time_check b: 1558640278.200138807
time_check b: 1558640279.247962713
time_check b: 1558640274.809945583
time_check b: 1558640274.512533903
time_check b: 1558640281.483368158
time_check b: 1558640280.224678993
time_check b: 1558640276.289685726
time_check b: 1558640277.330018044
time_check b: 1558640276.720997095
time_check b: 1558640276.067118883
:::MLL 1558640277.961 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558640277.962 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.494, Average Loss: 0.022, avg. samples / sec: 162.43
Iteration:      0, Loss function: 22.584, Average Loss: 0.023, avg. samples / sec: 148.54
Iteration:      0, Loss function: 22.894, Average Loss: 0.023, avg. samples / sec: 145.09
Iteration:      0, Loss function: 22.775, Average Loss: 0.023, avg. samples / sec: 144.40
Iteration:      0, Loss function: 22.742, Average Loss: 0.023, avg. samples / sec: 144.57
Iteration:      0, Loss function: 22.599, Average Loss: 0.023, avg. samples / sec: 144.40
Iteration:      0, Loss function: 22.788, Average Loss: 0.023, avg. samples / sec: 144.68
Iteration:      0, Loss function: 22.554, Average Loss: 0.023, avg. samples / sec: 143.04
Iteration:      0, Loss function: 22.872, Average Loss: 0.023, avg. samples / sec: 143.16
Iteration:      0, Loss function: 22.334, Average Loss: 0.022, avg. samples / sec: 148.91
Iteration:      0, Loss function: 22.599, Average Loss: 0.023, avg. samples / sec: 146.28
Iteration:      0, Loss function: 23.127, Average Loss: 0.023, avg. samples / sec: 146.24
Iteration:      0, Loss function: 23.944, Average Loss: 0.024, avg. samples / sec: 146.65
Iteration:      0, Loss function: 22.522, Average Loss: 0.023, avg. samples / sec: 144.94
Iteration:      0, Loss function: 23.732, Average Loss: 0.024, avg. samples / sec: 144.02
Iteration:      0, Loss function: 23.768, Average Loss: 0.024, avg. samples / sec: 168.85
Iteration:      0, Loss function: 22.664, Average Loss: 0.023, avg. samples / sec: 142.48
Iteration:      0, Loss function: 22.994, Average Loss: 0.023, avg. samples / sec: 147.02
Iteration:      0, Loss function: 22.763, Average Loss: 0.023, avg. samples / sec: 143.34
Iteration:      0, Loss function: 23.081, Average Loss: 0.023, avg. samples / sec: 143.06
Iteration:      0, Loss function: 21.940, Average Loss: 0.022, avg. samples / sec: 144.35
Iteration:      0, Loss function: 23.280, Average Loss: 0.023, avg. samples / sec: 142.50
Iteration:      0, Loss function: 23.733, Average Loss: 0.024, avg. samples / sec: 144.79
Iteration:      0, Loss function: 22.665, Average Loss: 0.023, avg. samples / sec: 144.41
Iteration:      0, Loss function: 22.684, Average Loss: 0.023, avg. samples / sec: 143.31
Iteration:      0, Loss function: 22.593, Average Loss: 0.023, avg. samples / sec: 144.18
Iteration:      0, Loss function: 22.499, Average Loss: 0.022, avg. samples / sec: 143.67
Iteration:      0, Loss function: 22.561, Average Loss: 0.023, avg. samples / sec: 140.80
Iteration:      0, Loss function: 23.585, Average Loss: 0.024, avg. samples / sec: 142.99
Iteration:      0, Loss function: 22.807, Average Loss: 0.023, avg. samples / sec: 143.76
Iteration:     20, Loss function: 20.659, Average Loss: 0.447, avg. samples / sec: 33933.60
Iteration:     20, Loss function: 20.365, Average Loss: 0.444, avg. samples / sec: 34903.32
Iteration:     20, Loss function: 20.842, Average Loss: 0.447, avg. samples / sec: 34189.68
Iteration:     20, Loss function: 20.240, Average Loss: 0.445, avg. samples / sec: 36340.49
Iteration:     20, Loss function: 21.009, Average Loss: 0.449, avg. samples / sec: 33960.17
Iteration:     20, Loss function: 20.526, Average Loss: 0.445, avg. samples / sec: 35136.35
Iteration:     20, Loss function: 20.629, Average Loss: 0.446, avg. samples / sec: 34840.21
Iteration:     20, Loss function: 20.388, Average Loss: 0.446, avg. samples / sec: 35444.58
Iteration:     20, Loss function: 20.341, Average Loss: 0.446, avg. samples / sec: 32401.24
Iteration:     20, Loss function: 20.482, Average Loss: 0.446, avg. samples / sec: 33006.43
Iteration:     20, Loss function: 20.729, Average Loss: 0.447, avg. samples / sec: 33253.35
Iteration:     20, Loss function: 20.439, Average Loss: 0.445, avg. samples / sec: 34674.48
Iteration:     20, Loss function: 20.306, Average Loss: 0.449, avg. samples / sec: 34068.46
Iteration:     20, Loss function: 20.892, Average Loss: 0.444, avg. samples / sec: 33887.99
Iteration:     20, Loss function: 21.826, Average Loss: 0.445, avg. samples / sec: 36150.60
Iteration:     20, Loss function: 21.082, Average Loss: 0.444, avg. samples / sec: 34399.96
Iteration:     20, Loss function: 20.772, Average Loss: 0.445, avg. samples / sec: 32863.70
Iteration:     20, Loss function: 20.605, Average Loss: 0.443, avg. samples / sec: 35142.63
Iteration:     20, Loss function: 20.358, Average Loss: 0.443, avg. samples / sec: 33520.29
Iteration:     20, Loss function: 20.090, Average Loss: 0.445, avg. samples / sec: 34046.75
Iteration:     20, Loss function: 22.551, Average Loss: 0.448, avg. samples / sec: 34129.48
Iteration:     20, Loss function: 20.185, Average Loss: 0.446, avg. samples / sec: 36419.12
Iteration:     20, Loss function: 21.280, Average Loss: 0.445, avg. samples / sec: 32709.51
Iteration:     20, Loss function: 19.965, Average Loss: 0.442, avg. samples / sec: 35252.40
Iteration:     20, Loss function: 21.027, Average Loss: 0.451, avg. samples / sec: 33290.79
Iteration:     20, Loss function: 20.371, Average Loss: 0.447, avg. samples / sec: 33424.10
Iteration:     20, Loss function: 20.702, Average Loss: 0.447, avg. samples / sec: 34543.95
Iteration:     20, Loss function: 20.215, Average Loss: 0.443, avg. samples / sec: 33530.26
Iteration:     20, Loss function: 20.782, Average Loss: 0.444, avg. samples / sec: 33194.37
Iteration:     20, Loss function: 20.410, Average Loss: 0.445, avg. samples / sec: 33019.02
Iteration:     40, Loss function: 18.602, Average Loss: 0.831, avg. samples / sec: 48556.81
Iteration:     40, Loss function: 19.758, Average Loss: 0.837, avg. samples / sec: 47931.56
Iteration:     40, Loss function: 19.308, Average Loss: 0.833, avg. samples / sec: 48211.76
Iteration:     40, Loss function: 18.557, Average Loss: 0.839, avg. samples / sec: 48092.38
Iteration:     40, Loss function: 20.343, Average Loss: 0.842, avg. samples / sec: 47964.25
Iteration:     40, Loss function: 18.733, Average Loss: 0.835, avg. samples / sec: 47867.14
Iteration:     40, Loss function: 18.431, Average Loss: 0.837, avg. samples / sec: 47828.44
Iteration:     40, Loss function: 19.268, Average Loss: 0.841, avg. samples / sec: 47798.76
Iteration:     40, Loss function: 18.378, Average Loss: 0.835, avg. samples / sec: 48098.47
Iteration:     40, Loss function: 18.621, Average Loss: 0.839, avg. samples / sec: 48055.52
Iteration:     40, Loss function: 18.610, Average Loss: 0.844, avg. samples / sec: 48150.04
Iteration:     40, Loss function: 18.350, Average Loss: 0.829, avg. samples / sec: 48122.20
Iteration:     40, Loss function: 18.963, Average Loss: 0.836, avg. samples / sec: 47921.65
Iteration:     40, Loss function: 19.041, Average Loss: 0.840, avg. samples / sec: 48498.31
Iteration:     40, Loss function: 18.861, Average Loss: 0.836, avg. samples / sec: 48012.10
Iteration:     40, Loss function: 18.990, Average Loss: 0.833, avg. samples / sec: 47907.12
Iteration:     40, Loss function: 18.571, Average Loss: 0.836, avg. samples / sec: 47681.36
Iteration:     40, Loss function: 18.446, Average Loss: 0.835, avg. samples / sec: 47808.49
Iteration:     40, Loss function: 19.023, Average Loss: 0.837, avg. samples / sec: 48129.83
Iteration:     40, Loss function: 18.989, Average Loss: 0.838, avg. samples / sec: 47664.53
Iteration:     40, Loss function: 18.818, Average Loss: 0.830, avg. samples / sec: 47920.33
Iteration:     40, Loss function: 18.798, Average Loss: 0.836, avg. samples / sec: 47674.78
Iteration:     40, Loss function: 19.148, Average Loss: 0.835, avg. samples / sec: 47670.82
Iteration:     40, Loss function: 19.021, Average Loss: 0.833, avg. samples / sec: 48115.75
Iteration:     40, Loss function: 18.787, Average Loss: 0.838, avg. samples / sec: 47593.40
Iteration:     40, Loss function: 18.760, Average Loss: 0.836, avg. samples / sec: 47999.72
Iteration:     40, Loss function: 19.127, Average Loss: 0.835, avg. samples / sec: 47760.32
Iteration:     40, Loss function: 20.352, Average Loss: 0.836, avg. samples / sec: 47743.44
Iteration:     40, Loss function: 19.387, Average Loss: 0.832, avg. samples / sec: 47719.89
Iteration:     40, Loss function: 18.549, Average Loss: 0.835, avg. samples / sec: 47166.92
Iteration:     60, Loss function: 15.350, Average Loss: 1.119, avg. samples / sec: 50267.57
Iteration:     60, Loss function: 13.224, Average Loss: 1.109, avg. samples / sec: 50721.19
Iteration:     60, Loss function: 15.773, Average Loss: 1.104, avg. samples / sec: 50546.49
Iteration:     60, Loss function: 14.292, Average Loss: 1.114, avg. samples / sec: 50428.36
Iteration:     60, Loss function: 12.615, Average Loss: 1.112, avg. samples / sec: 50259.04
Iteration:     60, Loss function: 15.230, Average Loss: 1.111, avg. samples / sec: 50520.78
Iteration:     60, Loss function: 14.914, Average Loss: 1.112, avg. samples / sec: 50283.57
Iteration:     60, Loss function: 15.069, Average Loss: 1.112, avg. samples / sec: 50259.10
Iteration:     60, Loss function: 16.282, Average Loss: 1.119, avg. samples / sec: 50175.23
Iteration:     60, Loss function: 14.069, Average Loss: 1.103, avg. samples / sec: 49979.83
Iteration:     60, Loss function: 13.276, Average Loss: 1.108, avg. samples / sec: 50027.64
Iteration:     60, Loss function: 12.854, Average Loss: 1.109, avg. samples / sec: 50191.22
Iteration:     60, Loss function: 14.964, Average Loss: 1.112, avg. samples / sec: 50145.59
Iteration:     60, Loss function: 13.779, Average Loss: 1.108, avg. samples / sec: 50082.59
Iteration:     60, Loss function: 15.933, Average Loss: 1.114, avg. samples / sec: 50288.88
Iteration:     60, Loss function: 15.962, Average Loss: 1.106, avg. samples / sec: 50727.83
Iteration:     60, Loss function: 14.207, Average Loss: 1.102, avg. samples / sec: 50222.45
Iteration:     60, Loss function: 13.640, Average Loss: 1.114, avg. samples / sec: 50081.35
Iteration:     60, Loss function: 14.777, Average Loss: 1.109, avg. samples / sec: 50224.24
Iteration:     60, Loss function: 15.831, Average Loss: 1.108, avg. samples / sec: 50293.46
Iteration:     60, Loss function: 14.984, Average Loss: 1.109, avg. samples / sec: 50082.13
Iteration:     60, Loss function: 14.336, Average Loss: 1.112, avg. samples / sec: 49901.99
Iteration:     60, Loss function: 14.732, Average Loss: 1.112, avg. samples / sec: 49946.49
Iteration:     60, Loss function: 14.980, Average Loss: 1.107, avg. samples / sec: 49816.95
Iteration:     60, Loss function: 13.667, Average Loss: 1.101, avg. samples / sec: 49680.44
Iteration:     60, Loss function: 12.890, Average Loss: 1.107, avg. samples / sec: 50132.67
Iteration:     60, Loss function: 15.559, Average Loss: 1.113, avg. samples / sec: 50057.07
Iteration:     60, Loss function: 13.938, Average Loss: 1.110, avg. samples / sec: 50146.02
Iteration:     60, Loss function: 15.461, Average Loss: 1.104, avg. samples / sec: 49825.03
Iteration:     60, Loss function: 14.545, Average Loss: 1.102, avg. samples / sec: 49788.14
:::MLL 1558640281.523 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558640281.524 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 10.542, Average Loss: 1.303, avg. samples / sec: 51934.97
Iteration:     80, Loss function: 10.099, Average Loss: 1.310, avg. samples / sec: 51908.27
Iteration:     80, Loss function: 10.549, Average Loss: 1.310, avg. samples / sec: 51947.61
Iteration:     80, Loss function: 9.875, Average Loss: 1.303, avg. samples / sec: 52333.65
Iteration:     80, Loss function: 9.985, Average Loss: 1.312, avg. samples / sec: 51709.43
Iteration:     80, Loss function: 9.688, Average Loss: 1.308, avg. samples / sec: 51566.50
Iteration:     80, Loss function: 10.229, Average Loss: 1.306, avg. samples / sec: 51578.30
Iteration:     80, Loss function: 9.765, Average Loss: 1.313, avg. samples / sec: 51771.73
Iteration:     80, Loss function: 10.054, Average Loss: 1.302, avg. samples / sec: 51825.88
Iteration:     80, Loss function: 10.334, Average Loss: 1.298, avg. samples / sec: 51628.80
Iteration:     80, Loss function: 9.500, Average Loss: 1.311, avg. samples / sec: 51516.70
Iteration:     80, Loss function: 8.664, Average Loss: 1.294, avg. samples / sec: 51776.58
Iteration:     80, Loss function: 10.281, Average Loss: 1.319, avg. samples / sec: 51605.76
Iteration:     80, Loss function: 9.607, Average Loss: 1.303, avg. samples / sec: 51591.83
Iteration:     80, Loss function: 10.071, Average Loss: 1.300, avg. samples / sec: 51961.72
Iteration:     80, Loss function: 9.677, Average Loss: 1.312, avg. samples / sec: 51717.93
Iteration:     80, Loss function: 9.502, Average Loss: 1.306, avg. samples / sec: 51655.52
Iteration:     80, Loss function: 9.682, Average Loss: 1.303, avg. samples / sec: 51571.75
Iteration:     80, Loss function: 10.037, Average Loss: 1.302, avg. samples / sec: 51297.90
Iteration:     80, Loss function: 11.548, Average Loss: 1.318, avg. samples / sec: 51186.16
Iteration:     80, Loss function: 10.030, Average Loss: 1.302, avg. samples / sec: 51612.07
Iteration:     80, Loss function: 9.683, Average Loss: 1.303, avg. samples / sec: 51205.64
Iteration:     80, Loss function: 10.223, Average Loss: 1.301, avg. samples / sec: 51496.44
Iteration:     80, Loss function: 9.842, Average Loss: 1.305, avg. samples / sec: 51483.93
Iteration:     80, Loss function: 10.495, Average Loss: 1.309, avg. samples / sec: 51626.97
Iteration:     80, Loss function: 10.518, Average Loss: 1.309, avg. samples / sec: 51631.32
Iteration:     80, Loss function: 9.478, Average Loss: 1.304, avg. samples / sec: 51358.73
Iteration:     80, Loss function: 9.977, Average Loss: 1.298, avg. samples / sec: 51213.79
Iteration:     80, Loss function: 9.598, Average Loss: 1.310, avg. samples / sec: 51186.41
Iteration:     80, Loss function: 10.735, Average Loss: 1.310, avg. samples / sec: 51210.03
Iteration:    100, Loss function: 9.870, Average Loss: 1.471, avg. samples / sec: 50241.34
Iteration:    100, Loss function: 9.655, Average Loss: 1.480, avg. samples / sec: 49920.64
Iteration:    100, Loss function: 9.692, Average Loss: 1.484, avg. samples / sec: 49771.66
Iteration:    100, Loss function: 9.783, Average Loss: 1.493, avg. samples / sec: 49844.33
Iteration:    100, Loss function: 9.313, Average Loss: 1.472, avg. samples / sec: 50203.25
Iteration:    100, Loss function: 9.272, Average Loss: 1.488, avg. samples / sec: 49533.89
Iteration:    100, Loss function: 10.534, Average Loss: 1.480, avg. samples / sec: 49863.31
Iteration:    100, Loss function: 9.658, Average Loss: 1.472, avg. samples / sec: 49829.37
Iteration:    100, Loss function: 9.676, Average Loss: 1.483, avg. samples / sec: 49868.94
Iteration:    100, Loss function: 9.926, Average Loss: 1.478, avg. samples / sec: 49596.31
Iteration:    100, Loss function: 10.588, Average Loss: 1.469, avg. samples / sec: 49555.03
Iteration:    100, Loss function: 9.839, Average Loss: 1.474, avg. samples / sec: 49641.09
Iteration:    100, Loss function: 9.774, Average Loss: 1.479, avg. samples / sec: 49353.48
Iteration:    100, Loss function: 9.945, Average Loss: 1.484, avg. samples / sec: 49823.34
Iteration:    100, Loss function: 9.079, Average Loss: 1.490, avg. samples / sec: 49403.58
Iteration:    100, Loss function: 9.575, Average Loss: 1.487, avg. samples / sec: 49349.82
Iteration:    100, Loss function: 9.562, Average Loss: 1.476, avg. samples / sec: 49326.77
Iteration:    100, Loss function: 10.185, Average Loss: 1.487, avg. samples / sec: 49521.15
Iteration:    100, Loss function: 10.023, Average Loss: 1.484, avg. samples / sec: 49722.14
Iteration:    100, Loss function: 9.930, Average Loss: 1.477, avg. samples / sec: 49166.92
Iteration:    100, Loss function: 10.371, Average Loss: 1.489, avg. samples / sec: 48992.76
Iteration:    100, Loss function: 11.208, Average Loss: 1.490, avg. samples / sec: 49063.07
Iteration:    100, Loss function: 10.385, Average Loss: 1.493, avg. samples / sec: 49279.65
Iteration:    100, Loss function: 9.016, Average Loss: 1.479, avg. samples / sec: 49182.10
Iteration:    100, Loss function: 9.170, Average Loss: 1.484, avg. samples / sec: 49081.76
Iteration:    100, Loss function: 8.770, Average Loss: 1.476, avg. samples / sec: 48752.47
Iteration:    100, Loss function: 10.001, Average Loss: 1.485, avg. samples / sec: 48881.56
Iteration:    100, Loss function: 9.374, Average Loss: 1.476, avg. samples / sec: 48746.25
Iteration:    100, Loss function: 9.782, Average Loss: 1.477, avg. samples / sec: 48601.42
Iteration:    100, Loss function: 10.570, Average Loss: 1.480, avg. samples / sec: 48266.07
Iteration:    120, Loss function: 8.834, Average Loss: 1.641, avg. samples / sec: 52589.35
Iteration:    120, Loss function: 8.433, Average Loss: 1.635, avg. samples / sec: 52275.63
Iteration:    120, Loss function: 9.779, Average Loss: 1.632, avg. samples / sec: 52006.59
Iteration:    120, Loss function: 9.148, Average Loss: 1.636, avg. samples / sec: 51683.92
Iteration:    120, Loss function: 10.139, Average Loss: 1.646, avg. samples / sec: 52494.93
Iteration:    120, Loss function: 9.149, Average Loss: 1.632, avg. samples / sec: 52457.86
Iteration:    120, Loss function: 8.996, Average Loss: 1.633, avg. samples / sec: 51393.62
Iteration:    120, Loss function: 8.205, Average Loss: 1.621, avg. samples / sec: 51715.18
Iteration:    120, Loss function: 9.308, Average Loss: 1.627, avg. samples / sec: 52186.39
Iteration:    120, Loss function: 9.460, Average Loss: 1.638, avg. samples / sec: 52271.23
Iteration:    120, Loss function: 9.164, Average Loss: 1.642, avg. samples / sec: 52182.91
Iteration:    120, Loss function: 9.491, Average Loss: 1.634, avg. samples / sec: 52436.70
Iteration:    120, Loss function: 8.829, Average Loss: 1.638, avg. samples / sec: 51678.05
Iteration:    120, Loss function: 9.146, Average Loss: 1.647, avg. samples / sec: 51512.03
Iteration:    120, Loss function: 10.210, Average Loss: 1.635, avg. samples / sec: 51835.01
Iteration:    120, Loss function: 9.554, Average Loss: 1.641, avg. samples / sec: 51993.80
Iteration:    120, Loss function: 9.245, Average Loss: 1.636, avg. samples / sec: 52138.06
Iteration:    120, Loss function: 8.979, Average Loss: 1.641, avg. samples / sec: 52213.63
Iteration:    120, Loss function: 9.557, Average Loss: 1.627, avg. samples / sec: 51769.19
Iteration:    120, Loss function: 9.906, Average Loss: 1.635, avg. samples / sec: 51685.53
Iteration:    120, Loss function: 9.510, Average Loss: 1.622, avg. samples / sec: 51732.39
Iteration:    120, Loss function: 9.681, Average Loss: 1.638, avg. samples / sec: 52679.52
Iteration:    120, Loss function: 8.337, Average Loss: 1.628, avg. samples / sec: 51556.56
Iteration:    120, Loss function: 9.986, Average Loss: 1.627, avg. samples / sec: 51485.23
Iteration:    120, Loss function: 9.394, Average Loss: 1.635, avg. samples / sec: 52607.19
Iteration:    120, Loss function: 8.584, Average Loss: 1.648, avg. samples / sec: 51648.25
Iteration:    120, Loss function: 9.171, Average Loss: 1.629, avg. samples / sec: 52050.47
Iteration:    120, Loss function: 9.269, Average Loss: 1.626, avg. samples / sec: 50616.22
Iteration:    120, Loss function: 9.132, Average Loss: 1.630, avg. samples / sec: 52067.25
Iteration:    120, Loss function: 9.353, Average Loss: 1.632, avg. samples / sec: 51365.90
:::MLL 1558640283.812 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558640283.813 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 9.515, Average Loss: 1.793, avg. samples / sec: 52946.63
Iteration:    140, Loss function: 9.058, Average Loss: 1.784, avg. samples / sec: 53029.35
Iteration:    140, Loss function: 9.089, Average Loss: 1.782, avg. samples / sec: 52603.05
Iteration:    140, Loss function: 9.418, Average Loss: 1.773, avg. samples / sec: 52879.16
Iteration:    140, Loss function: 9.035, Average Loss: 1.772, avg. samples / sec: 53285.45
Iteration:    140, Loss function: 8.862, Average Loss: 1.783, avg. samples / sec: 52825.24
Iteration:    140, Loss function: 9.013, Average Loss: 1.778, avg. samples / sec: 52884.16
Iteration:    140, Loss function: 8.653, Average Loss: 1.778, avg. samples / sec: 52725.54
Iteration:    140, Loss function: 9.404, Average Loss: 1.782, avg. samples / sec: 52658.89
Iteration:    140, Loss function: 8.829, Average Loss: 1.780, avg. samples / sec: 52480.73
Iteration:    140, Loss function: 8.853, Average Loss: 1.772, avg. samples / sec: 52607.76
Iteration:    140, Loss function: 9.014, Average Loss: 1.791, avg. samples / sec: 52435.37
Iteration:    140, Loss function: 8.234, Average Loss: 1.775, avg. samples / sec: 53036.97
Iteration:    140, Loss function: 9.598, Average Loss: 1.784, avg. samples / sec: 52483.74
Iteration:    140, Loss function: 10.334, Average Loss: 1.770, avg. samples / sec: 52467.31
Iteration:    140, Loss function: 9.130, Average Loss: 1.777, avg. samples / sec: 52891.62
Iteration:    140, Loss function: 9.135, Average Loss: 1.782, avg. samples / sec: 52292.68
Iteration:    140, Loss function: 9.900, Average Loss: 1.772, avg. samples / sec: 52798.71
Iteration:    140, Loss function: 9.756, Average Loss: 1.780, avg. samples / sec: 52583.20
Iteration:    140, Loss function: 9.955, Average Loss: 1.780, avg. samples / sec: 52548.15
Iteration:    140, Loss function: 8.668, Average Loss: 1.791, avg. samples / sec: 52551.48
Iteration:    140, Loss function: 8.919, Average Loss: 1.770, avg. samples / sec: 52653.85
Iteration:    140, Loss function: 9.359, Average Loss: 1.790, avg. samples / sec: 52383.57
Iteration:    140, Loss function: 9.143, Average Loss: 1.772, avg. samples / sec: 52456.90
Iteration:    140, Loss function: 8.693, Average Loss: 1.793, avg. samples / sec: 52613.14
Iteration:    140, Loss function: 9.590, Average Loss: 1.775, avg. samples / sec: 52998.63
Iteration:    140, Loss function: 9.514, Average Loss: 1.785, avg. samples / sec: 51944.64
Iteration:    140, Loss function: 9.082, Average Loss: 1.779, avg. samples / sec: 51744.17
Iteration:    140, Loss function: 9.415, Average Loss: 1.786, avg. samples / sec: 51288.43
Iteration:    140, Loss function: 9.002, Average Loss: 1.772, avg. samples / sec: 53371.80
Iteration:    160, Loss function: 8.668, Average Loss: 1.911, avg. samples / sec: 54377.78
Iteration:    160, Loss function: 7.965, Average Loss: 1.922, avg. samples / sec: 53310.71
Iteration:    160, Loss function: 8.658, Average Loss: 1.910, avg. samples / sec: 53136.48
Iteration:    160, Loss function: 8.021, Average Loss: 1.919, avg. samples / sec: 53316.52
Iteration:    160, Loss function: 8.894, Average Loss: 1.935, avg. samples / sec: 53360.75
Iteration:    160, Loss function: 9.043, Average Loss: 1.924, avg. samples / sec: 52936.76
Iteration:    160, Loss function: 8.876, Average Loss: 1.919, avg. samples / sec: 52986.30
Iteration:    160, Loss function: 7.986, Average Loss: 1.930, avg. samples / sec: 52783.79
Iteration:    160, Loss function: 8.542, Average Loss: 1.910, avg. samples / sec: 53018.61
Iteration:    160, Loss function: 8.873, Average Loss: 1.924, avg. samples / sec: 53784.13
Iteration:    160, Loss function: 8.587, Average Loss: 1.917, avg. samples / sec: 52925.31
Iteration:    160, Loss function: 9.404, Average Loss: 1.921, avg. samples / sec: 52977.08
Iteration:    160, Loss function: 8.448, Average Loss: 1.914, avg. samples / sec: 53052.42
Iteration:    160, Loss function: 8.731, Average Loss: 1.920, avg. samples / sec: 53146.07
Iteration:    160, Loss function: 8.671, Average Loss: 1.911, avg. samples / sec: 53092.40
Iteration:    160, Loss function: 7.570, Average Loss: 1.925, avg. samples / sec: 53001.17
Iteration:    160, Loss function: 7.809, Average Loss: 1.906, avg. samples / sec: 52718.77
Iteration:    160, Loss function: 8.110, Average Loss: 1.913, avg. samples / sec: 53173.14
Iteration:    160, Loss function: 8.160, Average Loss: 1.924, avg. samples / sec: 53943.78
Iteration:    160, Loss function: 8.284, Average Loss: 1.932, avg. samples / sec: 52989.97
Iteration:    160, Loss function: 8.952, Average Loss: 1.920, avg. samples / sec: 53615.44
Iteration:    160, Loss function: 8.173, Average Loss: 1.914, avg. samples / sec: 52872.57
Iteration:    160, Loss function: 8.277, Average Loss: 1.910, avg. samples / sec: 52920.08
Iteration:    160, Loss function: 8.289, Average Loss: 1.913, avg. samples / sec: 52751.81
Iteration:    160, Loss function: 8.747, Average Loss: 1.915, avg. samples / sec: 52584.36
Iteration:    160, Loss function: 8.153, Average Loss: 1.911, avg. samples / sec: 53172.90
Iteration:    160, Loss function: 8.473, Average Loss: 1.934, avg. samples / sec: 52883.80
Iteration:    160, Loss function: 8.682, Average Loss: 1.920, avg. samples / sec: 52029.73
Iteration:    160, Loss function: 7.668, Average Loss: 1.917, avg. samples / sec: 51903.30
Iteration:    160, Loss function: 7.874, Average Loss: 1.920, avg. samples / sec: 51850.94
Iteration:    180, Loss function: 7.922, Average Loss: 2.041, avg. samples / sec: 53172.78
Iteration:    180, Loss function: 9.010, Average Loss: 2.056, avg. samples / sec: 52924.69
Iteration:    180, Loss function: 9.948, Average Loss: 2.057, avg. samples / sec: 52634.68
Iteration:    180, Loss function: 7.976, Average Loss: 2.048, avg. samples / sec: 52601.03
Iteration:    180, Loss function: 8.209, Average Loss: 2.039, avg. samples / sec: 52435.08
Iteration:    180, Loss function: 9.033, Average Loss: 2.057, avg. samples / sec: 52694.76
Iteration:    180, Loss function: 9.296, Average Loss: 2.044, avg. samples / sec: 53154.03
Iteration:    180, Loss function: 8.305, Average Loss: 2.050, avg. samples / sec: 52382.85
Iteration:    180, Loss function: 8.728, Average Loss: 2.048, avg. samples / sec: 53753.07
Iteration:    180, Loss function: 7.967, Average Loss: 2.040, avg. samples / sec: 52625.99
Iteration:    180, Loss function: 9.886, Average Loss: 2.062, avg. samples / sec: 52569.06
Iteration:    180, Loss function: 7.401, Average Loss: 2.048, avg. samples / sec: 52820.33
Iteration:    180, Loss function: 8.578, Average Loss: 2.044, avg. samples / sec: 52769.09
Iteration:    180, Loss function: 8.307, Average Loss: 2.048, avg. samples / sec: 52536.88
Iteration:    180, Loss function: 7.791, Average Loss: 2.038, avg. samples / sec: 52487.46
Iteration:    180, Loss function: 9.373, Average Loss: 2.067, avg. samples / sec: 53090.38
Iteration:    180, Loss function: 8.134, Average Loss: 2.051, avg. samples / sec: 52482.57
Iteration:    180, Loss function: 8.471, Average Loss: 2.050, avg. samples / sec: 52438.91
Iteration:    180, Loss function: 9.287, Average Loss: 2.040, avg. samples / sec: 52987.24
Iteration:    180, Loss function: 9.920, Average Loss: 2.070, avg. samples / sec: 52330.58
Iteration:    180, Loss function: 8.187, Average Loss: 2.047, avg. samples / sec: 52670.89
Iteration:    180, Loss function: 8.970, Average Loss: 2.033, avg. samples / sec: 52501.44
Iteration:    180, Loss function: 8.680, Average Loss: 2.045, avg. samples / sec: 53370.89
Iteration:    180, Loss function: 8.525, Average Loss: 2.061, avg. samples / sec: 52192.73
Iteration:    180, Loss function: 8.443, Average Loss: 2.055, avg. samples / sec: 51915.44
Iteration:    180, Loss function: 8.282, Average Loss: 2.050, avg. samples / sec: 52704.72
Iteration:    180, Loss function: 9.805, Average Loss: 2.041, avg. samples / sec: 51583.35
Iteration:    180, Loss function: 8.303, Average Loss: 2.040, avg. samples / sec: 51866.13
Iteration:    180, Loss function: 8.786, Average Loss: 2.049, avg. samples / sec: 51642.12
Iteration:    180, Loss function: 8.179, Average Loss: 2.041, avg. samples / sec: 52042.97
Iteration:    200, Loss function: 8.962, Average Loss: 2.165, avg. samples / sec: 52729.38
Iteration:    200, Loss function: 8.618, Average Loss: 2.180, avg. samples / sec: 52628.31
Iteration:    200, Loss function: 8.797, Average Loss: 2.188, avg. samples / sec: 52665.54
Iteration:    200, Loss function: 8.241, Average Loss: 2.170, avg. samples / sec: 52793.90
Iteration:    200, Loss function: 9.265, Average Loss: 2.175, avg. samples / sec: 53432.27
Iteration:    200, Loss function: 8.610, Average Loss: 2.175, avg. samples / sec: 52582.44
Iteration:    200, Loss function: 9.681, Average Loss: 2.165, avg. samples / sec: 52577.04
Iteration:    200, Loss function: 8.303, Average Loss: 2.171, avg. samples / sec: 52584.15
Iteration:    200, Loss function: 8.325, Average Loss: 2.169, avg. samples / sec: 52615.99
Iteration:    200, Loss function: 7.902, Average Loss: 2.168, avg. samples / sec: 52558.10
Iteration:    200, Loss function: 7.733, Average Loss: 2.160, avg. samples / sec: 52812.61
Iteration:    200, Loss function: 9.013, Average Loss: 2.161, avg. samples / sec: 53364.81
Iteration:    200, Loss function: 7.498, Average Loss: 2.191, avg. samples / sec: 52640.07
Iteration:    200, Loss function: 7.575, Average Loss: 2.166, avg. samples / sec: 52528.25
Iteration:    200, Loss function: 9.103, Average Loss: 2.185, avg. samples / sec: 53244.66
Iteration:    200, Loss function: 8.474, Average Loss: 2.179, avg. samples / sec: 52297.03
Iteration:    200, Loss function: 8.907, Average Loss: 2.160, avg. samples / sec: 52544.17
Iteration:    200, Loss function: 8.246, Average Loss: 2.190, avg. samples / sec: 52963.84
Iteration:    200, Loss function: 8.519, Average Loss: 2.171, avg. samples / sec: 52624.63
Iteration:    200, Loss function: 7.621, Average Loss: 2.172, avg. samples / sec: 53041.96
Iteration:    200, Loss function: 7.885, Average Loss: 2.163, avg. samples / sec: 52176.27
Iteration:    200, Loss function: 8.279, Average Loss: 2.195, avg. samples / sec: 52491.35
Iteration:    200, Loss function: 8.562, Average Loss: 2.174, avg. samples / sec: 52481.75
Iteration:    200, Loss function: 8.240, Average Loss: 2.167, avg. samples / sec: 53066.43
Iteration:    200, Loss function: 7.717, Average Loss: 2.168, avg. samples / sec: 52084.98
Iteration:    200, Loss function: 9.587, Average Loss: 2.181, avg. samples / sec: 52055.39
Iteration:    200, Loss function: 8.448, Average Loss: 2.174, avg. samples / sec: 52227.78
Iteration:    200, Loss function: 7.140, Average Loss: 2.168, avg. samples / sec: 52804.20
Iteration:    200, Loss function: 9.366, Average Loss: 2.163, avg. samples / sec: 52034.99
Iteration:    200, Loss function: 8.057, Average Loss: 2.167, avg. samples / sec: 51740.96
:::MLL 1558640286.045 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558640286.046 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 8.768, Average Loss: 2.290, avg. samples / sec: 52995.58
Iteration:    220, Loss function: 8.005, Average Loss: 2.286, avg. samples / sec: 53217.36
Iteration:    220, Loss function: 8.360, Average Loss: 2.288, avg. samples / sec: 53168.83
Iteration:    220, Loss function: 8.547, Average Loss: 2.291, avg. samples / sec: 52968.18
Iteration:    220, Loss function: 7.943, Average Loss: 2.290, avg. samples / sec: 53611.46
Iteration:    220, Loss function: 7.834, Average Loss: 2.287, avg. samples / sec: 52989.93
Iteration:    220, Loss function: 8.599, Average Loss: 2.289, avg. samples / sec: 53797.02
Iteration:    220, Loss function: 7.647, Average Loss: 2.305, avg. samples / sec: 53010.99
Iteration:    220, Loss function: 8.687, Average Loss: 2.285, avg. samples / sec: 53610.46
Iteration:    220, Loss function: 9.027, Average Loss: 2.302, avg. samples / sec: 52777.98
Iteration:    220, Loss function: 7.545, Average Loss: 2.303, avg. samples / sec: 53062.67
Iteration:    220, Loss function: 8.701, Average Loss: 2.292, avg. samples / sec: 53415.56
Iteration:    220, Loss function: 8.385, Average Loss: 2.297, avg. samples / sec: 52874.06
Iteration:    220, Loss function: 8.261, Average Loss: 2.280, avg. samples / sec: 52851.36
Iteration:    220, Loss function: 8.074, Average Loss: 2.312, avg. samples / sec: 52851.20
Iteration:    220, Loss function: 8.290, Average Loss: 2.307, avg. samples / sec: 53012.23
Iteration:    220, Loss function: 8.257, Average Loss: 2.293, avg. samples / sec: 52721.67
Iteration:    220, Loss function: 8.466, Average Loss: 2.286, avg. samples / sec: 53134.71
Iteration:    220, Loss function: 8.280, Average Loss: 2.279, avg. samples / sec: 52780.79
Iteration:    220, Loss function: 8.752, Average Loss: 2.306, avg. samples / sec: 52664.18
Iteration:    220, Loss function: 8.632, Average Loss: 2.285, avg. samples / sec: 53001.19
Iteration:    220, Loss function: 7.753, Average Loss: 2.287, avg. samples / sec: 52699.02
Iteration:    220, Loss function: 9.076, Average Loss: 2.291, avg. samples / sec: 52864.94
Iteration:    220, Loss function: 7.388, Average Loss: 2.290, avg. samples / sec: 52812.40
Iteration:    220, Loss function: 7.500, Average Loss: 2.302, avg. samples / sec: 52990.56
Iteration:    220, Loss function: 8.406, Average Loss: 2.280, avg. samples / sec: 52600.26
Iteration:    220, Loss function: 9.043, Average Loss: 2.283, avg. samples / sec: 52318.52
Iteration:    220, Loss function: 9.060, Average Loss: 2.292, avg. samples / sec: 52477.67
Iteration:    220, Loss function: 9.223, Average Loss: 2.319, avg. samples / sec: 52374.83
Iteration:    220, Loss function: 7.808, Average Loss: 2.285, avg. samples / sec: 52242.84
Iteration:    240, Loss function: 7.332, Average Loss: 2.411, avg. samples / sec: 53031.22
Iteration:    240, Loss function: 7.743, Average Loss: 2.399, avg. samples / sec: 52919.72
Iteration:    240, Loss function: 8.235, Average Loss: 2.414, avg. samples / sec: 52967.62
Iteration:    240, Loss function: 8.593, Average Loss: 2.399, avg. samples / sec: 54162.75
Iteration:    240, Loss function: 8.187, Average Loss: 2.404, avg. samples / sec: 52656.19
Iteration:    240, Loss function: 7.182, Average Loss: 2.396, avg. samples / sec: 52613.42
Iteration:    240, Loss function: 8.565, Average Loss: 2.398, avg. samples / sec: 52992.72
Iteration:    240, Loss function: 7.832, Average Loss: 2.400, avg. samples / sec: 53581.07
Iteration:    240, Loss function: 7.414, Average Loss: 2.405, avg. samples / sec: 53023.38
Iteration:    240, Loss function: 8.144, Average Loss: 2.421, avg. samples / sec: 52956.49
Iteration:    240, Loss function: 9.130, Average Loss: 2.397, avg. samples / sec: 53479.89
Iteration:    240, Loss function: 7.781, Average Loss: 2.413, avg. samples / sec: 53250.40
Iteration:    240, Loss function: 7.569, Average Loss: 2.400, avg. samples / sec: 52733.17
Iteration:    240, Loss function: 6.919, Average Loss: 2.424, avg. samples / sec: 53645.93
Iteration:    240, Loss function: 7.499, Average Loss: 2.400, avg. samples / sec: 52708.13
Iteration:    240, Loss function: 8.321, Average Loss: 2.396, avg. samples / sec: 52750.54
Iteration:    240, Loss function: 8.232, Average Loss: 2.419, avg. samples / sec: 52947.24
Iteration:    240, Loss function: 7.151, Average Loss: 2.416, avg. samples / sec: 52757.30
Iteration:    240, Loss function: 7.330, Average Loss: 2.417, avg. samples / sec: 52713.31
Iteration:    240, Loss function: 8.572, Average Loss: 2.402, avg. samples / sec: 52943.08
Iteration:    240, Loss function: 8.070, Average Loss: 2.399, avg. samples / sec: 53068.86
Iteration:    240, Loss function: 8.493, Average Loss: 2.400, avg. samples / sec: 52551.75
Iteration:    240, Loss function: 8.208, Average Loss: 2.393, avg. samples / sec: 52793.68
Iteration:    240, Loss function: 7.569, Average Loss: 2.392, avg. samples / sec: 53153.25
Iteration:    240, Loss function: 7.636, Average Loss: 2.405, avg. samples / sec: 52632.42
Iteration:    240, Loss function: 8.222, Average Loss: 2.391, avg. samples / sec: 52781.05
Iteration:    240, Loss function: 7.922, Average Loss: 2.420, avg. samples / sec: 52740.42
Iteration:    240, Loss function: 8.123, Average Loss: 2.400, avg. samples / sec: 52887.97
Iteration:    240, Loss function: 8.612, Average Loss: 2.401, avg. samples / sec: 52210.79
Iteration:    240, Loss function: 7.680, Average Loss: 2.399, avg. samples / sec: 52082.46
Iteration:    260, Loss function: 7.997, Average Loss: 2.511, avg. samples / sec: 53784.05
Iteration:    260, Loss function: 7.595, Average Loss: 2.501, avg. samples / sec: 53830.45
Iteration:    260, Loss function: 7.718, Average Loss: 2.502, avg. samples / sec: 53426.69
Iteration:    260, Loss function: 7.854, Average Loss: 2.505, avg. samples / sec: 53516.43
Iteration:    260, Loss function: 8.078, Average Loss: 2.522, avg. samples / sec: 53341.22
Iteration:    260, Loss function: 8.111, Average Loss: 2.513, avg. samples / sec: 53376.49
Iteration:    260, Loss function: 7.635, Average Loss: 2.507, avg. samples / sec: 53305.93
Iteration:    260, Loss function: 8.236, Average Loss: 2.527, avg. samples / sec: 53397.36
Iteration:    260, Loss function: 7.737, Average Loss: 2.511, avg. samples / sec: 53425.88
Iteration:    260, Loss function: 7.927, Average Loss: 2.515, avg. samples / sec: 53227.89
Iteration:    260, Loss function: 7.861, Average Loss: 2.506, avg. samples / sec: 53404.10
Iteration:    260, Loss function: 8.019, Average Loss: 2.516, avg. samples / sec: 53351.21
Iteration:    260, Loss function: 7.242, Average Loss: 2.512, avg. samples / sec: 53577.12
Iteration:    260, Loss function: 7.587, Average Loss: 2.519, avg. samples / sec: 53361.88
Iteration:    260, Loss function: 7.342, Average Loss: 2.522, avg. samples / sec: 53407.44
Iteration:    260, Loss function: 7.127, Average Loss: 2.522, avg. samples / sec: 53401.39
Iteration:    260, Loss function: 7.327, Average Loss: 2.509, avg. samples / sec: 53258.43
Iteration:    260, Loss function: 7.353, Average Loss: 2.504, avg. samples / sec: 53694.95
Iteration:    260, Loss function: 8.417, Average Loss: 2.511, avg. samples / sec: 53374.11
Iteration:    260, Loss function: 7.801, Average Loss: 2.525, avg. samples / sec: 53271.51
Iteration:    260, Loss function: 7.192, Average Loss: 2.500, avg. samples / sec: 53390.89
Iteration:    260, Loss function: 7.265, Average Loss: 2.525, avg. samples / sec: 53386.84
Iteration:    260, Loss function: 7.148, Average Loss: 2.504, avg. samples / sec: 53252.31
Iteration:    260, Loss function: 6.993, Average Loss: 2.509, avg. samples / sec: 53070.12
Iteration:    260, Loss function: 8.517, Average Loss: 2.502, avg. samples / sec: 53296.35
Iteration:    260, Loss function: 7.906, Average Loss: 2.507, avg. samples / sec: 53968.18
Iteration:    260, Loss function: 7.308, Average Loss: 2.503, avg. samples / sec: 53209.76
Iteration:    260, Loss function: 7.067, Average Loss: 2.506, avg. samples / sec: 52740.69
Iteration:    260, Loss function: 6.696, Average Loss: 2.499, avg. samples / sec: 52130.77
Iteration:    260, Loss function: 7.884, Average Loss: 2.534, avg. samples / sec: 52048.81
:::MLL 1558640288.273 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558640288.274 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 6.937, Average Loss: 2.607, avg. samples / sec: 52040.47
Iteration:    280, Loss function: 7.437, Average Loss: 2.610, avg. samples / sec: 51850.36
Iteration:    280, Loss function: 7.477, Average Loss: 2.630, avg. samples / sec: 51906.57
Iteration:    280, Loss function: 8.085, Average Loss: 2.614, avg. samples / sec: 51803.72
Iteration:    280, Loss function: 7.491, Average Loss: 2.609, avg. samples / sec: 52002.41
Iteration:    280, Loss function: 7.221, Average Loss: 2.599, avg. samples / sec: 51924.05
Iteration:    280, Loss function: 6.537, Average Loss: 2.602, avg. samples / sec: 51693.99
Iteration:    280, Loss function: 8.367, Average Loss: 2.622, avg. samples / sec: 51922.42
Iteration:    280, Loss function: 7.446, Average Loss: 2.612, avg. samples / sec: 51724.52
Iteration:    280, Loss function: 7.868, Average Loss: 2.615, avg. samples / sec: 51684.24
Iteration:    280, Loss function: 7.108, Average Loss: 2.601, avg. samples / sec: 52128.21
Iteration:    280, Loss function: 7.580, Average Loss: 2.608, avg. samples / sec: 51542.23
Iteration:    280, Loss function: 7.159, Average Loss: 2.623, avg. samples / sec: 51664.20
Iteration:    280, Loss function: 7.517, Average Loss: 2.596, avg. samples / sec: 51636.29
Iteration:    280, Loss function: 9.189, Average Loss: 2.610, avg. samples / sec: 51598.07
Iteration:    280, Loss function: 7.583, Average Loss: 2.610, avg. samples / sec: 51479.00
Iteration:    280, Loss function: 7.435, Average Loss: 2.615, avg. samples / sec: 51254.93
Iteration:    280, Loss function: 9.390, Average Loss: 2.601, avg. samples / sec: 50979.21
Iteration:    280, Loss function: 7.201, Average Loss: 2.612, avg. samples / sec: 51114.97
Iteration:    280, Loss function: 7.116, Average Loss: 2.607, avg. samples / sec: 51642.71
Iteration:    280, Loss function: 6.750, Average Loss: 2.600, avg. samples / sec: 51303.24
Iteration:    280, Loss function: 7.799, Average Loss: 2.618, avg. samples / sec: 51106.98
Iteration:    280, Loss function: 7.117, Average Loss: 2.601, avg. samples / sec: 50886.18
Iteration:    280, Loss function: 7.847, Average Loss: 2.615, avg. samples / sec: 50817.02
Iteration:    280, Loss function: 7.897, Average Loss: 2.617, avg. samples / sec: 50811.07
Iteration:    280, Loss function: 7.424, Average Loss: 2.609, avg. samples / sec: 50536.45
Iteration:    280, Loss function: 7.390, Average Loss: 2.615, avg. samples / sec: 50629.64
Iteration:    280, Loss function: 7.763, Average Loss: 2.635, avg. samples / sec: 52017.54
Iteration:    280, Loss function: 7.188, Average Loss: 2.602, avg. samples / sec: 51818.64
Iteration:    280, Loss function: 8.493, Average Loss: 2.600, avg. samples / sec: 50774.69
Iteration:    300, Loss function: 6.302, Average Loss: 2.698, avg. samples / sec: 54052.49
Iteration:    300, Loss function: 7.831, Average Loss: 2.716, avg. samples / sec: 53834.81
Iteration:    300, Loss function: 8.041, Average Loss: 2.708, avg. samples / sec: 53780.17
Iteration:    300, Loss function: 7.905, Average Loss: 2.714, avg. samples / sec: 52534.55
Iteration:    300, Loss function: 7.761, Average Loss: 2.717, avg. samples / sec: 52737.14
Iteration:    300, Loss function: 7.321, Average Loss: 2.706, avg. samples / sec: 52438.69
Iteration:    300, Loss function: 8.284, Average Loss: 2.712, avg. samples / sec: 53590.53
Iteration:    300, Loss function: 7.153, Average Loss: 2.699, avg. samples / sec: 52519.38
Iteration:    300, Loss function: 8.421, Average Loss: 2.699, avg. samples / sec: 53219.73
Iteration:    300, Loss function: 8.301, Average Loss: 2.731, avg. samples / sec: 52413.67
Iteration:    300, Loss function: 8.600, Average Loss: 2.712, avg. samples / sec: 52602.83
Iteration:    300, Loss function: 7.775, Average Loss: 2.702, avg. samples / sec: 52526.00
Iteration:    300, Loss function: 7.068, Average Loss: 2.708, avg. samples / sec: 53121.75
Iteration:    300, Loss function: 7.870, Average Loss: 2.708, avg. samples / sec: 53119.13
Iteration:    300, Loss function: 7.026, Average Loss: 2.709, avg. samples / sec: 53230.55
Iteration:    300, Loss function: 7.292, Average Loss: 2.704, avg. samples / sec: 52390.75
Iteration:    300, Loss function: 7.823, Average Loss: 2.701, avg. samples / sec: 53210.13
Iteration:    300, Loss function: 7.900, Average Loss: 2.716, avg. samples / sec: 53188.62
Iteration:    300, Loss function: 7.145, Average Loss: 2.720, avg. samples / sec: 52385.36
Iteration:    300, Loss function: 8.459, Average Loss: 2.703, avg. samples / sec: 53636.87
Iteration:    300, Loss function: 9.389, Average Loss: 2.719, avg. samples / sec: 53429.89
Iteration:    300, Loss function: 7.180, Average Loss: 2.708, avg. samples / sec: 52647.18
Iteration:    300, Loss function: 8.340, Average Loss: 2.711, avg. samples / sec: 52876.30
Iteration:    300, Loss function: 8.218, Average Loss: 2.696, avg. samples / sec: 52763.36
Iteration:    300, Loss function: 7.200, Average Loss: 2.701, avg. samples / sec: 53055.20
Iteration:    300, Loss function: 8.520, Average Loss: 2.733, avg. samples / sec: 53416.31
Iteration:    300, Loss function: 8.258, Average Loss: 2.720, avg. samples / sec: 52512.30
Iteration:    300, Loss function: 7.345, Average Loss: 2.701, avg. samples / sec: 52307.16
Iteration:    300, Loss function: 7.963, Average Loss: 2.698, avg. samples / sec: 51594.70
Iteration:    300, Loss function: 7.412, Average Loss: 2.705, avg. samples / sec: 51115.11
Iteration:    320, Loss function: 7.340, Average Loss: 2.813, avg. samples / sec: 53588.81
Iteration:    320, Loss function: 7.876, Average Loss: 2.831, avg. samples / sec: 53476.73
Iteration:    320, Loss function: 7.492, Average Loss: 2.804, avg. samples / sec: 54493.43
Iteration:    320, Loss function: 7.639, Average Loss: 2.813, avg. samples / sec: 53230.34
Iteration:    320, Loss function: 7.339, Average Loss: 2.818, avg. samples / sec: 53584.64
Iteration:    320, Loss function: 7.465, Average Loss: 2.803, avg. samples / sec: 53307.54
Iteration:    320, Loss function: 8.596, Average Loss: 2.816, avg. samples / sec: 53259.19
Iteration:    320, Loss function: 8.124, Average Loss: 2.795, avg. samples / sec: 53122.92
Iteration:    320, Loss function: 6.955, Average Loss: 2.813, avg. samples / sec: 53295.97
Iteration:    320, Loss function: 7.553, Average Loss: 2.807, avg. samples / sec: 53197.29
Iteration:    320, Loss function: 7.346, Average Loss: 2.832, avg. samples / sec: 53584.43
Iteration:    320, Loss function: 7.882, Average Loss: 2.807, avg. samples / sec: 54584.40
Iteration:    320, Loss function: 7.488, Average Loss: 2.806, avg. samples / sec: 53267.45
Iteration:    320, Loss function: 7.030, Average Loss: 2.804, avg. samples / sec: 53278.94
Iteration:    320, Loss function: 6.397, Average Loss: 2.809, avg. samples / sec: 53295.12
Iteration:    320, Loss function: 6.959, Average Loss: 2.811, avg. samples / sec: 53491.42
Iteration:    320, Loss function: 6.851, Average Loss: 2.804, avg. samples / sec: 53301.94
Iteration:    320, Loss function: 6.906, Average Loss: 2.799, avg. samples / sec: 53220.55
Iteration:    320, Loss function: 6.815, Average Loss: 2.818, avg. samples / sec: 53320.07
Iteration:    320, Loss function: 8.921, Average Loss: 2.799, avg. samples / sec: 53380.80
Iteration:    320, Loss function: 9.089, Average Loss: 2.818, avg. samples / sec: 53017.97
Iteration:    320, Loss function: 7.585, Average Loss: 2.806, avg. samples / sec: 53172.12
Iteration:    320, Loss function: 7.712, Average Loss: 2.796, avg. samples / sec: 53322.02
Iteration:    320, Loss function: 6.564, Average Loss: 2.812, avg. samples / sec: 53306.63
Iteration:    320, Loss function: 7.503, Average Loss: 2.819, avg. samples / sec: 53249.33
Iteration:    320, Loss function: 8.145, Average Loss: 2.797, avg. samples / sec: 53029.19
Iteration:    320, Loss function: 7.470, Average Loss: 2.806, avg. samples / sec: 53094.54
Iteration:    320, Loss function: 7.254, Average Loss: 2.823, avg. samples / sec: 53298.35
Iteration:    320, Loss function: 6.002, Average Loss: 2.798, avg. samples / sec: 53083.36
Iteration:    320, Loss function: 7.277, Average Loss: 2.798, avg. samples / sec: 53372.63
Iteration:    340, Loss function: 6.729, Average Loss: 2.905, avg. samples / sec: 53607.41
Iteration:    340, Loss function: 6.637, Average Loss: 2.904, avg. samples / sec: 53754.85
Iteration:    340, Loss function: 7.655, Average Loss: 2.888, avg. samples / sec: 53483.08
Iteration:    340, Loss function: 7.272, Average Loss: 2.904, avg. samples / sec: 53506.37
Iteration:    340, Loss function: 7.379, Average Loss: 2.895, avg. samples / sec: 53497.11
Iteration:    340, Loss function: 6.387, Average Loss: 2.900, avg. samples / sec: 53220.70
Iteration:    340, Loss function: 6.566, Average Loss: 2.898, avg. samples / sec: 53384.15
Iteration:    340, Loss function: 7.270, Average Loss: 2.915, avg. samples / sec: 53239.78
Iteration:    340, Loss function: 6.670, Average Loss: 2.887, avg. samples / sec: 53483.65
Iteration:    340, Loss function: 5.462, Average Loss: 2.896, avg. samples / sec: 53460.60
Iteration:    340, Loss function: 7.662, Average Loss: 2.894, avg. samples / sec: 53478.25
Iteration:    340, Loss function: 6.951, Average Loss: 2.889, avg. samples / sec: 53420.46
Iteration:    340, Loss function: 6.793, Average Loss: 2.891, avg. samples / sec: 53575.33
Iteration:    340, Loss function: 7.166, Average Loss: 2.897, avg. samples / sec: 53405.23
Iteration:    340, Loss function: 6.600, Average Loss: 2.902, avg. samples / sec: 53470.34
Iteration:    340, Loss function: 6.721, Average Loss: 2.887, avg. samples / sec: 53342.23
Iteration:    340, Loss function: 7.267, Average Loss: 2.900, avg. samples / sec: 53556.43
Iteration:    340, Loss function: 7.680, Average Loss: 2.893, avg. samples / sec: 53563.27
Iteration:    340, Loss function: 6.958, Average Loss: 2.896, avg. samples / sec: 53499.81
Iteration:    340, Loss function: 7.951, Average Loss: 2.886, avg. samples / sec: 53228.90
Iteration:    340, Loss function: 7.563, Average Loss: 2.882, avg. samples / sec: 53464.76
Iteration:    340, Loss function: 7.267, Average Loss: 2.885, avg. samples / sec: 53348.20
Iteration:    340, Loss function: 7.329, Average Loss: 2.912, avg. samples / sec: 53615.03
Iteration:    340, Loss function: 7.477, Average Loss: 2.920, avg. samples / sec: 53188.42
Iteration:    340, Loss function: 8.176, Average Loss: 2.888, avg. samples / sec: 53436.44
Iteration:    340, Loss function: 8.051, Average Loss: 2.890, avg. samples / sec: 53652.08
Iteration:    340, Loss function: 7.304, Average Loss: 2.885, avg. samples / sec: 54238.09
Iteration:    340, Loss function: 7.921, Average Loss: 2.891, avg. samples / sec: 53020.87
Iteration:    340, Loss function: 6.887, Average Loss: 2.900, avg. samples / sec: 53047.97
Iteration:    340, Loss function: 7.113, Average Loss: 2.892, avg. samples / sec: 52985.92
:::MLL 1558640290.489 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558640290.490 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 7.816, Average Loss: 2.989, avg. samples / sec: 53110.40
Iteration:    360, Loss function: 6.254, Average Loss: 2.983, avg. samples / sec: 53039.03
Iteration:    360, Loss function: 7.335, Average Loss: 2.979, avg. samples / sec: 53122.60
Iteration:    360, Loss function: 7.059, Average Loss: 2.976, avg. samples / sec: 53045.99
Iteration:    360, Loss function: 6.350, Average Loss: 2.972, avg. samples / sec: 53113.57
Iteration:    360, Loss function: 6.966, Average Loss: 2.977, avg. samples / sec: 53498.19
Iteration:    360, Loss function: 7.598, Average Loss: 2.998, avg. samples / sec: 53056.66
Iteration:    360, Loss function: 7.217, Average Loss: 2.968, avg. samples / sec: 53057.84
Iteration:    360, Loss function: 7.803, Average Loss: 2.969, avg. samples / sec: 53273.10
Iteration:    360, Loss function: 7.345, Average Loss: 2.964, avg. samples / sec: 53147.50
Iteration:    360, Loss function: 6.720, Average Loss: 2.978, avg. samples / sec: 53044.32
Iteration:    360, Loss function: 6.556, Average Loss: 2.983, avg. samples / sec: 53399.26
Iteration:    360, Loss function: 5.797, Average Loss: 2.970, avg. samples / sec: 52933.24
Iteration:    360, Loss function: 5.596, Average Loss: 2.985, avg. samples / sec: 53092.34
Iteration:    360, Loss function: 6.577, Average Loss: 2.967, avg. samples / sec: 53196.19
Iteration:    360, Loss function: 5.289, Average Loss: 2.974, avg. samples / sec: 53004.35
Iteration:    360, Loss function: 7.526, Average Loss: 2.980, avg. samples / sec: 53139.54
Iteration:    360, Loss function: 8.053, Average Loss: 2.987, avg. samples / sec: 53028.33
Iteration:    360, Loss function: 7.807, Average Loss: 2.984, avg. samples / sec: 53000.05
Iteration:    360, Loss function: 7.482, Average Loss: 2.986, avg. samples / sec: 52611.43
Iteration:    360, Loss function: 7.140, Average Loss: 2.995, avg. samples / sec: 53066.25
Iteration:    360, Loss function: 7.862, Average Loss: 2.974, avg. samples / sec: 53051.92
Iteration:    360, Loss function: 7.198, Average Loss: 3.006, avg. samples / sec: 53034.65
Iteration:    360, Loss function: 8.003, Average Loss: 2.978, avg. samples / sec: 52958.66
Iteration:    360, Loss function: 7.133, Average Loss: 2.963, avg. samples / sec: 53037.73
Iteration:    360, Loss function: 6.830, Average Loss: 2.970, avg. samples / sec: 53017.87
Iteration:    360, Loss function: 6.850, Average Loss: 2.971, avg. samples / sec: 53020.03
Iteration:    360, Loss function: 7.017, Average Loss: 2.975, avg. samples / sec: 52635.15
Iteration:    360, Loss function: 8.119, Average Loss: 2.984, avg. samples / sec: 52334.39
Iteration:    360, Loss function: 6.968, Average Loss: 2.970, avg. samples / sec: 52509.40
Iteration:    380, Loss function: 6.441, Average Loss: 3.061, avg. samples / sec: 53186.35
Iteration:    380, Loss function: 7.746, Average Loss: 3.062, avg. samples / sec: 53269.40
Iteration:    380, Loss function: 6.969, Average Loss: 3.048, avg. samples / sec: 53292.00
Iteration:    380, Loss function: 7.484, Average Loss: 3.066, avg. samples / sec: 53957.87
Iteration:    380, Loss function: 6.411, Average Loss: 3.067, avg. samples / sec: 53279.00
Iteration:    380, Loss function: 6.350, Average Loss: 3.069, avg. samples / sec: 53086.04
Iteration:    380, Loss function: 5.166, Average Loss: 3.056, avg. samples / sec: 53154.65
Iteration:    380, Loss function: 6.582, Average Loss: 3.062, avg. samples / sec: 53096.46
Iteration:    380, Loss function: 6.843, Average Loss: 3.059, avg. samples / sec: 53168.65
Iteration:    380, Loss function: 6.838, Average Loss: 3.080, avg. samples / sec: 53175.19
Iteration:    380, Loss function: 6.685, Average Loss: 3.063, avg. samples / sec: 53190.54
Iteration:    380, Loss function: 7.141, Average Loss: 3.066, avg. samples / sec: 53167.31
Iteration:    380, Loss function: 7.749, Average Loss: 3.046, avg. samples / sec: 53156.46
Iteration:    380, Loss function: 6.861, Average Loss: 3.054, avg. samples / sec: 53142.37
Iteration:    380, Loss function: 7.467, Average Loss: 3.067, avg. samples / sec: 53211.71
Iteration:    380, Loss function: 7.608, Average Loss: 3.056, avg. samples / sec: 53395.89
Iteration:    380, Loss function: 7.272, Average Loss: 3.064, avg. samples / sec: 53172.40
Iteration:    380, Loss function: 7.172, Average Loss: 3.057, avg. samples / sec: 53148.02
Iteration:    380, Loss function: 7.285, Average Loss: 3.053, avg. samples / sec: 53023.44
Iteration:    380, Loss function: 6.268, Average Loss: 3.065, avg. samples / sec: 53191.91
Iteration:    380, Loss function: 6.965, Average Loss: 3.055, avg. samples / sec: 53231.93
Iteration:    380, Loss function: 6.513, Average Loss: 3.066, avg. samples / sec: 53167.05
Iteration:    380, Loss function: 6.539, Average Loss: 3.079, avg. samples / sec: 53162.07
Iteration:    380, Loss function: 7.654, Average Loss: 3.054, avg. samples / sec: 53676.05
Iteration:    380, Loss function: 6.377, Average Loss: 3.059, avg. samples / sec: 53175.95
Iteration:    380, Loss function: 7.462, Average Loss: 3.054, avg. samples / sec: 52921.02
Iteration:    380, Loss function: 6.639, Average Loss: 3.087, avg. samples / sec: 53168.79
Iteration:    380, Loss function: 6.640, Average Loss: 3.053, avg. samples / sec: 53370.81
Iteration:    380, Loss function: 7.305, Average Loss: 3.045, avg. samples / sec: 53172.88
Iteration:    380, Loss function: 7.655, Average Loss: 3.044, avg. samples / sec: 53145.71
Iteration:    400, Loss function: 6.444, Average Loss: 3.140, avg. samples / sec: 52853.56
Iteration:    400, Loss function: 7.535, Average Loss: 3.132, avg. samples / sec: 52951.16
Iteration:    400, Loss function: 7.327, Average Loss: 3.140, avg. samples / sec: 52845.69
Iteration:    400, Loss function: 7.336, Average Loss: 3.140, avg. samples / sec: 52719.46
Iteration:    400, Loss function: 6.273, Average Loss: 3.163, avg. samples / sec: 53055.16
Iteration:    400, Loss function: 7.085, Average Loss: 3.150, avg. samples / sec: 52784.15
Iteration:    400, Loss function: 7.460, Average Loss: 3.124, avg. samples / sec: 53049.13
Iteration:    400, Loss function: 7.205, Average Loss: 3.138, avg. samples / sec: 52684.11
Iteration:    400, Loss function: 7.889, Average Loss: 3.140, avg. samples / sec: 52773.30
Iteration:    400, Loss function: 6.824, Average Loss: 3.126, avg. samples / sec: 53010.64
Iteration:    400, Loss function: 6.177, Average Loss: 3.119, avg. samples / sec: 52764.37
Iteration:    400, Loss function: 7.038, Average Loss: 3.139, avg. samples / sec: 52638.20
Iteration:    400, Loss function: 7.022, Average Loss: 3.130, avg. samples / sec: 52670.58
Iteration:    400, Loss function: 7.738, Average Loss: 3.127, avg. samples / sec: 52856.98
Iteration:    400, Loss function: 6.788, Average Loss: 3.132, avg. samples / sec: 52724.93
Iteration:    400, Loss function: 7.316, Average Loss: 3.125, avg. samples / sec: 52584.73
Iteration:    400, Loss function: 6.865, Average Loss: 3.131, avg. samples / sec: 52864.42
Iteration:    400, Loss function: 5.693, Average Loss: 3.142, avg. samples / sec: 52714.32
Iteration:    400, Loss function: 6.575, Average Loss: 3.130, avg. samples / sec: 52740.32
Iteration:    400, Loss function: 6.626, Average Loss: 3.126, avg. samples / sec: 52910.21
Iteration:    400, Loss function: 7.536, Average Loss: 3.135, avg. samples / sec: 52589.68
Iteration:    400, Loss function: 6.629, Average Loss: 3.125, avg. samples / sec: 52848.32
Iteration:    400, Loss function: 5.917, Average Loss: 3.138, avg. samples / sec: 52768.95
Iteration:    400, Loss function: 6.879, Average Loss: 3.145, avg. samples / sec: 52581.93
Iteration:    400, Loss function: 7.068, Average Loss: 3.135, avg. samples / sec: 52757.10
Iteration:    400, Loss function: 6.864, Average Loss: 3.152, avg. samples / sec: 52721.83
Iteration:    400, Loss function: 6.157, Average Loss: 3.125, avg. samples / sec: 52552.91
Iteration:    400, Loss function: 6.196, Average Loss: 3.115, avg. samples / sec: 52782.65
Iteration:    400, Loss function: 6.200, Average Loss: 3.145, avg. samples / sec: 52270.06
Iteration:    400, Loss function: 6.137, Average Loss: 3.137, avg. samples / sec: 51835.83
:::MLL 1558640292.707 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558640292.708 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 6.708, Average Loss: 3.210, avg. samples / sec: 53349.48
Iteration:    420, Loss function: 7.746, Average Loss: 3.207, avg. samples / sec: 54161.28
Iteration:    420, Loss function: 7.191, Average Loss: 3.210, avg. samples / sec: 53373.40
Iteration:    420, Loss function: 6.053, Average Loss: 3.212, avg. samples / sec: 52975.44
Iteration:    420, Loss function: 5.783, Average Loss: 3.217, avg. samples / sec: 53901.86
Iteration:    420, Loss function: 6.212, Average Loss: 3.219, avg. samples / sec: 53187.11
Iteration:    420, Loss function: 7.462, Average Loss: 3.200, avg. samples / sec: 53309.80
Iteration:    420, Loss function: 6.701, Average Loss: 3.201, avg. samples / sec: 53257.24
Iteration:    420, Loss function: 6.392, Average Loss: 3.213, avg. samples / sec: 53075.98
Iteration:    420, Loss function: 7.982, Average Loss: 3.197, avg. samples / sec: 53250.96
Iteration:    420, Loss function: 5.797, Average Loss: 3.213, avg. samples / sec: 53130.81
Iteration:    420, Loss function: 6.656, Average Loss: 3.185, avg. samples / sec: 53477.99
Iteration:    420, Loss function: 7.133, Average Loss: 3.208, avg. samples / sec: 53111.10
Iteration:    420, Loss function: 5.995, Average Loss: 3.212, avg. samples / sec: 53093.08
Iteration:    420, Loss function: 6.573, Average Loss: 3.214, avg. samples / sec: 53119.85
Iteration:    420, Loss function: 6.717, Average Loss: 3.224, avg. samples / sec: 53297.14
Iteration:    420, Loss function: 7.056, Average Loss: 3.198, avg. samples / sec: 53159.27
Iteration:    420, Loss function: 6.795, Average Loss: 3.214, avg. samples / sec: 53215.69
Iteration:    420, Loss function: 6.389, Average Loss: 3.203, avg. samples / sec: 52753.37
Iteration:    420, Loss function: 6.782, Average Loss: 3.198, avg. samples / sec: 52957.15
Iteration:    420, Loss function: 7.118, Average Loss: 3.195, avg. samples / sec: 52924.42
Iteration:    420, Loss function: 6.718, Average Loss: 3.198, avg. samples / sec: 53004.20
Iteration:    420, Loss function: 6.337, Average Loss: 3.210, avg. samples / sec: 53083.56
Iteration:    420, Loss function: 5.670, Average Loss: 3.239, avg. samples / sec: 52793.48
Iteration:    420, Loss function: 5.963, Average Loss: 3.193, avg. samples / sec: 53103.22
Iteration:    420, Loss function: 6.900, Average Loss: 3.205, avg. samples / sec: 52898.73
Iteration:    420, Loss function: 6.231, Average Loss: 3.201, avg. samples / sec: 52663.22
Iteration:    420, Loss function: 7.923, Average Loss: 3.192, avg. samples / sec: 52402.89
Iteration:    420, Loss function: 7.246, Average Loss: 3.206, avg. samples / sec: 52252.78
Iteration:    420, Loss function: 5.950, Average Loss: 3.196, avg. samples / sec: 51832.57
Iteration:    440, Loss function: 6.961, Average Loss: 3.280, avg. samples / sec: 53490.23
Iteration:    440, Loss function: 6.509, Average Loss: 3.279, avg. samples / sec: 53554.20
Iteration:    440, Loss function: 6.370, Average Loss: 3.273, avg. samples / sec: 53427.46
Iteration:    440, Loss function: 6.248, Average Loss: 3.273, avg. samples / sec: 54075.36
Iteration:    440, Loss function: 5.784, Average Loss: 3.264, avg. samples / sec: 54936.10
Iteration:    440, Loss function: 6.433, Average Loss: 3.283, avg. samples / sec: 53326.30
Iteration:    440, Loss function: 7.882, Average Loss: 3.265, avg. samples / sec: 53315.95
Iteration:    440, Loss function: 6.623, Average Loss: 3.269, avg. samples / sec: 53579.42
Iteration:    440, Loss function: 5.760, Average Loss: 3.261, avg. samples / sec: 54105.55
Iteration:    440, Loss function: 6.795, Average Loss: 3.271, avg. samples / sec: 53254.12
Iteration:    440, Loss function: 6.057, Average Loss: 3.279, avg. samples / sec: 53216.19
Iteration:    440, Loss function: 6.334, Average Loss: 3.285, avg. samples / sec: 53110.96
Iteration:    440, Loss function: 7.421, Average Loss: 3.286, avg. samples / sec: 53228.88
Iteration:    440, Loss function: 7.319, Average Loss: 3.275, avg. samples / sec: 53106.10
Iteration:    440, Loss function: 7.796, Average Loss: 3.290, avg. samples / sec: 53165.98
Iteration:    440, Loss function: 5.871, Average Loss: 3.265, avg. samples / sec: 53426.23
Iteration:    440, Loss function: 6.127, Average Loss: 3.275, avg. samples / sec: 54219.58
Iteration:    440, Loss function: 6.984, Average Loss: 3.280, avg. samples / sec: 53236.84
Iteration:    440, Loss function: 6.733, Average Loss: 3.288, avg. samples / sec: 53309.56
Iteration:    440, Loss function: 6.759, Average Loss: 3.269, avg. samples / sec: 53584.45
Iteration:    440, Loss function: 5.198, Average Loss: 3.262, avg. samples / sec: 53200.60
Iteration:    440, Loss function: 6.089, Average Loss: 3.291, avg. samples / sec: 52985.20
Iteration:    440, Loss function: 5.433, Average Loss: 3.275, avg. samples / sec: 53319.06
Iteration:    440, Loss function: 5.961, Average Loss: 3.270, avg. samples / sec: 53242.85
Iteration:    440, Loss function: 6.897, Average Loss: 3.252, avg. samples / sec: 53006.19
Iteration:    440, Loss function: 6.419, Average Loss: 3.264, avg. samples / sec: 53338.87
Iteration:    440, Loss function: 6.271, Average Loss: 3.292, avg. samples / sec: 53128.90
Iteration:    440, Loss function: 6.121, Average Loss: 3.284, avg. samples / sec: 53202.59
Iteration:    440, Loss function: 5.903, Average Loss: 3.257, avg. samples / sec: 53105.12
Iteration:    440, Loss function: 6.466, Average Loss: 3.311, avg. samples / sec: 52429.15
Iteration:    460, Loss function: 6.600, Average Loss: 3.322, avg. samples / sec: 53607.22
Iteration:    460, Loss function: 6.925, Average Loss: 3.349, avg. samples / sec: 53400.60
Iteration:    460, Loss function: 6.850, Average Loss: 3.338, avg. samples / sec: 53614.89
Iteration:    460, Loss function: 6.667, Average Loss: 3.328, avg. samples / sec: 53455.00
Iteration:    460, Loss function: 6.794, Average Loss: 3.353, avg. samples / sec: 53605.04
Iteration:    460, Loss function: 6.494, Average Loss: 3.352, avg. samples / sec: 53609.95
Iteration:    460, Loss function: 6.685, Average Loss: 3.343, avg. samples / sec: 53796.45
Iteration:    460, Loss function: 6.592, Average Loss: 3.352, avg. samples / sec: 53599.25
Iteration:    460, Loss function: 6.700, Average Loss: 3.344, avg. samples / sec: 53496.56
Iteration:    460, Loss function: 5.695, Average Loss: 3.358, avg. samples / sec: 53691.26
Iteration:    460, Loss function: 6.259, Average Loss: 3.336, avg. samples / sec: 53374.37
Iteration:    460, Loss function: 8.922, Average Loss: 3.335, avg. samples / sec: 53605.55
Iteration:    460, Loss function: 6.483, Average Loss: 3.379, avg. samples / sec: 54571.42
Iteration:    460, Loss function: 6.858, Average Loss: 3.337, avg. samples / sec: 53491.95
Iteration:    460, Loss function: 5.689, Average Loss: 3.336, avg. samples / sec: 53497.78
Iteration:    460, Loss function: 5.736, Average Loss: 3.337, avg. samples / sec: 53212.58
Iteration:    460, Loss function: 6.791, Average Loss: 3.328, avg. samples / sec: 53514.32
Iteration:    460, Loss function: 6.426, Average Loss: 3.332, avg. samples / sec: 53156.80
Iteration:    460, Loss function: 6.900, Average Loss: 3.347, avg. samples / sec: 53155.50
Iteration:    460, Loss function: 6.806, Average Loss: 3.353, avg. samples / sec: 53106.60
Iteration:    460, Loss function: 6.057, Average Loss: 3.331, avg. samples / sec: 52945.07
Iteration:    460, Loss function: 6.141, Average Loss: 3.344, avg. samples / sec: 52726.39
Iteration:    460, Loss function: 6.806, Average Loss: 3.351, avg. samples / sec: 53182.84
Iteration:    460, Loss function: 7.113, Average Loss: 3.317, avg. samples / sec: 53062.65
Iteration:    460, Loss function: 7.024, Average Loss: 3.353, avg. samples / sec: 52671.68
Iteration:    460, Loss function: 6.436, Average Loss: 3.336, avg. samples / sec: 52534.28
Iteration:    460, Loss function: 6.890, Average Loss: 3.362, avg. samples / sec: 52854.05
Iteration:    460, Loss function: 7.402, Average Loss: 3.323, avg. samples / sec: 52994.37
Iteration:    460, Loss function: 7.275, Average Loss: 3.340, avg. samples / sec: 52598.02
Iteration:    460, Loss function: 7.581, Average Loss: 3.338, avg. samples / sec: 52010.07
Iteration:    480, Loss function: 7.761, Average Loss: 3.416, avg. samples / sec: 53604.37
Iteration:    480, Loss function: 6.826, Average Loss: 3.414, avg. samples / sec: 54168.06
Iteration:    480, Loss function: 5.560, Average Loss: 3.421, avg. samples / sec: 53615.36
Iteration:    480, Loss function: 6.272, Average Loss: 3.390, avg. samples / sec: 53564.17
Iteration:    480, Loss function: 6.825, Average Loss: 3.413, avg. samples / sec: 54127.99
Iteration:    480, Loss function: 6.176, Average Loss: 3.418, avg. samples / sec: 54353.77
Iteration:    480, Loss function: 6.025, Average Loss: 3.404, avg. samples / sec: 54365.51
Iteration:    480, Loss function: 6.344, Average Loss: 3.410, avg. samples / sec: 53428.58
Iteration:    480, Loss function: 5.780, Average Loss: 3.404, avg. samples / sec: 53808.01
Iteration:    480, Loss function: 6.667, Average Loss: 3.446, avg. samples / sec: 53684.17
Iteration:    480, Loss function: 7.565, Average Loss: 3.423, avg. samples / sec: 53969.93
Iteration:    480, Loss function: 6.503, Average Loss: 3.413, avg. samples / sec: 53539.93
Iteration:    480, Loss function: 7.120, Average Loss: 3.419, avg. samples / sec: 53476.18
Iteration:    480, Loss function: 6.806, Average Loss: 3.410, avg. samples / sec: 54474.26
Iteration:    480, Loss function: 7.335, Average Loss: 3.410, avg. samples / sec: 53412.14
Iteration:    480, Loss function: 7.164, Average Loss: 3.400, avg. samples / sec: 53556.33
Iteration:    480, Loss function: 6.699, Average Loss: 3.400, avg. samples / sec: 53576.65
Iteration:    480, Loss function: 7.466, Average Loss: 3.397, avg. samples / sec: 53817.94
Iteration:    480, Loss function: 5.787, Average Loss: 3.422, avg. samples / sec: 53436.07
Iteration:    480, Loss function: 6.601, Average Loss: 3.420, avg. samples / sec: 53914.99
Iteration:    480, Loss function: 5.719, Average Loss: 3.404, avg. samples / sec: 54667.95
Iteration:    480, Loss function: 6.372, Average Loss: 3.407, avg. samples / sec: 53556.88
Iteration:    480, Loss function: 6.562, Average Loss: 3.430, avg. samples / sec: 54205.29
Iteration:    480, Loss function: 6.293, Average Loss: 3.397, avg. samples / sec: 54215.60
Iteration:    480, Loss function: 6.878, Average Loss: 3.397, avg. samples / sec: 53554.36
Iteration:    480, Loss function: 5.727, Average Loss: 3.404, avg. samples / sec: 53512.33
Iteration:    480, Loss function: 7.368, Average Loss: 3.402, avg. samples / sec: 53761.21
Iteration:    480, Loss function: 6.623, Average Loss: 3.385, avg. samples / sec: 53848.10
Iteration:    480, Loss function: 8.001, Average Loss: 3.392, avg. samples / sec: 52759.86
Iteration:    480, Loss function: 6.578, Average Loss: 3.422, avg. samples / sec: 52757.67
:::MLL 1558640294.909 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558640294.910 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 6.045, Average Loss: 3.459, avg. samples / sec: 53803.80
Iteration:    500, Loss function: 5.779, Average Loss: 3.469, avg. samples / sec: 53742.02
Iteration:    500, Loss function: 6.795, Average Loss: 3.478, avg. samples / sec: 53592.52
Iteration:    500, Loss function: 6.271, Average Loss: 3.473, avg. samples / sec: 53744.75
Iteration:    500, Loss function: 5.978, Average Loss: 3.474, avg. samples / sec: 53476.91
Iteration:    500, Loss function: 6.346, Average Loss: 3.459, avg. samples / sec: 53644.26
Iteration:    500, Loss function: 6.382, Average Loss: 3.473, avg. samples / sec: 53597.50
Iteration:    500, Loss function: 6.619, Average Loss: 3.472, avg. samples / sec: 53652.71
Iteration:    500, Loss function: 7.965, Average Loss: 3.449, avg. samples / sec: 53473.38
Iteration:    500, Loss function: 5.824, Average Loss: 3.447, avg. samples / sec: 54263.82
Iteration:    500, Loss function: 6.793, Average Loss: 3.479, avg. samples / sec: 54320.58
Iteration:    500, Loss function: 6.145, Average Loss: 3.476, avg. samples / sec: 53375.66
Iteration:    500, Loss function: 5.455, Average Loss: 3.470, avg. samples / sec: 53625.78
Iteration:    500, Loss function: 6.808, Average Loss: 3.471, avg. samples / sec: 53508.44
Iteration:    500, Loss function: 6.339, Average Loss: 3.479, avg. samples / sec: 53579.63
Iteration:    500, Loss function: 5.984, Average Loss: 3.458, avg. samples / sec: 53559.79
Iteration:    500, Loss function: 6.962, Average Loss: 3.443, avg. samples / sec: 53869.16
Iteration:    500, Loss function: 5.143, Average Loss: 3.502, avg. samples / sec: 53431.37
Iteration:    500, Loss function: 6.115, Average Loss: 3.478, avg. samples / sec: 53417.54
Iteration:    500, Loss function: 5.908, Average Loss: 3.462, avg. samples / sec: 53629.44
Iteration:    500, Loss function: 5.067, Average Loss: 3.457, avg. samples / sec: 53434.41
Iteration:    500, Loss function: 6.490, Average Loss: 3.489, avg. samples / sec: 53599.29
Iteration:    500, Loss function: 5.470, Average Loss: 3.480, avg. samples / sec: 53546.61
Iteration:    500, Loss function: 5.870, Average Loss: 3.457, avg. samples / sec: 53479.49
Iteration:    500, Loss function: 6.951, Average Loss: 3.458, avg. samples / sec: 53585.55
Iteration:    500, Loss function: 5.293, Average Loss: 3.459, avg. samples / sec: 53608.42
Iteration:    500, Loss function: 6.077, Average Loss: 3.457, avg. samples / sec: 53578.91
Iteration:    500, Loss function: 6.291, Average Loss: 3.481, avg. samples / sec: 53537.84
Iteration:    500, Loss function: 6.366, Average Loss: 3.458, avg. samples / sec: 53521.10
Iteration:    500, Loss function: 6.150, Average Loss: 3.469, avg. samples / sec: 52996.80
Iteration:    520, Loss function: 7.027, Average Loss: 3.541, avg. samples / sec: 53890.17
Iteration:    520, Loss function: 6.832, Average Loss: 3.522, avg. samples / sec: 53798.34
Iteration:    520, Loss function: 6.013, Average Loss: 3.530, avg. samples / sec: 53811.50
Iteration:    520, Loss function: 7.674, Average Loss: 3.534, avg. samples / sec: 53949.73
Iteration:    520, Loss function: 7.169, Average Loss: 3.534, avg. samples / sec: 53909.51
Iteration:    520, Loss function: 6.707, Average Loss: 3.546, avg. samples / sec: 54125.54
Iteration:    520, Loss function: 6.610, Average Loss: 3.541, avg. samples / sec: 53950.68
Iteration:    520, Loss function: 6.362, Average Loss: 3.536, avg. samples / sec: 53911.53
Iteration:    520, Loss function: 5.496, Average Loss: 3.531, avg. samples / sec: 53849.65
Iteration:    520, Loss function: 6.645, Average Loss: 3.526, avg. samples / sec: 53936.62
Iteration:    520, Loss function: 6.604, Average Loss: 3.528, avg. samples / sec: 54718.83
Iteration:    520, Loss function: 6.625, Average Loss: 3.535, avg. samples / sec: 53884.83
Iteration:    520, Loss function: 6.087, Average Loss: 3.512, avg. samples / sec: 53799.63
Iteration:    520, Loss function: 7.118, Average Loss: 3.509, avg. samples / sec: 53808.46
Iteration:    520, Loss function: 6.540, Average Loss: 3.535, avg. samples / sec: 53724.22
Iteration:    520, Loss function: 6.628, Average Loss: 3.523, avg. samples / sec: 53953.10
Iteration:    520, Loss function: 6.513, Average Loss: 3.522, avg. samples / sec: 53820.98
Iteration:    520, Loss function: 6.831, Average Loss: 3.531, avg. samples / sec: 53587.14
Iteration:    520, Loss function: 5.997, Average Loss: 3.521, avg. samples / sec: 53897.40
Iteration:    520, Loss function: 6.058, Average Loss: 3.517, avg. samples / sec: 53869.41
Iteration:    520, Loss function: 6.635, Average Loss: 3.528, avg. samples / sec: 53860.06
Iteration:    520, Loss function: 6.857, Average Loss: 3.520, avg. samples / sec: 53572.42
Iteration:    520, Loss function: 6.877, Average Loss: 3.535, avg. samples / sec: 53855.12
Iteration:    520, Loss function: 6.709, Average Loss: 3.546, avg. samples / sec: 53892.27
Iteration:    520, Loss function: 6.726, Average Loss: 3.516, avg. samples / sec: 53870.50
Iteration:    520, Loss function: 6.439, Average Loss: 3.516, avg. samples / sec: 53850.24
Iteration:    520, Loss function: 6.278, Average Loss: 3.519, avg. samples / sec: 53925.27
Iteration:    520, Loss function: 6.675, Average Loss: 3.503, avg. samples / sec: 53722.56
Iteration:    520, Loss function: 6.043, Average Loss: 3.556, avg. samples / sec: 53528.54
Iteration:    520, Loss function: 6.113, Average Loss: 3.549, avg. samples / sec: 52837.37
Iteration:    540, Loss function: 5.915, Average Loss: 3.587, avg. samples / sec: 52560.14
Iteration:    540, Loss function: 5.126, Average Loss: 3.592, avg. samples / sec: 52480.11
Iteration:    540, Loss function: 5.837, Average Loss: 3.581, avg. samples / sec: 52550.21
Iteration:    540, Loss function: 5.396, Average Loss: 3.588, avg. samples / sec: 52432.90
Iteration:    540, Loss function: 6.438, Average Loss: 3.576, avg. samples / sec: 52539.35
Iteration:    540, Loss function: 7.181, Average Loss: 3.566, avg. samples / sec: 52569.51
Iteration:    540, Loss function: 6.240, Average Loss: 3.569, avg. samples / sec: 52548.58
Iteration:    540, Loss function: 6.492, Average Loss: 3.574, avg. samples / sec: 52723.03
Iteration:    540, Loss function: 4.999, Average Loss: 3.593, avg. samples / sec: 52478.25
Iteration:    540, Loss function: 5.627, Average Loss: 3.588, avg. samples / sec: 52499.03
Iteration:    540, Loss function: 6.084, Average Loss: 3.588, avg. samples / sec: 52609.35
Iteration:    540, Loss function: 6.715, Average Loss: 3.575, avg. samples / sec: 52290.18
Iteration:    540, Loss function: 7.090, Average Loss: 3.595, avg. samples / sec: 52448.19
Iteration:    540, Loss function: 6.662, Average Loss: 3.588, avg. samples / sec: 52572.40
Iteration:    540, Loss function: 6.686, Average Loss: 3.581, avg. samples / sec: 52344.52
Iteration:    540, Loss function: 6.358, Average Loss: 3.596, avg. samples / sec: 52133.74
Iteration:    540, Loss function: 7.364, Average Loss: 3.603, avg. samples / sec: 52576.22
Iteration:    540, Loss function: 6.586, Average Loss: 3.586, avg. samples / sec: 52499.31
Iteration:    540, Loss function: 5.552, Average Loss: 3.567, avg. samples / sec: 52564.26
Iteration:    540, Loss function: 6.175, Average Loss: 3.577, avg. samples / sec: 52464.19
Iteration:    540, Loss function: 5.282, Average Loss: 3.581, avg. samples / sec: 52460.08
Iteration:    540, Loss function: 6.482, Average Loss: 3.577, avg. samples / sec: 52515.43
Iteration:    540, Loss function: 5.778, Average Loss: 3.571, avg. samples / sec: 52549.05
Iteration:    540, Loss function: 4.684, Average Loss: 3.587, avg. samples / sec: 52534.44
Iteration:    540, Loss function: 6.659, Average Loss: 3.605, avg. samples / sec: 52772.67
Iteration:    540, Loss function: 6.256, Average Loss: 3.567, avg. samples / sec: 52505.68
Iteration:    540, Loss function: 6.020, Average Loss: 3.572, avg. samples / sec: 52531.11
Iteration:    540, Loss function: 6.283, Average Loss: 3.553, avg. samples / sec: 52535.34
Iteration:    540, Loss function: 6.248, Average Loss: 3.602, avg. samples / sec: 52171.01
Iteration:    540, Loss function: 5.960, Average Loss: 3.607, avg. samples / sec: 53216.84
:::MLL 1558640297.115 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558640297.115 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 6.336, Average Loss: 3.621, avg. samples / sec: 53494.71
Iteration:    560, Loss function: 6.139, Average Loss: 3.637, avg. samples / sec: 53264.06
Iteration:    560, Loss function: 6.152, Average Loss: 3.627, avg. samples / sec: 53505.62
Iteration:    560, Loss function: 5.132, Average Loss: 3.651, avg. samples / sec: 53697.18
Iteration:    560, Loss function: 5.084, Average Loss: 3.640, avg. samples / sec: 53266.32
Iteration:    560, Loss function: 5.057, Average Loss: 3.638, avg. samples / sec: 53384.40
Iteration:    560, Loss function: 5.920, Average Loss: 3.629, avg. samples / sec: 53362.48
Iteration:    560, Loss function: 6.360, Average Loss: 3.637, avg. samples / sec: 53365.60
Iteration:    560, Loss function: 6.642, Average Loss: 3.633, avg. samples / sec: 53524.17
Iteration:    560, Loss function: 6.915, Average Loss: 3.617, avg. samples / sec: 53299.24
Iteration:    560, Loss function: 5.239, Average Loss: 3.627, avg. samples / sec: 53257.84
Iteration:    560, Loss function: 6.355, Average Loss: 3.625, avg. samples / sec: 53217.92
Iteration:    560, Loss function: 5.172, Average Loss: 3.640, avg. samples / sec: 53306.94
Iteration:    560, Loss function: 5.880, Average Loss: 3.633, avg. samples / sec: 53195.56
Iteration:    560, Loss function: 5.240, Average Loss: 3.620, avg. samples / sec: 53465.19
Iteration:    560, Loss function: 5.030, Average Loss: 3.614, avg. samples / sec: 53437.51
Iteration:    560, Loss function: 5.634, Average Loss: 3.652, avg. samples / sec: 53739.48
Iteration:    560, Loss function: 5.465, Average Loss: 3.637, avg. samples / sec: 53206.57
Iteration:    560, Loss function: 6.373, Average Loss: 3.655, avg. samples / sec: 53379.75
Iteration:    560, Loss function: 5.844, Average Loss: 3.628, avg. samples / sec: 53374.39
Iteration:    560, Loss function: 6.531, Average Loss: 3.625, avg. samples / sec: 53331.55
Iteration:    560, Loss function: 5.399, Average Loss: 3.638, avg. samples / sec: 53344.08
Iteration:    560, Loss function: 5.393, Average Loss: 3.628, avg. samples / sec: 53287.61
Iteration:    560, Loss function: 7.377, Average Loss: 3.616, avg. samples / sec: 53303.89
Iteration:    560, Loss function: 7.259, Average Loss: 3.627, avg. samples / sec: 53284.50
Iteration:    560, Loss function: 7.213, Average Loss: 3.603, avg. samples / sec: 53278.84
Iteration:    560, Loss function: 5.647, Average Loss: 3.639, avg. samples / sec: 53179.34
Iteration:    560, Loss function: 6.227, Average Loss: 3.641, avg. samples / sec: 53195.62
Iteration:    560, Loss function: 5.910, Average Loss: 3.626, avg. samples / sec: 53198.19
Iteration:    560, Loss function: 6.328, Average Loss: 3.655, avg. samples / sec: 53216.13
Iteration:    580, Loss function: 5.697, Average Loss: 3.692, avg. samples / sec: 53829.24
Iteration:    580, Loss function: 5.433, Average Loss: 3.678, avg. samples / sec: 53714.18
Iteration:    580, Loss function: 6.071, Average Loss: 3.670, avg. samples / sec: 53822.68
Iteration:    580, Loss function: 5.253, Average Loss: 3.678, avg. samples / sec: 53705.52
Iteration:    580, Loss function: 5.622, Average Loss: 3.672, avg. samples / sec: 54041.52
Iteration:    580, Loss function: 5.551, Average Loss: 3.687, avg. samples / sec: 53764.06
Iteration:    580, Loss function: 6.009, Average Loss: 3.668, avg. samples / sec: 53967.64
Iteration:    580, Loss function: 5.888, Average Loss: 3.676, avg. samples / sec: 53553.30
Iteration:    580, Loss function: 6.713, Average Loss: 3.685, avg. samples / sec: 53820.55
Iteration:    580, Loss function: 5.905, Average Loss: 3.683, avg. samples / sec: 53668.16
Iteration:    580, Loss function: 5.626, Average Loss: 3.663, avg. samples / sec: 53678.38
Iteration:    580, Loss function: 6.339, Average Loss: 3.689, avg. samples / sec: 53989.56
Iteration:    580, Loss function: 5.955, Average Loss: 3.678, avg. samples / sec: 53668.98
Iteration:    580, Loss function: 7.368, Average Loss: 3.686, avg. samples / sec: 53638.56
Iteration:    580, Loss function: 6.616, Average Loss: 3.675, avg. samples / sec: 53680.57
Iteration:    580, Loss function: 6.697, Average Loss: 3.698, avg. samples / sec: 53577.71
Iteration:    580, Loss function: 6.330, Average Loss: 3.704, avg. samples / sec: 53979.75
Iteration:    580, Loss function: 5.418, Average Loss: 3.671, avg. samples / sec: 53418.94
Iteration:    580, Loss function: 6.102, Average Loss: 3.701, avg. samples / sec: 53726.04
Iteration:    580, Loss function: 6.348, Average Loss: 3.669, avg. samples / sec: 53799.86
Iteration:    580, Loss function: 5.947, Average Loss: 3.676, avg. samples / sec: 53776.04
Iteration:    580, Loss function: 4.826, Average Loss: 3.677, avg. samples / sec: 53684.45
Iteration:    580, Loss function: 6.177, Average Loss: 3.664, avg. samples / sec: 53614.77
Iteration:    580, Loss function: 6.779, Average Loss: 3.682, avg. samples / sec: 53802.59
Iteration:    580, Loss function: 6.454, Average Loss: 3.674, avg. samples / sec: 53673.00
Iteration:    580, Loss function: 5.387, Average Loss: 3.688, avg. samples / sec: 53683.08
Iteration:    580, Loss function: 5.553, Average Loss: 3.666, avg. samples / sec: 53549.45
Iteration:    580, Loss function: 5.959, Average Loss: 3.702, avg. samples / sec: 53567.41
Iteration:    580, Loss function: 6.480, Average Loss: 3.651, avg. samples / sec: 53716.66
Iteration:    580, Loss function: 6.490, Average Loss: 3.678, avg. samples / sec: 53394.59
Iteration:    600, Loss function: 6.302, Average Loss: 3.739, avg. samples / sec: 54042.16
Iteration:    600, Loss function: 7.064, Average Loss: 3.727, avg. samples / sec: 54060.07
Iteration:    600, Loss function: 6.792, Average Loss: 3.728, avg. samples / sec: 54587.67
Iteration:    600, Loss function: 7.074, Average Loss: 3.724, avg. samples / sec: 54194.14
Iteration:    600, Loss function: 7.480, Average Loss: 3.742, avg. samples / sec: 54167.77
Iteration:    600, Loss function: 6.204, Average Loss: 3.727, avg. samples / sec: 54122.61
Iteration:    600, Loss function: 5.703, Average Loss: 3.713, avg. samples / sec: 54376.59
Iteration:    600, Loss function: 6.129, Average Loss: 3.752, avg. samples / sec: 54194.00
Iteration:    600, Loss function: 6.067, Average Loss: 3.731, avg. samples / sec: 54160.67
Iteration:    600, Loss function: 5.892, Average Loss: 3.726, avg. samples / sec: 54151.27
Iteration:    600, Loss function: 5.975, Average Loss: 3.723, avg. samples / sec: 54163.05
Iteration:    600, Loss function: 6.245, Average Loss: 3.717, avg. samples / sec: 54142.01
Iteration:    600, Loss function: 5.949, Average Loss: 3.724, avg. samples / sec: 54042.29
Iteration:    600, Loss function: 6.215, Average Loss: 3.735, avg. samples / sec: 54130.03
Iteration:    600, Loss function: 6.007, Average Loss: 3.735, avg. samples / sec: 54098.42
Iteration:    600, Loss function: 5.220, Average Loss: 3.718, avg. samples / sec: 54150.91
Iteration:    600, Loss function: 6.838, Average Loss: 3.740, avg. samples / sec: 53978.93
Iteration:    600, Loss function: 7.145, Average Loss: 3.729, avg. samples / sec: 54064.60
Iteration:    600, Loss function: 6.623, Average Loss: 3.749, avg. samples / sec: 54030.42
Iteration:    600, Loss function: 7.146, Average Loss: 3.728, avg. samples / sec: 54149.16
Iteration:    600, Loss function: 6.165, Average Loss: 3.737, avg. samples / sec: 54123.07
Iteration:    600, Loss function: 6.012, Average Loss: 3.727, avg. samples / sec: 53905.05
Iteration:    600, Loss function: 6.234, Average Loss: 3.720, avg. samples / sec: 54148.50
Iteration:    600, Loss function: 6.665, Average Loss: 3.757, avg. samples / sec: 53955.16
Iteration:    600, Loss function: 6.386, Average Loss: 3.753, avg. samples / sec: 54162.59
Iteration:    600, Loss function: 7.334, Average Loss: 3.721, avg. samples / sec: 53881.35
Iteration:    600, Loss function: 5.884, Average Loss: 3.718, avg. samples / sec: 54008.74
Iteration:    600, Loss function: 6.701, Average Loss: 3.706, avg. samples / sec: 54158.28
Iteration:    600, Loss function: 6.330, Average Loss: 3.732, avg. samples / sec: 53948.10
Iteration:    600, Loss function: 5.846, Average Loss: 3.740, avg. samples / sec: 53181.17
Iteration:    620, Loss function: 6.472, Average Loss: 3.781, avg. samples / sec: 53887.53
Iteration:    620, Loss function: 5.517, Average Loss: 3.774, avg. samples / sec: 53963.36
Iteration:    620, Loss function: 6.258, Average Loss: 3.768, avg. samples / sec: 53900.19
Iteration:    620, Loss function: 5.866, Average Loss: 3.765, avg. samples / sec: 53941.06
Iteration:    620, Loss function: 4.750, Average Loss: 3.770, avg. samples / sec: 53782.22
Iteration:    620, Loss function: 6.142, Average Loss: 3.788, avg. samples / sec: 54017.45
Iteration:    620, Loss function: 5.205, Average Loss: 3.779, avg. samples / sec: 53719.47
Iteration:    620, Loss function: 6.464, Average Loss: 3.792, avg. samples / sec: 53782.47
Iteration:    620, Loss function: 5.943, Average Loss: 3.797, avg. samples / sec: 53775.18
Iteration:    620, Loss function: 5.977, Average Loss: 3.796, avg. samples / sec: 54004.68
Iteration:    620, Loss function: 5.955, Average Loss: 3.783, avg. samples / sec: 53817.63
Iteration:    620, Loss function: 6.705, Average Loss: 3.774, avg. samples / sec: 53743.74
Iteration:    620, Loss function: 6.957, Average Loss: 3.771, avg. samples / sec: 53794.13
Iteration:    620, Loss function: 7.832, Average Loss: 3.809, avg. samples / sec: 54001.35
Iteration:    620, Loss function: 4.909, Average Loss: 3.760, avg. samples / sec: 53713.84
Iteration:    620, Loss function: 6.325, Average Loss: 3.770, avg. samples / sec: 53976.32
Iteration:    620, Loss function: 4.578, Average Loss: 3.763, avg. samples / sec: 53756.68
Iteration:    620, Loss function: 5.655, Average Loss: 3.782, avg. samples / sec: 53755.61
Iteration:    620, Loss function: 6.353, Average Loss: 3.799, avg. samples / sec: 53854.34
Iteration:    620, Loss function: 6.346, Average Loss: 3.764, avg. samples / sec: 53852.92
Iteration:    620, Loss function: 6.065, Average Loss: 3.775, avg. samples / sec: 53801.95
Iteration:    620, Loss function: 6.081, Average Loss: 3.764, avg. samples / sec: 53831.93
Iteration:    620, Loss function: 5.943, Average Loss: 3.787, avg. samples / sec: 53789.14
Iteration:    620, Loss function: 6.131, Average Loss: 3.768, avg. samples / sec: 53782.59
Iteration:    620, Loss function: 6.560, Average Loss: 3.781, avg. samples / sec: 53902.52
Iteration:    620, Loss function: 6.626, Average Loss: 3.781, avg. samples / sec: 54734.47
Iteration:    620, Loss function: 6.501, Average Loss: 3.780, avg. samples / sec: 53718.95
Iteration:    620, Loss function: 6.045, Average Loss: 3.753, avg. samples / sec: 53743.15
Iteration:    620, Loss function: 7.264, Average Loss: 3.773, avg. samples / sec: 53421.02
Iteration:    620, Loss function: 5.076, Average Loss: 3.770, avg. samples / sec: 53093.78
:::MLL 1558640299.303 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558640299.304 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 5.305, Average Loss: 3.814, avg. samples / sec: 53581.13
Iteration:    640, Loss function: 5.557, Average Loss: 3.812, avg. samples / sec: 53315.93
Iteration:    640, Loss function: 6.649, Average Loss: 3.810, avg. samples / sec: 53279.29
Iteration:    640, Loss function: 6.428, Average Loss: 3.817, avg. samples / sec: 53152.31
Iteration:    640, Loss function: 4.977, Average Loss: 3.824, avg. samples / sec: 53102.92
Iteration:    640, Loss function: 5.769, Average Loss: 3.809, avg. samples / sec: 53550.23
Iteration:    640, Loss function: 6.551, Average Loss: 3.807, avg. samples / sec: 53460.48
Iteration:    640, Loss function: 5.067, Average Loss: 3.811, avg. samples / sec: 53231.13
Iteration:    640, Loss function: 5.719, Average Loss: 3.839, avg. samples / sec: 53205.53
Iteration:    640, Loss function: 4.472, Average Loss: 3.832, avg. samples / sec: 53181.17
Iteration:    640, Loss function: 4.849, Average Loss: 3.820, avg. samples / sec: 53219.73
Iteration:    640, Loss function: 5.082, Average Loss: 3.812, avg. samples / sec: 53244.36
Iteration:    640, Loss function: 4.776, Average Loss: 3.805, avg. samples / sec: 53118.41
Iteration:    640, Loss function: 5.570, Average Loss: 3.809, avg. samples / sec: 53082.32
Iteration:    640, Loss function: 5.575, Average Loss: 3.802, avg. samples / sec: 53209.70
Iteration:    640, Loss function: 5.818, Average Loss: 3.815, avg. samples / sec: 53858.60
Iteration:    640, Loss function: 4.706, Average Loss: 3.818, avg. samples / sec: 53233.00
Iteration:    640, Loss function: 6.549, Average Loss: 3.809, avg. samples / sec: 53185.67
Iteration:    640, Loss function: 5.342, Average Loss: 3.811, avg. samples / sec: 53163.68
Iteration:    640, Loss function: 5.098, Average Loss: 3.817, avg. samples / sec: 53420.58
Iteration:    640, Loss function: 5.246, Average Loss: 3.834, avg. samples / sec: 53049.87
Iteration:    640, Loss function: 4.886, Average Loss: 3.818, avg. samples / sec: 53227.19
Iteration:    640, Loss function: 6.023, Average Loss: 3.827, avg. samples / sec: 53194.96
Iteration:    640, Loss function: 5.573, Average Loss: 3.801, avg. samples / sec: 53164.52
Iteration:    640, Loss function: 4.928, Average Loss: 3.835, avg. samples / sec: 53124.00
Iteration:    640, Loss function: 6.152, Average Loss: 3.824, avg. samples / sec: 52910.25
Iteration:    640, Loss function: 6.551, Average Loss: 3.823, avg. samples / sec: 53193.70
Iteration:    640, Loss function: 5.205, Average Loss: 3.841, avg. samples / sec: 52949.47
Iteration:    640, Loss function: 5.564, Average Loss: 3.797, avg. samples / sec: 53220.68
Iteration:    640, Loss function: 6.850, Average Loss: 3.804, avg. samples / sec: 53124.96
Iteration:    660, Loss function: 5.645, Average Loss: 3.853, avg. samples / sec: 53743.13
Iteration:    660, Loss function: 7.025, Average Loss: 3.868, avg. samples / sec: 53754.34
Iteration:    660, Loss function: 6.721, Average Loss: 3.848, avg. samples / sec: 53833.02
Iteration:    660, Loss function: 6.147, Average Loss: 3.846, avg. samples / sec: 53645.93
Iteration:    660, Loss function: 5.083, Average Loss: 3.869, avg. samples / sec: 53724.38
Iteration:    660, Loss function: 4.829, Average Loss: 3.845, avg. samples / sec: 53768.00
Iteration:    660, Loss function: 5.918, Average Loss: 3.854, avg. samples / sec: 53744.81
Iteration:    660, Loss function: 5.739, Average Loss: 3.854, avg. samples / sec: 53751.37
Iteration:    660, Loss function: 6.064, Average Loss: 3.843, avg. samples / sec: 53709.29
Iteration:    660, Loss function: 5.295, Average Loss: 3.847, avg. samples / sec: 53636.25
Iteration:    660, Loss function: 5.472, Average Loss: 3.848, avg. samples / sec: 53632.60
Iteration:    660, Loss function: 5.327, Average Loss: 3.850, avg. samples / sec: 53695.62
Iteration:    660, Loss function: 5.858, Average Loss: 3.838, avg. samples / sec: 53668.98
Iteration:    660, Loss function: 5.217, Average Loss: 3.846, avg. samples / sec: 53648.04
Iteration:    660, Loss function: 4.266, Average Loss: 3.874, avg. samples / sec: 53621.07
Iteration:    660, Loss function: 5.486, Average Loss: 3.859, avg. samples / sec: 53648.48
Iteration:    660, Loss function: 4.783, Average Loss: 3.857, avg. samples / sec: 53580.85
Iteration:    660, Loss function: 5.464, Average Loss: 3.855, avg. samples / sec: 53469.85
Iteration:    660, Loss function: 6.643, Average Loss: 3.874, avg. samples / sec: 53817.18
Iteration:    660, Loss function: 6.831, Average Loss: 3.868, avg. samples / sec: 53700.08
Iteration:    660, Loss function: 5.520, Average Loss: 3.850, avg. samples / sec: 53334.64
Iteration:    660, Loss function: 6.879, Average Loss: 3.857, avg. samples / sec: 53675.97
Iteration:    660, Loss function: 5.616, Average Loss: 3.859, avg. samples / sec: 53710.09
Iteration:    660, Loss function: 7.095, Average Loss: 3.874, avg. samples / sec: 53604.92
Iteration:    660, Loss function: 5.590, Average Loss: 3.832, avg. samples / sec: 53725.73
Iteration:    660, Loss function: 4.735, Average Loss: 3.841, avg. samples / sec: 53415.27
Iteration:    660, Loss function: 6.645, Average Loss: 3.842, avg. samples / sec: 53705.81
Iteration:    660, Loss function: 4.948, Average Loss: 3.872, avg. samples / sec: 53704.93
Iteration:    660, Loss function: 4.511, Average Loss: 3.860, avg. samples / sec: 53653.39
Iteration:    660, Loss function: 7.233, Average Loss: 3.843, avg. samples / sec: 53470.95
Iteration:    680, Loss function: 6.306, Average Loss: 3.905, avg. samples / sec: 53489.39
Iteration:    680, Loss function: 6.265, Average Loss: 3.880, avg. samples / sec: 53504.40
Iteration:    680, Loss function: 5.179, Average Loss: 3.894, avg. samples / sec: 53695.97
Iteration:    680, Loss function: 4.632, Average Loss: 3.880, avg. samples / sec: 53453.22
Iteration:    680, Loss function: 6.383, Average Loss: 3.906, avg. samples / sec: 53400.11
Iteration:    680, Loss function: 5.522, Average Loss: 3.896, avg. samples / sec: 53683.61
Iteration:    680, Loss function: 6.793, Average Loss: 3.885, avg. samples / sec: 53291.72
Iteration:    680, Loss function: 5.348, Average Loss: 3.910, avg. samples / sec: 53677.91
Iteration:    680, Loss function: 4.011, Average Loss: 3.886, avg. samples / sec: 53417.99
Iteration:    680, Loss function: 5.046, Average Loss: 3.904, avg. samples / sec: 53483.16
Iteration:    680, Loss function: 4.528, Average Loss: 3.909, avg. samples / sec: 53685.33
Iteration:    680, Loss function: 5.566, Average Loss: 3.889, avg. samples / sec: 53474.72
Iteration:    680, Loss function: 4.904, Average Loss: 3.889, avg. samples / sec: 53394.13
Iteration:    680, Loss function: 5.305, Average Loss: 3.891, avg. samples / sec: 53466.87
Iteration:    680, Loss function: 4.939, Average Loss: 3.887, avg. samples / sec: 53472.47
Iteration:    680, Loss function: 5.500, Average Loss: 3.873, avg. samples / sec: 53419.53
Iteration:    680, Loss function: 4.877, Average Loss: 3.876, avg. samples / sec: 53357.17
Iteration:    680, Loss function: 6.283, Average Loss: 3.884, avg. samples / sec: 53316.31
Iteration:    680, Loss function: 6.918, Average Loss: 3.889, avg. samples / sec: 53336.57
Iteration:    680, Loss function: 6.042, Average Loss: 3.907, avg. samples / sec: 53473.73
Iteration:    680, Loss function: 6.520, Average Loss: 3.889, avg. samples / sec: 53006.63
Iteration:    680, Loss function: 6.210, Average Loss: 3.897, avg. samples / sec: 53456.12
Iteration:    680, Loss function: 4.768, Average Loss: 3.887, avg. samples / sec: 53429.13
Iteration:    680, Loss function: 5.055, Average Loss: 3.878, avg. samples / sec: 53448.94
Iteration:    680, Loss function: 6.507, Average Loss: 3.896, avg. samples / sec: 53465.57
Iteration:    680, Loss function: 5.815, Average Loss: 3.882, avg. samples / sec: 53619.23
Iteration:    680, Loss function: 7.198, Average Loss: 3.884, avg. samples / sec: 53437.43
Iteration:    680, Loss function: 4.189, Average Loss: 3.867, avg. samples / sec: 53397.02
Iteration:    680, Loss function: 7.458, Average Loss: 3.908, avg. samples / sec: 53273.63
Iteration:    680, Loss function: 6.090, Average Loss: 3.882, avg. samples / sec: 52631.16
:::MLL 1558640301.505 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558640301.506 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 5.862, Average Loss: 3.941, avg. samples / sec: 53043.98
Iteration:    700, Loss function: 6.563, Average Loss: 3.919, avg. samples / sec: 53079.96
Iteration:    700, Loss function: 6.071, Average Loss: 3.929, avg. samples / sec: 53395.97
Iteration:    700, Loss function: 6.837, Average Loss: 3.937, avg. samples / sec: 53240.46
Iteration:    700, Loss function: 5.549, Average Loss: 3.921, avg. samples / sec: 53205.26
Iteration:    700, Loss function: 4.664, Average Loss: 3.925, avg. samples / sec: 53222.28
Iteration:    700, Loss function: 5.663, Average Loss: 3.927, avg. samples / sec: 53204.44
Iteration:    700, Loss function: 6.841, Average Loss: 3.924, avg. samples / sec: 53331.18
Iteration:    700, Loss function: 5.775, Average Loss: 3.924, avg. samples / sec: 53180.97
Iteration:    700, Loss function: 5.367, Average Loss: 3.911, avg. samples / sec: 53181.75
Iteration:    700, Loss function: 5.876, Average Loss: 3.915, avg. samples / sec: 53183.28
Iteration:    700, Loss function: 5.904, Average Loss: 3.926, avg. samples / sec: 53103.44
Iteration:    700, Loss function: 5.693, Average Loss: 3.918, avg. samples / sec: 53267.38
Iteration:    700, Loss function: 5.223, Average Loss: 3.948, avg. samples / sec: 53034.25
Iteration:    700, Loss function: 5.669, Average Loss: 3.940, avg. samples / sec: 53304.01
Iteration:    700, Loss function: 6.263, Average Loss: 3.916, avg. samples / sec: 53869.90
Iteration:    700, Loss function: 5.833, Average Loss: 3.925, avg. samples / sec: 53265.87
Iteration:    700, Loss function: 7.195, Average Loss: 3.926, avg. samples / sec: 52999.95
Iteration:    700, Loss function: 5.925, Average Loss: 3.929, avg. samples / sec: 53202.31
Iteration:    700, Loss function: 6.353, Average Loss: 3.941, avg. samples / sec: 52960.53
Iteration:    700, Loss function: 5.653, Average Loss: 3.924, avg. samples / sec: 52960.79
Iteration:    700, Loss function: 6.213, Average Loss: 3.921, avg. samples / sec: 53046.33
Iteration:    700, Loss function: 5.123, Average Loss: 3.950, avg. samples / sec: 52958.74
Iteration:    700, Loss function: 5.629, Average Loss: 3.912, avg. samples / sec: 53161.89
Iteration:    700, Loss function: 5.584, Average Loss: 3.927, avg. samples / sec: 52740.02
Iteration:    700, Loss function: 5.929, Average Loss: 3.900, avg. samples / sec: 53161.39
Iteration:    700, Loss function: 5.197, Average Loss: 3.944, avg. samples / sec: 53026.97
Iteration:    700, Loss function: 5.803, Average Loss: 3.931, avg. samples / sec: 52838.87
Iteration:    700, Loss function: 6.331, Average Loss: 3.933, avg. samples / sec: 53100.18
Iteration:    700, Loss function: 6.288, Average Loss: 3.918, avg. samples / sec: 53037.49
Iteration:    720, Loss function: 5.098, Average Loss: 3.947, avg. samples / sec: 53372.97
Iteration:    720, Loss function: 4.605, Average Loss: 3.980, avg. samples / sec: 53587.86
Iteration:    720, Loss function: 6.480, Average Loss: 3.962, avg. samples / sec: 53747.64
Iteration:    720, Loss function: 5.692, Average Loss: 3.973, avg. samples / sec: 53301.01
Iteration:    720, Loss function: 5.652, Average Loss: 3.963, avg. samples / sec: 53603.92
Iteration:    720, Loss function: 5.975, Average Loss: 3.950, avg. samples / sec: 53466.20
Iteration:    720, Loss function: 5.683, Average Loss: 3.951, avg. samples / sec: 53526.02
Iteration:    720, Loss function: 4.979, Average Loss: 3.961, avg. samples / sec: 53267.79
Iteration:    720, Loss function: 6.030, Average Loss: 3.948, avg. samples / sec: 53454.68
Iteration:    720, Loss function: 6.189, Average Loss: 3.980, avg. samples / sec: 53229.76
Iteration:    720, Loss function: 6.256, Average Loss: 3.959, avg. samples / sec: 53464.33
Iteration:    720, Loss function: 5.902, Average Loss: 3.980, avg. samples / sec: 53513.30
Iteration:    720, Loss function: 4.618, Average Loss: 3.955, avg. samples / sec: 53484.64
Iteration:    720, Loss function: 6.394, Average Loss: 3.972, avg. samples / sec: 53470.99
Iteration:    720, Loss function: 5.172, Average Loss: 3.945, avg. samples / sec: 53316.82
Iteration:    720, Loss function: 4.887, Average Loss: 3.958, avg. samples / sec: 53171.94
Iteration:    720, Loss function: 5.063, Average Loss: 3.953, avg. samples / sec: 53203.50
Iteration:    720, Loss function: 5.646, Average Loss: 3.957, avg. samples / sec: 53337.64
Iteration:    720, Loss function: 6.007, Average Loss: 3.958, avg. samples / sec: 53265.37
Iteration:    720, Loss function: 5.408, Average Loss: 3.974, avg. samples / sec: 53243.58
Iteration:    720, Loss function: 4.618, Average Loss: 3.947, avg. samples / sec: 53093.00
Iteration:    720, Loss function: 5.589, Average Loss: 3.957, avg. samples / sec: 53238.97
Iteration:    720, Loss function: 4.303, Average Loss: 3.972, avg. samples / sec: 53376.23
Iteration:    720, Loss function: 4.295, Average Loss: 3.929, avg. samples / sec: 53333.55
Iteration:    720, Loss function: 5.718, Average Loss: 3.957, avg. samples / sec: 53185.45
Iteration:    720, Loss function: 5.820, Average Loss: 3.953, avg. samples / sec: 53408.94
Iteration:    720, Loss function: 5.068, Average Loss: 3.941, avg. samples / sec: 53259.03
Iteration:    720, Loss function: 4.552, Average Loss: 3.961, avg. samples / sec: 53332.01
Iteration:    720, Loss function: 5.374, Average Loss: 3.945, avg. samples / sec: 53007.96
Iteration:    720, Loss function: 5.914, Average Loss: 3.954, avg. samples / sec: 52540.04
Iteration:    740, Loss function: 5.628, Average Loss: 3.985, avg. samples / sec: 54857.36
Iteration:    740, Loss function: 6.132, Average Loss: 3.993, avg. samples / sec: 54042.74
Iteration:    740, Loss function: 5.921, Average Loss: 3.973, avg. samples / sec: 53725.86
Iteration:    740, Loss function: 6.995, Average Loss: 3.984, avg. samples / sec: 53895.88
Iteration:    740, Loss function: 5.198, Average Loss: 4.008, avg. samples / sec: 53744.81
Iteration:    740, Loss function: 6.290, Average Loss: 3.979, avg. samples / sec: 53738.31
Iteration:    740, Loss function: 5.257, Average Loss: 3.979, avg. samples / sec: 53713.14
Iteration:    740, Loss function: 6.497, Average Loss: 3.988, avg. samples / sec: 53901.94
Iteration:    740, Loss function: 5.170, Average Loss: 4.009, avg. samples / sec: 53459.02
Iteration:    740, Loss function: 5.696, Average Loss: 3.995, avg. samples / sec: 53468.47
Iteration:    740, Loss function: 5.196, Average Loss: 3.979, avg. samples / sec: 53449.55
Iteration:    740, Loss function: 6.539, Average Loss: 3.974, avg. samples / sec: 53744.89
Iteration:    740, Loss function: 7.192, Average Loss: 4.010, avg. samples / sec: 53453.48
Iteration:    740, Loss function: 4.880, Average Loss: 4.001, avg. samples / sec: 53687.36
Iteration:    740, Loss function: 5.752, Average Loss: 3.995, avg. samples / sec: 53239.94
Iteration:    740, Loss function: 6.155, Average Loss: 4.007, avg. samples / sec: 53573.62
Iteration:    740, Loss function: 5.271, Average Loss: 3.972, avg. samples / sec: 53693.17
Iteration:    740, Loss function: 5.944, Average Loss: 3.995, avg. samples / sec: 53280.82
Iteration:    740, Loss function: 6.214, Average Loss: 3.957, avg. samples / sec: 53549.84
Iteration:    740, Loss function: 5.504, Average Loss: 3.989, avg. samples / sec: 53311.84
Iteration:    740, Loss function: 6.593, Average Loss: 3.990, avg. samples / sec: 53279.87
Iteration:    740, Loss function: 6.702, Average Loss: 3.987, avg. samples / sec: 53259.94
Iteration:    740, Loss function: 6.095, Average Loss: 3.987, avg. samples / sec: 53165.04
Iteration:    740, Loss function: 5.021, Average Loss: 3.979, avg. samples / sec: 53083.12
Iteration:    740, Loss function: 7.069, Average Loss: 3.980, avg. samples / sec: 53350.71
Iteration:    740, Loss function: 5.010, Average Loss: 3.993, avg. samples / sec: 53357.37
Iteration:    740, Loss function: 4.862, Average Loss: 4.010, avg. samples / sec: 52861.43
Iteration:    740, Loss function: 6.115, Average Loss: 3.993, avg. samples / sec: 53017.91
Iteration:    740, Loss function: 5.834, Average Loss: 3.998, avg. samples / sec: 52807.61
Iteration:    740, Loss function: 5.444, Average Loss: 3.984, avg. samples / sec: 52964.18
Iteration:    760, Loss function: 6.026, Average Loss: 4.017, avg. samples / sec: 54912.64
Iteration:    760, Loss function: 5.092, Average Loss: 4.015, avg. samples / sec: 54720.42
Iteration:    760, Loss function: 5.133, Average Loss: 4.042, avg. samples / sec: 54060.86
Iteration:    760, Loss function: 4.670, Average Loss: 4.026, avg. samples / sec: 54424.04
Iteration:    760, Loss function: 5.251, Average Loss: 4.013, avg. samples / sec: 54026.15
Iteration:    760, Loss function: 6.203, Average Loss: 4.035, avg. samples / sec: 54454.79
Iteration:    760, Loss function: 6.400, Average Loss: 4.029, avg. samples / sec: 54984.07
Iteration:    760, Loss function: 5.469, Average Loss: 4.019, avg. samples / sec: 54501.50
Iteration:    760, Loss function: 5.530, Average Loss: 4.025, avg. samples / sec: 54581.73
Iteration:    760, Loss function: 6.424, Average Loss: 4.041, avg. samples / sec: 54273.91
Iteration:    760, Loss function: 4.927, Average Loss: 4.014, avg. samples / sec: 54256.32
Iteration:    760, Loss function: 5.153, Average Loss: 4.039, avg. samples / sec: 54091.63
Iteration:    760, Loss function: 6.203, Average Loss: 4.019, avg. samples / sec: 53637.34
Iteration:    760, Loss function: 5.054, Average Loss: 4.015, avg. samples / sec: 54029.59
Iteration:    760, Loss function: 5.546, Average Loss: 4.004, avg. samples / sec: 53780.64
Iteration:    760, Loss function: 4.812, Average Loss: 4.030, avg. samples / sec: 54150.52
Iteration:    760, Loss function: 7.230, Average Loss: 4.016, avg. samples / sec: 53784.15
Iteration:    760, Loss function: 5.349, Average Loss: 4.024, avg. samples / sec: 54427.60
Iteration:    760, Loss function: 4.830, Average Loss: 4.028, avg. samples / sec: 53657.94
Iteration:    760, Loss function: 5.578, Average Loss: 4.016, avg. samples / sec: 54416.75
Iteration:    760, Loss function: 5.434, Average Loss: 4.015, avg. samples / sec: 54037.25
Iteration:    760, Loss function: 6.582, Average Loss: 4.029, avg. samples / sec: 54737.21
Iteration:    760, Loss function: 5.675, Average Loss: 4.007, avg. samples / sec: 54147.42
Iteration:    760, Loss function: 4.161, Average Loss: 4.020, avg. samples / sec: 54845.23
Iteration:    760, Loss function: 4.971, Average Loss: 4.044, avg. samples / sec: 54667.21
Iteration:    760, Loss function: 6.900, Average Loss: 4.038, avg. samples / sec: 54122.01
Iteration:    760, Loss function: 5.645, Average Loss: 4.023, avg. samples / sec: 54422.03
Iteration:    760, Loss function: 6.450, Average Loss: 4.033, avg. samples / sec: 54023.58
Iteration:    760, Loss function: 5.868, Average Loss: 3.996, avg. samples / sec: 54178.14
Iteration:    760, Loss function: 6.414, Average Loss: 4.025, avg. samples / sec: 53842.75
:::MLL 1558640303.695 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558640303.696 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 5.624, Average Loss: 4.069, avg. samples / sec: 54251.41
Iteration:    780, Loss function: 5.408, Average Loss: 4.052, avg. samples / sec: 54219.77
Iteration:    780, Loss function: 5.203, Average Loss: 4.032, avg. samples / sec: 54261.29
Iteration:    780, Loss function: 5.161, Average Loss: 4.042, avg. samples / sec: 54097.30
Iteration:    780, Loss function: 4.400, Average Loss: 4.037, avg. samples / sec: 53834.46
Iteration:    780, Loss function: 6.452, Average Loss: 4.059, avg. samples / sec: 54079.18
Iteration:    780, Loss function: 5.923, Average Loss: 4.057, avg. samples / sec: 54020.93
Iteration:    780, Loss function: 4.740, Average Loss: 4.037, avg. samples / sec: 54023.50
Iteration:    780, Loss function: 5.079, Average Loss: 4.048, avg. samples / sec: 54027.56
Iteration:    780, Loss function: 3.751, Average Loss: 4.043, avg. samples / sec: 53957.10
Iteration:    780, Loss function: 5.219, Average Loss: 4.054, avg. samples / sec: 53990.53
Iteration:    780, Loss function: 4.410, Average Loss: 4.059, avg. samples / sec: 53974.23
Iteration:    780, Loss function: 5.776, Average Loss: 4.065, avg. samples / sec: 54221.33
Iteration:    780, Loss function: 5.928, Average Loss: 4.053, avg. samples / sec: 54068.02
Iteration:    780, Loss function: 5.401, Average Loss: 4.037, avg. samples / sec: 53987.36
Iteration:    780, Loss function: 5.084, Average Loss: 4.071, avg. samples / sec: 53960.57
Iteration:    780, Loss function: 5.943, Average Loss: 4.042, avg. samples / sec: 53618.77
Iteration:    780, Loss function: 5.600, Average Loss: 4.068, avg. samples / sec: 53675.25
Iteration:    780, Loss function: 4.640, Average Loss: 4.045, avg. samples / sec: 54054.93
Iteration:    780, Loss function: 5.753, Average Loss: 4.052, avg. samples / sec: 53906.62
Iteration:    780, Loss function: 5.037, Average Loss: 4.058, avg. samples / sec: 54064.91
Iteration:    780, Loss function: 4.576, Average Loss: 4.048, avg. samples / sec: 53771.14
Iteration:    780, Loss function: 5.107, Average Loss: 4.035, avg. samples / sec: 54052.57
Iteration:    780, Loss function: 6.287, Average Loss: 4.065, avg. samples / sec: 54075.40
Iteration:    780, Loss function: 4.684, Average Loss: 4.030, avg. samples / sec: 54026.65
Iteration:    780, Loss function: 5.637, Average Loss: 4.026, avg. samples / sec: 54035.80
Iteration:    780, Loss function: 5.924, Average Loss: 4.047, avg. samples / sec: 53996.40
Iteration:    780, Loss function: 5.268, Average Loss: 4.076, avg. samples / sec: 53984.57
Iteration:    780, Loss function: 5.784, Average Loss: 4.060, avg. samples / sec: 53977.46
Iteration:    780, Loss function: 4.594, Average Loss: 4.056, avg. samples / sec: 53854.83
Iteration:    800, Loss function: 6.439, Average Loss: 4.062, avg. samples / sec: 53985.71
Iteration:    800, Loss function: 4.851, Average Loss: 4.085, avg. samples / sec: 54174.41
Iteration:    800, Loss function: 5.823, Average Loss: 4.066, avg. samples / sec: 54139.20
Iteration:    800, Loss function: 5.410, Average Loss: 4.082, avg. samples / sec: 53944.40
Iteration:    800, Loss function: 4.786, Average Loss: 4.064, avg. samples / sec: 54162.94
Iteration:    800, Loss function: 5.482, Average Loss: 4.069, avg. samples / sec: 54069.95
Iteration:    800, Loss function: 5.209, Average Loss: 4.094, avg. samples / sec: 54219.25
Iteration:    800, Loss function: 4.427, Average Loss: 4.068, avg. samples / sec: 54267.87
Iteration:    800, Loss function: 6.114, Average Loss: 4.101, avg. samples / sec: 54110.97
Iteration:    800, Loss function: 4.977, Average Loss: 4.057, avg. samples / sec: 54270.80
Iteration:    800, Loss function: 5.682, Average Loss: 4.088, avg. samples / sec: 54022.61
Iteration:    800, Loss function: 5.481, Average Loss: 4.078, avg. samples / sec: 54028.76
Iteration:    800, Loss function: 4.597, Average Loss: 4.068, avg. samples / sec: 54013.77
Iteration:    800, Loss function: 5.985, Average Loss: 4.087, avg. samples / sec: 54191.14
Iteration:    800, Loss function: 5.637, Average Loss: 4.085, avg. samples / sec: 54026.52
Iteration:    800, Loss function: 4.813, Average Loss: 4.098, avg. samples / sec: 53758.05
Iteration:    800, Loss function: 4.258, Average Loss: 4.076, avg. samples / sec: 53969.03
Iteration:    800, Loss function: 5.098, Average Loss: 4.068, avg. samples / sec: 53949.96
Iteration:    800, Loss function: 5.000, Average Loss: 4.086, avg. samples / sec: 53972.37
Iteration:    800, Loss function: 5.655, Average Loss: 4.073, avg. samples / sec: 54042.37
Iteration:    800, Loss function: 4.960, Average Loss: 4.068, avg. samples / sec: 53977.25
Iteration:    800, Loss function: 4.763, Average Loss: 4.099, avg. samples / sec: 54088.25
Iteration:    800, Loss function: 5.805, Average Loss: 4.094, avg. samples / sec: 54015.77
Iteration:    800, Loss function: 5.687, Average Loss: 4.096, avg. samples / sec: 53855.06
Iteration:    800, Loss function: 5.097, Average Loss: 4.087, avg. samples / sec: 54229.57
Iteration:    800, Loss function: 5.254, Average Loss: 4.086, avg. samples / sec: 53985.73
Iteration:    800, Loss function: 6.564, Average Loss: 4.074, avg. samples / sec: 53980.44
Iteration:    800, Loss function: 4.362, Average Loss: 4.060, avg. samples / sec: 54006.05
Iteration:    800, Loss function: 5.789, Average Loss: 4.088, avg. samples / sec: 54050.99
Iteration:    800, Loss function: 5.154, Average Loss: 4.071, avg. samples / sec: 53994.19
Iteration:    820, Loss function: 5.086, Average Loss: 4.106, avg. samples / sec: 54732.32
Iteration:    820, Loss function: 5.661, Average Loss: 4.099, avg. samples / sec: 54920.58
Iteration:    820, Loss function: 4.819, Average Loss: 4.113, avg. samples / sec: 54519.67
Iteration:    820, Loss function: 5.235, Average Loss: 4.094, avg. samples / sec: 54661.52
Iteration:    820, Loss function: 6.671, Average Loss: 4.085, avg. samples / sec: 54436.76
Iteration:    820, Loss function: 5.344, Average Loss: 4.097, avg. samples / sec: 54432.28
Iteration:    820, Loss function: 5.908, Average Loss: 4.119, avg. samples / sec: 54786.37
Iteration:    820, Loss function: 4.959, Average Loss: 4.100, avg. samples / sec: 54466.22
Iteration:    820, Loss function: 6.247, Average Loss: 4.121, avg. samples / sec: 54598.61
Iteration:    820, Loss function: 5.929, Average Loss: 4.125, avg. samples / sec: 54516.55
Iteration:    820, Loss function: 4.876, Average Loss: 4.096, avg. samples / sec: 54491.19
Iteration:    820, Loss function: 5.837, Average Loss: 4.091, avg. samples / sec: 54533.64
Iteration:    820, Loss function: 5.741, Average Loss: 4.106, avg. samples / sec: 54389.56
Iteration:    820, Loss function: 6.384, Average Loss: 4.118, avg. samples / sec: 54581.90
Iteration:    820, Loss function: 5.478, Average Loss: 4.103, avg. samples / sec: 54559.06
Iteration:    820, Loss function: 5.168, Average Loss: 4.107, avg. samples / sec: 54494.92
Iteration:    820, Loss function: 6.106, Average Loss: 4.118, avg. samples / sec: 54449.21
Iteration:    820, Loss function: 5.549, Average Loss: 4.112, avg. samples / sec: 54491.97
Iteration:    820, Loss function: 5.512, Average Loss: 4.105, avg. samples / sec: 54466.43
Iteration:    820, Loss function: 5.828, Average Loss: 4.095, avg. samples / sec: 54490.84
Iteration:    820, Loss function: 5.191, Average Loss: 4.105, avg. samples / sec: 54470.39
Iteration:    820, Loss function: 5.057, Average Loss: 4.081, avg. samples / sec: 54282.96
Iteration:    820, Loss function: 5.368, Average Loss: 4.115, avg. samples / sec: 54524.99
Iteration:    820, Loss function: 4.549, Average Loss: 4.096, avg. samples / sec: 54252.87
Iteration:    820, Loss function: 5.299, Average Loss: 4.084, avg. samples / sec: 54548.58
Iteration:    820, Loss function: 4.168, Average Loss: 4.113, avg. samples / sec: 54505.15
Iteration:    820, Loss function: 5.260, Average Loss: 4.125, avg. samples / sec: 54463.25
Iteration:    820, Loss function: 5.379, Average Loss: 4.115, avg. samples / sec: 54525.88
Iteration:    820, Loss function: 6.371, Average Loss: 4.099, avg. samples / sec: 54523.83
Iteration:    820, Loss function: 5.535, Average Loss: 4.119, avg. samples / sec: 54439.88
:::MLL 1558640305.874 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558640305.875 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 4.727, Average Loss: 4.109, avg. samples / sec: 53394.21
Iteration:    840, Loss function: 5.532, Average Loss: 4.144, avg. samples / sec: 53366.38
Iteration:    840, Loss function: 4.413, Average Loss: 4.144, avg. samples / sec: 53362.04
Iteration:    840, Loss function: 4.957, Average Loss: 4.125, avg. samples / sec: 53332.70
Iteration:    840, Loss function: 5.107, Average Loss: 4.128, avg. samples / sec: 53373.24
Iteration:    840, Loss function: 5.181, Average Loss: 4.148, avg. samples / sec: 53347.44
Iteration:    840, Loss function: 5.376, Average Loss: 4.145, avg. samples / sec: 53325.05
Iteration:    840, Loss function: 4.311, Average Loss: 4.123, avg. samples / sec: 53147.04
Iteration:    840, Loss function: 4.086, Average Loss: 4.133, avg. samples / sec: 53137.14
Iteration:    840, Loss function: 4.274, Average Loss: 4.125, avg. samples / sec: 53183.44
Iteration:    840, Loss function: 5.085, Average Loss: 4.134, avg. samples / sec: 53198.34
Iteration:    840, Loss function: 4.849, Average Loss: 4.131, avg. samples / sec: 53212.44
Iteration:    840, Loss function: 4.938, Average Loss: 4.119, avg. samples / sec: 53179.75
Iteration:    840, Loss function: 5.660, Average Loss: 4.125, avg. samples / sec: 53184.96
Iteration:    840, Loss function: 5.610, Average Loss: 4.120, avg. samples / sec: 53350.69
Iteration:    840, Loss function: 4.467, Average Loss: 4.140, avg. samples / sec: 53109.42
Iteration:    840, Loss function: 5.848, Average Loss: 4.123, avg. samples / sec: 53342.04
Iteration:    840, Loss function: 5.684, Average Loss: 4.137, avg. samples / sec: 53186.33
Iteration:    840, Loss function: 5.467, Average Loss: 4.118, avg. samples / sec: 53053.98
Iteration:    840, Loss function: 4.691, Average Loss: 4.109, avg. samples / sec: 53128.46
Iteration:    840, Loss function: 4.654, Average Loss: 4.140, avg. samples / sec: 53363.68
Iteration:    840, Loss function: 5.551, Average Loss: 4.120, avg. samples / sec: 53315.87
Iteration:    840, Loss function: 4.888, Average Loss: 4.145, avg. samples / sec: 53335.02
Iteration:    840, Loss function: 4.154, Average Loss: 4.137, avg. samples / sec: 53257.60
Iteration:    840, Loss function: 4.837, Average Loss: 4.108, avg. samples / sec: 53238.47
Iteration:    840, Loss function: 4.878, Average Loss: 4.102, avg. samples / sec: 53191.99
Iteration:    840, Loss function: 5.561, Average Loss: 4.150, avg. samples / sec: 53216.09
Iteration:    840, Loss function: 4.833, Average Loss: 4.118, avg. samples / sec: 53234.91
Iteration:    840, Loss function: 6.080, Average Loss: 4.121, avg. samples / sec: 52808.38
Iteration:    840, Loss function: 5.190, Average Loss: 4.135, avg. samples / sec: 53205.53
Iteration:    860, Loss function: 5.381, Average Loss: 4.144, avg. samples / sec: 54513.50
Iteration:    860, Loss function: 6.371, Average Loss: 4.145, avg. samples / sec: 54160.90
Iteration:    860, Loss function: 5.882, Average Loss: 4.168, avg. samples / sec: 54122.07
Iteration:    860, Loss function: 5.706, Average Loss: 4.150, avg. samples / sec: 54179.04
Iteration:    860, Loss function: 5.282, Average Loss: 4.143, avg. samples / sec: 54253.66
Iteration:    860, Loss function: 5.345, Average Loss: 4.165, avg. samples / sec: 54282.71
Iteration:    860, Loss function: 5.276, Average Loss: 4.165, avg. samples / sec: 54020.74
Iteration:    860, Loss function: 6.637, Average Loss: 4.159, avg. samples / sec: 54156.45
Iteration:    860, Loss function: 4.582, Average Loss: 4.131, avg. samples / sec: 54285.81
Iteration:    860, Loss function: 4.113, Average Loss: 4.170, avg. samples / sec: 54063.46
Iteration:    860, Loss function: 4.297, Average Loss: 4.161, avg. samples / sec: 54198.23
Iteration:    860, Loss function: 4.187, Average Loss: 4.164, avg. samples / sec: 54245.88
Iteration:    860, Loss function: 6.611, Average Loss: 4.148, avg. samples / sec: 54199.56
Iteration:    860, Loss function: 5.228, Average Loss: 4.167, avg. samples / sec: 54047.45
Iteration:    860, Loss function: 3.694, Average Loss: 4.161, avg. samples / sec: 54172.19
Iteration:    860, Loss function: 4.349, Average Loss: 4.139, avg. samples / sec: 54223.71
Iteration:    860, Loss function: 5.699, Average Loss: 4.177, avg. samples / sec: 54385.40
Iteration:    860, Loss function: 6.071, Average Loss: 4.153, avg. samples / sec: 54091.20
Iteration:    860, Loss function: 5.214, Average Loss: 4.161, avg. samples / sec: 54150.85
Iteration:    860, Loss function: 5.826, Average Loss: 4.142, avg. samples / sec: 54296.95
Iteration:    860, Loss function: 4.515, Average Loss: 4.120, avg. samples / sec: 54239.78
Iteration:    860, Loss function: 5.539, Average Loss: 4.133, avg. samples / sec: 53730.38
Iteration:    860, Loss function: 5.816, Average Loss: 4.154, avg. samples / sec: 54163.25
Iteration:    860, Loss function: 6.144, Average Loss: 4.146, avg. samples / sec: 54057.54
Iteration:    860, Loss function: 5.389, Average Loss: 4.129, avg. samples / sec: 54193.95
Iteration:    860, Loss function: 4.705, Average Loss: 4.166, avg. samples / sec: 54154.30
Iteration:    860, Loss function: 4.171, Average Loss: 4.141, avg. samples / sec: 54104.09
Iteration:    860, Loss function: 5.101, Average Loss: 4.134, avg. samples / sec: 54220.48
Iteration:    860, Loss function: 4.892, Average Loss: 4.157, avg. samples / sec: 54228.30
Iteration:    860, Loss function: 5.237, Average Loss: 4.153, avg. samples / sec: 53826.84
Iteration:    880, Loss function: 5.714, Average Loss: 4.190, avg. samples / sec: 54300.97
Iteration:    880, Loss function: 6.245, Average Loss: 4.195, avg. samples / sec: 54198.85
Iteration:    880, Loss function: 4.714, Average Loss: 4.171, avg. samples / sec: 54001.70
Iteration:    880, Loss function: 4.793, Average Loss: 4.181, avg. samples / sec: 54164.19
Iteration:    880, Loss function: 3.653, Average Loss: 4.171, avg. samples / sec: 54123.40
Iteration:    880, Loss function: 4.745, Average Loss: 4.176, avg. samples / sec: 54102.47
Iteration:    880, Loss function: 5.337, Average Loss: 4.178, avg. samples / sec: 53961.09
Iteration:    880, Loss function: 5.350, Average Loss: 4.152, avg. samples / sec: 54038.87
Iteration:    880, Loss function: 5.426, Average Loss: 4.187, avg. samples / sec: 54063.52
Iteration:    880, Loss function: 5.587, Average Loss: 4.196, avg. samples / sec: 53899.73
Iteration:    880, Loss function: 4.661, Average Loss: 4.179, avg. samples / sec: 53995.53
Iteration:    880, Loss function: 6.002, Average Loss: 4.168, avg. samples / sec: 53965.90
Iteration:    880, Loss function: 4.611, Average Loss: 4.175, avg. samples / sec: 54242.79
Iteration:    880, Loss function: 4.277, Average Loss: 4.189, avg. samples / sec: 53951.13
Iteration:    880, Loss function: 4.595, Average Loss: 4.188, avg. samples / sec: 53991.75
Iteration:    880, Loss function: 4.439, Average Loss: 4.145, avg. samples / sec: 54046.25
Iteration:    880, Loss function: 5.648, Average Loss: 4.168, avg. samples / sec: 53980.77
Iteration:    880, Loss function: 4.198, Average Loss: 4.186, avg. samples / sec: 54020.41
Iteration:    880, Loss function: 4.654, Average Loss: 4.171, avg. samples / sec: 54031.80
Iteration:    880, Loss function: 5.778, Average Loss: 4.162, avg. samples / sec: 54035.91
Iteration:    880, Loss function: 3.773, Average Loss: 4.180, avg. samples / sec: 54041.96
Iteration:    880, Loss function: 5.309, Average Loss: 4.154, avg. samples / sec: 54001.29
Iteration:    880, Loss function: 5.494, Average Loss: 4.192, avg. samples / sec: 53808.96
Iteration:    880, Loss function: 4.370, Average Loss: 4.153, avg. samples / sec: 53985.94
Iteration:    880, Loss function: 5.538, Average Loss: 4.181, avg. samples / sec: 53986.66
Iteration:    880, Loss function: 4.768, Average Loss: 4.171, avg. samples / sec: 53514.89
Iteration:    880, Loss function: 5.504, Average Loss: 4.198, avg. samples / sec: 53786.00
Iteration:    880, Loss function: 5.088, Average Loss: 4.185, avg. samples / sec: 53488.24
Iteration:    880, Loss function: 4.835, Average Loss: 4.186, avg. samples / sec: 53571.95
Iteration:    880, Loss function: 6.270, Average Loss: 4.170, avg. samples / sec: 53296.96
Iteration:    900, Loss function: 5.743, Average Loss: 4.198, avg. samples / sec: 53818.98
Iteration:    900, Loss function: 6.024, Average Loss: 4.213, avg. samples / sec: 53931.60
Iteration:    900, Loss function: 5.488, Average Loss: 4.195, avg. samples / sec: 53656.33
Iteration:    900, Loss function: 5.648, Average Loss: 4.223, avg. samples / sec: 53765.23
Iteration:    900, Loss function: 5.190, Average Loss: 4.197, avg. samples / sec: 53664.11
Iteration:    900, Loss function: 4.907, Average Loss: 4.180, avg. samples / sec: 53681.75
Iteration:    900, Loss function: 5.721, Average Loss: 4.204, avg. samples / sec: 54198.87
Iteration:    900, Loss function: 3.890, Average Loss: 4.210, avg. samples / sec: 53358.30
Iteration:    900, Loss function: 3.852, Average Loss: 4.169, avg. samples / sec: 53609.63
Iteration:    900, Loss function: 3.741, Average Loss: 4.199, avg. samples / sec: 53629.21
Iteration:    900, Loss function: 4.172, Average Loss: 4.210, avg. samples / sec: 53434.05
Iteration:    900, Loss function: 5.418, Average Loss: 4.190, avg. samples / sec: 53825.31
Iteration:    900, Loss function: 3.892, Average Loss: 4.192, avg. samples / sec: 53518.85
Iteration:    900, Loss function: 3.781, Average Loss: 4.201, avg. samples / sec: 53609.71
Iteration:    900, Loss function: 6.719, Average Loss: 4.218, avg. samples / sec: 53857.01
Iteration:    900, Loss function: 5.075, Average Loss: 4.187, avg. samples / sec: 53750.92
Iteration:    900, Loss function: 5.229, Average Loss: 4.212, avg. samples / sec: 53535.64
Iteration:    900, Loss function: 5.209, Average Loss: 4.172, avg. samples / sec: 53706.04
Iteration:    900, Loss function: 4.747, Average Loss: 4.194, avg. samples / sec: 54381.79
Iteration:    900, Loss function: 5.307, Average Loss: 4.205, avg. samples / sec: 53652.34
Iteration:    900, Loss function: 4.628, Average Loss: 4.199, avg. samples / sec: 53447.58
Iteration:    900, Loss function: 5.110, Average Loss: 4.162, avg. samples / sec: 53579.75
Iteration:    900, Loss function: 4.056, Average Loss: 4.199, avg. samples / sec: 53992.76
Iteration:    900, Loss function: 4.518, Average Loss: 4.175, avg. samples / sec: 53627.19
Iteration:    900, Loss function: 4.755, Average Loss: 4.202, avg. samples / sec: 53628.05
Iteration:    900, Loss function: 4.659, Average Loss: 4.202, avg. samples / sec: 53609.08
Iteration:    900, Loss function: 4.979, Average Loss: 4.212, avg. samples / sec: 53618.66
Iteration:    900, Loss function: 5.341, Average Loss: 4.178, avg. samples / sec: 53600.47
Iteration:    900, Loss function: 6.325, Average Loss: 4.197, avg. samples / sec: 53056.38
Iteration:    900, Loss function: 3.999, Average Loss: 4.194, avg. samples / sec: 53046.03
:::MLL 1558640308.060 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558640308.060 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 4.955, Average Loss: 4.215, avg. samples / sec: 53409.73
Iteration:    920, Loss function: 4.781, Average Loss: 4.240, avg. samples / sec: 53420.66
Iteration:    920, Loss function: 4.528, Average Loss: 4.210, avg. samples / sec: 54274.85
Iteration:    920, Loss function: 6.435, Average Loss: 4.219, avg. samples / sec: 53204.06
Iteration:    920, Loss function: 4.983, Average Loss: 4.187, avg. samples / sec: 53426.47
Iteration:    920, Loss function: 5.451, Average Loss: 4.214, avg. samples / sec: 53473.24
Iteration:    920, Loss function: 5.652, Average Loss: 4.208, avg. samples / sec: 53463.97
Iteration:    920, Loss function: 5.770, Average Loss: 4.225, avg. samples / sec: 53495.38
Iteration:    920, Loss function: 4.476, Average Loss: 4.228, avg. samples / sec: 53078.82
Iteration:    920, Loss function: 4.448, Average Loss: 4.223, avg. samples / sec: 53314.06
Iteration:    920, Loss function: 4.386, Average Loss: 4.219, avg. samples / sec: 53511.63
Iteration:    920, Loss function: 5.775, Average Loss: 4.200, avg. samples / sec: 53501.19
Iteration:    920, Loss function: 4.886, Average Loss: 4.214, avg. samples / sec: 53471.31
Iteration:    920, Loss function: 4.303, Average Loss: 4.227, avg. samples / sec: 53199.52
Iteration:    920, Loss function: 4.547, Average Loss: 4.190, avg. samples / sec: 53301.73
Iteration:    920, Loss function: 4.204, Average Loss: 4.179, avg. samples / sec: 53337.14
Iteration:    920, Loss function: 4.475, Average Loss: 4.214, avg. samples / sec: 53068.96
Iteration:    920, Loss function: 5.051, Average Loss: 4.204, avg. samples / sec: 53073.78
Iteration:    920, Loss function: 5.129, Average Loss: 4.230, avg. samples / sec: 52978.05
Iteration:    920, Loss function: 4.868, Average Loss: 4.210, avg. samples / sec: 53163.84
Iteration:    920, Loss function: 4.782, Average Loss: 4.214, avg. samples / sec: 53510.01
Iteration:    920, Loss function: 6.152, Average Loss: 4.233, avg. samples / sec: 53058.61
Iteration:    920, Loss function: 5.259, Average Loss: 4.192, avg. samples / sec: 53203.24
Iteration:    920, Loss function: 4.802, Average Loss: 4.215, avg. samples / sec: 52844.18
Iteration:    920, Loss function: 4.420, Average Loss: 4.211, avg. samples / sec: 53109.24
Iteration:    920, Loss function: 3.731, Average Loss: 4.199, avg. samples / sec: 52835.13
Iteration:    920, Loss function: 5.237, Average Loss: 4.203, avg. samples / sec: 52931.87
Iteration:    920, Loss function: 4.530, Average Loss: 4.231, avg. samples / sec: 52894.64
Iteration:    920, Loss function: 3.400, Average Loss: 4.216, avg. samples / sec: 53001.19
Iteration:    920, Loss function: 4.536, Average Loss: 4.229, avg. samples / sec: 52976.62
Iteration:    940, Loss function: 4.365, Average Loss: 4.240, avg. samples / sec: 54768.31
Iteration:    940, Loss function: 4.806, Average Loss: 4.241, avg. samples / sec: 54298.88
Iteration:    940, Loss function: 5.172, Average Loss: 4.232, avg. samples / sec: 54675.69
Iteration:    940, Loss function: 6.514, Average Loss: 4.229, avg. samples / sec: 54694.09
Iteration:    940, Loss function: 4.507, Average Loss: 4.212, avg. samples / sec: 54710.80
Iteration:    940, Loss function: 5.573, Average Loss: 4.231, avg. samples / sec: 53988.89
Iteration:    940, Loss function: 4.572, Average Loss: 4.253, avg. samples / sec: 53996.01
Iteration:    940, Loss function: 5.799, Average Loss: 4.242, avg. samples / sec: 54235.58
Iteration:    940, Loss function: 5.192, Average Loss: 4.225, avg. samples / sec: 54048.36
Iteration:    940, Loss function: 5.885, Average Loss: 4.242, avg. samples / sec: 54242.58
Iteration:    940, Loss function: 4.501, Average Loss: 4.250, avg. samples / sec: 54545.42
Iteration:    940, Loss function: 4.777, Average Loss: 4.223, avg. samples / sec: 54086.38
Iteration:    940, Loss function: 4.899, Average Loss: 4.214, avg. samples / sec: 54664.22
Iteration:    940, Loss function: 5.732, Average Loss: 4.228, avg. samples / sec: 54057.50
Iteration:    940, Loss function: 4.718, Average Loss: 4.230, avg. samples / sec: 54420.98
Iteration:    940, Loss function: 4.305, Average Loss: 4.244, avg. samples / sec: 54237.57
Iteration:    940, Loss function: 5.949, Average Loss: 4.206, avg. samples / sec: 53968.28
Iteration:    940, Loss function: 5.223, Average Loss: 4.223, avg. samples / sec: 54375.75
Iteration:    940, Loss function: 5.857, Average Loss: 4.245, avg. samples / sec: 54625.63
Iteration:    940, Loss function: 3.821, Average Loss: 4.204, avg. samples / sec: 54192.89
Iteration:    940, Loss function: 6.392, Average Loss: 4.199, avg. samples / sec: 54201.60
Iteration:    940, Loss function: 4.931, Average Loss: 4.224, avg. samples / sec: 54450.43
Iteration:    940, Loss function: 5.096, Average Loss: 4.241, avg. samples / sec: 53978.72
Iteration:    940, Loss function: 4.388, Average Loss: 4.209, avg. samples / sec: 54335.79
Iteration:    940, Loss function: 5.718, Average Loss: 4.240, avg. samples / sec: 54527.84
Iteration:    940, Loss function: 4.416, Average Loss: 4.234, avg. samples / sec: 54010.02
Iteration:    940, Loss function: 5.738, Average Loss: 4.229, avg. samples / sec: 54023.17
Iteration:    940, Loss function: 5.083, Average Loss: 4.221, avg. samples / sec: 54256.21
Iteration:    940, Loss function: 4.660, Average Loss: 4.217, avg. samples / sec: 53993.51
Iteration:    940, Loss function: 6.273, Average Loss: 4.249, avg. samples / sec: 54446.52
Iteration:    960, Loss function: 6.165, Average Loss: 4.265, avg. samples / sec: 53984.80
Iteration:    960, Loss function: 6.106, Average Loss: 4.272, avg. samples / sec: 54204.65
Iteration:    960, Loss function: 5.960, Average Loss: 4.257, avg. samples / sec: 54118.08
Iteration:    960, Loss function: 5.843, Average Loss: 4.258, avg. samples / sec: 54125.60
Iteration:    960, Loss function: 6.203, Average Loss: 4.233, avg. samples / sec: 54165.31
Iteration:    960, Loss function: 4.990, Average Loss: 4.249, avg. samples / sec: 54027.06
Iteration:    960, Loss function: 7.161, Average Loss: 4.243, avg. samples / sec: 54055.60
Iteration:    960, Loss function: 4.544, Average Loss: 4.266, avg. samples / sec: 54085.24
Iteration:    960, Loss function: 4.932, Average Loss: 4.234, avg. samples / sec: 53957.95
Iteration:    960, Loss function: 5.445, Average Loss: 4.256, avg. samples / sec: 53924.61
Iteration:    960, Loss function: 6.074, Average Loss: 4.278, avg. samples / sec: 53967.62
Iteration:    960, Loss function: 4.828, Average Loss: 4.270, avg. samples / sec: 54254.06
Iteration:    960, Loss function: 5.536, Average Loss: 4.265, avg. samples / sec: 53745.20
Iteration:    960, Loss function: 5.751, Average Loss: 4.256, avg. samples / sec: 54002.55
Iteration:    960, Loss function: 5.022, Average Loss: 4.243, avg. samples / sec: 53959.83
Iteration:    960, Loss function: 4.613, Average Loss: 4.266, avg. samples / sec: 53923.66
Iteration:    960, Loss function: 5.085, Average Loss: 4.262, avg. samples / sec: 53796.57
Iteration:    960, Loss function: 5.611, Average Loss: 4.264, avg. samples / sec: 53856.58
Iteration:    960, Loss function: 4.664, Average Loss: 4.251, avg. samples / sec: 54012.36
Iteration:    960, Loss function: 6.526, Average Loss: 4.230, avg. samples / sec: 54029.90
Iteration:    960, Loss function: 4.573, Average Loss: 4.255, avg. samples / sec: 54057.94
Iteration:    960, Loss function: 4.056, Average Loss: 4.231, avg. samples / sec: 54003.50
Iteration:    960, Loss function: 6.316, Average Loss: 4.247, avg. samples / sec: 54032.61
Iteration:    960, Loss function: 5.317, Average Loss: 4.249, avg. samples / sec: 53994.31
Iteration:    960, Loss function: 7.835, Average Loss: 4.264, avg. samples / sec: 53999.51
Iteration:    960, Loss function: 4.459, Average Loss: 4.268, avg. samples / sec: 53944.59
Iteration:    960, Loss function: 6.659, Average Loss: 4.237, avg. samples / sec: 53989.04
Iteration:    960, Loss function: 5.386, Average Loss: 4.255, avg. samples / sec: 53983.99
Iteration:    960, Loss function: 5.346, Average Loss: 4.239, avg. samples / sec: 53990.90
Iteration:    960, Loss function: 6.441, Average Loss: 4.273, avg. samples / sec: 53957.16
:::MLL 1558640310.243 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558640310.244 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 5.324, Average Loss: 4.284, avg. samples / sec: 53827.25
Iteration:    980, Loss function: 4.874, Average Loss: 4.293, avg. samples / sec: 53753.03
Iteration:    980, Loss function: 5.806, Average Loss: 4.278, avg. samples / sec: 53631.60
Iteration:    980, Loss function: 5.586, Average Loss: 4.292, avg. samples / sec: 53495.08
Iteration:    980, Loss function: 4.384, Average Loss: 4.275, avg. samples / sec: 53529.60
Iteration:    980, Loss function: 6.189, Average Loss: 4.284, avg. samples / sec: 53705.52
Iteration:    980, Loss function: 5.513, Average Loss: 4.250, avg. samples / sec: 53585.96
Iteration:    980, Loss function: 6.315, Average Loss: 4.292, avg. samples / sec: 53685.78
Iteration:    980, Loss function: 5.603, Average Loss: 4.276, avg. samples / sec: 53659.23
Iteration:    980, Loss function: 4.371, Average Loss: 4.274, avg. samples / sec: 53560.53
Iteration:    980, Loss function: 3.974, Average Loss: 4.254, avg. samples / sec: 53545.32
Iteration:    980, Loss function: 5.936, Average Loss: 4.276, avg. samples / sec: 53702.29
Iteration:    980, Loss function: 4.771, Average Loss: 4.290, avg. samples / sec: 53311.01
Iteration:    980, Loss function: 4.331, Average Loss: 4.279, avg. samples / sec: 53634.72
Iteration:    980, Loss function: 4.601, Average Loss: 4.280, avg. samples / sec: 53480.85
Iteration:    980, Loss function: 3.541, Average Loss: 4.270, avg. samples / sec: 53712.75
Iteration:    980, Loss function: 4.918, Average Loss: 4.288, avg. samples / sec: 53520.86
Iteration:    980, Loss function: 4.877, Average Loss: 4.274, avg. samples / sec: 53461.82
Iteration:    980, Loss function: 3.923, Average Loss: 4.264, avg. samples / sec: 53532.20
Iteration:    980, Loss function: 6.752, Average Loss: 4.251, avg. samples / sec: 53645.52
Iteration:    980, Loss function: 3.789, Average Loss: 4.290, avg. samples / sec: 53700.18
Iteration:    980, Loss function: 5.305, Average Loss: 4.283, avg. samples / sec: 53682.31
Iteration:    980, Loss function: 3.938, Average Loss: 4.273, avg. samples / sec: 53691.33
Iteration:    980, Loss function: 4.665, Average Loss: 4.265, avg. samples / sec: 53386.50
Iteration:    980, Loss function: 4.314, Average Loss: 4.276, avg. samples / sec: 53537.61
Iteration:    980, Loss function: 5.588, Average Loss: 4.269, avg. samples / sec: 53536.82
Iteration:    980, Loss function: 5.598, Average Loss: 4.248, avg. samples / sec: 53483.14
Iteration:    980, Loss function: 3.565, Average Loss: 4.259, avg. samples / sec: 53555.64
Iteration:    980, Loss function: 4.535, Average Loss: 4.289, avg. samples / sec: 53568.06
Iteration:    980, Loss function: 5.530, Average Loss: 4.260, avg. samples / sec: 53506.43
Iteration:   1000, Loss function: 4.663, Average Loss: 4.293, avg. samples / sec: 54308.50
Iteration:   1000, Loss function: 5.667, Average Loss: 4.296, avg. samples / sec: 54129.07
Iteration:   1000, Loss function: 4.543, Average Loss: 4.299, avg. samples / sec: 54438.07
Iteration:   1000, Loss function: 4.975, Average Loss: 4.293, avg. samples / sec: 54117.45
Iteration:   1000, Loss function: 4.637, Average Loss: 4.311, avg. samples / sec: 54067.75
Iteration:   1000, Loss function: 6.341, Average Loss: 4.260, avg. samples / sec: 54508.56
Iteration:   1000, Loss function: 4.176, Average Loss: 4.306, avg. samples / sec: 54125.87
Iteration:   1000, Loss function: 4.868, Average Loss: 4.293, avg. samples / sec: 54285.16
Iteration:   1000, Loss function: 5.305, Average Loss: 4.283, avg. samples / sec: 54301.77
Iteration:   1000, Loss function: 5.999, Average Loss: 4.296, avg. samples / sec: 54254.06
Iteration:   1000, Loss function: 3.509, Average Loss: 4.294, avg. samples / sec: 54239.97
Iteration:   1000, Loss function: 5.465, Average Loss: 4.287, avg. samples / sec: 54136.23
Iteration:   1000, Loss function: 6.589, Average Loss: 4.303, avg. samples / sec: 54240.09
Iteration:   1000, Loss function: 5.668, Average Loss: 4.271, avg. samples / sec: 54190.02
Iteration:   1000, Loss function: 5.260, Average Loss: 4.299, avg. samples / sec: 54101.64
Iteration:   1000, Loss function: 4.820, Average Loss: 4.266, avg. samples / sec: 54072.71
Iteration:   1000, Loss function: 3.243, Average Loss: 4.289, avg. samples / sec: 54158.17
Iteration:   1000, Loss function: 4.013, Average Loss: 4.296, avg. samples / sec: 54022.61
Iteration:   1000, Loss function: 4.951, Average Loss: 4.293, avg. samples / sec: 54170.44
Iteration:   1000, Loss function: 5.618, Average Loss: 4.294, avg. samples / sec: 54055.08
Iteration:   1000, Loss function: 4.890, Average Loss: 4.268, avg. samples / sec: 54108.66
Iteration:   1000, Loss function: 4.803, Average Loss: 4.281, avg. samples / sec: 54072.42
Iteration:   1000, Loss function: 6.073, Average Loss: 4.309, avg. samples / sec: 54105.38
Iteration:   1000, Loss function: 5.551, Average Loss: 4.289, avg. samples / sec: 54226.34
Iteration:   1000, Loss function: 5.270, Average Loss: 4.305, avg. samples / sec: 54234.27
Iteration:   1000, Loss function: 4.883, Average Loss: 4.273, avg. samples / sec: 54284.87
Iteration:   1000, Loss function: 4.069, Average Loss: 4.277, avg. samples / sec: 54098.86
Iteration:   1000, Loss function: 6.065, Average Loss: 4.292, avg. samples / sec: 54140.32
Iteration:   1000, Loss function: 5.683, Average Loss: 4.311, avg. samples / sec: 53862.55
Iteration:   1000, Loss function: 3.845, Average Loss: 4.271, avg. samples / sec: 54041.09
Iteration:   1020, Loss function: 4.974, Average Loss: 4.305, avg. samples / sec: 54424.89
Iteration:   1020, Loss function: 5.745, Average Loss: 4.308, avg. samples / sec: 54455.23
Iteration:   1020, Loss function: 6.864, Average Loss: 4.311, avg. samples / sec: 54525.66
Iteration:   1020, Loss function: 4.973, Average Loss: 4.308, avg. samples / sec: 54404.99
Iteration:   1020, Loss function: 4.433, Average Loss: 4.304, avg. samples / sec: 54445.05
Iteration:   1020, Loss function: 4.499, Average Loss: 4.281, avg. samples / sec: 54478.77
Iteration:   1020, Loss function: 5.365, Average Loss: 4.313, avg. samples / sec: 54489.61
Iteration:   1020, Loss function: 3.611, Average Loss: 4.318, avg. samples / sec: 54451.93
Iteration:   1020, Loss function: 5.509, Average Loss: 4.328, avg. samples / sec: 54371.82
Iteration:   1020, Loss function: 4.058, Average Loss: 4.303, avg. samples / sec: 54475.08
Iteration:   1020, Loss function: 3.776, Average Loss: 4.310, avg. samples / sec: 54418.60
Iteration:   1020, Loss function: 3.593, Average Loss: 4.292, avg. samples / sec: 54403.67
Iteration:   1020, Loss function: 4.270, Average Loss: 4.309, avg. samples / sec: 54482.68
Iteration:   1020, Loss function: 4.596, Average Loss: 4.299, avg. samples / sec: 54422.15
Iteration:   1020, Loss function: 4.100, Average Loss: 4.321, avg. samples / sec: 54345.20
Iteration:   1020, Loss function: 5.208, Average Loss: 4.295, avg. samples / sec: 54623.09
Iteration:   1020, Loss function: 5.149, Average Loss: 4.291, avg. samples / sec: 54473.73
Iteration:   1020, Loss function: 6.026, Average Loss: 4.282, avg. samples / sec: 54452.94
Iteration:   1020, Loss function: 4.567, Average Loss: 4.312, avg. samples / sec: 54420.58
Iteration:   1020, Loss function: 4.464, Average Loss: 4.317, avg. samples / sec: 54487.61
Iteration:   1020, Loss function: 4.629, Average Loss: 4.271, avg. samples / sec: 54176.81
Iteration:   1020, Loss function: 5.505, Average Loss: 4.309, avg. samples / sec: 54106.86
Iteration:   1020, Loss function: 4.928, Average Loss: 4.326, avg. samples / sec: 54423.98
Iteration:   1020, Loss function: 6.044, Average Loss: 4.307, avg. samples / sec: 54364.78
Iteration:   1020, Loss function: 4.610, Average Loss: 4.303, avg. samples / sec: 54423.96
Iteration:   1020, Loss function: 5.326, Average Loss: 4.282, avg. samples / sec: 54624.43
Iteration:   1020, Loss function: 4.053, Average Loss: 4.301, avg. samples / sec: 54456.60
Iteration:   1020, Loss function: 5.207, Average Loss: 4.324, avg. samples / sec: 54565.21
Iteration:   1020, Loss function: 4.373, Average Loss: 4.281, avg. samples / sec: 54222.96
Iteration:   1020, Loss function: 4.402, Average Loss: 4.285, avg. samples / sec: 54276.44
Iteration:   1040, Loss function: 4.379, Average Loss: 4.320, avg. samples / sec: 53834.65
Iteration:   1040, Loss function: 5.770, Average Loss: 4.314, avg. samples / sec: 54030.46
Iteration:   1040, Loss function: 5.811, Average Loss: 4.318, avg. samples / sec: 53836.69
Iteration:   1040, Loss function: 4.833, Average Loss: 4.332, avg. samples / sec: 53857.84
Iteration:   1040, Loss function: 4.121, Average Loss: 4.321, avg. samples / sec: 53853.95
Iteration:   1040, Loss function: 4.978, Average Loss: 4.336, avg. samples / sec: 53839.17
Iteration:   1040, Loss function: 5.368, Average Loss: 4.321, avg. samples / sec: 53801.40
Iteration:   1040, Loss function: 5.258, Average Loss: 4.324, avg. samples / sec: 53685.82
Iteration:   1040, Loss function: 4.667, Average Loss: 4.328, avg. samples / sec: 53808.28
Iteration:   1040, Loss function: 5.562, Average Loss: 4.335, avg. samples / sec: 53862.24
Iteration:   1040, Loss function: 4.899, Average Loss: 4.288, avg. samples / sec: 53794.95
Iteration:   1040, Loss function: 4.807, Average Loss: 4.318, avg. samples / sec: 53816.93
Iteration:   1040, Loss function: 6.537, Average Loss: 4.324, avg. samples / sec: 53708.92
Iteration:   1040, Loss function: 5.560, Average Loss: 4.306, avg. samples / sec: 53800.66
Iteration:   1040, Loss function: 4.160, Average Loss: 4.311, avg. samples / sec: 53802.67
Iteration:   1040, Loss function: 4.962, Average Loss: 4.323, avg. samples / sec: 53789.73
Iteration:   1040, Loss function: 4.938, Average Loss: 4.291, avg. samples / sec: 54008.26
Iteration:   1040, Loss function: 5.074, Average Loss: 4.330, avg. samples / sec: 53889.04
Iteration:   1040, Loss function: 3.841, Average Loss: 4.296, avg. samples / sec: 53837.94
Iteration:   1040, Loss function: 5.157, Average Loss: 4.288, avg. samples / sec: 53844.75
Iteration:   1040, Loss function: 5.000, Average Loss: 4.326, avg. samples / sec: 53813.54
Iteration:   1040, Loss function: 3.920, Average Loss: 4.302, avg. samples / sec: 53775.26
Iteration:   1040, Loss function: 4.778, Average Loss: 4.319, avg. samples / sec: 53852.20
Iteration:   1040, Loss function: 5.958, Average Loss: 4.344, avg. samples / sec: 53826.61
Iteration:   1040, Loss function: 5.311, Average Loss: 4.334, avg. samples / sec: 53868.01
Iteration:   1040, Loss function: 4.088, Average Loss: 4.304, avg. samples / sec: 53989.47
Iteration:   1040, Loss function: 4.829, Average Loss: 4.326, avg. samples / sec: 53797.12
Iteration:   1040, Loss function: 3.514, Average Loss: 4.299, avg. samples / sec: 53811.46
Iteration:   1040, Loss function: 4.220, Average Loss: 4.308, avg. samples / sec: 53810.56
Iteration:   1040, Loss function: 4.961, Average Loss: 4.323, avg. samples / sec: 53793.26
:::MLL 1558640312.417 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558640312.418 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 4.532, Average Loss: 4.327, avg. samples / sec: 54088.67
Iteration:   1060, Loss function: 4.792, Average Loss: 4.337, avg. samples / sec: 54309.61
Iteration:   1060, Loss function: 5.057, Average Loss: 4.330, avg. samples / sec: 54299.72
Iteration:   1060, Loss function: 3.622, Average Loss: 4.295, avg. samples / sec: 54221.96
Iteration:   1060, Loss function: 5.496, Average Loss: 4.343, avg. samples / sec: 54182.35
Iteration:   1060, Loss function: 3.181, Average Loss: 4.345, avg. samples / sec: 54205.21
Iteration:   1060, Loss function: 4.916, Average Loss: 4.329, avg. samples / sec: 54245.37
Iteration:   1060, Loss function: 4.276, Average Loss: 4.351, avg. samples / sec: 54176.89
Iteration:   1060, Loss function: 4.699, Average Loss: 4.331, avg. samples / sec: 54178.66
Iteration:   1060, Loss function: 4.527, Average Loss: 4.346, avg. samples / sec: 54179.33
Iteration:   1060, Loss function: 4.419, Average Loss: 4.332, avg. samples / sec: 54191.14
Iteration:   1060, Loss function: 4.078, Average Loss: 4.325, avg. samples / sec: 54126.91
Iteration:   1060, Loss function: 4.794, Average Loss: 4.322, avg. samples / sec: 54203.83
Iteration:   1060, Loss function: 5.300, Average Loss: 4.304, avg. samples / sec: 54224.06
Iteration:   1060, Loss function: 4.446, Average Loss: 4.335, avg. samples / sec: 54185.64
Iteration:   1060, Loss function: 4.997, Average Loss: 4.313, avg. samples / sec: 54162.07
Iteration:   1060, Loss function: 4.237, Average Loss: 4.299, avg. samples / sec: 54202.33
Iteration:   1060, Loss function: 4.612, Average Loss: 4.328, avg. samples / sec: 54216.99
Iteration:   1060, Loss function: 5.223, Average Loss: 4.340, avg. samples / sec: 54198.91
Iteration:   1060, Loss function: 4.883, Average Loss: 4.308, avg. samples / sec: 54165.09
Iteration:   1060, Loss function: 4.899, Average Loss: 4.344, avg. samples / sec: 54193.00
Iteration:   1060, Loss function: 4.625, Average Loss: 4.320, avg. samples / sec: 54221.56
Iteration:   1060, Loss function: 4.934, Average Loss: 4.312, avg. samples / sec: 54164.09
Iteration:   1060, Loss function: 5.382, Average Loss: 4.342, avg. samples / sec: 54076.96
Iteration:   1060, Loss function: 5.159, Average Loss: 4.318, avg. samples / sec: 54187.58
Iteration:   1060, Loss function: 5.684, Average Loss: 4.337, avg. samples / sec: 54185.43
Iteration:   1060, Loss function: 5.215, Average Loss: 4.349, avg. samples / sec: 54158.40
Iteration:   1060, Loss function: 5.568, Average Loss: 4.320, avg. samples / sec: 53803.04
Iteration:   1060, Loss function: 4.650, Average Loss: 4.340, avg. samples / sec: 54170.44
Iteration:   1060, Loss function: 4.446, Average Loss: 4.308, avg. samples / sec: 53650.10
Iteration:   1080, Loss function: 3.862, Average Loss: 4.321, avg. samples / sec: 54564.68
Iteration:   1080, Loss function: 5.569, Average Loss: 4.354, avg. samples / sec: 54308.27
Iteration:   1080, Loss function: 4.941, Average Loss: 4.338, avg. samples / sec: 54391.38
Iteration:   1080, Loss function: 5.216, Average Loss: 4.340, avg. samples / sec: 54381.52
Iteration:   1080, Loss function: 4.469, Average Loss: 4.332, avg. samples / sec: 54357.29
Iteration:   1080, Loss function: 5.227, Average Loss: 4.353, avg. samples / sec: 54307.35
Iteration:   1080, Loss function: 3.848, Average Loss: 4.336, avg. samples / sec: 54190.08
Iteration:   1080, Loss function: 4.737, Average Loss: 4.337, avg. samples / sec: 54169.85
Iteration:   1080, Loss function: 4.577, Average Loss: 4.309, avg. samples / sec: 54263.21
Iteration:   1080, Loss function: 4.896, Average Loss: 4.350, avg. samples / sec: 54294.78
Iteration:   1080, Loss function: 5.008, Average Loss: 4.318, avg. samples / sec: 54317.46
Iteration:   1080, Loss function: 3.492, Average Loss: 4.344, avg. samples / sec: 54271.63
Iteration:   1080, Loss function: 3.933, Average Loss: 4.350, avg. samples / sec: 54306.43
Iteration:   1080, Loss function: 5.653, Average Loss: 4.356, avg. samples / sec: 54251.20
Iteration:   1080, Loss function: 4.767, Average Loss: 4.343, avg. samples / sec: 54223.56
Iteration:   1080, Loss function: 5.280, Average Loss: 4.356, avg. samples / sec: 54307.79
Iteration:   1080, Loss function: 4.218, Average Loss: 4.339, avg. samples / sec: 54263.50
Iteration:   1080, Loss function: 5.811, Average Loss: 4.348, avg. samples / sec: 54263.36
Iteration:   1080, Loss function: 4.588, Average Loss: 4.319, avg. samples / sec: 54265.68
Iteration:   1080, Loss function: 4.614, Average Loss: 4.308, avg. samples / sec: 54255.61
Iteration:   1080, Loss function: 5.378, Average Loss: 4.315, avg. samples / sec: 54304.44
Iteration:   1080, Loss function: 4.385, Average Loss: 4.354, avg. samples / sec: 54295.43
Iteration:   1080, Loss function: 4.527, Average Loss: 4.334, avg. samples / sec: 54279.28
Iteration:   1080, Loss function: 5.202, Average Loss: 4.320, avg. samples / sec: 54848.91
Iteration:   1080, Loss function: 3.907, Average Loss: 4.332, avg. samples / sec: 54283.19
Iteration:   1080, Loss function: 4.731, Average Loss: 4.362, avg. samples / sec: 54040.34
Iteration:   1080, Loss function: 5.686, Average Loss: 4.348, avg. samples / sec: 54327.49
Iteration:   1080, Loss function: 6.019, Average Loss: 4.358, avg. samples / sec: 54276.67
Iteration:   1080, Loss function: 4.698, Average Loss: 4.348, avg. samples / sec: 54261.48
Iteration:   1080, Loss function: 4.961, Average Loss: 4.331, avg. samples / sec: 54203.13
Iteration:   1100, Loss function: 6.358, Average Loss: 4.363, avg. samples / sec: 54595.18
Iteration:   1100, Loss function: 5.934, Average Loss: 4.359, avg. samples / sec: 54636.28
Iteration:   1100, Loss function: 6.553, Average Loss: 4.358, avg. samples / sec: 54480.94
Iteration:   1100, Loss function: 6.458, Average Loss: 4.373, avg. samples / sec: 54541.17
Iteration:   1100, Loss function: 5.287, Average Loss: 4.352, avg. samples / sec: 54542.15
Iteration:   1100, Loss function: 5.186, Average Loss: 4.366, avg. samples / sec: 54588.86
Iteration:   1100, Loss function: 6.744, Average Loss: 4.333, avg. samples / sec: 54323.60
Iteration:   1100, Loss function: 4.755, Average Loss: 4.338, avg. samples / sec: 54524.95
Iteration:   1100, Loss function: 5.127, Average Loss: 4.368, avg. samples / sec: 54521.76
Iteration:   1100, Loss function: 4.836, Average Loss: 4.378, avg. samples / sec: 54762.46
Iteration:   1100, Loss function: 5.171, Average Loss: 4.365, avg. samples / sec: 54473.33
Iteration:   1100, Loss function: 5.049, Average Loss: 4.346, avg. samples / sec: 54387.16
Iteration:   1100, Loss function: 5.505, Average Loss: 4.336, avg. samples / sec: 54573.45
Iteration:   1100, Loss function: 5.094, Average Loss: 4.358, avg. samples / sec: 54569.35
Iteration:   1100, Loss function: 4.666, Average Loss: 4.347, avg. samples / sec: 54700.90
Iteration:   1100, Loss function: 5.398, Average Loss: 4.370, avg. samples / sec: 54580.65
Iteration:   1100, Loss function: 5.732, Average Loss: 4.354, avg. samples / sec: 54560.35
Iteration:   1100, Loss function: 6.514, Average Loss: 4.374, avg. samples / sec: 54535.58
Iteration:   1100, Loss function: 5.518, Average Loss: 4.322, avg. samples / sec: 54555.43
Iteration:   1100, Loss function: 5.769, Average Loss: 4.338, avg. samples / sec: 54564.66
Iteration:   1100, Loss function: 6.140, Average Loss: 4.357, avg. samples / sec: 54544.74
Iteration:   1100, Loss function: 5.255, Average Loss: 4.368, avg. samples / sec: 54559.02
Iteration:   1100, Loss function: 5.877, Average Loss: 4.365, avg. samples / sec: 54558.95
Iteration:   1100, Loss function: 5.892, Average Loss: 4.346, avg. samples / sec: 54520.48
Iteration:   1100, Loss function: 5.776, Average Loss: 4.352, avg. samples / sec: 54254.81
Iteration:   1100, Loss function: 6.379, Average Loss: 4.325, avg. samples / sec: 54252.14
Iteration:   1100, Loss function: 6.101, Average Loss: 4.356, avg. samples / sec: 54133.69
Iteration:   1100, Loss function: 5.337, Average Loss: 4.363, avg. samples / sec: 54443.89
Iteration:   1100, Loss function: 6.128, Average Loss: 4.374, avg. samples / sec: 53991.77
Iteration:   1100, Loss function: 5.743, Average Loss: 4.332, avg. samples / sec: 54306.24
:::MLL 1558640314.590 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558640314.591 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 5.467, Average Loss: 4.367, avg. samples / sec: 53402.04
Iteration:   1120, Loss function: 3.970, Average Loss: 4.352, avg. samples / sec: 53429.92
Iteration:   1120, Loss function: 3.761, Average Loss: 4.382, avg. samples / sec: 53434.90
Iteration:   1120, Loss function: 5.445, Average Loss: 4.368, avg. samples / sec: 53656.84
Iteration:   1120, Loss function: 5.734, Average Loss: 4.378, avg. samples / sec: 53322.35
Iteration:   1120, Loss function: 5.472, Average Loss: 4.377, avg. samples / sec: 53309.30
Iteration:   1120, Loss function: 4.265, Average Loss: 4.393, avg. samples / sec: 53722.76
Iteration:   1120, Loss function: 4.710, Average Loss: 4.389, avg. samples / sec: 53292.77
Iteration:   1120, Loss function: 5.664, Average Loss: 4.340, avg. samples / sec: 53576.73
Iteration:   1120, Loss function: 3.484, Average Loss: 4.356, avg. samples / sec: 53307.10
Iteration:   1120, Loss function: 5.332, Average Loss: 4.373, avg. samples / sec: 53606.28
Iteration:   1120, Loss function: 4.901, Average Loss: 4.353, avg. samples / sec: 53433.54
Iteration:   1120, Loss function: 5.749, Average Loss: 4.386, avg. samples / sec: 53321.94
Iteration:   1120, Loss function: 4.936, Average Loss: 4.398, avg. samples / sec: 53263.14
Iteration:   1120, Loss function: 5.974, Average Loss: 4.379, avg. samples / sec: 53190.18
Iteration:   1120, Loss function: 6.576, Average Loss: 4.363, avg. samples / sec: 53326.97
Iteration:   1120, Loss function: 3.951, Average Loss: 4.381, avg. samples / sec: 53446.67
Iteration:   1120, Loss function: 5.879, Average Loss: 4.389, avg. samples / sec: 53391.96
Iteration:   1120, Loss function: 3.666, Average Loss: 4.348, avg. samples / sec: 53620.95
Iteration:   1120, Loss function: 4.886, Average Loss: 4.373, avg. samples / sec: 53330.54
Iteration:   1120, Loss function: 3.724, Average Loss: 4.378, avg. samples / sec: 53400.66
Iteration:   1120, Loss function: 4.453, Average Loss: 4.378, avg. samples / sec: 53426.41
Iteration:   1120, Loss function: 4.049, Average Loss: 4.335, avg. samples / sec: 53269.64
Iteration:   1120, Loss function: 4.851, Average Loss: 4.387, avg. samples / sec: 53240.84
Iteration:   1120, Loss function: 4.078, Average Loss: 4.368, avg. samples / sec: 53231.63
Iteration:   1120, Loss function: 4.837, Average Loss: 4.364, avg. samples / sec: 53211.01
Iteration:   1120, Loss function: 4.673, Average Loss: 4.364, avg. samples / sec: 53269.20
Iteration:   1120, Loss function: 3.448, Average Loss: 4.368, avg. samples / sec: 53229.94
Iteration:   1120, Loss function: 4.229, Average Loss: 4.361, avg. samples / sec: 53190.04
Iteration:   1120, Loss function: 6.588, Average Loss: 4.382, avg. samples / sec: 52826.27
Iteration:   1140, Loss function: 4.122, Average Loss: 4.402, avg. samples / sec: 52392.45
Iteration:   1140, Loss function: 4.524, Average Loss: 4.380, avg. samples / sec: 52186.04
Iteration:   1140, Loss function: 5.296, Average Loss: 4.346, avg. samples / sec: 52314.07
Iteration:   1140, Loss function: 6.418, Average Loss: 4.393, avg. samples / sec: 52229.98
Iteration:   1140, Loss function: 3.828, Average Loss: 4.396, avg. samples / sec: 52252.31
Iteration:   1140, Loss function: 4.688, Average Loss: 4.382, avg. samples / sec: 52294.19
Iteration:   1140, Loss function: 5.460, Average Loss: 4.406, avg. samples / sec: 52324.35
Iteration:   1140, Loss function: 5.368, Average Loss: 4.389, avg. samples / sec: 52210.27
Iteration:   1140, Loss function: 5.712, Average Loss: 4.391, avg. samples / sec: 52135.98
Iteration:   1140, Loss function: 4.630, Average Loss: 4.383, avg. samples / sec: 52318.69
Iteration:   1140, Loss function: 4.144, Average Loss: 4.388, avg. samples / sec: 52649.09
Iteration:   1140, Loss function: 5.027, Average Loss: 4.374, avg. samples / sec: 52298.11
Iteration:   1140, Loss function: 4.971, Average Loss: 4.362, avg. samples / sec: 52097.40
Iteration:   1140, Loss function: 4.475, Average Loss: 4.394, avg. samples / sec: 52224.33
Iteration:   1140, Loss function: 6.423, Average Loss: 4.367, avg. samples / sec: 52144.35
Iteration:   1140, Loss function: 4.991, Average Loss: 4.363, avg. samples / sec: 52119.42
Iteration:   1140, Loss function: 4.623, Average Loss: 4.355, avg. samples / sec: 52192.34
Iteration:   1140, Loss function: 4.762, Average Loss: 4.383, avg. samples / sec: 52215.26
Iteration:   1140, Loss function: 5.750, Average Loss: 4.398, avg. samples / sec: 52294.81
Iteration:   1140, Loss function: 4.661, Average Loss: 4.374, avg. samples / sec: 52301.20
Iteration:   1140, Loss function: 6.134, Average Loss: 4.341, avg. samples / sec: 52273.44
Iteration:   1140, Loss function: 5.375, Average Loss: 4.396, avg. samples / sec: 52137.54
Iteration:   1140, Loss function: 4.682, Average Loss: 4.388, avg. samples / sec: 52233.88
Iteration:   1140, Loss function: 5.184, Average Loss: 4.389, avg. samples / sec: 52120.40
Iteration:   1140, Loss function: 4.570, Average Loss: 4.377, avg. samples / sec: 52315.97
Iteration:   1140, Loss function: 4.039, Average Loss: 4.386, avg. samples / sec: 52165.35
Iteration:   1140, Loss function: 5.211, Average Loss: 4.375, avg. samples / sec: 52296.41
Iteration:   1140, Loss function: 4.846, Average Loss: 4.374, avg. samples / sec: 52299.26
Iteration:   1140, Loss function: 3.981, Average Loss: 4.378, avg. samples / sec: 51879.91
Iteration:   1140, Loss function: 5.780, Average Loss: 4.375, avg. samples / sec: 52171.38
Iteration:   1160, Loss function: 4.979, Average Loss: 4.389, avg. samples / sec: 54960.09
Iteration:   1160, Loss function: 4.693, Average Loss: 4.407, avg. samples / sec: 54813.62
Iteration:   1160, Loss function: 4.831, Average Loss: 4.394, avg. samples / sec: 54963.78
Iteration:   1160, Loss function: 3.811, Average Loss: 4.354, avg. samples / sec: 54871.12
Iteration:   1160, Loss function: 5.082, Average Loss: 4.402, avg. samples / sec: 54887.19
Iteration:   1160, Loss function: 4.512, Average Loss: 4.364, avg. samples / sec: 54963.35
Iteration:   1160, Loss function: 5.688, Average Loss: 4.391, avg. samples / sec: 54883.21
Iteration:   1160, Loss function: 4.498, Average Loss: 4.377, avg. samples / sec: 54931.00
Iteration:   1160, Loss function: 4.998, Average Loss: 4.389, avg. samples / sec: 55215.37
Iteration:   1160, Loss function: 5.714, Average Loss: 4.413, avg. samples / sec: 54878.04
Iteration:   1160, Loss function: 4.974, Average Loss: 4.396, avg. samples / sec: 54882.14
Iteration:   1160, Loss function: 5.269, Average Loss: 4.396, avg. samples / sec: 54865.33
Iteration:   1160, Loss function: 4.583, Average Loss: 4.390, avg. samples / sec: 54873.62
Iteration:   1160, Loss function: 4.374, Average Loss: 4.395, avg. samples / sec: 55043.57
Iteration:   1160, Loss function: 4.609, Average Loss: 4.397, avg. samples / sec: 54819.46
Iteration:   1160, Loss function: 5.087, Average Loss: 4.401, avg. samples / sec: 54925.28
Iteration:   1160, Loss function: 4.484, Average Loss: 4.367, avg. samples / sec: 54880.43
Iteration:   1160, Loss function: 4.415, Average Loss: 4.366, avg. samples / sec: 54892.60
Iteration:   1160, Loss function: 4.980, Average Loss: 4.403, avg. samples / sec: 54935.50
Iteration:   1160, Loss function: 3.850, Average Loss: 4.348, avg. samples / sec: 54918.46
Iteration:   1160, Loss function: 4.360, Average Loss: 4.381, avg. samples / sec: 55074.14
Iteration:   1160, Loss function: 4.697, Average Loss: 4.374, avg. samples / sec: 54843.16
Iteration:   1160, Loss function: 6.041, Average Loss: 4.381, avg. samples / sec: 54878.81
Iteration:   1160, Loss function: 4.618, Average Loss: 4.399, avg. samples / sec: 54874.83
Iteration:   1160, Loss function: 4.541, Average Loss: 4.383, avg. samples / sec: 54953.75
Iteration:   1160, Loss function: 4.522, Average Loss: 4.382, avg. samples / sec: 54905.11
Iteration:   1160, Loss function: 6.006, Average Loss: 4.395, avg. samples / sec: 54896.62
Iteration:   1160, Loss function: 5.440, Average Loss: 4.383, avg. samples / sec: 54901.66
Iteration:   1160, Loss function: 3.780, Average Loss: 4.397, avg. samples / sec: 54877.53
Iteration:   1160, Loss function: 4.820, Average Loss: 4.394, avg. samples / sec: 54879.79
Iteration:   1180, Loss function: 6.614, Average Loss: 4.394, avg. samples / sec: 54877.03
Iteration:   1180, Loss function: 6.069, Average Loss: 4.414, avg. samples / sec: 54466.62
Iteration:   1180, Loss function: 4.291, Average Loss: 4.413, avg. samples / sec: 54556.59
Iteration:   1180, Loss function: 4.240, Average Loss: 4.413, avg. samples / sec: 54586.91
Iteration:   1180, Loss function: 5.084, Average Loss: 4.398, avg. samples / sec: 54518.41
Iteration:   1180, Loss function: 4.220, Average Loss: 4.424, avg. samples / sec: 54515.52
Iteration:   1180, Loss function: 5.471, Average Loss: 4.405, avg. samples / sec: 54489.36
Iteration:   1180, Loss function: 4.328, Average Loss: 4.367, avg. samples / sec: 54436.81
Iteration:   1180, Loss function: 5.531, Average Loss: 4.409, avg. samples / sec: 54506.07
Iteration:   1180, Loss function: 4.672, Average Loss: 4.377, avg. samples / sec: 54443.60
Iteration:   1180, Loss function: 5.940, Average Loss: 4.383, avg. samples / sec: 54635.61
Iteration:   1180, Loss function: 5.256, Average Loss: 4.389, avg. samples / sec: 54444.14
Iteration:   1180, Loss function: 4.099, Average Loss: 4.402, avg. samples / sec: 54406.44
Iteration:   1180, Loss function: 4.972, Average Loss: 4.395, avg. samples / sec: 54665.85
Iteration:   1180, Loss function: 5.196, Average Loss: 4.411, avg. samples / sec: 54413.01
Iteration:   1180, Loss function: 5.022, Average Loss: 4.405, avg. samples / sec: 54482.09
Iteration:   1180, Loss function: 5.729, Average Loss: 4.400, avg. samples / sec: 54464.13
Iteration:   1180, Loss function: 4.557, Average Loss: 4.383, avg. samples / sec: 54608.28
Iteration:   1180, Loss function: 5.286, Average Loss: 4.407, avg. samples / sec: 54340.77
Iteration:   1180, Loss function: 4.905, Average Loss: 4.363, avg. samples / sec: 54470.43
Iteration:   1180, Loss function: 5.621, Average Loss: 4.413, avg. samples / sec: 54498.00
Iteration:   1180, Loss function: 5.372, Average Loss: 4.401, avg. samples / sec: 54137.68
Iteration:   1180, Loss function: 5.241, Average Loss: 4.413, avg. samples / sec: 54508.29
Iteration:   1180, Loss function: 4.687, Average Loss: 4.398, avg. samples / sec: 54478.01
Iteration:   1180, Loss function: 4.423, Average Loss: 4.379, avg. samples / sec: 54418.73
Iteration:   1180, Loss function: 4.595, Average Loss: 4.408, avg. samples / sec: 54479.76
Iteration:   1180, Loss function: 3.877, Average Loss: 4.416, avg. samples / sec: 54410.01
Iteration:   1180, Loss function: 5.623, Average Loss: 4.395, avg. samples / sec: 54462.43
Iteration:   1180, Loss function: 5.595, Average Loss: 4.398, avg. samples / sec: 54435.38
Iteration:   1180, Loss function: 3.671, Average Loss: 4.403, avg. samples / sec: 54446.92
:::MLL 1558640316.774 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558640316.775 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 2.770, Average Loss: 4.418, avg. samples / sec: 54603.62
Iteration:   1200, Loss function: 4.990, Average Loss: 4.408, avg. samples / sec: 54581.37
Iteration:   1200, Loss function: 4.387, Average Loss: 4.414, avg. samples / sec: 54510.12
Iteration:   1200, Loss function: 4.297, Average Loss: 4.387, avg. samples / sec: 54468.32
Iteration:   1200, Loss function: 3.753, Average Loss: 4.419, avg. samples / sec: 54333.32
Iteration:   1200, Loss function: 4.297, Average Loss: 4.433, avg. samples / sec: 54393.23
Iteration:   1200, Loss function: 4.685, Average Loss: 4.418, avg. samples / sec: 54392.89
Iteration:   1200, Loss function: 4.669, Average Loss: 4.425, avg. samples / sec: 54237.48
Iteration:   1200, Loss function: 4.392, Average Loss: 4.406, avg. samples / sec: 54089.81
Iteration:   1200, Loss function: 4.110, Average Loss: 4.417, avg. samples / sec: 54525.52
Iteration:   1200, Loss function: 4.746, Average Loss: 4.412, avg. samples / sec: 54435.19
Iteration:   1200, Loss function: 4.917, Average Loss: 4.406, avg. samples / sec: 54473.75
Iteration:   1200, Loss function: 5.075, Average Loss: 4.374, avg. samples / sec: 54174.27
Iteration:   1200, Loss function: 6.101, Average Loss: 4.403, avg. samples / sec: 54398.81
Iteration:   1200, Loss function: 5.069, Average Loss: 4.404, avg. samples / sec: 54140.88
Iteration:   1200, Loss function: 5.227, Average Loss: 4.419, avg. samples / sec: 54071.40
Iteration:   1200, Loss function: 4.227, Average Loss: 4.407, avg. samples / sec: 54278.59
Iteration:   1200, Loss function: 4.433, Average Loss: 4.390, avg. samples / sec: 54031.93
Iteration:   1200, Loss function: 3.575, Average Loss: 4.389, avg. samples / sec: 54087.05
Iteration:   1200, Loss function: 4.037, Average Loss: 4.388, avg. samples / sec: 54206.71
Iteration:   1200, Loss function: 4.641, Average Loss: 4.410, avg. samples / sec: 53999.36
Iteration:   1200, Loss function: 4.745, Average Loss: 4.421, avg. samples / sec: 54164.48
Iteration:   1200, Loss function: 4.493, Average Loss: 4.374, avg. samples / sec: 54145.63
Iteration:   1200, Loss function: 4.616, Average Loss: 4.399, avg. samples / sec: 53973.61
Iteration:   1200, Loss function: 5.513, Average Loss: 4.416, avg. samples / sec: 54042.04
Iteration:   1200, Loss function: 4.204, Average Loss: 4.405, avg. samples / sec: 53731.49
Iteration:   1200, Loss function: 4.315, Average Loss: 4.405, avg. samples / sec: 53724.69
Iteration:   1200, Loss function: 4.484, Average Loss: 4.424, avg. samples / sec: 53997.27
Iteration:   1200, Loss function: 4.468, Average Loss: 4.411, avg. samples / sec: 54034.83
Iteration:   1200, Loss function: 5.180, Average Loss: 4.423, avg. samples / sec: 53434.07
Iteration:   1220, Loss function: 4.906, Average Loss: 4.431, avg. samples / sec: 53830.56
Iteration:   1220, Loss function: 3.825, Average Loss: 4.423, avg. samples / sec: 54076.96
Iteration:   1220, Loss function: 4.822, Average Loss: 4.406, avg. samples / sec: 54474.09
Iteration:   1220, Loss function: 5.330, Average Loss: 4.423, avg. samples / sec: 54447.41
Iteration:   1220, Loss function: 6.265, Average Loss: 4.433, avg. samples / sec: 54321.69
Iteration:   1220, Loss function: 3.845, Average Loss: 4.387, avg. samples / sec: 54207.94
Iteration:   1220, Loss function: 4.910, Average Loss: 4.427, avg. samples / sec: 54078.54
Iteration:   1220, Loss function: 4.135, Average Loss: 4.419, avg. samples / sec: 54624.81
Iteration:   1220, Loss function: 4.739, Average Loss: 4.398, avg. samples / sec: 54357.50
Iteration:   1220, Loss function: 4.828, Average Loss: 4.428, avg. samples / sec: 53921.97
Iteration:   1220, Loss function: 6.335, Average Loss: 4.413, avg. samples / sec: 53806.41
Iteration:   1220, Loss function: 5.224, Average Loss: 4.421, avg. samples / sec: 53869.04
Iteration:   1220, Loss function: 5.686, Average Loss: 4.417, avg. samples / sec: 54575.41
Iteration:   1220, Loss function: 5.200, Average Loss: 4.403, avg. samples / sec: 53866.30
Iteration:   1220, Loss function: 5.555, Average Loss: 4.395, avg. samples / sec: 54292.00
Iteration:   1220, Loss function: 5.552, Average Loss: 4.424, avg. samples / sec: 53991.87
Iteration:   1220, Loss function: 3.765, Average Loss: 4.382, avg. samples / sec: 54251.43
Iteration:   1220, Loss function: 5.560, Average Loss: 4.426, avg. samples / sec: 54340.84
Iteration:   1220, Loss function: 6.369, Average Loss: 4.437, avg. samples / sec: 54241.39
Iteration:   1220, Loss function: 4.629, Average Loss: 4.401, avg. samples / sec: 54175.02
Iteration:   1220, Loss function: 5.126, Average Loss: 4.434, avg. samples / sec: 54436.85
Iteration:   1220, Loss function: 5.646, Average Loss: 4.417, avg. samples / sec: 53959.64
Iteration:   1220, Loss function: 4.918, Average Loss: 4.409, avg. samples / sec: 54409.00
Iteration:   1220, Loss function: 4.658, Average Loss: 4.435, avg. samples / sec: 54958.14
Iteration:   1220, Loss function: 3.969, Average Loss: 4.445, avg. samples / sec: 53721.66
Iteration:   1220, Loss function: 5.197, Average Loss: 4.410, avg. samples / sec: 54013.75
Iteration:   1220, Loss function: 5.876, Average Loss: 4.410, avg. samples / sec: 54021.30
Iteration:   1220, Loss function: 4.934, Average Loss: 4.428, avg. samples / sec: 53853.10
Iteration:   1220, Loss function: 4.366, Average Loss: 4.416, avg. samples / sec: 54076.15
Iteration:   1220, Loss function: 5.513, Average Loss: 4.415, avg. samples / sec: 53769.02
Iteration:   1240, Loss function: 4.766, Average Loss: 4.440, avg. samples / sec: 54967.42
Iteration:   1240, Loss function: 4.887, Average Loss: 4.417, avg. samples / sec: 54948.26
Iteration:   1240, Loss function: 5.360, Average Loss: 4.427, avg. samples / sec: 54912.70
Iteration:   1240, Loss function: 5.258, Average Loss: 4.396, avg. samples / sec: 54834.33
Iteration:   1240, Loss function: 4.776, Average Loss: 4.443, avg. samples / sec: 54796.74
Iteration:   1240, Loss function: 4.325, Average Loss: 4.458, avg. samples / sec: 55039.02
Iteration:   1240, Loss function: 6.223, Average Loss: 4.440, avg. samples / sec: 54742.65
Iteration:   1240, Loss function: 4.028, Average Loss: 4.420, avg. samples / sec: 54816.71
Iteration:   1240, Loss function: 5.772, Average Loss: 4.431, avg. samples / sec: 54810.61
Iteration:   1240, Loss function: 5.742, Average Loss: 4.439, avg. samples / sec: 54761.42
Iteration:   1240, Loss function: 3.762, Average Loss: 4.426, avg. samples / sec: 55081.70
Iteration:   1240, Loss function: 4.392, Average Loss: 4.437, avg. samples / sec: 54917.15
Iteration:   1240, Loss function: 4.725, Average Loss: 4.432, avg. samples / sec: 54697.89
Iteration:   1240, Loss function: 5.717, Average Loss: 4.445, avg. samples / sec: 54569.75
Iteration:   1240, Loss function: 5.064, Average Loss: 4.411, avg. samples / sec: 54791.48
Iteration:   1240, Loss function: 5.076, Average Loss: 4.441, avg. samples / sec: 54864.15
Iteration:   1240, Loss function: 3.822, Average Loss: 4.415, avg. samples / sec: 54606.60
Iteration:   1240, Loss function: 4.840, Average Loss: 4.428, avg. samples / sec: 54837.42
Iteration:   1240, Loss function: 6.374, Average Loss: 4.448, avg. samples / sec: 54788.16
Iteration:   1240, Loss function: 5.611, Average Loss: 4.413, avg. samples / sec: 54802.20
Iteration:   1240, Loss function: 5.540, Average Loss: 4.410, avg. samples / sec: 54618.58
Iteration:   1240, Loss function: 5.758, Average Loss: 4.441, avg. samples / sec: 54777.12
Iteration:   1240, Loss function: 4.960, Average Loss: 4.441, avg. samples / sec: 54847.86
Iteration:   1240, Loss function: 4.049, Average Loss: 4.444, avg. samples / sec: 54819.31
Iteration:   1240, Loss function: 4.746, Average Loss: 4.413, avg. samples / sec: 54832.18
Iteration:   1240, Loss function: 4.696, Average Loss: 4.425, avg. samples / sec: 54808.95
Iteration:   1240, Loss function: 5.079, Average Loss: 4.382, avg. samples / sec: 54745.91
Iteration:   1240, Loss function: 4.971, Average Loss: 4.420, avg. samples / sec: 54806.29
Iteration:   1240, Loss function: 5.389, Average Loss: 4.428, avg. samples / sec: 54806.35
Iteration:   1240, Loss function: 6.103, Average Loss: 4.430, avg. samples / sec: 54547.51
:::MLL 1558640318.932 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558640318.933 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 4.316, Average Loss: 4.444, avg. samples / sec: 54544.62
Iteration:   1260, Loss function: 6.122, Average Loss: 4.431, avg. samples / sec: 54903.44
Iteration:   1260, Loss function: 6.095, Average Loss: 4.447, avg. samples / sec: 54668.35
Iteration:   1260, Loss function: 4.368, Average Loss: 4.440, avg. samples / sec: 54654.34
Iteration:   1260, Loss function: 4.140, Average Loss: 4.441, avg. samples / sec: 54633.45
Iteration:   1260, Loss function: 5.752, Average Loss: 4.450, avg. samples / sec: 54752.95
Iteration:   1260, Loss function: 4.569, Average Loss: 4.450, avg. samples / sec: 54766.61
Iteration:   1260, Loss function: 6.099, Average Loss: 4.452, avg. samples / sec: 54529.23
Iteration:   1260, Loss function: 5.130, Average Loss: 4.447, avg. samples / sec: 54649.65
Iteration:   1260, Loss function: 4.455, Average Loss: 4.406, avg. samples / sec: 54462.85
Iteration:   1260, Loss function: 4.813, Average Loss: 4.440, avg. samples / sec: 54436.53
Iteration:   1260, Loss function: 4.306, Average Loss: 4.464, avg. samples / sec: 54491.87
Iteration:   1260, Loss function: 5.183, Average Loss: 4.453, avg. samples / sec: 54691.12
Iteration:   1260, Loss function: 3.883, Average Loss: 4.421, avg. samples / sec: 54612.38
Iteration:   1260, Loss function: 5.949, Average Loss: 4.419, avg. samples / sec: 54588.88
Iteration:   1260, Loss function: 5.208, Average Loss: 4.430, avg. samples / sec: 54491.24
Iteration:   1260, Loss function: 5.024, Average Loss: 4.425, avg. samples / sec: 54349.81
Iteration:   1260, Loss function: 4.190, Average Loss: 4.446, avg. samples / sec: 54498.80
Iteration:   1260, Loss function: 3.210, Average Loss: 4.427, avg. samples / sec: 54648.11
Iteration:   1260, Loss function: 5.000, Average Loss: 4.454, avg. samples / sec: 54593.70
Iteration:   1260, Loss function: 4.564, Average Loss: 4.413, avg. samples / sec: 54593.51
Iteration:   1260, Loss function: 4.347, Average Loss: 4.436, avg. samples / sec: 54446.27
Iteration:   1260, Loss function: 5.255, Average Loss: 4.450, avg. samples / sec: 54450.08
Iteration:   1260, Loss function: 4.629, Average Loss: 4.434, avg. samples / sec: 54547.53
Iteration:   1260, Loss function: 4.840, Average Loss: 4.417, avg. samples / sec: 54493.36
Iteration:   1260, Loss function: 4.275, Average Loss: 4.416, avg. samples / sec: 54460.32
Iteration:   1260, Loss function: 4.295, Average Loss: 4.428, avg. samples / sec: 54505.34
Iteration:   1260, Loss function: 3.735, Average Loss: 4.441, avg. samples / sec: 54428.88
Iteration:   1260, Loss function: 3.663, Average Loss: 4.434, avg. samples / sec: 54286.79
Iteration:   1260, Loss function: 4.946, Average Loss: 4.383, avg. samples / sec: 53929.54
Iteration:   1280, Loss function: 5.394, Average Loss: 4.453, avg. samples / sec: 54576.24
Iteration:   1280, Loss function: 5.263, Average Loss: 4.450, avg. samples / sec: 54401.59
Iteration:   1280, Loss function: 4.611, Average Loss: 4.414, avg. samples / sec: 54513.07
Iteration:   1280, Loss function: 4.755, Average Loss: 4.453, avg. samples / sec: 54505.08
Iteration:   1280, Loss function: 5.076, Average Loss: 4.451, avg. samples / sec: 54383.72
Iteration:   1280, Loss function: 4.438, Average Loss: 4.470, avg. samples / sec: 54489.00
Iteration:   1280, Loss function: 5.793, Average Loss: 4.437, avg. samples / sec: 54513.18
Iteration:   1280, Loss function: 5.271, Average Loss: 4.434, avg. samples / sec: 54496.76
Iteration:   1280, Loss function: 4.091, Average Loss: 4.454, avg. samples / sec: 54414.44
Iteration:   1280, Loss function: 4.067, Average Loss: 4.456, avg. samples / sec: 54398.88
Iteration:   1280, Loss function: 3.549, Average Loss: 4.454, avg. samples / sec: 54287.17
Iteration:   1280, Loss function: 5.655, Average Loss: 4.441, avg. samples / sec: 54539.80
Iteration:   1280, Loss function: 5.819, Average Loss: 4.431, avg. samples / sec: 54460.05
Iteration:   1280, Loss function: 4.499, Average Loss: 4.456, avg. samples / sec: 54422.64
Iteration:   1280, Loss function: 6.756, Average Loss: 4.423, avg. samples / sec: 54414.04
Iteration:   1280, Loss function: 4.016, Average Loss: 4.451, avg. samples / sec: 54352.13
Iteration:   1280, Loss function: 4.106, Average Loss: 4.425, avg. samples / sec: 54324.16
Iteration:   1280, Loss function: 6.348, Average Loss: 4.436, avg. samples / sec: 54351.97
Iteration:   1280, Loss function: 4.342, Average Loss: 4.419, avg. samples / sec: 54506.43
Iteration:   1280, Loss function: 5.279, Average Loss: 4.431, avg. samples / sec: 54503.50
Iteration:   1280, Loss function: 4.134, Average Loss: 4.453, avg. samples / sec: 54218.26
Iteration:   1280, Loss function: 3.606, Average Loss: 4.451, avg. samples / sec: 54225.98
Iteration:   1280, Loss function: 4.565, Average Loss: 4.437, avg. samples / sec: 54533.87
Iteration:   1280, Loss function: 4.488, Average Loss: 4.448, avg. samples / sec: 54486.98
Iteration:   1280, Loss function: 4.236, Average Loss: 4.385, avg. samples / sec: 55036.63
Iteration:   1280, Loss function: 4.709, Average Loss: 4.454, avg. samples / sec: 54405.89
Iteration:   1280, Loss function: 4.937, Average Loss: 4.444, avg. samples / sec: 54083.77
Iteration:   1280, Loss function: 4.981, Average Loss: 4.440, avg. samples / sec: 54424.04
Iteration:   1280, Loss function: 4.961, Average Loss: 4.459, avg. samples / sec: 54231.47
Iteration:   1280, Loss function: 3.988, Average Loss: 4.435, avg. samples / sec: 54441.22
Iteration:   1300, Loss function: 5.080, Average Loss: 4.460, avg. samples / sec: 54613.33
Iteration:   1300, Loss function: 3.947, Average Loss: 4.449, avg. samples / sec: 54900.14
Iteration:   1300, Loss function: 4.861, Average Loss: 4.462, avg. samples / sec: 54649.04
Iteration:   1300, Loss function: 4.833, Average Loss: 4.456, avg. samples / sec: 54554.62
Iteration:   1300, Loss function: 5.073, Average Loss: 4.460, avg. samples / sec: 54603.03
Iteration:   1300, Loss function: 4.893, Average Loss: 4.423, avg. samples / sec: 54530.22
Iteration:   1300, Loss function: 4.362, Average Loss: 4.476, avg. samples / sec: 54551.46
Iteration:   1300, Loss function: 3.756, Average Loss: 4.434, avg. samples / sec: 54629.72
Iteration:   1300, Loss function: 5.344, Average Loss: 4.457, avg. samples / sec: 54604.04
Iteration:   1300, Loss function: 3.696, Average Loss: 4.442, avg. samples / sec: 54554.12
Iteration:   1300, Loss function: 4.131, Average Loss: 4.444, avg. samples / sec: 54536.30
Iteration:   1300, Loss function: 4.240, Average Loss: 4.443, avg. samples / sec: 54585.12
Iteration:   1300, Loss function: 4.532, Average Loss: 4.460, avg. samples / sec: 54496.34
Iteration:   1300, Loss function: 5.532, Average Loss: 4.429, avg. samples / sec: 54594.46
Iteration:   1300, Loss function: 5.250, Average Loss: 4.458, avg. samples / sec: 54602.61
Iteration:   1300, Loss function: 6.224, Average Loss: 4.435, avg. samples / sec: 54589.03
Iteration:   1300, Loss function: 4.273, Average Loss: 4.423, avg. samples / sec: 54587.82
Iteration:   1300, Loss function: 5.648, Average Loss: 4.431, avg. samples / sec: 54550.00
Iteration:   1300, Loss function: 3.389, Average Loss: 4.459, avg. samples / sec: 54537.23
Iteration:   1300, Loss function: 4.110, Average Loss: 4.443, avg. samples / sec: 54587.97
Iteration:   1300, Loss function: 3.539, Average Loss: 4.463, avg. samples / sec: 54633.49
Iteration:   1300, Loss function: 4.770, Average Loss: 4.390, avg. samples / sec: 54611.41
Iteration:   1300, Loss function: 4.930, Average Loss: 4.461, avg. samples / sec: 54611.47
Iteration:   1300, Loss function: 6.424, Average Loss: 4.441, avg. samples / sec: 54624.13
Iteration:   1300, Loss function: 3.939, Average Loss: 4.444, avg. samples / sec: 54544.07
Iteration:   1300, Loss function: 4.319, Average Loss: 4.455, avg. samples / sec: 54548.04
Iteration:   1300, Loss function: 5.064, Average Loss: 4.451, avg. samples / sec: 54584.73
Iteration:   1300, Loss function: 3.646, Average Loss: 4.458, avg. samples / sec: 54112.63
Iteration:   1300, Loss function: 6.240, Average Loss: 4.452, avg. samples / sec: 54584.04
Iteration:   1300, Loss function: 4.729, Average Loss: 4.444, avg. samples / sec: 54578.03
Iteration:   1320, Loss function: 4.412, Average Loss: 4.464, avg. samples / sec: 54751.03
Iteration:   1320, Loss function: 6.260, Average Loss: 4.466, avg. samples / sec: 54384.60
Iteration:   1320, Loss function: 5.303, Average Loss: 4.433, avg. samples / sec: 54538.49
Iteration:   1320, Loss function: 4.535, Average Loss: 4.447, avg. samples / sec: 54559.61
Iteration:   1320, Loss function: 5.939, Average Loss: 4.446, avg. samples / sec: 54520.03
Iteration:   1320, Loss function: 4.387, Average Loss: 4.460, avg. samples / sec: 54476.81
Iteration:   1320, Loss function: 3.953, Average Loss: 4.453, avg. samples / sec: 54492.46
Iteration:   1320, Loss function: 5.516, Average Loss: 4.481, avg. samples / sec: 54464.32
Iteration:   1320, Loss function: 4.321, Average Loss: 4.467, avg. samples / sec: 54485.23
Iteration:   1320, Loss function: 5.237, Average Loss: 4.467, avg. samples / sec: 54417.05
Iteration:   1320, Loss function: 4.321, Average Loss: 4.462, avg. samples / sec: 54438.45
Iteration:   1320, Loss function: 4.622, Average Loss: 4.464, avg. samples / sec: 54392.07
Iteration:   1320, Loss function: 5.520, Average Loss: 4.450, avg. samples / sec: 54416.71
Iteration:   1320, Loss function: 3.489, Average Loss: 4.465, avg. samples / sec: 54487.11
Iteration:   1320, Loss function: 4.760, Average Loss: 4.450, avg. samples / sec: 54487.02
Iteration:   1320, Loss function: 3.953, Average Loss: 4.431, avg. samples / sec: 54453.36
Iteration:   1320, Loss function: 4.809, Average Loss: 4.432, avg. samples / sec: 54458.54
Iteration:   1320, Loss function: 4.889, Average Loss: 4.451, avg. samples / sec: 54127.95
Iteration:   1320, Loss function: 4.112, Average Loss: 4.445, avg. samples / sec: 54489.11
Iteration:   1320, Loss function: 5.070, Average Loss: 4.453, avg. samples / sec: 54485.17
Iteration:   1320, Loss function: 4.850, Average Loss: 4.472, avg. samples / sec: 54453.93
Iteration:   1320, Loss function: 4.270, Average Loss: 4.441, avg. samples / sec: 54420.85
Iteration:   1320, Loss function: 5.087, Average Loss: 4.444, avg. samples / sec: 54461.00
Iteration:   1320, Loss function: 5.941, Average Loss: 4.464, avg. samples / sec: 54473.02
Iteration:   1320, Loss function: 4.999, Average Loss: 4.400, avg. samples / sec: 54450.37
Iteration:   1320, Loss function: 4.641, Average Loss: 4.457, avg. samples / sec: 54472.28
Iteration:   1320, Loss function: 4.683, Average Loss: 4.459, avg. samples / sec: 54475.54
Iteration:   1320, Loss function: 4.190, Average Loss: 4.471, avg. samples / sec: 54439.81
Iteration:   1320, Loss function: 3.975, Average Loss: 4.447, avg. samples / sec: 54455.84
Iteration:   1320, Loss function: 4.882, Average Loss: 4.433, avg. samples / sec: 54339.87
:::MLL 1558640321.094 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558640321.095 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 4.150, Average Loss: 4.487, avg. samples / sec: 54357.77
Iteration:   1340, Loss function: 3.947, Average Loss: 4.469, avg. samples / sec: 54259.12
Iteration:   1340, Loss function: 5.014, Average Loss: 4.441, avg. samples / sec: 54172.66
Iteration:   1340, Loss function: 5.071, Average Loss: 4.461, avg. samples / sec: 54196.08
Iteration:   1340, Loss function: 4.932, Average Loss: 4.469, avg. samples / sec: 54239.57
Iteration:   1340, Loss function: 4.213, Average Loss: 4.453, avg. samples / sec: 54131.59
Iteration:   1340, Loss function: 3.353, Average Loss: 4.450, avg. samples / sec: 54247.21
Iteration:   1340, Loss function: 4.572, Average Loss: 4.461, avg. samples / sec: 54161.11
Iteration:   1340, Loss function: 4.839, Average Loss: 4.450, avg. samples / sec: 54106.28
Iteration:   1340, Loss function: 3.756, Average Loss: 4.464, avg. samples / sec: 54197.06
Iteration:   1340, Loss function: 4.963, Average Loss: 4.473, avg. samples / sec: 54176.97
Iteration:   1340, Loss function: 4.176, Average Loss: 4.468, avg. samples / sec: 53990.78
Iteration:   1340, Loss function: 4.044, Average Loss: 4.454, avg. samples / sec: 54227.15
Iteration:   1340, Loss function: 4.141, Average Loss: 4.442, avg. samples / sec: 54337.97
Iteration:   1340, Loss function: 4.423, Average Loss: 4.471, avg. samples / sec: 54182.95
Iteration:   1340, Loss function: 5.015, Average Loss: 4.440, avg. samples / sec: 54206.61
Iteration:   1340, Loss function: 3.767, Average Loss: 4.444, avg. samples / sec: 54233.35
Iteration:   1340, Loss function: 5.374, Average Loss: 4.436, avg. samples / sec: 54191.12
Iteration:   1340, Loss function: 3.738, Average Loss: 4.450, avg. samples / sec: 54197.04
Iteration:   1340, Loss function: 5.075, Average Loss: 4.456, avg. samples / sec: 54164.23
Iteration:   1340, Loss function: 4.150, Average Loss: 4.471, avg. samples / sec: 54204.98
Iteration:   1340, Loss function: 5.564, Average Loss: 4.474, avg. samples / sec: 54209.19
Iteration:   1340, Loss function: 4.452, Average Loss: 4.402, avg. samples / sec: 54210.86
Iteration:   1340, Loss function: 4.248, Average Loss: 4.464, avg. samples / sec: 54210.09
Iteration:   1340, Loss function: 3.724, Average Loss: 4.452, avg. samples / sec: 54235.52
Iteration:   1340, Loss function: 6.209, Average Loss: 4.459, avg. samples / sec: 54180.70
Iteration:   1340, Loss function: 4.941, Average Loss: 4.453, avg. samples / sec: 54189.16
Iteration:   1340, Loss function: 4.235, Average Loss: 4.464, avg. samples / sec: 54180.68
Iteration:   1340, Loss function: 3.353, Average Loss: 4.468, avg. samples / sec: 54184.62
Iteration:   1340, Loss function: 4.022, Average Loss: 4.468, avg. samples / sec: 53350.22
Iteration:   1360, Loss function: 4.119, Average Loss: 4.453, avg. samples / sec: 54700.71
Iteration:   1360, Loss function: 3.803, Average Loss: 4.461, avg. samples / sec: 54617.42
Iteration:   1360, Loss function: 4.597, Average Loss: 4.449, avg. samples / sec: 54527.35
Iteration:   1360, Loss function: 4.085, Average Loss: 4.478, avg. samples / sec: 54559.69
Iteration:   1360, Loss function: 3.948, Average Loss: 4.452, avg. samples / sec: 54595.33
Iteration:   1360, Loss function: 4.826, Average Loss: 4.458, avg. samples / sec: 54781.72
Iteration:   1360, Loss function: 4.060, Average Loss: 4.489, avg. samples / sec: 54414.50
Iteration:   1360, Loss function: 5.168, Average Loss: 4.462, avg. samples / sec: 54790.14
Iteration:   1360, Loss function: 4.442, Average Loss: 4.462, avg. samples / sec: 54532.06
Iteration:   1360, Loss function: 4.580, Average Loss: 4.476, avg. samples / sec: 54617.19
Iteration:   1360, Loss function: 5.093, Average Loss: 4.474, avg. samples / sec: 55495.29
Iteration:   1360, Loss function: 4.346, Average Loss: 4.472, avg. samples / sec: 54416.50
Iteration:   1360, Loss function: 3.575, Average Loss: 4.452, avg. samples / sec: 54591.25
Iteration:   1360, Loss function: 4.743, Average Loss: 4.466, avg. samples / sec: 54578.41
Iteration:   1360, Loss function: 4.262, Average Loss: 4.441, avg. samples / sec: 54575.71
Iteration:   1360, Loss function: 3.587, Average Loss: 4.473, avg. samples / sec: 54484.98
Iteration:   1360, Loss function: 3.606, Average Loss: 4.472, avg. samples / sec: 54601.55
Iteration:   1360, Loss function: 5.055, Average Loss: 4.447, avg. samples / sec: 54561.19
Iteration:   1360, Loss function: 5.516, Average Loss: 4.479, avg. samples / sec: 54556.02
Iteration:   1360, Loss function: 4.684, Average Loss: 4.405, avg. samples / sec: 54575.12
Iteration:   1360, Loss function: 4.810, Average Loss: 4.460, avg. samples / sec: 54533.03
Iteration:   1360, Loss function: 4.073, Average Loss: 4.482, avg. samples / sec: 54563.90
Iteration:   1360, Loss function: 6.238, Average Loss: 4.446, avg. samples / sec: 54541.72
Iteration:   1360, Loss function: 4.956, Average Loss: 4.447, avg. samples / sec: 54523.49
Iteration:   1360, Loss function: 4.495, Average Loss: 4.476, avg. samples / sec: 54563.14
Iteration:   1360, Loss function: 4.749, Average Loss: 4.469, avg. samples / sec: 54604.21
Iteration:   1360, Loss function: 4.534, Average Loss: 4.453, avg. samples / sec: 54547.47
Iteration:   1360, Loss function: 4.462, Average Loss: 4.456, avg. samples / sec: 54572.79
Iteration:   1360, Loss function: 4.406, Average Loss: 4.453, avg. samples / sec: 54563.50
Iteration:   1360, Loss function: 4.601, Average Loss: 4.467, avg. samples / sec: 54581.20
Iteration:   1380, Loss function: 4.741, Average Loss: 4.473, avg. samples / sec: 54413.85
Iteration:   1380, Loss function: 6.029, Average Loss: 4.470, avg. samples / sec: 54372.54
Iteration:   1380, Loss function: 4.733, Average Loss: 4.490, avg. samples / sec: 54326.38
Iteration:   1380, Loss function: 4.739, Average Loss: 4.466, avg. samples / sec: 54312.23
Iteration:   1380, Loss function: 4.086, Average Loss: 4.461, avg. samples / sec: 54302.67
Iteration:   1380, Loss function: 4.798, Average Loss: 4.454, avg. samples / sec: 54243.60
Iteration:   1380, Loss function: 3.353, Average Loss: 4.454, avg. samples / sec: 54210.36
Iteration:   1380, Loss function: 5.042, Average Loss: 4.455, avg. samples / sec: 54102.77
Iteration:   1380, Loss function: 3.770, Average Loss: 4.467, avg. samples / sec: 54165.00
Iteration:   1380, Loss function: 5.373, Average Loss: 4.476, avg. samples / sec: 54372.45
Iteration:   1380, Loss function: 4.310, Average Loss: 4.456, avg. samples / sec: 54362.16
Iteration:   1380, Loss function: 5.109, Average Loss: 4.479, avg. samples / sec: 54144.44
Iteration:   1380, Loss function: 5.449, Average Loss: 4.480, avg. samples / sec: 54331.24
Iteration:   1380, Loss function: 4.184, Average Loss: 4.408, avg. samples / sec: 54298.94
Iteration:   1380, Loss function: 4.276, Average Loss: 4.461, avg. samples / sec: 54295.24
Iteration:   1380, Loss function: 4.710, Average Loss: 4.485, avg. samples / sec: 54274.02
Iteration:   1380, Loss function: 4.701, Average Loss: 4.456, avg. samples / sec: 54274.66
Iteration:   1380, Loss function: 5.047, Average Loss: 4.484, avg. samples / sec: 54038.74
Iteration:   1380, Loss function: 3.974, Average Loss: 4.478, avg. samples / sec: 54040.17
Iteration:   1380, Loss function: 4.129, Average Loss: 4.475, avg. samples / sec: 54173.39
Iteration:   1380, Loss function: 4.266, Average Loss: 4.444, avg. samples / sec: 54090.43
Iteration:   1380, Loss function: 4.910, Average Loss: 4.453, avg. samples / sec: 54074.72
Iteration:   1380, Loss function: 3.878, Average Loss: 4.452, avg. samples / sec: 54111.22
Iteration:   1380, Loss function: 5.201, Average Loss: 4.474, avg. samples / sec: 54059.37
Iteration:   1380, Loss function: 5.145, Average Loss: 4.450, avg. samples / sec: 53994.31
Iteration:   1380, Loss function: 4.963, Average Loss: 4.463, avg. samples / sec: 53977.73
Iteration:   1380, Loss function: 4.789, Average Loss: 4.471, avg. samples / sec: 53774.20
Iteration:   1380, Loss function: 5.263, Average Loss: 4.460, avg. samples / sec: 53760.64
Iteration:   1380, Loss function: 4.431, Average Loss: 4.475, avg. samples / sec: 53882.46
Iteration:   1380, Loss function: 3.995, Average Loss: 4.467, avg. samples / sec: 53928.98
:::MLL 1558640323.258 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558640323.259 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 5.354, Average Loss: 4.478, avg. samples / sec: 54090.70
Iteration:   1400, Loss function: 3.873, Average Loss: 4.481, avg. samples / sec: 54289.22
Iteration:   1400, Loss function: 4.949, Average Loss: 4.457, avg. samples / sec: 54178.16
Iteration:   1400, Loss function: 4.299, Average Loss: 4.485, avg. samples / sec: 54358.65
Iteration:   1400, Loss function: 4.206, Average Loss: 4.462, avg. samples / sec: 54629.36
Iteration:   1400, Loss function: 4.378, Average Loss: 4.492, avg. samples / sec: 54058.00
Iteration:   1400, Loss function: 5.425, Average Loss: 4.471, avg. samples / sec: 54065.45
Iteration:   1400, Loss function: 5.298, Average Loss: 4.460, avg. samples / sec: 54168.08
Iteration:   1400, Loss function: 6.254, Average Loss: 4.488, avg. samples / sec: 54293.65
Iteration:   1400, Loss function: 5.079, Average Loss: 4.473, avg. samples / sec: 54160.57
Iteration:   1400, Loss function: 4.733, Average Loss: 4.456, avg. samples / sec: 54186.33
Iteration:   1400, Loss function: 4.005, Average Loss: 4.453, avg. samples / sec: 54075.36
Iteration:   1400, Loss function: 5.212, Average Loss: 4.476, avg. samples / sec: 53974.71
Iteration:   1400, Loss function: 4.478, Average Loss: 4.462, avg. samples / sec: 54016.46
Iteration:   1400, Loss function: 4.572, Average Loss: 4.447, avg. samples / sec: 54392.91
Iteration:   1400, Loss function: 4.846, Average Loss: 4.452, avg. samples / sec: 54409.23
Iteration:   1400, Loss function: 4.392, Average Loss: 4.487, avg. samples / sec: 54145.96
Iteration:   1400, Loss function: 5.436, Average Loss: 4.480, avg. samples / sec: 54564.97
Iteration:   1400, Loss function: 4.605, Average Loss: 4.455, avg. samples / sec: 54213.26
Iteration:   1400, Loss function: 3.961, Average Loss: 4.476, avg. samples / sec: 54110.45
Iteration:   1400, Loss function: 4.546, Average Loss: 4.469, avg. samples / sec: 54541.89
Iteration:   1400, Loss function: 6.080, Average Loss: 4.479, avg. samples / sec: 54214.91
Iteration:   1400, Loss function: 3.508, Average Loss: 4.408, avg. samples / sec: 54093.13
Iteration:   1400, Loss function: 5.026, Average Loss: 4.459, avg. samples / sec: 54388.21
Iteration:   1400, Loss function: 4.000, Average Loss: 4.471, avg. samples / sec: 54373.06
Iteration:   1400, Loss function: 4.746, Average Loss: 4.476, avg. samples / sec: 54281.52
Iteration:   1400, Loss function: 3.633, Average Loss: 4.483, avg. samples / sec: 54046.89
Iteration:   1400, Loss function: 4.159, Average Loss: 4.452, avg. samples / sec: 54310.56
Iteration:   1400, Loss function: 4.246, Average Loss: 4.462, avg. samples / sec: 54017.49
Iteration:   1400, Loss function: 4.201, Average Loss: 4.449, avg. samples / sec: 54210.69
Iteration:   1420, Loss function: 4.693, Average Loss: 4.480, avg. samples / sec: 54707.38
Iteration:   1420, Loss function: 3.913, Average Loss: 4.490, avg. samples / sec: 54761.71
Iteration:   1420, Loss function: 5.433, Average Loss: 4.474, avg. samples / sec: 54706.13
Iteration:   1420, Loss function: 4.502, Average Loss: 4.494, avg. samples / sec: 54689.65
Iteration:   1420, Loss function: 4.503, Average Loss: 4.487, avg. samples / sec: 54657.05
Iteration:   1420, Loss function: 5.787, Average Loss: 4.486, avg. samples / sec: 54603.41
Iteration:   1420, Loss function: 4.813, Average Loss: 4.460, avg. samples / sec: 54623.22
Iteration:   1420, Loss function: 5.692, Average Loss: 4.456, avg. samples / sec: 54683.92
Iteration:   1420, Loss function: 3.973, Average Loss: 4.459, avg. samples / sec: 54649.21
Iteration:   1420, Loss function: 3.879, Average Loss: 4.466, avg. samples / sec: 54707.12
Iteration:   1420, Loss function: 4.852, Average Loss: 4.452, avg. samples / sec: 54693.79
Iteration:   1420, Loss function: 4.661, Average Loss: 4.481, avg. samples / sec: 54642.07
Iteration:   1420, Loss function: 5.503, Average Loss: 4.476, avg. samples / sec: 54654.89
Iteration:   1420, Loss function: 4.592, Average Loss: 4.456, avg. samples / sec: 54588.92
Iteration:   1420, Loss function: 3.902, Average Loss: 4.485, avg. samples / sec: 54596.56
Iteration:   1420, Loss function: 4.274, Average Loss: 4.462, avg. samples / sec: 54539.51
Iteration:   1420, Loss function: 2.984, Average Loss: 4.460, avg. samples / sec: 54725.73
Iteration:   1420, Loss function: 4.270, Average Loss: 4.483, avg. samples / sec: 54605.10
Iteration:   1420, Loss function: 4.302, Average Loss: 4.450, avg. samples / sec: 54770.72
Iteration:   1420, Loss function: 3.894, Average Loss: 4.482, avg. samples / sec: 54735.85
Iteration:   1420, Loss function: 5.128, Average Loss: 4.463, avg. samples / sec: 54599.58
Iteration:   1420, Loss function: 4.890, Average Loss: 4.478, avg. samples / sec: 54587.27
Iteration:   1420, Loss function: 4.607, Average Loss: 4.470, avg. samples / sec: 54630.19
Iteration:   1420, Loss function: 4.322, Average Loss: 4.413, avg. samples / sec: 54657.28
Iteration:   1420, Loss function: 5.242, Average Loss: 4.483, avg. samples / sec: 54724.56
Iteration:   1420, Loss function: 5.818, Average Loss: 4.469, avg. samples / sec: 54740.29
Iteration:   1420, Loss function: 5.550, Average Loss: 4.470, avg. samples / sec: 54417.13
Iteration:   1420, Loss function: 3.957, Average Loss: 4.473, avg. samples / sec: 54669.54
Iteration:   1420, Loss function: 2.757, Average Loss: 4.454, avg. samples / sec: 54710.48
Iteration:   1420, Loss function: 4.404, Average Loss: 4.482, avg. samples / sec: 54584.57
Iteration:   1440, Loss function: 4.460, Average Loss: 4.458, avg. samples / sec: 55308.24
Iteration:   1440, Loss function: 5.616, Average Loss: 4.478, avg. samples / sec: 54942.39
Iteration:   1440, Loss function: 4.227, Average Loss: 4.487, avg. samples / sec: 55003.04
Iteration:   1440, Loss function: 3.696, Average Loss: 4.458, avg. samples / sec: 55067.79
Iteration:   1440, Loss function: 3.946, Average Loss: 4.495, avg. samples / sec: 55010.19
Iteration:   1440, Loss function: 5.471, Average Loss: 4.479, avg. samples / sec: 54997.09
Iteration:   1440, Loss function: 5.143, Average Loss: 4.464, avg. samples / sec: 55020.41
Iteration:   1440, Loss function: 4.224, Average Loss: 4.461, avg. samples / sec: 55020.43
Iteration:   1440, Loss function: 3.877, Average Loss: 4.481, avg. samples / sec: 55042.31
Iteration:   1440, Loss function: 4.045, Average Loss: 4.491, avg. samples / sec: 54958.87
Iteration:   1440, Loss function: 3.584, Average Loss: 4.476, avg. samples / sec: 55029.73
Iteration:   1440, Loss function: 3.871, Average Loss: 4.456, avg. samples / sec: 54980.33
Iteration:   1440, Loss function: 5.186, Average Loss: 4.488, avg. samples / sec: 54947.56
Iteration:   1440, Loss function: 4.995, Average Loss: 4.487, avg. samples / sec: 55041.34
Iteration:   1440, Loss function: 4.350, Average Loss: 4.464, avg. samples / sec: 55023.50
Iteration:   1440, Loss function: 3.643, Average Loss: 4.465, avg. samples / sec: 55014.70
Iteration:   1440, Loss function: 4.553, Average Loss: 4.452, avg. samples / sec: 54868.68
Iteration:   1440, Loss function: 5.122, Average Loss: 4.471, avg. samples / sec: 55046.99
Iteration:   1440, Loss function: 4.034, Average Loss: 4.465, avg. samples / sec: 55000.29
Iteration:   1440, Loss function: 4.819, Average Loss: 4.486, avg. samples / sec: 54958.23
Iteration:   1440, Loss function: 3.484, Average Loss: 4.418, avg. samples / sec: 54991.94
Iteration:   1440, Loss function: 5.465, Average Loss: 4.489, avg. samples / sec: 55005.29
Iteration:   1440, Loss function: 3.922, Average Loss: 4.444, avg. samples / sec: 54968.62
Iteration:   1440, Loss function: 5.147, Average Loss: 4.485, avg. samples / sec: 54967.68
Iteration:   1440, Loss function: 3.717, Average Loss: 4.473, avg. samples / sec: 54972.46
Iteration:   1440, Loss function: 5.432, Average Loss: 4.476, avg. samples / sec: 54972.12
Iteration:   1440, Loss function: 4.743, Average Loss: 4.485, avg. samples / sec: 55007.89
Iteration:   1440, Loss function: 3.831, Average Loss: 4.456, avg. samples / sec: 54984.19
Iteration:   1440, Loss function: 3.841, Average Loss: 4.472, avg. samples / sec: 54928.30
Iteration:   1440, Loss function: 4.175, Average Loss: 4.476, avg. samples / sec: 54979.24
Iteration:   1460, Loss function: 4.468, Average Loss: 4.468, avg. samples / sec: 54475.10
Iteration:   1460, Loss function: 4.475, Average Loss: 4.476, avg. samples / sec: 54475.10
Iteration:   1460, Loss function: 3.560, Average Loss: 4.457, avg. samples / sec: 54470.62
Iteration:   1460, Loss function: 4.657, Average Loss: 4.489, avg. samples / sec: 54428.48
Iteration:   1460, Loss function: 4.143, Average Loss: 4.492, avg. samples / sec: 54503.16
Iteration:   1460, Loss function: 4.182, Average Loss: 4.479, avg. samples / sec: 54464.83
Iteration:   1460, Loss function: 3.873, Average Loss: 4.487, avg. samples / sec: 54503.71
Iteration:   1460, Loss function: 3.499, Average Loss: 4.495, avg. samples / sec: 54390.56
Iteration:   1460, Loss function: 5.362, Average Loss: 4.481, avg. samples / sec: 54474.66
Iteration:   1460, Loss function: 4.466, Average Loss: 4.467, avg. samples / sec: 54442.40
Iteration:   1460, Loss function: 5.319, Average Loss: 4.469, avg. samples / sec: 54389.98
Iteration:   1460, Loss function: 3.745, Average Loss: 4.463, avg. samples / sec: 54473.04
Iteration:   1460, Loss function: 4.443, Average Loss: 4.462, avg. samples / sec: 54446.90
Iteration:   1460, Loss function: 5.160, Average Loss: 4.489, avg. samples / sec: 54432.81
Iteration:   1460, Loss function: 4.722, Average Loss: 4.480, avg. samples / sec: 54263.09
Iteration:   1460, Loss function: 5.208, Average Loss: 4.485, avg. samples / sec: 54480.18
Iteration:   1460, Loss function: 5.352, Average Loss: 4.470, avg. samples / sec: 54460.45
Iteration:   1460, Loss function: 4.049, Average Loss: 4.454, avg. samples / sec: 54452.35
Iteration:   1460, Loss function: 4.099, Average Loss: 4.493, avg. samples / sec: 54481.36
Iteration:   1460, Loss function: 4.154, Average Loss: 4.444, avg. samples / sec: 54478.28
Iteration:   1460, Loss function: 3.823, Average Loss: 4.474, avg. samples / sec: 54437.63
Iteration:   1460, Loss function: 4.450, Average Loss: 4.476, avg. samples / sec: 54519.95
Iteration:   1460, Loss function: 4.356, Average Loss: 4.420, avg. samples / sec: 54460.58
Iteration:   1460, Loss function: 4.805, Average Loss: 4.471, avg. samples / sec: 54496.25
Iteration:   1460, Loss function: 3.587, Average Loss: 4.489, avg. samples / sec: 54476.93
Iteration:   1460, Loss function: 4.210, Average Loss: 4.472, avg. samples / sec: 54476.64
Iteration:   1460, Loss function: 4.399, Average Loss: 4.472, avg. samples / sec: 54448.67
Iteration:   1460, Loss function: 5.132, Average Loss: 4.459, avg. samples / sec: 54480.22
Iteration:   1460, Loss function: 5.550, Average Loss: 4.488, avg. samples / sec: 54421.38
Iteration:   1460, Loss function: 3.580, Average Loss: 4.455, avg. samples / sec: 54172.46
:::MLL 1558640325.411 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558640325.411 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.543, Average Loss: 4.477, avg. samples / sec: 54021.30
Iteration:   1480, Loss function: 4.237, Average Loss: 4.470, avg. samples / sec: 53966.32
Iteration:   1480, Loss function: 5.236, Average Loss: 4.461, avg. samples / sec: 53941.30
Iteration:   1480, Loss function: 4.995, Average Loss: 4.485, avg. samples / sec: 54166.44
Iteration:   1480, Loss function: 4.739, Average Loss: 4.490, avg. samples / sec: 53975.87
Iteration:   1480, Loss function: 4.834, Average Loss: 4.500, avg. samples / sec: 53998.99
Iteration:   1480, Loss function: 3.959, Average Loss: 4.467, avg. samples / sec: 54002.82
Iteration:   1480, Loss function: 5.062, Average Loss: 4.486, avg. samples / sec: 53968.92
Iteration:   1480, Loss function: 3.123, Average Loss: 4.466, avg. samples / sec: 54026.34
Iteration:   1480, Loss function: 5.781, Average Loss: 4.491, avg. samples / sec: 53946.14
Iteration:   1480, Loss function: 4.948, Average Loss: 4.488, avg. samples / sec: 53900.29
Iteration:   1480, Loss function: 5.097, Average Loss: 4.457, avg. samples / sec: 54256.90
Iteration:   1480, Loss function: 4.721, Average Loss: 4.479, avg. samples / sec: 53939.84
Iteration:   1480, Loss function: 4.687, Average Loss: 4.460, avg. samples / sec: 53961.90
Iteration:   1480, Loss function: 4.181, Average Loss: 4.456, avg. samples / sec: 53991.65
Iteration:   1480, Loss function: 4.247, Average Loss: 4.485, avg. samples / sec: 53952.91
Iteration:   1480, Loss function: 4.107, Average Loss: 4.491, avg. samples / sec: 54033.98
Iteration:   1480, Loss function: 5.507, Average Loss: 4.462, avg. samples / sec: 53942.23
Iteration:   1480, Loss function: 4.009, Average Loss: 4.485, avg. samples / sec: 53959.38
Iteration:   1480, Loss function: 4.737, Average Loss: 4.417, avg. samples / sec: 53977.11
Iteration:   1480, Loss function: 5.877, Average Loss: 4.473, avg. samples / sec: 53951.46
Iteration:   1480, Loss function: 4.406, Average Loss: 4.444, avg. samples / sec: 53954.50
Iteration:   1480, Loss function: 3.509, Average Loss: 4.472, avg. samples / sec: 53996.65
Iteration:   1480, Loss function: 3.515, Average Loss: 4.486, avg. samples / sec: 53987.30
Iteration:   1480, Loss function: 3.134, Average Loss: 4.477, avg. samples / sec: 53960.26
Iteration:   1480, Loss function: 5.078, Average Loss: 4.475, avg. samples / sec: 53950.31
Iteration:   1480, Loss function: 4.593, Average Loss: 4.468, avg. samples / sec: 53976.65
Iteration:   1480, Loss function: 4.905, Average Loss: 4.473, avg. samples / sec: 53973.84
Iteration:   1480, Loss function: 5.354, Average Loss: 4.493, avg. samples / sec: 53931.19
Iteration:   1480, Loss function: 3.840, Average Loss: 4.462, avg. samples / sec: 53938.41
Iteration:   1500, Loss function: 4.641, Average Loss: 4.460, avg. samples / sec: 54683.14
Iteration:   1500, Loss function: 3.990, Average Loss: 4.491, avg. samples / sec: 54566.05
Iteration:   1500, Loss function: 6.371, Average Loss: 4.484, avg. samples / sec: 54539.21
Iteration:   1500, Loss function: 5.496, Average Loss: 4.466, avg. samples / sec: 54580.27
Iteration:   1500, Loss function: 4.297, Average Loss: 4.479, avg. samples / sec: 54612.70
Iteration:   1500, Loss function: 4.150, Average Loss: 4.493, avg. samples / sec: 54587.59
Iteration:   1500, Loss function: 4.043, Average Loss: 4.473, avg. samples / sec: 54541.74
Iteration:   1500, Loss function: 4.543, Average Loss: 4.453, avg. samples / sec: 54584.57
Iteration:   1500, Loss function: 4.185, Average Loss: 4.486, avg. samples / sec: 54551.71
Iteration:   1500, Loss function: 4.726, Average Loss: 4.467, avg. samples / sec: 54375.66
Iteration:   1500, Loss function: 3.586, Average Loss: 4.485, avg. samples / sec: 54562.42
Iteration:   1500, Loss function: 3.914, Average Loss: 4.476, avg. samples / sec: 54338.47
Iteration:   1500, Loss function: 3.529, Average Loss: 4.475, avg. samples / sec: 54651.54
Iteration:   1500, Loss function: 3.511, Average Loss: 4.502, avg. samples / sec: 54348.80
Iteration:   1500, Loss function: 4.280, Average Loss: 4.460, avg. samples / sec: 54504.96
Iteration:   1500, Loss function: 3.049, Average Loss: 4.458, avg. samples / sec: 54620.78
Iteration:   1500, Loss function: 4.608, Average Loss: 4.494, avg. samples / sec: 54541.89
Iteration:   1500, Loss function: 5.922, Average Loss: 4.479, avg. samples / sec: 54562.54
Iteration:   1500, Loss function: 5.973, Average Loss: 4.480, avg. samples / sec: 54552.96
Iteration:   1500, Loss function: 4.420, Average Loss: 4.496, avg. samples / sec: 54521.97
Iteration:   1500, Loss function: 3.877, Average Loss: 4.471, avg. samples / sec: 54545.46
Iteration:   1500, Loss function: 2.776, Average Loss: 4.439, avg. samples / sec: 54542.15
Iteration:   1500, Loss function: 4.607, Average Loss: 4.485, avg. samples / sec: 54518.03
Iteration:   1500, Loss function: 3.819, Average Loss: 4.476, avg. samples / sec: 54535.56
Iteration:   1500, Loss function: 4.489, Average Loss: 4.459, avg. samples / sec: 54489.95
Iteration:   1500, Loss function: 4.463, Average Loss: 4.418, avg. samples / sec: 54531.04
Iteration:   1500, Loss function: 5.784, Average Loss: 4.466, avg. samples / sec: 54502.15
Iteration:   1500, Loss function: 4.409, Average Loss: 4.465, avg. samples / sec: 54532.90
Iteration:   1500, Loss function: 5.121, Average Loss: 4.482, avg. samples / sec: 54519.06
Iteration:   1500, Loss function: 4.790, Average Loss: 4.495, avg. samples / sec: 54517.69
Iteration:   1520, Loss function: 5.469, Average Loss: 4.473, avg. samples / sec: 54849.01
Iteration:   1520, Loss function: 4.515, Average Loss: 4.481, avg. samples / sec: 54755.99
Iteration:   1520, Loss function: 4.662, Average Loss: 4.457, avg. samples / sec: 54509.70
Iteration:   1520, Loss function: 4.173, Average Loss: 4.489, avg. samples / sec: 54649.23
Iteration:   1520, Loss function: 4.838, Average Loss: 4.489, avg. samples / sec: 54656.73
Iteration:   1520, Loss function: 5.538, Average Loss: 4.488, avg. samples / sec: 54673.48
Iteration:   1520, Loss function: 4.813, Average Loss: 4.458, avg. samples / sec: 54656.20
Iteration:   1520, Loss function: 4.172, Average Loss: 4.473, avg. samples / sec: 54622.39
Iteration:   1520, Loss function: 4.433, Average Loss: 4.502, avg. samples / sec: 54805.58
Iteration:   1520, Loss function: 4.864, Average Loss: 4.467, avg. samples / sec: 54588.56
Iteration:   1520, Loss function: 5.153, Average Loss: 4.490, avg. samples / sec: 54560.12
Iteration:   1520, Loss function: 4.199, Average Loss: 4.488, avg. samples / sec: 54601.04
Iteration:   1520, Loss function: 5.100, Average Loss: 4.470, avg. samples / sec: 54592.07
Iteration:   1520, Loss function: 3.595, Average Loss: 4.497, avg. samples / sec: 54858.73
Iteration:   1520, Loss function: 2.991, Average Loss: 4.480, avg. samples / sec: 54731.51
Iteration:   1520, Loss function: 3.705, Average Loss: 4.494, avg. samples / sec: 54676.56
Iteration:   1520, Loss function: 4.788, Average Loss: 4.457, avg. samples / sec: 54665.74
Iteration:   1520, Loss function: 4.777, Average Loss: 4.459, avg. samples / sec: 54662.27
Iteration:   1520, Loss function: 4.204, Average Loss: 4.440, avg. samples / sec: 54657.67
Iteration:   1520, Loss function: 3.324, Average Loss: 4.413, avg. samples / sec: 54652.18
Iteration:   1520, Loss function: 5.331, Average Loss: 4.469, avg. samples / sec: 54668.86
Iteration:   1520, Loss function: 5.317, Average Loss: 4.473, avg. samples / sec: 54545.59
Iteration:   1520, Loss function: 3.971, Average Loss: 4.495, avg. samples / sec: 54630.59
Iteration:   1520, Loss function: 5.342, Average Loss: 4.474, avg. samples / sec: 54625.23
Iteration:   1520, Loss function: 3.836, Average Loss: 4.475, avg. samples / sec: 54620.21
Iteration:   1520, Loss function: 4.325, Average Loss: 4.483, avg. samples / sec: 54647.68
Iteration:   1520, Loss function: 3.250, Average Loss: 4.478, avg. samples / sec: 54605.99
Iteration:   1520, Loss function: 5.176, Average Loss: 4.478, avg. samples / sec: 54603.90
Iteration:   1520, Loss function: 4.415, Average Loss: 4.471, avg. samples / sec: 54633.21
Iteration:   1520, Loss function: 4.605, Average Loss: 4.460, avg. samples / sec: 54492.90
:::MLL 1558640327.582 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558640327.582 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.883, Average Loss: 4.471, avg. samples / sec: 53541.19
Iteration:   1540, Loss function: 5.265, Average Loss: 4.458, avg. samples / sec: 53705.22
Iteration:   1540, Loss function: 4.335, Average Loss: 4.487, avg. samples / sec: 53722.97
Iteration:   1540, Loss function: 4.857, Average Loss: 4.473, avg. samples / sec: 53914.00
Iteration:   1540, Loss function: 3.692, Average Loss: 4.481, avg. samples / sec: 53570.48
Iteration:   1540, Loss function: 4.127, Average Loss: 4.481, avg. samples / sec: 53657.94
Iteration:   1540, Loss function: 4.941, Average Loss: 4.486, avg. samples / sec: 53563.90
Iteration:   1540, Loss function: 3.912, Average Loss: 4.474, avg. samples / sec: 53585.74
Iteration:   1540, Loss function: 4.325, Average Loss: 4.471, avg. samples / sec: 53789.28
Iteration:   1540, Loss function: 5.444, Average Loss: 4.492, avg. samples / sec: 53572.82
Iteration:   1540, Loss function: 4.183, Average Loss: 4.449, avg. samples / sec: 53522.38
Iteration:   1540, Loss function: 3.878, Average Loss: 4.499, avg. samples / sec: 53564.39
Iteration:   1540, Loss function: 4.998, Average Loss: 4.496, avg. samples / sec: 53674.76
Iteration:   1540, Loss function: 5.689, Average Loss: 4.474, avg. samples / sec: 53559.41
Iteration:   1540, Loss function: 4.664, Average Loss: 4.458, avg. samples / sec: 53673.45
Iteration:   1540, Loss function: 4.117, Average Loss: 4.468, avg. samples / sec: 53534.24
Iteration:   1540, Loss function: 4.844, Average Loss: 4.483, avg. samples / sec: 53709.58
Iteration:   1540, Loss function: 4.093, Average Loss: 4.490, avg. samples / sec: 53456.22
Iteration:   1540, Loss function: 4.764, Average Loss: 4.484, avg. samples / sec: 53593.83
Iteration:   1540, Loss function: 5.632, Average Loss: 4.418, avg. samples / sec: 53663.70
Iteration:   1540, Loss function: 3.936, Average Loss: 4.468, avg. samples / sec: 53695.48
Iteration:   1540, Loss function: 4.900, Average Loss: 4.473, avg. samples / sec: 53691.92
Iteration:   1540, Loss function: 4.130, Average Loss: 4.463, avg. samples / sec: 53600.76
Iteration:   1540, Loss function: 4.504, Average Loss: 4.438, avg. samples / sec: 53596.93
Iteration:   1540, Loss function: 3.959, Average Loss: 4.497, avg. samples / sec: 53430.28
Iteration:   1540, Loss function: 4.290, Average Loss: 4.498, avg. samples / sec: 53536.43
Iteration:   1540, Loss function: 4.344, Average Loss: 4.477, avg. samples / sec: 53556.88
Iteration:   1540, Loss function: 4.630, Average Loss: 4.481, avg. samples / sec: 53535.01
Iteration:   1540, Loss function: 3.957, Average Loss: 4.463, avg. samples / sec: 53618.52
Iteration:   1540, Loss function: 4.161, Average Loss: 4.470, avg. samples / sec: 53478.27
Iteration:   1560, Loss function: 4.783, Average Loss: 4.476, avg. samples / sec: 54637.24
Iteration:   1560, Loss function: 3.911, Average Loss: 4.483, avg. samples / sec: 54451.55
Iteration:   1560, Loss function: 3.535, Average Loss: 4.472, avg. samples / sec: 54401.15
Iteration:   1560, Loss function: 2.679, Average Loss: 4.480, avg. samples / sec: 54487.55
Iteration:   1560, Loss function: 4.890, Average Loss: 4.473, avg. samples / sec: 54571.52
Iteration:   1560, Loss function: 5.382, Average Loss: 4.489, avg. samples / sec: 54587.65
Iteration:   1560, Loss function: 3.741, Average Loss: 4.495, avg. samples / sec: 54518.58
Iteration:   1560, Loss function: 4.563, Average Loss: 4.490, avg. samples / sec: 54471.80
Iteration:   1560, Loss function: 5.584, Average Loss: 4.458, avg. samples / sec: 54334.89
Iteration:   1560, Loss function: 4.688, Average Loss: 4.479, avg. samples / sec: 54436.57
Iteration:   1560, Loss function: 4.300, Average Loss: 4.487, avg. samples / sec: 54378.01
Iteration:   1560, Loss function: 4.279, Average Loss: 4.479, avg. samples / sec: 54447.09
Iteration:   1560, Loss function: 3.605, Average Loss: 4.485, avg. samples / sec: 54549.39
Iteration:   1560, Loss function: 4.032, Average Loss: 4.452, avg. samples / sec: 54453.74
Iteration:   1560, Loss function: 4.727, Average Loss: 4.462, avg. samples / sec: 54535.01
Iteration:   1560, Loss function: 3.963, Average Loss: 4.469, avg. samples / sec: 54341.36
Iteration:   1560, Loss function: 5.145, Average Loss: 4.499, avg. samples / sec: 54405.37
Iteration:   1560, Loss function: 3.573, Average Loss: 4.455, avg. samples / sec: 54414.57
Iteration:   1560, Loss function: 3.754, Average Loss: 4.437, avg. samples / sec: 54499.45
Iteration:   1560, Loss function: 4.221, Average Loss: 4.495, avg. samples / sec: 54521.97
Iteration:   1560, Loss function: 5.083, Average Loss: 4.470, avg. samples / sec: 54429.53
Iteration:   1560, Loss function: 4.699, Average Loss: 4.500, avg. samples / sec: 54578.69
Iteration:   1560, Loss function: 4.871, Average Loss: 4.476, avg. samples / sec: 54438.21
Iteration:   1560, Loss function: 4.549, Average Loss: 4.423, avg. samples / sec: 54399.44
Iteration:   1560, Loss function: 3.978, Average Loss: 4.480, avg. samples / sec: 54390.21
Iteration:   1560, Loss function: 4.470, Average Loss: 4.470, avg. samples / sec: 54175.45
Iteration:   1560, Loss function: 3.889, Average Loss: 4.460, avg. samples / sec: 54588.39
Iteration:   1560, Loss function: 4.397, Average Loss: 4.486, avg. samples / sec: 54558.97
Iteration:   1560, Loss function: 5.413, Average Loss: 4.470, avg. samples / sec: 54541.24
Iteration:   1560, Loss function: 5.222, Average Loss: 4.476, avg. samples / sec: 54471.80
Iteration:   1580, Loss function: 4.281, Average Loss: 4.487, avg. samples / sec: 55142.30
Iteration:   1580, Loss function: 4.722, Average Loss: 4.468, avg. samples / sec: 55008.81
Iteration:   1580, Loss function: 4.808, Average Loss: 4.448, avg. samples / sec: 55105.39
Iteration:   1580, Loss function: 3.063, Average Loss: 4.477, avg. samples / sec: 55012.35
Iteration:   1580, Loss function: 4.295, Average Loss: 4.495, avg. samples / sec: 55015.49
Iteration:   1580, Loss function: 3.432, Average Loss: 4.488, avg. samples / sec: 55001.04
Iteration:   1580, Loss function: 4.363, Average Loss: 4.469, avg. samples / sec: 54981.47
Iteration:   1580, Loss function: 4.847, Average Loss: 4.463, avg. samples / sec: 55001.68
Iteration:   1580, Loss function: 4.200, Average Loss: 4.481, avg. samples / sec: 54957.61
Iteration:   1580, Loss function: 4.487, Average Loss: 4.491, avg. samples / sec: 54972.57
Iteration:   1580, Loss function: 4.135, Average Loss: 4.482, avg. samples / sec: 54877.97
Iteration:   1580, Loss function: 4.036, Average Loss: 4.477, avg. samples / sec: 54980.53
Iteration:   1580, Loss function: 3.766, Average Loss: 4.477, avg. samples / sec: 54867.12
Iteration:   1580, Loss function: 5.184, Average Loss: 4.465, avg. samples / sec: 54936.57
Iteration:   1580, Loss function: 4.814, Average Loss: 4.457, avg. samples / sec: 54965.64
Iteration:   1580, Loss function: 4.273, Average Loss: 4.470, avg. samples / sec: 55067.34
Iteration:   1580, Loss function: 3.907, Average Loss: 4.478, avg. samples / sec: 55004.99
Iteration:   1580, Loss function: 3.589, Average Loss: 4.437, avg. samples / sec: 54960.31
Iteration:   1580, Loss function: 4.681, Average Loss: 4.466, avg. samples / sec: 54932.59
Iteration:   1580, Loss function: 4.491, Average Loss: 4.416, avg. samples / sec: 54982.01
Iteration:   1580, Loss function: 5.301, Average Loss: 4.500, avg. samples / sec: 54924.81
Iteration:   1580, Loss function: 5.281, Average Loss: 4.465, avg. samples / sec: 54982.89
Iteration:   1580, Loss function: 5.068, Average Loss: 4.477, avg. samples / sec: 55060.35
Iteration:   1580, Loss function: 4.264, Average Loss: 4.491, avg. samples / sec: 54930.72
Iteration:   1580, Loss function: 4.575, Average Loss: 4.473, avg. samples / sec: 54931.43
Iteration:   1580, Loss function: 3.205, Average Loss: 4.489, avg. samples / sec: 54789.18
Iteration:   1580, Loss function: 4.976, Average Loss: 4.474, avg. samples / sec: 54916.47
Iteration:   1580, Loss function: 3.195, Average Loss: 4.463, avg. samples / sec: 54926.38
Iteration:   1580, Loss function: 4.912, Average Loss: 4.485, avg. samples / sec: 54930.34
Iteration:   1580, Loss function: 4.221, Average Loss: 4.499, avg. samples / sec: 54757.46
Iteration:   1600, Loss function: 4.528, Average Loss: 4.468, avg. samples / sec: 54962.19
Iteration:   1600, Loss function: 3.602, Average Loss: 4.475, avg. samples / sec: 55021.20
Iteration:   1600, Loss function: 4.127, Average Loss: 4.464, avg. samples / sec: 54968.37
Iteration:   1600, Loss function: 3.336, Average Loss: 4.455, avg. samples / sec: 54905.19
Iteration:   1600, Loss function: 4.050, Average Loss: 4.464, avg. samples / sec: 55192.38
Iteration:   1600, Loss function: 4.191, Average Loss: 4.487, avg. samples / sec: 54955.91
Iteration:   1600, Loss function: 3.862, Average Loss: 4.496, avg. samples / sec: 54944.11
Iteration:   1600, Loss function: 4.539, Average Loss: 4.485, avg. samples / sec: 54966.16
Iteration:   1600, Loss function: 3.968, Average Loss: 4.496, avg. samples / sec: 54965.09
Iteration:   1600, Loss function: 3.144, Average Loss: 4.466, avg. samples / sec: 54940.30
Iteration:   1600, Loss function: 3.906, Average Loss: 4.478, avg. samples / sec: 54902.54
Iteration:   1600, Loss function: 3.986, Average Loss: 4.478, avg. samples / sec: 54949.29
Iteration:   1600, Loss function: 5.317, Average Loss: 4.484, avg. samples / sec: 54924.28
Iteration:   1600, Loss function: 4.224, Average Loss: 4.499, avg. samples / sec: 55211.89
Iteration:   1600, Loss function: 3.401, Average Loss: 4.462, avg. samples / sec: 54976.60
Iteration:   1600, Loss function: 5.634, Average Loss: 4.464, avg. samples / sec: 54968.88
Iteration:   1600, Loss function: 4.335, Average Loss: 4.479, avg. samples / sec: 54948.07
Iteration:   1600, Loss function: 5.408, Average Loss: 4.496, avg. samples / sec: 54971.03
Iteration:   1600, Loss function: 3.832, Average Loss: 4.463, avg. samples / sec: 54956.86
Iteration:   1600, Loss function: 4.020, Average Loss: 4.454, avg. samples / sec: 54923.72
Iteration:   1600, Loss function: 4.594, Average Loss: 4.481, avg. samples / sec: 54619.68
Iteration:   1600, Loss function: 4.466, Average Loss: 4.492, avg. samples / sec: 54962.11
Iteration:   1600, Loss function: 5.501, Average Loss: 4.418, avg. samples / sec: 54932.59
Iteration:   1600, Loss function: 4.336, Average Loss: 4.436, avg. samples / sec: 54912.89
Iteration:   1600, Loss function: 6.371, Average Loss: 4.469, avg. samples / sec: 54950.62
Iteration:   1600, Loss function: 4.308, Average Loss: 4.476, avg. samples / sec: 54966.20
Iteration:   1600, Loss function: 3.830, Average Loss: 4.489, avg. samples / sec: 54949.78
Iteration:   1600, Loss function: 4.771, Average Loss: 4.477, avg. samples / sec: 54910.88
Iteration:   1600, Loss function: 4.205, Average Loss: 4.465, avg. samples / sec: 54966.50
Iteration:   1600, Loss function: 4.715, Average Loss: 4.483, avg. samples / sec: 54953.02
:::MLL 1558640329.733 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558640329.734 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 3.849, Average Loss: 4.468, avg. samples / sec: 53862.32
Iteration:   1620, Loss function: 5.796, Average Loss: 4.478, avg. samples / sec: 53927.70
Iteration:   1620, Loss function: 4.513, Average Loss: 4.452, avg. samples / sec: 53813.11
Iteration:   1620, Loss function: 4.888, Average Loss: 4.463, avg. samples / sec: 53946.90
Iteration:   1620, Loss function: 4.219, Average Loss: 4.489, avg. samples / sec: 53818.55
Iteration:   1620, Loss function: 4.358, Average Loss: 4.493, avg. samples / sec: 53762.30
Iteration:   1620, Loss function: 4.252, Average Loss: 4.485, avg. samples / sec: 53753.15
Iteration:   1620, Loss function: 4.428, Average Loss: 4.473, avg. samples / sec: 53734.11
Iteration:   1620, Loss function: 4.875, Average Loss: 4.480, avg. samples / sec: 53752.88
Iteration:   1620, Loss function: 4.852, Average Loss: 4.464, avg. samples / sec: 53761.37
Iteration:   1620, Loss function: 4.133, Average Loss: 4.477, avg. samples / sec: 53771.67
Iteration:   1620, Loss function: 5.009, Average Loss: 4.463, avg. samples / sec: 53706.00
Iteration:   1620, Loss function: 4.075, Average Loss: 4.494, avg. samples / sec: 53631.68
Iteration:   1620, Loss function: 3.995, Average Loss: 4.459, avg. samples / sec: 53736.18
Iteration:   1620, Loss function: 5.303, Average Loss: 4.449, avg. samples / sec: 53788.56
Iteration:   1620, Loss function: 3.619, Average Loss: 4.476, avg. samples / sec: 53773.50
Iteration:   1620, Loss function: 3.437, Average Loss: 4.479, avg. samples / sec: 53777.38
Iteration:   1620, Loss function: 3.462, Average Loss: 4.488, avg. samples / sec: 53758.32
Iteration:   1620, Loss function: 3.531, Average Loss: 4.499, avg. samples / sec: 53710.33
Iteration:   1620, Loss function: 3.972, Average Loss: 4.460, avg. samples / sec: 53739.95
Iteration:   1620, Loss function: 3.949, Average Loss: 4.424, avg. samples / sec: 53774.61
Iteration:   1620, Loss function: 4.328, Average Loss: 4.434, avg. samples / sec: 53776.00
Iteration:   1620, Loss function: 4.312, Average Loss: 4.470, avg. samples / sec: 53779.18
Iteration:   1620, Loss function: 3.831, Average Loss: 4.479, avg. samples / sec: 53813.60
Iteration:   1620, Loss function: 4.863, Average Loss: 4.464, avg. samples / sec: 53506.94
Iteration:   1620, Loss function: 4.091, Average Loss: 4.489, avg. samples / sec: 53732.23
Iteration:   1620, Loss function: 4.039, Average Loss: 4.469, avg. samples / sec: 53742.39
Iteration:   1620, Loss function: 3.999, Average Loss: 4.486, avg. samples / sec: 53750.75
Iteration:   1620, Loss function: 4.212, Average Loss: 4.477, avg. samples / sec: 53763.51
Iteration:   1620, Loss function: 3.868, Average Loss: 4.458, avg. samples / sec: 53735.26
Iteration:   1640, Loss function: 4.180, Average Loss: 4.478, avg. samples / sec: 54110.97
Iteration:   1640, Loss function: 4.493, Average Loss: 4.458, avg. samples / sec: 54165.11
Iteration:   1640, Loss function: 4.747, Average Loss: 4.487, avg. samples / sec: 54226.55
Iteration:   1640, Loss function: 4.269, Average Loss: 4.475, avg. samples / sec: 54229.68
Iteration:   1640, Loss function: 5.546, Average Loss: 4.465, avg. samples / sec: 54241.72
Iteration:   1640, Loss function: 4.870, Average Loss: 4.479, avg. samples / sec: 54226.84
Iteration:   1640, Loss function: 4.489, Average Loss: 4.489, avg. samples / sec: 54175.27
Iteration:   1640, Loss function: 6.650, Average Loss: 4.493, avg. samples / sec: 54310.41
Iteration:   1640, Loss function: 3.432, Average Loss: 4.464, avg. samples / sec: 54217.33
Iteration:   1640, Loss function: 3.260, Average Loss: 4.467, avg. samples / sec: 53949.25
Iteration:   1640, Loss function: 4.856, Average Loss: 4.491, avg. samples / sec: 54117.97
Iteration:   1640, Loss function: 4.808, Average Loss: 4.475, avg. samples / sec: 54211.70
Iteration:   1640, Loss function: 5.322, Average Loss: 4.489, avg. samples / sec: 54214.53
Iteration:   1640, Loss function: 4.717, Average Loss: 4.449, avg. samples / sec: 54184.43
Iteration:   1640, Loss function: 6.255, Average Loss: 4.430, avg. samples / sec: 54228.74
Iteration:   1640, Loss function: 4.023, Average Loss: 4.461, avg. samples / sec: 54219.56
Iteration:   1640, Loss function: 3.685, Average Loss: 4.458, avg. samples / sec: 53983.83
Iteration:   1640, Loss function: 3.517, Average Loss: 4.455, avg. samples / sec: 54179.97
Iteration:   1640, Loss function: 3.676, Average Loss: 4.467, avg. samples / sec: 54255.86
Iteration:   1640, Loss function: 5.742, Average Loss: 4.438, avg. samples / sec: 54208.53
Iteration:   1640, Loss function: 3.857, Average Loss: 4.477, avg. samples / sec: 54020.81
Iteration:   1640, Loss function: 4.305, Average Loss: 4.474, avg. samples / sec: 54172.27
Iteration:   1640, Loss function: 3.991, Average Loss: 4.463, avg. samples / sec: 54269.10
Iteration:   1640, Loss function: 3.007, Average Loss: 4.499, avg. samples / sec: 54185.29
Iteration:   1640, Loss function: 3.223, Average Loss: 4.475, avg. samples / sec: 54204.56
Iteration:   1640, Loss function: 3.342, Average Loss: 4.471, avg. samples / sec: 54194.18
Iteration:   1640, Loss function: 4.271, Average Loss: 4.490, avg. samples / sec: 54220.04
Iteration:   1640, Loss function: 4.131, Average Loss: 4.470, avg. samples / sec: 54213.18
Iteration:   1640, Loss function: 4.077, Average Loss: 4.474, avg. samples / sec: 54206.21
Iteration:   1640, Loss function: 4.363, Average Loss: 4.486, avg. samples / sec: 54177.60
Iteration:   1660, Loss function: 4.580, Average Loss: 4.473, avg. samples / sec: 54306.85
Iteration:   1660, Loss function: 4.801, Average Loss: 4.479, avg. samples / sec: 54344.25
Iteration:   1660, Loss function: 3.537, Average Loss: 4.456, avg. samples / sec: 54070.16
Iteration:   1660, Loss function: 4.122, Average Loss: 4.484, avg. samples / sec: 54077.15
Iteration:   1660, Loss function: 4.186, Average Loss: 4.483, avg. samples / sec: 54057.03
Iteration:   1660, Loss function: 3.139, Average Loss: 4.476, avg. samples / sec: 54065.90
Iteration:   1660, Loss function: 5.659, Average Loss: 4.486, avg. samples / sec: 54059.18
Iteration:   1660, Loss function: 4.069, Average Loss: 4.473, avg. samples / sec: 54283.61
Iteration:   1660, Loss function: 3.510, Average Loss: 4.495, avg. samples / sec: 54148.37
Iteration:   1660, Loss function: 3.501, Average Loss: 4.466, avg. samples / sec: 54043.26
Iteration:   1660, Loss function: 5.030, Average Loss: 4.490, avg. samples / sec: 54076.23
Iteration:   1660, Loss function: 4.836, Average Loss: 4.466, avg. samples / sec: 54219.75
Iteration:   1660, Loss function: 4.543, Average Loss: 4.469, avg. samples / sec: 54031.04
Iteration:   1660, Loss function: 5.808, Average Loss: 4.495, avg. samples / sec: 54019.09
Iteration:   1660, Loss function: 5.120, Average Loss: 4.460, avg. samples / sec: 54113.15
Iteration:   1660, Loss function: 5.433, Average Loss: 4.429, avg. samples / sec: 54086.36
Iteration:   1660, Loss function: 3.763, Average Loss: 4.459, avg. samples / sec: 54099.40
Iteration:   1660, Loss function: 4.815, Average Loss: 4.444, avg. samples / sec: 54097.05
Iteration:   1660, Loss function: 4.892, Average Loss: 4.468, avg. samples / sec: 54089.77
Iteration:   1660, Loss function: 5.613, Average Loss: 4.489, avg. samples / sec: 54071.42
Iteration:   1660, Loss function: 4.080, Average Loss: 4.462, avg. samples / sec: 54091.78
Iteration:   1660, Loss function: 4.325, Average Loss: 4.475, avg. samples / sec: 54052.11
Iteration:   1660, Loss function: 5.411, Average Loss: 4.481, avg. samples / sec: 54084.39
Iteration:   1660, Loss function: 5.289, Average Loss: 4.477, avg. samples / sec: 54086.42
Iteration:   1660, Loss function: 4.779, Average Loss: 4.500, avg. samples / sec: 54080.20
Iteration:   1660, Loss function: 5.326, Average Loss: 4.472, avg. samples / sec: 54079.55
Iteration:   1660, Loss function: 4.399, Average Loss: 4.474, avg. samples / sec: 54081.55
Iteration:   1660, Loss function: 3.315, Average Loss: 4.476, avg. samples / sec: 54078.72
Iteration:   1660, Loss function: 3.136, Average Loss: 4.496, avg. samples / sec: 54053.56
Iteration:   1660, Loss function: 5.083, Average Loss: 4.483, avg. samples / sec: 54098.03
:::MLL 1558640331.912 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558640331.912 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 5.237, Average Loss: 4.485, avg. samples / sec: 53984.43
Iteration:   1680, Loss function: 6.228, Average Loss: 4.474, avg. samples / sec: 53808.85
Iteration:   1680, Loss function: 6.009, Average Loss: 4.475, avg. samples / sec: 53891.86
Iteration:   1680, Loss function: 3.608, Average Loss: 4.456, avg. samples / sec: 54043.97
Iteration:   1680, Loss function: 5.505, Average Loss: 4.489, avg. samples / sec: 53800.33
Iteration:   1680, Loss function: 4.766, Average Loss: 4.498, avg. samples / sec: 53818.65
Iteration:   1680, Loss function: 4.110, Average Loss: 4.475, avg. samples / sec: 53797.29
Iteration:   1680, Loss function: 3.641, Average Loss: 4.485, avg. samples / sec: 53779.84
Iteration:   1680, Loss function: 3.627, Average Loss: 4.454, avg. samples / sec: 53763.51
Iteration:   1680, Loss function: 5.270, Average Loss: 4.494, avg. samples / sec: 53874.31
Iteration:   1680, Loss function: 3.390, Average Loss: 4.491, avg. samples / sec: 53811.26
Iteration:   1680, Loss function: 4.315, Average Loss: 4.464, avg. samples / sec: 53851.50
Iteration:   1680, Loss function: 3.328, Average Loss: 4.491, avg. samples / sec: 53968.94
Iteration:   1680, Loss function: 6.160, Average Loss: 4.426, avg. samples / sec: 53947.85
Iteration:   1680, Loss function: 3.928, Average Loss: 4.482, avg. samples / sec: 53979.32
Iteration:   1680, Loss function: 3.903, Average Loss: 4.470, avg. samples / sec: 53961.34
Iteration:   1680, Loss function: 4.633, Average Loss: 4.467, avg. samples / sec: 53936.10
Iteration:   1680, Loss function: 5.533, Average Loss: 4.475, avg. samples / sec: 53977.17
Iteration:   1680, Loss function: 4.030, Average Loss: 4.478, avg. samples / sec: 53688.75
Iteration:   1680, Loss function: 3.584, Average Loss: 4.462, avg. samples / sec: 53930.32
Iteration:   1680, Loss function: 2.514, Average Loss: 4.480, avg. samples / sec: 53967.41
Iteration:   1680, Loss function: 3.681, Average Loss: 4.466, avg. samples / sec: 53713.22
Iteration:   1680, Loss function: 3.786, Average Loss: 4.477, avg. samples / sec: 53828.32
Iteration:   1680, Loss function: 4.889, Average Loss: 4.468, avg. samples / sec: 53669.30
Iteration:   1680, Loss function: 4.083, Average Loss: 4.503, avg. samples / sec: 53818.12
Iteration:   1680, Loss function: 3.648, Average Loss: 4.470, avg. samples / sec: 53822.38
Iteration:   1680, Loss function: 4.341, Average Loss: 4.446, avg. samples / sec: 53777.03
Iteration:   1680, Loss function: 5.012, Average Loss: 4.500, avg. samples / sec: 53846.68
Iteration:   1680, Loss function: 4.002, Average Loss: 4.460, avg. samples / sec: 53762.48
Iteration:   1680, Loss function: 5.749, Average Loss: 4.476, avg. samples / sec: 53832.04
Iteration:   1700, Loss function: 5.172, Average Loss: 4.475, avg. samples / sec: 53846.97
Iteration:   1700, Loss function: 5.127, Average Loss: 4.488, avg. samples / sec: 53884.13
Iteration:   1700, Loss function: 4.441, Average Loss: 4.470, avg. samples / sec: 53891.98
Iteration:   1700, Loss function: 5.863, Average Loss: 4.487, avg. samples / sec: 53682.92
Iteration:   1700, Loss function: 4.045, Average Loss: 4.452, avg. samples / sec: 53876.37
Iteration:   1700, Loss function: 4.402, Average Loss: 4.492, avg. samples / sec: 53848.47
Iteration:   1700, Loss function: 5.049, Average Loss: 4.484, avg. samples / sec: 53862.08
Iteration:   1700, Loss function: 3.990, Average Loss: 4.492, avg. samples / sec: 53853.16
Iteration:   1700, Loss function: 4.103, Average Loss: 4.468, avg. samples / sec: 53741.80
Iteration:   1700, Loss function: 3.551, Average Loss: 4.465, avg. samples / sec: 53875.40
Iteration:   1700, Loss function: 3.841, Average Loss: 4.487, avg. samples / sec: 53830.31
Iteration:   1700, Loss function: 4.610, Average Loss: 4.468, avg. samples / sec: 53898.35
Iteration:   1700, Loss function: 4.212, Average Loss: 4.461, avg. samples / sec: 53829.69
Iteration:   1700, Loss function: 3.630, Average Loss: 4.478, avg. samples / sec: 53818.39
Iteration:   1700, Loss function: 4.356, Average Loss: 4.454, avg. samples / sec: 53610.89
Iteration:   1700, Loss function: 4.440, Average Loss: 4.488, avg. samples / sec: 53709.35
Iteration:   1700, Loss function: 4.518, Average Loss: 4.457, avg. samples / sec: 53887.59
Iteration:   1700, Loss function: 4.366, Average Loss: 4.444, avg. samples / sec: 53884.69
Iteration:   1700, Loss function: 4.831, Average Loss: 4.463, avg. samples / sec: 53718.30
Iteration:   1700, Loss function: 5.137, Average Loss: 4.472, avg. samples / sec: 53703.83
Iteration:   1700, Loss function: 4.501, Average Loss: 4.463, avg. samples / sec: 53837.01
Iteration:   1700, Loss function: 3.994, Average Loss: 4.474, avg. samples / sec: 53814.44
Iteration:   1700, Loss function: 4.283, Average Loss: 4.475, avg. samples / sec: 53729.17
Iteration:   1700, Loss function: 3.508, Average Loss: 4.421, avg. samples / sec: 53670.80
Iteration:   1700, Loss function: 3.486, Average Loss: 4.480, avg. samples / sec: 53669.26
Iteration:   1700, Loss function: 4.038, Average Loss: 4.499, avg. samples / sec: 53835.53
Iteration:   1700, Loss function: 4.038, Average Loss: 4.471, avg. samples / sec: 53842.94
Iteration:   1700, Loss function: 3.851, Average Loss: 4.462, avg. samples / sec: 53699.77
Iteration:   1700, Loss function: 4.103, Average Loss: 4.501, avg. samples / sec: 53815.43
Iteration:   1700, Loss function: 4.841, Average Loss: 4.472, avg. samples / sec: 53745.50
Iteration:   1720, Loss function: 4.588, Average Loss: 4.476, avg. samples / sec: 54996.45
Iteration:   1720, Loss function: 3.838, Average Loss: 4.456, avg. samples / sec: 55160.37
Iteration:   1720, Loss function: 4.610, Average Loss: 4.487, avg. samples / sec: 55012.81
Iteration:   1720, Loss function: 3.668, Average Loss: 4.448, avg. samples / sec: 55045.47
Iteration:   1720, Loss function: 4.432, Average Loss: 4.483, avg. samples / sec: 55021.48
Iteration:   1720, Loss function: 4.172, Average Loss: 4.489, avg. samples / sec: 55025.89
Iteration:   1720, Loss function: 4.605, Average Loss: 4.472, avg. samples / sec: 54966.33
Iteration:   1720, Loss function: 3.406, Average Loss: 4.480, avg. samples / sec: 55042.33
Iteration:   1720, Loss function: 4.275, Average Loss: 4.471, avg. samples / sec: 55023.63
Iteration:   1720, Loss function: 4.511, Average Loss: 4.490, avg. samples / sec: 55013.77
Iteration:   1720, Loss function: 4.630, Average Loss: 4.462, avg. samples / sec: 55054.71
Iteration:   1720, Loss function: 5.229, Average Loss: 4.485, avg. samples / sec: 54982.61
Iteration:   1720, Loss function: 4.223, Average Loss: 4.449, avg. samples / sec: 55036.09
Iteration:   1720, Loss function: 3.662, Average Loss: 4.458, avg. samples / sec: 55055.27
Iteration:   1720, Loss function: 5.487, Average Loss: 4.464, avg. samples / sec: 55068.18
Iteration:   1720, Loss function: 5.367, Average Loss: 4.426, avg. samples / sec: 55062.05
Iteration:   1720, Loss function: 4.177, Average Loss: 4.444, avg. samples / sec: 55025.54
Iteration:   1720, Loss function: 5.931, Average Loss: 4.501, avg. samples / sec: 55070.76
Iteration:   1720, Loss function: 4.322, Average Loss: 4.480, avg. samples / sec: 54926.10
Iteration:   1720, Loss function: 5.157, Average Loss: 4.475, avg. samples / sec: 55050.37
Iteration:   1720, Loss function: 4.421, Average Loss: 4.495, avg. samples / sec: 55073.24
Iteration:   1720, Loss function: 2.554, Average Loss: 4.489, avg. samples / sec: 54997.63
Iteration:   1720, Loss function: 3.499, Average Loss: 4.478, avg. samples / sec: 55029.60
Iteration:   1720, Loss function: 4.271, Average Loss: 4.469, avg. samples / sec: 55029.78
Iteration:   1720, Loss function: 3.275, Average Loss: 4.457, avg. samples / sec: 54824.22
Iteration:   1720, Loss function: 3.565, Average Loss: 4.474, avg. samples / sec: 55024.30
Iteration:   1720, Loss function: 4.307, Average Loss: 4.463, avg. samples / sec: 54985.22
Iteration:   1720, Loss function: 5.140, Average Loss: 4.475, avg. samples / sec: 55023.89
Iteration:   1720, Loss function: 6.372, Average Loss: 4.457, avg. samples / sec: 55011.93
Iteration:   1720, Loss function: 3.546, Average Loss: 4.470, avg. samples / sec: 55036.14
Iteration:   1740, Loss function: 4.404, Average Loss: 4.475, avg. samples / sec: 54787.45
Iteration:   1740, Loss function: 5.718, Average Loss: 4.474, avg. samples / sec: 54811.92
Iteration:   1740, Loss function: 3.627, Average Loss: 4.452, avg. samples / sec: 54744.67
Iteration:   1740, Loss function: 2.620, Average Loss: 4.473, avg. samples / sec: 54798.30
Iteration:   1740, Loss function: 4.220, Average Loss: 4.484, avg. samples / sec: 54753.16
Iteration:   1740, Loss function: 3.821, Average Loss: 4.494, avg. samples / sec: 54784.02
Iteration:   1740, Loss function: 4.448, Average Loss: 4.453, avg. samples / sec: 54659.02
Iteration:   1740, Loss function: 4.071, Average Loss: 4.487, avg. samples / sec: 54684.01
Iteration:   1740, Loss function: 5.580, Average Loss: 4.460, avg. samples / sec: 54741.40
Iteration:   1740, Loss function: 4.874, Average Loss: 4.486, avg. samples / sec: 54694.64
Iteration:   1740, Loss function: 3.070, Average Loss: 4.477, avg. samples / sec: 54728.82
Iteration:   1740, Loss function: 4.897, Average Loss: 4.468, avg. samples / sec: 54793.55
Iteration:   1740, Loss function: 5.239, Average Loss: 4.452, avg. samples / sec: 54739.02
Iteration:   1740, Loss function: 3.646, Average Loss: 4.445, avg. samples / sec: 54772.97
Iteration:   1740, Loss function: 4.981, Average Loss: 4.476, avg. samples / sec: 54801.85
Iteration:   1740, Loss function: 5.044, Average Loss: 4.478, avg. samples / sec: 54771.36
Iteration:   1740, Loss function: 5.664, Average Loss: 4.485, avg. samples / sec: 54772.44
Iteration:   1740, Loss function: 4.795, Average Loss: 4.453, avg. samples / sec: 54718.72
Iteration:   1740, Loss function: 4.649, Average Loss: 4.461, avg. samples / sec: 54790.61
Iteration:   1740, Loss function: 4.143, Average Loss: 4.422, avg. samples / sec: 54741.08
Iteration:   1740, Loss function: 4.813, Average Loss: 4.459, avg. samples / sec: 54768.76
Iteration:   1740, Loss function: 4.953, Average Loss: 4.498, avg. samples / sec: 54743.12
Iteration:   1740, Loss function: 4.162, Average Loss: 4.470, avg. samples / sec: 54772.38
Iteration:   1740, Loss function: 4.502, Average Loss: 4.473, avg. samples / sec: 54738.68
Iteration:   1740, Loss function: 3.407, Average Loss: 4.466, avg. samples / sec: 54841.46
Iteration:   1740, Loss function: 4.458, Average Loss: 4.468, avg. samples / sec: 54743.68
Iteration:   1740, Loss function: 4.477, Average Loss: 4.459, avg. samples / sec: 54762.61
Iteration:   1740, Loss function: 4.836, Average Loss: 4.481, avg. samples / sec: 54738.81
Iteration:   1740, Loss function: 4.214, Average Loss: 4.499, avg. samples / sec: 54693.98
Iteration:   1740, Loss function: 5.796, Average Loss: 4.477, avg. samples / sec: 54384.39
:::MLL 1558640334.071 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558640334.071 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 4.927, Average Loss: 4.476, avg. samples / sec: 54473.12
Iteration:   1760, Loss function: 4.385, Average Loss: 4.451, avg. samples / sec: 54438.00
Iteration:   1760, Loss function: 5.538, Average Loss: 4.487, avg. samples / sec: 54435.54
Iteration:   1760, Loss function: 4.472, Average Loss: 4.453, avg. samples / sec: 54449.97
Iteration:   1760, Loss function: 4.933, Average Loss: 4.479, avg. samples / sec: 54460.20
Iteration:   1760, Loss function: 3.837, Average Loss: 4.469, avg. samples / sec: 54393.48
Iteration:   1760, Loss function: 4.873, Average Loss: 4.471, avg. samples / sec: 54407.47
Iteration:   1760, Loss function: 4.197, Average Loss: 4.477, avg. samples / sec: 54811.62
Iteration:   1760, Loss function: 5.484, Average Loss: 4.460, avg. samples / sec: 54458.43
Iteration:   1760, Loss function: 4.080, Average Loss: 4.483, avg. samples / sec: 54448.29
Iteration:   1760, Loss function: 4.557, Average Loss: 4.482, avg. samples / sec: 54394.70
Iteration:   1760, Loss function: 4.377, Average Loss: 4.447, avg. samples / sec: 54427.16
Iteration:   1760, Loss function: 3.816, Average Loss: 4.479, avg. samples / sec: 54429.03
Iteration:   1760, Loss function: 4.942, Average Loss: 4.454, avg. samples / sec: 54442.29
Iteration:   1760, Loss function: 3.775, Average Loss: 4.462, avg. samples / sec: 54446.16
Iteration:   1760, Loss function: 3.994, Average Loss: 4.462, avg. samples / sec: 54461.59
Iteration:   1760, Loss function: 4.789, Average Loss: 4.468, avg. samples / sec: 54370.12
Iteration:   1760, Loss function: 3.740, Average Loss: 4.455, avg. samples / sec: 54422.68
Iteration:   1760, Loss function: 4.213, Average Loss: 4.499, avg. samples / sec: 54476.15
Iteration:   1760, Loss function: 5.703, Average Loss: 4.485, avg. samples / sec: 54463.25
Iteration:   1760, Loss function: 5.319, Average Loss: 4.448, avg. samples / sec: 54378.92
Iteration:   1760, Loss function: 4.297, Average Loss: 4.474, avg. samples / sec: 54417.95
Iteration:   1760, Loss function: 3.507, Average Loss: 4.499, avg. samples / sec: 54409.04
Iteration:   1760, Loss function: 3.914, Average Loss: 4.461, avg. samples / sec: 54421.82
Iteration:   1760, Loss function: 5.179, Average Loss: 4.493, avg. samples / sec: 54173.79
Iteration:   1760, Loss function: 5.238, Average Loss: 4.478, avg. samples / sec: 54367.55
Iteration:   1760, Loss function: 5.256, Average Loss: 4.473, avg. samples / sec: 54394.85
Iteration:   1760, Loss function: 4.709, Average Loss: 4.471, avg. samples / sec: 54351.69
Iteration:   1760, Loss function: 4.097, Average Loss: 4.426, avg. samples / sec: 54367.80
Iteration:   1760, Loss function: 4.921, Average Loss: 4.461, avg. samples / sec: 54379.42
Iteration:   1780, Loss function: 4.379, Average Loss: 4.472, avg. samples / sec: 54735.21
Iteration:   1780, Loss function: 3.542, Average Loss: 4.465, avg. samples / sec: 54873.21
Iteration:   1780, Loss function: 4.146, Average Loss: 4.480, avg. samples / sec: 54842.95
Iteration:   1780, Loss function: 3.654, Average Loss: 4.448, avg. samples / sec: 54840.48
Iteration:   1780, Loss function: 4.125, Average Loss: 4.459, avg. samples / sec: 54850.72
Iteration:   1780, Loss function: 3.935, Average Loss: 4.471, avg. samples / sec: 54832.41
Iteration:   1780, Loss function: 3.191, Average Loss: 4.451, avg. samples / sec: 54783.15
Iteration:   1780, Loss function: 4.563, Average Loss: 4.480, avg. samples / sec: 54791.73
Iteration:   1780, Loss function: 4.383, Average Loss: 4.476, avg. samples / sec: 54795.48
Iteration:   1780, Loss function: 3.220, Average Loss: 4.483, avg. samples / sec: 54796.49
Iteration:   1780, Loss function: 4.915, Average Loss: 4.481, avg. samples / sec: 54840.37
Iteration:   1780, Loss function: 4.399, Average Loss: 4.451, avg. samples / sec: 54906.11
Iteration:   1780, Loss function: 4.005, Average Loss: 4.438, avg. samples / sec: 54827.93
Iteration:   1780, Loss function: 5.132, Average Loss: 4.474, avg. samples / sec: 54807.59
Iteration:   1780, Loss function: 3.582, Average Loss: 4.451, avg. samples / sec: 54809.55
Iteration:   1780, Loss function: 4.217, Average Loss: 4.456, avg. samples / sec: 54813.43
Iteration:   1780, Loss function: 4.639, Average Loss: 4.470, avg. samples / sec: 54800.98
Iteration:   1780, Loss function: 4.361, Average Loss: 4.470, avg. samples / sec: 54819.36
Iteration:   1780, Loss function: 3.566, Average Loss: 4.446, avg. samples / sec: 54806.52
Iteration:   1780, Loss function: 4.406, Average Loss: 4.483, avg. samples / sec: 54800.53
Iteration:   1780, Loss function: 5.146, Average Loss: 4.464, avg. samples / sec: 54776.49
Iteration:   1780, Loss function: 4.083, Average Loss: 4.499, avg. samples / sec: 54790.31
Iteration:   1780, Loss function: 3.791, Average Loss: 4.489, avg. samples / sec: 54821.87
Iteration:   1780, Loss function: 4.553, Average Loss: 4.423, avg. samples / sec: 54834.31
Iteration:   1780, Loss function: 5.274, Average Loss: 4.477, avg. samples / sec: 54815.65
Iteration:   1780, Loss function: 3.162, Average Loss: 4.459, avg. samples / sec: 54842.03
Iteration:   1780, Loss function: 5.709, Average Loss: 4.467, avg. samples / sec: 54811.21
Iteration:   1780, Loss function: 5.150, Average Loss: 4.497, avg. samples / sec: 54790.78
Iteration:   1780, Loss function: 3.707, Average Loss: 4.466, avg. samples / sec: 54804.65
Iteration:   1780, Loss function: 3.239, Average Loss: 4.456, avg. samples / sec: 54784.36
Iteration:   1800, Loss function: 3.707, Average Loss: 4.471, avg. samples / sec: 54990.01
Iteration:   1800, Loss function: 4.070, Average Loss: 4.462, avg. samples / sec: 54971.20
Iteration:   1800, Loss function: 5.182, Average Loss: 4.452, avg. samples / sec: 55009.11
Iteration:   1800, Loss function: 4.040, Average Loss: 4.469, avg. samples / sec: 55007.03
Iteration:   1800, Loss function: 3.533, Average Loss: 4.479, avg. samples / sec: 55002.26
Iteration:   1800, Loss function: 4.459, Average Loss: 4.473, avg. samples / sec: 54952.42
Iteration:   1800, Loss function: 4.924, Average Loss: 4.487, avg. samples / sec: 55024.02
Iteration:   1800, Loss function: 3.994, Average Loss: 4.476, avg. samples / sec: 54902.99
Iteration:   1800, Loss function: 5.050, Average Loss: 4.455, avg. samples / sec: 54915.10
Iteration:   1800, Loss function: 4.602, Average Loss: 4.447, avg. samples / sec: 54901.15
Iteration:   1800, Loss function: 3.819, Average Loss: 4.480, avg. samples / sec: 54991.06
Iteration:   1800, Loss function: 5.169, Average Loss: 4.449, avg. samples / sec: 54982.99
Iteration:   1800, Loss function: 4.057, Average Loss: 4.464, avg. samples / sec: 55008.47
Iteration:   1800, Loss function: 4.010, Average Loss: 4.468, avg. samples / sec: 54962.47
Iteration:   1800, Loss function: 4.852, Average Loss: 4.458, avg. samples / sec: 55005.78
Iteration:   1800, Loss function: 3.968, Average Loss: 4.461, avg. samples / sec: 55022.11
Iteration:   1800, Loss function: 4.012, Average Loss: 4.494, avg. samples / sec: 55026.68
Iteration:   1800, Loss function: 3.718, Average Loss: 4.483, avg. samples / sec: 54994.11
Iteration:   1800, Loss function: 3.297, Average Loss: 4.453, avg. samples / sec: 54870.60
Iteration:   1800, Loss function: 4.327, Average Loss: 4.452, avg. samples / sec: 55003.21
Iteration:   1800, Loss function: 5.306, Average Loss: 4.446, avg. samples / sec: 54978.72
Iteration:   1800, Loss function: 3.385, Average Loss: 4.457, avg. samples / sec: 54946.61
Iteration:   1800, Loss function: 3.637, Average Loss: 4.476, avg. samples / sec: 54994.21
Iteration:   1800, Loss function: 4.366, Average Loss: 4.467, avg. samples / sec: 54965.99
Iteration:   1800, Loss function: 3.327, Average Loss: 4.492, avg. samples / sec: 54971.97
Iteration:   1800, Loss function: 4.317, Average Loss: 4.464, avg. samples / sec: 54995.61
Iteration:   1800, Loss function: 4.914, Average Loss: 4.417, avg. samples / sec: 54967.15
Iteration:   1800, Loss function: 4.983, Average Loss: 4.453, avg. samples / sec: 54988.03
Iteration:   1800, Loss function: 4.917, Average Loss: 4.482, avg. samples / sec: 54942.67
Iteration:   1800, Loss function: 4.015, Average Loss: 4.434, avg. samples / sec: 54579.47
:::MLL 1558640336.219 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558640336.219 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 4.225, Average Loss: 4.468, avg. samples / sec: 54582.68
Iteration:   1820, Loss function: 5.296, Average Loss: 4.478, avg. samples / sec: 54672.17
Iteration:   1820, Loss function: 3.951, Average Loss: 4.459, avg. samples / sec: 54556.63
Iteration:   1820, Loss function: 2.866, Average Loss: 4.443, avg. samples / sec: 54563.47
Iteration:   1820, Loss function: 4.251, Average Loss: 4.447, avg. samples / sec: 54746.65
Iteration:   1820, Loss function: 5.130, Average Loss: 4.477, avg. samples / sec: 54574.63
Iteration:   1820, Loss function: 5.053, Average Loss: 4.452, avg. samples / sec: 54481.78
Iteration:   1820, Loss function: 5.548, Average Loss: 4.458, avg. samples / sec: 54519.19
Iteration:   1820, Loss function: 4.717, Average Loss: 4.472, avg. samples / sec: 54484.03
Iteration:   1820, Loss function: 4.484, Average Loss: 4.478, avg. samples / sec: 54472.89
Iteration:   1820, Loss function: 4.146, Average Loss: 4.429, avg. samples / sec: 55032.70
Iteration:   1820, Loss function: 3.797, Average Loss: 4.456, avg. samples / sec: 54687.53
Iteration:   1820, Loss function: 4.190, Average Loss: 4.481, avg. samples / sec: 54456.01
Iteration:   1820, Loss function: 5.612, Average Loss: 4.469, avg. samples / sec: 54435.14
Iteration:   1820, Loss function: 5.050, Average Loss: 4.424, avg. samples / sec: 54703.13
Iteration:   1820, Loss function: 5.472, Average Loss: 4.464, avg. samples / sec: 54616.19
Iteration:   1820, Loss function: 3.822, Average Loss: 4.489, avg. samples / sec: 54648.76
Iteration:   1820, Loss function: 4.467, Average Loss: 4.446, avg. samples / sec: 54564.42
Iteration:   1820, Loss function: 4.556, Average Loss: 4.461, avg. samples / sec: 54503.80
Iteration:   1820, Loss function: 5.127, Average Loss: 4.449, avg. samples / sec: 54480.39
Iteration:   1820, Loss function: 4.205, Average Loss: 4.456, avg. samples / sec: 54520.18
Iteration:   1820, Loss function: 4.127, Average Loss: 4.468, avg. samples / sec: 54523.34
Iteration:   1820, Loss function: 3.672, Average Loss: 4.474, avg. samples / sec: 54505.29
Iteration:   1820, Loss function: 4.337, Average Loss: 4.482, avg. samples / sec: 54549.03
Iteration:   1820, Loss function: 4.145, Average Loss: 4.448, avg. samples / sec: 54486.96
Iteration:   1820, Loss function: 4.618, Average Loss: 4.491, avg. samples / sec: 54470.98
Iteration:   1820, Loss function: 4.292, Average Loss: 4.460, avg. samples / sec: 54502.32
Iteration:   1820, Loss function: 4.839, Average Loss: 4.449, avg. samples / sec: 54503.99
Iteration:   1820, Loss function: 4.766, Average Loss: 4.482, avg. samples / sec: 54442.19
Iteration:   1820, Loss function: 4.263, Average Loss: 4.456, avg. samples / sec: 54425.68
Iteration:   1840, Loss function: 4.404, Average Loss: 4.474, avg. samples / sec: 54806.39
Iteration:   1840, Loss function: 3.862, Average Loss: 4.457, avg. samples / sec: 54671.79
Iteration:   1840, Loss function: 4.045, Average Loss: 4.447, avg. samples / sec: 54731.64
Iteration:   1840, Loss function: 4.320, Average Loss: 4.453, avg. samples / sec: 54751.99
Iteration:   1840, Loss function: 4.387, Average Loss: 4.480, avg. samples / sec: 54785.64
Iteration:   1840, Loss function: 3.446, Average Loss: 4.450, avg. samples / sec: 54710.67
Iteration:   1840, Loss function: 4.495, Average Loss: 4.475, avg. samples / sec: 54750.54
Iteration:   1840, Loss function: 4.154, Average Loss: 4.475, avg. samples / sec: 54709.33
Iteration:   1840, Loss function: 5.317, Average Loss: 4.444, avg. samples / sec: 54704.81
Iteration:   1840, Loss function: 4.398, Average Loss: 4.464, avg. samples / sec: 54437.50
Iteration:   1840, Loss function: 4.373, Average Loss: 4.461, avg. samples / sec: 54808.38
Iteration:   1840, Loss function: 4.779, Average Loss: 4.449, avg. samples / sec: 54812.55
Iteration:   1840, Loss function: 4.243, Average Loss: 4.462, avg. samples / sec: 54672.64
Iteration:   1840, Loss function: 4.181, Average Loss: 4.448, avg. samples / sec: 54713.33
Iteration:   1840, Loss function: 5.429, Average Loss: 4.427, avg. samples / sec: 54575.01
Iteration:   1840, Loss function: 4.471, Average Loss: 4.486, avg. samples / sec: 54648.45
Iteration:   1840, Loss function: 3.688, Average Loss: 4.475, avg. samples / sec: 54764.06
Iteration:   1840, Loss function: 4.883, Average Loss: 4.456, avg. samples / sec: 54743.10
Iteration:   1840, Loss function: 3.083, Average Loss: 4.481, avg. samples / sec: 54760.57
Iteration:   1840, Loss function: 4.347, Average Loss: 4.469, avg. samples / sec: 54740.80
Iteration:   1840, Loss function: 3.807, Average Loss: 4.477, avg. samples / sec: 54363.54
Iteration:   1840, Loss function: 5.214, Average Loss: 4.489, avg. samples / sec: 54766.23
Iteration:   1840, Loss function: 4.345, Average Loss: 4.455, avg. samples / sec: 54769.01
Iteration:   1840, Loss function: 3.868, Average Loss: 4.426, avg. samples / sec: 54567.87
Iteration:   1840, Loss function: 4.679, Average Loss: 4.455, avg. samples / sec: 54520.07
Iteration:   1840, Loss function: 3.685, Average Loss: 4.441, avg. samples / sec: 54696.04
Iteration:   1840, Loss function: 4.511, Average Loss: 4.448, avg. samples / sec: 54623.47
Iteration:   1840, Loss function: 5.473, Average Loss: 4.471, avg. samples / sec: 54388.13
Iteration:   1840, Loss function: 4.376, Average Loss: 4.480, avg. samples / sec: 54526.76
Iteration:   1840, Loss function: 4.811, Average Loss: 4.457, avg. samples / sec: 54306.81
Iteration:   1860, Loss function: 4.517, Average Loss: 4.461, avg. samples / sec: 54831.07
Iteration:   1860, Loss function: 3.842, Average Loss: 4.451, avg. samples / sec: 54709.52
Iteration:   1860, Loss function: 4.677, Average Loss: 4.471, avg. samples / sec: 54704.47
Iteration:   1860, Loss function: 4.668, Average Loss: 4.479, avg. samples / sec: 54954.95
Iteration:   1860, Loss function: 4.177, Average Loss: 4.470, avg. samples / sec: 54723.50
Iteration:   1860, Loss function: 5.247, Average Loss: 4.449, avg. samples / sec: 54693.77
Iteration:   1860, Loss function: 4.325, Average Loss: 4.449, avg. samples / sec: 54710.10
Iteration:   1860, Loss function: 3.944, Average Loss: 4.468, avg. samples / sec: 54690.35
Iteration:   1860, Loss function: 4.740, Average Loss: 4.480, avg. samples / sec: 54683.03
Iteration:   1860, Loss function: 3.249, Average Loss: 4.453, avg. samples / sec: 54664.37
Iteration:   1860, Loss function: 6.058, Average Loss: 4.464, avg. samples / sec: 55041.88
Iteration:   1860, Loss function: 5.325, Average Loss: 4.462, avg. samples / sec: 54795.23
Iteration:   1860, Loss function: 4.718, Average Loss: 4.452, avg. samples / sec: 54878.98
Iteration:   1860, Loss function: 3.089, Average Loss: 4.424, avg. samples / sec: 54728.33
Iteration:   1860, Loss function: 4.108, Average Loss: 4.448, avg. samples / sec: 54713.98
Iteration:   1860, Loss function: 5.888, Average Loss: 4.456, avg. samples / sec: 54640.73
Iteration:   1860, Loss function: 3.133, Average Loss: 4.447, avg. samples / sec: 54651.24
Iteration:   1860, Loss function: 3.419, Average Loss: 4.475, avg. samples / sec: 54722.57
Iteration:   1860, Loss function: 4.294, Average Loss: 4.424, avg. samples / sec: 54736.91
Iteration:   1860, Loss function: 3.600, Average Loss: 4.472, avg. samples / sec: 54714.79
Iteration:   1860, Loss function: 5.055, Average Loss: 4.454, avg. samples / sec: 55230.75
Iteration:   1860, Loss function: 3.726, Average Loss: 4.482, avg. samples / sec: 54691.48
Iteration:   1860, Loss function: 5.831, Average Loss: 4.452, avg. samples / sec: 54700.67
Iteration:   1860, Loss function: 4.249, Average Loss: 4.469, avg. samples / sec: 54708.65
Iteration:   1860, Loss function: 5.697, Average Loss: 4.482, avg. samples / sec: 54701.28
Iteration:   1860, Loss function: 3.025, Average Loss: 4.439, avg. samples / sec: 54503.04
Iteration:   1860, Loss function: 6.014, Average Loss: 4.444, avg. samples / sec: 54864.24
Iteration:   1860, Loss function: 5.088, Average Loss: 4.439, avg. samples / sec: 54763.42
Iteration:   1860, Loss function: 4.358, Average Loss: 4.452, avg. samples / sec: 54676.64
Iteration:   1860, Loss function: 5.064, Average Loss: 4.477, avg. samples / sec: 54927.62
Iteration:   1880, Loss function: 4.569, Average Loss: 4.456, avg. samples / sec: 55003.66
Iteration:   1880, Loss function: 4.636, Average Loss: 4.442, avg. samples / sec: 55054.46
Iteration:   1880, Loss function: 4.136, Average Loss: 4.446, avg. samples / sec: 54874.15
Iteration:   1880, Loss function: 3.876, Average Loss: 4.464, avg. samples / sec: 54858.49
Iteration:   1880, Loss function: 4.119, Average Loss: 4.447, avg. samples / sec: 54815.52
Iteration:   1880, Loss function: 3.743, Average Loss: 4.449, avg. samples / sec: 54887.14
Iteration:   1880, Loss function: 4.712, Average Loss: 4.468, avg. samples / sec: 54867.72
Iteration:   1880, Loss function: 4.050, Average Loss: 4.466, avg. samples / sec: 54795.02
Iteration:   1880, Loss function: 4.216, Average Loss: 4.475, avg. samples / sec: 54814.35
Iteration:   1880, Loss function: 3.971, Average Loss: 4.473, avg. samples / sec: 54832.64
Iteration:   1880, Loss function: 4.957, Average Loss: 4.460, avg. samples / sec: 54849.23
Iteration:   1880, Loss function: 4.982, Average Loss: 4.453, avg. samples / sec: 54939.57
Iteration:   1880, Loss function: 4.759, Average Loss: 4.443, avg. samples / sec: 54878.42
Iteration:   1880, Loss function: 3.614, Average Loss: 4.441, avg. samples / sec: 54854.01
Iteration:   1880, Loss function: 3.699, Average Loss: 4.422, avg. samples / sec: 54837.83
Iteration:   1880, Loss function: 5.492, Average Loss: 4.449, avg. samples / sec: 54851.32
Iteration:   1880, Loss function: 3.360, Average Loss: 4.478, avg. samples / sec: 54885.31
Iteration:   1880, Loss function: 3.561, Average Loss: 4.432, avg. samples / sec: 54876.61
Iteration:   1880, Loss function: 2.525, Average Loss: 4.421, avg. samples / sec: 54850.17
Iteration:   1880, Loss function: 4.378, Average Loss: 4.462, avg. samples / sec: 54853.05
Iteration:   1880, Loss function: 3.708, Average Loss: 4.448, avg. samples / sec: 54701.98
Iteration:   1880, Loss function: 4.614, Average Loss: 4.462, avg. samples / sec: 54702.41
Iteration:   1880, Loss function: 3.398, Average Loss: 4.471, avg. samples / sec: 54829.51
Iteration:   1880, Loss function: 4.865, Average Loss: 4.457, avg. samples / sec: 54878.72
Iteration:   1880, Loss function: 3.801, Average Loss: 4.470, avg. samples / sec: 54817.59
Iteration:   1880, Loss function: 4.349, Average Loss: 4.475, avg. samples / sec: 54808.80
Iteration:   1880, Loss function: 4.167, Average Loss: 4.451, avg. samples / sec: 54826.63
Iteration:   1880, Loss function: 4.276, Average Loss: 4.433, avg. samples / sec: 54831.28
Iteration:   1880, Loss function: 4.716, Average Loss: 4.441, avg. samples / sec: 54791.84
Iteration:   1880, Loss function: 3.690, Average Loss: 4.478, avg. samples / sec: 54817.16
:::MLL 1558640338.369 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558640338.370 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 5.371, Average Loss: 4.460, avg. samples / sec: 54582.05
Iteration:   1900, Loss function: 3.662, Average Loss: 4.466, avg. samples / sec: 54550.78
Iteration:   1900, Loss function: 3.710, Average Loss: 4.439, avg. samples / sec: 54490.67
Iteration:   1900, Loss function: 4.866, Average Loss: 4.459, avg. samples / sec: 54564.70
Iteration:   1900, Loss function: 3.829, Average Loss: 4.445, avg. samples / sec: 54294.80
Iteration:   1900, Loss function: 3.265, Average Loss: 4.443, avg. samples / sec: 54479.31
Iteration:   1900, Loss function: 4.162, Average Loss: 4.459, avg. samples / sec: 54492.18
Iteration:   1900, Loss function: 3.481, Average Loss: 4.460, avg. samples / sec: 54468.43
Iteration:   1900, Loss function: 3.382, Average Loss: 4.441, avg. samples / sec: 54467.75
Iteration:   1900, Loss function: 4.017, Average Loss: 4.452, avg. samples / sec: 54203.56
Iteration:   1900, Loss function: 4.019, Average Loss: 4.466, avg. samples / sec: 54478.64
Iteration:   1900, Loss function: 3.640, Average Loss: 4.458, avg. samples / sec: 54597.04
Iteration:   1900, Loss function: 4.419, Average Loss: 4.444, avg. samples / sec: 54492.99
Iteration:   1900, Loss function: 4.461, Average Loss: 4.418, avg. samples / sec: 54504.24
Iteration:   1900, Loss function: 4.268, Average Loss: 4.452, avg. samples / sec: 54523.72
Iteration:   1900, Loss function: 4.041, Average Loss: 4.420, avg. samples / sec: 54496.90
Iteration:   1900, Loss function: 4.512, Average Loss: 4.448, avg. samples / sec: 54477.02
Iteration:   1900, Loss function: 3.934, Average Loss: 4.433, avg. samples / sec: 54472.76
Iteration:   1900, Loss function: 5.449, Average Loss: 4.457, avg. samples / sec: 54504.32
Iteration:   1900, Loss function: 5.488, Average Loss: 4.434, avg. samples / sec: 54486.37
Iteration:   1900, Loss function: 3.849, Average Loss: 4.477, avg. samples / sec: 54474.11
Iteration:   1900, Loss function: 3.255, Average Loss: 4.467, avg. samples / sec: 54502.91
Iteration:   1900, Loss function: 4.493, Average Loss: 4.435, avg. samples / sec: 54560.83
Iteration:   1900, Loss function: 3.868, Average Loss: 4.471, avg. samples / sec: 54508.31
Iteration:   1900, Loss function: 4.275, Average Loss: 4.444, avg. samples / sec: 54393.29
Iteration:   1900, Loss function: 4.121, Average Loss: 4.461, avg. samples / sec: 54500.66
Iteration:   1900, Loss function: 5.107, Average Loss: 4.429, avg. samples / sec: 54512.38
Iteration:   1900, Loss function: 4.015, Average Loss: 4.444, avg. samples / sec: 54468.26
Iteration:   1900, Loss function: 5.855, Average Loss: 4.447, avg. samples / sec: 54482.41
Iteration:   1900, Loss function: 3.199, Average Loss: 4.472, avg. samples / sec: 54549.77
Iteration:   1920, Loss function: 2.678, Average Loss: 4.444, avg. samples / sec: 55061.49
Iteration:   1920, Loss function: 4.956, Average Loss: 4.459, avg. samples / sec: 54866.35
Iteration:   1920, Loss function: 3.733, Average Loss: 4.456, avg. samples / sec: 54790.20
Iteration:   1920, Loss function: 5.180, Average Loss: 4.439, avg. samples / sec: 54870.28
Iteration:   1920, Loss function: 3.755, Average Loss: 4.441, avg. samples / sec: 54871.16
Iteration:   1920, Loss function: 4.150, Average Loss: 4.457, avg. samples / sec: 54838.79
Iteration:   1920, Loss function: 4.969, Average Loss: 4.457, avg. samples / sec: 54843.68
Iteration:   1920, Loss function: 6.071, Average Loss: 4.437, avg. samples / sec: 54793.74
Iteration:   1920, Loss function: 3.705, Average Loss: 4.440, avg. samples / sec: 54833.09
Iteration:   1920, Loss function: 5.391, Average Loss: 4.456, avg. samples / sec: 54803.67
Iteration:   1920, Loss function: 3.428, Average Loss: 4.467, avg. samples / sec: 54841.76
Iteration:   1920, Loss function: 3.822, Average Loss: 4.453, avg. samples / sec: 54794.57
Iteration:   1920, Loss function: 4.477, Average Loss: 4.418, avg. samples / sec: 54835.44
Iteration:   1920, Loss function: 5.772, Average Loss: 4.443, avg. samples / sec: 54814.13
Iteration:   1920, Loss function: 2.966, Average Loss: 4.440, avg. samples / sec: 54829.30
Iteration:   1920, Loss function: 4.471, Average Loss: 4.436, avg. samples / sec: 54834.31
Iteration:   1920, Loss function: 4.110, Average Loss: 4.434, avg. samples / sec: 54851.77
Iteration:   1920, Loss function: 4.091, Average Loss: 4.443, avg. samples / sec: 54873.06
Iteration:   1920, Loss function: 4.702, Average Loss: 4.458, avg. samples / sec: 54822.06
Iteration:   1920, Loss function: 4.242, Average Loss: 4.417, avg. samples / sec: 54806.18
Iteration:   1920, Loss function: 4.117, Average Loss: 4.467, avg. samples / sec: 54836.36
Iteration:   1920, Loss function: 3.723, Average Loss: 4.426, avg. samples / sec: 54815.18
Iteration:   1920, Loss function: 4.859, Average Loss: 4.441, avg. samples / sec: 54847.56
Iteration:   1920, Loss function: 4.465, Average Loss: 4.470, avg. samples / sec: 54847.48
Iteration:   1920, Loss function: 5.735, Average Loss: 4.424, avg. samples / sec: 54825.26
Iteration:   1920, Loss function: 4.323, Average Loss: 4.474, avg. samples / sec: 54798.87
Iteration:   1920, Loss function: 4.100, Average Loss: 4.439, avg. samples / sec: 54818.93
Iteration:   1920, Loss function: 5.927, Average Loss: 4.446, avg. samples / sec: 54778.34
Iteration:   1920, Loss function: 4.449, Average Loss: 4.456, avg. samples / sec: 54808.36
Iteration:   1920, Loss function: 4.503, Average Loss: 4.462, avg. samples / sec: 54792.69
Iteration:   1940, Loss function: 4.813, Average Loss: 4.449, avg. samples / sec: 54940.89
Iteration:   1940, Loss function: 3.344, Average Loss: 4.438, avg. samples / sec: 54850.89
Iteration:   1940, Loss function: 3.207, Average Loss: 4.435, avg. samples / sec: 54894.16
Iteration:   1940, Loss function: 4.837, Average Loss: 4.440, avg. samples / sec: 54823.62
Iteration:   1940, Loss function: 4.442, Average Loss: 4.452, avg. samples / sec: 54784.15
Iteration:   1940, Loss function: 4.042, Average Loss: 4.451, avg. samples / sec: 54845.81
Iteration:   1940, Loss function: 3.903, Average Loss: 4.455, avg. samples / sec: 54803.71
Iteration:   1940, Loss function: 4.751, Average Loss: 4.434, avg. samples / sec: 54860.56
Iteration:   1940, Loss function: 4.592, Average Loss: 4.452, avg. samples / sec: 54865.31
Iteration:   1940, Loss function: 4.234, Average Loss: 4.460, avg. samples / sec: 54883.30
Iteration:   1940, Loss function: 4.313, Average Loss: 4.457, avg. samples / sec: 54814.47
Iteration:   1940, Loss function: 4.305, Average Loss: 4.418, avg. samples / sec: 54875.65
Iteration:   1940, Loss function: 4.471, Average Loss: 4.442, avg. samples / sec: 54891.46
Iteration:   1940, Loss function: 6.314, Average Loss: 4.439, avg. samples / sec: 54887.04
Iteration:   1940, Loss function: 2.915, Average Loss: 4.468, avg. samples / sec: 54927.96
Iteration:   1940, Loss function: 4.772, Average Loss: 4.449, avg. samples / sec: 54809.21
Iteration:   1940, Loss function: 3.245, Average Loss: 4.430, avg. samples / sec: 54854.44
Iteration:   1940, Loss function: 3.456, Average Loss: 4.454, avg. samples / sec: 54908.51
Iteration:   1940, Loss function: 3.862, Average Loss: 4.426, avg. samples / sec: 54866.59
Iteration:   1940, Loss function: 4.859, Average Loss: 4.439, avg. samples / sec: 54848.35
Iteration:   1940, Loss function: 4.286, Average Loss: 4.430, avg. samples / sec: 54839.51
Iteration:   1940, Loss function: 4.721, Average Loss: 4.462, avg. samples / sec: 54857.89
Iteration:   1940, Loss function: 4.482, Average Loss: 4.422, avg. samples / sec: 54874.15
Iteration:   1940, Loss function: 5.212, Average Loss: 4.457, avg. samples / sec: 54896.59
Iteration:   1940, Loss function: 4.975, Average Loss: 4.432, avg. samples / sec: 54862.70
Iteration:   1940, Loss function: 3.494, Average Loss: 4.465, avg. samples / sec: 54863.98
Iteration:   1940, Loss function: 5.768, Average Loss: 4.445, avg. samples / sec: 54877.72
Iteration:   1940, Loss function: 3.910, Average Loss: 4.438, avg. samples / sec: 54859.52
Iteration:   1940, Loss function: 4.189, Average Loss: 4.455, avg. samples / sec: 54832.77
Iteration:   1940, Loss function: 5.347, Average Loss: 4.416, avg. samples / sec: 54829.70
:::MLL 1558640340.520 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558640340.521 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.786, Average Loss: 4.452, avg. samples / sec: 54260.27
Iteration:   1960, Loss function: 4.805, Average Loss: 4.455, avg. samples / sec: 54445.03
Iteration:   1960, Loss function: 3.764, Average Loss: 4.436, avg. samples / sec: 54399.49
Iteration:   1960, Loss function: 3.161, Average Loss: 4.431, avg. samples / sec: 54316.10
Iteration:   1960, Loss function: 4.382, Average Loss: 4.458, avg. samples / sec: 54348.57
Iteration:   1960, Loss function: 5.260, Average Loss: 4.444, avg. samples / sec: 54314.68
Iteration:   1960, Loss function: 5.353, Average Loss: 4.454, avg. samples / sec: 54338.99
Iteration:   1960, Loss function: 4.707, Average Loss: 4.452, avg. samples / sec: 54299.07
Iteration:   1960, Loss function: 3.723, Average Loss: 4.449, avg. samples / sec: 54322.78
Iteration:   1960, Loss function: 4.345, Average Loss: 4.414, avg. samples / sec: 54430.83
Iteration:   1960, Loss function: 5.066, Average Loss: 4.451, avg. samples / sec: 54281.92
Iteration:   1960, Loss function: 3.994, Average Loss: 4.429, avg. samples / sec: 54275.27
Iteration:   1960, Loss function: 3.776, Average Loss: 4.426, avg. samples / sec: 54461.82
Iteration:   1960, Loss function: 4.203, Average Loss: 4.463, avg. samples / sec: 54452.03
Iteration:   1960, Loss function: 3.170, Average Loss: 4.451, avg. samples / sec: 54409.90
Iteration:   1960, Loss function: 5.404, Average Loss: 4.447, avg. samples / sec: 54397.83
Iteration:   1960, Loss function: 4.657, Average Loss: 4.426, avg. samples / sec: 54408.56
Iteration:   1960, Loss function: 6.176, Average Loss: 4.454, avg. samples / sec: 54331.58
Iteration:   1960, Loss function: 5.055, Average Loss: 4.421, avg. samples / sec: 54302.25
Iteration:   1960, Loss function: 4.290, Average Loss: 4.458, avg. samples / sec: 54311.33
Iteration:   1960, Loss function: 3.742, Average Loss: 4.436, avg. samples / sec: 54310.76
Iteration:   1960, Loss function: 4.502, Average Loss: 4.436, avg. samples / sec: 54225.75
Iteration:   1960, Loss function: 3.295, Average Loss: 4.415, avg. samples / sec: 54327.22
Iteration:   1960, Loss function: 5.034, Average Loss: 4.467, avg. samples / sec: 54241.60
Iteration:   1960, Loss function: 5.720, Average Loss: 4.439, avg. samples / sec: 54238.90
Iteration:   1960, Loss function: 4.709, Average Loss: 4.434, avg. samples / sec: 54293.36
Iteration:   1960, Loss function: 4.633, Average Loss: 4.428, avg. samples / sec: 54264.49
Iteration:   1960, Loss function: 3.658, Average Loss: 4.437, avg. samples / sec: 54267.54
Iteration:   1960, Loss function: 3.819, Average Loss: 4.450, avg. samples / sec: 54257.13
Iteration:   1960, Loss function: 5.244, Average Loss: 4.421, avg. samples / sec: 54248.07
Iteration:   1980, Loss function: 5.870, Average Loss: 4.449, avg. samples / sec: 54906.80
Iteration:   1980, Loss function: 4.274, Average Loss: 4.440, avg. samples / sec: 54980.10
Iteration:   1980, Loss function: 4.047, Average Loss: 4.434, avg. samples / sec: 54804.28
Iteration:   1980, Loss function: 3.266, Average Loss: 4.449, avg. samples / sec: 54936.95
Iteration:   1980, Loss function: 4.182, Average Loss: 4.449, avg. samples / sec: 54937.32
Iteration:   1980, Loss function: 4.122, Average Loss: 4.437, avg. samples / sec: 55116.92
Iteration:   1980, Loss function: 4.093, Average Loss: 4.428, avg. samples / sec: 54920.19
Iteration:   1980, Loss function: 5.208, Average Loss: 4.450, avg. samples / sec: 54710.71
Iteration:   1980, Loss function: 4.647, Average Loss: 4.431, avg. samples / sec: 54834.50
Iteration:   1980, Loss function: 3.352, Average Loss: 4.442, avg. samples / sec: 54862.81
Iteration:   1980, Loss function: 3.821, Average Loss: 4.455, avg. samples / sec: 54832.58
Iteration:   1980, Loss function: 3.672, Average Loss: 4.450, avg. samples / sec: 54839.07
Iteration:   1980, Loss function: 3.665, Average Loss: 4.410, avg. samples / sec: 54833.65
Iteration:   1980, Loss function: 3.474, Average Loss: 4.432, avg. samples / sec: 54971.75
Iteration:   1980, Loss function: 4.535, Average Loss: 4.459, avg. samples / sec: 54773.12
Iteration:   1980, Loss function: 5.159, Average Loss: 4.446, avg. samples / sec: 54794.53
Iteration:   1980, Loss function: 3.589, Average Loss: 4.416, avg. samples / sec: 54753.67
Iteration:   1980, Loss function: 4.788, Average Loss: 4.437, avg. samples / sec: 54942.78
Iteration:   1980, Loss function: 4.581, Average Loss: 4.418, avg. samples / sec: 54902.15
Iteration:   1980, Loss function: 4.047, Average Loss: 4.416, avg. samples / sec: 54921.62
Iteration:   1980, Loss function: 4.270, Average Loss: 4.423, avg. samples / sec: 54925.16
Iteration:   1980, Loss function: 5.179, Average Loss: 4.444, avg. samples / sec: 54787.15
Iteration:   1980, Loss function: 5.034, Average Loss: 4.424, avg. samples / sec: 54797.89
Iteration:   1980, Loss function: 5.432, Average Loss: 4.433, avg. samples / sec: 54925.28
Iteration:   1980, Loss function: 4.110, Average Loss: 4.431, avg. samples / sec: 54902.77
Iteration:   1980, Loss function: 4.049, Average Loss: 4.465, avg. samples / sec: 54905.64
Iteration:   1980, Loss function: 3.827, Average Loss: 4.451, avg. samples / sec: 54877.68
Iteration:   1980, Loss function: 4.265, Average Loss: 4.458, avg. samples / sec: 54874.71
Iteration:   1980, Loss function: 3.958, Average Loss: 4.444, avg. samples / sec: 54919.70
Iteration:   1980, Loss function: 4.009, Average Loss: 4.424, avg. samples / sec: 54906.20
Iteration:   2000, Loss function: 3.923, Average Loss: 4.447, avg. samples / sec: 54949.85
Iteration:   2000, Loss function: 4.514, Average Loss: 4.437, avg. samples / sec: 54975.53
Iteration:   2000, Loss function: 4.504, Average Loss: 4.442, avg. samples / sec: 55002.69
Iteration:   2000, Loss function: 4.290, Average Loss: 4.440, avg. samples / sec: 55026.92
Iteration:   2000, Loss function: 4.801, Average Loss: 4.432, avg. samples / sec: 54880.88
Iteration:   2000, Loss function: 4.946, Average Loss: 4.443, avg. samples / sec: 54941.13
Iteration:   2000, Loss function: 4.029, Average Loss: 4.437, avg. samples / sec: 55014.89
Iteration:   2000, Loss function: 4.465, Average Loss: 4.420, avg. samples / sec: 54983.34
Iteration:   2000, Loss function: 4.066, Average Loss: 4.430, avg. samples / sec: 54975.23
Iteration:   2000, Loss function: 4.116, Average Loss: 4.444, avg. samples / sec: 54986.02
Iteration:   2000, Loss function: 3.373, Average Loss: 4.448, avg. samples / sec: 54944.15
Iteration:   2000, Loss function: 4.554, Average Loss: 4.433, avg. samples / sec: 54897.39
Iteration:   2000, Loss function: 3.424, Average Loss: 4.406, avg. samples / sec: 54902.15
Iteration:   2000, Loss function: 4.485, Average Loss: 4.425, avg. samples / sec: 54957.69
Iteration:   2000, Loss function: 4.203, Average Loss: 4.439, avg. samples / sec: 54986.90
Iteration:   2000, Loss function: 3.775, Average Loss: 4.431, avg. samples / sec: 54982.07
Iteration:   2000, Loss function: 3.812, Average Loss: 4.434, avg. samples / sec: 54995.91
Iteration:   2000, Loss function: 4.658, Average Loss: 4.414, avg. samples / sec: 54968.75
Iteration:   2000, Loss function: 4.662, Average Loss: 4.426, avg. samples / sec: 54988.61
Iteration:   2000, Loss function: 3.080, Average Loss: 4.442, avg. samples / sec: 54985.12
Iteration:   2000, Loss function: 3.522, Average Loss: 4.434, avg. samples / sec: 54975.89
Iteration:   2000, Loss function: 3.931, Average Loss: 4.463, avg. samples / sec: 54976.02
Iteration:   2000, Loss function: 3.710, Average Loss: 4.419, avg. samples / sec: 55019.53
Iteration:   2000, Loss function: 3.975, Average Loss: 4.454, avg. samples / sec: 54940.04
Iteration:   2000, Loss function: 6.332, Average Loss: 4.425, avg. samples / sec: 54958.61
Iteration:   2000, Loss function: 5.156, Average Loss: 4.413, avg. samples / sec: 54945.41
Iteration:   2000, Loss function: 4.455, Average Loss: 4.417, avg. samples / sec: 54958.08
Iteration:   2000, Loss function: 3.192, Average Loss: 4.451, avg. samples / sec: 54977.39
Iteration:   2000, Loss function: 5.142, Average Loss: 4.442, avg. samples / sec: 54970.13
Iteration:   2000, Loss function: 3.279, Average Loss: 4.408, avg. samples / sec: 54927.40
Iteration:   2020, Loss function: 3.864, Average Loss: 4.447, avg. samples / sec: 54980.25
Iteration:   2020, Loss function: 4.302, Average Loss: 4.434, avg. samples / sec: 54984.28
Iteration:   2020, Loss function: 3.665, Average Loss: 4.424, avg. samples / sec: 55045.83
Iteration:   2020, Loss function: 5.319, Average Loss: 4.441, avg. samples / sec: 54960.54
Iteration:   2020, Loss function: 4.190, Average Loss: 4.441, avg. samples / sec: 54989.19
Iteration:   2020, Loss function: 4.316, Average Loss: 4.438, avg. samples / sec: 54951.28
Iteration:   2020, Loss function: 5.517, Average Loss: 4.426, avg. samples / sec: 54983.64
Iteration:   2020, Loss function: 4.882, Average Loss: 4.451, avg. samples / sec: 55038.69
Iteration:   2020, Loss function: 4.308, Average Loss: 4.430, avg. samples / sec: 54941.28
Iteration:   2020, Loss function: 5.004, Average Loss: 4.441, avg. samples / sec: 54966.74
Iteration:   2020, Loss function: 3.530, Average Loss: 4.424, avg. samples / sec: 55121.38
Iteration:   2020, Loss function: 4.187, Average Loss: 4.433, avg. samples / sec: 54917.11
Iteration:   2020, Loss function: 4.219, Average Loss: 4.420, avg. samples / sec: 54975.87
Iteration:   2020, Loss function: 5.443, Average Loss: 4.400, avg. samples / sec: 54960.46
Iteration:   2020, Loss function: 5.288, Average Loss: 4.440, avg. samples / sec: 55012.14
Iteration:   2020, Loss function: 5.739, Average Loss: 4.427, avg. samples / sec: 54884.94
Iteration:   2020, Loss function: 3.374, Average Loss: 4.415, avg. samples / sec: 54990.09
Iteration:   2020, Loss function: 4.500, Average Loss: 4.429, avg. samples / sec: 54974.22
Iteration:   2020, Loss function: 4.449, Average Loss: 4.449, avg. samples / sec: 55005.87
Iteration:   2020, Loss function: 4.381, Average Loss: 4.435, avg. samples / sec: 54961.27
Iteration:   2020, Loss function: 6.033, Average Loss: 4.411, avg. samples / sec: 54998.34
Iteration:   2020, Loss function: 3.941, Average Loss: 4.439, avg. samples / sec: 55010.04
Iteration:   2020, Loss function: 4.774, Average Loss: 4.419, avg. samples / sec: 54969.48
Iteration:   2020, Loss function: 3.791, Average Loss: 4.441, avg. samples / sec: 54962.09
Iteration:   2020, Loss function: 5.088, Average Loss: 4.415, avg. samples / sec: 54974.91
Iteration:   2020, Loss function: 2.497, Average Loss: 4.444, avg. samples / sec: 54974.33
Iteration:   2020, Loss function: 5.503, Average Loss: 4.407, avg. samples / sec: 54969.48
Iteration:   2020, Loss function: 4.684, Average Loss: 4.463, avg. samples / sec: 54934.73
Iteration:   2020, Loss function: 4.116, Average Loss: 4.425, avg. samples / sec: 54918.84
Iteration:   2020, Loss function: 4.122, Average Loss: 4.418, avg. samples / sec: 54936.12
:::MLL 1558640342.665 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558640342.666 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 4.602, Average Loss: 4.443, avg. samples / sec: 54481.15
Iteration:   2040, Loss function: 4.268, Average Loss: 4.438, avg. samples / sec: 54526.95
Iteration:   2040, Loss function: 4.732, Average Loss: 4.429, avg. samples / sec: 54493.45
Iteration:   2040, Loss function: 4.066, Average Loss: 4.420, avg. samples / sec: 54550.27
Iteration:   2040, Loss function: 4.998, Average Loss: 4.439, avg. samples / sec: 54497.35
Iteration:   2040, Loss function: 5.245, Average Loss: 4.420, avg. samples / sec: 54467.88
Iteration:   2040, Loss function: 4.249, Average Loss: 4.449, avg. samples / sec: 54505.99
Iteration:   2040, Loss function: 4.946, Average Loss: 4.441, avg. samples / sec: 54533.05
Iteration:   2040, Loss function: 4.160, Average Loss: 4.429, avg. samples / sec: 54539.66
Iteration:   2040, Loss function: 4.700, Average Loss: 4.431, avg. samples / sec: 54478.89
Iteration:   2040, Loss function: 5.214, Average Loss: 4.420, avg. samples / sec: 54476.66
Iteration:   2040, Loss function: 3.591, Average Loss: 4.396, avg. samples / sec: 54526.23
Iteration:   2040, Loss function: 4.253, Average Loss: 4.405, avg. samples / sec: 54519.78
Iteration:   2040, Loss function: 3.863, Average Loss: 4.445, avg. samples / sec: 54517.97
Iteration:   2040, Loss function: 4.311, Average Loss: 4.423, avg. samples / sec: 54514.13
Iteration:   2040, Loss function: 2.903, Average Loss: 4.420, avg. samples / sec: 54491.13
Iteration:   2040, Loss function: 5.441, Average Loss: 4.437, avg. samples / sec: 54499.10
Iteration:   2040, Loss function: 3.841, Average Loss: 4.423, avg. samples / sec: 54361.55
Iteration:   2040, Loss function: 5.078, Average Loss: 4.414, avg. samples / sec: 54587.44
Iteration:   2040, Loss function: 4.281, Average Loss: 4.404, avg. samples / sec: 54518.62
Iteration:   2040, Loss function: 3.009, Average Loss: 4.435, avg. samples / sec: 54514.02
Iteration:   2040, Loss function: 5.627, Average Loss: 4.426, avg. samples / sec: 54490.27
Iteration:   2040, Loss function: 3.144, Average Loss: 4.421, avg. samples / sec: 54560.52
Iteration:   2040, Loss function: 5.134, Average Loss: 4.436, avg. samples / sec: 54525.69
Iteration:   2040, Loss function: 4.587, Average Loss: 4.416, avg. samples / sec: 54527.04
Iteration:   2040, Loss function: 4.082, Average Loss: 4.435, avg. samples / sec: 54492.14
Iteration:   2040, Loss function: 4.470, Average Loss: 4.460, avg. samples / sec: 54542.44
Iteration:   2040, Loss function: 4.180, Average Loss: 4.438, avg. samples / sec: 54512.46
Iteration:   2040, Loss function: 4.352, Average Loss: 4.405, avg. samples / sec: 54520.07
Iteration:   2040, Loss function: 4.087, Average Loss: 4.414, avg. samples / sec: 54488.81
Iteration:   2060, Loss function: 4.639, Average Loss: 4.446, avg. samples / sec: 54867.46
Iteration:   2060, Loss function: 3.706, Average Loss: 4.421, avg. samples / sec: 54846.26
Iteration:   2060, Loss function: 3.647, Average Loss: 4.434, avg. samples / sec: 54906.56
Iteration:   2060, Loss function: 4.414, Average Loss: 4.436, avg. samples / sec: 54838.55
Iteration:   2060, Loss function: 3.484, Average Loss: 4.415, avg. samples / sec: 54833.63
Iteration:   2060, Loss function: 4.535, Average Loss: 4.434, avg. samples / sec: 54852.75
Iteration:   2060, Loss function: 4.470, Average Loss: 4.415, avg. samples / sec: 54849.10
Iteration:   2060, Loss function: 3.721, Average Loss: 4.419, avg. samples / sec: 54875.45
Iteration:   2060, Loss function: 3.172, Average Loss: 4.421, avg. samples / sec: 54854.35
Iteration:   2060, Loss function: 5.944, Average Loss: 4.452, avg. samples / sec: 54830.72
Iteration:   2060, Loss function: 3.019, Average Loss: 4.433, avg. samples / sec: 54819.48
Iteration:   2060, Loss function: 3.837, Average Loss: 4.393, avg. samples / sec: 54817.78
Iteration:   2060, Loss function: 4.307, Average Loss: 4.417, avg. samples / sec: 54844.36
Iteration:   2060, Loss function: 5.255, Average Loss: 4.419, avg. samples / sec: 54846.07
Iteration:   2060, Loss function: 4.490, Average Loss: 4.415, avg. samples / sec: 54810.12
Iteration:   2060, Loss function: 4.642, Average Loss: 4.421, avg. samples / sec: 54834.39
Iteration:   2060, Loss function: 5.481, Average Loss: 4.403, avg. samples / sec: 54815.48
Iteration:   2060, Loss function: 2.989, Average Loss: 4.410, avg. samples / sec: 54834.93
Iteration:   2060, Loss function: 4.543, Average Loss: 4.443, avg. samples / sec: 54800.30
Iteration:   2060, Loss function: 4.014, Average Loss: 4.434, avg. samples / sec: 54844.12
Iteration:   2060, Loss function: 3.802, Average Loss: 4.431, avg. samples / sec: 54825.65
Iteration:   2060, Loss function: 4.281, Average Loss: 4.433, avg. samples / sec: 54793.76
Iteration:   2060, Loss function: 4.664, Average Loss: 4.451, avg. samples / sec: 54828.23
Iteration:   2060, Loss function: 4.855, Average Loss: 4.410, avg. samples / sec: 54846.90
Iteration:   2060, Loss function: 3.724, Average Loss: 4.399, avg. samples / sec: 54766.99
Iteration:   2060, Loss function: 4.057, Average Loss: 4.400, avg. samples / sec: 54829.32
Iteration:   2060, Loss function: 3.970, Average Loss: 4.438, avg. samples / sec: 54800.73
Iteration:   2060, Loss function: 5.164, Average Loss: 4.409, avg. samples / sec: 54775.61
Iteration:   2060, Loss function: 6.483, Average Loss: 4.430, avg. samples / sec: 54789.26
Iteration:   2060, Loss function: 4.064, Average Loss: 4.417, avg. samples / sec: 54790.90
Iteration:   2080, Loss function: 3.581, Average Loss: 4.408, avg. samples / sec: 54703.58
Iteration:   2080, Loss function: 4.241, Average Loss: 4.445, avg. samples / sec: 54493.20
Iteration:   2080, Loss function: 3.717, Average Loss: 4.419, avg. samples / sec: 54588.46
Iteration:   2080, Loss function: 3.476, Average Loss: 4.415, avg. samples / sec: 54612.55
Iteration:   2080, Loss function: 5.183, Average Loss: 4.429, avg. samples / sec: 54572.41
Iteration:   2080, Loss function: 3.517, Average Loss: 4.446, avg. samples / sec: 54633.81
Iteration:   2080, Loss function: 4.032, Average Loss: 4.426, avg. samples / sec: 54571.97
Iteration:   2080, Loss function: 2.921, Average Loss: 4.418, avg. samples / sec: 54582.47
Iteration:   2080, Loss function: 5.048, Average Loss: 4.419, avg. samples / sec: 54585.39
Iteration:   2080, Loss function: 3.040, Average Loss: 4.434, avg. samples / sec: 54511.15
Iteration:   2080, Loss function: 4.172, Average Loss: 4.433, avg. samples / sec: 54586.55
Iteration:   2080, Loss function: 3.432, Average Loss: 4.413, avg. samples / sec: 54658.15
Iteration:   2080, Loss function: 5.410, Average Loss: 4.400, avg. samples / sec: 54641.62
Iteration:   2080, Loss function: 3.387, Average Loss: 4.413, avg. samples / sec: 54607.26
Iteration:   2080, Loss function: 3.359, Average Loss: 4.407, avg. samples / sec: 54634.57
Iteration:   2080, Loss function: 4.114, Average Loss: 4.431, avg. samples / sec: 54646.03
Iteration:   2080, Loss function: 3.929, Average Loss: 4.414, avg. samples / sec: 54584.73
Iteration:   2080, Loss function: 4.504, Average Loss: 4.396, avg. samples / sec: 54653.15
Iteration:   2080, Loss function: 4.105, Average Loss: 4.446, avg. samples / sec: 54638.81
Iteration:   2080, Loss function: 4.241, Average Loss: 4.433, avg. samples / sec: 54614.12
Iteration:   2080, Loss function: 4.444, Average Loss: 4.390, avg. samples / sec: 54557.83
Iteration:   2080, Loss function: 5.671, Average Loss: 4.442, avg. samples / sec: 54611.39
Iteration:   2080, Loss function: 4.260, Average Loss: 4.404, avg. samples / sec: 54592.81
Iteration:   2080, Loss function: 4.551, Average Loss: 4.416, avg. samples / sec: 54628.13
Iteration:   2080, Loss function: 3.881, Average Loss: 4.403, avg. samples / sec: 54622.44
Iteration:   2080, Loss function: 3.741, Average Loss: 4.427, avg. samples / sec: 54621.88
Iteration:   2080, Loss function: 3.973, Average Loss: 4.437, avg. samples / sec: 54611.28
Iteration:   2080, Loss function: 4.514, Average Loss: 4.430, avg. samples / sec: 54575.75
Iteration:   2080, Loss function: 4.448, Average Loss: 4.404, avg. samples / sec: 54574.12
Iteration:   2080, Loss function: 3.492, Average Loss: 4.398, avg. samples / sec: 54575.94
:::MLL 1558640344.818 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558640344.818 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 5.418, Average Loss: 4.434, avg. samples / sec: 54421.67
Iteration:   2100, Loss function: 4.100, Average Loss: 4.427, avg. samples / sec: 54710.37
Iteration:   2100, Loss function: 5.335, Average Loss: 4.427, avg. samples / sec: 54552.15
Iteration:   2100, Loss function: 4.743, Average Loss: 4.410, avg. samples / sec: 54453.13
Iteration:   2100, Loss function: 3.591, Average Loss: 4.408, avg. samples / sec: 54382.99
Iteration:   2100, Loss function: 4.180, Average Loss: 4.428, avg. samples / sec: 54442.36
Iteration:   2100, Loss function: 3.837, Average Loss: 4.405, avg. samples / sec: 54267.75
Iteration:   2100, Loss function: 4.488, Average Loss: 4.412, avg. samples / sec: 54375.14
Iteration:   2100, Loss function: 4.431, Average Loss: 4.416, avg. samples / sec: 54348.34
Iteration:   2100, Loss function: 3.174, Average Loss: 4.419, avg. samples / sec: 54348.19
Iteration:   2100, Loss function: 4.154, Average Loss: 4.440, avg. samples / sec: 54300.70
Iteration:   2100, Loss function: 4.102, Average Loss: 4.386, avg. samples / sec: 54528.79
Iteration:   2100, Loss function: 4.494, Average Loss: 4.394, avg. samples / sec: 54498.36
Iteration:   2100, Loss function: 4.858, Average Loss: 4.401, avg. samples / sec: 54532.61
Iteration:   2100, Loss function: 4.166, Average Loss: 4.431, avg. samples / sec: 54483.72
Iteration:   2100, Loss function: 4.443, Average Loss: 4.422, avg. samples / sec: 54453.49
Iteration:   2100, Loss function: 3.636, Average Loss: 4.402, avg. samples / sec: 54421.21
Iteration:   2100, Loss function: 3.286, Average Loss: 4.399, avg. samples / sec: 54365.34
Iteration:   2100, Loss function: 2.421, Average Loss: 4.392, avg. samples / sec: 54351.21
Iteration:   2100, Loss function: 4.344, Average Loss: 4.403, avg. samples / sec: 54346.96
Iteration:   2100, Loss function: 3.539, Average Loss: 4.406, avg. samples / sec: 54376.90
Iteration:   2100, Loss function: 4.848, Average Loss: 4.408, avg. samples / sec: 54338.39
Iteration:   2100, Loss function: 3.668, Average Loss: 4.421, avg. samples / sec: 54381.81
Iteration:   2100, Loss function: 5.058, Average Loss: 4.400, avg. samples / sec: 54401.21
Iteration:   2100, Loss function: 4.121, Average Loss: 4.414, avg. samples / sec: 54288.32
Iteration:   2100, Loss function: 4.612, Average Loss: 4.441, avg. samples / sec: 54330.22
Iteration:   2100, Loss function: 4.811, Average Loss: 4.440, avg. samples / sec: 54333.84
Iteration:   2100, Loss function: 3.349, Average Loss: 4.422, avg. samples / sec: 54098.74
Iteration:   2100, Loss function: 4.657, Average Loss: 4.388, avg. samples / sec: 54384.67
Iteration:   2100, Loss function: 4.584, Average Loss: 4.427, avg. samples / sec: 54308.94
Iteration:   2120, Loss function: 5.313, Average Loss: 4.432, avg. samples / sec: 54970.19
Iteration:   2120, Loss function: 4.182, Average Loss: 4.405, avg. samples / sec: 54897.88
Iteration:   2120, Loss function: 3.910, Average Loss: 4.401, avg. samples / sec: 54923.25
Iteration:   2120, Loss function: 4.530, Average Loss: 4.414, avg. samples / sec: 54952.68
Iteration:   2120, Loss function: 3.858, Average Loss: 4.407, avg. samples / sec: 54802.24
Iteration:   2120, Loss function: 4.126, Average Loss: 4.409, avg. samples / sec: 54935.20
Iteration:   2120, Loss function: 3.469, Average Loss: 4.439, avg. samples / sec: 54967.06
Iteration:   2120, Loss function: 4.190, Average Loss: 4.419, avg. samples / sec: 54752.23
Iteration:   2120, Loss function: 4.397, Average Loss: 4.418, avg. samples / sec: 54915.03
Iteration:   2120, Loss function: 4.135, Average Loss: 4.421, avg. samples / sec: 54809.08
Iteration:   2120, Loss function: 5.620, Average Loss: 4.415, avg. samples / sec: 55008.92
Iteration:   2120, Loss function: 4.924, Average Loss: 4.406, avg. samples / sec: 54971.09
Iteration:   2120, Loss function: 5.103, Average Loss: 4.390, avg. samples / sec: 54929.57
Iteration:   2120, Loss function: 5.069, Average Loss: 4.401, avg. samples / sec: 54935.48
Iteration:   2120, Loss function: 4.675, Average Loss: 4.438, avg. samples / sec: 54969.70
Iteration:   2120, Loss function: 5.402, Average Loss: 4.397, avg. samples / sec: 54910.99
Iteration:   2120, Loss function: 4.450, Average Loss: 4.381, avg. samples / sec: 54785.34
Iteration:   2120, Loss function: 4.088, Average Loss: 4.390, avg. samples / sec: 54778.10
Iteration:   2120, Loss function: 3.807, Average Loss: 4.436, avg. samples / sec: 54959.00
Iteration:   2120, Loss function: 4.562, Average Loss: 4.419, avg. samples / sec: 54881.24
Iteration:   2120, Loss function: 4.136, Average Loss: 4.422, avg. samples / sec: 54975.21
Iteration:   2120, Loss function: 4.640, Average Loss: 4.423, avg. samples / sec: 54814.79
Iteration:   2120, Loss function: 4.876, Average Loss: 4.399, avg. samples / sec: 54907.57
Iteration:   2120, Loss function: 4.422, Average Loss: 4.403, avg. samples / sec: 54752.12
Iteration:   2120, Loss function: 3.771, Average Loss: 4.398, avg. samples / sec: 54855.37
Iteration:   2120, Loss function: 4.266, Average Loss: 4.417, avg. samples / sec: 54899.95
Iteration:   2120, Loss function: 3.115, Average Loss: 4.402, avg. samples / sec: 54898.20
Iteration:   2120, Loss function: 4.881, Average Loss: 4.424, avg. samples / sec: 54914.05
Iteration:   2120, Loss function: 4.403, Average Loss: 4.380, avg. samples / sec: 54912.17
Iteration:   2120, Loss function: 3.605, Average Loss: 4.423, avg. samples / sec: 54484.03
Iteration:   2140, Loss function: 3.944, Average Loss: 4.430, avg. samples / sec: 54700.54
Iteration:   2140, Loss function: 2.731, Average Loss: 4.406, avg. samples / sec: 54872.68
Iteration:   2140, Loss function: 4.937, Average Loss: 4.397, avg. samples / sec: 54832.39
Iteration:   2140, Loss function: 4.182, Average Loss: 4.410, avg. samples / sec: 54848.24
Iteration:   2140, Loss function: 4.183, Average Loss: 4.417, avg. samples / sec: 54908.59
Iteration:   2140, Loss function: 3.943, Average Loss: 4.434, avg. samples / sec: 54820.44
Iteration:   2140, Loss function: 5.632, Average Loss: 4.394, avg. samples / sec: 54801.51
Iteration:   2140, Loss function: 3.802, Average Loss: 4.404, avg. samples / sec: 54806.07
Iteration:   2140, Loss function: 4.419, Average Loss: 4.415, avg. samples / sec: 55074.03
Iteration:   2140, Loss function: 4.806, Average Loss: 4.416, avg. samples / sec: 54814.13
Iteration:   2140, Loss function: 4.680, Average Loss: 4.413, avg. samples / sec: 54787.03
Iteration:   2140, Loss function: 4.357, Average Loss: 4.400, avg. samples / sec: 54847.03
Iteration:   2140, Loss function: 4.014, Average Loss: 4.403, avg. samples / sec: 54838.36
Iteration:   2140, Loss function: 3.446, Average Loss: 4.392, avg. samples / sec: 54840.28
Iteration:   2140, Loss function: 3.720, Average Loss: 4.412, avg. samples / sec: 54784.75
Iteration:   2140, Loss function: 3.925, Average Loss: 4.379, avg. samples / sec: 54901.34
Iteration:   2140, Loss function: 4.498, Average Loss: 4.414, avg. samples / sec: 54840.73
Iteration:   2140, Loss function: 5.441, Average Loss: 4.434, avg. samples / sec: 54820.55
Iteration:   2140, Loss function: 3.673, Average Loss: 4.387, avg. samples / sec: 54827.78
Iteration:   2140, Loss function: 3.840, Average Loss: 4.380, avg. samples / sec: 54801.43
Iteration:   2140, Loss function: 3.498, Average Loss: 4.418, avg. samples / sec: 54821.06
Iteration:   2140, Loss function: 4.861, Average Loss: 4.400, avg. samples / sec: 54838.53
Iteration:   2140, Loss function: 4.502, Average Loss: 4.386, avg. samples / sec: 54779.32
Iteration:   2140, Loss function: 5.244, Average Loss: 4.392, avg. samples / sec: 54826.95
Iteration:   2140, Loss function: 5.695, Average Loss: 4.433, avg. samples / sec: 54802.84
Iteration:   2140, Loss function: 3.867, Average Loss: 4.402, avg. samples / sec: 54817.48
Iteration:   2140, Loss function: 3.815, Average Loss: 4.404, avg. samples / sec: 54816.54
Iteration:   2140, Loss function: 4.251, Average Loss: 4.421, avg. samples / sec: 54800.30
Iteration:   2140, Loss function: 3.528, Average Loss: 4.422, avg. samples / sec: 54832.32
Iteration:   2140, Loss function: 4.483, Average Loss: 4.404, avg. samples / sec: 54796.63
Iteration:   2160, Loss function: 4.219, Average Loss: 4.427, avg. samples / sec: 54978.66
Iteration:   2160, Loss function: 4.382, Average Loss: 4.403, avg. samples / sec: 54890.86
Iteration:   2160, Loss function: 3.714, Average Loss: 4.390, avg. samples / sec: 54894.88
Iteration:   2160, Loss function: 3.849, Average Loss: 4.409, avg. samples / sec: 54907.03
Iteration:   2160, Loss function: 3.939, Average Loss: 4.395, avg. samples / sec: 54881.84
Iteration:   2160, Loss function: 3.674, Average Loss: 4.433, avg. samples / sec: 54885.13
Iteration:   2160, Loss function: 3.538, Average Loss: 4.412, avg. samples / sec: 54861.65
Iteration:   2160, Loss function: 4.266, Average Loss: 4.401, avg. samples / sec: 54869.36
Iteration:   2160, Loss function: 4.146, Average Loss: 4.417, avg. samples / sec: 54875.26
Iteration:   2160, Loss function: 4.386, Average Loss: 4.412, avg. samples / sec: 54881.31
Iteration:   2160, Loss function: 4.603, Average Loss: 4.380, avg. samples / sec: 54914.69
Iteration:   2160, Loss function: 4.278, Average Loss: 4.403, avg. samples / sec: 54888.55
Iteration:   2160, Loss function: 4.821, Average Loss: 4.393, avg. samples / sec: 54882.23
Iteration:   2160, Loss function: 4.386, Average Loss: 4.409, avg. samples / sec: 54908.02
Iteration:   2160, Loss function: 4.703, Average Loss: 4.382, avg. samples / sec: 54914.95
Iteration:   2160, Loss function: 5.342, Average Loss: 4.435, avg. samples / sec: 54906.00
Iteration:   2160, Loss function: 2.843, Average Loss: 4.386, avg. samples / sec: 54883.38
Iteration:   2160, Loss function: 3.948, Average Loss: 4.384, avg. samples / sec: 54928.56
Iteration:   2160, Loss function: 3.631, Average Loss: 4.411, avg. samples / sec: 54892.77
Iteration:   2160, Loss function: 2.480, Average Loss: 4.374, avg. samples / sec: 54911.07
Iteration:   2160, Loss function: 3.453, Average Loss: 4.419, avg. samples / sec: 54939.59
Iteration:   2160, Loss function: 4.237, Average Loss: 4.396, avg. samples / sec: 54936.31
Iteration:   2160, Loss function: 4.376, Average Loss: 4.416, avg. samples / sec: 54900.76
Iteration:   2160, Loss function: 3.207, Average Loss: 4.395, avg. samples / sec: 54958.85
Iteration:   2160, Loss function: 4.179, Average Loss: 4.401, avg. samples / sec: 54914.95
Iteration:   2160, Loss function: 2.958, Average Loss: 4.384, avg. samples / sec: 54904.08
Iteration:   2160, Loss function: 3.616, Average Loss: 4.397, avg. samples / sec: 54895.63
Iteration:   2160, Loss function: 3.384, Average Loss: 4.413, avg. samples / sec: 54694.41
Iteration:   2160, Loss function: 3.621, Average Loss: 4.429, avg. samples / sec: 54889.52
Iteration:   2160, Loss function: 4.425, Average Loss: 4.422, avg. samples / sec: 54901.11
:::MLL 1558640346.971 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558640346.972 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 3.720, Average Loss: 4.420, avg. samples / sec: 53813.91
Iteration:   2180, Loss function: 4.505, Average Loss: 4.386, avg. samples / sec: 53902.60
Iteration:   2180, Loss function: 3.538, Average Loss: 4.407, avg. samples / sec: 53891.78
Iteration:   2180, Loss function: 3.842, Average Loss: 4.388, avg. samples / sec: 53948.78
Iteration:   2180, Loss function: 3.741, Average Loss: 4.396, avg. samples / sec: 53935.48
Iteration:   2180, Loss function: 4.653, Average Loss: 4.415, avg. samples / sec: 53969.11
Iteration:   2180, Loss function: 4.831, Average Loss: 4.396, avg. samples / sec: 53847.46
Iteration:   2180, Loss function: 4.311, Average Loss: 4.426, avg. samples / sec: 53907.82
Iteration:   2180, Loss function: 5.062, Average Loss: 4.410, avg. samples / sec: 53942.96
Iteration:   2180, Loss function: 3.298, Average Loss: 4.405, avg. samples / sec: 53876.94
Iteration:   2180, Loss function: 3.637, Average Loss: 4.395, avg. samples / sec: 53976.69
Iteration:   2180, Loss function: 4.184, Average Loss: 4.379, avg. samples / sec: 53919.06
Iteration:   2180, Loss function: 4.539, Average Loss: 4.402, avg. samples / sec: 53920.34
Iteration:   2180, Loss function: 4.433, Average Loss: 4.389, avg. samples / sec: 53891.90
Iteration:   2180, Loss function: 5.005, Average Loss: 4.367, avg. samples / sec: 53918.83
Iteration:   2180, Loss function: 3.349, Average Loss: 4.374, avg. samples / sec: 53878.28
Iteration:   2180, Loss function: 2.773, Average Loss: 4.379, avg. samples / sec: 53894.60
Iteration:   2180, Loss function: 4.631, Average Loss: 4.394, avg. samples / sec: 53924.59
Iteration:   2180, Loss function: 4.608, Average Loss: 4.377, avg. samples / sec: 53883.93
Iteration:   2180, Loss function: 4.266, Average Loss: 4.408, avg. samples / sec: 53877.33
Iteration:   2180, Loss function: 4.404, Average Loss: 4.433, avg. samples / sec: 53876.47
Iteration:   2180, Loss function: 4.976, Average Loss: 4.390, avg. samples / sec: 53898.66
Iteration:   2180, Loss function: 5.423, Average Loss: 4.410, avg. samples / sec: 53929.99
Iteration:   2180, Loss function: 3.724, Average Loss: 4.394, avg. samples / sec: 53898.31
Iteration:   2180, Loss function: 4.496, Average Loss: 4.389, avg. samples / sec: 53886.32
Iteration:   2180, Loss function: 4.540, Average Loss: 4.414, avg. samples / sec: 53879.74
Iteration:   2180, Loss function: 4.192, Average Loss: 4.423, avg. samples / sec: 53904.93
Iteration:   2180, Loss function: 3.841, Average Loss: 4.375, avg. samples / sec: 53868.62
Iteration:   2180, Loss function: 2.653, Average Loss: 4.415, avg. samples / sec: 53843.12
Iteration:   2180, Loss function: 4.655, Average Loss: 4.418, avg. samples / sec: 53831.17
Iteration:   2200, Loss function: 4.640, Average Loss: 4.378, avg. samples / sec: 54497.49
Iteration:   2200, Loss function: 5.533, Average Loss: 4.413, avg. samples / sec: 54558.62
Iteration:   2200, Loss function: 3.965, Average Loss: 4.410, avg. samples / sec: 54497.75
Iteration:   2200, Loss function: 3.878, Average Loss: 4.379, avg. samples / sec: 54473.16
Iteration:   2200, Loss function: 5.397, Average Loss: 4.394, avg. samples / sec: 54493.51
Iteration:   2200, Loss function: 4.885, Average Loss: 4.420, avg. samples / sec: 54488.31
Iteration:   2200, Loss function: 4.500, Average Loss: 4.387, avg. samples / sec: 54453.44
Iteration:   2200, Loss function: 3.505, Average Loss: 4.397, avg. samples / sec: 54503.12
Iteration:   2200, Loss function: 4.557, Average Loss: 4.405, avg. samples / sec: 54439.22
Iteration:   2200, Loss function: 5.275, Average Loss: 4.410, avg. samples / sec: 54544.68
Iteration:   2200, Loss function: 3.946, Average Loss: 4.369, avg. samples / sec: 54512.44
Iteration:   2200, Loss function: 4.680, Average Loss: 4.371, avg. samples / sec: 54486.08
Iteration:   2200, Loss function: 3.950, Average Loss: 4.376, avg. samples / sec: 54453.19
Iteration:   2200, Loss function: 3.771, Average Loss: 4.401, avg. samples / sec: 54479.76
Iteration:   2200, Loss function: 3.623, Average Loss: 4.387, avg. samples / sec: 54476.91
Iteration:   2200, Loss function: 2.788, Average Loss: 4.387, avg. samples / sec: 54500.99
Iteration:   2200, Loss function: 4.392, Average Loss: 4.391, avg. samples / sec: 54353.77
Iteration:   2200, Loss function: 4.421, Average Loss: 4.381, avg. samples / sec: 54439.90
Iteration:   2200, Loss function: 4.282, Average Loss: 4.387, avg. samples / sec: 54489.11
Iteration:   2200, Loss function: 3.998, Average Loss: 4.413, avg. samples / sec: 54489.95
Iteration:   2200, Loss function: 4.102, Average Loss: 4.369, avg. samples / sec: 54444.65
Iteration:   2200, Loss function: 4.717, Average Loss: 4.417, avg. samples / sec: 54165.77
Iteration:   2200, Loss function: 3.813, Average Loss: 4.411, avg. samples / sec: 54564.07
Iteration:   2200, Loss function: 4.288, Average Loss: 4.370, avg. samples / sec: 54442.97
Iteration:   2200, Loss function: 3.650, Average Loss: 4.419, avg. samples / sec: 54478.72
Iteration:   2200, Loss function: 4.719, Average Loss: 4.430, avg. samples / sec: 54451.82
Iteration:   2200, Loss function: 3.761, Average Loss: 4.393, avg. samples / sec: 54442.29
Iteration:   2200, Loss function: 3.639, Average Loss: 4.368, avg. samples / sec: 54488.41
Iteration:   2200, Loss function: 3.317, Average Loss: 4.400, avg. samples / sec: 54404.36
Iteration:   2200, Loss function: 3.620, Average Loss: 4.412, avg. samples / sec: 54468.60
Iteration:   2220, Loss function: 5.111, Average Loss: 4.410, avg. samples / sec: 55267.06
Iteration:   2220, Loss function: 4.195, Average Loss: 4.381, avg. samples / sec: 54864.13
Iteration:   2220, Loss function: 5.428, Average Loss: 4.414, avg. samples / sec: 54837.59
Iteration:   2220, Loss function: 5.072, Average Loss: 4.408, avg. samples / sec: 54835.31
Iteration:   2220, Loss function: 5.381, Average Loss: 4.385, avg. samples / sec: 54897.81
Iteration:   2220, Loss function: 4.727, Average Loss: 4.393, avg. samples / sec: 54848.31
Iteration:   2220, Loss function: 3.818, Average Loss: 4.414, avg. samples / sec: 54842.67
Iteration:   2220, Loss function: 3.961, Average Loss: 4.376, avg. samples / sec: 54803.73
Iteration:   2220, Loss function: 4.158, Average Loss: 4.396, avg. samples / sec: 54841.84
Iteration:   2220, Loss function: 3.988, Average Loss: 4.400, avg. samples / sec: 54828.68
Iteration:   2220, Loss function: 3.605, Average Loss: 4.377, avg. samples / sec: 54894.28
Iteration:   2220, Loss function: 4.383, Average Loss: 4.379, avg. samples / sec: 54915.65
Iteration:   2220, Loss function: 3.826, Average Loss: 4.371, avg. samples / sec: 54924.54
Iteration:   2220, Loss function: 4.340, Average Loss: 4.397, avg. samples / sec: 54887.25
Iteration:   2220, Loss function: 3.974, Average Loss: 4.398, avg. samples / sec: 54935.75
Iteration:   2220, Loss function: 4.256, Average Loss: 4.411, avg. samples / sec: 54910.22
Iteration:   2220, Loss function: 4.406, Average Loss: 4.372, avg. samples / sec: 54849.99
Iteration:   2220, Loss function: 3.929, Average Loss: 4.385, avg. samples / sec: 54878.79
Iteration:   2220, Loss function: 3.952, Average Loss: 4.362, avg. samples / sec: 54838.30
Iteration:   2220, Loss function: 2.540, Average Loss: 4.371, avg. samples / sec: 54886.48
Iteration:   2220, Loss function: 3.871, Average Loss: 4.414, avg. samples / sec: 54934.08
Iteration:   2220, Loss function: 3.812, Average Loss: 4.421, avg. samples / sec: 54889.73
Iteration:   2220, Loss function: 5.082, Average Loss: 4.408, avg. samples / sec: 54862.17
Iteration:   2220, Loss function: 5.268, Average Loss: 4.392, avg. samples / sec: 54863.94
Iteration:   2220, Loss function: 5.411, Average Loss: 4.391, avg. samples / sec: 54894.52
Iteration:   2220, Loss function: 4.614, Average Loss: 4.361, avg. samples / sec: 54890.56
Iteration:   2220, Loss function: 3.994, Average Loss: 4.386, avg. samples / sec: 54847.13
Iteration:   2220, Loss function: 4.717, Average Loss: 4.407, avg. samples / sec: 54864.86
Iteration:   2220, Loss function: 4.948, Average Loss: 4.412, avg. samples / sec: 54774.97
Iteration:   2220, Loss function: 5.773, Average Loss: 4.385, avg. samples / sec: 54844.55
:::MLL 1558640349.126 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558640349.126 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 4.445, Average Loss: 4.412, avg. samples / sec: 54634.82
Iteration:   2240, Loss function: 4.908, Average Loss: 4.401, avg. samples / sec: 54529.95
Iteration:   2240, Loss function: 4.458, Average Loss: 4.408, avg. samples / sec: 54505.23
Iteration:   2240, Loss function: 4.001, Average Loss: 4.405, avg. samples / sec: 54355.70
Iteration:   2240, Loss function: 4.738, Average Loss: 4.372, avg. samples / sec: 54427.43
Iteration:   2240, Loss function: 4.233, Average Loss: 4.382, avg. samples / sec: 54382.17
Iteration:   2240, Loss function: 4.546, Average Loss: 4.380, avg. samples / sec: 54313.61
Iteration:   2240, Loss function: 4.645, Average Loss: 4.368, avg. samples / sec: 54551.10
Iteration:   2240, Loss function: 3.256, Average Loss: 4.394, avg. samples / sec: 54414.21
Iteration:   2240, Loss function: 2.737, Average Loss: 4.387, avg. samples / sec: 54390.00
Iteration:   2240, Loss function: 4.426, Average Loss: 4.379, avg. samples / sec: 54316.42
Iteration:   2240, Loss function: 3.349, Average Loss: 4.352, avg. samples / sec: 54503.27
Iteration:   2240, Loss function: 3.468, Average Loss: 4.378, avg. samples / sec: 54494.67
Iteration:   2240, Loss function: 3.499, Average Loss: 4.376, avg. samples / sec: 54435.04
Iteration:   2240, Loss function: 4.483, Average Loss: 4.391, avg. samples / sec: 54417.87
Iteration:   2240, Loss function: 4.562, Average Loss: 4.368, avg. samples / sec: 54407.09
Iteration:   2240, Loss function: 4.529, Average Loss: 4.358, avg. samples / sec: 54419.57
Iteration:   2240, Loss function: 3.396, Average Loss: 4.409, avg. samples / sec: 54390.25
Iteration:   2240, Loss function: 3.665, Average Loss: 4.390, avg. samples / sec: 54361.55
Iteration:   2240, Loss function: 5.073, Average Loss: 4.408, avg. samples / sec: 54363.20
Iteration:   2240, Loss function: 4.056, Average Loss: 4.374, avg. samples / sec: 54330.93
Iteration:   2240, Loss function: 3.587, Average Loss: 4.379, avg. samples / sec: 54351.38
Iteration:   2240, Loss function: 4.008, Average Loss: 4.415, avg. samples / sec: 54366.79
Iteration:   2240, Loss function: 4.067, Average Loss: 4.361, avg. samples / sec: 54328.77
Iteration:   2240, Loss function: 3.728, Average Loss: 4.381, avg. samples / sec: 54386.05
Iteration:   2240, Loss function: 4.122, Average Loss: 4.392, avg. samples / sec: 54362.47
Iteration:   2240, Loss function: 3.611, Average Loss: 4.405, avg. samples / sec: 54370.00
Iteration:   2240, Loss function: 2.307, Average Loss: 4.399, avg. samples / sec: 54348.28
Iteration:   2240, Loss function: 3.398, Average Loss: 4.397, avg. samples / sec: 54348.68
Iteration:   2240, Loss function: 4.305, Average Loss: 4.392, avg. samples / sec: 54313.23
Iteration:   2260, Loss function: 2.865, Average Loss: 4.402, avg. samples / sec: 54516.19
Iteration:   2260, Loss function: 4.318, Average Loss: 4.403, avg. samples / sec: 54418.71
Iteration:   2260, Loss function: 5.407, Average Loss: 4.376, avg. samples / sec: 54575.35
Iteration:   2260, Loss function: 4.908, Average Loss: 4.404, avg. samples / sec: 54334.09
Iteration:   2260, Loss function: 3.776, Average Loss: 4.383, avg. samples / sec: 54553.99
Iteration:   2260, Loss function: 4.083, Average Loss: 4.396, avg. samples / sec: 54384.94
Iteration:   2260, Loss function: 4.851, Average Loss: 4.404, avg. samples / sec: 54791.80
Iteration:   2260, Loss function: 4.316, Average Loss: 4.389, avg. samples / sec: 54552.98
Iteration:   2260, Loss function: 3.441, Average Loss: 4.366, avg. samples / sec: 54539.15
Iteration:   2260, Loss function: 5.140, Average Loss: 4.366, avg. samples / sec: 54500.51
Iteration:   2260, Loss function: 4.061, Average Loss: 4.385, avg. samples / sec: 54530.73
Iteration:   2260, Loss function: 4.462, Average Loss: 4.375, avg. samples / sec: 54542.74
Iteration:   2260, Loss function: 4.659, Average Loss: 4.390, avg. samples / sec: 54741.38
Iteration:   2260, Loss function: 5.021, Average Loss: 4.392, avg. samples / sec: 54505.55
Iteration:   2260, Loss function: 3.080, Average Loss: 4.365, avg. samples / sec: 54538.28
Iteration:   2260, Loss function: 5.057, Average Loss: 4.348, avg. samples / sec: 54418.50
Iteration:   2260, Loss function: 4.391, Average Loss: 4.368, avg. samples / sec: 54566.92
Iteration:   2260, Loss function: 4.424, Average Loss: 4.370, avg. samples / sec: 54453.27
Iteration:   2260, Loss function: 4.249, Average Loss: 4.382, avg. samples / sec: 54527.61
Iteration:   2260, Loss function: 4.260, Average Loss: 4.355, avg. samples / sec: 54505.08
Iteration:   2260, Loss function: 4.307, Average Loss: 4.373, avg. samples / sec: 54535.37
Iteration:   2260, Loss function: 3.866, Average Loss: 4.403, avg. samples / sec: 54521.89
Iteration:   2260, Loss function: 4.681, Average Loss: 4.407, avg. samples / sec: 54503.04
Iteration:   2260, Loss function: 3.693, Average Loss: 4.383, avg. samples / sec: 54534.21
Iteration:   2260, Loss function: 4.580, Average Loss: 4.390, avg. samples / sec: 54572.96
Iteration:   2260, Loss function: 3.132, Average Loss: 4.411, avg. samples / sec: 54508.62
Iteration:   2260, Loss function: 5.017, Average Loss: 4.377, avg. samples / sec: 54387.79
Iteration:   2260, Loss function: 4.856, Average Loss: 4.360, avg. samples / sec: 54504.60
Iteration:   2260, Loss function: 2.788, Average Loss: 4.400, avg. samples / sec: 54528.26
Iteration:   2260, Loss function: 5.130, Average Loss: 4.373, avg. samples / sec: 54475.23
Iteration:   2280, Loss function: 4.431, Average Loss: 4.388, avg. samples / sec: 55052.05
Iteration:   2280, Loss function: 3.747, Average Loss: 4.393, avg. samples / sec: 54575.92
Iteration:   2280, Loss function: 3.978, Average Loss: 4.371, avg. samples / sec: 54553.25
Iteration:   2280, Loss function: 3.183, Average Loss: 4.390, avg. samples / sec: 54553.86
Iteration:   2280, Loss function: 4.258, Average Loss: 4.371, avg. samples / sec: 54542.27
Iteration:   2280, Loss function: 4.414, Average Loss: 4.402, avg. samples / sec: 54533.72
Iteration:   2280, Loss function: 4.214, Average Loss: 4.368, avg. samples / sec: 54603.47
Iteration:   2280, Loss function: 3.357, Average Loss: 4.400, avg. samples / sec: 54510.40
Iteration:   2280, Loss function: 4.274, Average Loss: 4.361, avg. samples / sec: 54560.09
Iteration:   2280, Loss function: 3.719, Average Loss: 4.387, avg. samples / sec: 54568.97
Iteration:   2280, Loss function: 5.558, Average Loss: 4.381, avg. samples / sec: 54539.85
Iteration:   2280, Loss function: 3.637, Average Loss: 4.393, avg. samples / sec: 54380.22
Iteration:   2280, Loss function: 4.192, Average Loss: 4.358, avg. samples / sec: 54640.44
Iteration:   2280, Loss function: 3.497, Average Loss: 4.366, avg. samples / sec: 54574.27
Iteration:   2280, Loss function: 4.246, Average Loss: 4.360, avg. samples / sec: 54391.55
Iteration:   2280, Loss function: 4.494, Average Loss: 4.404, avg. samples / sec: 54627.58
Iteration:   2280, Loss function: 4.247, Average Loss: 4.397, avg. samples / sec: 54599.18
Iteration:   2280, Loss function: 4.007, Average Loss: 4.359, avg. samples / sec: 54541.83
Iteration:   2280, Loss function: 4.361, Average Loss: 4.342, avg. samples / sec: 54534.93
Iteration:   2280, Loss function: 5.202, Average Loss: 4.403, avg. samples / sec: 54577.23
Iteration:   2280, Loss function: 4.259, Average Loss: 4.381, avg. samples / sec: 54585.37
Iteration:   2280, Loss function: 4.237, Average Loss: 4.368, avg. samples / sec: 54561.72
Iteration:   2280, Loss function: 3.328, Average Loss: 4.352, avg. samples / sec: 54555.28
Iteration:   2280, Loss function: 4.247, Average Loss: 4.373, avg. samples / sec: 54590.55
Iteration:   2280, Loss function: 3.191, Average Loss: 4.379, avg. samples / sec: 54540.67
Iteration:   2280, Loss function: 5.393, Average Loss: 4.388, avg. samples / sec: 54385.29
Iteration:   2280, Loss function: 3.678, Average Loss: 4.382, avg. samples / sec: 54479.69
Iteration:   2280, Loss function: 5.019, Average Loss: 4.372, avg. samples / sec: 54599.45
Iteration:   2280, Loss function: 3.638, Average Loss: 4.397, avg. samples / sec: 54562.00
Iteration:   2280, Loss function: 3.507, Average Loss: 4.363, avg. samples / sec: 54000.85
:::MLL 1558640350.575 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.06 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.56s)
DONE (t=2.68s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.15433
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.28923
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.15081
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03357
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.16771
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.24826
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.16856
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.25882
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.27100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.40457
Current AP: 0.15433 AP goal: 0.23000
:::MLL 1558640354.836 eval_accuracy: {"value": 0.15432822312657993, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558640354.928 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558640354.934 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558640354.935 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 3.800, Average Loss: 4.385, avg. samples / sec: 6686.51
Iteration:   2300, Loss function: 3.833, Average Loss: 4.354, avg. samples / sec: 6685.60
Iteration:   2300, Loss function: 4.251, Average Loss: 4.362, avg. samples / sec: 6684.75
Iteration:   2300, Loss function: 4.120, Average Loss: 4.401, avg. samples / sec: 6681.02
Iteration:   2300, Loss function: 3.194, Average Loss: 4.356, avg. samples / sec: 6683.87
Iteration:   2300, Loss function: 3.695, Average Loss: 4.357, avg. samples / sec: 6683.93
Iteration:   2300, Loss function: 4.139, Average Loss: 4.379, avg. samples / sec: 6684.60
Iteration:   2300, Loss function: 3.874, Average Loss: 4.385, avg. samples / sec: 6680.63
Iteration:   2300, Loss function: 4.946, Average Loss: 4.366, avg. samples / sec: 6680.58
Iteration:   2300, Loss function: 5.287, Average Loss: 4.386, avg. samples / sec: 6677.35
Iteration:   2300, Loss function: 4.121, Average Loss: 4.400, avg. samples / sec: 6680.74
Iteration:   2300, Loss function: 4.074, Average Loss: 4.359, avg. samples / sec: 6680.79
Iteration:   2300, Loss function: 4.066, Average Loss: 4.362, avg. samples / sec: 6680.25
Iteration:   2300, Loss function: 4.463, Average Loss: 4.370, avg. samples / sec: 6679.85
Iteration:   2300, Loss function: 3.998, Average Loss: 4.377, avg. samples / sec: 6680.63
Iteration:   2300, Loss function: 4.728, Average Loss: 4.360, avg. samples / sec: 6681.62
Iteration:   2300, Loss function: 3.733, Average Loss: 4.376, avg. samples / sec: 6681.31
Iteration:   2300, Loss function: 3.100, Average Loss: 4.351, avg. samples / sec: 6689.05
Iteration:   2300, Loss function: 3.060, Average Loss: 4.364, avg. samples / sec: 6681.02
Iteration:   2300, Loss function: 4.080, Average Loss: 4.393, avg. samples / sec: 6679.90
Iteration:   2300, Loss function: 3.979, Average Loss: 4.380, avg. samples / sec: 6677.34
Iteration:   2300, Loss function: 3.487, Average Loss: 4.340, avg. samples / sec: 6680.25
Iteration:   2300, Loss function: 4.069, Average Loss: 4.398, avg. samples / sec: 6680.19
Iteration:   2300, Loss function: 3.892, Average Loss: 4.388, avg. samples / sec: 6679.80
Iteration:   2300, Loss function: 4.059, Average Loss: 4.386, avg. samples / sec: 6674.70
Iteration:   2300, Loss function: 3.689, Average Loss: 4.392, avg. samples / sec: 6680.78
Iteration:   2300, Loss function: 4.679, Average Loss: 4.348, avg. samples / sec: 6679.65
Iteration:   2300, Loss function: 3.101, Average Loss: 4.380, avg. samples / sec: 6679.70
Iteration:   2300, Loss function: 5.021, Average Loss: 4.369, avg. samples / sec: 6679.53
Iteration:   2300, Loss function: 3.595, Average Loss: 4.371, avg. samples / sec: 6679.71
:::MLL 1558640355.702 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558640355.703 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 4.665, Average Loss: 4.353, avg. samples / sec: 53732.33
Iteration:   2320, Loss function: 5.308, Average Loss: 4.356, avg. samples / sec: 53735.05
Iteration:   2320, Loss function: 4.078, Average Loss: 4.396, avg. samples / sec: 53722.58
Iteration:   2320, Loss function: 5.017, Average Loss: 4.360, avg. samples / sec: 53722.70
Iteration:   2320, Loss function: 3.877, Average Loss: 4.368, avg. samples / sec: 53769.09
Iteration:   2320, Loss function: 4.187, Average Loss: 4.382, avg. samples / sec: 53722.07
Iteration:   2320, Loss function: 4.283, Average Loss: 4.355, avg. samples / sec: 53756.53
Iteration:   2320, Loss function: 3.801, Average Loss: 4.381, avg. samples / sec: 54031.97
Iteration:   2320, Loss function: 4.619, Average Loss: 4.375, avg. samples / sec: 53714.27
Iteration:   2320, Loss function: 4.315, Average Loss: 4.369, avg. samples / sec: 53711.24
Iteration:   2320, Loss function: 4.524, Average Loss: 4.355, avg. samples / sec: 53730.73
Iteration:   2320, Loss function: 4.289, Average Loss: 4.394, avg. samples / sec: 53722.33
Iteration:   2320, Loss function: 3.774, Average Loss: 4.381, avg. samples / sec: 53704.17
Iteration:   2320, Loss function: 4.978, Average Loss: 4.360, avg. samples / sec: 53656.53
Iteration:   2320, Loss function: 4.022, Average Loss: 4.374, avg. samples / sec: 53697.38
Iteration:   2320, Loss function: 5.024, Average Loss: 4.338, avg. samples / sec: 53785.07
Iteration:   2320, Loss function: 4.953, Average Loss: 4.356, avg. samples / sec: 53648.10
Iteration:   2320, Loss function: 3.449, Average Loss: 4.362, avg. samples / sec: 53736.02
Iteration:   2320, Loss function: 2.660, Average Loss: 4.382, avg. samples / sec: 53322.57
Iteration:   2320, Loss function: 4.445, Average Loss: 4.344, avg. samples / sec: 53709.56
Iteration:   2320, Loss function: 3.988, Average Loss: 4.398, avg. samples / sec: 53750.92
Iteration:   2320, Loss function: 4.289, Average Loss: 4.365, avg. samples / sec: 53667.42
Iteration:   2320, Loss function: 4.006, Average Loss: 4.381, avg. samples / sec: 53727.70
Iteration:   2320, Loss function: 4.330, Average Loss: 4.391, avg. samples / sec: 53719.04
Iteration:   2320, Loss function: 4.526, Average Loss: 4.366, avg. samples / sec: 53777.87
Iteration:   2320, Loss function: 5.861, Average Loss: 4.379, avg. samples / sec: 53717.28
Iteration:   2320, Loss function: 3.400, Average Loss: 4.342, avg. samples / sec: 53759.08
Iteration:   2320, Loss function: 4.431, Average Loss: 4.385, avg. samples / sec: 53722.50
Iteration:   2320, Loss function: 3.655, Average Loss: 4.365, avg. samples / sec: 53756.74
Iteration:   2320, Loss function: 4.342, Average Loss: 4.380, avg. samples / sec: 53677.34
Iteration:   2340, Loss function: 3.760, Average Loss: 4.353, avg. samples / sec: 54308.44
Iteration:   2340, Loss function: 3.345, Average Loss: 4.347, avg. samples / sec: 54248.97
Iteration:   2340, Loss function: 4.549, Average Loss: 4.360, avg. samples / sec: 54262.65
Iteration:   2340, Loss function: 4.327, Average Loss: 4.376, avg. samples / sec: 54238.28
Iteration:   2340, Loss function: 3.696, Average Loss: 4.387, avg. samples / sec: 54249.76
Iteration:   2340, Loss function: 3.622, Average Loss: 4.359, avg. samples / sec: 54216.62
Iteration:   2340, Loss function: 3.377, Average Loss: 4.378, avg. samples / sec: 54239.67
Iteration:   2340, Loss function: 4.369, Average Loss: 4.347, avg. samples / sec: 54179.20
Iteration:   2340, Loss function: 3.753, Average Loss: 4.373, avg. samples / sec: 54203.73
Iteration:   2340, Loss function: 4.183, Average Loss: 4.365, avg. samples / sec: 54200.23
Iteration:   2340, Loss function: 3.807, Average Loss: 4.370, avg. samples / sec: 54250.49
Iteration:   2340, Loss function: 5.159, Average Loss: 4.346, avg. samples / sec: 54039.68
Iteration:   2340, Loss function: 3.494, Average Loss: 4.393, avg. samples / sec: 54123.38
Iteration:   2340, Loss function: 3.832, Average Loss: 4.350, avg. samples / sec: 54194.16
Iteration:   2340, Loss function: 4.741, Average Loss: 4.332, avg. samples / sec: 54175.12
Iteration:   2340, Loss function: 4.952, Average Loss: 4.345, avg. samples / sec: 54205.09
Iteration:   2340, Loss function: 5.107, Average Loss: 4.399, avg. samples / sec: 54196.43
Iteration:   2340, Loss function: 4.132, Average Loss: 4.382, avg. samples / sec: 54221.54
Iteration:   2340, Loss function: 3.911, Average Loss: 4.375, avg. samples / sec: 54182.39
Iteration:   2340, Loss function: 5.842, Average Loss: 4.364, avg. samples / sec: 54195.39
Iteration:   2340, Loss function: 4.396, Average Loss: 4.379, avg. samples / sec: 54217.97
Iteration:   2340, Loss function: 3.763, Average Loss: 4.382, avg. samples / sec: 54202.46
Iteration:   2340, Loss function: 4.017, Average Loss: 4.363, avg. samples / sec: 54201.69
Iteration:   2340, Loss function: 6.031, Average Loss: 4.350, avg. samples / sec: 54139.64
Iteration:   2340, Loss function: 4.326, Average Loss: 4.358, avg. samples / sec: 54228.34
Iteration:   2340, Loss function: 4.767, Average Loss: 4.374, avg. samples / sec: 54185.22
Iteration:   2340, Loss function: 3.790, Average Loss: 4.373, avg. samples / sec: 54234.02
Iteration:   2340, Loss function: 2.967, Average Loss: 4.341, avg. samples / sec: 54163.79
Iteration:   2340, Loss function: 5.490, Average Loss: 4.357, avg. samples / sec: 53855.30
Iteration:   2340, Loss function: 3.655, Average Loss: 4.356, avg. samples / sec: 53880.42
Iteration:   2360, Loss function: 3.045, Average Loss: 4.344, avg. samples / sec: 54380.87
Iteration:   2360, Loss function: 3.883, Average Loss: 4.372, avg. samples / sec: 54380.24
Iteration:   2360, Loss function: 4.294, Average Loss: 4.355, avg. samples / sec: 54761.95
Iteration:   2360, Loss function: 4.230, Average Loss: 4.341, avg. samples / sec: 54388.15
Iteration:   2360, Loss function: 4.064, Average Loss: 4.388, avg. samples / sec: 54450.29
Iteration:   2360, Loss function: 3.802, Average Loss: 4.340, avg. samples / sec: 54409.38
Iteration:   2360, Loss function: 4.530, Average Loss: 4.372, avg. samples / sec: 54373.10
Iteration:   2360, Loss function: 3.043, Average Loss: 4.357, avg. samples / sec: 54318.91
Iteration:   2360, Loss function: 3.481, Average Loss: 4.383, avg. samples / sec: 54346.64
Iteration:   2360, Loss function: 3.563, Average Loss: 4.349, avg. samples / sec: 54709.84
Iteration:   2360, Loss function: 4.250, Average Loss: 4.351, avg. samples / sec: 54341.93
Iteration:   2360, Loss function: 4.045, Average Loss: 4.360, avg. samples / sec: 54361.32
Iteration:   2360, Loss function: 4.833, Average Loss: 4.349, avg. samples / sec: 54255.31
Iteration:   2360, Loss function: 2.972, Average Loss: 4.365, avg. samples / sec: 54341.57
Iteration:   2360, Loss function: 3.457, Average Loss: 4.368, avg. samples / sec: 54436.11
Iteration:   2360, Loss function: 4.033, Average Loss: 4.347, avg. samples / sec: 54396.06
Iteration:   2360, Loss function: 4.245, Average Loss: 4.391, avg. samples / sec: 54411.14
Iteration:   2360, Loss function: 3.440, Average Loss: 4.339, avg. samples / sec: 54397.34
Iteration:   2360, Loss function: 5.149, Average Loss: 4.381, avg. samples / sec: 54420.87
Iteration:   2360, Loss function: 3.853, Average Loss: 4.348, avg. samples / sec: 54434.43
Iteration:   2360, Loss function: 3.927, Average Loss: 4.358, avg. samples / sec: 54414.00
Iteration:   2360, Loss function: 3.878, Average Loss: 4.326, avg. samples / sec: 54388.84
Iteration:   2360, Loss function: 5.389, Average Loss: 4.367, avg. samples / sec: 54438.70
Iteration:   2360, Loss function: 5.185, Average Loss: 4.374, avg. samples / sec: 54388.09
Iteration:   2360, Loss function: 3.933, Average Loss: 4.359, avg. samples / sec: 54402.05
Iteration:   2360, Loss function: 5.410, Average Loss: 4.348, avg. samples / sec: 54448.56
Iteration:   2360, Loss function: 3.727, Average Loss: 4.369, avg. samples / sec: 54412.24
Iteration:   2360, Loss function: 5.191, Average Loss: 4.351, avg. samples / sec: 54399.40
Iteration:   2360, Loss function: 3.285, Average Loss: 4.374, avg. samples / sec: 54368.24
Iteration:   2360, Loss function: 3.913, Average Loss: 4.370, avg. samples / sec: 54100.94
:::MLL 1558640357.873 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558640357.873 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 4.151, Average Loss: 4.364, avg. samples / sec: 54089.00
Iteration:   2380, Loss function: 4.483, Average Loss: 4.381, avg. samples / sec: 54109.85
Iteration:   2380, Loss function: 3.184, Average Loss: 4.354, avg. samples / sec: 54076.38
Iteration:   2380, Loss function: 3.638, Average Loss: 4.377, avg. samples / sec: 54098.84
Iteration:   2380, Loss function: 4.348, Average Loss: 4.343, avg. samples / sec: 54066.88
Iteration:   2380, Loss function: 4.960, Average Loss: 4.353, avg. samples / sec: 54070.96
Iteration:   2380, Loss function: 3.523, Average Loss: 4.348, avg. samples / sec: 54019.92
Iteration:   2380, Loss function: 4.448, Average Loss: 4.339, avg. samples / sec: 53949.34
Iteration:   2380, Loss function: 3.963, Average Loss: 4.340, avg. samples / sec: 53975.25
Iteration:   2380, Loss function: 5.585, Average Loss: 4.341, avg. samples / sec: 54012.59
Iteration:   2380, Loss function: 4.542, Average Loss: 4.357, avg. samples / sec: 54052.63
Iteration:   2380, Loss function: 4.352, Average Loss: 4.337, avg. samples / sec: 53980.68
Iteration:   2380, Loss function: 3.744, Average Loss: 4.347, avg. samples / sec: 54020.87
Iteration:   2380, Loss function: 4.297, Average Loss: 4.369, avg. samples / sec: 53940.85
Iteration:   2380, Loss function: 2.648, Average Loss: 4.386, avg. samples / sec: 54101.15
Iteration:   2380, Loss function: 3.474, Average Loss: 4.327, avg. samples / sec: 54098.80
Iteration:   2380, Loss function: 4.157, Average Loss: 4.334, avg. samples / sec: 54079.87
Iteration:   2380, Loss function: 3.921, Average Loss: 4.358, avg. samples / sec: 54089.89
Iteration:   2380, Loss function: 4.046, Average Loss: 4.364, avg. samples / sec: 54108.96
Iteration:   2380, Loss function: 4.347, Average Loss: 4.356, avg. samples / sec: 54054.19
Iteration:   2380, Loss function: 5.675, Average Loss: 4.346, avg. samples / sec: 53995.93
Iteration:   2380, Loss function: 4.475, Average Loss: 4.360, avg. samples / sec: 53959.83
Iteration:   2380, Loss function: 4.717, Average Loss: 4.345, avg. samples / sec: 53968.14
Iteration:   2380, Loss function: 4.533, Average Loss: 4.354, avg. samples / sec: 53987.57
Iteration:   2380, Loss function: 5.202, Average Loss: 4.375, avg. samples / sec: 53974.83
Iteration:   2380, Loss function: 5.378, Average Loss: 4.368, avg. samples / sec: 53988.48
Iteration:   2380, Loss function: 3.146, Average Loss: 4.364, avg. samples / sec: 53965.64
Iteration:   2380, Loss function: 3.049, Average Loss: 4.343, avg. samples / sec: 53976.76
Iteration:   2380, Loss function: 3.854, Average Loss: 4.346, avg. samples / sec: 53984.53
Iteration:   2380, Loss function: 3.689, Average Loss: 4.374, avg. samples / sec: 53974.92
Iteration:   2400, Loss function: 3.917, Average Loss: 4.334, avg. samples / sec: 54293.57
Iteration:   2400, Loss function: 4.625, Average Loss: 4.360, avg. samples / sec: 54151.31
Iteration:   2400, Loss function: 4.014, Average Loss: 4.345, avg. samples / sec: 54229.57
Iteration:   2400, Loss function: 3.234, Average Loss: 4.331, avg. samples / sec: 54271.95
Iteration:   2400, Loss function: 5.546, Average Loss: 4.349, avg. samples / sec: 54254.67
Iteration:   2400, Loss function: 3.892, Average Loss: 4.346, avg. samples / sec: 54162.80
Iteration:   2400, Loss function: 5.151, Average Loss: 4.377, avg. samples / sec: 54171.75
Iteration:   2400, Loss function: 4.271, Average Loss: 4.364, avg. samples / sec: 54309.53
Iteration:   2400, Loss function: 4.444, Average Loss: 4.373, avg. samples / sec: 54104.93
Iteration:   2400, Loss function: 4.546, Average Loss: 4.348, avg. samples / sec: 54183.33
Iteration:   2400, Loss function: 4.562, Average Loss: 4.358, avg. samples / sec: 54221.67
Iteration:   2400, Loss function: 5.050, Average Loss: 4.338, avg. samples / sec: 54213.97
Iteration:   2400, Loss function: 3.863, Average Loss: 4.342, avg. samples / sec: 54192.14
Iteration:   2400, Loss function: 4.169, Average Loss: 4.359, avg. samples / sec: 54391.63
Iteration:   2400, Loss function: 4.506, Average Loss: 4.335, avg. samples / sec: 54286.41
Iteration:   2400, Loss function: 4.789, Average Loss: 4.348, avg. samples / sec: 54277.80
Iteration:   2400, Loss function: 3.236, Average Loss: 4.346, avg. samples / sec: 54267.83
Iteration:   2400, Loss function: 3.172, Average Loss: 4.378, avg. samples / sec: 54128.12
Iteration:   2400, Loss function: 3.491, Average Loss: 4.375, avg. samples / sec: 54254.27
Iteration:   2400, Loss function: 2.860, Average Loss: 4.336, avg. samples / sec: 54139.45
Iteration:   2400, Loss function: 4.417, Average Loss: 4.328, avg. samples / sec: 54126.79
Iteration:   2400, Loss function: 3.745, Average Loss: 4.364, avg. samples / sec: 54251.56
Iteration:   2400, Loss function: 3.122, Average Loss: 4.338, avg. samples / sec: 54263.23
Iteration:   2400, Loss function: 3.615, Average Loss: 4.356, avg. samples / sec: 54159.17
Iteration:   2400, Loss function: 3.606, Average Loss: 4.370, avg. samples / sec: 54267.49
Iteration:   2400, Loss function: 3.327, Average Loss: 4.344, avg. samples / sec: 54237.07
Iteration:   2400, Loss function: 4.076, Average Loss: 4.352, avg. samples / sec: 54166.27
Iteration:   2400, Loss function: 4.108, Average Loss: 4.349, avg. samples / sec: 54095.79
Iteration:   2400, Loss function: 4.573, Average Loss: 4.342, avg. samples / sec: 53930.32
Iteration:   2400, Loss function: 3.304, Average Loss: 4.355, avg. samples / sec: 54112.16
Iteration:   2420, Loss function: 3.777, Average Loss: 4.346, avg. samples / sec: 53865.37
Iteration:   2420, Loss function: 3.274, Average Loss: 4.339, avg. samples / sec: 53883.66
Iteration:   2420, Loss function: 4.152, Average Loss: 4.326, avg. samples / sec: 53839.75
Iteration:   2420, Loss function: 5.373, Average Loss: 4.330, avg. samples / sec: 53906.41
Iteration:   2420, Loss function: 4.956, Average Loss: 4.357, avg. samples / sec: 53860.92
Iteration:   2420, Loss function: 2.717, Average Loss: 4.355, avg. samples / sec: 53826.20
Iteration:   2420, Loss function: 3.584, Average Loss: 4.351, avg. samples / sec: 54115.48
Iteration:   2420, Loss function: 4.060, Average Loss: 4.330, avg. samples / sec: 53827.27
Iteration:   2420, Loss function: 5.045, Average Loss: 4.346, avg. samples / sec: 53827.53
Iteration:   2420, Loss function: 4.254, Average Loss: 4.356, avg. samples / sec: 53879.79
Iteration:   2420, Loss function: 4.456, Average Loss: 4.340, avg. samples / sec: 54161.61
Iteration:   2420, Loss function: 3.960, Average Loss: 4.341, avg. samples / sec: 53901.55
Iteration:   2420, Loss function: 3.985, Average Loss: 4.348, avg. samples / sec: 53836.42
Iteration:   2420, Loss function: 3.847, Average Loss: 4.364, avg. samples / sec: 53826.65
Iteration:   2420, Loss function: 3.958, Average Loss: 4.366, avg. samples / sec: 53766.50
Iteration:   2420, Loss function: 4.346, Average Loss: 4.335, avg. samples / sec: 53843.51
Iteration:   2420, Loss function: 4.257, Average Loss: 4.348, avg. samples / sec: 53923.76
Iteration:   2420, Loss function: 4.493, Average Loss: 4.326, avg. samples / sec: 53875.07
Iteration:   2420, Loss function: 4.977, Average Loss: 4.347, avg. samples / sec: 53820.92
Iteration:   2420, Loss function: 4.510, Average Loss: 4.340, avg. samples / sec: 53837.38
Iteration:   2420, Loss function: 3.617, Average Loss: 4.356, avg. samples / sec: 53861.23
Iteration:   2420, Loss function: 4.484, Average Loss: 4.334, avg. samples / sec: 53860.70
Iteration:   2420, Loss function: 3.394, Average Loss: 4.351, avg. samples / sec: 53987.98
Iteration:   2420, Loss function: 3.363, Average Loss: 4.335, avg. samples / sec: 53886.54
Iteration:   2420, Loss function: 3.971, Average Loss: 4.375, avg. samples / sec: 53825.91
Iteration:   2420, Loss function: 5.197, Average Loss: 4.353, avg. samples / sec: 53719.90
Iteration:   2420, Loss function: 4.990, Average Loss: 4.345, avg. samples / sec: 53889.35
Iteration:   2420, Loss function: 4.665, Average Loss: 4.362, avg. samples / sec: 53848.78
Iteration:   2420, Loss function: 3.462, Average Loss: 4.335, avg. samples / sec: 53828.79
Iteration:   2420, Loss function: 4.977, Average Loss: 4.376, avg. samples / sec: 53797.27
Iteration:   2440, Loss function: 5.025, Average Loss: 4.358, avg. samples / sec: 54197.10
Iteration:   2440, Loss function: 5.142, Average Loss: 4.351, avg. samples / sec: 54129.99
Iteration:   2440, Loss function: 4.464, Average Loss: 4.336, avg. samples / sec: 54140.47
Iteration:   2440, Loss function: 3.899, Average Loss: 4.324, avg. samples / sec: 54130.92
Iteration:   2440, Loss function: 4.227, Average Loss: 4.332, avg. samples / sec: 54074.20
Iteration:   2440, Loss function: 3.782, Average Loss: 4.339, avg. samples / sec: 54122.52
Iteration:   2440, Loss function: 3.939, Average Loss: 4.324, avg. samples / sec: 54086.07
Iteration:   2440, Loss function: 4.003, Average Loss: 4.338, avg. samples / sec: 54065.59
Iteration:   2440, Loss function: 2.714, Average Loss: 4.321, avg. samples / sec: 54090.33
Iteration:   2440, Loss function: 4.654, Average Loss: 4.351, avg. samples / sec: 54084.51
Iteration:   2440, Loss function: 4.201, Average Loss: 4.350, avg. samples / sec: 54100.92
Iteration:   2440, Loss function: 4.787, Average Loss: 4.359, avg. samples / sec: 54167.56
Iteration:   2440, Loss function: 4.177, Average Loss: 4.337, avg. samples / sec: 54119.45
Iteration:   2440, Loss function: 4.289, Average Loss: 4.343, avg. samples / sec: 54110.22
Iteration:   2440, Loss function: 3.425, Average Loss: 4.332, avg. samples / sec: 54077.02
Iteration:   2440, Loss function: 3.911, Average Loss: 4.343, avg. samples / sec: 54195.62
Iteration:   2440, Loss function: 4.296, Average Loss: 4.326, avg. samples / sec: 54140.01
Iteration:   2440, Loss function: 3.846, Average Loss: 4.340, avg. samples / sec: 54144.63
Iteration:   2440, Loss function: 5.758, Average Loss: 4.332, avg. samples / sec: 54150.85
Iteration:   2440, Loss function: 3.955, Average Loss: 4.319, avg. samples / sec: 54122.07
Iteration:   2440, Loss function: 4.264, Average Loss: 4.365, avg. samples / sec: 54139.78
Iteration:   2440, Loss function: 3.737, Average Loss: 4.345, avg. samples / sec: 54114.90
Iteration:   2440, Loss function: 2.229, Average Loss: 4.347, avg. samples / sec: 54110.08
Iteration:   2440, Loss function: 4.131, Average Loss: 4.369, avg. samples / sec: 54163.86
Iteration:   2440, Loss function: 4.910, Average Loss: 4.341, avg. samples / sec: 54124.79
Iteration:   2440, Loss function: 3.752, Average Loss: 4.355, avg. samples / sec: 54130.42
Iteration:   2440, Loss function: 4.154, Average Loss: 4.334, avg. samples / sec: 54095.10
Iteration:   2440, Loss function: 4.223, Average Loss: 4.331, avg. samples / sec: 54131.88
Iteration:   2440, Loss function: 3.859, Average Loss: 4.346, avg. samples / sec: 54036.53
Iteration:   2440, Loss function: 3.906, Average Loss: 4.336, avg. samples / sec: 54005.53
:::MLL 1558640360.052 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558640360.053 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.871, Average Loss: 4.321, avg. samples / sec: 53770.34
Iteration:   2460, Loss function: 3.112, Average Loss: 4.331, avg. samples / sec: 53741.10
Iteration:   2460, Loss function: 6.345, Average Loss: 4.333, avg. samples / sec: 53730.28
Iteration:   2460, Loss function: 3.010, Average Loss: 4.331, avg. samples / sec: 53751.20
Iteration:   2460, Loss function: 4.106, Average Loss: 4.350, avg. samples / sec: 53698.96
Iteration:   2460, Loss function: 3.966, Average Loss: 4.346, avg. samples / sec: 53715.41
Iteration:   2460, Loss function: 4.151, Average Loss: 4.354, avg. samples / sec: 53741.20
Iteration:   2460, Loss function: 4.496, Average Loss: 4.325, avg. samples / sec: 53773.44
Iteration:   2460, Loss function: 4.387, Average Loss: 4.318, avg. samples / sec: 53712.53
Iteration:   2460, Loss function: 3.074, Average Loss: 4.357, avg. samples / sec: 53736.34
Iteration:   2460, Loss function: 4.501, Average Loss: 4.316, avg. samples / sec: 53722.23
Iteration:   2460, Loss function: 5.645, Average Loss: 4.329, avg. samples / sec: 53974.46
Iteration:   2460, Loss function: 5.353, Average Loss: 4.337, avg. samples / sec: 53688.24
Iteration:   2460, Loss function: 4.267, Average Loss: 4.335, avg. samples / sec: 53723.30
Iteration:   2460, Loss function: 4.368, Average Loss: 4.333, avg. samples / sec: 53690.55
Iteration:   2460, Loss function: 4.913, Average Loss: 4.343, avg. samples / sec: 53684.08
Iteration:   2460, Loss function: 3.651, Average Loss: 4.338, avg. samples / sec: 53722.52
Iteration:   2460, Loss function: 5.255, Average Loss: 4.329, avg. samples / sec: 53701.72
Iteration:   2460, Loss function: 4.450, Average Loss: 4.321, avg. samples / sec: 53677.58
Iteration:   2460, Loss function: 4.425, Average Loss: 4.335, avg. samples / sec: 53725.06
Iteration:   2460, Loss function: 3.865, Average Loss: 4.347, avg. samples / sec: 53729.42
Iteration:   2460, Loss function: 4.164, Average Loss: 4.311, avg. samples / sec: 53694.86
Iteration:   2460, Loss function: 3.265, Average Loss: 4.339, avg. samples / sec: 53616.73
Iteration:   2460, Loss function: 3.904, Average Loss: 4.360, avg. samples / sec: 53682.69
Iteration:   2460, Loss function: 3.570, Average Loss: 4.360, avg. samples / sec: 53703.60
Iteration:   2460, Loss function: 4.622, Average Loss: 4.350, avg. samples / sec: 53710.42
Iteration:   2460, Loss function: 3.423, Average Loss: 4.335, avg. samples / sec: 53688.63
Iteration:   2460, Loss function: 4.726, Average Loss: 4.322, avg. samples / sec: 53704.60
Iteration:   2460, Loss function: 5.099, Average Loss: 4.331, avg. samples / sec: 53754.30
Iteration:   2460, Loss function: 4.075, Average Loss: 4.340, avg. samples / sec: 53734.79
Iteration:   2480, Loss function: 4.668, Average Loss: 4.351, avg. samples / sec: 54288.53
Iteration:   2480, Loss function: 3.934, Average Loss: 4.331, avg. samples / sec: 54240.13
Iteration:   2480, Loss function: 4.129, Average Loss: 4.328, avg. samples / sec: 54169.92
Iteration:   2480, Loss function: 3.731, Average Loss: 4.315, avg. samples / sec: 54191.85
Iteration:   2480, Loss function: 4.436, Average Loss: 4.331, avg. samples / sec: 54222.52
Iteration:   2480, Loss function: 4.312, Average Loss: 4.308, avg. samples / sec: 54188.39
Iteration:   2480, Loss function: 2.899, Average Loss: 4.318, avg. samples / sec: 54171.94
Iteration:   2480, Loss function: 3.711, Average Loss: 4.338, avg. samples / sec: 54228.49
Iteration:   2480, Loss function: 3.635, Average Loss: 4.324, avg. samples / sec: 54178.75
Iteration:   2480, Loss function: 3.306, Average Loss: 4.327, avg. samples / sec: 54137.83
Iteration:   2480, Loss function: 4.262, Average Loss: 4.312, avg. samples / sec: 54092.28
Iteration:   2480, Loss function: 4.809, Average Loss: 4.354, avg. samples / sec: 54148.12
Iteration:   2480, Loss function: 5.387, Average Loss: 4.329, avg. samples / sec: 54180.70
Iteration:   2480, Loss function: 4.144, Average Loss: 4.347, avg. samples / sec: 54101.06
Iteration:   2480, Loss function: 3.778, Average Loss: 4.315, avg. samples / sec: 54215.45
Iteration:   2480, Loss function: 4.463, Average Loss: 4.334, avg. samples / sec: 54168.35
Iteration:   2480, Loss function: 4.709, Average Loss: 4.307, avg. samples / sec: 54201.71
Iteration:   2480, Loss function: 4.369, Average Loss: 4.330, avg. samples / sec: 54250.72
Iteration:   2480, Loss function: 4.537, Average Loss: 4.338, avg. samples / sec: 53923.90
Iteration:   2480, Loss function: 3.545, Average Loss: 4.327, avg. samples / sec: 54155.97
Iteration:   2480, Loss function: 5.078, Average Loss: 4.333, avg. samples / sec: 54166.67
Iteration:   2480, Loss function: 4.313, Average Loss: 4.332, avg. samples / sec: 54172.06
Iteration:   2480, Loss function: 4.112, Average Loss: 4.332, avg. samples / sec: 54165.36
Iteration:   2480, Loss function: 3.770, Average Loss: 4.351, avg. samples / sec: 54196.64
Iteration:   2480, Loss function: 4.024, Average Loss: 4.339, avg. samples / sec: 54245.56
Iteration:   2480, Loss function: 3.630, Average Loss: 4.312, avg. samples / sec: 54209.80
Iteration:   2480, Loss function: 3.933, Average Loss: 4.354, avg. samples / sec: 54176.85
Iteration:   2480, Loss function: 4.810, Average Loss: 4.331, avg. samples / sec: 53873.28
Iteration:   2480, Loss function: 3.791, Average Loss: 4.335, avg. samples / sec: 54178.04
Iteration:   2480, Loss function: 3.595, Average Loss: 4.343, avg. samples / sec: 54160.48
Iteration:   2500, Loss function: 3.821, Average Loss: 4.323, avg. samples / sec: 54445.34
Iteration:   2500, Loss function: 2.633, Average Loss: 4.319, avg. samples / sec: 54068.10
Iteration:   2500, Loss function: 3.819, Average Loss: 4.309, avg. samples / sec: 54034.70
Iteration:   2500, Loss function: 4.014, Average Loss: 4.325, avg. samples / sec: 54021.47
Iteration:   2500, Loss function: 4.467, Average Loss: 4.349, avg. samples / sec: 54081.84
Iteration:   2500, Loss function: 4.323, Average Loss: 4.323, avg. samples / sec: 54048.92
Iteration:   2500, Loss function: 2.793, Average Loss: 4.320, avg. samples / sec: 54011.97
Iteration:   2500, Loss function: 4.211, Average Loss: 4.342, avg. samples / sec: 54078.12
Iteration:   2500, Loss function: 3.727, Average Loss: 4.317, avg. samples / sec: 54017.47
Iteration:   2500, Loss function: 4.612, Average Loss: 4.334, avg. samples / sec: 54255.50
Iteration:   2500, Loss function: 4.394, Average Loss: 4.349, avg. samples / sec: 53897.67
Iteration:   2500, Loss function: 4.443, Average Loss: 4.328, avg. samples / sec: 53971.59
Iteration:   2500, Loss function: 4.944, Average Loss: 4.300, avg. samples / sec: 53983.21
Iteration:   2500, Loss function: 2.398, Average Loss: 4.336, avg. samples / sec: 53989.14
Iteration:   2500, Loss function: 5.196, Average Loss: 4.328, avg. samples / sec: 54011.22
Iteration:   2500, Loss function: 5.520, Average Loss: 4.309, avg. samples / sec: 53993.47
Iteration:   2500, Loss function: 3.068, Average Loss: 4.333, avg. samples / sec: 54029.92
Iteration:   2500, Loss function: 2.892, Average Loss: 4.307, avg. samples / sec: 54010.97
Iteration:   2500, Loss function: 3.798, Average Loss: 4.348, avg. samples / sec: 54079.58
Iteration:   2500, Loss function: 3.537, Average Loss: 4.327, avg. samples / sec: 54038.14
Iteration:   2500, Loss function: 3.684, Average Loss: 4.302, avg. samples / sec: 54014.93
Iteration:   2500, Loss function: 3.770, Average Loss: 4.327, avg. samples / sec: 54035.89
Iteration:   2500, Loss function: 3.350, Average Loss: 4.323, avg. samples / sec: 54021.88
Iteration:   2500, Loss function: 3.882, Average Loss: 4.329, avg. samples / sec: 54068.25
Iteration:   2500, Loss function: 3.900, Average Loss: 4.345, avg. samples / sec: 54015.71
Iteration:   2500, Loss function: 2.973, Average Loss: 4.332, avg. samples / sec: 54058.42
Iteration:   2500, Loss function: 3.249, Average Loss: 4.323, avg. samples / sec: 54003.52
Iteration:   2500, Loss function: 2.857, Average Loss: 4.306, avg. samples / sec: 54011.24
Iteration:   2500, Loss function: 4.071, Average Loss: 4.327, avg. samples / sec: 53997.38
Iteration:   2500, Loss function: 3.744, Average Loss: 4.338, avg. samples / sec: 53965.12
:::MLL 1558640362.230 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558640362.231 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 3.709, Average Loss: 4.331, avg. samples / sec: 53873.26
Iteration:   2520, Loss function: 3.470, Average Loss: 4.333, avg. samples / sec: 53855.84
Iteration:   2520, Loss function: 4.323, Average Loss: 4.319, avg. samples / sec: 53717.01
Iteration:   2520, Loss function: 3.236, Average Loss: 4.312, avg. samples / sec: 53812.74
Iteration:   2520, Loss function: 4.250, Average Loss: 4.344, avg. samples / sec: 53816.33
Iteration:   2520, Loss function: 4.679, Average Loss: 4.315, avg. samples / sec: 53764.57
Iteration:   2520, Loss function: 4.089, Average Loss: 4.313, avg. samples / sec: 53742.76
Iteration:   2520, Loss function: 3.809, Average Loss: 4.315, avg. samples / sec: 53730.92
Iteration:   2520, Loss function: 4.426, Average Loss: 4.294, avg. samples / sec: 53763.20
Iteration:   2520, Loss function: 3.892, Average Loss: 4.307, avg. samples / sec: 53726.51
Iteration:   2520, Loss function: 4.102, Average Loss: 4.324, avg. samples / sec: 53954.62
Iteration:   2520, Loss function: 3.103, Average Loss: 4.301, avg. samples / sec: 53695.13
Iteration:   2520, Loss function: 4.527, Average Loss: 4.330, avg. samples / sec: 53916.66
Iteration:   2520, Loss function: 5.105, Average Loss: 4.342, avg. samples / sec: 53708.57
Iteration:   2520, Loss function: 4.482, Average Loss: 4.321, avg. samples / sec: 53739.99
Iteration:   2520, Loss function: 3.656, Average Loss: 4.348, avg. samples / sec: 53883.18
Iteration:   2520, Loss function: 3.510, Average Loss: 4.323, avg. samples / sec: 53698.53
Iteration:   2520, Loss function: 3.165, Average Loss: 4.327, avg. samples / sec: 53698.38
Iteration:   2520, Loss function: 4.099, Average Loss: 4.308, avg. samples / sec: 53698.79
Iteration:   2520, Loss function: 4.189, Average Loss: 4.319, avg. samples / sec: 53851.62
Iteration:   2520, Loss function: 3.616, Average Loss: 4.300, avg. samples / sec: 53832.57
Iteration:   2520, Loss function: 3.253, Average Loss: 4.322, avg. samples / sec: 53830.87
Iteration:   2520, Loss function: 4.123, Average Loss: 4.316, avg. samples / sec: 53829.96
Iteration:   2520, Loss function: 4.848, Average Loss: 4.338, avg. samples / sec: 53792.63
Iteration:   2520, Loss function: 3.775, Average Loss: 4.300, avg. samples / sec: 53721.39
Iteration:   2520, Loss function: 3.085, Average Loss: 4.327, avg. samples / sec: 53762.56
Iteration:   2520, Loss function: 5.133, Average Loss: 4.332, avg. samples / sec: 53804.00
Iteration:   2520, Loss function: 2.687, Average Loss: 4.319, avg. samples / sec: 53684.92
Iteration:   2520, Loss function: 2.793, Average Loss: 4.300, avg. samples / sec: 53736.12
Iteration:   2520, Loss function: 4.903, Average Loss: 4.322, avg. samples / sec: 53740.01
Iteration:   2540, Loss function: 2.996, Average Loss: 4.300, avg. samples / sec: 54242.60
Iteration:   2540, Loss function: 5.446, Average Loss: 4.330, avg. samples / sec: 54107.96
Iteration:   2540, Loss function: 3.628, Average Loss: 4.307, avg. samples / sec: 54092.80
Iteration:   2540, Loss function: 4.554, Average Loss: 4.330, avg. samples / sec: 54072.23
Iteration:   2540, Loss function: 4.377, Average Loss: 4.315, avg. samples / sec: 54147.19
Iteration:   2540, Loss function: 3.633, Average Loss: 4.311, avg. samples / sec: 54185.29
Iteration:   2540, Loss function: 3.330, Average Loss: 4.334, avg. samples / sec: 54071.07
Iteration:   2540, Loss function: 4.913, Average Loss: 4.334, avg. samples / sec: 54207.50
Iteration:   2540, Loss function: 4.627, Average Loss: 4.292, avg. samples / sec: 54174.50
Iteration:   2540, Loss function: 4.772, Average Loss: 4.327, avg. samples / sec: 54235.00
Iteration:   2540, Loss function: 3.591, Average Loss: 4.308, avg. samples / sec: 54123.31
Iteration:   2540, Loss function: 4.400, Average Loss: 4.319, avg. samples / sec: 54197.35
Iteration:   2540, Loss function: 3.626, Average Loss: 4.320, avg. samples / sec: 54197.56
Iteration:   2540, Loss function: 3.214, Average Loss: 4.312, avg. samples / sec: 54010.23
Iteration:   2540, Loss function: 3.366, Average Loss: 4.305, avg. samples / sec: 54200.39
Iteration:   2540, Loss function: 3.826, Average Loss: 4.325, avg. samples / sec: 54299.17
Iteration:   2540, Loss function: 4.879, Average Loss: 4.324, avg. samples / sec: 54009.69
Iteration:   2540, Loss function: 3.792, Average Loss: 4.316, avg. samples / sec: 54105.76
Iteration:   2540, Loss function: 3.551, Average Loss: 4.289, avg. samples / sec: 54194.20
Iteration:   2540, Loss function: 4.643, Average Loss: 4.316, avg. samples / sec: 54242.72
Iteration:   2540, Loss function: 3.689, Average Loss: 4.296, avg. samples / sec: 54096.33
Iteration:   2540, Loss function: 3.446, Average Loss: 4.340, avg. samples / sec: 54018.76
Iteration:   2540, Loss function: 2.741, Average Loss: 4.312, avg. samples / sec: 54226.03
Iteration:   2540, Loss function: 4.167, Average Loss: 4.321, avg. samples / sec: 53963.18
Iteration:   2540, Loss function: 3.557, Average Loss: 4.311, avg. samples / sec: 54114.67
Iteration:   2540, Loss function: 4.736, Average Loss: 4.327, avg. samples / sec: 54162.94
Iteration:   2540, Loss function: 4.314, Average Loss: 4.335, avg. samples / sec: 54124.73
Iteration:   2540, Loss function: 4.088, Average Loss: 4.305, avg. samples / sec: 53931.29
Iteration:   2540, Loss function: 3.507, Average Loss: 4.324, avg. samples / sec: 54067.25
Iteration:   2540, Loss function: 3.134, Average Loss: 4.296, avg. samples / sec: 54178.85
Iteration:   2560, Loss function: 4.060, Average Loss: 4.326, avg. samples / sec: 54396.40
Iteration:   2560, Loss function: 4.567, Average Loss: 4.299, avg. samples / sec: 54356.85
Iteration:   2560, Loss function: 4.862, Average Loss: 4.317, avg. samples / sec: 54427.26
Iteration:   2560, Loss function: 3.776, Average Loss: 4.303, avg. samples / sec: 54394.11
Iteration:   2560, Loss function: 3.671, Average Loss: 4.318, avg. samples / sec: 54394.78
Iteration:   2560, Loss function: 4.979, Average Loss: 4.312, avg. samples / sec: 54331.85
Iteration:   2560, Loss function: 4.284, Average Loss: 4.303, avg. samples / sec: 54615.32
Iteration:   2560, Loss function: 3.585, Average Loss: 4.307, avg. samples / sec: 54399.53
Iteration:   2560, Loss function: 3.788, Average Loss: 4.328, avg. samples / sec: 54358.99
Iteration:   2560, Loss function: 4.272, Average Loss: 4.304, avg. samples / sec: 54312.67
Iteration:   2560, Loss function: 3.066, Average Loss: 4.321, avg. samples / sec: 54284.78
Iteration:   2560, Loss function: 3.305, Average Loss: 4.329, avg. samples / sec: 54332.00
Iteration:   2560, Loss function: 3.181, Average Loss: 4.324, avg. samples / sec: 54345.62
Iteration:   2560, Loss function: 5.236, Average Loss: 4.300, avg. samples / sec: 54399.99
Iteration:   2560, Loss function: 5.038, Average Loss: 4.309, avg. samples / sec: 54306.04
Iteration:   2560, Loss function: 5.776, Average Loss: 4.289, avg. samples / sec: 54302.35
Iteration:   2560, Loss function: 5.204, Average Loss: 4.319, avg. samples / sec: 54357.88
Iteration:   2560, Loss function: 5.930, Average Loss: 4.287, avg. samples / sec: 54364.94
Iteration:   2560, Loss function: 3.398, Average Loss: 4.289, avg. samples / sec: 54358.61
Iteration:   2560, Loss function: 3.522, Average Loss: 4.312, avg. samples / sec: 54347.02
Iteration:   2560, Loss function: 5.100, Average Loss: 4.315, avg. samples / sec: 54372.03
Iteration:   2560, Loss function: 4.128, Average Loss: 4.320, avg. samples / sec: 54345.76
Iteration:   2560, Loss function: 3.436, Average Loss: 4.320, avg. samples / sec: 54401.82
Iteration:   2560, Loss function: 3.248, Average Loss: 4.323, avg. samples / sec: 54383.64
Iteration:   2560, Loss function: 3.894, Average Loss: 4.325, avg. samples / sec: 54380.74
Iteration:   2560, Loss function: 3.919, Average Loss: 4.331, avg. samples / sec: 54341.07
Iteration:   2560, Loss function: 3.414, Average Loss: 4.305, avg. samples / sec: 54345.93
Iteration:   2560, Loss function: 4.334, Average Loss: 4.325, avg. samples / sec: 54217.26
Iteration:   2560, Loss function: 4.052, Average Loss: 4.307, avg. samples / sec: 54318.59
Iteration:   2560, Loss function: 3.649, Average Loss: 4.294, avg. samples / sec: 54347.10
Iteration:   2580, Loss function: 3.879, Average Loss: 4.302, avg. samples / sec: 54254.15
Iteration:   2580, Loss function: 3.882, Average Loss: 4.299, avg. samples / sec: 54229.51
Iteration:   2580, Loss function: 4.276, Average Loss: 4.329, avg. samples / sec: 54246.88
Iteration:   2580, Loss function: 3.520, Average Loss: 4.321, avg. samples / sec: 54135.75
Iteration:   2580, Loss function: 4.206, Average Loss: 4.303, avg. samples / sec: 54197.00
Iteration:   2580, Loss function: 3.943, Average Loss: 4.303, avg. samples / sec: 54195.77
Iteration:   2580, Loss function: 2.525, Average Loss: 4.323, avg. samples / sec: 54214.32
Iteration:   2580, Loss function: 3.869, Average Loss: 4.324, avg. samples / sec: 54181.47
Iteration:   2580, Loss function: 3.493, Average Loss: 4.320, avg. samples / sec: 54142.76
Iteration:   2580, Loss function: 3.473, Average Loss: 4.306, avg. samples / sec: 54173.48
Iteration:   2580, Loss function: 3.933, Average Loss: 4.315, avg. samples / sec: 54187.43
Iteration:   2580, Loss function: 4.028, Average Loss: 4.294, avg. samples / sec: 54114.52
Iteration:   2580, Loss function: 3.329, Average Loss: 4.281, avg. samples / sec: 54225.94
Iteration:   2580, Loss function: 2.855, Average Loss: 4.311, avg. samples / sec: 54197.14
Iteration:   2580, Loss function: 4.277, Average Loss: 4.301, avg. samples / sec: 54170.00
Iteration:   2580, Loss function: 3.774, Average Loss: 4.315, avg. samples / sec: 54127.80
Iteration:   2580, Loss function: 5.225, Average Loss: 4.286, avg. samples / sec: 54204.86
Iteration:   2580, Loss function: 3.762, Average Loss: 4.308, avg. samples / sec: 54177.56
Iteration:   2580, Loss function: 2.337, Average Loss: 4.313, avg. samples / sec: 54195.87
Iteration:   2580, Loss function: 3.333, Average Loss: 4.286, avg. samples / sec: 54156.66
Iteration:   2580, Loss function: 3.536, Average Loss: 4.313, avg. samples / sec: 54138.35
Iteration:   2580, Loss function: 4.546, Average Loss: 4.317, avg. samples / sec: 54160.17
Iteration:   2580, Loss function: 4.127, Average Loss: 4.327, avg. samples / sec: 54174.23
Iteration:   2580, Loss function: 4.007, Average Loss: 4.302, avg. samples / sec: 54204.88
Iteration:   2580, Loss function: 4.583, Average Loss: 4.320, avg. samples / sec: 54166.98
Iteration:   2580, Loss function: 4.137, Average Loss: 4.310, avg. samples / sec: 54151.89
Iteration:   2580, Loss function: 4.743, Average Loss: 4.310, avg. samples / sec: 54138.14
Iteration:   2580, Loss function: 3.843, Average Loss: 4.323, avg. samples / sec: 54150.20
Iteration:   2580, Loss function: 4.562, Average Loss: 4.303, avg. samples / sec: 54165.48
Iteration:   2580, Loss function: 4.175, Average Loss: 4.286, avg. samples / sec: 54168.17
:::MLL 1558640364.404 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558640364.404 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 3.970, Average Loss: 4.291, avg. samples / sec: 53654.06
Iteration:   2600, Loss function: 2.370, Average Loss: 4.305, avg. samples / sec: 53706.18
Iteration:   2600, Loss function: 3.566, Average Loss: 4.298, avg. samples / sec: 53624.27
Iteration:   2600, Loss function: 3.946, Average Loss: 4.315, avg. samples / sec: 53661.50
Iteration:   2600, Loss function: 5.347, Average Loss: 4.304, avg. samples / sec: 53689.01
Iteration:   2600, Loss function: 4.098, Average Loss: 4.319, avg. samples / sec: 53691.51
Iteration:   2600, Loss function: 2.629, Average Loss: 4.294, avg. samples / sec: 53665.05
Iteration:   2600, Loss function: 4.597, Average Loss: 4.293, avg. samples / sec: 53689.57
Iteration:   2600, Loss function: 3.727, Average Loss: 4.318, avg. samples / sec: 53657.06
Iteration:   2600, Loss function: 3.524, Average Loss: 4.283, avg. samples / sec: 53667.59
Iteration:   2600, Loss function: 3.733, Average Loss: 4.310, avg. samples / sec: 53694.07
Iteration:   2600, Loss function: 4.560, Average Loss: 4.307, avg. samples / sec: 53677.85
Iteration:   2600, Loss function: 3.409, Average Loss: 4.297, avg. samples / sec: 53679.67
Iteration:   2600, Loss function: 4.957, Average Loss: 4.296, avg. samples / sec: 53627.93
Iteration:   2600, Loss function: 3.064, Average Loss: 4.278, avg. samples / sec: 53789.34
Iteration:   2600, Loss function: 4.475, Average Loss: 4.319, avg. samples / sec: 53615.99
Iteration:   2600, Loss function: 2.774, Average Loss: 4.304, avg. samples / sec: 53862.18
Iteration:   2600, Loss function: 4.673, Average Loss: 4.320, avg. samples / sec: 53553.56
Iteration:   2600, Loss function: 3.685, Average Loss: 4.307, avg. samples / sec: 53703.54
Iteration:   2600, Loss function: 3.530, Average Loss: 4.298, avg. samples / sec: 53736.57
Iteration:   2600, Loss function: 4.846, Average Loss: 4.277, avg. samples / sec: 53688.15
Iteration:   2600, Loss function: 4.532, Average Loss: 4.322, avg. samples / sec: 53687.66
Iteration:   2600, Loss function: 2.990, Average Loss: 4.315, avg. samples / sec: 53682.78
Iteration:   2600, Loss function: 3.623, Average Loss: 4.316, avg. samples / sec: 53700.00
Iteration:   2600, Loss function: 5.336, Average Loss: 4.318, avg. samples / sec: 53671.29
Iteration:   2600, Loss function: 3.004, Average Loss: 4.299, avg. samples / sec: 53663.60
Iteration:   2600, Loss function: 3.982, Average Loss: 4.283, avg. samples / sec: 53713.02
Iteration:   2600, Loss function: 3.894, Average Loss: 4.304, avg. samples / sec: 53650.06
Iteration:   2600, Loss function: 4.952, Average Loss: 4.309, avg. samples / sec: 53647.95
Iteration:   2600, Loss function: 3.733, Average Loss: 4.294, avg. samples / sec: 53694.33
Iteration:   2620, Loss function: 3.218, Average Loss: 4.308, avg. samples / sec: 54668.27
Iteration:   2620, Loss function: 4.726, Average Loss: 4.309, avg. samples / sec: 54771.93
Iteration:   2620, Loss function: 5.201, Average Loss: 4.295, avg. samples / sec: 54476.91
Iteration:   2620, Loss function: 3.617, Average Loss: 4.302, avg. samples / sec: 54489.89
Iteration:   2620, Loss function: 3.593, Average Loss: 4.288, avg. samples / sec: 54420.83
Iteration:   2620, Loss function: 3.608, Average Loss: 4.290, avg. samples / sec: 54453.74
Iteration:   2620, Loss function: 2.641, Average Loss: 4.298, avg. samples / sec: 54431.00
Iteration:   2620, Loss function: 3.962, Average Loss: 4.316, avg. samples / sec: 54430.62
Iteration:   2620, Loss function: 4.856, Average Loss: 4.292, avg. samples / sec: 54467.50
Iteration:   2620, Loss function: 3.099, Average Loss: 4.311, avg. samples / sec: 54414.95
Iteration:   2620, Loss function: 3.453, Average Loss: 4.295, avg. samples / sec: 54362.41
Iteration:   2620, Loss function: 4.221, Average Loss: 4.292, avg. samples / sec: 54421.02
Iteration:   2620, Loss function: 4.652, Average Loss: 4.307, avg. samples / sec: 54412.49
Iteration:   2620, Loss function: 3.807, Average Loss: 4.311, avg. samples / sec: 54440.76
Iteration:   2620, Loss function: 4.527, Average Loss: 4.303, avg. samples / sec: 54429.28
Iteration:   2620, Loss function: 5.042, Average Loss: 4.296, avg. samples / sec: 54412.42
Iteration:   2620, Loss function: 3.807, Average Loss: 4.272, avg. samples / sec: 54258.07
Iteration:   2620, Loss function: 3.317, Average Loss: 4.314, avg. samples / sec: 54449.36
Iteration:   2620, Loss function: 2.401, Average Loss: 4.314, avg. samples / sec: 54408.81
Iteration:   2620, Loss function: 4.078, Average Loss: 4.289, avg. samples / sec: 54427.47
Iteration:   2620, Loss function: 2.563, Average Loss: 4.272, avg. samples / sec: 54400.96
Iteration:   2620, Loss function: 2.715, Average Loss: 4.300, avg. samples / sec: 54365.34
Iteration:   2620, Loss function: 3.478, Average Loss: 4.311, avg. samples / sec: 54420.41
Iteration:   2620, Loss function: 4.186, Average Loss: 4.306, avg. samples / sec: 54438.51
Iteration:   2620, Loss function: 4.289, Average Loss: 4.282, avg. samples / sec: 54180.02
Iteration:   2620, Loss function: 4.226, Average Loss: 4.311, avg. samples / sec: 54139.70
Iteration:   2620, Loss function: 3.382, Average Loss: 4.296, avg. samples / sec: 54407.61
Iteration:   2620, Loss function: 5.432, Average Loss: 4.280, avg. samples / sec: 54398.58
Iteration:   2620, Loss function: 4.176, Average Loss: 4.286, avg. samples / sec: 54121.51
Iteration:   2620, Loss function: 3.957, Average Loss: 4.289, avg. samples / sec: 54368.36
Iteration:   2640, Loss function: 4.074, Average Loss: 4.299, avg. samples / sec: 54657.16
Iteration:   2640, Loss function: 3.651, Average Loss: 4.292, avg. samples / sec: 54442.80
Iteration:   2640, Loss function: 3.286, Average Loss: 4.297, avg. samples / sec: 54378.33
Iteration:   2640, Loss function: 4.241, Average Loss: 4.310, avg. samples / sec: 54585.26
Iteration:   2640, Loss function: 4.782, Average Loss: 4.288, avg. samples / sec: 54300.07
Iteration:   2640, Loss function: 4.662, Average Loss: 4.301, avg. samples / sec: 54374.22
Iteration:   2640, Loss function: 3.858, Average Loss: 4.304, avg. samples / sec: 54352.64
Iteration:   2640, Loss function: 4.340, Average Loss: 4.288, avg. samples / sec: 54266.66
Iteration:   2640, Loss function: 3.534, Average Loss: 4.289, avg. samples / sec: 54236.19
Iteration:   2640, Loss function: 3.520, Average Loss: 4.290, avg. samples / sec: 54289.61
Iteration:   2640, Loss function: 4.360, Average Loss: 4.280, avg. samples / sec: 54594.10
Iteration:   2640, Loss function: 3.891, Average Loss: 4.301, avg. samples / sec: 54171.91
Iteration:   2640, Loss function: 3.855, Average Loss: 4.304, avg. samples / sec: 54240.74
Iteration:   2640, Loss function: 4.124, Average Loss: 4.304, avg. samples / sec: 54548.80
Iteration:   2640, Loss function: 4.896, Average Loss: 4.301, avg. samples / sec: 54104.93
Iteration:   2640, Loss function: 4.001, Average Loss: 4.315, avg. samples / sec: 54237.80
Iteration:   2640, Loss function: 3.471, Average Loss: 4.291, avg. samples / sec: 54282.19
Iteration:   2640, Loss function: 3.911, Average Loss: 4.284, avg. samples / sec: 54235.94
Iteration:   2640, Loss function: 4.966, Average Loss: 4.310, avg. samples / sec: 54234.75
Iteration:   2640, Loss function: 4.159, Average Loss: 4.308, avg. samples / sec: 54386.74
Iteration:   2640, Loss function: 3.893, Average Loss: 4.273, avg. samples / sec: 54315.27
Iteration:   2640, Loss function: 4.099, Average Loss: 4.316, avg. samples / sec: 54299.59
Iteration:   2640, Loss function: 3.197, Average Loss: 4.302, avg. samples / sec: 54313.93
Iteration:   2640, Loss function: 3.443, Average Loss: 4.297, avg. samples / sec: 54304.09
Iteration:   2640, Loss function: 3.566, Average Loss: 4.278, avg. samples / sec: 54309.28
Iteration:   2640, Loss function: 5.037, Average Loss: 4.285, avg. samples / sec: 54281.06
Iteration:   2640, Loss function: 4.068, Average Loss: 4.271, avg. samples / sec: 54285.85
Iteration:   2640, Loss function: 3.668, Average Loss: 4.280, avg. samples / sec: 54314.22
Iteration:   2640, Loss function: 3.428, Average Loss: 4.293, avg. samples / sec: 54288.07
Iteration:   2640, Loss function: 4.611, Average Loss: 4.286, avg. samples / sec: 54320.14
:::MLL 1558640366.575 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558640366.576 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 3.884, Average Loss: 4.315, avg. samples / sec: 54085.53
Iteration:   2660, Loss function: 4.146, Average Loss: 4.282, avg. samples / sec: 54012.81
Iteration:   2660, Loss function: 4.385, Average Loss: 4.298, avg. samples / sec: 54033.56
Iteration:   2660, Loss function: 4.189, Average Loss: 4.277, avg. samples / sec: 54006.50
Iteration:   2660, Loss function: 4.834, Average Loss: 4.293, avg. samples / sec: 53962.19
Iteration:   2660, Loss function: 4.398, Average Loss: 4.286, avg. samples / sec: 53880.07
Iteration:   2660, Loss function: 4.437, Average Loss: 4.290, avg. samples / sec: 53917.28
Iteration:   2660, Loss function: 3.805, Average Loss: 4.292, avg. samples / sec: 53953.72
Iteration:   2660, Loss function: 3.500, Average Loss: 4.300, avg. samples / sec: 53872.02
Iteration:   2660, Loss function: 4.224, Average Loss: 4.284, avg. samples / sec: 53889.82
Iteration:   2660, Loss function: 3.042, Average Loss: 4.290, avg. samples / sec: 53882.28
Iteration:   2660, Loss function: 3.955, Average Loss: 4.289, avg. samples / sec: 53867.61
Iteration:   2660, Loss function: 4.224, Average Loss: 4.279, avg. samples / sec: 53913.75
Iteration:   2660, Loss function: 3.862, Average Loss: 4.284, avg. samples / sec: 53888.03
Iteration:   2660, Loss function: 2.627, Average Loss: 4.297, avg. samples / sec: 53844.48
Iteration:   2660, Loss function: 4.252, Average Loss: 4.309, avg. samples / sec: 53900.74
Iteration:   2660, Loss function: 4.835, Average Loss: 4.307, avg. samples / sec: 53804.70
Iteration:   2660, Loss function: 3.027, Average Loss: 4.293, avg. samples / sec: 53770.81
Iteration:   2660, Loss function: 4.266, Average Loss: 4.265, avg. samples / sec: 54015.59
Iteration:   2660, Loss function: 4.826, Average Loss: 4.294, avg. samples / sec: 53972.64
Iteration:   2660, Loss function: 5.016, Average Loss: 4.269, avg. samples / sec: 53877.05
Iteration:   2660, Loss function: 3.469, Average Loss: 4.284, avg. samples / sec: 53932.43
Iteration:   2660, Loss function: 4.117, Average Loss: 4.310, avg. samples / sec: 53869.71
Iteration:   2660, Loss function: 4.176, Average Loss: 4.304, avg. samples / sec: 53804.64
Iteration:   2660, Loss function: 4.451, Average Loss: 4.277, avg. samples / sec: 53932.70
Iteration:   2660, Loss function: 4.429, Average Loss: 4.273, avg. samples / sec: 53864.30
Iteration:   2660, Loss function: 4.481, Average Loss: 4.291, avg. samples / sec: 53469.10
Iteration:   2660, Loss function: 3.959, Average Loss: 4.284, avg. samples / sec: 53890.40
Iteration:   2660, Loss function: 4.424, Average Loss: 4.295, avg. samples / sec: 53827.37
Iteration:   2660, Loss function: 3.678, Average Loss: 4.279, avg. samples / sec: 53854.95
Iteration:   2680, Loss function: 4.159, Average Loss: 4.295, avg. samples / sec: 54239.15
Iteration:   2680, Loss function: 4.087, Average Loss: 4.282, avg. samples / sec: 54237.00
Iteration:   2680, Loss function: 5.506, Average Loss: 4.287, avg. samples / sec: 54130.92
Iteration:   2680, Loss function: 3.914, Average Loss: 4.289, avg. samples / sec: 54103.76
Iteration:   2680, Loss function: 2.999, Average Loss: 4.309, avg. samples / sec: 54071.07
Iteration:   2680, Loss function: 3.756, Average Loss: 4.276, avg. samples / sec: 54095.83
Iteration:   2680, Loss function: 3.937, Average Loss: 4.284, avg. samples / sec: 54193.02
Iteration:   2680, Loss function: 4.004, Average Loss: 4.286, avg. samples / sec: 54280.12
Iteration:   2680, Loss function: 4.982, Average Loss: 4.285, avg. samples / sec: 54239.59
Iteration:   2680, Loss function: 4.888, Average Loss: 4.280, avg. samples / sec: 54199.79
Iteration:   2680, Loss function: 5.049, Average Loss: 4.300, avg. samples / sec: 54277.40
Iteration:   2680, Loss function: 3.596, Average Loss: 4.285, avg. samples / sec: 54146.29
Iteration:   2680, Loss function: 4.109, Average Loss: 4.279, avg. samples / sec: 54087.69
Iteration:   2680, Loss function: 3.165, Average Loss: 4.284, avg. samples / sec: 54253.96
Iteration:   2680, Loss function: 4.246, Average Loss: 4.282, avg. samples / sec: 54211.17
Iteration:   2680, Loss function: 5.401, Average Loss: 4.304, avg. samples / sec: 54209.80
Iteration:   2680, Loss function: 3.016, Average Loss: 4.265, avg. samples / sec: 54216.07
Iteration:   2680, Loss function: 4.298, Average Loss: 4.300, avg. samples / sec: 54243.60
Iteration:   2680, Loss function: 3.612, Average Loss: 4.289, avg. samples / sec: 54144.61
Iteration:   2680, Loss function: 4.723, Average Loss: 4.289, avg. samples / sec: 54283.61
Iteration:   2680, Loss function: 3.805, Average Loss: 4.285, avg. samples / sec: 54261.33
Iteration:   2680, Loss function: 3.492, Average Loss: 4.263, avg. samples / sec: 54233.93
Iteration:   2680, Loss function: 3.294, Average Loss: 4.274, avg. samples / sec: 54211.76
Iteration:   2680, Loss function: 4.040, Average Loss: 4.272, avg. samples / sec: 53980.42
Iteration:   2680, Loss function: 3.398, Average Loss: 4.295, avg. samples / sec: 54190.39
Iteration:   2680, Loss function: 3.259, Average Loss: 4.275, avg. samples / sec: 54156.82
Iteration:   2680, Loss function: 4.636, Average Loss: 4.276, avg. samples / sec: 54241.47
Iteration:   2680, Loss function: 3.243, Average Loss: 4.284, avg. samples / sec: 54211.51
Iteration:   2680, Loss function: 4.543, Average Loss: 4.261, avg. samples / sec: 54048.26
Iteration:   2680, Loss function: 4.656, Average Loss: 4.275, avg. samples / sec: 53647.34
Iteration:   2700, Loss function: 3.955, Average Loss: 4.292, avg. samples / sec: 53916.09
Iteration:   2700, Loss function: 4.424, Average Loss: 4.287, avg. samples / sec: 53881.41
Iteration:   2700, Loss function: 4.244, Average Loss: 4.281, avg. samples / sec: 53866.67
Iteration:   2700, Loss function: 4.315, Average Loss: 4.282, avg. samples / sec: 53861.69
Iteration:   2700, Loss function: 3.129, Average Loss: 4.265, avg. samples / sec: 54141.78
Iteration:   2700, Loss function: 4.166, Average Loss: 4.276, avg. samples / sec: 53892.19
Iteration:   2700, Loss function: 4.407, Average Loss: 4.273, avg. samples / sec: 53859.87
Iteration:   2700, Loss function: 4.369, Average Loss: 4.266, avg. samples / sec: 54328.50
Iteration:   2700, Loss function: 2.891, Average Loss: 4.276, avg. samples / sec: 53888.11
Iteration:   2700, Loss function: 4.358, Average Loss: 4.279, avg. samples / sec: 53852.26
Iteration:   2700, Loss function: 4.407, Average Loss: 4.285, avg. samples / sec: 53851.99
Iteration:   2700, Loss function: 3.441, Average Loss: 4.295, avg. samples / sec: 53847.03
Iteration:   2700, Loss function: 4.336, Average Loss: 4.279, avg. samples / sec: 53832.39
Iteration:   2700, Loss function: 5.150, Average Loss: 4.283, avg. samples / sec: 53849.97
Iteration:   2700, Loss function: 4.729, Average Loss: 4.282, avg. samples / sec: 53824.86
Iteration:   2700, Loss function: 3.117, Average Loss: 4.303, avg. samples / sec: 53806.28
Iteration:   2700, Loss function: 4.194, Average Loss: 4.275, avg. samples / sec: 53868.66
Iteration:   2700, Loss function: 3.719, Average Loss: 4.272, avg. samples / sec: 54078.12
Iteration:   2700, Loss function: 2.803, Average Loss: 4.300, avg. samples / sec: 53870.85
Iteration:   2700, Loss function: 3.769, Average Loss: 4.297, avg. samples / sec: 53872.02
Iteration:   2700, Loss function: 3.977, Average Loss: 4.288, avg. samples / sec: 53869.22
Iteration:   2700, Loss function: 4.559, Average Loss: 4.258, avg. samples / sec: 53938.64
Iteration:   2700, Loss function: 5.050, Average Loss: 4.259, avg. samples / sec: 53844.34
Iteration:   2700, Loss function: 5.108, Average Loss: 4.277, avg. samples / sec: 53919.96
Iteration:   2700, Loss function: 3.586, Average Loss: 4.291, avg. samples / sec: 53890.62
Iteration:   2700, Loss function: 2.926, Average Loss: 4.276, avg. samples / sec: 53862.28
Iteration:   2700, Loss function: 3.624, Average Loss: 4.263, avg. samples / sec: 53872.82
Iteration:   2700, Loss function: 4.525, Average Loss: 4.268, avg. samples / sec: 53867.14
Iteration:   2700, Loss function: 2.928, Average Loss: 4.278, avg. samples / sec: 53807.68
Iteration:   2700, Loss function: 3.853, Average Loss: 4.270, avg. samples / sec: 53849.09
Iteration:   2720, Loss function: 4.692, Average Loss: 4.281, avg. samples / sec: 54199.08
Iteration:   2720, Loss function: 4.890, Average Loss: 4.291, avg. samples / sec: 53854.71
Iteration:   2720, Loss function: 4.594, Average Loss: 4.282, avg. samples / sec: 53853.00
Iteration:   2720, Loss function: 4.453, Average Loss: 4.280, avg. samples / sec: 53927.62
Iteration:   2720, Loss function: 4.140, Average Loss: 4.276, avg. samples / sec: 53890.05
Iteration:   2720, Loss function: 2.816, Average Loss: 4.275, avg. samples / sec: 53854.93
Iteration:   2720, Loss function: 4.270, Average Loss: 4.262, avg. samples / sec: 53855.94
Iteration:   2720, Loss function: 3.561, Average Loss: 4.267, avg. samples / sec: 53856.05
Iteration:   2720, Loss function: 5.332, Average Loss: 4.304, avg. samples / sec: 53901.59
Iteration:   2720, Loss function: 4.734, Average Loss: 4.273, avg. samples / sec: 53837.06
Iteration:   2720, Loss function: 3.299, Average Loss: 4.284, avg. samples / sec: 53862.96
Iteration:   2720, Loss function: 3.658, Average Loss: 4.274, avg. samples / sec: 53856.68
Iteration:   2720, Loss function: 6.376, Average Loss: 4.276, avg. samples / sec: 53875.36
Iteration:   2720, Loss function: 2.795, Average Loss: 4.271, avg. samples / sec: 53871.55
Iteration:   2720, Loss function: 4.720, Average Loss: 4.280, avg. samples / sec: 53850.69
Iteration:   2720, Loss function: 3.835, Average Loss: 4.273, avg. samples / sec: 53839.22
Iteration:   2720, Loss function: 3.050, Average Loss: 4.291, avg. samples / sec: 53877.19
Iteration:   2720, Loss function: 4.272, Average Loss: 4.276, avg. samples / sec: 53744.36
Iteration:   2720, Loss function: 3.512, Average Loss: 4.252, avg. samples / sec: 53893.61
Iteration:   2720, Loss function: 4.452, Average Loss: 4.257, avg. samples / sec: 53884.17
Iteration:   2720, Loss function: 4.418, Average Loss: 4.272, avg. samples / sec: 53927.80
Iteration:   2720, Loss function: 2.886, Average Loss: 4.286, avg. samples / sec: 53878.96
Iteration:   2720, Loss function: 4.433, Average Loss: 4.295, avg. samples / sec: 53842.14
Iteration:   2720, Loss function: 3.758, Average Loss: 4.268, avg. samples / sec: 53885.31
Iteration:   2720, Loss function: 4.180, Average Loss: 4.262, avg. samples / sec: 53606.65
Iteration:   2720, Loss function: 3.109, Average Loss: 4.260, avg. samples / sec: 53848.06
Iteration:   2720, Loss function: 3.578, Average Loss: 4.266, avg. samples / sec: 53871.40
Iteration:   2720, Loss function: 4.263, Average Loss: 4.264, avg. samples / sec: 53640.03
Iteration:   2720, Loss function: 3.214, Average Loss: 4.269, avg. samples / sec: 53814.77
Iteration:   2720, Loss function: 4.922, Average Loss: 4.264, avg. samples / sec: 53808.48
:::MLL 1558640368.756 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558640368.757 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 4.090, Average Loss: 4.278, avg. samples / sec: 54074.78
Iteration:   2740, Loss function: 3.288, Average Loss: 4.273, avg. samples / sec: 53925.93
Iteration:   2740, Loss function: 4.250, Average Loss: 4.275, avg. samples / sec: 53884.01
Iteration:   2740, Loss function: 4.705, Average Loss: 4.267, avg. samples / sec: 53930.51
Iteration:   2740, Loss function: 4.188, Average Loss: 4.271, avg. samples / sec: 53905.73
Iteration:   2740, Loss function: 5.198, Average Loss: 4.263, avg. samples / sec: 53886.15
Iteration:   2740, Loss function: 3.619, Average Loss: 4.257, avg. samples / sec: 53887.20
Iteration:   2740, Loss function: 3.814, Average Loss: 4.272, avg. samples / sec: 53850.47
Iteration:   2740, Loss function: 4.989, Average Loss: 4.305, avg. samples / sec: 53882.69
Iteration:   2740, Loss function: 5.014, Average Loss: 4.289, avg. samples / sec: 53811.54
Iteration:   2740, Loss function: 3.972, Average Loss: 4.269, avg. samples / sec: 53978.53
Iteration:   2740, Loss function: 2.664, Average Loss: 4.278, avg. samples / sec: 53897.05
Iteration:   2740, Loss function: 4.229, Average Loss: 4.263, avg. samples / sec: 53890.38
Iteration:   2740, Loss function: 4.167, Average Loss: 4.269, avg. samples / sec: 53896.02
Iteration:   2740, Loss function: 3.963, Average Loss: 4.280, avg. samples / sec: 53867.33
Iteration:   2740, Loss function: 3.485, Average Loss: 4.277, avg. samples / sec: 53755.39
Iteration:   2740, Loss function: 4.831, Average Loss: 4.261, avg. samples / sec: 53787.62
Iteration:   2740, Loss function: 4.951, Average Loss: 4.285, avg. samples / sec: 53831.67
Iteration:   2740, Loss function: 3.656, Average Loss: 4.270, avg. samples / sec: 53879.79
Iteration:   2740, Loss function: 3.229, Average Loss: 4.255, avg. samples / sec: 53857.73
Iteration:   2740, Loss function: 4.507, Average Loss: 4.289, avg. samples / sec: 53881.68
Iteration:   2740, Loss function: 3.199, Average Loss: 4.246, avg. samples / sec: 53855.57
Iteration:   2740, Loss function: 4.745, Average Loss: 4.279, avg. samples / sec: 53876.28
Iteration:   2740, Loss function: 3.539, Average Loss: 4.253, avg. samples / sec: 53895.94
Iteration:   2740, Loss function: 3.198, Average Loss: 4.263, avg. samples / sec: 53915.86
Iteration:   2740, Loss function: 3.820, Average Loss: 4.264, avg. samples / sec: 53852.32
Iteration:   2740, Loss function: 3.250, Average Loss: 4.268, avg. samples / sec: 53894.09
Iteration:   2740, Loss function: 4.197, Average Loss: 4.253, avg. samples / sec: 53869.84
Iteration:   2740, Loss function: 4.184, Average Loss: 4.257, avg. samples / sec: 53913.55
Iteration:   2740, Loss function: 3.919, Average Loss: 4.258, avg. samples / sec: 53881.56
Iteration:   2760, Loss function: 3.401, Average Loss: 4.272, avg. samples / sec: 54343.16
Iteration:   2760, Loss function: 2.974, Average Loss: 4.260, avg. samples / sec: 54335.68
Iteration:   2760, Loss function: 4.299, Average Loss: 4.257, avg. samples / sec: 54282.42
Iteration:   2760, Loss function: 3.570, Average Loss: 4.266, avg. samples / sec: 54275.94
Iteration:   2760, Loss function: 3.473, Average Loss: 4.254, avg. samples / sec: 54294.80
Iteration:   2760, Loss function: 4.039, Average Loss: 4.262, avg. samples / sec: 54301.56
Iteration:   2760, Loss function: 3.645, Average Loss: 4.256, avg. samples / sec: 54353.43
Iteration:   2760, Loss function: 3.231, Average Loss: 4.257, avg. samples / sec: 54288.48
Iteration:   2760, Loss function: 5.130, Average Loss: 4.273, avg. samples / sec: 54358.97
Iteration:   2760, Loss function: 2.893, Average Loss: 4.270, avg. samples / sec: 54085.88
Iteration:   2760, Loss function: 4.082, Average Loss: 4.276, avg. samples / sec: 54080.20
Iteration:   2760, Loss function: 3.679, Average Loss: 4.263, avg. samples / sec: 54222.04
Iteration:   2760, Loss function: 3.695, Average Loss: 4.271, avg. samples / sec: 54306.64
Iteration:   2760, Loss function: 3.284, Average Loss: 4.276, avg. samples / sec: 54252.85
Iteration:   2760, Loss function: 4.763, Average Loss: 4.262, avg. samples / sec: 54186.83
Iteration:   2760, Loss function: 3.597, Average Loss: 4.301, avg. samples / sec: 54169.39
Iteration:   2760, Loss function: 4.018, Average Loss: 4.245, avg. samples / sec: 54311.14
Iteration:   2760, Loss function: 4.206, Average Loss: 4.263, avg. samples / sec: 54311.67
Iteration:   2760, Loss function: 4.053, Average Loss: 4.280, avg. samples / sec: 54284.89
Iteration:   2760, Loss function: 3.503, Average Loss: 4.283, avg. samples / sec: 54052.32
Iteration:   2760, Loss function: 4.082, Average Loss: 4.263, avg. samples / sec: 54315.12
Iteration:   2760, Loss function: 5.490, Average Loss: 4.255, avg. samples / sec: 54314.95
Iteration:   2760, Loss function: 3.844, Average Loss: 4.276, avg. samples / sec: 54263.00
Iteration:   2760, Loss function: 4.752, Average Loss: 4.253, avg. samples / sec: 54270.36
Iteration:   2760, Loss function: 3.884, Average Loss: 4.249, avg. samples / sec: 54251.79
Iteration:   2760, Loss function: 5.387, Average Loss: 4.253, avg. samples / sec: 54302.42
Iteration:   2760, Loss function: 3.035, Average Loss: 4.267, avg. samples / sec: 53958.38
Iteration:   2760, Loss function: 4.534, Average Loss: 4.252, avg. samples / sec: 54302.00
Iteration:   2760, Loss function: 4.348, Average Loss: 4.260, avg. samples / sec: 54251.53
Iteration:   2760, Loss function: 3.448, Average Loss: 4.265, avg. samples / sec: 54096.41
Iteration:   2780, Loss function: 3.480, Average Loss: 4.251, avg. samples / sec: 54465.42
Iteration:   2780, Loss function: 4.594, Average Loss: 4.263, avg. samples / sec: 54425.12
Iteration:   2780, Loss function: 3.682, Average Loss: 4.257, avg. samples / sec: 54387.39
Iteration:   2780, Loss function: 4.245, Average Loss: 4.272, avg. samples / sec: 54404.63
Iteration:   2780, Loss function: 4.845, Average Loss: 4.264, avg. samples / sec: 54594.55
Iteration:   2780, Loss function: 4.039, Average Loss: 4.263, avg. samples / sec: 54273.76
Iteration:   2780, Loss function: 4.320, Average Loss: 4.260, avg. samples / sec: 54244.96
Iteration:   2780, Loss function: 4.570, Average Loss: 4.254, avg. samples / sec: 54250.97
Iteration:   2780, Loss function: 3.478, Average Loss: 4.277, avg. samples / sec: 54505.65
Iteration:   2780, Loss function: 5.298, Average Loss: 4.258, avg. samples / sec: 54333.71
Iteration:   2780, Loss function: 4.550, Average Loss: 4.265, avg. samples / sec: 54316.21
Iteration:   2780, Loss function: 3.537, Average Loss: 4.298, avg. samples / sec: 54364.84
Iteration:   2780, Loss function: 2.585, Average Loss: 4.252, avg. samples / sec: 54225.02
Iteration:   2780, Loss function: 3.302, Average Loss: 4.264, avg. samples / sec: 54214.78
Iteration:   2780, Loss function: 5.431, Average Loss: 4.278, avg. samples / sec: 54279.62
Iteration:   2780, Loss function: 4.692, Average Loss: 4.264, avg. samples / sec: 54238.21
Iteration:   2780, Loss function: 4.392, Average Loss: 4.259, avg. samples / sec: 54223.40
Iteration:   2780, Loss function: 4.405, Average Loss: 4.246, avg. samples / sec: 54282.13
Iteration:   2780, Loss function: 5.666, Average Loss: 4.254, avg. samples / sec: 54081.28
Iteration:   2780, Loss function: 3.635, Average Loss: 4.275, avg. samples / sec: 54297.77
Iteration:   2780, Loss function: 5.031, Average Loss: 4.257, avg. samples / sec: 54437.04
Iteration:   2780, Loss function: 3.730, Average Loss: 4.260, avg. samples / sec: 54259.89
Iteration:   2780, Loss function: 4.050, Average Loss: 4.273, avg. samples / sec: 54260.91
Iteration:   2780, Loss function: 4.284, Average Loss: 4.247, avg. samples / sec: 54276.98
Iteration:   2780, Loss function: 3.785, Average Loss: 4.250, avg. samples / sec: 54264.61
Iteration:   2780, Loss function: 5.688, Average Loss: 4.257, avg. samples / sec: 54242.85
Iteration:   2780, Loss function: 3.620, Average Loss: 4.251, avg. samples / sec: 54253.46
Iteration:   2780, Loss function: 4.390, Average Loss: 4.257, avg. samples / sec: 54276.08
Iteration:   2780, Loss function: 3.353, Average Loss: 4.247, avg. samples / sec: 54235.33
Iteration:   2780, Loss function: 3.785, Average Loss: 4.252, avg. samples / sec: 54233.12
:::MLL 1558640370.927 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558640370.928 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 4.594, Average Loss: 4.249, avg. samples / sec: 54120.68
Iteration:   2800, Loss function: 3.789, Average Loss: 4.252, avg. samples / sec: 54025.65
Iteration:   2800, Loss function: 4.426, Average Loss: 4.264, avg. samples / sec: 53990.80
Iteration:   2800, Loss function: 4.026, Average Loss: 4.257, avg. samples / sec: 54099.13
Iteration:   2800, Loss function: 4.865, Average Loss: 4.294, avg. samples / sec: 54096.80
Iteration:   2800, Loss function: 4.298, Average Loss: 4.272, avg. samples / sec: 54072.35
Iteration:   2800, Loss function: 3.493, Average Loss: 4.247, avg. samples / sec: 54080.53
Iteration:   2800, Loss function: 4.516, Average Loss: 4.257, avg. samples / sec: 53985.01
Iteration:   2800, Loss function: 4.378, Average Loss: 4.257, avg. samples / sec: 53941.63
Iteration:   2800, Loss function: 4.724, Average Loss: 4.275, avg. samples / sec: 54023.33
Iteration:   2800, Loss function: 3.532, Average Loss: 4.245, avg. samples / sec: 53798.75
Iteration:   2800, Loss function: 3.733, Average Loss: 4.260, avg. samples / sec: 53988.34
Iteration:   2800, Loss function: 2.561, Average Loss: 4.256, avg. samples / sec: 53945.27
Iteration:   2800, Loss function: 3.812, Average Loss: 4.245, avg. samples / sec: 53969.00
Iteration:   2800, Loss function: 4.431, Average Loss: 4.263, avg. samples / sec: 53946.86
Iteration:   2800, Loss function: 5.012, Average Loss: 4.263, avg. samples / sec: 53987.67
Iteration:   2800, Loss function: 3.673, Average Loss: 4.257, avg. samples / sec: 54143.21
Iteration:   2800, Loss function: 3.883, Average Loss: 4.270, avg. samples / sec: 53851.19
Iteration:   2800, Loss function: 4.021, Average Loss: 4.246, avg. samples / sec: 54121.98
Iteration:   2800, Loss function: 4.468, Average Loss: 4.252, avg. samples / sec: 54081.32
Iteration:   2800, Loss function: 4.858, Average Loss: 4.243, avg. samples / sec: 54134.10
Iteration:   2800, Loss function: 4.098, Average Loss: 4.250, avg. samples / sec: 54036.07
Iteration:   2800, Loss function: 4.009, Average Loss: 4.239, avg. samples / sec: 53946.65
Iteration:   2800, Loss function: 4.951, Average Loss: 4.271, avg. samples / sec: 53967.27
Iteration:   2800, Loss function: 5.408, Average Loss: 4.271, avg. samples / sec: 53964.75
Iteration:   2800, Loss function: 2.706, Average Loss: 4.251, avg. samples / sec: 53997.42
Iteration:   2800, Loss function: 3.770, Average Loss: 4.246, avg. samples / sec: 53969.44
Iteration:   2800, Loss function: 4.136, Average Loss: 4.252, avg. samples / sec: 53924.48
Iteration:   2800, Loss function: 3.991, Average Loss: 4.246, avg. samples / sec: 53961.32
Iteration:   2800, Loss function: 4.180, Average Loss: 4.238, avg. samples / sec: 53923.02
Iteration:   2820, Loss function: 3.759, Average Loss: 4.252, avg. samples / sec: 54439.48
Iteration:   2820, Loss function: 2.214, Average Loss: 4.264, avg. samples / sec: 54379.00
Iteration:   2820, Loss function: 5.753, Average Loss: 4.264, avg. samples / sec: 54445.85
Iteration:   2820, Loss function: 4.821, Average Loss: 4.255, avg. samples / sec: 54428.44
Iteration:   2820, Loss function: 3.236, Average Loss: 4.252, avg. samples / sec: 54468.58
Iteration:   2820, Loss function: 3.847, Average Loss: 4.262, avg. samples / sec: 54327.41
Iteration:   2820, Loss function: 4.623, Average Loss: 4.265, avg. samples / sec: 54506.35
Iteration:   2820, Loss function: 3.845, Average Loss: 4.294, avg. samples / sec: 54332.44
Iteration:   2820, Loss function: 4.271, Average Loss: 4.246, avg. samples / sec: 54289.28
Iteration:   2820, Loss function: 2.823, Average Loss: 4.242, avg. samples / sec: 54385.02
Iteration:   2820, Loss function: 4.921, Average Loss: 4.267, avg. samples / sec: 54414.27
Iteration:   2820, Loss function: 4.089, Average Loss: 4.240, avg. samples / sec: 54441.12
Iteration:   2820, Loss function: 3.933, Average Loss: 4.256, avg. samples / sec: 54407.19
Iteration:   2820, Loss function: 5.164, Average Loss: 4.260, avg. samples / sec: 54435.71
Iteration:   2820, Loss function: 4.658, Average Loss: 4.253, avg. samples / sec: 54280.20
Iteration:   2820, Loss function: 3.780, Average Loss: 4.258, avg. samples / sec: 54432.28
Iteration:   2820, Loss function: 4.459, Average Loss: 4.246, avg. samples / sec: 54574.25
Iteration:   2820, Loss function: 4.448, Average Loss: 4.256, avg. samples / sec: 54393.86
Iteration:   2820, Loss function: 4.908, Average Loss: 4.249, avg. samples / sec: 54343.92
Iteration:   2820, Loss function: 3.691, Average Loss: 4.264, avg. samples / sec: 54436.05
Iteration:   2820, Loss function: 4.336, Average Loss: 4.229, avg. samples / sec: 54497.12
Iteration:   2820, Loss function: 3.308, Average Loss: 4.232, avg. samples / sec: 54404.74
Iteration:   2820, Loss function: 4.001, Average Loss: 4.241, avg. samples / sec: 54312.80
Iteration:   2820, Loss function: 4.164, Average Loss: 4.248, avg. samples / sec: 54165.61
Iteration:   2820, Loss function: 3.653, Average Loss: 4.246, avg. samples / sec: 54276.57
Iteration:   2820, Loss function: 4.777, Average Loss: 4.244, avg. samples / sec: 54453.80
Iteration:   2820, Loss function: 4.548, Average Loss: 4.247, avg. samples / sec: 54445.89
Iteration:   2820, Loss function: 4.199, Average Loss: 4.270, avg. samples / sec: 54399.95
Iteration:   2820, Loss function: 3.496, Average Loss: 4.244, avg. samples / sec: 54423.62
Iteration:   2820, Loss function: 4.503, Average Loss: 4.249, avg. samples / sec: 54396.17
Iteration:   2840, Loss function: 3.895, Average Loss: 4.242, avg. samples / sec: 53470.72
Iteration:   2840, Loss function: 4.549, Average Loss: 4.258, avg. samples / sec: 53452.15
Iteration:   2840, Loss function: 4.579, Average Loss: 4.260, avg. samples / sec: 53416.65
Iteration:   2840, Loss function: 3.880, Average Loss: 4.237, avg. samples / sec: 53426.17
Iteration:   2840, Loss function: 4.177, Average Loss: 4.287, avg. samples / sec: 53408.35
Iteration:   2840, Loss function: 4.535, Average Loss: 4.251, avg. samples / sec: 53379.54
Iteration:   2840, Loss function: 5.709, Average Loss: 4.261, avg. samples / sec: 53365.46
Iteration:   2840, Loss function: 3.574, Average Loss: 4.251, avg. samples / sec: 53435.16
Iteration:   2840, Loss function: 3.951, Average Loss: 4.239, avg. samples / sec: 53389.86
Iteration:   2840, Loss function: 3.943, Average Loss: 4.252, avg. samples / sec: 53423.90
Iteration:   2840, Loss function: 4.533, Average Loss: 4.245, avg. samples / sec: 53642.34
Iteration:   2840, Loss function: 2.445, Average Loss: 4.268, avg. samples / sec: 53375.22
Iteration:   2840, Loss function: 5.649, Average Loss: 4.241, avg. samples / sec: 53377.32
Iteration:   2840, Loss function: 4.599, Average Loss: 4.261, avg. samples / sec: 53364.20
Iteration:   2840, Loss function: 3.893, Average Loss: 4.243, avg. samples / sec: 53343.58
Iteration:   2840, Loss function: 4.701, Average Loss: 4.256, avg. samples / sec: 53390.83
Iteration:   2840, Loss function: 4.989, Average Loss: 4.257, avg. samples / sec: 53415.21
Iteration:   2840, Loss function: 3.776, Average Loss: 4.254, avg. samples / sec: 53338.15
Iteration:   2840, Loss function: 3.479, Average Loss: 4.245, avg. samples / sec: 53388.95
Iteration:   2840, Loss function: 4.156, Average Loss: 4.223, avg. samples / sec: 53407.50
Iteration:   2840, Loss function: 4.090, Average Loss: 4.259, avg. samples / sec: 53383.85
Iteration:   2840, Loss function: 4.475, Average Loss: 4.234, avg. samples / sec: 53411.33
Iteration:   2840, Loss function: 3.942, Average Loss: 4.242, avg. samples / sec: 53430.28
Iteration:   2840, Loss function: 2.476, Average Loss: 4.266, avg. samples / sec: 53420.40
Iteration:   2840, Loss function: 5.017, Average Loss: 4.245, avg. samples / sec: 53392.49
Iteration:   2840, Loss function: 3.259, Average Loss: 4.239, avg. samples / sec: 53197.59
Iteration:   2840, Loss function: 3.647, Average Loss: 4.245, avg. samples / sec: 53411.75
Iteration:   2840, Loss function: 4.264, Average Loss: 4.236, avg. samples / sec: 53385.02
Iteration:   2840, Loss function: 3.835, Average Loss: 4.241, avg. samples / sec: 53400.24
Iteration:   2840, Loss function: 3.730, Average Loss: 4.222, avg. samples / sec: 53332.15
Iteration:   2860, Loss function: 4.645, Average Loss: 4.237, avg. samples / sec: 54655.57
Iteration:   2860, Loss function: 3.278, Average Loss: 4.248, avg. samples / sec: 54660.06
Iteration:   2860, Loss function: 4.552, Average Loss: 4.238, avg. samples / sec: 54760.82
Iteration:   2860, Loss function: 4.525, Average Loss: 4.287, avg. samples / sec: 54702.43
Iteration:   2860, Loss function: 4.425, Average Loss: 4.247, avg. samples / sec: 54709.76
Iteration:   2860, Loss function: 3.861, Average Loss: 4.244, avg. samples / sec: 54720.08
Iteration:   2860, Loss function: 4.765, Average Loss: 4.250, avg. samples / sec: 54702.24
Iteration:   2860, Loss function: 4.656, Average Loss: 4.261, avg. samples / sec: 54694.09
Iteration:   2860, Loss function: 4.396, Average Loss: 4.257, avg. samples / sec: 54661.76
Iteration:   2860, Loss function: 3.994, Average Loss: 4.251, avg. samples / sec: 54687.66
Iteration:   2860, Loss function: 4.643, Average Loss: 4.250, avg. samples / sec: 54768.69
Iteration:   2860, Loss function: 4.166, Average Loss: 4.230, avg. samples / sec: 54650.35
Iteration:   2860, Loss function: 3.719, Average Loss: 4.262, avg. samples / sec: 54689.80
Iteration:   2860, Loss function: 5.232, Average Loss: 4.251, avg. samples / sec: 54712.88
Iteration:   2860, Loss function: 3.440, Average Loss: 4.255, avg. samples / sec: 54660.53
Iteration:   2860, Loss function: 2.892, Average Loss: 4.253, avg. samples / sec: 54693.83
Iteration:   2860, Loss function: 3.413, Average Loss: 4.240, avg. samples / sec: 54672.93
Iteration:   2860, Loss function: 3.352, Average Loss: 4.240, avg. samples / sec: 54628.79
Iteration:   2860, Loss function: 4.202, Average Loss: 4.217, avg. samples / sec: 54723.54
Iteration:   2860, Loss function: 4.800, Average Loss: 4.242, avg. samples / sec: 54715.81
Iteration:   2860, Loss function: 3.757, Average Loss: 4.252, avg. samples / sec: 54714.11
Iteration:   2860, Loss function: 2.865, Average Loss: 4.243, avg. samples / sec: 54748.08
Iteration:   2860, Loss function: 3.290, Average Loss: 4.261, avg. samples / sec: 54726.84
Iteration:   2860, Loss function: 4.931, Average Loss: 4.237, avg. samples / sec: 54701.79
Iteration:   2860, Loss function: 3.387, Average Loss: 4.237, avg. samples / sec: 54719.44
Iteration:   2860, Loss function: 5.392, Average Loss: 4.231, avg. samples / sec: 54671.64
Iteration:   2860, Loss function: 4.661, Average Loss: 4.233, avg. samples / sec: 54709.04
Iteration:   2860, Loss function: 3.750, Average Loss: 4.216, avg. samples / sec: 54732.39
Iteration:   2860, Loss function: 4.578, Average Loss: 4.239, avg. samples / sec: 54697.27
Iteration:   2860, Loss function: 4.710, Average Loss: 4.236, avg. samples / sec: 54670.79
:::MLL 1558640373.103 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558640373.104 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 2.999, Average Loss: 4.230, avg. samples / sec: 53575.76
Iteration:   2880, Loss function: 4.249, Average Loss: 4.241, avg. samples / sec: 53628.56
Iteration:   2880, Loss function: 4.831, Average Loss: 4.247, avg. samples / sec: 53676.29
Iteration:   2880, Loss function: 4.480, Average Loss: 4.245, avg. samples / sec: 53656.35
Iteration:   2880, Loss function: 4.059, Average Loss: 4.239, avg. samples / sec: 53663.68
Iteration:   2880, Loss function: 5.180, Average Loss: 4.247, avg. samples / sec: 53635.21
Iteration:   2880, Loss function: 2.583, Average Loss: 4.234, avg. samples / sec: 53592.48
Iteration:   2880, Loss function: 3.974, Average Loss: 4.279, avg. samples / sec: 53619.42
Iteration:   2880, Loss function: 4.129, Average Loss: 4.257, avg. samples / sec: 53643.58
Iteration:   2880, Loss function: 4.062, Average Loss: 4.249, avg. samples / sec: 53690.53
Iteration:   2880, Loss function: 3.939, Average Loss: 4.219, avg. samples / sec: 53655.82
Iteration:   2880, Loss function: 4.639, Average Loss: 4.246, avg. samples / sec: 53667.83
Iteration:   2880, Loss function: 3.853, Average Loss: 4.241, avg. samples / sec: 53599.05
Iteration:   2880, Loss function: 3.087, Average Loss: 4.255, avg. samples / sec: 53623.64
Iteration:   2880, Loss function: 3.539, Average Loss: 4.243, avg. samples / sec: 53618.97
Iteration:   2880, Loss function: 3.726, Average Loss: 4.237, avg. samples / sec: 53656.59
Iteration:   2880, Loss function: 4.204, Average Loss: 4.234, avg. samples / sec: 53671.98
Iteration:   2880, Loss function: 4.325, Average Loss: 4.245, avg. samples / sec: 53627.01
Iteration:   2880, Loss function: 3.022, Average Loss: 4.249, avg. samples / sec: 53687.66
Iteration:   2880, Loss function: 3.942, Average Loss: 4.245, avg. samples / sec: 53617.73
Iteration:   2880, Loss function: 2.910, Average Loss: 4.214, avg. samples / sec: 53619.32
Iteration:   2880, Loss function: 3.260, Average Loss: 4.231, avg. samples / sec: 53649.49
Iteration:   2880, Loss function: 4.494, Average Loss: 4.224, avg. samples / sec: 53656.45
Iteration:   2880, Loss function: 3.928, Average Loss: 4.243, avg. samples / sec: 53613.22
Iteration:   2880, Loss function: 4.594, Average Loss: 4.228, avg. samples / sec: 53668.63
Iteration:   2880, Loss function: 3.769, Average Loss: 4.228, avg. samples / sec: 53670.78
Iteration:   2880, Loss function: 3.603, Average Loss: 4.232, avg. samples / sec: 53615.50
Iteration:   2880, Loss function: 4.118, Average Loss: 4.227, avg. samples / sec: 53630.38
Iteration:   2880, Loss function: 4.966, Average Loss: 4.209, avg. samples / sec: 53629.11
Iteration:   2880, Loss function: 4.719, Average Loss: 4.253, avg. samples / sec: 53584.68
Iteration:   2900, Loss function: 4.371, Average Loss: 4.275, avg. samples / sec: 53912.68
Iteration:   2900, Loss function: 4.439, Average Loss: 4.243, avg. samples / sec: 53900.58
Iteration:   2900, Loss function: 4.906, Average Loss: 4.241, avg. samples / sec: 53884.54
Iteration:   2900, Loss function: 3.171, Average Loss: 4.227, avg. samples / sec: 53889.06
Iteration:   2900, Loss function: 3.902, Average Loss: 4.231, avg. samples / sec: 53912.21
Iteration:   2900, Loss function: 3.357, Average Loss: 4.215, avg. samples / sec: 53894.19
Iteration:   2900, Loss function: 2.247, Average Loss: 4.236, avg. samples / sec: 53938.00
Iteration:   2900, Loss function: 3.827, Average Loss: 4.253, avg. samples / sec: 53902.21
Iteration:   2900, Loss function: 4.483, Average Loss: 4.233, avg. samples / sec: 53910.17
Iteration:   2900, Loss function: 4.951, Average Loss: 4.237, avg. samples / sec: 53859.63
Iteration:   2900, Loss function: 4.350, Average Loss: 4.229, avg. samples / sec: 53744.97
Iteration:   2900, Loss function: 4.966, Average Loss: 4.243, avg. samples / sec: 53844.52
Iteration:   2900, Loss function: 3.524, Average Loss: 4.242, avg. samples / sec: 53788.46
Iteration:   2900, Loss function: 4.694, Average Loss: 4.235, avg. samples / sec: 53833.13
Iteration:   2900, Loss function: 4.059, Average Loss: 4.232, avg. samples / sec: 53746.14
Iteration:   2900, Loss function: 4.003, Average Loss: 4.210, avg. samples / sec: 53911.94
Iteration:   2900, Loss function: 5.609, Average Loss: 4.249, avg. samples / sec: 53956.61
Iteration:   2900, Loss function: 3.599, Average Loss: 4.242, avg. samples / sec: 53902.31
Iteration:   2900, Loss function: 6.366, Average Loss: 4.242, avg. samples / sec: 53922.65
Iteration:   2900, Loss function: 2.507, Average Loss: 4.216, avg. samples / sec: 53902.39
Iteration:   2900, Loss function: 4.766, Average Loss: 4.220, avg. samples / sec: 53908.45
Iteration:   2900, Loss function: 5.043, Average Loss: 4.222, avg. samples / sec: 53880.51
Iteration:   2900, Loss function: 4.760, Average Loss: 4.240, avg. samples / sec: 53581.15
Iteration:   2900, Loss function: 5.624, Average Loss: 4.226, avg. samples / sec: 53865.53
Iteration:   2900, Loss function: 3.195, Average Loss: 4.244, avg. samples / sec: 53797.64
Iteration:   2900, Loss function: 3.079, Average Loss: 4.230, avg. samples / sec: 53906.02
Iteration:   2900, Loss function: 3.755, Average Loss: 4.250, avg. samples / sec: 53602.70
Iteration:   2900, Loss function: 3.542, Average Loss: 4.232, avg. samples / sec: 53640.17
Iteration:   2900, Loss function: 3.923, Average Loss: 4.226, avg. samples / sec: 53882.94
Iteration:   2900, Loss function: 3.882, Average Loss: 4.207, avg. samples / sec: 53883.37
Iteration:   2920, Loss function: 4.055, Average Loss: 4.219, avg. samples / sec: 53971.44
Iteration:   2920, Loss function: 4.207, Average Loss: 4.237, avg. samples / sec: 54123.23
Iteration:   2920, Loss function: 4.146, Average Loss: 4.272, avg. samples / sec: 53823.20
Iteration:   2920, Loss function: 4.272, Average Loss: 4.240, avg. samples / sec: 53899.42
Iteration:   2920, Loss function: 3.077, Average Loss: 4.242, avg. samples / sec: 53815.47
Iteration:   2920, Loss function: 3.566, Average Loss: 4.210, avg. samples / sec: 53839.36
Iteration:   2920, Loss function: 4.448, Average Loss: 4.235, avg. samples / sec: 53816.66
Iteration:   2920, Loss function: 3.458, Average Loss: 4.222, avg. samples / sec: 53818.70
Iteration:   2920, Loss function: 4.090, Average Loss: 4.245, avg. samples / sec: 53857.40
Iteration:   2920, Loss function: 4.423, Average Loss: 4.225, avg. samples / sec: 53826.79
Iteration:   2920, Loss function: 2.575, Average Loss: 4.246, avg. samples / sec: 53874.25
Iteration:   2920, Loss function: 4.586, Average Loss: 4.249, avg. samples / sec: 54097.45
Iteration:   2920, Loss function: 3.937, Average Loss: 4.231, avg. samples / sec: 53894.62
Iteration:   2920, Loss function: 4.042, Average Loss: 4.228, avg. samples / sec: 54092.57
Iteration:   2920, Loss function: 3.563, Average Loss: 4.232, avg. samples / sec: 53915.30
Iteration:   2920, Loss function: 2.718, Average Loss: 4.233, avg. samples / sec: 53818.41
Iteration:   2920, Loss function: 4.292, Average Loss: 4.229, avg. samples / sec: 53764.68
Iteration:   2920, Loss function: 3.920, Average Loss: 4.230, avg. samples / sec: 53781.36
Iteration:   2920, Loss function: 3.009, Average Loss: 4.239, avg. samples / sec: 53957.10
Iteration:   2920, Loss function: 3.451, Average Loss: 4.243, avg. samples / sec: 53826.77
Iteration:   2920, Loss function: 4.229, Average Loss: 4.203, avg. samples / sec: 53810.58
Iteration:   2920, Loss function: 3.812, Average Loss: 4.240, avg. samples / sec: 53851.54
Iteration:   2920, Loss function: 3.753, Average Loss: 4.244, avg. samples / sec: 53808.75
Iteration:   2920, Loss function: 3.499, Average Loss: 4.226, avg. samples / sec: 53865.64
Iteration:   2920, Loss function: 3.692, Average Loss: 4.224, avg. samples / sec: 53817.30
Iteration:   2920, Loss function: 3.328, Average Loss: 4.220, avg. samples / sec: 53826.73
Iteration:   2920, Loss function: 5.425, Average Loss: 4.222, avg. samples / sec: 53813.33
Iteration:   2920, Loss function: 3.829, Average Loss: 4.213, avg. samples / sec: 53802.14
Iteration:   2920, Loss function: 3.434, Average Loss: 4.203, avg. samples / sec: 53839.38
Iteration:   2920, Loss function: 4.213, Average Loss: 4.214, avg. samples / sec: 53763.55
:::MLL 1558640375.288 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558640375.288 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 4.193, Average Loss: 4.216, avg. samples / sec: 53827.58
Iteration:   2940, Loss function: 2.938, Average Loss: 4.213, avg. samples / sec: 53902.76
Iteration:   2940, Loss function: 4.610, Average Loss: 4.226, avg. samples / sec: 53926.40
Iteration:   2940, Loss function: 5.223, Average Loss: 4.270, avg. samples / sec: 53852.55
Iteration:   2940, Loss function: 4.543, Average Loss: 4.244, avg. samples / sec: 53877.05
Iteration:   2940, Loss function: 4.836, Average Loss: 4.247, avg. samples / sec: 53875.89
Iteration:   2940, Loss function: 3.821, Average Loss: 4.207, avg. samples / sec: 53792.28
Iteration:   2940, Loss function: 3.155, Average Loss: 4.230, avg. samples / sec: 53752.86
Iteration:   2940, Loss function: 4.074, Average Loss: 4.233, avg. samples / sec: 53761.76
Iteration:   2940, Loss function: 4.688, Average Loss: 4.235, avg. samples / sec: 53731.55
Iteration:   2940, Loss function: 3.707, Average Loss: 4.238, avg. samples / sec: 53741.53
Iteration:   2940, Loss function: 3.610, Average Loss: 4.235, avg. samples / sec: 53712.24
Iteration:   2940, Loss function: 3.398, Average Loss: 4.229, avg. samples / sec: 53757.52
Iteration:   2940, Loss function: 4.233, Average Loss: 4.217, avg. samples / sec: 53715.10
Iteration:   2940, Loss function: 5.057, Average Loss: 4.224, avg. samples / sec: 53744.83
Iteration:   2940, Loss function: 3.271, Average Loss: 4.233, avg. samples / sec: 53787.91
Iteration:   2940, Loss function: 3.354, Average Loss: 4.227, avg. samples / sec: 53709.05
Iteration:   2940, Loss function: 3.989, Average Loss: 4.226, avg. samples / sec: 53739.93
Iteration:   2940, Loss function: 3.762, Average Loss: 4.227, avg. samples / sec: 53730.92
Iteration:   2940, Loss function: 3.376, Average Loss: 4.199, avg. samples / sec: 53841.11
Iteration:   2940, Loss function: 3.461, Average Loss: 4.241, avg. samples / sec: 53830.06
Iteration:   2940, Loss function: 4.713, Average Loss: 4.216, avg. samples / sec: 53847.28
Iteration:   2940, Loss function: 3.146, Average Loss: 4.231, avg. samples / sec: 53798.40
Iteration:   2940, Loss function: 3.958, Average Loss: 4.208, avg. samples / sec: 53831.38
Iteration:   2940, Loss function: 3.112, Average Loss: 4.233, avg. samples / sec: 53756.39
Iteration:   2940, Loss function: 3.346, Average Loss: 4.209, avg. samples / sec: 53804.52
Iteration:   2940, Loss function: 4.262, Average Loss: 4.215, avg. samples / sec: 53742.16
Iteration:   2940, Loss function: 4.528, Average Loss: 4.223, avg. samples / sec: 53703.54
Iteration:   2940, Loss function: 3.823, Average Loss: 4.218, avg. samples / sec: 53715.35
Iteration:   2940, Loss function: 4.773, Average Loss: 4.200, avg. samples / sec: 53726.02
Iteration:   2960, Loss function: 4.012, Average Loss: 4.210, avg. samples / sec: 53827.19
Iteration:   2960, Loss function: 4.274, Average Loss: 4.226, avg. samples / sec: 53872.56
Iteration:   2960, Loss function: 3.919, Average Loss: 4.244, avg. samples / sec: 53794.09
Iteration:   2960, Loss function: 3.571, Average Loss: 4.212, avg. samples / sec: 53746.98
Iteration:   2960, Loss function: 3.651, Average Loss: 4.228, avg. samples / sec: 53875.01
Iteration:   2960, Loss function: 3.688, Average Loss: 4.218, avg. samples / sec: 53746.65
Iteration:   2960, Loss function: 4.253, Average Loss: 4.265, avg. samples / sec: 53757.05
Iteration:   2960, Loss function: 3.714, Average Loss: 4.233, avg. samples / sec: 53889.68
Iteration:   2960, Loss function: 4.735, Average Loss: 4.204, avg. samples / sec: 53829.14
Iteration:   2960, Loss function: 3.413, Average Loss: 4.233, avg. samples / sec: 53895.36
Iteration:   2960, Loss function: 4.188, Average Loss: 4.240, avg. samples / sec: 53768.74
Iteration:   2960, Loss function: 4.117, Average Loss: 4.231, avg. samples / sec: 53882.30
Iteration:   2960, Loss function: 3.702, Average Loss: 4.213, avg. samples / sec: 53877.89
Iteration:   2960, Loss function: 4.231, Average Loss: 4.223, avg. samples / sec: 53944.63
Iteration:   2960, Loss function: 4.137, Average Loss: 4.219, avg. samples / sec: 53932.26
Iteration:   2960, Loss function: 4.969, Average Loss: 4.224, avg. samples / sec: 53916.93
Iteration:   2960, Loss function: 3.300, Average Loss: 4.221, avg. samples / sec: 53852.40
Iteration:   2960, Loss function: 4.461, Average Loss: 4.242, avg. samples / sec: 53806.98
Iteration:   2960, Loss function: 2.785, Average Loss: 4.202, avg. samples / sec: 53860.39
Iteration:   2960, Loss function: 3.354, Average Loss: 4.213, avg. samples / sec: 53685.01
Iteration:   2960, Loss function: 3.900, Average Loss: 4.224, avg. samples / sec: 53842.20
Iteration:   2960, Loss function: 2.977, Average Loss: 4.214, avg. samples / sec: 53952.29
Iteration:   2960, Loss function: 2.518, Average Loss: 4.226, avg. samples / sec: 53696.75
Iteration:   2960, Loss function: 4.707, Average Loss: 4.226, avg. samples / sec: 53870.06
Iteration:   2960, Loss function: 4.248, Average Loss: 4.194, avg. samples / sec: 53764.18
Iteration:   2960, Loss function: 5.405, Average Loss: 4.220, avg. samples / sec: 53920.89
Iteration:   2960, Loss function: 3.525, Average Loss: 4.205, avg. samples / sec: 53859.87
Iteration:   2960, Loss function: 3.286, Average Loss: 4.210, avg. samples / sec: 53871.71
Iteration:   2960, Loss function: 5.070, Average Loss: 4.196, avg. samples / sec: 53906.68
Iteration:   2960, Loss function: 4.354, Average Loss: 4.213, avg. samples / sec: 53740.83
Iteration:   2980, Loss function: 4.165, Average Loss: 4.209, avg. samples / sec: 53990.74
Iteration:   2980, Loss function: 3.638, Average Loss: 4.208, avg. samples / sec: 54190.37
Iteration:   2980, Loss function: 4.511, Average Loss: 4.227, avg. samples / sec: 53918.77
Iteration:   2980, Loss function: 5.369, Average Loss: 4.199, avg. samples / sec: 53927.56
Iteration:   2980, Loss function: 4.206, Average Loss: 4.209, avg. samples / sec: 53908.31
Iteration:   2980, Loss function: 3.551, Average Loss: 4.224, avg. samples / sec: 53924.34
Iteration:   2980, Loss function: 4.476, Average Loss: 4.238, avg. samples / sec: 53893.82
Iteration:   2980, Loss function: 3.627, Average Loss: 4.231, avg. samples / sec: 53907.55
Iteration:   2980, Loss function: 2.718, Average Loss: 4.260, avg. samples / sec: 53898.33
Iteration:   2980, Loss function: 4.222, Average Loss: 4.214, avg. samples / sec: 53894.33
Iteration:   2980, Loss function: 4.197, Average Loss: 4.226, avg. samples / sec: 53888.97
Iteration:   2980, Loss function: 4.036, Average Loss: 4.215, avg. samples / sec: 53944.44
Iteration:   2980, Loss function: 3.710, Average Loss: 4.210, avg. samples / sec: 53918.38
Iteration:   2980, Loss function: 3.715, Average Loss: 4.209, avg. samples / sec: 53913.42
Iteration:   2980, Loss function: 3.075, Average Loss: 4.223, avg. samples / sec: 53872.39
Iteration:   2980, Loss function: 4.360, Average Loss: 4.225, avg. samples / sec: 53851.74
Iteration:   2980, Loss function: 4.342, Average Loss: 4.215, avg. samples / sec: 53895.45
Iteration:   2980, Loss function: 4.212, Average Loss: 4.216, avg. samples / sec: 53869.04
Iteration:   2980, Loss function: 3.253, Average Loss: 4.190, avg. samples / sec: 53949.83
Iteration:   2980, Loss function: 2.958, Average Loss: 4.198, avg. samples / sec: 53910.21
Iteration:   2980, Loss function: 4.761, Average Loss: 4.219, avg. samples / sec: 53911.53
Iteration:   2980, Loss function: 3.576, Average Loss: 4.221, avg. samples / sec: 53918.83
Iteration:   2980, Loss function: 4.006, Average Loss: 4.205, avg. samples / sec: 53917.03
Iteration:   2980, Loss function: 4.260, Average Loss: 4.237, avg. samples / sec: 53861.17
Iteration:   2980, Loss function: 4.356, Average Loss: 4.206, avg. samples / sec: 53957.37
Iteration:   2980, Loss function: 2.946, Average Loss: 4.209, avg. samples / sec: 53917.18
Iteration:   2980, Loss function: 4.199, Average Loss: 4.217, avg. samples / sec: 53884.30
Iteration:   2980, Loss function: 3.641, Average Loss: 4.211, avg. samples / sec: 53854.19
Iteration:   2980, Loss function: 4.436, Average Loss: 4.222, avg. samples / sec: 53849.38
Iteration:   2980, Loss function: 3.795, Average Loss: 4.188, avg. samples / sec: 53856.81
Iteration:   3000, Loss function: 4.533, Average Loss: 4.206, avg. samples / sec: 53226.99
Iteration:   3000, Loss function: 3.874, Average Loss: 4.222, avg. samples / sec: 53333.08
Iteration:   3000, Loss function: 3.929, Average Loss: 4.258, avg. samples / sec: 53372.06
Iteration:   3000, Loss function: 2.955, Average Loss: 4.212, avg. samples / sec: 53373.74
Iteration:   3000, Loss function: 2.587, Average Loss: 4.206, avg. samples / sec: 53358.46
Iteration:   3000, Loss function: 5.169, Average Loss: 4.230, avg. samples / sec: 53347.76
Iteration:   3000, Loss function: 3.852, Average Loss: 4.215, avg. samples / sec: 53390.97
Iteration:   3000, Loss function: 3.529, Average Loss: 4.233, avg. samples / sec: 53326.87
Iteration:   3000, Loss function: 4.361, Average Loss: 4.221, avg. samples / sec: 53366.40
Iteration:   3000, Loss function: 3.695, Average Loss: 4.207, avg. samples / sec: 53295.75
Iteration:   3000, Loss function: 2.846, Average Loss: 4.200, avg. samples / sec: 53269.88
Iteration:   3000, Loss function: 3.924, Average Loss: 4.222, avg. samples / sec: 53293.01
Iteration:   3000, Loss function: 3.195, Average Loss: 4.209, avg. samples / sec: 53342.93
Iteration:   3000, Loss function: 4.303, Average Loss: 4.208, avg. samples / sec: 53365.29
Iteration:   3000, Loss function: 3.568, Average Loss: 4.200, avg. samples / sec: 53316.94
Iteration:   3000, Loss function: 3.611, Average Loss: 4.203, avg. samples / sec: 53345.03
Iteration:   3000, Loss function: 4.929, Average Loss: 4.196, avg. samples / sec: 53235.77
Iteration:   3000, Loss function: 3.776, Average Loss: 4.226, avg. samples / sec: 53273.97
Iteration:   3000, Loss function: 3.702, Average Loss: 4.190, avg. samples / sec: 53336.84
Iteration:   3000, Loss function: 3.895, Average Loss: 4.205, avg. samples / sec: 53401.47
Iteration:   3000, Loss function: 2.850, Average Loss: 4.212, avg. samples / sec: 53345.68
Iteration:   3000, Loss function: 4.010, Average Loss: 4.218, avg. samples / sec: 53339.34
Iteration:   3000, Loss function: 3.688, Average Loss: 4.229, avg. samples / sec: 53370.77
Iteration:   3000, Loss function: 3.860, Average Loss: 4.218, avg. samples / sec: 53373.90
Iteration:   3000, Loss function: 4.063, Average Loss: 4.216, avg. samples / sec: 53392.24
Iteration:   3000, Loss function: 3.011, Average Loss: 4.200, avg. samples / sec: 53350.49
Iteration:   3000, Loss function: 3.048, Average Loss: 4.205, avg. samples / sec: 53346.79
Iteration:   3000, Loss function: 3.633, Average Loss: 4.195, avg. samples / sec: 53268.31
Iteration:   3000, Loss function: 4.654, Average Loss: 4.189, avg. samples / sec: 53366.28
Iteration:   3000, Loss function: 4.236, Average Loss: 4.204, avg. samples / sec: 53284.99
:::MLL 1558640377.480 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558640377.481 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 3.800, Average Loss: 4.203, avg. samples / sec: 53581.95
Iteration:   3020, Loss function: 3.265, Average Loss: 4.208, avg. samples / sec: 53506.27
Iteration:   3020, Loss function: 5.316, Average Loss: 4.223, avg. samples / sec: 53542.11
Iteration:   3020, Loss function: 3.490, Average Loss: 4.220, avg. samples / sec: 53478.72
Iteration:   3020, Loss function: 4.670, Average Loss: 4.209, avg. samples / sec: 53503.20
Iteration:   3020, Loss function: 4.198, Average Loss: 4.200, avg. samples / sec: 53534.50
Iteration:   3020, Loss function: 2.651, Average Loss: 4.249, avg. samples / sec: 53477.20
Iteration:   3020, Loss function: 5.482, Average Loss: 4.194, avg. samples / sec: 53580.20
Iteration:   3020, Loss function: 4.751, Average Loss: 4.209, avg. samples / sec: 53480.97
Iteration:   3020, Loss function: 4.321, Average Loss: 4.225, avg. samples / sec: 53577.63
Iteration:   3020, Loss function: 4.418, Average Loss: 4.226, avg. samples / sec: 53479.06
Iteration:   3020, Loss function: 4.137, Average Loss: 4.216, avg. samples / sec: 53479.61
Iteration:   3020, Loss function: 3.923, Average Loss: 4.209, avg. samples / sec: 53484.83
Iteration:   3020, Loss function: 4.344, Average Loss: 4.195, avg. samples / sec: 53529.79
Iteration:   3020, Loss function: 4.164, Average Loss: 4.228, avg. samples / sec: 53459.49
Iteration:   3020, Loss function: 3.168, Average Loss: 4.202, avg. samples / sec: 53493.13
Iteration:   3020, Loss function: 4.345, Average Loss: 4.202, avg. samples / sec: 53457.72
Iteration:   3020, Loss function: 2.907, Average Loss: 4.215, avg. samples / sec: 53529.13
Iteration:   3020, Loss function: 3.084, Average Loss: 4.208, avg. samples / sec: 53521.45
Iteration:   3020, Loss function: 3.880, Average Loss: 4.200, avg. samples / sec: 53494.35
Iteration:   3020, Loss function: 4.075, Average Loss: 4.185, avg. samples / sec: 53486.96
Iteration:   3020, Loss function: 4.129, Average Loss: 4.217, avg. samples / sec: 53509.83
Iteration:   3020, Loss function: 4.434, Average Loss: 4.197, avg. samples / sec: 53517.32
Iteration:   3020, Loss function: 5.075, Average Loss: 4.205, avg. samples / sec: 53267.51
Iteration:   3020, Loss function: 4.649, Average Loss: 4.224, avg. samples / sec: 53473.67
Iteration:   3020, Loss function: 4.412, Average Loss: 4.212, avg. samples / sec: 53477.93
Iteration:   3020, Loss function: 3.451, Average Loss: 4.206, avg. samples / sec: 53536.72
Iteration:   3020, Loss function: 3.914, Average Loss: 4.193, avg. samples / sec: 53505.90
Iteration:   3020, Loss function: 4.045, Average Loss: 4.199, avg. samples / sec: 53485.66
Iteration:   3020, Loss function: 3.708, Average Loss: 4.187, avg. samples / sec: 53495.38
Iteration:   3040, Loss function: 4.067, Average Loss: 4.205, avg. samples / sec: 53934.06
Iteration:   3040, Loss function: 4.504, Average Loss: 4.212, avg. samples / sec: 53982.13
Iteration:   3040, Loss function: 3.481, Average Loss: 4.201, avg. samples / sec: 53994.02
Iteration:   3040, Loss function: 3.391, Average Loss: 4.189, avg. samples / sec: 53913.92
Iteration:   3040, Loss function: 3.386, Average Loss: 4.243, avg. samples / sec: 53904.60
Iteration:   3040, Loss function: 3.049, Average Loss: 4.216, avg. samples / sec: 53896.68
Iteration:   3040, Loss function: 3.457, Average Loss: 4.207, avg. samples / sec: 53894.62
Iteration:   3040, Loss function: 4.023, Average Loss: 4.207, avg. samples / sec: 53945.52
Iteration:   3040, Loss function: 5.093, Average Loss: 4.203, avg. samples / sec: 53893.47
Iteration:   3040, Loss function: 3.893, Average Loss: 4.205, avg. samples / sec: 53894.23
Iteration:   3040, Loss function: 3.802, Average Loss: 4.224, avg. samples / sec: 53900.91
Iteration:   3040, Loss function: 4.891, Average Loss: 4.225, avg. samples / sec: 53887.86
Iteration:   3040, Loss function: 3.478, Average Loss: 4.197, avg. samples / sec: 53897.40
Iteration:   3040, Loss function: 3.388, Average Loss: 4.202, avg. samples / sec: 53831.67
Iteration:   3040, Loss function: 3.810, Average Loss: 4.193, avg. samples / sec: 53916.42
Iteration:   3040, Loss function: 3.704, Average Loss: 4.210, avg. samples / sec: 53875.98
Iteration:   3040, Loss function: 5.065, Average Loss: 4.215, avg. samples / sec: 53921.06
Iteration:   3040, Loss function: 5.073, Average Loss: 4.213, avg. samples / sec: 53652.69
Iteration:   3040, Loss function: 2.684, Average Loss: 4.180, avg. samples / sec: 53905.67
Iteration:   3040, Loss function: 5.096, Average Loss: 4.204, avg. samples / sec: 53873.96
Iteration:   3040, Loss function: 3.875, Average Loss: 4.201, avg. samples / sec: 53933.91
Iteration:   3040, Loss function: 4.156, Average Loss: 4.195, avg. samples / sec: 53944.13
Iteration:   3040, Loss function: 3.416, Average Loss: 4.222, avg. samples / sec: 53921.10
Iteration:   3040, Loss function: 3.810, Average Loss: 4.186, avg. samples / sec: 53960.88
Iteration:   3040, Loss function: 3.939, Average Loss: 4.188, avg. samples / sec: 53920.60
Iteration:   3040, Loss function: 2.980, Average Loss: 4.210, avg. samples / sec: 53901.47
Iteration:   3040, Loss function: 3.528, Average Loss: 4.222, avg. samples / sec: 53662.78
Iteration:   3040, Loss function: 3.315, Average Loss: 4.203, avg. samples / sec: 53883.16
Iteration:   3040, Loss function: 3.784, Average Loss: 4.190, avg. samples / sec: 53833.27
Iteration:   3040, Loss function: 4.111, Average Loss: 4.199, avg. samples / sec: 53612.34
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558640378.687 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.49s)
DONE (t=2.22s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32341
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17217
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04796
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18951
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.27879
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28113
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07767
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30265
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.43529
Current AP: 0.17472 AP goal: 0.23000
:::MLL 1558640382.032 eval_accuracy: {"value": 0.17472038001208, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558640382.113 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558640382.119 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558640382.120 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 4.534, Average Loss: 4.199, avg. samples / sec: 8233.00
Iteration:   3060, Loss function: 3.665, Average Loss: 4.239, avg. samples / sec: 8234.87
Iteration:   3060, Loss function: 2.973, Average Loss: 4.197, avg. samples / sec: 8235.78
Iteration:   3060, Loss function: 3.739, Average Loss: 4.201, avg. samples / sec: 8234.26
Iteration:   3060, Loss function: 2.902, Average Loss: 4.213, avg. samples / sec: 8234.73
Iteration:   3060, Loss function: 4.127, Average Loss: 4.189, avg. samples / sec: 8242.63
Iteration:   3060, Loss function: 3.104, Average Loss: 4.197, avg. samples / sec: 8234.29
Iteration:   3060, Loss function: 5.666, Average Loss: 4.211, avg. samples / sec: 8239.67
Iteration:   3060, Loss function: 2.832, Average Loss: 4.195, avg. samples / sec: 8233.94
Iteration:   3060, Loss function: 2.853, Average Loss: 4.197, avg. samples / sec: 8232.98
Iteration:   3060, Loss function: 3.565, Average Loss: 4.210, avg. samples / sec: 8232.47
Iteration:   3060, Loss function: 4.875, Average Loss: 4.192, avg. samples / sec: 8234.40
Iteration:   3060, Loss function: 3.324, Average Loss: 4.208, avg. samples / sec: 8232.92
Iteration:   3060, Loss function: 5.171, Average Loss: 4.214, avg. samples / sec: 8239.77
Iteration:   3060, Loss function: 3.387, Average Loss: 4.197, avg. samples / sec: 8238.62
Iteration:   3060, Loss function: 4.200, Average Loss: 4.221, avg. samples / sec: 8230.97
Iteration:   3060, Loss function: 3.964, Average Loss: 4.212, avg. samples / sec: 8235.35
Iteration:   3060, Loss function: 4.351, Average Loss: 4.207, avg. samples / sec: 8234.28
Iteration:   3060, Loss function: 3.176, Average Loss: 4.191, avg. samples / sec: 8234.31
Iteration:   3060, Loss function: 4.522, Average Loss: 4.202, avg. samples / sec: 8233.96
Iteration:   3060, Loss function: 4.228, Average Loss: 4.173, avg. samples / sec: 8233.94
Iteration:   3060, Loss function: 3.609, Average Loss: 4.186, avg. samples / sec: 8233.58
Iteration:   3060, Loss function: 3.747, Average Loss: 4.187, avg. samples / sec: 8227.83
Iteration:   3060, Loss function: 3.580, Average Loss: 4.208, avg. samples / sec: 8233.69
Iteration:   3060, Loss function: 3.584, Average Loss: 4.199, avg. samples / sec: 8234.58
Iteration:   3060, Loss function: 4.216, Average Loss: 4.183, avg. samples / sec: 8234.07
Iteration:   3060, Loss function: 3.545, Average Loss: 4.196, avg. samples / sec: 8234.89
Iteration:   3060, Loss function: 4.066, Average Loss: 4.180, avg. samples / sec: 8234.79
Iteration:   3060, Loss function: 3.156, Average Loss: 4.197, avg. samples / sec: 8227.20
Iteration:   3060, Loss function: 3.104, Average Loss: 4.185, avg. samples / sec: 8233.60
:::MLL 1558640383.138 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558640383.138 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 3.629, Average Loss: 4.199, avg. samples / sec: 52629.59
Iteration:   3080, Loss function: 3.534, Average Loss: 4.194, avg. samples / sec: 52446.81
Iteration:   3080, Loss function: 3.779, Average Loss: 4.199, avg. samples / sec: 52570.83
Iteration:   3080, Loss function: 3.003, Average Loss: 4.177, avg. samples / sec: 52544.60
Iteration:   3080, Loss function: 4.246, Average Loss: 4.184, avg. samples / sec: 52526.92
Iteration:   3080, Loss function: 1.867, Average Loss: 4.204, avg. samples / sec: 52583.32
Iteration:   3080, Loss function: 3.847, Average Loss: 4.225, avg. samples / sec: 52494.73
Iteration:   3080, Loss function: 3.031, Average Loss: 4.206, avg. samples / sec: 52658.71
Iteration:   3080, Loss function: 5.345, Average Loss: 4.198, avg. samples / sec: 52510.34
Iteration:   3080, Loss function: 3.881, Average Loss: 4.193, avg. samples / sec: 52443.39
Iteration:   3080, Loss function: 3.998, Average Loss: 4.186, avg. samples / sec: 52416.24
Iteration:   3080, Loss function: 2.615, Average Loss: 4.182, avg. samples / sec: 52432.56
Iteration:   3080, Loss function: 3.091, Average Loss: 4.201, avg. samples / sec: 52373.13
Iteration:   3080, Loss function: 3.766, Average Loss: 4.193, avg. samples / sec: 52407.39
Iteration:   3080, Loss function: 4.883, Average Loss: 4.178, avg. samples / sec: 52636.05
Iteration:   3080, Loss function: 4.005, Average Loss: 4.184, avg. samples / sec: 52413.73
Iteration:   3080, Loss function: 3.095, Average Loss: 4.193, avg. samples / sec: 52568.26
Iteration:   3080, Loss function: 4.288, Average Loss: 4.180, avg. samples / sec: 52364.86
Iteration:   3080, Loss function: 4.729, Average Loss: 4.170, avg. samples / sec: 52592.72
Iteration:   3080, Loss function: 4.057, Average Loss: 4.186, avg. samples / sec: 52575.08
Iteration:   3080, Loss function: 2.877, Average Loss: 4.201, avg. samples / sec: 52491.64
Iteration:   3080, Loss function: 3.304, Average Loss: 4.199, avg. samples / sec: 52471.65
Iteration:   3080, Loss function: 3.208, Average Loss: 4.182, avg. samples / sec: 52441.17
Iteration:   3080, Loss function: 3.705, Average Loss: 4.186, avg. samples / sec: 52450.26
Iteration:   3080, Loss function: 4.053, Average Loss: 4.173, avg. samples / sec: 52478.49
Iteration:   3080, Loss function: 3.834, Average Loss: 4.200, avg. samples / sec: 52431.78
Iteration:   3080, Loss function: 3.238, Average Loss: 4.176, avg. samples / sec: 52428.66
Iteration:   3080, Loss function: 3.658, Average Loss: 4.180, avg. samples / sec: 52421.62
Iteration:   3080, Loss function: 3.917, Average Loss: 4.189, avg. samples / sec: 52422.68
Iteration:   3080, Loss function: 3.247, Average Loss: 4.160, avg. samples / sec: 52376.48
Iteration:   3100, Loss function: 3.465, Average Loss: 4.176, avg. samples / sec: 53002.08
Iteration:   3100, Loss function: 4.088, Average Loss: 4.176, avg. samples / sec: 52975.28
Iteration:   3100, Loss function: 3.136, Average Loss: 4.188, avg. samples / sec: 52923.90
Iteration:   3100, Loss function: 4.610, Average Loss: 4.167, avg. samples / sec: 52973.07
Iteration:   3100, Loss function: 4.995, Average Loss: 4.170, avg. samples / sec: 53101.74
Iteration:   3100, Loss function: 3.963, Average Loss: 4.182, avg. samples / sec: 53057.36
Iteration:   3100, Loss function: 3.050, Average Loss: 4.185, avg. samples / sec: 52932.88
Iteration:   3100, Loss function: 3.684, Average Loss: 4.194, avg. samples / sec: 53108.44
Iteration:   3100, Loss function: 3.170, Average Loss: 4.214, avg. samples / sec: 52946.94
Iteration:   3100, Loss function: 3.329, Average Loss: 4.188, avg. samples / sec: 52936.32
Iteration:   3100, Loss function: 2.622, Average Loss: 4.173, avg. samples / sec: 53117.33
Iteration:   3100, Loss function: 3.701, Average Loss: 4.189, avg. samples / sec: 53004.29
Iteration:   3100, Loss function: 3.348, Average Loss: 4.181, avg. samples / sec: 53083.84
Iteration:   3100, Loss function: 3.574, Average Loss: 4.193, avg. samples / sec: 52955.04
Iteration:   3100, Loss function: 2.865, Average Loss: 4.168, avg. samples / sec: 53111.88
Iteration:   3100, Loss function: 2.268, Average Loss: 4.170, avg. samples / sec: 52975.23
Iteration:   3100, Loss function: 3.440, Average Loss: 4.149, avg. samples / sec: 53150.82
Iteration:   3100, Loss function: 3.707, Average Loss: 4.158, avg. samples / sec: 52953.97
Iteration:   3100, Loss function: 2.316, Average Loss: 4.185, avg. samples / sec: 52960.81
Iteration:   3100, Loss function: 4.180, Average Loss: 4.168, avg. samples / sec: 53062.97
Iteration:   3100, Loss function: 2.532, Average Loss: 4.179, avg. samples / sec: 52950.01
Iteration:   3100, Loss function: 3.313, Average Loss: 4.189, avg. samples / sec: 52984.81
Iteration:   3100, Loss function: 3.576, Average Loss: 4.175, avg. samples / sec: 53067.98
Iteration:   3100, Loss function: 3.133, Average Loss: 4.166, avg. samples / sec: 53046.55
Iteration:   3100, Loss function: 4.246, Average Loss: 4.173, avg. samples / sec: 53027.69
Iteration:   3100, Loss function: 4.505, Average Loss: 4.170, avg. samples / sec: 53057.10
Iteration:   3100, Loss function: 2.720, Average Loss: 4.181, avg. samples / sec: 52895.27
Iteration:   3100, Loss function: 4.014, Average Loss: 4.181, avg. samples / sec: 53028.87
Iteration:   3100, Loss function: 3.666, Average Loss: 4.193, avg. samples / sec: 53035.89
Iteration:   3100, Loss function: 2.676, Average Loss: 4.168, avg. samples / sec: 52826.67
Iteration:   3120, Loss function: 3.353, Average Loss: 4.166, avg. samples / sec: 53236.18
Iteration:   3120, Loss function: 3.023, Average Loss: 4.156, avg. samples / sec: 53317.18
Iteration:   3120, Loss function: 3.450, Average Loss: 4.203, avg. samples / sec: 53211.57
Iteration:   3120, Loss function: 4.443, Average Loss: 4.154, avg. samples / sec: 53177.84
Iteration:   3120, Loss function: 3.702, Average Loss: 4.179, avg. samples / sec: 53208.76
Iteration:   3120, Loss function: 5.327, Average Loss: 4.180, avg. samples / sec: 53162.19
Iteration:   3120, Loss function: 4.465, Average Loss: 4.166, avg. samples / sec: 53176.64
Iteration:   3120, Loss function: 3.456, Average Loss: 4.162, avg. samples / sec: 53167.57
Iteration:   3120, Loss function: 4.301, Average Loss: 4.179, avg. samples / sec: 53192.47
Iteration:   3120, Loss function: 2.719, Average Loss: 4.174, avg. samples / sec: 53163.66
Iteration:   3120, Loss function: 4.753, Average Loss: 4.152, avg. samples / sec: 53233.20
Iteration:   3120, Loss function: 2.830, Average Loss: 4.179, avg. samples / sec: 53179.08
Iteration:   3120, Loss function: 4.932, Average Loss: 4.160, avg. samples / sec: 53175.73
Iteration:   3120, Loss function: 3.275, Average Loss: 4.170, avg. samples / sec: 53176.92
Iteration:   3120, Loss function: 3.844, Average Loss: 4.164, avg. samples / sec: 53022.84
Iteration:   3120, Loss function: 3.635, Average Loss: 4.134, avg. samples / sec: 53196.29
Iteration:   3120, Loss function: 3.359, Average Loss: 4.183, avg. samples / sec: 53013.43
Iteration:   3120, Loss function: 4.016, Average Loss: 4.178, avg. samples / sec: 53255.53
Iteration:   3120, Loss function: 3.174, Average Loss: 4.179, avg. samples / sec: 53228.68
Iteration:   3120, Loss function: 4.634, Average Loss: 4.173, avg. samples / sec: 53211.49
Iteration:   3120, Loss function: 4.012, Average Loss: 4.164, avg. samples / sec: 53213.52
Iteration:   3120, Loss function: 3.361, Average Loss: 4.154, avg. samples / sec: 53224.31
Iteration:   3120, Loss function: 3.284, Average Loss: 4.169, avg. samples / sec: 53222.40
Iteration:   3120, Loss function: 2.686, Average Loss: 4.161, avg. samples / sec: 53209.36
Iteration:   3120, Loss function: 4.544, Average Loss: 4.152, avg. samples / sec: 53207.88
Iteration:   3120, Loss function: 4.273, Average Loss: 4.170, avg. samples / sec: 53190.75
Iteration:   3120, Loss function: 3.547, Average Loss: 4.166, avg. samples / sec: 53204.84
Iteration:   3120, Loss function: 3.017, Average Loss: 4.161, avg. samples / sec: 53197.77
Iteration:   3120, Loss function: 3.255, Average Loss: 4.156, avg. samples / sec: 53217.68
Iteration:   3120, Loss function: 3.116, Average Loss: 4.143, avg. samples / sec: 53143.45
Iteration:   3140, Loss function: 4.461, Average Loss: 4.157, avg. samples / sec: 53163.32
Iteration:   3140, Loss function: 3.267, Average Loss: 4.155, avg. samples / sec: 53253.44
Iteration:   3140, Loss function: 3.694, Average Loss: 4.151, avg. samples / sec: 53149.44
Iteration:   3140, Loss function: 3.232, Average Loss: 4.146, avg. samples / sec: 53123.48
Iteration:   3140, Loss function: 4.086, Average Loss: 4.163, avg. samples / sec: 53129.18
Iteration:   3140, Loss function: 3.806, Average Loss: 4.149, avg. samples / sec: 53266.96
Iteration:   3140, Loss function: 4.037, Average Loss: 4.170, avg. samples / sec: 53103.28
Iteration:   3140, Loss function: 3.510, Average Loss: 4.153, avg. samples / sec: 53137.16
Iteration:   3140, Loss function: 3.066, Average Loss: 4.144, avg. samples / sec: 53072.58
Iteration:   3140, Loss function: 4.354, Average Loss: 4.150, avg. samples / sec: 53119.97
Iteration:   3140, Loss function: 4.594, Average Loss: 4.190, avg. samples / sec: 53069.86
Iteration:   3140, Loss function: 2.953, Average Loss: 4.163, avg. samples / sec: 53103.38
Iteration:   3140, Loss function: 3.690, Average Loss: 4.163, avg. samples / sec: 53097.50
Iteration:   3140, Loss function: 3.766, Average Loss: 4.139, avg. samples / sec: 53081.66
Iteration:   3140, Loss function: 4.046, Average Loss: 4.170, avg. samples / sec: 53069.58
Iteration:   3140, Loss function: 4.958, Average Loss: 4.126, avg. samples / sec: 53103.88
Iteration:   3140, Loss function: 3.651, Average Loss: 4.158, avg. samples / sec: 53119.55
Iteration:   3140, Loss function: 3.210, Average Loss: 4.157, avg. samples / sec: 53125.78
Iteration:   3140, Loss function: 1.987, Average Loss: 4.169, avg. samples / sec: 53106.76
Iteration:   3140, Loss function: 3.158, Average Loss: 4.154, avg. samples / sec: 53134.19
Iteration:   3140, Loss function: 3.578, Average Loss: 4.162, avg. samples / sec: 53098.78
Iteration:   3140, Loss function: 3.468, Average Loss: 4.139, avg. samples / sec: 53103.70
Iteration:   3140, Loss function: 3.698, Average Loss: 4.143, avg. samples / sec: 53133.53
Iteration:   3140, Loss function: 3.081, Average Loss: 4.153, avg. samples / sec: 53122.68
Iteration:   3140, Loss function: 2.564, Average Loss: 4.137, avg. samples / sec: 53113.91
Iteration:   3140, Loss function: 3.566, Average Loss: 4.150, avg. samples / sec: 53111.06
Iteration:   3140, Loss function: 2.156, Average Loss: 4.157, avg. samples / sec: 53097.34
Iteration:   3140, Loss function: 2.700, Average Loss: 4.148, avg. samples / sec: 53095.82
Iteration:   3140, Loss function: 3.168, Average Loss: 4.169, avg. samples / sec: 53033.54
Iteration:   3140, Loss function: 3.018, Average Loss: 4.131, avg. samples / sec: 53065.47
:::MLL 1558640385.355 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558640385.355 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 2.931, Average Loss: 4.140, avg. samples / sec: 52829.90
Iteration:   3160, Loss function: 4.397, Average Loss: 4.144, avg. samples / sec: 52762.77
Iteration:   3160, Loss function: 4.054, Average Loss: 4.142, avg. samples / sec: 52865.69
Iteration:   3160, Loss function: 4.319, Average Loss: 4.157, avg. samples / sec: 52950.80
Iteration:   3160, Loss function: 3.840, Average Loss: 4.142, avg. samples / sec: 52887.89
Iteration:   3160, Loss function: 2.952, Average Loss: 4.133, avg. samples / sec: 52846.26
Iteration:   3160, Loss function: 4.754, Average Loss: 4.153, avg. samples / sec: 52846.26
Iteration:   3160, Loss function: 2.628, Average Loss: 4.176, avg. samples / sec: 52892.08
Iteration:   3160, Loss function: 3.721, Average Loss: 4.149, avg. samples / sec: 52885.98
Iteration:   3160, Loss function: 3.114, Average Loss: 4.132, avg. samples / sec: 52829.32
Iteration:   3160, Loss function: 3.435, Average Loss: 4.149, avg. samples / sec: 52889.12
Iteration:   3160, Loss function: 3.519, Average Loss: 4.159, avg. samples / sec: 52840.87
Iteration:   3160, Loss function: 4.215, Average Loss: 4.126, avg. samples / sec: 52850.36
Iteration:   3160, Loss function: 3.227, Average Loss: 4.137, avg. samples / sec: 52848.38
Iteration:   3160, Loss function: 2.661, Average Loss: 4.118, avg. samples / sec: 52874.93
Iteration:   3160, Loss function: 3.386, Average Loss: 4.156, avg. samples / sec: 53094.64
Iteration:   3160, Loss function: 3.505, Average Loss: 4.151, avg. samples / sec: 52874.75
Iteration:   3160, Loss function: 3.159, Average Loss: 4.150, avg. samples / sec: 52886.12
Iteration:   3160, Loss function: 3.158, Average Loss: 4.142, avg. samples / sec: 52864.90
Iteration:   3160, Loss function: 3.286, Average Loss: 4.116, avg. samples / sec: 52854.84
Iteration:   3160, Loss function: 3.535, Average Loss: 4.153, avg. samples / sec: 52864.24
Iteration:   3160, Loss function: 2.902, Average Loss: 4.126, avg. samples / sec: 52876.04
Iteration:   3160, Loss function: 4.360, Average Loss: 4.142, avg. samples / sec: 52888.23
Iteration:   3160, Loss function: 3.419, Average Loss: 4.139, avg. samples / sec: 52864.90
Iteration:   3160, Loss function: 4.002, Average Loss: 4.132, avg. samples / sec: 52865.83
Iteration:   3160, Loss function: 3.221, Average Loss: 4.137, avg. samples / sec: 52843.35
Iteration:   3160, Loss function: 3.495, Average Loss: 4.118, avg. samples / sec: 52935.59
Iteration:   3160, Loss function: 4.090, Average Loss: 4.140, avg. samples / sec: 52867.20
Iteration:   3160, Loss function: 4.296, Average Loss: 4.132, avg. samples / sec: 52849.73
Iteration:   3160, Loss function: 3.650, Average Loss: 4.144, avg. samples / sec: 52846.58
Iteration:   3180, Loss function: 4.794, Average Loss: 4.128, avg. samples / sec: 53347.84
Iteration:   3180, Loss function: 3.243, Average Loss: 4.161, avg. samples / sec: 53380.76
Iteration:   3180, Loss function: 3.985, Average Loss: 4.122, avg. samples / sec: 53390.99
Iteration:   3180, Loss function: 3.349, Average Loss: 4.137, avg. samples / sec: 53366.12
Iteration:   3180, Loss function: 4.207, Average Loss: 4.148, avg. samples / sec: 53360.85
Iteration:   3180, Loss function: 4.609, Average Loss: 4.131, avg. samples / sec: 53280.29
Iteration:   3180, Loss function: 3.690, Average Loss: 4.104, avg. samples / sec: 53362.97
Iteration:   3180, Loss function: 3.660, Average Loss: 4.114, avg. samples / sec: 53339.48
Iteration:   3180, Loss function: 3.749, Average Loss: 4.122, avg. samples / sec: 53295.77
Iteration:   3180, Loss function: 4.586, Average Loss: 4.129, avg. samples / sec: 53288.35
Iteration:   3180, Loss function: 4.125, Average Loss: 4.146, avg. samples / sec: 53265.69
Iteration:   3180, Loss function: 3.583, Average Loss: 4.143, avg. samples / sec: 53291.46
Iteration:   3180, Loss function: 3.407, Average Loss: 4.121, avg. samples / sec: 53316.37
Iteration:   3180, Loss function: 3.454, Average Loss: 4.128, avg. samples / sec: 53104.12
Iteration:   3180, Loss function: 3.231, Average Loss: 4.106, avg. samples / sec: 53350.61
Iteration:   3180, Loss function: 4.703, Average Loss: 4.127, avg. samples / sec: 53342.41
Iteration:   3180, Loss function: 2.302, Average Loss: 4.134, avg. samples / sec: 53343.11
Iteration:   3180, Loss function: 3.211, Average Loss: 4.138, avg. samples / sec: 53330.22
Iteration:   3180, Loss function: 4.387, Average Loss: 4.118, avg. samples / sec: 53349.29
Iteration:   3180, Loss function: 3.401, Average Loss: 4.147, avg. samples / sec: 53166.38
Iteration:   3180, Loss function: 3.913, Average Loss: 4.137, avg. samples / sec: 53338.94
Iteration:   3180, Loss function: 3.897, Average Loss: 4.128, avg. samples / sec: 53364.04
Iteration:   3180, Loss function: 4.016, Average Loss: 4.141, avg. samples / sec: 53100.90
Iteration:   3180, Loss function: 4.089, Average Loss: 4.131, avg. samples / sec: 53385.87
Iteration:   3180, Loss function: 3.818, Average Loss: 4.126, avg. samples / sec: 53345.17
Iteration:   3180, Loss function: 4.433, Average Loss: 4.119, avg. samples / sec: 53354.87
Iteration:   3180, Loss function: 3.595, Average Loss: 4.130, avg. samples / sec: 53339.78
Iteration:   3180, Loss function: 2.928, Average Loss: 4.107, avg. samples / sec: 53325.92
Iteration:   3180, Loss function: 3.678, Average Loss: 4.119, avg. samples / sec: 53317.16
Iteration:   3180, Loss function: 4.638, Average Loss: 4.134, avg. samples / sec: 53286.42
Iteration:   3200, Loss function: 2.587, Average Loss: 4.114, avg. samples / sec: 53547.32
Iteration:   3200, Loss function: 4.194, Average Loss: 4.153, avg. samples / sec: 53248.83
Iteration:   3200, Loss function: 2.512, Average Loss: 4.107, avg. samples / sec: 53325.13
Iteration:   3200, Loss function: 4.163, Average Loss: 4.117, avg. samples / sec: 53214.71
Iteration:   3200, Loss function: 4.865, Average Loss: 4.131, avg. samples / sec: 53512.20
Iteration:   3200, Loss function: 2.615, Average Loss: 4.131, avg. samples / sec: 53304.54
Iteration:   3200, Loss function: 2.308, Average Loss: 4.109, avg. samples / sec: 53198.80
Iteration:   3200, Loss function: 3.694, Average Loss: 4.125, avg. samples / sec: 53224.92
Iteration:   3200, Loss function: 4.437, Average Loss: 4.105, avg. samples / sec: 53253.70
Iteration:   3200, Loss function: 3.475, Average Loss: 4.111, avg. samples / sec: 53277.47
Iteration:   3200, Loss function: 3.296, Average Loss: 4.093, avg. samples / sec: 53233.58
Iteration:   3200, Loss function: 3.780, Average Loss: 4.130, avg. samples / sec: 53248.99
Iteration:   3200, Loss function: 3.512, Average Loss: 4.117, avg. samples / sec: 53246.27
Iteration:   3200, Loss function: 3.761, Average Loss: 4.121, avg. samples / sec: 53210.21
Iteration:   3200, Loss function: 3.804, Average Loss: 4.140, avg. samples / sec: 53165.68
Iteration:   3200, Loss function: 2.259, Average Loss: 4.099, avg. samples / sec: 53281.95
Iteration:   3200, Loss function: 4.462, Average Loss: 4.126, avg. samples / sec: 53276.06
Iteration:   3200, Loss function: 2.539, Average Loss: 4.130, avg. samples / sec: 53270.95
Iteration:   3200, Loss function: 3.656, Average Loss: 4.094, avg. samples / sec: 53311.27
Iteration:   3200, Loss function: 4.305, Average Loss: 4.112, avg. samples / sec: 53244.24
Iteration:   3200, Loss function: 3.829, Average Loss: 4.123, avg. samples / sec: 53245.33
Iteration:   3200, Loss function: 2.650, Average Loss: 4.123, avg. samples / sec: 53317.69
Iteration:   3200, Loss function: 3.994, Average Loss: 4.121, avg. samples / sec: 53238.55
Iteration:   3200, Loss function: 3.361, Average Loss: 4.118, avg. samples / sec: 53246.31
Iteration:   3200, Loss function: 4.080, Average Loss: 4.102, avg. samples / sec: 53252.93
Iteration:   3200, Loss function: 4.075, Average Loss: 4.108, avg. samples / sec: 53216.29
Iteration:   3200, Loss function: 2.691, Average Loss: 4.117, avg. samples / sec: 53222.10
Iteration:   3200, Loss function: 3.757, Average Loss: 4.108, avg. samples / sec: 53249.27
Iteration:   3200, Loss function: 3.126, Average Loss: 4.119, avg. samples / sec: 53228.33
Iteration:   3200, Loss function: 4.058, Average Loss: 4.114, avg. samples / sec: 53198.36
:::MLL 1558640387.567 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558640387.568 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 4.649, Average Loss: 4.105, avg. samples / sec: 52862.18
Iteration:   3220, Loss function: 2.614, Average Loss: 4.115, avg. samples / sec: 53059.93
Iteration:   3220, Loss function: 2.915, Average Loss: 4.095, avg. samples / sec: 53070.78
Iteration:   3220, Loss function: 3.271, Average Loss: 4.117, avg. samples / sec: 53054.22
Iteration:   3220, Loss function: 3.060, Average Loss: 4.144, avg. samples / sec: 52988.41
Iteration:   3220, Loss function: 4.305, Average Loss: 4.095, avg. samples / sec: 52998.67
Iteration:   3220, Loss function: 4.053, Average Loss: 4.106, avg. samples / sec: 52943.58
Iteration:   3220, Loss function: 3.899, Average Loss: 4.120, avg. samples / sec: 52919.96
Iteration:   3220, Loss function: 3.700, Average Loss: 4.117, avg. samples / sec: 52974.89
Iteration:   3220, Loss function: 3.808, Average Loss: 4.110, avg. samples / sec: 52944.26
Iteration:   3220, Loss function: 3.173, Average Loss: 4.095, avg. samples / sec: 52903.51
Iteration:   3220, Loss function: 3.762, Average Loss: 4.104, avg. samples / sec: 52924.22
Iteration:   3220, Loss function: 3.150, Average Loss: 4.079, avg. samples / sec: 52899.36
Iteration:   3220, Loss function: 2.774, Average Loss: 4.103, avg. samples / sec: 52893.35
Iteration:   3220, Loss function: 3.353, Average Loss: 4.130, avg. samples / sec: 52941.35
Iteration:   3220, Loss function: 3.959, Average Loss: 4.101, avg. samples / sec: 52995.96
Iteration:   3220, Loss function: 2.836, Average Loss: 4.107, avg. samples / sec: 52993.55
Iteration:   3220, Loss function: 2.794, Average Loss: 4.081, avg. samples / sec: 52969.73
Iteration:   3220, Loss function: 3.627, Average Loss: 4.109, avg. samples / sec: 52933.80
Iteration:   3220, Loss function: 3.899, Average Loss: 4.085, avg. samples / sec: 52907.11
Iteration:   3220, Loss function: 3.432, Average Loss: 4.098, avg. samples / sec: 52999.07
Iteration:   3220, Loss function: 3.043, Average Loss: 4.120, avg. samples / sec: 52881.14
Iteration:   3220, Loss function: 3.681, Average Loss: 4.112, avg. samples / sec: 52888.41
Iteration:   3220, Loss function: 3.121, Average Loss: 4.107, avg. samples / sec: 52888.05
Iteration:   3220, Loss function: 3.492, Average Loss: 4.106, avg. samples / sec: 52941.67
Iteration:   3220, Loss function: 3.758, Average Loss: 4.110, avg. samples / sec: 52918.65
Iteration:   3220, Loss function: 3.261, Average Loss: 4.102, avg. samples / sec: 52940.50
Iteration:   3220, Loss function: 4.401, Average Loss: 4.097, avg. samples / sec: 52904.65
Iteration:   3220, Loss function: 4.217, Average Loss: 4.097, avg. samples / sec: 52865.89
Iteration:   3220, Loss function: 3.238, Average Loss: 4.108, avg. samples / sec: 52804.88
Iteration:   3240, Loss function: 2.415, Average Loss: 4.088, avg. samples / sec: 53115.49
Iteration:   3240, Loss function: 3.361, Average Loss: 4.129, avg. samples / sec: 53042.10
Iteration:   3240, Loss function: 3.099, Average Loss: 4.101, avg. samples / sec: 53164.66
Iteration:   3240, Loss function: 2.457, Average Loss: 4.103, avg. samples / sec: 52985.08
Iteration:   3240, Loss function: 3.650, Average Loss: 4.093, avg. samples / sec: 53091.48
Iteration:   3240, Loss function: 4.011, Average Loss: 4.087, avg. samples / sec: 52992.16
Iteration:   3240, Loss function: 2.854, Average Loss: 4.103, avg. samples / sec: 53084.76
Iteration:   3240, Loss function: 3.319, Average Loss: 4.107, avg. samples / sec: 53082.24
Iteration:   3240, Loss function: 3.944, Average Loss: 4.082, avg. samples / sec: 52958.07
Iteration:   3240, Loss function: 4.220, Average Loss: 4.096, avg. samples / sec: 53140.88
Iteration:   3240, Loss function: 3.897, Average Loss: 4.102, avg. samples / sec: 52967.92
Iteration:   3240, Loss function: 3.124, Average Loss: 4.120, avg. samples / sec: 53151.21
Iteration:   3240, Loss function: 3.386, Average Loss: 4.085, avg. samples / sec: 53122.07
Iteration:   3240, Loss function: 3.336, Average Loss: 4.070, avg. samples / sec: 53128.26
Iteration:   3240, Loss function: 3.607, Average Loss: 4.092, avg. samples / sec: 53122.64
Iteration:   3240, Loss function: 2.555, Average Loss: 4.093, avg. samples / sec: 53196.11
Iteration:   3240, Loss function: 3.716, Average Loss: 4.091, avg. samples / sec: 53077.38
Iteration:   3240, Loss function: 2.943, Average Loss: 4.074, avg. samples / sec: 53103.52
Iteration:   3240, Loss function: 2.574, Average Loss: 4.087, avg. samples / sec: 53101.42
Iteration:   3240, Loss function: 3.122, Average Loss: 4.107, avg. samples / sec: 53143.09
Iteration:   3240, Loss function: 3.253, Average Loss: 4.090, avg. samples / sec: 53145.19
Iteration:   3240, Loss function: 5.179, Average Loss: 4.086, avg. samples / sec: 53148.26
Iteration:   3240, Loss function: 3.265, Average Loss: 4.098, avg. samples / sec: 53129.14
Iteration:   3240, Loss function: 4.186, Average Loss: 4.069, avg. samples / sec: 53040.06
Iteration:   3240, Loss function: 2.398, Average Loss: 4.099, avg. samples / sec: 53058.27
Iteration:   3240, Loss function: 2.834, Average Loss: 4.094, avg. samples / sec: 53026.59
Iteration:   3240, Loss function: 3.189, Average Loss: 4.095, avg. samples / sec: 53102.94
Iteration:   3240, Loss function: 3.550, Average Loss: 4.082, avg. samples / sec: 53145.49
Iteration:   3240, Loss function: 3.307, Average Loss: 4.101, avg. samples / sec: 53099.68
Iteration:   3240, Loss function: 4.294, Average Loss: 4.094, avg. samples / sec: 53168.61
Iteration:   3260, Loss function: 2.770, Average Loss: 4.079, avg. samples / sec: 53346.71
Iteration:   3260, Loss function: 3.740, Average Loss: 4.093, avg. samples / sec: 53317.02
Iteration:   3260, Loss function: 3.332, Average Loss: 4.064, avg. samples / sec: 53341.50
Iteration:   3260, Loss function: 3.298, Average Loss: 4.097, avg. samples / sec: 53329.13
Iteration:   3260, Loss function: 3.582, Average Loss: 4.081, avg. samples / sec: 53296.76
Iteration:   3260, Loss function: 3.712, Average Loss: 4.106, avg. samples / sec: 53334.74
Iteration:   3260, Loss function: 3.591, Average Loss: 4.119, avg. samples / sec: 53262.75
Iteration:   3260, Loss function: 3.842, Average Loss: 4.086, avg. samples / sec: 53275.00
Iteration:   3260, Loss function: 2.978, Average Loss: 4.092, avg. samples / sec: 53315.37
Iteration:   3260, Loss function: 3.156, Average Loss: 4.076, avg. samples / sec: 53297.78
Iteration:   3260, Loss function: 2.909, Average Loss: 4.095, avg. samples / sec: 53290.13
Iteration:   3260, Loss function: 4.193, Average Loss: 4.085, avg. samples / sec: 53296.19
Iteration:   3260, Loss function: 3.736, Average Loss: 4.077, avg. samples / sec: 53296.29
Iteration:   3260, Loss function: 2.723, Average Loss: 4.076, avg. samples / sec: 53312.64
Iteration:   3260, Loss function: 4.116, Average Loss: 4.057, avg. samples / sec: 53290.23
Iteration:   3260, Loss function: 4.031, Average Loss: 4.085, avg. samples / sec: 53289.98
Iteration:   3260, Loss function: 3.568, Average Loss: 4.064, avg. samples / sec: 53313.49
Iteration:   3260, Loss function: 3.735, Average Loss: 4.081, avg. samples / sec: 53268.09
Iteration:   3260, Loss function: 2.500, Average Loss: 4.079, avg. samples / sec: 53319.02
Iteration:   3260, Loss function: 3.443, Average Loss: 4.093, avg. samples / sec: 53284.99
Iteration:   3260, Loss function: 3.881, Average Loss: 4.072, avg. samples / sec: 53307.12
Iteration:   3260, Loss function: 3.348, Average Loss: 4.053, avg. samples / sec: 53299.13
Iteration:   3260, Loss function: 3.253, Average Loss: 4.089, avg. samples / sec: 53339.38
Iteration:   3260, Loss function: 3.706, Average Loss: 4.088, avg. samples / sec: 53339.30
Iteration:   3260, Loss function: 2.867, Average Loss: 4.072, avg. samples / sec: 53323.48
Iteration:   3260, Loss function: 2.916, Average Loss: 4.085, avg. samples / sec: 53290.73
Iteration:   3260, Loss function: 4.924, Average Loss: 4.080, avg. samples / sec: 53283.68
Iteration:   3260, Loss function: 4.473, Average Loss: 4.089, avg. samples / sec: 53317.48
Iteration:   3260, Loss function: 3.554, Average Loss: 4.082, avg. samples / sec: 53291.15
Iteration:   3260, Loss function: 3.963, Average Loss: 4.076, avg. samples / sec: 53220.15
Iteration:   3280, Loss function: 3.088, Average Loss: 4.071, avg. samples / sec: 53500.50
Iteration:   3280, Loss function: 3.564, Average Loss: 4.062, avg. samples / sec: 53582.23
Iteration:   3280, Loss function: 3.718, Average Loss: 4.084, avg. samples / sec: 53554.52
Iteration:   3280, Loss function: 4.060, Average Loss: 4.074, avg. samples / sec: 53555.76
Iteration:   3280, Loss function: 4.341, Average Loss: 4.073, avg. samples / sec: 53564.23
Iteration:   3280, Loss function: 3.888, Average Loss: 4.081, avg. samples / sec: 53509.40
Iteration:   3280, Loss function: 3.526, Average Loss: 4.054, avg. samples / sec: 53509.09
Iteration:   3280, Loss function: 4.205, Average Loss: 4.085, avg. samples / sec: 53552.28
Iteration:   3280, Loss function: 2.217, Average Loss: 4.094, avg. samples / sec: 53514.84
Iteration:   3280, Loss function: 2.717, Average Loss: 4.042, avg. samples / sec: 53551.92
Iteration:   3280, Loss function: 2.957, Average Loss: 4.073, avg. samples / sec: 53532.49
Iteration:   3280, Loss function: 3.979, Average Loss: 4.115, avg. samples / sec: 53488.05
Iteration:   3280, Loss function: 3.662, Average Loss: 4.063, avg. samples / sec: 53528.93
Iteration:   3280, Loss function: 3.214, Average Loss: 4.071, avg. samples / sec: 53503.73
Iteration:   3280, Loss function: 3.810, Average Loss: 4.076, avg. samples / sec: 53491.18
Iteration:   3280, Loss function: 4.655, Average Loss: 4.075, avg. samples / sec: 53535.46
Iteration:   3280, Loss function: 3.352, Average Loss: 4.068, avg. samples / sec: 53519.50
Iteration:   3280, Loss function: 2.753, Average Loss: 4.069, avg. samples / sec: 53528.22
Iteration:   3280, Loss function: 3.245, Average Loss: 4.075, avg. samples / sec: 53556.35
Iteration:   3280, Loss function: 5.391, Average Loss: 4.061, avg. samples / sec: 53529.68
Iteration:   3280, Loss function: 3.020, Average Loss: 4.068, avg. samples / sec: 53549.01
Iteration:   3280, Loss function: 3.464, Average Loss: 4.044, avg. samples / sec: 53524.26
Iteration:   3280, Loss function: 2.894, Average Loss: 4.048, avg. samples / sec: 53475.00
Iteration:   3280, Loss function: 2.881, Average Loss: 4.077, avg. samples / sec: 53503.73
Iteration:   3280, Loss function: 3.046, Average Loss: 4.060, avg. samples / sec: 53517.53
Iteration:   3280, Loss function: 4.654, Average Loss: 4.070, avg. samples / sec: 53516.59
Iteration:   3280, Loss function: 4.392, Average Loss: 4.077, avg. samples / sec: 53492.89
Iteration:   3280, Loss function: 4.491, Average Loss: 4.077, avg. samples / sec: 53486.80
Iteration:   3280, Loss function: 2.908, Average Loss: 4.077, avg. samples / sec: 53464.07
Iteration:   3280, Loss function: 2.732, Average Loss: 4.060, avg. samples / sec: 53510.54
:::MLL 1558640389.778 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558640389.779 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 4.081, Average Loss: 4.059, avg. samples / sec: 52709.33
Iteration:   3300, Loss function: 3.176, Average Loss: 4.066, avg. samples / sec: 52790.38
Iteration:   3300, Loss function: 3.566, Average Loss: 4.047, avg. samples / sec: 52759.82
Iteration:   3300, Loss function: 2.693, Average Loss: 4.073, avg. samples / sec: 52740.08
Iteration:   3300, Loss function: 4.021, Average Loss: 4.058, avg. samples / sec: 52708.03
Iteration:   3300, Loss function: 2.964, Average Loss: 4.100, avg. samples / sec: 52765.73
Iteration:   3300, Loss function: 3.274, Average Loss: 4.050, avg. samples / sec: 52687.18
Iteration:   3300, Loss function: 2.683, Average Loss: 4.061, avg. samples / sec: 52747.60
Iteration:   3300, Loss function: 4.401, Average Loss: 4.071, avg. samples / sec: 52656.74
Iteration:   3300, Loss function: 4.786, Average Loss: 4.090, avg. samples / sec: 52701.70
Iteration:   3300, Loss function: 3.003, Average Loss: 4.053, avg. samples / sec: 52702.71
Iteration:   3300, Loss function: 2.579, Average Loss: 4.068, avg. samples / sec: 52712.25
Iteration:   3300, Loss function: 3.457, Average Loss: 4.074, avg. samples / sec: 52660.74
Iteration:   3300, Loss function: 4.074, Average Loss: 4.058, avg. samples / sec: 52679.16
Iteration:   3300, Loss function: 3.440, Average Loss: 4.026, avg. samples / sec: 52639.83
Iteration:   3300, Loss function: 2.769, Average Loss: 4.035, avg. samples / sec: 52753.33
Iteration:   3300, Loss function: 3.985, Average Loss: 4.054, avg. samples / sec: 52732.98
Iteration:   3300, Loss function: 3.862, Average Loss: 4.057, avg. samples / sec: 52708.58
Iteration:   3300, Loss function: 2.718, Average Loss: 4.053, avg. samples / sec: 52705.31
Iteration:   3300, Loss function: 3.950, Average Loss: 4.050, avg. samples / sec: 52740.20
Iteration:   3300, Loss function: 3.714, Average Loss: 4.071, avg. samples / sec: 52728.97
Iteration:   3300, Loss function: 2.595, Average Loss: 4.058, avg. samples / sec: 52770.51
Iteration:   3300, Loss function: 3.661, Average Loss: 4.069, avg. samples / sec: 52757.89
Iteration:   3300, Loss function: 2.465, Average Loss: 4.050, avg. samples / sec: 52696.81
Iteration:   3300, Loss function: 3.518, Average Loss: 4.052, avg. samples / sec: 52765.79
Iteration:   3300, Loss function: 3.784, Average Loss: 4.065, avg. samples / sec: 52722.60
Iteration:   3300, Loss function: 2.974, Average Loss: 4.062, avg. samples / sec: 52636.17
Iteration:   3300, Loss function: 2.508, Average Loss: 4.066, avg. samples / sec: 52733.88
Iteration:   3300, Loss function: 3.108, Average Loss: 4.031, avg. samples / sec: 52683.26
Iteration:   3300, Loss function: 3.566, Average Loss: 4.063, avg. samples / sec: 52658.02
Iteration:   3320, Loss function: 2.836, Average Loss: 4.054, avg. samples / sec: 53316.11
Iteration:   3320, Loss function: 4.783, Average Loss: 4.050, avg. samples / sec: 53170.28
Iteration:   3320, Loss function: 3.909, Average Loss: 4.089, avg. samples / sec: 53323.62
Iteration:   3320, Loss function: 3.172, Average Loss: 4.032, avg. samples / sec: 53234.79
Iteration:   3320, Loss function: 4.530, Average Loss: 4.062, avg. samples / sec: 53244.38
Iteration:   3320, Loss function: 4.173, Average Loss: 4.068, avg. samples / sec: 53329.07
Iteration:   3320, Loss function: 4.060, Average Loss: 4.060, avg. samples / sec: 53279.45
Iteration:   3320, Loss function: 2.251, Average Loss: 4.055, avg. samples / sec: 53317.10
Iteration:   3320, Loss function: 3.216, Average Loss: 4.045, avg. samples / sec: 53215.51
Iteration:   3320, Loss function: 3.398, Average Loss: 4.013, avg. samples / sec: 53353.25
Iteration:   3320, Loss function: 3.275, Average Loss: 4.077, avg. samples / sec: 53252.93
Iteration:   3320, Loss function: 3.181, Average Loss: 4.041, avg. samples / sec: 53221.44
Iteration:   3320, Loss function: 3.793, Average Loss: 4.045, avg. samples / sec: 53286.40
Iteration:   3320, Loss function: 3.451, Average Loss: 4.045, avg. samples / sec: 53229.92
Iteration:   3320, Loss function: 2.496, Average Loss: 4.032, avg. samples / sec: 53369.21
Iteration:   3320, Loss function: 2.515, Average Loss: 4.024, avg. samples / sec: 53303.75
Iteration:   3320, Loss function: 4.435, Average Loss: 4.041, avg. samples / sec: 53302.06
Iteration:   3320, Loss function: 4.126, Average Loss: 4.066, avg. samples / sec: 53088.42
Iteration:   3320, Loss function: 3.966, Average Loss: 4.042, avg. samples / sec: 53301.90
Iteration:   3320, Loss function: 2.210, Average Loss: 4.051, avg. samples / sec: 53353.25
Iteration:   3320, Loss function: 3.022, Average Loss: 4.045, avg. samples / sec: 53311.37
Iteration:   3320, Loss function: 4.069, Average Loss: 4.037, avg. samples / sec: 53305.18
Iteration:   3320, Loss function: 3.019, Average Loss: 4.050, avg. samples / sec: 53323.70
Iteration:   3320, Loss function: 4.431, Average Loss: 4.022, avg. samples / sec: 53329.63
Iteration:   3320, Loss function: 2.879, Average Loss: 4.053, avg. samples / sec: 53307.40
Iteration:   3320, Loss function: 4.177, Average Loss: 4.057, avg. samples / sec: 53304.36
Iteration:   3320, Loss function: 4.042, Average Loss: 4.048, avg. samples / sec: 53262.53
Iteration:   3320, Loss function: 2.893, Average Loss: 4.061, avg. samples / sec: 53277.68
Iteration:   3320, Loss function: 3.900, Average Loss: 4.059, avg. samples / sec: 53262.75
Iteration:   3320, Loss function: 2.441, Average Loss: 4.042, avg. samples / sec: 53264.65
Iteration:   3340, Loss function: 3.898, Average Loss: 4.045, avg. samples / sec: 53531.76
Iteration:   3340, Loss function: 3.800, Average Loss: 4.039, avg. samples / sec: 53563.13
Iteration:   3340, Loss function: 2.285, Average Loss: 4.020, avg. samples / sec: 53516.08
Iteration:   3340, Loss function: 3.546, Average Loss: 4.049, avg. samples / sec: 53493.03
Iteration:   3340, Loss function: 3.951, Average Loss: 4.030, avg. samples / sec: 53540.10
Iteration:   3340, Loss function: 1.946, Average Loss: 4.043, avg. samples / sec: 53509.32
Iteration:   3340, Loss function: 4.064, Average Loss: 4.034, avg. samples / sec: 53518.44
Iteration:   3340, Loss function: 3.918, Average Loss: 4.078, avg. samples / sec: 53419.18
Iteration:   3340, Loss function: 3.108, Average Loss: 4.035, avg. samples / sec: 53545.43
Iteration:   3340, Loss function: 3.287, Average Loss: 4.030, avg. samples / sec: 53506.78
Iteration:   3340, Loss function: 2.426, Average Loss: 4.055, avg. samples / sec: 53454.88
Iteration:   3340, Loss function: 2.957, Average Loss: 4.001, avg. samples / sec: 53474.50
Iteration:   3340, Loss function: 2.419, Average Loss: 4.056, avg. samples / sec: 53653.84
Iteration:   3340, Loss function: 4.123, Average Loss: 4.057, avg. samples / sec: 53430.04
Iteration:   3340, Loss function: 3.610, Average Loss: 4.013, avg. samples / sec: 53457.66
Iteration:   3340, Loss function: 3.590, Average Loss: 4.037, avg. samples / sec: 53482.35
Iteration:   3340, Loss function: 2.944, Average Loss: 4.034, avg. samples / sec: 53511.88
Iteration:   3340, Loss function: 4.085, Average Loss: 4.037, avg. samples / sec: 53482.43
Iteration:   3340, Loss function: 3.834, Average Loss: 4.043, avg. samples / sec: 53482.29
Iteration:   3340, Loss function: 4.121, Average Loss: 4.010, avg. samples / sec: 53478.41
Iteration:   3340, Loss function: 3.154, Average Loss: 4.027, avg. samples / sec: 53463.54
Iteration:   3340, Loss function: 3.891, Average Loss: 4.028, avg. samples / sec: 53457.46
Iteration:   3340, Loss function: 3.815, Average Loss: 4.021, avg. samples / sec: 53399.43
Iteration:   3340, Loss function: 3.454, Average Loss: 4.030, avg. samples / sec: 53504.91
Iteration:   3340, Loss function: 3.922, Average Loss: 4.025, avg. samples / sec: 53448.27
Iteration:   3340, Loss function: 3.058, Average Loss: 4.027, avg. samples / sec: 53423.74
Iteration:   3340, Loss function: 3.044, Average Loss: 4.063, avg. samples / sec: 53256.84
Iteration:   3340, Loss function: 3.985, Average Loss: 4.049, avg. samples / sec: 53464.25
Iteration:   3340, Loss function: 3.398, Average Loss: 4.043, avg. samples / sec: 53445.64
Iteration:   3340, Loss function: 3.600, Average Loss: 4.045, avg. samples / sec: 53450.85
:::MLL 1558640391.988 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558640391.989 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 4.645, Average Loss: 4.047, avg. samples / sec: 53235.87
Iteration:   3360, Loss function: 3.192, Average Loss: 4.065, avg. samples / sec: 53211.57
Iteration:   3360, Loss function: 2.712, Average Loss: 4.033, avg. samples / sec: 53077.14
Iteration:   3360, Loss function: 2.574, Average Loss: 4.008, avg. samples / sec: 53145.39
Iteration:   3360, Loss function: 3.562, Average Loss: 4.017, avg. samples / sec: 53170.60
Iteration:   3360, Loss function: 2.779, Average Loss: 4.032, avg. samples / sec: 52981.50
Iteration:   3360, Loss function: 4.414, Average Loss: 4.026, avg. samples / sec: 53131.45
Iteration:   3360, Loss function: 4.378, Average Loss: 4.045, avg. samples / sec: 53182.86
Iteration:   3360, Loss function: 3.944, Average Loss: 4.034, avg. samples / sec: 53112.34
Iteration:   3360, Loss function: 4.390, Average Loss: 4.046, avg. samples / sec: 53147.14
Iteration:   3360, Loss function: 2.500, Average Loss: 4.043, avg. samples / sec: 53086.10
Iteration:   3360, Loss function: 3.792, Average Loss: 4.029, avg. samples / sec: 53077.90
Iteration:   3360, Loss function: 3.474, Average Loss: 4.016, avg. samples / sec: 53075.30
Iteration:   3360, Loss function: 4.162, Average Loss: 3.994, avg. samples / sec: 52998.35
Iteration:   3360, Loss function: 4.072, Average Loss: 4.024, avg. samples / sec: 53172.42
Iteration:   3360, Loss function: 3.797, Average Loss: 4.016, avg. samples / sec: 53191.95
Iteration:   3360, Loss function: 3.383, Average Loss: 4.015, avg. samples / sec: 53172.28
Iteration:   3360, Loss function: 2.951, Average Loss: 4.002, avg. samples / sec: 53124.52
Iteration:   3360, Loss function: 3.492, Average Loss: 3.999, avg. samples / sec: 53093.38
Iteration:   3360, Loss function: 4.190, Average Loss: 4.019, avg. samples / sec: 53076.56
Iteration:   3360, Loss function: 1.470, Average Loss: 4.036, avg. samples / sec: 53096.40
Iteration:   3360, Loss function: 3.465, Average Loss: 4.018, avg. samples / sec: 53054.24
Iteration:   3360, Loss function: 3.622, Average Loss: 4.014, avg. samples / sec: 53073.30
Iteration:   3360, Loss function: 3.167, Average Loss: 4.030, avg. samples / sec: 53092.82
Iteration:   3360, Loss function: 3.541, Average Loss: 4.033, avg. samples / sec: 53107.60
Iteration:   3360, Loss function: 3.473, Average Loss: 4.024, avg. samples / sec: 53024.44
Iteration:   3360, Loss function: 2.638, Average Loss: 4.007, avg. samples / sec: 53054.48
Iteration:   3360, Loss function: 2.996, Average Loss: 4.034, avg. samples / sec: 53041.62
Iteration:   3360, Loss function: 3.397, Average Loss: 4.029, avg. samples / sec: 53020.81
Iteration:   3360, Loss function: 3.617, Average Loss: 4.052, avg. samples / sec: 53053.04
Iteration:   3380, Loss function: 3.305, Average Loss: 4.023, avg. samples / sec: 53785.89
Iteration:   3380, Loss function: 3.294, Average Loss: 4.026, avg. samples / sec: 53638.21
Iteration:   3380, Loss function: 3.153, Average Loss: 3.997, avg. samples / sec: 53582.15
Iteration:   3380, Loss function: 2.773, Average Loss: 4.008, avg. samples / sec: 53579.79
Iteration:   3380, Loss function: 2.933, Average Loss: 4.018, avg. samples / sec: 53626.48
Iteration:   3380, Loss function: 3.154, Average Loss: 4.036, avg. samples / sec: 53505.11
Iteration:   3380, Loss function: 3.707, Average Loss: 4.019, avg. samples / sec: 53695.03
Iteration:   3380, Loss function: 2.936, Average Loss: 4.033, avg. samples / sec: 53634.13
Iteration:   3380, Loss function: 4.095, Average Loss: 4.022, avg. samples / sec: 53609.75
Iteration:   3380, Loss function: 3.745, Average Loss: 4.030, avg. samples / sec: 53579.93
Iteration:   3380, Loss function: 3.629, Average Loss: 4.006, avg. samples / sec: 53658.06
Iteration:   3380, Loss function: 2.647, Average Loss: 4.029, avg. samples / sec: 53645.71
Iteration:   3380, Loss function: 3.210, Average Loss: 4.053, avg. samples / sec: 53470.54
Iteration:   3380, Loss function: 3.407, Average Loss: 3.986, avg. samples / sec: 53691.08
Iteration:   3380, Loss function: 2.252, Average Loss: 4.007, avg. samples / sec: 53706.20
Iteration:   3380, Loss function: 2.827, Average Loss: 4.022, avg. samples / sec: 53717.15
Iteration:   3380, Loss function: 4.223, Average Loss: 4.022, avg. samples / sec: 53708.35
Iteration:   3380, Loss function: 1.983, Average Loss: 3.988, avg. samples / sec: 53626.85
Iteration:   3380, Loss function: 3.662, Average Loss: 4.013, avg. samples / sec: 53561.20
Iteration:   3380, Loss function: 3.538, Average Loss: 4.038, avg. samples / sec: 53719.45
Iteration:   3380, Loss function: 2.795, Average Loss: 4.013, avg. samples / sec: 53705.38
Iteration:   3380, Loss function: 2.816, Average Loss: 4.014, avg. samples / sec: 53700.20
Iteration:   3380, Loss function: 3.844, Average Loss: 4.005, avg. samples / sec: 53563.58
Iteration:   3380, Loss function: 3.321, Average Loss: 4.022, avg. samples / sec: 53672.49
Iteration:   3380, Loss function: 3.785, Average Loss: 4.011, avg. samples / sec: 53671.51
Iteration:   3380, Loss function: 3.741, Average Loss: 3.994, avg. samples / sec: 53602.33
Iteration:   3380, Loss function: 2.879, Average Loss: 4.014, avg. samples / sec: 53673.15
Iteration:   3380, Loss function: 3.231, Average Loss: 3.999, avg. samples / sec: 53553.56
Iteration:   3380, Loss function: 2.660, Average Loss: 3.996, avg. samples / sec: 53667.26
Iteration:   3380, Loss function: 2.955, Average Loss: 4.004, avg. samples / sec: 53654.33
Iteration:   3400, Loss function: 2.972, Average Loss: 4.016, avg. samples / sec: 53768.68
Iteration:   3400, Loss function: 2.792, Average Loss: 4.013, avg. samples / sec: 53624.03
Iteration:   3400, Loss function: 3.740, Average Loss: 4.027, avg. samples / sec: 53737.16
Iteration:   3400, Loss function: 3.917, Average Loss: 4.043, avg. samples / sec: 53802.59
Iteration:   3400, Loss function: 3.816, Average Loss: 4.023, avg. samples / sec: 53718.11
Iteration:   3400, Loss function: 3.525, Average Loss: 4.009, avg. samples / sec: 53691.71
Iteration:   3400, Loss function: 2.652, Average Loss: 3.993, avg. samples / sec: 53682.08
Iteration:   3400, Loss function: 4.967, Average Loss: 4.017, avg. samples / sec: 53749.44
Iteration:   3400, Loss function: 3.855, Average Loss: 3.986, avg. samples / sec: 53673.80
Iteration:   3400, Loss function: 3.115, Average Loss: 4.009, avg. samples / sec: 53680.81
Iteration:   3400, Loss function: 4.096, Average Loss: 3.997, avg. samples / sec: 53693.90
Iteration:   3400, Loss function: 4.294, Average Loss: 3.976, avg. samples / sec: 53743.76
Iteration:   3400, Loss function: 2.978, Average Loss: 4.008, avg. samples / sec: 53652.45
Iteration:   3400, Loss function: 3.394, Average Loss: 4.020, avg. samples / sec: 53678.36
Iteration:   3400, Loss function: 3.895, Average Loss: 3.976, avg. samples / sec: 53727.41
Iteration:   3400, Loss function: 3.505, Average Loss: 4.002, avg. samples / sec: 53735.40
Iteration:   3400, Loss function: 4.000, Average Loss: 4.002, avg. samples / sec: 53734.21
Iteration:   3400, Loss function: 2.309, Average Loss: 4.000, avg. samples / sec: 53724.38
Iteration:   3400, Loss function: 3.391, Average Loss: 4.008, avg. samples / sec: 53693.25
Iteration:   3400, Loss function: 4.600, Average Loss: 3.999, avg. samples / sec: 53724.91
Iteration:   3400, Loss function: 3.312, Average Loss: 3.993, avg. samples / sec: 53752.13
Iteration:   3400, Loss function: 3.637, Average Loss: 3.997, avg. samples / sec: 53667.30
Iteration:   3400, Loss function: 4.448, Average Loss: 4.029, avg. samples / sec: 53697.69
Iteration:   3400, Loss function: 3.155, Average Loss: 4.003, avg. samples / sec: 53716.42
Iteration:   3400, Loss function: 2.908, Average Loss: 4.012, avg. samples / sec: 53705.55
Iteration:   3400, Loss function: 3.806, Average Loss: 4.010, avg. samples / sec: 53681.12
Iteration:   3400, Loss function: 4.926, Average Loss: 3.990, avg. samples / sec: 53716.74
Iteration:   3400, Loss function: 3.345, Average Loss: 3.996, avg. samples / sec: 53699.51
Iteration:   3400, Loss function: 3.229, Average Loss: 3.986, avg. samples / sec: 53663.13
Iteration:   3400, Loss function: 2.337, Average Loss: 3.986, avg. samples / sec: 53665.73
Iteration:   3420, Loss function: 2.939, Average Loss: 4.005, avg. samples / sec: 53713.57
Iteration:   3420, Loss function: 2.805, Average Loss: 3.997, avg. samples / sec: 53730.61
Iteration:   3420, Loss function: 3.590, Average Loss: 3.986, avg. samples / sec: 53838.82
Iteration:   3420, Loss function: 3.581, Average Loss: 4.011, avg. samples / sec: 53771.63
Iteration:   3420, Loss function: 2.724, Average Loss: 3.974, avg. samples / sec: 53784.48
Iteration:   3420, Loss function: 2.795, Average Loss: 4.002, avg. samples / sec: 53768.66
Iteration:   3420, Loss function: 2.002, Average Loss: 3.991, avg. samples / sec: 54032.67
Iteration:   3420, Loss function: 3.316, Average Loss: 4.016, avg. samples / sec: 53699.16
Iteration:   3420, Loss function: 2.914, Average Loss: 4.031, avg. samples / sec: 53703.58
Iteration:   3420, Loss function: 2.531, Average Loss: 4.011, avg. samples / sec: 53790.31
Iteration:   3420, Loss function: 3.387, Average Loss: 4.004, avg. samples / sec: 53754.20
Iteration:   3420, Loss function: 3.342, Average Loss: 3.969, avg. samples / sec: 53791.58
Iteration:   3420, Loss function: 4.924, Average Loss: 4.008, avg. samples / sec: 53726.82
Iteration:   3420, Loss function: 3.399, Average Loss: 3.997, avg. samples / sec: 53769.95
Iteration:   3420, Loss function: 3.555, Average Loss: 3.986, avg. samples / sec: 53750.20
Iteration:   3420, Loss function: 4.027, Average Loss: 3.967, avg. samples / sec: 53776.19
Iteration:   3420, Loss function: 3.611, Average Loss: 3.995, avg. samples / sec: 53768.92
Iteration:   3420, Loss function: 3.433, Average Loss: 3.986, avg. samples / sec: 53751.45
Iteration:   3420, Loss function: 3.592, Average Loss: 3.990, avg. samples / sec: 53733.09
Iteration:   3420, Loss function: 4.327, Average Loss: 4.013, avg. samples / sec: 53763.28
Iteration:   3420, Loss function: 3.259, Average Loss: 3.998, avg. samples / sec: 53756.60
Iteration:   3420, Loss function: 2.463, Average Loss: 3.972, avg. samples / sec: 53817.61
Iteration:   3420, Loss function: 2.152, Average Loss: 3.989, avg. samples / sec: 53740.48
Iteration:   3420, Loss function: 3.561, Average Loss: 3.992, avg. samples / sec: 53708.70
Iteration:   3420, Loss function: 3.476, Average Loss: 3.984, avg. samples / sec: 53727.94
Iteration:   3420, Loss function: 2.862, Average Loss: 3.975, avg. samples / sec: 53785.15
Iteration:   3420, Loss function: 3.218, Average Loss: 4.001, avg. samples / sec: 53738.54
Iteration:   3420, Loss function: 3.257, Average Loss: 3.987, avg. samples / sec: 53706.94
Iteration:   3420, Loss function: 4.209, Average Loss: 3.983, avg. samples / sec: 53723.32
Iteration:   3420, Loss function: 4.119, Average Loss: 3.987, avg. samples / sec: 53720.76
:::MLL 1558640394.163 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.60s)
DONE (t=0.62s)
DONE (t=2.53s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22273
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38298
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06198
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.22954
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21711
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31759
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09980
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.51971
Current AP: 0.22273 AP goal: 0.23000
:::MLL 1558640397.940 eval_accuracy: {"value": 0.22273033062328676, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558640398.028 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558640398.034 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558640398.034 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558640398.067 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558640398.067 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 4.203, Average Loss: 3.994, avg. samples / sec: 7444.15
Iteration:   3440, Loss function: 3.286, Average Loss: 3.959, avg. samples / sec: 7446.08
Iteration:   3440, Loss function: 4.420, Average Loss: 3.962, avg. samples / sec: 7444.27
Iteration:   3440, Loss function: 3.164, Average Loss: 3.988, avg. samples / sec: 7444.17
Iteration:   3440, Loss function: 4.629, Average Loss: 3.982, avg. samples / sec: 7444.11
Iteration:   3440, Loss function: 2.524, Average Loss: 3.997, avg. samples / sec: 7449.15
Iteration:   3440, Loss function: 5.360, Average Loss: 3.976, avg. samples / sec: 7448.63
Iteration:   3440, Loss function: 3.560, Average Loss: 4.015, avg. samples / sec: 7444.02
Iteration:   3440, Loss function: 2.682, Average Loss: 3.997, avg. samples / sec: 7444.50
Iteration:   3440, Loss function: 4.097, Average Loss: 4.008, avg. samples / sec: 7444.16
Iteration:   3440, Loss function: 3.738, Average Loss: 3.963, avg. samples / sec: 7448.79
Iteration:   3440, Loss function: 3.425, Average Loss: 3.972, avg. samples / sec: 7444.52
Iteration:   3440, Loss function: 3.882, Average Loss: 3.998, avg. samples / sec: 7442.84
Iteration:   3440, Loss function: 4.077, Average Loss: 3.988, avg. samples / sec: 7440.79
Iteration:   3440, Loss function: 3.296, Average Loss: 3.989, avg. samples / sec: 7443.71
Iteration:   3440, Loss function: 2.899, Average Loss: 3.958, avg. samples / sec: 7445.42
Iteration:   3440, Loss function: 3.209, Average Loss: 4.008, avg. samples / sec: 7440.25
Iteration:   3440, Loss function: 3.911, Average Loss: 3.956, avg. samples / sec: 7443.75
Iteration:   3440, Loss function: 2.422, Average Loss: 3.979, avg. samples / sec: 7444.55
Iteration:   3440, Loss function: 5.142, Average Loss: 3.984, avg. samples / sec: 7443.93
Iteration:   3440, Loss function: 4.054, Average Loss: 3.970, avg. samples / sec: 7445.02
Iteration:   3440, Loss function: 2.884, Average Loss: 3.977, avg. samples / sec: 7444.32
Iteration:   3440, Loss function: 2.727, Average Loss: 3.975, avg. samples / sec: 7444.04
Iteration:   3440, Loss function: 2.926, Average Loss: 3.982, avg. samples / sec: 7444.15
Iteration:   3440, Loss function: 4.302, Average Loss: 3.994, avg. samples / sec: 7444.40
Iteration:   3440, Loss function: 3.247, Average Loss: 3.996, avg. samples / sec: 7439.36
Iteration:   3440, Loss function: 3.714, Average Loss: 3.983, avg. samples / sec: 7444.18
Iteration:   3440, Loss function: 3.421, Average Loss: 3.980, avg. samples / sec: 7444.47
Iteration:   3440, Loss function: 3.671, Average Loss: 3.976, avg. samples / sec: 7444.69
Iteration:   3440, Loss function: 3.133, Average Loss: 3.974, avg. samples / sec: 7437.05
Iteration:   3460, Loss function: 4.344, Average Loss: 3.947, avg. samples / sec: 53885.39
Iteration:   3460, Loss function: 3.728, Average Loss: 3.955, avg. samples / sec: 53825.11
Iteration:   3460, Loss function: 3.958, Average Loss: 3.978, avg. samples / sec: 53827.84
Iteration:   3460, Loss function: 3.797, Average Loss: 3.998, avg. samples / sec: 53867.16
Iteration:   3460, Loss function: 3.628, Average Loss: 3.987, avg. samples / sec: 53811.44
Iteration:   3460, Loss function: 3.341, Average Loss: 3.971, avg. samples / sec: 53788.77
Iteration:   3460, Loss function: 3.535, Average Loss: 3.946, avg. samples / sec: 53832.86
Iteration:   3460, Loss function: 3.147, Average Loss: 3.988, avg. samples / sec: 53815.88
Iteration:   3460, Loss function: 3.230, Average Loss: 3.978, avg. samples / sec: 53853.88
Iteration:   3460, Loss function: 2.920, Average Loss: 3.959, avg. samples / sec: 53803.43
Iteration:   3460, Loss function: 4.832, Average Loss: 3.982, avg. samples / sec: 53828.34
Iteration:   3460, Loss function: 2.876, Average Loss: 4.010, avg. samples / sec: 53767.18
Iteration:   3460, Loss function: 3.767, Average Loss: 3.971, avg. samples / sec: 53743.25
Iteration:   3460, Loss function: 3.132, Average Loss: 3.984, avg. samples / sec: 53598.19
Iteration:   3460, Loss function: 4.248, Average Loss: 3.975, avg. samples / sec: 53945.64
Iteration:   3460, Loss function: 4.423, Average Loss: 3.948, avg. samples / sec: 53803.55
Iteration:   3460, Loss function: 2.986, Average Loss: 3.947, avg. samples / sec: 53836.07
Iteration:   3460, Loss function: 4.607, Average Loss: 3.972, avg. samples / sec: 53870.70
Iteration:   3460, Loss function: 4.086, Average Loss: 3.983, avg. samples / sec: 53855.43
Iteration:   3460, Loss function: 3.879, Average Loss: 3.960, avg. samples / sec: 53844.85
Iteration:   3460, Loss function: 3.658, Average Loss: 3.974, avg. samples / sec: 53802.36
Iteration:   3460, Loss function: 3.677, Average Loss: 3.974, avg. samples / sec: 53833.81
Iteration:   3460, Loss function: 2.435, Average Loss: 3.996, avg. samples / sec: 53776.02
Iteration:   3460, Loss function: 3.397, Average Loss: 3.964, avg. samples / sec: 53838.89
Iteration:   3460, Loss function: 3.461, Average Loss: 3.967, avg. samples / sec: 53822.07
Iteration:   3460, Loss function: 3.150, Average Loss: 3.985, avg. samples / sec: 53582.52
Iteration:   3460, Loss function: 2.918, Average Loss: 3.968, avg. samples / sec: 53764.00
Iteration:   3460, Loss function: 4.365, Average Loss: 3.990, avg. samples / sec: 53794.31
Iteration:   3460, Loss function: 3.662, Average Loss: 3.976, avg. samples / sec: 53783.31
Iteration:   3460, Loss function: 3.174, Average Loss: 3.959, avg. samples / sec: 53774.05
Iteration:   3480, Loss function: 3.797, Average Loss: 3.972, avg. samples / sec: 54233.52
Iteration:   3480, Loss function: 3.132, Average Loss: 3.933, avg. samples / sec: 53935.07
Iteration:   3480, Loss function: 3.083, Average Loss: 3.970, avg. samples / sec: 53970.70
Iteration:   3480, Loss function: 3.608, Average Loss: 3.941, avg. samples / sec: 53959.48
Iteration:   3480, Loss function: 3.271, Average Loss: 3.989, avg. samples / sec: 53961.28
Iteration:   3480, Loss function: 2.364, Average Loss: 3.959, avg. samples / sec: 54061.09
Iteration:   3480, Loss function: 3.622, Average Loss: 3.937, avg. samples / sec: 53995.02
Iteration:   3480, Loss function: 2.868, Average Loss: 3.957, avg. samples / sec: 54254.94
Iteration:   3480, Loss function: 3.686, Average Loss: 3.958, avg. samples / sec: 53977.83
Iteration:   3480, Loss function: 3.429, Average Loss: 3.977, avg. samples / sec: 53963.32
Iteration:   3480, Loss function: 2.699, Average Loss: 4.000, avg. samples / sec: 54017.89
Iteration:   3480, Loss function: 2.604, Average Loss: 3.974, avg. samples / sec: 53965.53
Iteration:   3480, Loss function: 4.343, Average Loss: 3.978, avg. samples / sec: 54215.47
Iteration:   3480, Loss function: 3.196, Average Loss: 3.965, avg. samples / sec: 54183.62
Iteration:   3480, Loss function: 3.781, Average Loss: 3.968, avg. samples / sec: 53983.35
Iteration:   3480, Loss function: 3.457, Average Loss: 3.972, avg. samples / sec: 53934.80
Iteration:   3480, Loss function: 4.615, Average Loss: 3.945, avg. samples / sec: 53955.06
Iteration:   3480, Loss function: 4.229, Average Loss: 3.936, avg. samples / sec: 53960.26
Iteration:   3480, Loss function: 3.019, Average Loss: 3.953, avg. samples / sec: 54006.54
Iteration:   3480, Loss function: 3.320, Average Loss: 3.976, avg. samples / sec: 53957.41
Iteration:   3480, Loss function: 2.688, Average Loss: 3.952, avg. samples / sec: 53963.82
Iteration:   3480, Loss function: 4.012, Average Loss: 3.985, avg. samples / sec: 53978.29
Iteration:   3480, Loss function: 3.452, Average Loss: 3.940, avg. samples / sec: 53922.19
Iteration:   3480, Loss function: 5.016, Average Loss: 3.962, avg. samples / sec: 53970.64
Iteration:   3480, Loss function: 3.178, Average Loss: 3.961, avg. samples / sec: 53925.00
Iteration:   3480, Loss function: 3.630, Average Loss: 3.967, avg. samples / sec: 53997.09
Iteration:   3480, Loss function: 3.352, Average Loss: 3.964, avg. samples / sec: 53825.05
Iteration:   3480, Loss function: 3.874, Average Loss: 3.980, avg. samples / sec: 53978.27
Iteration:   3480, Loss function: 3.593, Average Loss: 3.959, avg. samples / sec: 53951.15
Iteration:   3480, Loss function: 2.863, Average Loss: 3.952, avg. samples / sec: 53960.59
:::MLL 1558640400.250 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558640400.250 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 2.927, Average Loss: 3.960, avg. samples / sec: 53877.71
Iteration:   3500, Loss function: 2.018, Average Loss: 3.923, avg. samples / sec: 53864.48
Iteration:   3500, Loss function: 3.579, Average Loss: 3.931, avg. samples / sec: 53942.93
Iteration:   3500, Loss function: 5.117, Average Loss: 3.971, avg. samples / sec: 53979.57
Iteration:   3500, Loss function: 3.349, Average Loss: 3.965, avg. samples / sec: 53988.48
Iteration:   3500, Loss function: 3.564, Average Loss: 3.961, avg. samples / sec: 53969.77
Iteration:   3500, Loss function: 3.234, Average Loss: 3.922, avg. samples / sec: 53915.40
Iteration:   3500, Loss function: 3.482, Average Loss: 3.958, avg. samples / sec: 53868.15
Iteration:   3500, Loss function: 4.890, Average Loss: 3.951, avg. samples / sec: 53888.89
Iteration:   3500, Loss function: 3.213, Average Loss: 3.951, avg. samples / sec: 53859.75
Iteration:   3500, Loss function: 3.501, Average Loss: 3.974, avg. samples / sec: 53834.24
Iteration:   3500, Loss function: 5.234, Average Loss: 3.976, avg. samples / sec: 53868.87
Iteration:   3500, Loss function: 3.744, Average Loss: 3.993, avg. samples / sec: 53838.17
Iteration:   3500, Loss function: 2.516, Average Loss: 3.925, avg. samples / sec: 54031.14
Iteration:   3500, Loss function: 2.591, Average Loss: 3.962, avg. samples / sec: 53862.86
Iteration:   3500, Loss function: 4.544, Average Loss: 3.935, avg. samples / sec: 53868.46
Iteration:   3500, Loss function: 4.154, Average Loss: 3.950, avg. samples / sec: 53770.54
Iteration:   3500, Loss function: 4.832, Average Loss: 3.943, avg. samples / sec: 54013.12
Iteration:   3500, Loss function: 3.147, Average Loss: 3.943, avg. samples / sec: 54092.59
Iteration:   3500, Loss function: 2.527, Average Loss: 3.965, avg. samples / sec: 53969.75
Iteration:   3500, Loss function: 3.278, Average Loss: 3.953, avg. samples / sec: 53946.78
Iteration:   3500, Loss function: 3.672, Average Loss: 3.948, avg. samples / sec: 53955.55
Iteration:   3500, Loss function: 2.889, Average Loss: 3.968, avg. samples / sec: 53935.81
Iteration:   3500, Loss function: 3.366, Average Loss: 3.972, avg. samples / sec: 53875.36
Iteration:   3500, Loss function: 3.510, Average Loss: 3.939, avg. samples / sec: 53872.58
Iteration:   3500, Loss function: 3.730, Average Loss: 3.934, avg. samples / sec: 53869.82
Iteration:   3500, Loss function: 4.343, Average Loss: 3.947, avg. samples / sec: 53889.70
Iteration:   3500, Loss function: 3.583, Average Loss: 3.956, avg. samples / sec: 53635.27
Iteration:   3500, Loss function: 3.109, Average Loss: 3.952, avg. samples / sec: 53854.89
Iteration:   3500, Loss function: 2.621, Average Loss: 3.958, avg. samples / sec: 53858.17
Iteration:   3520, Loss function: 3.764, Average Loss: 3.949, avg. samples / sec: 54137.08
Iteration:   3520, Loss function: 3.874, Average Loss: 3.911, avg. samples / sec: 54139.37
Iteration:   3520, Loss function: 4.300, Average Loss: 3.920, avg. samples / sec: 54085.97
Iteration:   3520, Loss function: 3.802, Average Loss: 3.953, avg. samples / sec: 54117.74
Iteration:   3520, Loss function: 3.737, Average Loss: 3.961, avg. samples / sec: 54167.15
Iteration:   3520, Loss function: 3.427, Average Loss: 3.946, avg. samples / sec: 54130.38
Iteration:   3520, Loss function: 3.807, Average Loss: 3.945, avg. samples / sec: 54227.57
Iteration:   3520, Loss function: 2.584, Average Loss: 3.940, avg. samples / sec: 54148.50
Iteration:   3520, Loss function: 3.760, Average Loss: 3.951, avg. samples / sec: 54191.16
Iteration:   3520, Loss function: 2.746, Average Loss: 3.952, avg. samples / sec: 54069.30
Iteration:   3520, Loss function: 3.088, Average Loss: 3.960, avg. samples / sec: 54140.80
Iteration:   3520, Loss function: 2.457, Average Loss: 3.926, avg. samples / sec: 54165.42
Iteration:   3520, Loss function: 2.239, Average Loss: 3.960, avg. samples / sec: 53999.05
Iteration:   3520, Loss function: 2.711, Average Loss: 3.981, avg. samples / sec: 54137.99
Iteration:   3520, Loss function: 3.772, Average Loss: 3.953, avg. samples / sec: 53991.15
Iteration:   3520, Loss function: 3.285, Average Loss: 3.914, avg. samples / sec: 53948.74
Iteration:   3520, Loss function: 3.040, Average Loss: 3.944, avg. samples / sec: 54218.68
Iteration:   3520, Loss function: 2.827, Average Loss: 3.927, avg. samples / sec: 54160.42
Iteration:   3520, Loss function: 3.109, Average Loss: 3.930, avg. samples / sec: 54153.78
Iteration:   3520, Loss function: 4.943, Average Loss: 3.935, avg. samples / sec: 53979.30
Iteration:   3520, Loss function: 3.948, Average Loss: 3.958, avg. samples / sec: 54110.78
Iteration:   3520, Loss function: 3.570, Average Loss: 3.952, avg. samples / sec: 54027.23
Iteration:   3520, Loss function: 3.629, Average Loss: 3.958, avg. samples / sec: 54114.54
Iteration:   3520, Loss function: 3.478, Average Loss: 3.942, avg. samples / sec: 54048.38
Iteration:   3520, Loss function: 3.136, Average Loss: 3.934, avg. samples / sec: 53953.51
Iteration:   3520, Loss function: 4.011, Average Loss: 3.948, avg. samples / sec: 54157.84
Iteration:   3520, Loss function: 2.225, Average Loss: 3.943, avg. samples / sec: 54150.02
Iteration:   3520, Loss function: 3.206, Average Loss: 3.937, avg. samples / sec: 54034.79
Iteration:   3520, Loss function: 3.812, Average Loss: 3.938, avg. samples / sec: 54109.56
Iteration:   3520, Loss function: 2.304, Average Loss: 3.915, avg. samples / sec: 53896.17
Iteration:   3540, Loss function: 3.502, Average Loss: 3.941, avg. samples / sec: 54394.53
Iteration:   3540, Loss function: 2.898, Average Loss: 3.901, avg. samples / sec: 54550.72
Iteration:   3540, Loss function: 3.428, Average Loss: 3.946, avg. samples / sec: 54400.03
Iteration:   3540, Loss function: 2.053, Average Loss: 3.932, avg. samples / sec: 54408.77
Iteration:   3540, Loss function: 4.136, Average Loss: 3.952, avg. samples / sec: 54438.49
Iteration:   3540, Loss function: 4.014, Average Loss: 3.953, avg. samples / sec: 54372.33
Iteration:   3540, Loss function: 2.928, Average Loss: 3.907, avg. samples / sec: 54338.78
Iteration:   3540, Loss function: 3.275, Average Loss: 3.930, avg. samples / sec: 54376.88
Iteration:   3540, Loss function: 3.088, Average Loss: 3.942, avg. samples / sec: 54383.01
Iteration:   3540, Loss function: 2.602, Average Loss: 3.932, avg. samples / sec: 54362.64
Iteration:   3540, Loss function: 3.790, Average Loss: 3.939, avg. samples / sec: 54362.49
Iteration:   3540, Loss function: 3.048, Average Loss: 3.947, avg. samples / sec: 54388.07
Iteration:   3540, Loss function: 2.582, Average Loss: 3.938, avg. samples / sec: 54409.97
Iteration:   3540, Loss function: 2.948, Average Loss: 3.903, avg. samples / sec: 54283.36
Iteration:   3540, Loss function: 3.493, Average Loss: 3.974, avg. samples / sec: 54366.08
Iteration:   3540, Loss function: 3.332, Average Loss: 3.917, avg. samples / sec: 54350.79
Iteration:   3540, Loss function: 2.765, Average Loss: 3.944, avg. samples / sec: 54475.99
Iteration:   3540, Loss function: 3.784, Average Loss: 3.908, avg. samples / sec: 54481.02
Iteration:   3540, Loss function: 4.728, Average Loss: 3.934, avg. samples / sec: 54373.84
Iteration:   3540, Loss function: 2.788, Average Loss: 3.917, avg. samples / sec: 54387.71
Iteration:   3540, Loss function: 3.398, Average Loss: 3.918, avg. samples / sec: 54382.25
Iteration:   3540, Loss function: 3.537, Average Loss: 3.929, avg. samples / sec: 54438.24
Iteration:   3540, Loss function: 2.762, Average Loss: 3.925, avg. samples / sec: 54415.98
Iteration:   3540, Loss function: 3.052, Average Loss: 3.939, avg. samples / sec: 54401.88
Iteration:   3540, Loss function: 3.072, Average Loss: 3.923, avg. samples / sec: 54423.77
Iteration:   3540, Loss function: 3.730, Average Loss: 3.933, avg. samples / sec: 54390.06
Iteration:   3540, Loss function: 3.639, Average Loss: 3.924, avg. samples / sec: 54360.88
Iteration:   3540, Loss function: 2.519, Average Loss: 3.937, avg. samples / sec: 54391.51
Iteration:   3540, Loss function: 2.676, Average Loss: 3.934, avg. samples / sec: 54384.43
Iteration:   3540, Loss function: 2.579, Average Loss: 3.949, avg. samples / sec: 54335.87
:::MLL 1558640402.114 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558640402.115 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 3.700, Average Loss: 3.931, avg. samples / sec: 53670.67
Iteration:   3560, Loss function: 2.752, Average Loss: 3.898, avg. samples / sec: 53813.74
Iteration:   3560, Loss function: 4.221, Average Loss: 3.940, avg. samples / sec: 53758.30
Iteration:   3560, Loss function: 3.954, Average Loss: 3.935, avg. samples / sec: 53821.57
Iteration:   3560, Loss function: 3.075, Average Loss: 3.891, avg. samples / sec: 53676.48
Iteration:   3560, Loss function: 3.767, Average Loss: 3.931, avg. samples / sec: 53780.78
Iteration:   3560, Loss function: 3.007, Average Loss: 3.916, avg. samples / sec: 53730.98
Iteration:   3560, Loss function: 3.860, Average Loss: 3.897, avg. samples / sec: 53758.20
Iteration:   3560, Loss function: 2.822, Average Loss: 3.941, avg. samples / sec: 53677.83
Iteration:   3560, Loss function: 3.225, Average Loss: 3.917, avg. samples / sec: 53687.93
Iteration:   3560, Loss function: 2.532, Average Loss: 3.945, avg. samples / sec: 53664.60
Iteration:   3560, Loss function: 3.804, Average Loss: 3.907, avg. samples / sec: 53717.17
Iteration:   3560, Loss function: 1.901, Average Loss: 3.926, avg. samples / sec: 53614.99
Iteration:   3560, Loss function: 4.143, Average Loss: 3.958, avg. samples / sec: 53692.59
Iteration:   3560, Loss function: 2.178, Average Loss: 3.931, avg. samples / sec: 53651.10
Iteration:   3560, Loss function: 3.034, Average Loss: 3.934, avg. samples / sec: 53620.28
Iteration:   3560, Loss function: 3.323, Average Loss: 3.928, avg. samples / sec: 53834.01
Iteration:   3560, Loss function: 3.306, Average Loss: 3.913, avg. samples / sec: 53814.24
Iteration:   3560, Loss function: 4.065, Average Loss: 3.914, avg. samples / sec: 53774.89
Iteration:   3560, Loss function: 4.212, Average Loss: 3.924, avg. samples / sec: 53782.05
Iteration:   3560, Loss function: 3.001, Average Loss: 3.927, avg. samples / sec: 53685.29
Iteration:   3560, Loss function: 2.932, Average Loss: 3.937, avg. samples / sec: 53805.73
Iteration:   3560, Loss function: 2.506, Average Loss: 3.924, avg. samples / sec: 53697.01
Iteration:   3560, Loss function: 3.757, Average Loss: 3.899, avg. samples / sec: 53688.34
Iteration:   3560, Loss function: 3.555, Average Loss: 3.915, avg. samples / sec: 53698.32
Iteration:   3560, Loss function: 2.716, Average Loss: 3.907, avg. samples / sec: 53650.36
Iteration:   3560, Loss function: 3.722, Average Loss: 3.927, avg. samples / sec: 53702.86
Iteration:   3560, Loss function: 2.403, Average Loss: 3.905, avg. samples / sec: 53659.99
Iteration:   3560, Loss function: 2.849, Average Loss: 3.921, avg. samples / sec: 53696.19
Iteration:   3560, Loss function: 2.804, Average Loss: 3.915, avg. samples / sec: 53643.07
Iteration:   3580, Loss function: 2.996, Average Loss: 3.917, avg. samples / sec: 54452.96
Iteration:   3580, Loss function: 3.852, Average Loss: 3.887, avg. samples / sec: 54343.73
Iteration:   3580, Loss function: 5.314, Average Loss: 3.884, avg. samples / sec: 54389.70
Iteration:   3580, Loss function: 4.193, Average Loss: 3.886, avg. samples / sec: 54433.31
Iteration:   3580, Loss function: 2.992, Average Loss: 3.921, avg. samples / sec: 54340.77
Iteration:   3580, Loss function: 2.747, Average Loss: 3.906, avg. samples / sec: 54432.41
Iteration:   3580, Loss function: 3.227, Average Loss: 3.923, avg. samples / sec: 54505.61
Iteration:   3580, Loss function: 4.035, Average Loss: 3.919, avg. samples / sec: 54463.82
Iteration:   3580, Loss function: 3.442, Average Loss: 3.949, avg. samples / sec: 54475.14
Iteration:   3580, Loss function: 3.728, Average Loss: 3.929, avg. samples / sec: 54295.30
Iteration:   3580, Loss function: 2.827, Average Loss: 3.893, avg. samples / sec: 54437.54
Iteration:   3580, Loss function: 4.435, Average Loss: 3.934, avg. samples / sec: 54406.98
Iteration:   3580, Loss function: 3.212, Average Loss: 3.932, avg. samples / sec: 54366.03
Iteration:   3580, Loss function: 3.368, Average Loss: 3.923, avg. samples / sec: 54424.32
Iteration:   3580, Loss function: 3.633, Average Loss: 3.905, avg. samples / sec: 54321.61
Iteration:   3580, Loss function: 3.395, Average Loss: 3.921, avg. samples / sec: 54284.91
Iteration:   3580, Loss function: 3.180, Average Loss: 3.889, avg. samples / sec: 54482.62
Iteration:   3580, Loss function: 2.947, Average Loss: 3.916, avg. samples / sec: 54427.01
Iteration:   3580, Loss function: 4.310, Average Loss: 3.896, avg. samples / sec: 54418.06
Iteration:   3580, Loss function: 3.723, Average Loss: 3.915, avg. samples / sec: 54376.84
Iteration:   3580, Loss function: 3.568, Average Loss: 3.921, avg. samples / sec: 54386.60
Iteration:   3580, Loss function: 3.633, Average Loss: 3.900, avg. samples / sec: 54442.13
Iteration:   3580, Loss function: 3.013, Average Loss: 3.902, avg. samples / sec: 54473.46
Iteration:   3580, Loss function: 4.720, Average Loss: 3.919, avg. samples / sec: 54282.67
Iteration:   3580, Loss function: 3.823, Average Loss: 3.909, avg. samples / sec: 54420.83
Iteration:   3580, Loss function: 2.938, Average Loss: 3.906, avg. samples / sec: 54318.41
Iteration:   3580, Loss function: 3.514, Average Loss: 3.907, avg. samples / sec: 54301.64
Iteration:   3580, Loss function: 3.567, Average Loss: 3.915, avg. samples / sec: 54413.90
Iteration:   3580, Loss function: 4.043, Average Loss: 3.910, avg. samples / sec: 54426.80
Iteration:   3580, Loss function: 4.028, Average Loss: 3.928, avg. samples / sec: 54320.16
Iteration:   3600, Loss function: 2.929, Average Loss: 3.872, avg. samples / sec: 54574.80
Iteration:   3600, Loss function: 2.402, Average Loss: 3.914, avg. samples / sec: 54475.92
Iteration:   3600, Loss function: 3.146, Average Loss: 3.921, avg. samples / sec: 54495.35
Iteration:   3600, Loss function: 3.423, Average Loss: 3.924, avg. samples / sec: 54477.14
Iteration:   3600, Loss function: 3.551, Average Loss: 3.873, avg. samples / sec: 54409.59
Iteration:   3600, Loss function: 3.010, Average Loss: 3.914, avg. samples / sec: 54503.31
Iteration:   3600, Loss function: 2.576, Average Loss: 3.943, avg. samples / sec: 54433.23
Iteration:   3600, Loss function: 3.005, Average Loss: 3.896, avg. samples / sec: 54419.42
Iteration:   3600, Loss function: 1.990, Average Loss: 3.878, avg. samples / sec: 54373.98
Iteration:   3600, Loss function: 4.098, Average Loss: 3.908, avg. samples / sec: 54438.82
Iteration:   3600, Loss function: 4.050, Average Loss: 3.910, avg. samples / sec: 54409.27
Iteration:   3600, Loss function: 3.242, Average Loss: 3.912, avg. samples / sec: 54481.99
Iteration:   3600, Loss function: 3.581, Average Loss: 3.880, avg. samples / sec: 54402.66
Iteration:   3600, Loss function: 3.296, Average Loss: 3.904, avg. samples / sec: 54177.27
Iteration:   3600, Loss function: 4.710, Average Loss: 3.891, avg. samples / sec: 54426.13
Iteration:   3600, Loss function: 2.991, Average Loss: 3.884, avg. samples / sec: 54477.84
Iteration:   3600, Loss function: 1.925, Average Loss: 3.922, avg. samples / sec: 54261.39
Iteration:   3600, Loss function: 2.943, Average Loss: 3.908, avg. samples / sec: 54464.77
Iteration:   3600, Loss function: 3.378, Average Loss: 3.903, avg. samples / sec: 54423.25
Iteration:   3600, Loss function: 4.581, Average Loss: 3.888, avg. samples / sec: 54462.03
Iteration:   3600, Loss function: 3.453, Average Loss: 3.906, avg. samples / sec: 54435.59
Iteration:   3600, Loss function: 2.293, Average Loss: 3.889, avg. samples / sec: 54448.77
Iteration:   3600, Loss function: 3.705, Average Loss: 3.902, avg. samples / sec: 54459.12
Iteration:   3600, Loss function: 2.930, Average Loss: 3.882, avg. samples / sec: 54411.25
Iteration:   3600, Loss function: 4.603, Average Loss: 3.892, avg. samples / sec: 54454.01
Iteration:   3600, Loss function: 3.330, Average Loss: 3.901, avg. samples / sec: 54456.91
Iteration:   3600, Loss function: 2.666, Average Loss: 3.907, avg. samples / sec: 54458.32
Iteration:   3600, Loss function: 3.131, Average Loss: 3.908, avg. samples / sec: 54410.43
Iteration:   3600, Loss function: 3.289, Average Loss: 3.897, avg. samples / sec: 54450.77
Iteration:   3600, Loss function: 4.372, Average Loss: 3.928, avg. samples / sec: 54457.31
Iteration:   3620, Loss function: 2.645, Average Loss: 3.865, avg. samples / sec: 54274.02
Iteration:   3620, Loss function: 1.938, Average Loss: 3.889, avg. samples / sec: 54493.01
Iteration:   3620, Loss function: 2.984, Average Loss: 3.917, avg. samples / sec: 54581.25
Iteration:   3620, Loss function: 4.185, Average Loss: 3.914, avg. samples / sec: 54346.39
Iteration:   3620, Loss function: 4.636, Average Loss: 3.867, avg. samples / sec: 54339.29
Iteration:   3620, Loss function: 2.740, Average Loss: 3.866, avg. samples / sec: 54352.95
Iteration:   3620, Loss function: 3.188, Average Loss: 3.899, avg. samples / sec: 54364.80
Iteration:   3620, Loss function: 3.667, Average Loss: 3.883, avg. samples / sec: 54342.74
Iteration:   3620, Loss function: 3.124, Average Loss: 3.896, avg. samples / sec: 54331.89
Iteration:   3620, Loss function: 2.659, Average Loss: 3.910, avg. samples / sec: 54294.82
Iteration:   3620, Loss function: 3.048, Average Loss: 3.884, avg. samples / sec: 54406.61
Iteration:   3620, Loss function: 3.220, Average Loss: 3.902, avg. samples / sec: 54300.47
Iteration:   3620, Loss function: 3.067, Average Loss: 3.930, avg. samples / sec: 54295.74
Iteration:   3620, Loss function: 2.181, Average Loss: 3.902, avg. samples / sec: 54219.85
Iteration:   3620, Loss function: 3.826, Average Loss: 3.903, avg. samples / sec: 54303.19
Iteration:   3620, Loss function: 3.639, Average Loss: 3.867, avg. samples / sec: 54303.02
Iteration:   3620, Loss function: 3.320, Average Loss: 3.900, avg. samples / sec: 54339.58
Iteration:   3620, Loss function: 3.836, Average Loss: 3.876, avg. samples / sec: 54351.44
Iteration:   3620, Loss function: 3.734, Average Loss: 3.878, avg. samples / sec: 54338.13
Iteration:   3620, Loss function: 3.161, Average Loss: 3.876, avg. samples / sec: 54318.15
Iteration:   3620, Loss function: 3.177, Average Loss: 3.895, avg. samples / sec: 54313.38
Iteration:   3620, Loss function: 3.554, Average Loss: 3.895, avg. samples / sec: 54347.38
Iteration:   3620, Loss function: 3.202, Average Loss: 3.872, avg. samples / sec: 54275.96
Iteration:   3620, Loss function: 2.921, Average Loss: 3.883, avg. samples / sec: 54325.78
Iteration:   3620, Loss function: 3.231, Average Loss: 3.885, avg. samples / sec: 54309.97
Iteration:   3620, Loss function: 4.546, Average Loss: 3.899, avg. samples / sec: 54310.41
Iteration:   3620, Loss function: 3.293, Average Loss: 3.922, avg. samples / sec: 54323.89
Iteration:   3620, Loss function: 3.935, Average Loss: 3.888, avg. samples / sec: 54299.95
Iteration:   3620, Loss function: 2.899, Average Loss: 3.893, avg. samples / sec: 54265.82
Iteration:   3620, Loss function: 3.868, Average Loss: 3.891, avg. samples / sec: 54269.77
:::MLL 1558640404.280 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558640404.281 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 2.570, Average Loss: 3.880, avg. samples / sec: 53674.97
Iteration:   3640, Loss function: 4.209, Average Loss: 3.859, avg. samples / sec: 53564.03
Iteration:   3640, Loss function: 2.971, Average Loss: 3.860, avg. samples / sec: 53607.71
Iteration:   3640, Loss function: 3.821, Average Loss: 3.909, avg. samples / sec: 53567.16
Iteration:   3640, Loss function: 2.601, Average Loss: 3.904, avg. samples / sec: 53569.14
Iteration:   3640, Loss function: 2.679, Average Loss: 3.893, avg. samples / sec: 53631.97
Iteration:   3640, Loss function: 2.641, Average Loss: 3.855, avg. samples / sec: 53568.32
Iteration:   3640, Loss function: 2.188, Average Loss: 3.891, avg. samples / sec: 53602.59
Iteration:   3640, Loss function: 4.019, Average Loss: 3.902, avg. samples / sec: 53566.14
Iteration:   3640, Loss function: 3.402, Average Loss: 3.887, avg. samples / sec: 53548.44
Iteration:   3640, Loss function: 3.715, Average Loss: 3.892, avg. samples / sec: 53536.92
Iteration:   3640, Loss function: 3.089, Average Loss: 3.867, avg. samples / sec: 53547.26
Iteration:   3640, Loss function: 2.941, Average Loss: 3.889, avg. samples / sec: 53579.85
Iteration:   3640, Loss function: 3.356, Average Loss: 3.871, avg. samples / sec: 53513.30
Iteration:   3640, Loss function: 3.103, Average Loss: 3.917, avg. samples / sec: 53549.35
Iteration:   3640, Loss function: 2.993, Average Loss: 3.855, avg. samples / sec: 53589.47
Iteration:   3640, Loss function: 4.551, Average Loss: 3.868, avg. samples / sec: 53606.85
Iteration:   3640, Loss function: 4.230, Average Loss: 3.874, avg. samples / sec: 53608.63
Iteration:   3640, Loss function: 3.832, Average Loss: 3.888, avg. samples / sec: 53580.46
Iteration:   3640, Loss function: 2.850, Average Loss: 3.865, avg. samples / sec: 53558.67
Iteration:   3640, Loss function: 2.685, Average Loss: 3.885, avg. samples / sec: 53572.07
Iteration:   3640, Loss function: 2.756, Average Loss: 3.871, avg. samples / sec: 53553.38
Iteration:   3640, Loss function: 3.837, Average Loss: 3.895, avg. samples / sec: 53533.40
Iteration:   3640, Loss function: 2.957, Average Loss: 3.870, avg. samples / sec: 53560.16
Iteration:   3640, Loss function: 3.947, Average Loss: 3.885, avg. samples / sec: 53619.66
Iteration:   3640, Loss function: 2.840, Average Loss: 3.886, avg. samples / sec: 53593.16
Iteration:   3640, Loss function: 4.050, Average Loss: 3.878, avg. samples / sec: 53579.67
Iteration:   3640, Loss function: 3.831, Average Loss: 3.884, avg. samples / sec: 53599.64
Iteration:   3640, Loss function: 2.657, Average Loss: 3.877, avg. samples / sec: 53584.76
Iteration:   3640, Loss function: 2.596, Average Loss: 3.910, avg. samples / sec: 53560.81
Iteration:   3660, Loss function: 2.949, Average Loss: 3.875, avg. samples / sec: 53965.04
Iteration:   3660, Loss function: 2.498, Average Loss: 3.846, avg. samples / sec: 53986.04
Iteration:   3660, Loss function: 3.871, Average Loss: 3.889, avg. samples / sec: 53984.05
Iteration:   3660, Loss function: 3.200, Average Loss: 3.896, avg. samples / sec: 53943.86
Iteration:   3660, Loss function: 3.204, Average Loss: 3.847, avg. samples / sec: 53908.35
Iteration:   3660, Loss function: 3.612, Average Loss: 3.870, avg. samples / sec: 54014.82
Iteration:   3660, Loss function: 3.564, Average Loss: 3.880, avg. samples / sec: 53978.16
Iteration:   3660, Loss function: 3.040, Average Loss: 3.859, avg. samples / sec: 53976.65
Iteration:   3660, Loss function: 2.253, Average Loss: 3.846, avg. samples / sec: 54005.80
Iteration:   3660, Loss function: 3.145, Average Loss: 3.897, avg. samples / sec: 53907.05
Iteration:   3660, Loss function: 3.646, Average Loss: 3.884, avg. samples / sec: 53961.50
Iteration:   3660, Loss function: 2.550, Average Loss: 3.905, avg. samples / sec: 53977.42
Iteration:   3660, Loss function: 3.229, Average Loss: 3.877, avg. samples / sec: 53950.43
Iteration:   3660, Loss function: 3.728, Average Loss: 3.895, avg. samples / sec: 53911.32
Iteration:   3660, Loss function: 4.241, Average Loss: 3.850, avg. samples / sec: 53741.28
Iteration:   3660, Loss function: 2.506, Average Loss: 3.877, avg. samples / sec: 53964.40
Iteration:   3660, Loss function: 2.623, Average Loss: 3.860, avg. samples / sec: 53961.67
Iteration:   3660, Loss function: 2.431, Average Loss: 3.882, avg. samples / sec: 53962.37
Iteration:   3660, Loss function: 3.740, Average Loss: 3.866, avg. samples / sec: 53932.59
Iteration:   3660, Loss function: 2.600, Average Loss: 3.871, avg. samples / sec: 53952.02
Iteration:   3660, Loss function: 4.099, Average Loss: 3.861, avg. samples / sec: 53896.29
Iteration:   3660, Loss function: 3.760, Average Loss: 3.859, avg. samples / sec: 53928.44
Iteration:   3660, Loss function: 3.008, Average Loss: 3.883, avg. samples / sec: 53697.14
Iteration:   3660, Loss function: 4.724, Average Loss: 3.869, avg. samples / sec: 53925.82
Iteration:   3660, Loss function: 4.121, Average Loss: 3.871, avg. samples / sec: 53936.84
Iteration:   3660, Loss function: 3.740, Average Loss: 3.895, avg. samples / sec: 53952.87
Iteration:   3660, Loss function: 4.440, Average Loss: 3.873, avg. samples / sec: 53930.94
Iteration:   3660, Loss function: 4.000, Average Loss: 3.875, avg. samples / sec: 53901.30
Iteration:   3660, Loss function: 2.437, Average Loss: 3.873, avg. samples / sec: 53919.49
Iteration:   3660, Loss function: 2.844, Average Loss: 3.878, avg. samples / sec: 53892.27
Iteration:   3680, Loss function: 2.996, Average Loss: 3.839, avg. samples / sec: 54086.11
Iteration:   3680, Loss function: 4.531, Average Loss: 3.866, avg. samples / sec: 53754.77
Iteration:   3680, Loss function: 4.623, Average Loss: 3.874, avg. samples / sec: 53871.24
Iteration:   3680, Loss function: 3.415, Average Loss: 3.844, avg. samples / sec: 53816.04
Iteration:   3680, Loss function: 3.272, Average Loss: 3.887, avg. samples / sec: 53867.76
Iteration:   3680, Loss function: 4.020, Average Loss: 3.885, avg. samples / sec: 53829.67
Iteration:   3680, Loss function: 3.728, Average Loss: 3.878, avg. samples / sec: 53805.07
Iteration:   3680, Loss function: 4.468, Average Loss: 3.861, avg. samples / sec: 53814.81
Iteration:   3680, Loss function: 3.466, Average Loss: 3.866, avg. samples / sec: 53874.25
Iteration:   3680, Loss function: 3.024, Average Loss: 3.842, avg. samples / sec: 53827.62
Iteration:   3680, Loss function: 3.032, Average Loss: 3.866, avg. samples / sec: 53831.19
Iteration:   3680, Loss function: 2.908, Average Loss: 3.877, avg. samples / sec: 53855.53
Iteration:   3680, Loss function: 2.744, Average Loss: 3.837, avg. samples / sec: 53771.59
Iteration:   3680, Loss function: 3.087, Average Loss: 3.893, avg. samples / sec: 53817.89
Iteration:   3680, Loss function: 3.201, Average Loss: 3.852, avg. samples / sec: 53788.91
Iteration:   3680, Loss function: 3.512, Average Loss: 3.877, avg. samples / sec: 53854.09
Iteration:   3680, Loss function: 3.937, Average Loss: 3.853, avg. samples / sec: 53859.63
Iteration:   3680, Loss function: 3.051, Average Loss: 3.865, avg. samples / sec: 53838.87
Iteration:   3680, Loss function: 1.735, Average Loss: 3.867, avg. samples / sec: 53813.95
Iteration:   3680, Loss function: 4.816, Average Loss: 3.859, avg. samples / sec: 53823.98
Iteration:   3680, Loss function: 2.751, Average Loss: 3.852, avg. samples / sec: 53815.84
Iteration:   3680, Loss function: 3.728, Average Loss: 3.865, avg. samples / sec: 53862.26
Iteration:   3680, Loss function: 3.748, Average Loss: 3.871, avg. samples / sec: 53877.38
Iteration:   3680, Loss function: 3.379, Average Loss: 3.848, avg. samples / sec: 53823.28
Iteration:   3680, Loss function: 3.466, Average Loss: 3.885, avg. samples / sec: 53843.31
Iteration:   3680, Loss function: 3.926, Average Loss: 3.867, avg. samples / sec: 53853.80
Iteration:   3680, Loss function: 3.650, Average Loss: 3.874, avg. samples / sec: 53818.22
Iteration:   3680, Loss function: 3.826, Average Loss: 3.863, avg. samples / sec: 53825.95
Iteration:   3680, Loss function: 3.727, Average Loss: 3.862, avg. samples / sec: 53834.75
Iteration:   3680, Loss function: 3.427, Average Loss: 3.861, avg. samples / sec: 53781.99
:::MLL 1558640406.471 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558640406.472 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 2.793, Average Loss: 3.882, avg. samples / sec: 53545.34
Iteration:   3700, Loss function: 3.650, Average Loss: 3.868, avg. samples / sec: 53477.97
Iteration:   3700, Loss function: 3.674, Average Loss: 3.835, avg. samples / sec: 53336.61
Iteration:   3700, Loss function: 3.377, Average Loss: 3.857, avg. samples / sec: 53347.50
Iteration:   3700, Loss function: 3.363, Average Loss: 3.838, avg. samples / sec: 53444.18
Iteration:   3700, Loss function: 4.055, Average Loss: 3.878, avg. samples / sec: 53438.97
Iteration:   3700, Loss function: 2.537, Average Loss: 3.872, avg. samples / sec: 53437.25
Iteration:   3700, Loss function: 2.994, Average Loss: 3.861, avg. samples / sec: 53430.95
Iteration:   3700, Loss function: 3.158, Average Loss: 3.833, avg. samples / sec: 53453.20
Iteration:   3700, Loss function: 3.905, Average Loss: 3.849, avg. samples / sec: 53393.26
Iteration:   3700, Loss function: 3.739, Average Loss: 3.869, avg. samples / sec: 53415.74
Iteration:   3700, Loss function: 3.309, Average Loss: 3.840, avg. samples / sec: 53423.62
Iteration:   3700, Loss function: 2.773, Average Loss: 3.853, avg. samples / sec: 53650.67
Iteration:   3700, Loss function: 2.997, Average Loss: 3.866, avg. samples / sec: 53310.69
Iteration:   3700, Loss function: 2.675, Average Loss: 3.857, avg. samples / sec: 53301.98
Iteration:   3700, Loss function: 3.805, Average Loss: 3.832, avg. samples / sec: 53263.66
Iteration:   3700, Loss function: 3.209, Average Loss: 3.865, avg. samples / sec: 53446.21
Iteration:   3700, Loss function: 2.802, Average Loss: 3.850, avg. samples / sec: 53466.38
Iteration:   3700, Loss function: 3.198, Average Loss: 3.859, avg. samples / sec: 53473.28
Iteration:   3700, Loss function: 2.437, Average Loss: 3.859, avg. samples / sec: 53486.17
Iteration:   3700, Loss function: 2.885, Average Loss: 3.875, avg. samples / sec: 53477.22
Iteration:   3700, Loss function: 3.707, Average Loss: 3.859, avg. samples / sec: 53432.85
Iteration:   3700, Loss function: 5.190, Average Loss: 3.857, avg. samples / sec: 53392.12
Iteration:   3700, Loss function: 3.127, Average Loss: 3.860, avg. samples / sec: 53387.35
Iteration:   3700, Loss function: 3.434, Average Loss: 3.839, avg. samples / sec: 53363.27
Iteration:   3700, Loss function: 3.382, Average Loss: 3.843, avg. samples / sec: 53366.47
Iteration:   3700, Loss function: 1.778, Average Loss: 3.857, avg. samples / sec: 53344.65
Iteration:   3700, Loss function: 3.233, Average Loss: 3.840, avg. samples / sec: 53370.85
Iteration:   3700, Loss function: 2.966, Average Loss: 3.852, avg. samples / sec: 53428.72
Iteration:   3700, Loss function: 3.080, Average Loss: 3.850, avg. samples / sec: 53374.71
Iteration:   3720, Loss function: 2.708, Average Loss: 3.822, avg. samples / sec: 53862.49
Iteration:   3720, Loss function: 3.984, Average Loss: 3.850, avg. samples / sec: 53873.19
Iteration:   3720, Loss function: 2.686, Average Loss: 3.869, avg. samples / sec: 53832.70
Iteration:   3720, Loss function: 3.940, Average Loss: 3.828, avg. samples / sec: 53791.35
Iteration:   3720, Loss function: 3.396, Average Loss: 3.869, avg. samples / sec: 53708.66
Iteration:   3720, Loss function: 4.406, Average Loss: 3.843, avg. samples / sec: 53806.12
Iteration:   3720, Loss function: 3.382, Average Loss: 3.862, avg. samples / sec: 53737.55
Iteration:   3720, Loss function: 3.640, Average Loss: 3.858, avg. samples / sec: 53833.46
Iteration:   3720, Loss function: 2.483, Average Loss: 3.868, avg. samples / sec: 53711.95
Iteration:   3720, Loss function: 3.356, Average Loss: 3.853, avg. samples / sec: 53883.95
Iteration:   3720, Loss function: 2.611, Average Loss: 3.857, avg. samples / sec: 53770.46
Iteration:   3720, Loss function: 3.188, Average Loss: 3.832, avg. samples / sec: 53675.52
Iteration:   3720, Loss function: 3.687, Average Loss: 3.825, avg. samples / sec: 53889.22
Iteration:   3720, Loss function: 2.995, Average Loss: 3.850, avg. samples / sec: 53689.57
Iteration:   3720, Loss function: 3.440, Average Loss: 3.831, avg. samples / sec: 53696.95
Iteration:   3720, Loss function: 4.130, Average Loss: 3.850, avg. samples / sec: 53868.15
Iteration:   3720, Loss function: 3.357, Average Loss: 3.847, avg. samples / sec: 53903.28
Iteration:   3720, Loss function: 4.312, Average Loss: 3.835, avg. samples / sec: 53827.23
Iteration:   3720, Loss function: 2.926, Average Loss: 3.852, avg. samples / sec: 53815.88
Iteration:   3720, Loss function: 4.198, Average Loss: 3.832, avg. samples / sec: 53835.47
Iteration:   3720, Loss function: 3.494, Average Loss: 3.847, avg. samples / sec: 53800.37
Iteration:   3720, Loss function: 2.840, Average Loss: 3.840, avg. samples / sec: 53720.18
Iteration:   3720, Loss function: 4.117, Average Loss: 3.851, avg. samples / sec: 53723.03
Iteration:   3720, Loss function: 3.550, Average Loss: 3.857, avg. samples / sec: 53688.50
Iteration:   3720, Loss function: 4.218, Average Loss: 3.852, avg. samples / sec: 53708.35
Iteration:   3720, Loss function: 4.818, Average Loss: 3.838, avg. samples / sec: 53815.35
Iteration:   3720, Loss function: 3.363, Average Loss: 3.830, avg. samples / sec: 53810.31
Iteration:   3720, Loss function: 3.305, Average Loss: 3.854, avg. samples / sec: 53749.99
Iteration:   3720, Loss function: 2.810, Average Loss: 3.849, avg. samples / sec: 53531.57
Iteration:   3720, Loss function: 3.502, Average Loss: 3.864, avg. samples / sec: 53669.43
Iteration:   3740, Loss function: 3.989, Average Loss: 3.861, avg. samples / sec: 53656.29
Iteration:   3740, Loss function: 2.610, Average Loss: 3.815, avg. samples / sec: 53582.76
Iteration:   3740, Loss function: 4.065, Average Loss: 3.863, avg. samples / sec: 53625.13
Iteration:   3740, Loss function: 3.865, Average Loss: 3.825, avg. samples / sec: 53665.34
Iteration:   3740, Loss function: 3.428, Average Loss: 3.853, avg. samples / sec: 53619.89
Iteration:   3740, Loss function: 3.160, Average Loss: 3.831, avg. samples / sec: 53590.75
Iteration:   3740, Loss function: 2.350, Average Loss: 3.855, avg. samples / sec: 53588.24
Iteration:   3740, Loss function: 4.202, Average Loss: 3.843, avg. samples / sec: 53659.90
Iteration:   3740, Loss function: 3.985, Average Loss: 3.847, avg. samples / sec: 53620.42
Iteration:   3740, Loss function: 2.858, Average Loss: 3.845, avg. samples / sec: 53418.61
Iteration:   3740, Loss function: 2.671, Average Loss: 3.822, avg. samples / sec: 53555.68
Iteration:   3740, Loss function: 3.197, Average Loss: 3.814, avg. samples / sec: 53609.20
Iteration:   3740, Loss function: 4.142, Average Loss: 3.824, avg. samples / sec: 53580.62
Iteration:   3740, Loss function: 4.211, Average Loss: 3.849, avg. samples / sec: 53647.83
Iteration:   3740, Loss function: 2.198, Average Loss: 3.825, avg. samples / sec: 53597.80
Iteration:   3740, Loss function: 3.368, Average Loss: 3.839, avg. samples / sec: 53614.54
Iteration:   3740, Loss function: 2.892, Average Loss: 3.845, avg. samples / sec: 53399.45
Iteration:   3740, Loss function: 2.978, Average Loss: 3.818, avg. samples / sec: 53642.13
Iteration:   3740, Loss function: 2.704, Average Loss: 3.851, avg. samples / sec: 53590.22
Iteration:   3740, Loss function: 2.488, Average Loss: 3.828, avg. samples / sec: 53600.80
Iteration:   3740, Loss function: 2.728, Average Loss: 3.843, avg. samples / sec: 53608.47
Iteration:   3740, Loss function: 3.963, Average Loss: 3.843, avg. samples / sec: 53568.95
Iteration:   3740, Loss function: 3.410, Average Loss: 3.860, avg. samples / sec: 53368.69
Iteration:   3740, Loss function: 5.158, Average Loss: 3.847, avg. samples / sec: 53618.52
Iteration:   3740, Loss function: 3.082, Average Loss: 3.824, avg. samples / sec: 53557.21
Iteration:   3740, Loss function: 3.363, Average Loss: 3.841, avg. samples / sec: 53600.53
Iteration:   3740, Loss function: 4.610, Average Loss: 3.843, avg. samples / sec: 53520.54
Iteration:   3740, Loss function: 3.904, Average Loss: 3.829, avg. samples / sec: 53572.92
Iteration:   3740, Loss function: 4.306, Average Loss: 3.860, avg. samples / sec: 53608.20
Iteration:   3740, Loss function: 2.841, Average Loss: 3.837, avg. samples / sec: 53569.65
Iteration:   3760, Loss function: 3.218, Average Loss: 3.846, avg. samples / sec: 53468.71
Iteration:   3760, Loss function: 3.399, Average Loss: 3.837, avg. samples / sec: 53671.20
Iteration:   3760, Loss function: 4.072, Average Loss: 3.805, avg. samples / sec: 53438.75
Iteration:   3760, Loss function: 4.341, Average Loss: 3.847, avg. samples / sec: 53532.53
Iteration:   3760, Loss function: 3.395, Average Loss: 3.853, avg. samples / sec: 53757.89
Iteration:   3760, Loss function: 2.850, Average Loss: 3.833, avg. samples / sec: 53510.80
Iteration:   3760, Loss function: 3.679, Average Loss: 3.853, avg. samples / sec: 53458.78
Iteration:   3760, Loss function: 4.189, Average Loss: 3.807, avg. samples / sec: 53521.39
Iteration:   3760, Loss function: 2.632, Average Loss: 3.813, avg. samples / sec: 53463.32
Iteration:   3760, Loss function: 3.940, Average Loss: 3.811, avg. samples / sec: 53614.44
Iteration:   3760, Loss function: 3.968, Average Loss: 3.824, avg. samples / sec: 53487.49
Iteration:   3760, Loss function: 2.975, Average Loss: 3.843, avg. samples / sec: 53466.85
Iteration:   3760, Loss function: 3.117, Average Loss: 3.830, avg. samples / sec: 53471.07
Iteration:   3760, Loss function: 3.203, Average Loss: 3.804, avg. samples / sec: 53444.93
Iteration:   3760, Loss function: 2.328, Average Loss: 3.833, avg. samples / sec: 53528.48
Iteration:   3760, Loss function: 4.003, Average Loss: 3.837, avg. samples / sec: 53489.58
Iteration:   3760, Loss function: 3.517, Average Loss: 3.821, avg. samples / sec: 53494.86
Iteration:   3760, Loss function: 2.169, Average Loss: 3.843, avg. samples / sec: 53498.96
Iteration:   3760, Loss function: 3.853, Average Loss: 3.822, avg. samples / sec: 53478.07
Iteration:   3760, Loss function: 3.280, Average Loss: 3.812, avg. samples / sec: 53475.96
Iteration:   3760, Loss function: 3.186, Average Loss: 3.818, avg. samples / sec: 53476.55
Iteration:   3760, Loss function: 3.138, Average Loss: 3.836, avg. samples / sec: 53456.93
Iteration:   3760, Loss function: 3.825, Average Loss: 3.825, avg. samples / sec: 53496.40
Iteration:   3760, Loss function: 3.787, Average Loss: 3.836, avg. samples / sec: 53462.04
Iteration:   3760, Loss function: 3.236, Average Loss: 3.824, avg. samples / sec: 53510.44
Iteration:   3760, Loss function: 2.939, Average Loss: 3.832, avg. samples / sec: 53505.62
Iteration:   3760, Loss function: 3.165, Average Loss: 3.847, avg. samples / sec: 53503.51
Iteration:   3760, Loss function: 3.299, Average Loss: 3.830, avg. samples / sec: 53523.89
Iteration:   3760, Loss function: 3.302, Average Loss: 3.843, avg. samples / sec: 53444.38
Iteration:   3760, Loss function: 3.576, Average Loss: 3.820, avg. samples / sec: 53444.81
:::MLL 1558640408.670 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558640408.670 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 3.576, Average Loss: 3.797, avg. samples / sec: 53235.87
Iteration:   3780, Loss function: 2.207, Average Loss: 3.824, avg. samples / sec: 53131.35
Iteration:   3780, Loss function: 4.381, Average Loss: 3.844, avg. samples / sec: 53090.90
Iteration:   3780, Loss function: 4.579, Average Loss: 3.801, avg. samples / sec: 53206.19
Iteration:   3780, Loss function: 4.083, Average Loss: 3.838, avg. samples / sec: 53203.92
Iteration:   3780, Loss function: 4.064, Average Loss: 3.841, avg. samples / sec: 53160.35
Iteration:   3780, Loss function: 1.985, Average Loss: 3.803, avg. samples / sec: 53176.96
Iteration:   3780, Loss function: 3.608, Average Loss: 3.817, avg. samples / sec: 53183.26
Iteration:   3780, Loss function: 2.894, Average Loss: 3.844, avg. samples / sec: 53148.28
Iteration:   3780, Loss function: 3.154, Average Loss: 3.823, avg. samples / sec: 53149.70
Iteration:   3780, Loss function: 3.984, Average Loss: 3.844, avg. samples / sec: 53132.11
Iteration:   3780, Loss function: 3.008, Average Loss: 3.803, avg. samples / sec: 53147.56
Iteration:   3780, Loss function: 3.363, Average Loss: 3.821, avg. samples / sec: 53160.11
Iteration:   3780, Loss function: 4.709, Average Loss: 3.794, avg. samples / sec: 53219.45
Iteration:   3780, Loss function: 3.248, Average Loss: 3.809, avg. samples / sec: 53263.36
Iteration:   3780, Loss function: 2.618, Average Loss: 3.812, avg. samples / sec: 53160.89
Iteration:   3780, Loss function: 2.846, Average Loss: 3.810, avg. samples / sec: 53193.98
Iteration:   3780, Loss function: 3.546, Average Loss: 3.823, avg. samples / sec: 53136.20
Iteration:   3780, Loss function: 2.771, Average Loss: 3.808, avg. samples / sec: 53172.56
Iteration:   3780, Loss function: 2.760, Average Loss: 3.804, avg. samples / sec: 53167.95
Iteration:   3780, Loss function: 3.786, Average Loss: 3.822, avg. samples / sec: 53193.03
Iteration:   3780, Loss function: 3.520, Average Loss: 3.829, avg. samples / sec: 53142.15
Iteration:   3780, Loss function: 3.091, Average Loss: 3.819, avg. samples / sec: 53181.65
Iteration:   3780, Loss function: 4.553, Average Loss: 3.826, avg. samples / sec: 53185.04
Iteration:   3780, Loss function: 3.297, Average Loss: 3.826, avg. samples / sec: 53177.02
Iteration:   3780, Loss function: 3.740, Average Loss: 3.834, avg. samples / sec: 53138.02
Iteration:   3780, Loss function: 3.891, Average Loss: 3.816, avg. samples / sec: 53171.20
Iteration:   3780, Loss function: 3.371, Average Loss: 3.840, avg. samples / sec: 53185.00
Iteration:   3780, Loss function: 2.885, Average Loss: 3.818, avg. samples / sec: 53193.34
Iteration:   3780, Loss function: 2.500, Average Loss: 3.833, avg. samples / sec: 53191.53
Iteration:   3800, Loss function: 2.526, Average Loss: 3.832, avg. samples / sec: 53764.41
Iteration:   3800, Loss function: 3.414, Average Loss: 3.819, avg. samples / sec: 53683.49
Iteration:   3800, Loss function: 3.092, Average Loss: 3.830, avg. samples / sec: 53687.89
Iteration:   3800, Loss function: 3.361, Average Loss: 3.804, avg. samples / sec: 53700.70
Iteration:   3800, Loss function: 2.615, Average Loss: 3.837, avg. samples / sec: 53714.84
Iteration:   3800, Loss function: 2.476, Average Loss: 3.791, avg. samples / sec: 53695.15
Iteration:   3800, Loss function: 3.896, Average Loss: 3.836, avg. samples / sec: 53713.98
Iteration:   3800, Loss function: 3.944, Average Loss: 3.793, avg. samples / sec: 53662.78
Iteration:   3800, Loss function: 4.821, Average Loss: 3.831, avg. samples / sec: 53657.12
Iteration:   3800, Loss function: 2.471, Average Loss: 3.796, avg. samples / sec: 53694.50
Iteration:   3800, Loss function: 3.135, Average Loss: 3.811, avg. samples / sec: 53693.41
Iteration:   3800, Loss function: 3.675, Average Loss: 3.784, avg. samples / sec: 53662.38
Iteration:   3800, Loss function: 3.112, Average Loss: 3.816, avg. samples / sec: 53618.91
Iteration:   3800, Loss function: 3.822, Average Loss: 3.793, avg. samples / sec: 53393.86
Iteration:   3800, Loss function: 3.847, Average Loss: 3.827, avg. samples / sec: 53740.20
Iteration:   3800, Loss function: 3.791, Average Loss: 3.815, avg. samples / sec: 53691.65
Iteration:   3800, Loss function: 4.924, Average Loss: 3.799, avg. samples / sec: 53655.86
Iteration:   3800, Loss function: 3.467, Average Loss: 3.798, avg. samples / sec: 53668.16
Iteration:   3800, Loss function: 3.448, Average Loss: 3.803, avg. samples / sec: 53652.94
Iteration:   3800, Loss function: 4.159, Average Loss: 3.819, avg. samples / sec: 53663.15
Iteration:   3800, Loss function: 1.381, Average Loss: 3.817, avg. samples / sec: 53671.33
Iteration:   3800, Loss function: 3.343, Average Loss: 3.812, avg. samples / sec: 53685.11
Iteration:   3800, Loss function: 2.916, Average Loss: 3.795, avg. samples / sec: 53646.93
Iteration:   3800, Loss function: 3.887, Average Loss: 3.800, avg. samples / sec: 53628.36
Iteration:   3800, Loss function: 2.789, Average Loss: 3.830, avg. samples / sec: 53673.09
Iteration:   3800, Loss function: 3.577, Average Loss: 3.815, avg. samples / sec: 53648.32
Iteration:   3800, Loss function: 2.978, Average Loss: 3.814, avg. samples / sec: 53649.18
Iteration:   3800, Loss function: 3.084, Average Loss: 3.826, avg. samples / sec: 53674.78
Iteration:   3800, Loss function: 3.239, Average Loss: 3.812, avg. samples / sec: 53631.80
Iteration:   3800, Loss function: 2.763, Average Loss: 3.806, avg. samples / sec: 53628.91
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558640409.936 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.60s)
DONE (t=2.51s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22587
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38691
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06180
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23325
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36723
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21861
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31909
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10036
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36128
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52271
Current AP: 0.22587 AP goal: 0.23000
:::MLL 1558640413.725 eval_accuracy: {"value": 0.2258743854929757, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558640413.782 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558640413.788 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558640413.789 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 2.263, Average Loss: 3.826, avg. samples / sec: 7476.62
Iteration:   3820, Loss function: 3.561, Average Loss: 3.787, avg. samples / sec: 7479.43
Iteration:   3820, Loss function: 3.696, Average Loss: 3.809, avg. samples / sec: 7474.36
Iteration:   3820, Loss function: 4.010, Average Loss: 3.785, avg. samples / sec: 7474.20
Iteration:   3820, Loss function: 4.321, Average Loss: 3.807, avg. samples / sec: 7478.35
Iteration:   3820, Loss function: 3.563, Average Loss: 3.832, avg. samples / sec: 7473.42
Iteration:   3820, Loss function: 3.101, Average Loss: 3.797, avg. samples / sec: 7473.13
Iteration:   3820, Loss function: 2.710, Average Loss: 3.804, avg. samples / sec: 7474.00
Iteration:   3820, Loss function: 5.235, Average Loss: 3.829, avg. samples / sec: 7473.52
Iteration:   3820, Loss function: 2.897, Average Loss: 3.791, avg. samples / sec: 7478.00
Iteration:   3820, Loss function: 4.328, Average Loss: 3.782, avg. samples / sec: 7473.50
Iteration:   3820, Loss function: 3.443, Average Loss: 3.804, avg. samples / sec: 7478.69
Iteration:   3820, Loss function: 3.779, Average Loss: 3.806, avg. samples / sec: 7474.33
Iteration:   3820, Loss function: 3.373, Average Loss: 3.782, avg. samples / sec: 7472.42
Iteration:   3820, Loss function: 4.220, Average Loss: 3.780, avg. samples / sec: 7473.55
Iteration:   3820, Loss function: 2.574, Average Loss: 3.824, avg. samples / sec: 7466.45
Iteration:   3820, Loss function: 3.012, Average Loss: 3.825, avg. samples / sec: 7468.78
Iteration:   3820, Loss function: 4.412, Average Loss: 3.795, avg. samples / sec: 7474.31
Iteration:   3820, Loss function: 4.337, Average Loss: 3.816, avg. samples / sec: 7473.29
Iteration:   3820, Loss function: 4.139, Average Loss: 3.789, avg. samples / sec: 7474.17
Iteration:   3820, Loss function: 3.869, Average Loss: 3.805, avg. samples / sec: 7474.73
Iteration:   3820, Loss function: 3.614, Average Loss: 3.789, avg. samples / sec: 7474.47
Iteration:   3820, Loss function: 3.786, Average Loss: 3.793, avg. samples / sec: 7474.50
Iteration:   3820, Loss function: 2.992, Average Loss: 3.801, avg. samples / sec: 7475.01
Iteration:   3820, Loss function: 2.592, Average Loss: 3.805, avg. samples / sec: 7473.83
Iteration:   3820, Loss function: 3.184, Average Loss: 3.807, avg. samples / sec: 7474.39
Iteration:   3820, Loss function: 3.677, Average Loss: 3.804, avg. samples / sec: 7474.05
Iteration:   3820, Loss function: 2.753, Average Loss: 3.810, avg. samples / sec: 7473.70
Iteration:   3820, Loss function: 2.990, Average Loss: 3.818, avg. samples / sec: 7473.84
Iteration:   3820, Loss function: 2.023, Average Loss: 3.814, avg. samples / sec: 7473.61
:::MLL 1558640414.737 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558640414.737 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 3.024, Average Loss: 3.778, avg. samples / sec: 53305.18
Iteration:   3840, Loss function: 2.368, Average Loss: 3.816, avg. samples / sec: 53179.30
Iteration:   3840, Loss function: 3.503, Average Loss: 3.823, avg. samples / sec: 53334.45
Iteration:   3840, Loss function: 4.879, Average Loss: 3.779, avg. samples / sec: 53133.17
Iteration:   3840, Loss function: 3.525, Average Loss: 3.819, avg. samples / sec: 53307.82
Iteration:   3840, Loss function: 3.103, Average Loss: 3.797, avg. samples / sec: 53148.04
Iteration:   3840, Loss function: 2.844, Average Loss: 3.772, avg. samples / sec: 53306.15
Iteration:   3840, Loss function: 3.572, Average Loss: 3.775, avg. samples / sec: 53312.44
Iteration:   3840, Loss function: 3.240, Average Loss: 3.799, avg. samples / sec: 53208.48
Iteration:   3840, Loss function: 4.013, Average Loss: 3.819, avg. samples / sec: 53391.56
Iteration:   3840, Loss function: 4.165, Average Loss: 3.797, avg. samples / sec: 53239.53
Iteration:   3840, Loss function: 3.542, Average Loss: 3.793, avg. samples / sec: 53197.71
Iteration:   3840, Loss function: 4.507, Average Loss: 3.790, avg. samples / sec: 53196.05
Iteration:   3840, Loss function: 2.963, Average Loss: 3.799, avg. samples / sec: 53163.90
Iteration:   3840, Loss function: 4.330, Average Loss: 3.776, avg. samples / sec: 53211.89
Iteration:   3840, Loss function: 3.476, Average Loss: 3.795, avg. samples / sec: 53180.49
Iteration:   3840, Loss function: 3.417, Average Loss: 3.781, avg. samples / sec: 53315.53
Iteration:   3840, Loss function: 4.085, Average Loss: 3.794, avg. samples / sec: 53327.03
Iteration:   3840, Loss function: 2.692, Average Loss: 3.800, avg. samples / sec: 53297.44
Iteration:   3840, Loss function: 3.336, Average Loss: 3.801, avg. samples / sec: 53322.53
Iteration:   3840, Loss function: 3.341, Average Loss: 3.805, avg. samples / sec: 53338.53
Iteration:   3840, Loss function: 2.458, Average Loss: 3.796, avg. samples / sec: 53294.68
Iteration:   3840, Loss function: 2.703, Average Loss: 3.808, avg. samples / sec: 53293.01
Iteration:   3840, Loss function: 2.476, Average Loss: 3.808, avg. samples / sec: 53227.25
Iteration:   3840, Loss function: 3.446, Average Loss: 3.788, avg. samples / sec: 53193.03
Iteration:   3840, Loss function: 4.290, Average Loss: 3.812, avg. samples / sec: 53187.75
Iteration:   3840, Loss function: 3.872, Average Loss: 3.787, avg. samples / sec: 53175.59
Iteration:   3840, Loss function: 2.885, Average Loss: 3.794, avg. samples / sec: 53195.08
Iteration:   3840, Loss function: 3.707, Average Loss: 3.796, avg. samples / sec: 53177.38
Iteration:   3840, Loss function: 5.035, Average Loss: 3.780, avg. samples / sec: 53144.27
Iteration:   3860, Loss function: 4.511, Average Loss: 3.807, avg. samples / sec: 53718.63
Iteration:   3860, Loss function: 2.566, Average Loss: 3.791, avg. samples / sec: 53745.34
Iteration:   3860, Loss function: 3.523, Average Loss: 3.810, avg. samples / sec: 53676.99
Iteration:   3860, Loss function: 3.196, Average Loss: 3.815, avg. samples / sec: 53621.66
Iteration:   3860, Loss function: 3.360, Average Loss: 3.766, avg. samples / sec: 53670.63
Iteration:   3860, Loss function: 2.668, Average Loss: 3.775, avg. samples / sec: 53653.82
Iteration:   3860, Loss function: 3.515, Average Loss: 3.791, avg. samples / sec: 53714.22
Iteration:   3860, Loss function: 3.233, Average Loss: 3.769, avg. samples / sec: 53588.53
Iteration:   3860, Loss function: 4.318, Average Loss: 3.792, avg. samples / sec: 53776.78
Iteration:   3860, Loss function: 3.865, Average Loss: 3.791, avg. samples / sec: 53740.63
Iteration:   3860, Loss function: 3.169, Average Loss: 3.791, avg. samples / sec: 53794.13
Iteration:   3860, Loss function: 3.061, Average Loss: 3.764, avg. samples / sec: 53662.19
Iteration:   3860, Loss function: 3.324, Average Loss: 3.786, avg. samples / sec: 53715.19
Iteration:   3860, Loss function: 2.499, Average Loss: 3.785, avg. samples / sec: 53728.09
Iteration:   3860, Loss function: 3.612, Average Loss: 3.805, avg. samples / sec: 53693.06
Iteration:   3860, Loss function: 4.551, Average Loss: 3.767, avg. samples / sec: 53738.11
Iteration:   3860, Loss function: 3.705, Average Loss: 3.793, avg. samples / sec: 53665.62
Iteration:   3860, Loss function: 3.359, Average Loss: 3.783, avg. samples / sec: 53751.68
Iteration:   3860, Loss function: 2.847, Average Loss: 3.793, avg. samples / sec: 53707.82
Iteration:   3860, Loss function: 2.099, Average Loss: 3.808, avg. samples / sec: 53742.29
Iteration:   3860, Loss function: 3.913, Average Loss: 3.778, avg. samples / sec: 53758.50
Iteration:   3860, Loss function: 4.074, Average Loss: 3.779, avg. samples / sec: 53621.70
Iteration:   3860, Loss function: 3.185, Average Loss: 3.786, avg. samples / sec: 53612.93
Iteration:   3860, Loss function: 4.249, Average Loss: 3.773, avg. samples / sec: 53773.56
Iteration:   3860, Loss function: 4.270, Average Loss: 3.794, avg. samples / sec: 53626.25
Iteration:   3860, Loss function: 4.541, Average Loss: 3.791, avg. samples / sec: 53635.40
Iteration:   3860, Loss function: 2.779, Average Loss: 3.787, avg. samples / sec: 53727.25
Iteration:   3860, Loss function: 3.506, Average Loss: 3.795, avg. samples / sec: 53638.34
Iteration:   3860, Loss function: 3.237, Average Loss: 3.789, avg. samples / sec: 53721.04
Iteration:   3860, Loss function: 2.703, Average Loss: 3.797, avg. samples / sec: 53559.91
Iteration:   3880, Loss function: 2.720, Average Loss: 3.763, avg. samples / sec: 53764.18
Iteration:   3880, Loss function: 3.602, Average Loss: 3.761, avg. samples / sec: 53744.64
Iteration:   3880, Loss function: 3.815, Average Loss: 3.799, avg. samples / sec: 53699.90
Iteration:   3880, Loss function: 2.590, Average Loss: 3.787, avg. samples / sec: 53724.52
Iteration:   3880, Loss function: 3.740, Average Loss: 3.756, avg. samples / sec: 53728.23
Iteration:   3880, Loss function: 2.265, Average Loss: 3.783, avg. samples / sec: 53708.21
Iteration:   3880, Loss function: 3.440, Average Loss: 3.783, avg. samples / sec: 53701.00
Iteration:   3880, Loss function: 3.113, Average Loss: 3.799, avg. samples / sec: 53648.57
Iteration:   3880, Loss function: 3.644, Average Loss: 3.782, avg. samples / sec: 53698.67
Iteration:   3880, Loss function: 2.423, Average Loss: 3.780, avg. samples / sec: 53668.18
Iteration:   3880, Loss function: 3.913, Average Loss: 3.758, avg. samples / sec: 53659.90
Iteration:   3880, Loss function: 3.580, Average Loss: 3.798, avg. samples / sec: 53713.32
Iteration:   3880, Loss function: 2.812, Average Loss: 3.780, avg. samples / sec: 53501.46
Iteration:   3880, Loss function: 3.484, Average Loss: 3.759, avg. samples / sec: 53649.89
Iteration:   3880, Loss function: 3.846, Average Loss: 3.775, avg. samples / sec: 53709.80
Iteration:   3880, Loss function: 2.793, Average Loss: 3.787, avg. samples / sec: 53690.26
Iteration:   3880, Loss function: 3.685, Average Loss: 3.770, avg. samples / sec: 53715.68
Iteration:   3880, Loss function: 3.572, Average Loss: 3.779, avg. samples / sec: 53724.07
Iteration:   3880, Loss function: 2.878, Average Loss: 3.791, avg. samples / sec: 53784.05
Iteration:   3880, Loss function: 3.018, Average Loss: 3.775, avg. samples / sec: 53732.16
Iteration:   3880, Loss function: 4.661, Average Loss: 3.770, avg. samples / sec: 53696.50
Iteration:   3880, Loss function: 3.488, Average Loss: 3.789, avg. samples / sec: 53717.30
Iteration:   3880, Loss function: 3.545, Average Loss: 3.799, avg. samples / sec: 53675.19
Iteration:   3880, Loss function: 2.719, Average Loss: 3.763, avg. samples / sec: 53705.95
Iteration:   3880, Loss function: 4.131, Average Loss: 3.787, avg. samples / sec: 53670.12
Iteration:   3880, Loss function: 2.737, Average Loss: 3.784, avg. samples / sec: 53714.86
Iteration:   3880, Loss function: 3.685, Average Loss: 3.778, avg. samples / sec: 53710.50
Iteration:   3880, Loss function: 2.508, Average Loss: 3.797, avg. samples / sec: 53270.89
Iteration:   3880, Loss function: 3.502, Average Loss: 3.778, avg. samples / sec: 53676.62
Iteration:   3880, Loss function: 3.717, Average Loss: 3.774, avg. samples / sec: 53429.83
Iteration:   3900, Loss function: 3.694, Average Loss: 3.784, avg. samples / sec: 54446.35
Iteration:   3900, Loss function: 3.798, Average Loss: 3.774, avg. samples / sec: 54223.17
Iteration:   3900, Loss function: 2.384, Average Loss: 3.755, avg. samples / sec: 53998.02
Iteration:   3900, Loss function: 2.505, Average Loss: 3.746, avg. samples / sec: 53960.57
Iteration:   3900, Loss function: 3.893, Average Loss: 3.756, avg. samples / sec: 53916.09
Iteration:   3900, Loss function: 3.003, Average Loss: 3.774, avg. samples / sec: 53941.14
Iteration:   3900, Loss function: 3.798, Average Loss: 3.775, avg. samples / sec: 53966.09
Iteration:   3900, Loss function: 3.307, Average Loss: 3.785, avg. samples / sec: 53948.26
Iteration:   3900, Loss function: 2.577, Average Loss: 3.774, avg. samples / sec: 53957.12
Iteration:   3900, Loss function: 2.602, Average Loss: 3.767, avg. samples / sec: 54248.42
Iteration:   3900, Loss function: 3.507, Average Loss: 3.758, avg. samples / sec: 53956.94
Iteration:   3900, Loss function: 3.508, Average Loss: 3.792, avg. samples / sec: 53892.56
Iteration:   3900, Loss function: 3.245, Average Loss: 3.779, avg. samples / sec: 53894.54
Iteration:   3900, Loss function: 3.352, Average Loss: 3.752, avg. samples / sec: 54011.90
Iteration:   3900, Loss function: 2.961, Average Loss: 3.785, avg. samples / sec: 53936.72
Iteration:   3900, Loss function: 1.993, Average Loss: 3.771, avg. samples / sec: 53897.88
Iteration:   3900, Loss function: 2.898, Average Loss: 3.772, avg. samples / sec: 54097.59
Iteration:   3900, Loss function: 3.499, Average Loss: 3.770, avg. samples / sec: 53958.28
Iteration:   3900, Loss function: 2.980, Average Loss: 3.776, avg. samples / sec: 53995.33
Iteration:   3900, Loss function: 3.124, Average Loss: 3.778, avg. samples / sec: 53942.93
Iteration:   3900, Loss function: 3.523, Average Loss: 3.767, avg. samples / sec: 53951.50
Iteration:   3900, Loss function: 2.726, Average Loss: 3.791, avg. samples / sec: 53979.44
Iteration:   3900, Loss function: 3.070, Average Loss: 3.764, avg. samples / sec: 53967.85
Iteration:   3900, Loss function: 3.587, Average Loss: 3.763, avg. samples / sec: 53974.19
Iteration:   3900, Loss function: 4.290, Average Loss: 3.771, avg. samples / sec: 54008.03
Iteration:   3900, Loss function: 2.909, Average Loss: 3.772, avg. samples / sec: 53932.88
Iteration:   3900, Loss function: 4.005, Average Loss: 3.768, avg. samples / sec: 53986.43
Iteration:   3900, Loss function: 4.540, Average Loss: 3.786, avg. samples / sec: 53925.82
Iteration:   3900, Loss function: 3.063, Average Loss: 3.782, avg. samples / sec: 53923.90
Iteration:   3900, Loss function: 2.616, Average Loss: 3.778, avg. samples / sec: 53943.51
:::MLL 1558640416.930 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558640416.930 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 2.639, Average Loss: 3.765, avg. samples / sec: 53302.28
Iteration:   3920, Loss function: 4.717, Average Loss: 3.778, avg. samples / sec: 53259.53
Iteration:   3920, Loss function: 2.932, Average Loss: 3.745, avg. samples / sec: 53292.60
Iteration:   3920, Loss function: 2.505, Average Loss: 3.768, avg. samples / sec: 53330.78
Iteration:   3920, Loss function: 4.686, Average Loss: 3.770, avg. samples / sec: 53291.60
Iteration:   3920, Loss function: 3.404, Average Loss: 3.749, avg. samples / sec: 53297.22
Iteration:   3920, Loss function: 2.633, Average Loss: 3.746, avg. samples / sec: 53260.40
Iteration:   3920, Loss function: 3.374, Average Loss: 3.767, avg. samples / sec: 53284.32
Iteration:   3920, Loss function: 3.482, Average Loss: 3.740, avg. samples / sec: 53239.53
Iteration:   3920, Loss function: 3.256, Average Loss: 3.782, avg. samples / sec: 53260.76
Iteration:   3920, Loss function: 2.652, Average Loss: 3.773, avg. samples / sec: 53289.08
Iteration:   3920, Loss function: 3.210, Average Loss: 3.745, avg. samples / sec: 53269.76
Iteration:   3920, Loss function: 3.283, Average Loss: 3.781, avg. samples / sec: 53259.74
Iteration:   3920, Loss function: 2.313, Average Loss: 3.765, avg. samples / sec: 53274.57
Iteration:   3920, Loss function: 2.986, Average Loss: 3.766, avg. samples / sec: 53212.36
Iteration:   3920, Loss function: 3.958, Average Loss: 3.766, avg. samples / sec: 53284.73
Iteration:   3920, Loss function: 3.441, Average Loss: 3.759, avg. samples / sec: 53126.08
Iteration:   3920, Loss function: 3.483, Average Loss: 3.772, avg. samples / sec: 53310.61
Iteration:   3920, Loss function: 3.984, Average Loss: 3.784, avg. samples / sec: 53309.46
Iteration:   3920, Loss function: 3.368, Average Loss: 3.768, avg. samples / sec: 53264.71
Iteration:   3920, Loss function: 2.712, Average Loss: 3.759, avg. samples / sec: 53288.25
Iteration:   3920, Loss function: 3.055, Average Loss: 3.760, avg. samples / sec: 53288.13
Iteration:   3920, Loss function: 3.274, Average Loss: 3.765, avg. samples / sec: 53268.94
Iteration:   3920, Loss function: 3.508, Average Loss: 3.765, avg. samples / sec: 53277.11
Iteration:   3920, Loss function: 4.664, Average Loss: 3.764, avg. samples / sec: 53285.23
Iteration:   3920, Loss function: 2.528, Average Loss: 3.758, avg. samples / sec: 53266.18
Iteration:   3920, Loss function: 3.076, Average Loss: 3.760, avg. samples / sec: 53280.29
Iteration:   3920, Loss function: 3.934, Average Loss: 3.777, avg. samples / sec: 53296.78
Iteration:   3920, Loss function: 3.790, Average Loss: 3.767, avg. samples / sec: 53288.19
Iteration:   3920, Loss function: 3.615, Average Loss: 3.780, avg. samples / sec: 53243.28
Iteration:   3940, Loss function: 4.275, Average Loss: 3.769, avg. samples / sec: 53876.57
Iteration:   3940, Loss function: 3.050, Average Loss: 3.734, avg. samples / sec: 53865.72
Iteration:   3940, Loss function: 3.614, Average Loss: 3.758, avg. samples / sec: 53781.79
Iteration:   3940, Loss function: 2.594, Average Loss: 3.777, avg. samples / sec: 53927.35
Iteration:   3940, Loss function: 3.313, Average Loss: 3.777, avg. samples / sec: 53898.39
Iteration:   3940, Loss function: 1.977, Average Loss: 3.742, avg. samples / sec: 53875.58
Iteration:   3940, Loss function: 4.359, Average Loss: 3.757, avg. samples / sec: 53834.69
Iteration:   3940, Loss function: 3.285, Average Loss: 3.732, avg. samples / sec: 53857.03
Iteration:   3940, Loss function: 3.061, Average Loss: 3.755, avg. samples / sec: 53988.19
Iteration:   3940, Loss function: 2.841, Average Loss: 3.756, avg. samples / sec: 53868.85
Iteration:   3940, Loss function: 2.613, Average Loss: 3.764, avg. samples / sec: 53808.30
Iteration:   3940, Loss function: 3.477, Average Loss: 3.765, avg. samples / sec: 53841.79
Iteration:   3940, Loss function: 2.736, Average Loss: 3.756, avg. samples / sec: 53819.09
Iteration:   3940, Loss function: 2.901, Average Loss: 3.738, avg. samples / sec: 53790.51
Iteration:   3940, Loss function: 2.766, Average Loss: 3.736, avg. samples / sec: 53835.31
Iteration:   3940, Loss function: 2.032, Average Loss: 3.758, avg. samples / sec: 53839.75
Iteration:   3940, Loss function: 3.301, Average Loss: 3.755, avg. samples / sec: 53894.52
Iteration:   3940, Loss function: 4.746, Average Loss: 3.764, avg. samples / sec: 53830.50
Iteration:   3940, Loss function: 3.097, Average Loss: 3.775, avg. samples / sec: 53806.63
Iteration:   3940, Loss function: 3.234, Average Loss: 3.763, avg. samples / sec: 53789.94
Iteration:   3940, Loss function: 2.368, Average Loss: 3.752, avg. samples / sec: 53827.39
Iteration:   3940, Loss function: 2.602, Average Loss: 3.749, avg. samples / sec: 53803.20
Iteration:   3940, Loss function: 2.848, Average Loss: 3.751, avg. samples / sec: 53799.77
Iteration:   3940, Loss function: 3.960, Average Loss: 3.751, avg. samples / sec: 53829.78
Iteration:   3940, Loss function: 3.407, Average Loss: 3.758, avg. samples / sec: 53667.34
Iteration:   3940, Loss function: 3.060, Average Loss: 3.753, avg. samples / sec: 53815.49
Iteration:   3940, Loss function: 5.154, Average Loss: 3.761, avg. samples / sec: 53829.47
Iteration:   3940, Loss function: 2.337, Average Loss: 3.751, avg. samples / sec: 53800.23
Iteration:   3940, Loss function: 3.663, Average Loss: 3.771, avg. samples / sec: 53796.84
Iteration:   3940, Loss function: 2.578, Average Loss: 3.773, avg. samples / sec: 53814.13
Iteration:   3960, Loss function: 3.892, Average Loss: 3.760, avg. samples / sec: 53785.54
Iteration:   3960, Loss function: 3.387, Average Loss: 3.747, avg. samples / sec: 53845.37
Iteration:   3960, Loss function: 3.440, Average Loss: 3.727, avg. samples / sec: 53752.41
Iteration:   3960, Loss function: 3.389, Average Loss: 3.750, avg. samples / sec: 53803.90
Iteration:   3960, Loss function: 3.146, Average Loss: 3.723, avg. samples / sec: 53815.28
Iteration:   3960, Loss function: 3.423, Average Loss: 3.735, avg. samples / sec: 53775.69
Iteration:   3960, Loss function: 3.613, Average Loss: 3.755, avg. samples / sec: 53834.55
Iteration:   3960, Loss function: 3.294, Average Loss: 3.768, avg. samples / sec: 53761.29
Iteration:   3960, Loss function: 2.923, Average Loss: 3.749, avg. samples / sec: 53825.05
Iteration:   3960, Loss function: 2.629, Average Loss: 3.745, avg. samples / sec: 53802.42
Iteration:   3960, Loss function: 2.412, Average Loss: 3.738, avg. samples / sec: 53794.93
Iteration:   3960, Loss function: 3.820, Average Loss: 3.762, avg. samples / sec: 53802.94
Iteration:   3960, Loss function: 2.813, Average Loss: 3.753, avg. samples / sec: 53831.13
Iteration:   3960, Loss function: 4.555, Average Loss: 3.731, avg. samples / sec: 53802.18
Iteration:   3960, Loss function: 3.952, Average Loss: 3.773, avg. samples / sec: 53714.02
Iteration:   3960, Loss function: 3.155, Average Loss: 3.731, avg. samples / sec: 53782.08
Iteration:   3960, Loss function: 3.407, Average Loss: 3.756, avg. samples / sec: 53833.74
Iteration:   3960, Loss function: 3.877, Average Loss: 3.756, avg. samples / sec: 53814.50
Iteration:   3960, Loss function: 3.047, Average Loss: 3.752, avg. samples / sec: 53755.12
Iteration:   3960, Loss function: 3.480, Average Loss: 3.741, avg. samples / sec: 53826.45
Iteration:   3960, Loss function: 3.501, Average Loss: 3.770, avg. samples / sec: 53785.01
Iteration:   3960, Loss function: 3.866, Average Loss: 3.743, avg. samples / sec: 53807.35
Iteration:   3960, Loss function: 3.229, Average Loss: 3.742, avg. samples / sec: 53802.53
Iteration:   3960, Loss function: 2.934, Average Loss: 3.744, avg. samples / sec: 53815.08
Iteration:   3960, Loss function: 3.435, Average Loss: 3.760, avg. samples / sec: 53854.28
Iteration:   3960, Loss function: 4.250, Average Loss: 3.752, avg. samples / sec: 53806.65
Iteration:   3960, Loss function: 3.286, Average Loss: 3.740, avg. samples / sec: 53790.49
Iteration:   3960, Loss function: 2.914, Average Loss: 3.745, avg. samples / sec: 53779.16
Iteration:   3960, Loss function: 3.016, Average Loss: 3.761, avg. samples / sec: 53794.11
Iteration:   3960, Loss function: 4.797, Average Loss: 3.752, avg. samples / sec: 53699.26
:::MLL 1558640419.120 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558640419.120 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.034, Average Loss: 3.742, avg. samples / sec: 53369.56
Iteration:   3980, Loss function: 3.154, Average Loss: 3.724, avg. samples / sec: 53522.63
Iteration:   3980, Loss function: 2.416, Average Loss: 3.765, avg. samples / sec: 53540.75
Iteration:   3980, Loss function: 3.319, Average Loss: 3.721, avg. samples / sec: 53551.41
Iteration:   3980, Loss function: 3.649, Average Loss: 3.760, avg. samples / sec: 53484.26
Iteration:   3980, Loss function: 3.349, Average Loss: 3.716, avg. samples / sec: 53455.13
Iteration:   3980, Loss function: 3.949, Average Loss: 3.724, avg. samples / sec: 53342.41
Iteration:   3980, Loss function: 3.556, Average Loss: 3.754, avg. samples / sec: 53259.55
Iteration:   3980, Loss function: 4.160, Average Loss: 3.739, avg. samples / sec: 53459.57
Iteration:   3980, Loss function: 3.471, Average Loss: 3.748, avg. samples / sec: 53423.29
Iteration:   3980, Loss function: 3.952, Average Loss: 3.742, avg. samples / sec: 53356.24
Iteration:   3980, Loss function: 3.739, Average Loss: 3.746, avg. samples / sec: 53347.19
Iteration:   3980, Loss function: 3.454, Average Loss: 3.755, avg. samples / sec: 53368.06
Iteration:   3980, Loss function: 3.670, Average Loss: 3.740, avg. samples / sec: 53320.15
Iteration:   3980, Loss function: 3.108, Average Loss: 3.730, avg. samples / sec: 53337.76
Iteration:   3980, Loss function: 2.933, Average Loss: 3.723, avg. samples / sec: 53359.53
Iteration:   3980, Loss function: 4.744, Average Loss: 3.748, avg. samples / sec: 53455.92
Iteration:   3980, Loss function: 2.769, Average Loss: 3.740, avg. samples / sec: 53472.51
Iteration:   3980, Loss function: 3.647, Average Loss: 3.736, avg. samples / sec: 53486.49
Iteration:   3980, Loss function: 3.601, Average Loss: 3.745, avg. samples / sec: 53485.13
Iteration:   3980, Loss function: 3.194, Average Loss: 3.746, avg. samples / sec: 53421.81
Iteration:   3980, Loss function: 3.572, Average Loss: 3.751, avg. samples / sec: 53479.12
Iteration:   3980, Loss function: 2.512, Average Loss: 3.759, avg. samples / sec: 53415.03
Iteration:   3980, Loss function: 3.066, Average Loss: 3.741, avg. samples / sec: 53386.88
Iteration:   3980, Loss function: 3.972, Average Loss: 3.733, avg. samples / sec: 53441.40
Iteration:   3980, Loss function: 4.201, Average Loss: 3.752, avg. samples / sec: 53441.34
Iteration:   3980, Loss function: 3.330, Average Loss: 3.735, avg. samples / sec: 53353.88
Iteration:   3980, Loss function: 3.386, Average Loss: 3.736, avg. samples / sec: 53367.40
Iteration:   3980, Loss function: 3.902, Average Loss: 3.737, avg. samples / sec: 53382.13
Iteration:   3980, Loss function: 2.660, Average Loss: 3.743, avg. samples / sec: 53458.74
Iteration:   4000, Loss function: 4.910, Average Loss: 3.749, avg. samples / sec: 53926.75
Iteration:   4000, Loss function: 2.857, Average Loss: 3.717, avg. samples / sec: 53880.82
Iteration:   4000, Loss function: 3.304, Average Loss: 3.742, avg. samples / sec: 53832.16
Iteration:   4000, Loss function: 4.196, Average Loss: 3.714, avg. samples / sec: 53692.14
Iteration:   4000, Loss function: 3.921, Average Loss: 3.758, avg. samples / sec: 53686.01
Iteration:   4000, Loss function: 3.048, Average Loss: 3.735, avg. samples / sec: 53626.01
Iteration:   4000, Loss function: 2.359, Average Loss: 3.707, avg. samples / sec: 53703.56
Iteration:   4000, Loss function: 3.894, Average Loss: 3.721, avg. samples / sec: 53634.07
Iteration:   4000, Loss function: 2.652, Average Loss: 3.745, avg. samples / sec: 53828.07
Iteration:   4000, Loss function: 3.189, Average Loss: 3.755, avg. samples / sec: 53673.00
Iteration:   4000, Loss function: 3.302, Average Loss: 3.735, avg. samples / sec: 53782.12
Iteration:   4000, Loss function: 3.388, Average Loss: 3.726, avg. samples / sec: 53838.93
Iteration:   4000, Loss function: 3.231, Average Loss: 3.733, avg. samples / sec: 53816.52
Iteration:   4000, Loss function: 2.954, Average Loss: 3.728, avg. samples / sec: 53696.93
Iteration:   4000, Loss function: 3.631, Average Loss: 3.745, avg. samples / sec: 53739.56
Iteration:   4000, Loss function: 4.131, Average Loss: 3.716, avg. samples / sec: 53809.70
Iteration:   4000, Loss function: 2.698, Average Loss: 3.740, avg. samples / sec: 53763.98
Iteration:   4000, Loss function: 2.502, Average Loss: 3.752, avg. samples / sec: 53790.10
Iteration:   4000, Loss function: 3.141, Average Loss: 3.728, avg. samples / sec: 53830.15
Iteration:   4000, Loss function: 2.448, Average Loss: 3.731, avg. samples / sec: 53786.34
Iteration:   4000, Loss function: 4.168, Average Loss: 3.729, avg. samples / sec: 53828.52
Iteration:   4000, Loss function: 3.934, Average Loss: 3.734, avg. samples / sec: 53702.60
Iteration:   4000, Loss function: 3.871, Average Loss: 3.737, avg. samples / sec: 53705.89
Iteration:   4000, Loss function: 3.819, Average Loss: 3.742, avg. samples / sec: 53738.91
Iteration:   4000, Loss function: 3.066, Average Loss: 3.727, avg. samples / sec: 53695.03
Iteration:   4000, Loss function: 3.474, Average Loss: 3.738, avg. samples / sec: 53664.87
Iteration:   4000, Loss function: 3.461, Average Loss: 3.732, avg. samples / sec: 53728.48
Iteration:   4000, Loss function: 3.051, Average Loss: 3.727, avg. samples / sec: 53783.43
Iteration:   4000, Loss function: 3.647, Average Loss: 3.732, avg. samples / sec: 53791.62
Iteration:   4000, Loss function: 3.929, Average Loss: 3.746, avg. samples / sec: 53702.97
Iteration:   4020, Loss function: 2.633, Average Loss: 3.702, avg. samples / sec: 53859.40
Iteration:   4020, Loss function: 3.085, Average Loss: 3.714, avg. samples / sec: 53854.23
Iteration:   4020, Loss function: 2.763, Average Loss: 3.747, avg. samples / sec: 53861.77
Iteration:   4020, Loss function: 4.394, Average Loss: 3.737, avg. samples / sec: 53894.04
Iteration:   4020, Loss function: 3.676, Average Loss: 3.736, avg. samples / sec: 53816.72
Iteration:   4020, Loss function: 3.313, Average Loss: 3.724, avg. samples / sec: 53854.34
Iteration:   4020, Loss function: 3.748, Average Loss: 3.708, avg. samples / sec: 53798.27
Iteration:   4020, Loss function: 3.403, Average Loss: 3.728, avg. samples / sec: 53810.25
Iteration:   4020, Loss function: 3.796, Average Loss: 3.723, avg. samples / sec: 53802.30
Iteration:   4020, Loss function: 3.227, Average Loss: 3.712, avg. samples / sec: 53816.44
Iteration:   4020, Loss function: 3.871, Average Loss: 3.737, avg. samples / sec: 53770.83
Iteration:   4020, Loss function: 3.503, Average Loss: 3.725, avg. samples / sec: 53760.00
Iteration:   4020, Loss function: 2.882, Average Loss: 3.751, avg. samples / sec: 53753.11
Iteration:   4020, Loss function: 2.698, Average Loss: 3.733, avg. samples / sec: 53895.05
Iteration:   4020, Loss function: 3.067, Average Loss: 3.736, avg. samples / sec: 53827.02
Iteration:   4020, Loss function: 3.788, Average Loss: 3.745, avg. samples / sec: 53810.29
Iteration:   4020, Loss function: 3.066, Average Loss: 3.723, avg. samples / sec: 53825.81
Iteration:   4020, Loss function: 3.706, Average Loss: 3.723, avg. samples / sec: 53815.94
Iteration:   4020, Loss function: 2.367, Average Loss: 3.735, avg. samples / sec: 53844.56
Iteration:   4020, Loss function: 3.054, Average Loss: 3.729, avg. samples / sec: 53828.62
Iteration:   4020, Loss function: 4.066, Average Loss: 3.713, avg. samples / sec: 53401.55
Iteration:   4020, Loss function: 3.106, Average Loss: 3.726, avg. samples / sec: 53798.83
Iteration:   4020, Loss function: 3.073, Average Loss: 3.731, avg. samples / sec: 53809.98
Iteration:   4020, Loss function: 2.276, Average Loss: 3.723, avg. samples / sec: 53858.70
Iteration:   4020, Loss function: 3.550, Average Loss: 3.724, avg. samples / sec: 53855.06
Iteration:   4020, Loss function: 3.359, Average Loss: 3.720, avg. samples / sec: 53825.07
Iteration:   4020, Loss function: 3.019, Average Loss: 3.737, avg. samples / sec: 53344.95
Iteration:   4020, Loss function: 2.972, Average Loss: 3.730, avg. samples / sec: 53828.36
Iteration:   4020, Loss function: 3.682, Average Loss: 3.737, avg. samples / sec: 53834.79
Iteration:   4020, Loss function: 3.666, Average Loss: 3.713, avg. samples / sec: 53523.04
Iteration:   4040, Loss function: 3.151, Average Loss: 3.728, avg. samples / sec: 54293.92
Iteration:   4040, Loss function: 3.767, Average Loss: 3.718, avg. samples / sec: 53975.93
Iteration:   4040, Loss function: 2.975, Average Loss: 3.711, avg. samples / sec: 53886.87
Iteration:   4040, Loss function: 3.230, Average Loss: 3.718, avg. samples / sec: 53866.15
Iteration:   4040, Loss function: 3.007, Average Loss: 3.701, avg. samples / sec: 53866.11
Iteration:   4040, Loss function: 2.475, Average Loss: 3.697, avg. samples / sec: 53801.50
Iteration:   4040, Loss function: 2.712, Average Loss: 3.716, avg. samples / sec: 53860.49
Iteration:   4040, Loss function: 3.544, Average Loss: 3.734, avg. samples / sec: 53820.01
Iteration:   4040, Loss function: 2.840, Average Loss: 3.699, avg. samples / sec: 53882.24
Iteration:   4040, Loss function: 2.929, Average Loss: 3.736, avg. samples / sec: 53803.35
Iteration:   4040, Loss function: 2.844, Average Loss: 3.713, avg. samples / sec: 53879.64
Iteration:   4040, Loss function: 2.979, Average Loss: 3.744, avg. samples / sec: 53885.95
Iteration:   4040, Loss function: 4.720, Average Loss: 3.732, avg. samples / sec: 53792.81
Iteration:   4040, Loss function: 3.282, Average Loss: 3.709, avg. samples / sec: 54128.16
Iteration:   4040, Loss function: 3.078, Average Loss: 3.728, avg. samples / sec: 53850.63
Iteration:   4040, Loss function: 3.901, Average Loss: 3.714, avg. samples / sec: 54007.23
Iteration:   4040, Loss function: 2.975, Average Loss: 3.719, avg. samples / sec: 53907.07
Iteration:   4040, Loss function: 3.150, Average Loss: 3.724, avg. samples / sec: 53844.42
Iteration:   4040, Loss function: 3.672, Average Loss: 3.721, avg. samples / sec: 53890.01
Iteration:   4040, Loss function: 3.495, Average Loss: 3.725, avg. samples / sec: 53895.90
Iteration:   4040, Loss function: 2.806, Average Loss: 3.738, avg. samples / sec: 53860.64
Iteration:   4040, Loss function: 4.213, Average Loss: 3.724, avg. samples / sec: 53891.26
Iteration:   4040, Loss function: 4.213, Average Loss: 3.722, avg. samples / sec: 53852.07
Iteration:   4040, Loss function: 1.911, Average Loss: 3.710, avg. samples / sec: 53864.03
Iteration:   4040, Loss function: 4.621, Average Loss: 3.724, avg. samples / sec: 53863.76
Iteration:   4040, Loss function: 3.268, Average Loss: 3.725, avg. samples / sec: 53789.71
Iteration:   4040, Loss function: 3.133, Average Loss: 3.716, avg. samples / sec: 53846.48
Iteration:   4040, Loss function: 3.958, Average Loss: 3.730, avg. samples / sec: 53820.85
Iteration:   4040, Loss function: 4.422, Average Loss: 3.705, avg. samples / sec: 53818.53
Iteration:   4040, Loss function: 4.105, Average Loss: 3.729, avg. samples / sec: 53861.46
:::MLL 1558640421.309 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558640421.309 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 3.366, Average Loss: 3.719, avg. samples / sec: 53552.26
Iteration:   4060, Loss function: 2.484, Average Loss: 3.710, avg. samples / sec: 53504.58
Iteration:   4060, Loss function: 3.378, Average Loss: 3.705, avg. samples / sec: 53499.28
Iteration:   4060, Loss function: 4.977, Average Loss: 3.713, avg. samples / sec: 53555.90
Iteration:   4060, Loss function: 1.633, Average Loss: 3.726, avg. samples / sec: 53543.84
Iteration:   4060, Loss function: 2.644, Average Loss: 3.687, avg. samples / sec: 53541.82
Iteration:   4060, Loss function: 2.848, Average Loss: 3.709, avg. samples / sec: 53507.10
Iteration:   4060, Loss function: 3.249, Average Loss: 3.723, avg. samples / sec: 53557.29
Iteration:   4060, Loss function: 2.820, Average Loss: 3.696, avg. samples / sec: 53522.45
Iteration:   4060, Loss function: 2.863, Average Loss: 3.726, avg. samples / sec: 53529.74
Iteration:   4060, Loss function: 3.809, Average Loss: 3.704, avg. samples / sec: 53520.86
Iteration:   4060, Loss function: 3.422, Average Loss: 3.702, avg. samples / sec: 53532.96
Iteration:   4060, Loss function: 2.938, Average Loss: 3.739, avg. samples / sec: 53510.15
Iteration:   4060, Loss function: 4.123, Average Loss: 3.733, avg. samples / sec: 53501.54
Iteration:   4060, Loss function: 3.278, Average Loss: 3.695, avg. samples / sec: 53465.63
Iteration:   4060, Loss function: 3.262, Average Loss: 3.713, avg. samples / sec: 53542.05
Iteration:   4060, Loss function: 3.838, Average Loss: 3.720, avg. samples / sec: 53565.21
Iteration:   4060, Loss function: 4.390, Average Loss: 3.716, avg. samples / sec: 53504.06
Iteration:   4060, Loss function: 3.015, Average Loss: 3.704, avg. samples / sec: 53536.86
Iteration:   4060, Loss function: 4.016, Average Loss: 3.729, avg. samples / sec: 53504.20
Iteration:   4060, Loss function: 3.222, Average Loss: 3.713, avg. samples / sec: 53488.77
Iteration:   4060, Loss function: 3.617, Average Loss: 3.713, avg. samples / sec: 53459.38
Iteration:   4060, Loss function: 2.453, Average Loss: 3.703, avg. samples / sec: 53360.57
Iteration:   4060, Loss function: 3.513, Average Loss: 3.698, avg. samples / sec: 53552.20
Iteration:   4060, Loss function: 4.546, Average Loss: 3.723, avg. samples / sec: 53506.86
Iteration:   4060, Loss function: 3.657, Average Loss: 3.718, avg. samples / sec: 53510.37
Iteration:   4060, Loss function: 3.546, Average Loss: 3.710, avg. samples / sec: 53521.53
Iteration:   4060, Loss function: 3.510, Average Loss: 3.725, avg. samples / sec: 53521.27
Iteration:   4060, Loss function: 4.434, Average Loss: 3.718, avg. samples / sec: 53515.25
Iteration:   4060, Loss function: 2.029, Average Loss: 3.714, avg. samples / sec: 53454.03
Iteration:   4080, Loss function: 3.139, Average Loss: 3.711, avg. samples / sec: 53795.54
Iteration:   4080, Loss function: 3.577, Average Loss: 3.701, avg. samples / sec: 53828.73
Iteration:   4080, Loss function: 4.080, Average Loss: 3.679, avg. samples / sec: 53868.27
Iteration:   4080, Loss function: 3.537, Average Loss: 3.696, avg. samples / sec: 53776.17
Iteration:   4080, Loss function: 1.731, Average Loss: 3.692, avg. samples / sec: 53829.51
Iteration:   4080, Loss function: 2.740, Average Loss: 3.690, avg. samples / sec: 53860.06
Iteration:   4080, Loss function: 4.482, Average Loss: 3.734, avg. samples / sec: 53841.00
Iteration:   4080, Loss function: 3.331, Average Loss: 3.725, avg. samples / sec: 53832.00
Iteration:   4080, Loss function: 2.832, Average Loss: 3.695, avg. samples / sec: 53819.46
Iteration:   4080, Loss function: 3.203, Average Loss: 3.700, avg. samples / sec: 53761.23
Iteration:   4080, Loss function: 4.285, Average Loss: 3.696, avg. samples / sec: 53788.97
Iteration:   4080, Loss function: 2.583, Average Loss: 3.716, avg. samples / sec: 53736.88
Iteration:   4080, Loss function: 3.608, Average Loss: 3.701, avg. samples / sec: 53749.83
Iteration:   4080, Loss function: 2.286, Average Loss: 3.714, avg. samples / sec: 53751.47
Iteration:   4080, Loss function: 3.577, Average Loss: 3.716, avg. samples / sec: 53752.21
Iteration:   4080, Loss function: 2.286, Average Loss: 3.690, avg. samples / sec: 53866.91
Iteration:   4080, Loss function: 3.927, Average Loss: 3.705, avg. samples / sec: 53797.29
Iteration:   4080, Loss function: 3.864, Average Loss: 3.721, avg. samples / sec: 53811.73
Iteration:   4080, Loss function: 2.935, Average Loss: 3.709, avg. samples / sec: 53799.16
Iteration:   4080, Loss function: 3.932, Average Loss: 3.712, avg. samples / sec: 53776.10
Iteration:   4080, Loss function: 3.097, Average Loss: 3.695, avg. samples / sec: 53805.96
Iteration:   4080, Loss function: 3.103, Average Loss: 3.705, avg. samples / sec: 53795.42
Iteration:   4080, Loss function: 3.961, Average Loss: 3.710, avg. samples / sec: 53832.68
Iteration:   4080, Loss function: 4.608, Average Loss: 3.698, avg. samples / sec: 53761.58
Iteration:   4080, Loss function: 4.009, Average Loss: 3.701, avg. samples / sec: 53792.26
Iteration:   4080, Loss function: 2.400, Average Loss: 3.717, avg. samples / sec: 53779.72
Iteration:   4080, Loss function: 2.987, Average Loss: 3.707, avg. samples / sec: 53752.91
Iteration:   4080, Loss function: 2.735, Average Loss: 3.710, avg. samples / sec: 53770.99
Iteration:   4080, Loss function: 3.495, Average Loss: 3.710, avg. samples / sec: 53810.54
Iteration:   4080, Loss function: 2.715, Average Loss: 3.715, avg. samples / sec: 53753.15
Iteration:   4100, Loss function: 3.851, Average Loss: 3.705, avg. samples / sec: 53806.59
Iteration:   4100, Loss function: 3.239, Average Loss: 3.692, avg. samples / sec: 53777.97
Iteration:   4100, Loss function: 3.711, Average Loss: 3.691, avg. samples / sec: 53819.19
Iteration:   4100, Loss function: 3.220, Average Loss: 3.705, avg. samples / sec: 53870.33
Iteration:   4100, Loss function: 4.530, Average Loss: 3.676, avg. samples / sec: 53734.11
Iteration:   4100, Loss function: 3.326, Average Loss: 3.690, avg. samples / sec: 53856.19
Iteration:   4100, Loss function: 3.306, Average Loss: 3.695, avg. samples / sec: 53837.34
Iteration:   4100, Loss function: 4.185, Average Loss: 3.696, avg. samples / sec: 53807.05
Iteration:   4100, Loss function: 2.486, Average Loss: 3.686, avg. samples / sec: 53778.07
Iteration:   4100, Loss function: 3.105, Average Loss: 3.717, avg. samples / sec: 53788.87
Iteration:   4100, Loss function: 3.315, Average Loss: 3.684, avg. samples / sec: 53771.22
Iteration:   4100, Loss function: 3.117, Average Loss: 3.706, avg. samples / sec: 53818.49
Iteration:   4100, Loss function: 4.020, Average Loss: 3.705, avg. samples / sec: 53828.34
Iteration:   4100, Loss function: 5.355, Average Loss: 3.730, avg. samples / sec: 53747.49
Iteration:   4100, Loss function: 3.231, Average Loss: 3.686, avg. samples / sec: 53739.95
Iteration:   4100, Loss function: 4.277, Average Loss: 3.710, avg. samples / sec: 53834.69
Iteration:   4100, Loss function: 2.858, Average Loss: 3.699, avg. samples / sec: 53878.36
Iteration:   4100, Loss function: 2.836, Average Loss: 3.697, avg. samples / sec: 53786.84
Iteration:   4100, Loss function: 3.510, Average Loss: 3.714, avg. samples / sec: 53807.93
Iteration:   4100, Loss function: 2.462, Average Loss: 3.696, avg. samples / sec: 53820.44
Iteration:   4100, Loss function: 3.222, Average Loss: 3.706, avg. samples / sec: 53849.93
Iteration:   4100, Loss function: 4.126, Average Loss: 3.703, avg. samples / sec: 53768.02
Iteration:   4100, Loss function: 2.730, Average Loss: 3.704, avg. samples / sec: 53848.02
Iteration:   4100, Loss function: 3.132, Average Loss: 3.690, avg. samples / sec: 53803.29
Iteration:   4100, Loss function: 3.983, Average Loss: 3.699, avg. samples / sec: 53800.88
Iteration:   4100, Loss function: 3.446, Average Loss: 3.704, avg. samples / sec: 53815.80
Iteration:   4100, Loss function: 4.064, Average Loss: 3.705, avg. samples / sec: 53785.42
Iteration:   4100, Loss function: 3.992, Average Loss: 3.683, avg. samples / sec: 53708.47
Iteration:   4100, Loss function: 2.888, Average Loss: 3.707, avg. samples / sec: 53794.37
Iteration:   4100, Loss function: 3.759, Average Loss: 3.693, avg. samples / sec: 53747.51
:::MLL 1558640423.498 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558640423.498 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 2.996, Average Loss: 3.687, avg. samples / sec: 53651.51
Iteration:   4120, Loss function: 3.970, Average Loss: 3.698, avg. samples / sec: 53505.11
Iteration:   4120, Loss function: 3.009, Average Loss: 3.685, avg. samples / sec: 53640.64
Iteration:   4120, Loss function: 3.881, Average Loss: 3.671, avg. samples / sec: 53598.98
Iteration:   4120, Loss function: 3.191, Average Loss: 3.675, avg. samples / sec: 53621.56
Iteration:   4120, Loss function: 3.285, Average Loss: 3.712, avg. samples / sec: 53588.77
Iteration:   4120, Loss function: 4.571, Average Loss: 3.685, avg. samples / sec: 53556.43
Iteration:   4120, Loss function: 3.249, Average Loss: 3.696, avg. samples / sec: 53594.03
Iteration:   4120, Loss function: 4.172, Average Loss: 3.725, avg. samples / sec: 53590.53
Iteration:   4120, Loss function: 3.310, Average Loss: 3.681, avg. samples / sec: 53533.69
Iteration:   4120, Loss function: 2.781, Average Loss: 3.699, avg. samples / sec: 53548.58
Iteration:   4120, Loss function: 3.847, Average Loss: 3.705, avg. samples / sec: 53474.82
Iteration:   4120, Loss function: 2.821, Average Loss: 3.692, avg. samples / sec: 53487.81
Iteration:   4120, Loss function: 3.796, Average Loss: 3.691, avg. samples / sec: 53420.50
Iteration:   4120, Loss function: 2.680, Average Loss: 3.676, avg. samples / sec: 53469.00
Iteration:   4120, Loss function: 4.119, Average Loss: 3.710, avg. samples / sec: 53609.42
Iteration:   4120, Loss function: 2.839, Average Loss: 3.692, avg. samples / sec: 53644.01
Iteration:   4120, Loss function: 3.045, Average Loss: 3.703, avg. samples / sec: 53630.89
Iteration:   4120, Loss function: 4.020, Average Loss: 3.701, avg. samples / sec: 53652.22
Iteration:   4120, Loss function: 4.513, Average Loss: 3.687, avg. samples / sec: 53639.05
Iteration:   4120, Loss function: 3.406, Average Loss: 3.702, avg. samples / sec: 53626.76
Iteration:   4120, Loss function: 2.435, Average Loss: 3.693, avg. samples / sec: 53616.64
Iteration:   4120, Loss function: 3.581, Average Loss: 3.691, avg. samples / sec: 53517.93
Iteration:   4120, Loss function: 3.959, Average Loss: 3.691, avg. samples / sec: 53517.47
Iteration:   4120, Loss function: 3.186, Average Loss: 3.689, avg. samples / sec: 53530.96
Iteration:   4120, Loss function: 2.589, Average Loss: 3.703, avg. samples / sec: 53495.91
Iteration:   4120, Loss function: 3.588, Average Loss: 3.682, avg. samples / sec: 53567.04
Iteration:   4120, Loss function: 3.565, Average Loss: 3.681, avg. samples / sec: 53559.06
Iteration:   4120, Loss function: 3.609, Average Loss: 3.695, avg. samples / sec: 53520.41
Iteration:   4120, Loss function: 3.122, Average Loss: 3.692, avg. samples / sec: 53492.40
Iteration:   4140, Loss function: 3.125, Average Loss: 3.687, avg. samples / sec: 53789.98
Iteration:   4140, Loss function: 3.205, Average Loss: 3.675, avg. samples / sec: 53717.71
Iteration:   4140, Loss function: 2.988, Average Loss: 3.680, avg. samples / sec: 53681.63
Iteration:   4140, Loss function: 2.841, Average Loss: 3.659, avg. samples / sec: 53737.68
Iteration:   4140, Loss function: 2.879, Average Loss: 3.720, avg. samples / sec: 53792.18
Iteration:   4140, Loss function: 3.080, Average Loss: 3.693, avg. samples / sec: 53814.79
Iteration:   4140, Loss function: 3.521, Average Loss: 3.699, avg. samples / sec: 53832.65
Iteration:   4140, Loss function: 3.664, Average Loss: 3.674, avg. samples / sec: 53756.25
Iteration:   4140, Loss function: 2.674, Average Loss: 3.683, avg. samples / sec: 53832.76
Iteration:   4140, Loss function: 4.023, Average Loss: 3.674, avg. samples / sec: 53707.80
Iteration:   4140, Loss function: 2.569, Average Loss: 3.706, avg. samples / sec: 53735.30
Iteration:   4140, Loss function: 3.449, Average Loss: 3.680, avg. samples / sec: 53889.12
Iteration:   4140, Loss function: 3.729, Average Loss: 3.676, avg. samples / sec: 53782.51
Iteration:   4140, Loss function: 2.825, Average Loss: 3.666, avg. samples / sec: 53867.61
Iteration:   4140, Loss function: 3.275, Average Loss: 3.681, avg. samples / sec: 53834.38
Iteration:   4140, Loss function: 4.549, Average Loss: 3.691, avg. samples / sec: 53744.48
Iteration:   4140, Loss function: 4.228, Average Loss: 3.692, avg. samples / sec: 53552.47
Iteration:   4140, Loss function: 3.816, Average Loss: 3.700, avg. samples / sec: 53813.37
Iteration:   4140, Loss function: 3.778, Average Loss: 3.687, avg. samples / sec: 53787.99
Iteration:   4140, Loss function: 2.916, Average Loss: 3.672, avg. samples / sec: 53810.27
Iteration:   4140, Loss function: 2.580, Average Loss: 3.704, avg. samples / sec: 53701.37
Iteration:   4140, Loss function: 3.248, Average Loss: 3.697, avg. samples / sec: 53713.49
Iteration:   4140, Loss function: 4.231, Average Loss: 3.681, avg. samples / sec: 53781.07
Iteration:   4140, Loss function: 2.749, Average Loss: 3.679, avg. samples / sec: 53716.68
Iteration:   4140, Loss function: 2.851, Average Loss: 3.678, avg. samples / sec: 53797.62
Iteration:   4140, Loss function: 4.052, Average Loss: 3.694, avg. samples / sec: 53717.48
Iteration:   4140, Loss function: 3.538, Average Loss: 3.687, avg. samples / sec: 53840.78
Iteration:   4140, Loss function: 3.260, Average Loss: 3.688, avg. samples / sec: 53801.81
Iteration:   4140, Loss function: 3.937, Average Loss: 3.691, avg. samples / sec: 53674.27
Iteration:   4140, Loss function: 3.439, Average Loss: 3.685, avg. samples / sec: 53682.29
Iteration:   4160, Loss function: 3.325, Average Loss: 3.695, avg. samples / sec: 53750.77
Iteration:   4160, Loss function: 3.595, Average Loss: 3.662, avg. samples / sec: 53704.73
Iteration:   4160, Loss function: 3.060, Average Loss: 3.676, avg. samples / sec: 53733.70
Iteration:   4160, Loss function: 3.088, Average Loss: 3.672, avg. samples / sec: 53680.65
Iteration:   4160, Loss function: 2.317, Average Loss: 3.666, avg. samples / sec: 53714.96
Iteration:   4160, Loss function: 3.855, Average Loss: 3.696, avg. samples / sec: 53710.03
Iteration:   4160, Loss function: 3.398, Average Loss: 3.660, avg. samples / sec: 53744.48
Iteration:   4160, Loss function: 4.375, Average Loss: 3.710, avg. samples / sec: 53672.82
Iteration:   4160, Loss function: 4.162, Average Loss: 3.686, avg. samples / sec: 53680.89
Iteration:   4160, Loss function: 3.295, Average Loss: 3.669, avg. samples / sec: 53694.50
Iteration:   4160, Loss function: 3.154, Average Loss: 3.672, avg. samples / sec: 53572.90
Iteration:   4160, Loss function: 4.697, Average Loss: 3.669, avg. samples / sec: 53684.21
Iteration:   4160, Loss function: 3.264, Average Loss: 3.690, avg. samples / sec: 53889.16
Iteration:   4160, Loss function: 2.452, Average Loss: 3.685, avg. samples / sec: 53823.40
Iteration:   4160, Loss function: 2.889, Average Loss: 3.693, avg. samples / sec: 53748.83
Iteration:   4160, Loss function: 3.059, Average Loss: 3.682, avg. samples / sec: 53740.01
Iteration:   4160, Loss function: 2.842, Average Loss: 3.670, avg. samples / sec: 53745.94
Iteration:   4160, Loss function: 3.683, Average Loss: 3.676, avg. samples / sec: 53719.40
Iteration:   4160, Loss function: 3.162, Average Loss: 3.670, avg. samples / sec: 53661.62
Iteration:   4160, Loss function: 4.023, Average Loss: 3.672, avg. samples / sec: 53699.26
Iteration:   4160, Loss function: 3.833, Average Loss: 3.673, avg. samples / sec: 53720.84
Iteration:   4160, Loss function: 3.268, Average Loss: 3.694, avg. samples / sec: 53692.06
Iteration:   4160, Loss function: 3.876, Average Loss: 3.691, avg. samples / sec: 53691.16
Iteration:   4160, Loss function: 2.871, Average Loss: 3.687, avg. samples / sec: 53731.04
Iteration:   4160, Loss function: 3.067, Average Loss: 3.681, avg. samples / sec: 53732.82
Iteration:   4160, Loss function: 3.968, Average Loss: 3.679, avg. samples / sec: 53700.08
Iteration:   4160, Loss function: 3.641, Average Loss: 3.683, avg. samples / sec: 53716.46
Iteration:   4160, Loss function: 2.070, Average Loss: 3.679, avg. samples / sec: 53264.75
Iteration:   4160, Loss function: 1.985, Average Loss: 3.689, avg. samples / sec: 53663.91
Iteration:   4160, Loss function: 3.323, Average Loss: 3.674, avg. samples / sec: 53397.12
Iteration:   4180, Loss function: 3.125, Average Loss: 3.673, avg. samples / sec: 54316.19
Iteration:   4180, Loss function: 2.591, Average Loss: 3.669, avg. samples / sec: 53870.23
Iteration:   4180, Loss function: 3.320, Average Loss: 3.668, avg. samples / sec: 53868.56
Iteration:   4180, Loss function: 3.901, Average Loss: 3.659, avg. samples / sec: 53877.38
Iteration:   4180, Loss function: 3.476, Average Loss: 3.657, avg. samples / sec: 53826.63
Iteration:   4180, Loss function: 4.246, Average Loss: 3.680, avg. samples / sec: 53933.62
Iteration:   4180, Loss function: 4.206, Average Loss: 3.703, avg. samples / sec: 53872.52
Iteration:   4180, Loss function: 3.514, Average Loss: 3.652, avg. samples / sec: 53839.87
Iteration:   4180, Loss function: 3.819, Average Loss: 3.692, avg. samples / sec: 53769.02
Iteration:   4180, Loss function: 3.457, Average Loss: 3.660, avg. samples / sec: 53839.15
Iteration:   4180, Loss function: 4.228, Average Loss: 3.668, avg. samples / sec: 54136.95
Iteration:   4180, Loss function: 4.186, Average Loss: 3.679, avg. samples / sec: 53822.44
Iteration:   4180, Loss function: 3.132, Average Loss: 3.689, avg. samples / sec: 53798.07
Iteration:   4180, Loss function: 3.575, Average Loss: 3.664, avg. samples / sec: 53782.65
Iteration:   4180, Loss function: 3.016, Average Loss: 3.659, avg. samples / sec: 53793.94
Iteration:   4180, Loss function: 2.525, Average Loss: 3.676, avg. samples / sec: 53766.77
Iteration:   4180, Loss function: 3.369, Average Loss: 3.665, avg. samples / sec: 53883.56
Iteration:   4180, Loss function: 4.088, Average Loss: 3.688, avg. samples / sec: 53811.67
Iteration:   4180, Loss function: 3.652, Average Loss: 3.665, avg. samples / sec: 53820.18
Iteration:   4180, Loss function: 4.189, Average Loss: 3.671, avg. samples / sec: 53847.69
Iteration:   4180, Loss function: 2.612, Average Loss: 3.675, avg. samples / sec: 53797.86
Iteration:   4180, Loss function: 2.198, Average Loss: 3.666, avg. samples / sec: 53830.31
Iteration:   4180, Loss function: 3.354, Average Loss: 3.666, avg. samples / sec: 53803.12
Iteration:   4180, Loss function: 3.505, Average Loss: 3.676, avg. samples / sec: 53844.85
Iteration:   4180, Loss function: 3.920, Average Loss: 3.691, avg. samples / sec: 53822.25
Iteration:   4180, Loss function: 3.314, Average Loss: 3.680, avg. samples / sec: 53874.00
Iteration:   4180, Loss function: 4.538, Average Loss: 3.689, avg. samples / sec: 53814.61
Iteration:   4180, Loss function: 3.866, Average Loss: 3.672, avg. samples / sec: 53829.63
Iteration:   4180, Loss function: 3.127, Average Loss: 3.679, avg. samples / sec: 53814.44
Iteration:   4180, Loss function: 2.888, Average Loss: 3.682, avg. samples / sec: 53791.09
:::MLL 1558640425.688 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558640425.689 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558640425.759 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.61s)
DONE (t=2.50s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23024
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39206
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23639
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06210
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24069
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37039
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22266
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32465
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34052
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10180
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52993
Current AP: 0.23024 AP goal: 0.23000
:::MLL 1558640429.546 eval_accuracy: {"value": 0.23024146708637852, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558640429.678 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558640429.685 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558640430.235 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 07:40:39 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:29 PM
ENDING TIMING RUN AT 2019-05-23 07:40:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:23 PM
ENDING TIMING RUN AT 2019-05-23 07:40:41 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:30 PM
ENDING TIMING RUN AT 2019-05-23 07:40:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:23 PM
ENDING TIMING RUN AT 2019-05-23 07:40:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:22 PM
ENDING TIMING RUN AT 2019-05-23 07:40:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:24 PM
ENDING TIMING RUN AT 2019-05-23 07:40:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:26 PM
ENDING TIMING RUN AT 2019-05-23 07:40:41 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:31 PM
ENDING TIMING RUN AT 2019-05-23 07:40:32 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:22 PM
ENDING TIMING RUN AT 2019-05-23 07:40:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:24 PM
ENDING TIMING RUN AT 2019-05-23 07:40:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:23 PM
ENDING TIMING RUN AT 2019-05-23 07:40:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:24 PM
ENDING TIMING RUN AT 2019-05-23 07:40:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:23 PM
ENDING TIMING RUN AT 2019-05-23 07:40:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:24 PM
ENDING TIMING RUN AT 2019-05-23 07:40:40 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:29 PM
ENDING TIMING RUN AT 2019-05-23 07:40:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:24 PM
ENDING TIMING RUN AT 2019-05-23 07:40:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:23 PM
ENDING TIMING RUN AT 2019-05-23 07:40:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:25 PM
ENDING TIMING RUN AT 2019-05-23 07:40:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:25 PM
ENDING TIMING RUN AT 2019-05-23 07:40:39 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:29 PM
ENDING TIMING RUN AT 2019-05-23 07:40:32 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:22 PM
ENDING TIMING RUN AT 2019-05-23 07:40:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:27 PM
ENDING TIMING RUN AT 2019-05-23 07:40:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:25 PM
ENDING TIMING RUN AT 2019-05-23 07:40:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:24 PM
ENDING TIMING RUN AT 2019-05-23 07:40:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:26 PM
ENDING TIMING RUN AT 2019-05-23 07:40:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:23 PM
ENDING TIMING RUN AT 2019-05-23 07:40:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:24 PM
ENDING TIMING RUN AT 2019-05-23 07:40:39 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:28 PM
ENDING TIMING RUN AT 2019-05-23 07:40:39 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 07:37:29 PM
ENDING TIMING RUN AT 2019-05-23 07:40:37 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:37:26 PM
