Beginning trial 3 of 5
Gathering sys log on sc-sdgx-407
:::MLL 1558640470.257 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558640470.258 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558640470.259 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558640470.260 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558640470.260 submission_platform: {"value": "30xDGX-1 with V100", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558640470.261 submission_entry: {"value": "{'hardware': 'DGX-1 with V100', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.2 LTS / NVIDIA DGX Server 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz', 'num_cores': '40', 'num_vcpus': '80', 'accelerator': 'Tesla V100-SXM2-16GB', 'num_accelerators': '8', 'sys_mem_size': '503 GB', 'sys_storage_type': 'SATA SSD', 'sys_storage_size': '1x 7T + 1x 446.6G', 'cpu_accel_interconnect': 'QPI', 'network_card': 'Mellanox Technologies MT27700 Family [ConnectX-4]', 'num_network_cards': '4', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558640470.262 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558640470.262 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558640525.144 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640514.778 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640513.619 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640521.004 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640513.123 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640513.699 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640513.875 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640516.119 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640517.022 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640512.130 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640518.321 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640515.713 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640516.038 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640515.535 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640513.878 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640513.187 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640513.775 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640513.382 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640518.653 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640512.012 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640515.750 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640518.928 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640514.164 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640516.237 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640518.486 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640525.024 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640517.849 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640518.359 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640516.885 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640525.123 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node sc-sdgx-407
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-408
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-414
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-407
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-408
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-415
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-407 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-408 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-416
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-414
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-415
+ set +x
Launching on node sc-sdgx-417
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-414 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-418
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-416
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-415 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-417
+ set +x
Launching on node sc-sdgx-423
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-416 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-417 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-418
Launching on node sc-sdgx-424
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-418 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-425
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-423
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-424
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-426
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-423 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-424 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-427
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-425
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-426
+ set +x
Launching on node sc-sdgx-433
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-425 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-434
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-427
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-426 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-433
+ set +x
Launching on node sc-sdgx-435
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-427 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-433 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-434
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-436
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-441
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-434 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-435
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-442
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-436
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-435 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-443
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-441
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-436 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-444
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-442
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-441 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-443
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-628
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-442 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-443 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ set +x
Launching on node sc-sdgx-629
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-444
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-628
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-630
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-444 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-628 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-629
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-631
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-629 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-630
Launching on node sc-sdgx-632
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-631
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-638
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-630 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-631 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-632
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-639
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-632 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-638
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-640
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-638 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-639
Launching on node sc-sdgx-641
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-639 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-646
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-640
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-641
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-640 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-641 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-646
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-646 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:42:10 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:07 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:42:10 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:42:03 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:42:04 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:07 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:00 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:02 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:04 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:02 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:42:00 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:42:05 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:42:04 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:42:02 PM
STARTING TIMING RUN AT 2019-05-23 07:42:01 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:42:04 PM
running benchmark
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:42:05 PM
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:02 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:02 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:14 PM
running benchmark
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:06 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:42:04 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:04 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:00 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:42:02 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:02 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:03 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:04 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:42:01 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558640527.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.788 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.788 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.788 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.788 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.997 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.997 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.997 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.997 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.997 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.997 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.998 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.999 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640528.085 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.085 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.085 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.085 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.397 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.397 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.397 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.397 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.398 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.399 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.399 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.400 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.628 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.628 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.628 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.629 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.630 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.630 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.630 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.631 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640524.336 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.336 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.336 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.336 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.016 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.016 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.016 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.016 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.017 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.017 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640524.338 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.338 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.338 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.338 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.018 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640531.019 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640528.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.786 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.787 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.787 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640528.788 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640530.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640530.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640530.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640530.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640530.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640530.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640530.642 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640530.643 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640531.330 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.330 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.330 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.332 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.332 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.332 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.332 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640531.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.836 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.836 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.836 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.836 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640528.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640524.838 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.838 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640524.838 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.155 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640524.839 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640531.025 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.025 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.025 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.866 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.866 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.866 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.866 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.027 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.027 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.027 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.027 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640531.027 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640525.868 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.868 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640525.870 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.870 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.274 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.275 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.275 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.275 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640526.276 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640538.712 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640538.712 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640538.712 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640538.713 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640538.713 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640538.713 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640538.713 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640538.714 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640524.232 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.232 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.232 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.232 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.232 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.232 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640524.234 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640524.234 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640528.778 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.778 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.778 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.778 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.780 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.780 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.780 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.780 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.827 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.827 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.827 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.827 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.828 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.828 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.829 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.829 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.356 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.356 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.356 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.356 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.356 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.356 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.357 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.358 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640528.649 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.649 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.649 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.649 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.650 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.650 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.650 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640528.652 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640527.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640527.259 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.260 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640534.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.671 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.671 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.671 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.884 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.672 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.672 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.672 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.673 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.673 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.555 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.555 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.555 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640526.556 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.556 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.556 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640526.556 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640526.557 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640529.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.900 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.901 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640529.902 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640534.408 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.408 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.409 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.409 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.409 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640534.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640525.955 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.955 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.955 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.955 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.956 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.956 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.956 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640525.957 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640527.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.242 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.242 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640527.242 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640527.244 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640528.841 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.841 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.841 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.841 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.841 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.841 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.841 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640528.842 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
1 Using seed = 4169357148
5 Using seed = 4169357152
0 Using seed = 4169357147
:::MLL 1558640544.310 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
3 Using seed = 4169357150
6 Using seed = 4169357153
7 Using seed = 4169357154
4 Using seed = 4169357151
13 Using seed = 4169357160
14 Using seed = 4169357161
15 Using seed = 4169357162
12 Using seed = 4169357159
10 Using seed = 4169357157
9 Using seed = 4169357156
8 Using seed = 4169357155
11 Using seed = 4169357158
16 Using seed = 4169357163
17 Using seed = 4169357164
18 Using seed = 4169357165
21 Using seed = 4169357168
23 Using seed = 4169357170
22 Using seed = 4169357169
19 Using seed = 4169357166
20 Using seed = 4169357167
25 Using seed = 4169357172
26 Using seed = 4169357173
24 Using seed = 4169357171
29 Using seed = 4169357176
27 Using seed = 4169357174
31 Using seed = 4169357178
30 Using seed = 4169357177
28 Using seed = 4169357175
36 Using seed = 4169357183
37 Using seed = 4169357184
38 Using seed = 4169357185
39 Using seed = 4169357186
32 Using seed = 4169357179
34 Using seed = 4169357181
35 Using seed = 4169357182
33 Using seed = 4169357180
44 Using seed = 4169357191
45 Using seed = 4169357192
47 Using seed = 4169357194
46 Using seed = 4169357193
41 Using seed = 4169357188
42 Using seed = 4169357189
43 Using seed = 4169357190
40 Using seed = 4169357187
55 Using seed = 4169357202
54 Using seed = 4169357201
53 Using seed = 4169357200
48 Using seed = 4169357195
51 Using seed = 4169357198
52 Using seed = 4169357199
49 Using seed = 4169357196
50 Using seed = 4169357197
56 Using seed = 4169357203
58 Using seed = 4169357205
59 Using seed = 4169357206
57 Using seed = 4169357204
61 Using seed = 4169357208
62 Using seed = 4169357209
60 Using seed = 4169357207
63 Using seed = 4169357210
66 Using seed = 4169357213
67 Using seed = 4169357214
64 Using seed = 4169357211
65 Using seed = 4169357212
71 Using seed = 4169357218
70 Using seed = 4169357217
69 Using seed = 4169357216
68 Using seed = 4169357215
77 Using seed = 4169357224
78 Using seed = 4169357225
76 Using seed = 4169357223
72 Using seed = 4169357219
79 Using seed = 4169357226
75 Using seed = 4169357222
74 Using seed = 4169357221
73 Using seed = 4169357220
83 Using seed = 4169357230
80 Using seed = 4169357227
82 Using seed = 4169357229
81 Using seed = 4169357228
87 Using seed = 4169357234
86 Using seed = 4169357233
85 Using seed = 4169357232
84 Using seed = 4169357231
93 Using seed = 4169357240
95 Using seed = 4169357242
92 Using seed = 4169357239
94 Using seed = 4169357241
89 Using seed = 4169357236
90 Using seed = 4169357237
91 Using seed = 4169357238
88 Using seed = 4169357235
98 Using seed = 4169357245
103 Using seed = 4169357250
99 Using seed = 4169357246
97 Using seed = 4169357244
96 Using seed = 4169357243
100 Using seed = 4169357247
102 Using seed = 4169357249
101 Using seed = 4169357248
106 Using seed = 4169357253
105 Using seed = 4169357252
104 Using seed = 4169357251
109 Using seed = 4169357256
107 Using seed = 4169357254
110 Using seed = 4169357257
111 Using seed = 4169357258
108 Using seed = 4169357255
119 Using seed = 4169357266
117 Using seed = 4169357264
116 Using seed = 4169357263
118 Using seed = 4169357265
115 Using seed = 4169357262
113 Using seed = 4169357260
112 Using seed = 4169357259
114 Using seed = 4169357261
121 Using seed = 4169357268
123 Using seed = 4169357270
122 Using seed = 4169357269
120 Using seed = 4169357267
125 Using seed = 4169357272
126 Using seed = 4169357273
127 Using seed = 4169357274
124 Using seed = 4169357271
134 Using seed = 4169357281
135 Using seed = 4169357282
132 Using seed = 4169357279
133 Using seed = 4169357280
129 Using seed = 4169357276
131 Using seed = 4169357278
130 Using seed = 4169357277
128 Using seed = 4169357275
143 Using seed = 4169357290
142 Using seed = 4169357289
141 Using seed = 4169357288
140 Using seed = 4169357287
139 Using seed = 4169357286
137 Using seed = 4169357284
136 Using seed = 4169357283
138 Using seed = 4169357285
145 Using seed = 4169357292
146 Using seed = 4169357293
144 Using seed = 4169357291
149 Using seed = 4169357296
151 Using seed = 4169357298
147 Using seed = 4169357294
150 Using seed = 4169357297
148 Using seed = 4169357295
153 Using seed = 4169357300
152 Using seed = 4169357299
154 Using seed = 4169357301
157 Using seed = 4169357304
155 Using seed = 4169357302
159 Using seed = 4169357306
158 Using seed = 4169357305
156 Using seed = 4169357303
162 Using seed = 4169357309
161 Using seed = 4169357308
160 Using seed = 4169357307
165 Using seed = 4169357312
163 Using seed = 4169357310
164 Using seed = 4169357311
167 Using seed = 4169357314
166 Using seed = 4169357313
168 Using seed = 4169357315
169 Using seed = 4169357316
170 Using seed = 4169357317
173 Using seed = 4169357320
174 Using seed = 4169357321
175 Using seed = 4169357322
171 Using seed = 4169357318
172 Using seed = 4169357319
181 Using seed = 4169357328
183 Using seed = 4169357330
180 Using seed = 4169357327
182 Using seed = 4169357329
176 Using seed = 4169357323
179 Using seed = 4169357326
177 Using seed = 4169357324
178 Using seed = 4169357325
191 Using seed = 4169357338
190 Using seed = 4169357337
189 Using seed = 4169357336
188 Using seed = 4169357335
187 Using seed = 4169357334
185 Using seed = 4169357332
186 Using seed = 4169357333
184 Using seed = 4169357331
198 Using seed = 4169357345
197 Using seed = 4169357344
196 Using seed = 4169357343
199 Using seed = 4169357346
192 Using seed = 4169357339
193 Using seed = 4169357340
194 Using seed = 4169357341
195 Using seed = 4169357342
207 Using seed = 4169357354
205 Using seed = 4169357352
204 Using seed = 4169357351
206 Using seed = 4169357353
202 Using seed = 4169357349
203 Using seed = 4169357350
201 Using seed = 4169357348
200 Using seed = 4169357347
214 Using seed = 4169357361
215 Using seed = 4169357362
212 Using seed = 4169357359
213 Using seed = 4169357360
209 Using seed = 4169357356
208 Using seed = 4169357355
210 Using seed = 4169357357
211 Using seed = 4169357358
222 Using seed = 4169357369
219 Using seed = 4169357366
223 Using seed = 4169357370
221 Using seed = 4169357368
220 Using seed = 4169357367
216 Using seed = 4169357363
218 Using seed = 4169357365
217 Using seed = 4169357364
231 Using seed = 4169357378
228 Using seed = 4169357375
230 Using seed = 4169357377
229 Using seed = 4169357376
224 Using seed = 4169357371
227 Using seed = 4169357374
225 Using seed = 4169357372
226 Using seed = 4169357373
233 Using seed = 4169357380
232 Using seed = 4169357379
235 Using seed = 4169357382
234 Using seed = 4169357381
239 Using seed = 4169357386
238 Using seed = 4169357385
237 Using seed = 4169357384
236 Using seed = 4169357383
2 Using seed = 4169357149
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558640549.095 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558640549.096 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
:::MLL 1558640549.104 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
Delaying allreduces to the end of backward()
:::MLL 1558640549.104 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1558640549.104 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558640549.105 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558640557.666 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558640557.667 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.48s)
Done (t=0.48s)
Done (t=0.48s)
creating index...
creating index...
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
Done (t=0.48s)
creating index...
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
Done (t=0.49s)
creating index...
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.55s)
creating index...
Done (t=0.55s)
creating index...
Done (t=0.56s)
creating index...
Done (t=0.56s)
creating index...
time_check a: 1558640553.457814455
time_check a: 1558640549.736500025
time_check a: 1558640551.568230867
time_check a: 1558640554.850130796
time_check a: 1558640552.049928904
time_check a: 1558640563.997242689
time_check a: 1558640554.004156828
time_check a: 1558640555.991753578
time_check a: 1558640551.858178377
time_check a: 1558640554.162793398
time_check a: 1558640549.515954971
time_check a: 1558640553.473613262
time_check a: 1558640552.460676670
time_check a: 1558640552.077171803
time_check a: 1558640560.076439619
time_check a: 1558640553.858195305
time_check a: 1558640556.432684183
time_check a: 1558640556.340991735
time_check a: 1558640555.056331873
time_check a: 1558640556.663027763
time_check a: 1558640559.521682501
time_check a: 1558640552.230360508
time_check a: 1558640550.168960333
time_check a: 1558640551.591332674
time_check a: 1558640552.616940975
time_check a: 1558640553.637625456
time_check a: 1558640551.041786909
time_check a: 1558640551.772424698
time_check a: 1558640551.205659151
time_check a: 1558640553.774770498
time_check b: 1558640560.069164753
time_check b: 1558640563.197245359
time_check b: 1558640553.433246374
time_check b: 1558640560.344736338
time_check b: 1558640553.856329203
time_check b: 1558640555.924700737
time_check b: 1558640555.287509680
time_check b: 1558640556.168666601
time_check b: 1558640557.189235210
time_check b: 1558640559.715651989
time_check b: 1558640560.055036306
time_check b: 1558640553.239109993
time_check b: 1558640555.799363852
time_check b: 1558640557.890164137
time_check b: 1558640557.340020180
time_check b: 1558640558.776266575
time_check b: 1558640554.743170738
time_check b: 1558640555.472862005
time_check b: 1558640555.599500179
time_check b: 1558640557.751145840
time_check b: 1558640557.222066164
time_check b: 1558640563.819924593
time_check b: 1558640556.347480774
time_check b: 1558640558.613416672
time_check b: 1558640555.816632271
time_check b: 1558640555.343841076
time_check b: 1558640567.780053616
time_check b: 1558640557.641144276
time_check b: 1558640555.022249222
time_check b: 1558640557.585324764
:::MLL 1558640564.385 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558640564.386 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.177, Average Loss: 0.022, avg. samples / sec: 135.59
Iteration:      0, Loss function: 22.008, Average Loss: 0.022, avg. samples / sec: 140.60
Iteration:      0, Loss function: 22.188, Average Loss: 0.022, avg. samples / sec: 137.21
Iteration:      0, Loss function: 22.026, Average Loss: 0.022, avg. samples / sec: 138.43
Iteration:      0, Loss function: 21.754, Average Loss: 0.022, avg. samples / sec: 138.91
Iteration:      0, Loss function: 22.646, Average Loss: 0.023, avg. samples / sec: 135.88
Iteration:      0, Loss function: 22.301, Average Loss: 0.022, avg. samples / sec: 136.76
Iteration:      0, Loss function: 22.088, Average Loss: 0.022, avg. samples / sec: 167.95
Iteration:      0, Loss function: 22.231, Average Loss: 0.022, avg. samples / sec: 136.31
Iteration:      0, Loss function: 21.777, Average Loss: 0.022, avg. samples / sec: 137.77
Iteration:      0, Loss function: 22.270, Average Loss: 0.022, avg. samples / sec: 156.68
Iteration:      0, Loss function: 22.104, Average Loss: 0.022, avg. samples / sec: 137.31
Iteration:      0, Loss function: 23.406, Average Loss: 0.023, avg. samples / sec: 136.18
Iteration:      0, Loss function: 21.876, Average Loss: 0.022, avg. samples / sec: 137.18
Iteration:      0, Loss function: 22.361, Average Loss: 0.022, avg. samples / sec: 137.84
Iteration:      0, Loss function: 22.191, Average Loss: 0.022, avg. samples / sec: 134.61
Iteration:      0, Loss function: 23.612, Average Loss: 0.024, avg. samples / sec: 137.32
Iteration:      0, Loss function: 22.526, Average Loss: 0.023, avg. samples / sec: 136.01
Iteration:      0, Loss function: 22.376, Average Loss: 0.022, avg. samples / sec: 140.65
Iteration:      0, Loss function: 22.721, Average Loss: 0.023, avg. samples / sec: 153.15
Iteration:      0, Loss function: 22.437, Average Loss: 0.022, avg. samples / sec: 140.35
Iteration:      0, Loss function: 22.436, Average Loss: 0.022, avg. samples / sec: 136.60
Iteration:      0, Loss function: 22.261, Average Loss: 0.022, avg. samples / sec: 131.74
Iteration:      0, Loss function: 22.451, Average Loss: 0.022, avg. samples / sec: 136.25
Iteration:      0, Loss function: 23.562, Average Loss: 0.024, avg. samples / sec: 136.03
Iteration:      0, Loss function: 22.212, Average Loss: 0.022, avg. samples / sec: 134.29
Iteration:      0, Loss function: 22.610, Average Loss: 0.023, avg. samples / sec: 140.19
Iteration:      0, Loss function: 22.058, Average Loss: 0.022, avg. samples / sec: 136.20
Iteration:      0, Loss function: 22.137, Average Loss: 0.022, avg. samples / sec: 136.28
Iteration:      0, Loss function: 22.528, Average Loss: 0.023, avg. samples / sec: 139.53
Iteration:     20, Loss function: 20.946, Average Loss: 0.443, avg. samples / sec: 31980.51
Iteration:     20, Loss function: 20.651, Average Loss: 0.444, avg. samples / sec: 33001.40
Iteration:     20, Loss function: 20.449, Average Loss: 0.443, avg. samples / sec: 32888.53
Iteration:     20, Loss function: 20.293, Average Loss: 0.442, avg. samples / sec: 33006.24
Iteration:     20, Loss function: 20.914, Average Loss: 0.443, avg. samples / sec: 32502.99
Iteration:     20, Loss function: 21.111, Average Loss: 0.443, avg. samples / sec: 33223.78
Iteration:     20, Loss function: 19.935, Average Loss: 0.442, avg. samples / sec: 37133.89
Iteration:     20, Loss function: 20.126, Average Loss: 0.441, avg. samples / sec: 32551.35
Iteration:     20, Loss function: 20.220, Average Loss: 0.439, avg. samples / sec: 35479.26
Iteration:     20, Loss function: 20.835, Average Loss: 0.442, avg. samples / sec: 33618.57
Iteration:     20, Loss function: 20.387, Average Loss: 0.441, avg. samples / sec: 32694.84
Iteration:     20, Loss function: 20.304, Average Loss: 0.440, avg. samples / sec: 32238.51
Iteration:     20, Loss function: 20.948, Average Loss: 0.443, avg. samples / sec: 32981.64
Iteration:     20, Loss function: 21.028, Average Loss: 0.446, avg. samples / sec: 32970.39
Iteration:     20, Loss function: 20.477, Average Loss: 0.440, avg. samples / sec: 32461.52
Iteration:     20, Loss function: 20.481, Average Loss: 0.442, avg. samples / sec: 34884.64
Iteration:     20, Loss function: 20.597, Average Loss: 0.446, avg. samples / sec: 33942.35
Iteration:     20, Loss function: 20.764, Average Loss: 0.445, avg. samples / sec: 34175.25
Iteration:     20, Loss function: 21.622, Average Loss: 0.442, avg. samples / sec: 33458.10
Iteration:     20, Loss function: 20.874, Average Loss: 0.441, avg. samples / sec: 32346.34
Iteration:     20, Loss function: 20.909, Average Loss: 0.443, avg. samples / sec: 32536.38
Iteration:     20, Loss function: 20.159, Average Loss: 0.441, avg. samples / sec: 33430.64
Iteration:     20, Loss function: 20.805, Average Loss: 0.439, avg. samples / sec: 32850.68
Iteration:     20, Loss function: 22.726, Average Loss: 0.446, avg. samples / sec: 32988.26
Iteration:     20, Loss function: 20.176, Average Loss: 0.444, avg. samples / sec: 31951.94
Iteration:     20, Loss function: 21.164, Average Loss: 0.442, avg. samples / sec: 32137.64
Iteration:     20, Loss function: 21.899, Average Loss: 0.442, avg. samples / sec: 31962.73
Iteration:     20, Loss function: 20.481, Average Loss: 0.440, avg. samples / sec: 33232.22
Iteration:     20, Loss function: 20.824, Average Loss: 0.442, avg. samples / sec: 33125.31
Iteration:     20, Loss function: 20.490, Average Loss: 0.450, avg. samples / sec: 34468.21
Iteration:     40, Loss function: 19.170, Average Loss: 0.835, avg. samples / sec: 49171.91
Iteration:     40, Loss function: 18.801, Average Loss: 0.843, avg. samples / sec: 49489.46
Iteration:     40, Loss function: 18.350, Average Loss: 0.829, avg. samples / sec: 48837.58
Iteration:     40, Loss function: 18.308, Average Loss: 0.838, avg. samples / sec: 49115.91
Iteration:     40, Loss function: 18.925, Average Loss: 0.831, avg. samples / sec: 49277.43
Iteration:     40, Loss function: 19.507, Average Loss: 0.837, avg. samples / sec: 48987.91
Iteration:     40, Loss function: 19.149, Average Loss: 0.829, avg. samples / sec: 48703.44
Iteration:     40, Loss function: 19.204, Average Loss: 0.833, avg. samples / sec: 48614.97
Iteration:     40, Loss function: 19.245, Average Loss: 0.831, avg. samples / sec: 48673.23
Iteration:     40, Loss function: 19.024, Average Loss: 0.833, avg. samples / sec: 48564.93
Iteration:     40, Loss function: 19.990, Average Loss: 0.838, avg. samples / sec: 48779.69
Iteration:     40, Loss function: 19.165, Average Loss: 0.830, avg. samples / sec: 48671.04
Iteration:     40, Loss function: 19.367, Average Loss: 0.834, avg. samples / sec: 48865.46
Iteration:     40, Loss function: 18.279, Average Loss: 0.827, avg. samples / sec: 48987.76
Iteration:     40, Loss function: 18.668, Average Loss: 0.835, avg. samples / sec: 49012.20
Iteration:     40, Loss function: 19.454, Average Loss: 0.836, avg. samples / sec: 48716.15
Iteration:     40, Loss function: 18.569, Average Loss: 0.830, avg. samples / sec: 48712.19
Iteration:     40, Loss function: 19.507, Average Loss: 0.834, avg. samples / sec: 48789.92
Iteration:     40, Loss function: 18.882, Average Loss: 0.833, avg. samples / sec: 48508.51
Iteration:     40, Loss function: 18.694, Average Loss: 0.831, avg. samples / sec: 48951.84
Iteration:     40, Loss function: 19.988, Average Loss: 0.834, avg. samples / sec: 48963.20
Iteration:     40, Loss function: 19.071, Average Loss: 0.828, avg. samples / sec: 48457.37
Iteration:     40, Loss function: 19.188, Average Loss: 0.834, avg. samples / sec: 48850.62
Iteration:     40, Loss function: 18.702, Average Loss: 0.835, avg. samples / sec: 48370.65
Iteration:     40, Loss function: 19.496, Average Loss: 0.839, avg. samples / sec: 48710.58
Iteration:     40, Loss function: 18.758, Average Loss: 0.834, avg. samples / sec: 48824.22
Iteration:     40, Loss function: 18.949, Average Loss: 0.831, avg. samples / sec: 48593.43
Iteration:     40, Loss function: 19.061, Average Loss: 0.835, avg. samples / sec: 48231.51
Iteration:     40, Loss function: 19.536, Average Loss: 0.833, avg. samples / sec: 48831.44
Iteration:     40, Loss function: 18.891, Average Loss: 0.830, avg. samples / sec: 47722.73
Iteration:     60, Loss function: 13.350, Average Loss: 1.105, avg. samples / sec: 50601.68
Iteration:     60, Loss function: 14.918, Average Loss: 1.116, avg. samples / sec: 50280.74
Iteration:     60, Loss function: 14.899, Average Loss: 1.110, avg. samples / sec: 50866.60
Iteration:     60, Loss function: 13.206, Average Loss: 1.101, avg. samples / sec: 50469.32
Iteration:     60, Loss function: 17.828, Average Loss: 1.117, avg. samples / sec: 50337.72
Iteration:     60, Loss function: 13.654, Average Loss: 1.112, avg. samples / sec: 50406.12
Iteration:     60, Loss function: 14.612, Average Loss: 1.103, avg. samples / sec: 51776.17
Iteration:     60, Loss function: 15.415, Average Loss: 1.110, avg. samples / sec: 50470.35
Iteration:     60, Loss function: 13.010, Average Loss: 1.104, avg. samples / sec: 50290.48
Iteration:     60, Loss function: 14.313, Average Loss: 1.109, avg. samples / sec: 50464.28
Iteration:     60, Loss function: 13.571, Average Loss: 1.101, avg. samples / sec: 50470.35
Iteration:     60, Loss function: 13.226, Average Loss: 1.104, avg. samples / sec: 50388.08
Iteration:     60, Loss function: 13.577, Average Loss: 1.104, avg. samples / sec: 50337.29
Iteration:     60, Loss function: 13.410, Average Loss: 1.112, avg. samples / sec: 50615.55
Iteration:     60, Loss function: 13.881, Average Loss: 1.102, avg. samples / sec: 50365.37
Iteration:     60, Loss function: 14.138, Average Loss: 1.102, avg. samples / sec: 50280.20
Iteration:     60, Loss function: 15.449, Average Loss: 1.102, avg. samples / sec: 50692.40
Iteration:     60, Loss function: 14.250, Average Loss: 1.104, avg. samples / sec: 50595.14
Iteration:     60, Loss function: 11.975, Average Loss: 1.102, avg. samples / sec: 50355.73
Iteration:     60, Loss function: 15.105, Average Loss: 1.106, avg. samples / sec: 50035.26
Iteration:     60, Loss function: 13.946, Average Loss: 1.107, avg. samples / sec: 50497.42
Iteration:     60, Loss function: 13.106, Average Loss: 1.100, avg. samples / sec: 50306.78
Iteration:     60, Loss function: 14.010, Average Loss: 1.099, avg. samples / sec: 49993.76
Iteration:     60, Loss function: 13.478, Average Loss: 1.106, avg. samples / sec: 50444.82
Iteration:     60, Loss function: 15.187, Average Loss: 1.101, avg. samples / sec: 50215.76
Iteration:     60, Loss function: 15.291, Average Loss: 1.111, avg. samples / sec: 50520.05
Iteration:     60, Loss function: 12.408, Average Loss: 1.097, avg. samples / sec: 50344.74
Iteration:     60, Loss function: 14.300, Average Loss: 1.096, avg. samples / sec: 50118.66
Iteration:     60, Loss function: 14.168, Average Loss: 1.106, avg. samples / sec: 50045.85
Iteration:     60, Loss function: 13.924, Average Loss: 1.102, avg. samples / sec: 50036.81
:::MLL 1558640567.958 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558640567.958 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 10.618, Average Loss: 1.315, avg. samples / sec: 50063.65
Iteration:     80, Loss function: 10.239, Average Loss: 1.318, avg. samples / sec: 49721.60
Iteration:     80, Loss function: 10.388, Average Loss: 1.310, avg. samples / sec: 49622.70
Iteration:     80, Loss function: 10.601, Average Loss: 1.309, avg. samples / sec: 49684.10
Iteration:     80, Loss function: 10.060, Average Loss: 1.312, avg. samples / sec: 49715.78
Iteration:     80, Loss function: 10.160, Average Loss: 1.316, avg. samples / sec: 49639.15
Iteration:     80, Loss function: 10.305, Average Loss: 1.313, avg. samples / sec: 49636.96
Iteration:     80, Loss function: 9.845, Average Loss: 1.317, avg. samples / sec: 49454.88
Iteration:     80, Loss function: 9.946, Average Loss: 1.293, avg. samples / sec: 49833.90
Iteration:     80, Loss function: 10.086, Average Loss: 1.310, avg. samples / sec: 49404.14
Iteration:     80, Loss function: 10.469, Average Loss: 1.327, avg. samples / sec: 49418.01
Iteration:     80, Loss function: 10.482, Average Loss: 1.302, avg. samples / sec: 49651.02
Iteration:     80, Loss function: 10.140, Average Loss: 1.310, avg. samples / sec: 49458.20
Iteration:     80, Loss function: 10.369, Average Loss: 1.310, avg. samples / sec: 49510.81
Iteration:     80, Loss function: 11.324, Average Loss: 1.325, avg. samples / sec: 49361.41
Iteration:     80, Loss function: 9.841, Average Loss: 1.310, avg. samples / sec: 49623.52
Iteration:     80, Loss function: 10.321, Average Loss: 1.327, avg. samples / sec: 49309.84
Iteration:     80, Loss function: 10.051, Average Loss: 1.316, avg. samples / sec: 49322.15
Iteration:     80, Loss function: 10.828, Average Loss: 1.310, avg. samples / sec: 49555.92
Iteration:     80, Loss function: 10.255, Average Loss: 1.308, avg. samples / sec: 49904.50
Iteration:     80, Loss function: 11.005, Average Loss: 1.312, avg. samples / sec: 49473.53
Iteration:     80, Loss function: 10.613, Average Loss: 1.309, avg. samples / sec: 49198.40
Iteration:     80, Loss function: 10.405, Average Loss: 1.302, avg. samples / sec: 49607.03
Iteration:     80, Loss function: 10.596, Average Loss: 1.312, avg. samples / sec: 49315.62
Iteration:     80, Loss function: 9.582, Average Loss: 1.306, avg. samples / sec: 49544.74
Iteration:     80, Loss function: 10.152, Average Loss: 1.313, avg. samples / sec: 49485.20
Iteration:     80, Loss function: 10.906, Average Loss: 1.304, avg. samples / sec: 49406.91
Iteration:     80, Loss function: 11.022, Average Loss: 1.310, avg. samples / sec: 48631.22
Iteration:     80, Loss function: 10.069, Average Loss: 1.309, avg. samples / sec: 48460.08
Iteration:     80, Loss function: 9.689, Average Loss: 1.309, avg. samples / sec: 48586.19
Iteration:    100, Loss function: 9.678, Average Loss: 1.477, avg. samples / sec: 53295.81
Iteration:    100, Loss function: 9.814, Average Loss: 1.487, avg. samples / sec: 52217.73
Iteration:    100, Loss function: 9.595, Average Loss: 1.494, avg. samples / sec: 51980.55
Iteration:    100, Loss function: 10.690, Average Loss: 1.500, avg. samples / sec: 51891.93
Iteration:    100, Loss function: 9.689, Average Loss: 1.483, avg. samples / sec: 51748.26
Iteration:    100, Loss function: 9.283, Average Loss: 1.488, avg. samples / sec: 51620.26
Iteration:    100, Loss function: 10.510, Average Loss: 1.477, avg. samples / sec: 52049.58
Iteration:    100, Loss function: 9.593, Average Loss: 1.487, avg. samples / sec: 51890.19
Iteration:    100, Loss function: 10.085, Average Loss: 1.490, avg. samples / sec: 51615.98
Iteration:    100, Loss function: 9.641, Average Loss: 1.486, avg. samples / sec: 51755.74
Iteration:    100, Loss function: 9.598, Average Loss: 1.484, avg. samples / sec: 51921.43
Iteration:    100, Loss function: 9.601, Average Loss: 1.481, avg. samples / sec: 51570.56
Iteration:    100, Loss function: 8.590, Average Loss: 1.485, avg. samples / sec: 51593.08
Iteration:    100, Loss function: 9.671, Average Loss: 1.481, avg. samples / sec: 51685.51
Iteration:    100, Loss function: 8.817, Average Loss: 1.479, avg. samples / sec: 51761.43
Iteration:    100, Loss function: 9.101, Average Loss: 1.478, avg. samples / sec: 51708.25
Iteration:    100, Loss function: 9.913, Average Loss: 1.482, avg. samples / sec: 51424.70
Iteration:    100, Loss function: 8.910, Average Loss: 1.478, avg. samples / sec: 51588.93
Iteration:    100, Loss function: 8.995, Average Loss: 1.462, avg. samples / sec: 51445.48
Iteration:    100, Loss function: 8.904, Average Loss: 1.482, avg. samples / sec: 51339.42
Iteration:    100, Loss function: 10.151, Average Loss: 1.484, avg. samples / sec: 52443.96
Iteration:    100, Loss function: 9.005, Average Loss: 1.477, avg. samples / sec: 51447.66
Iteration:    100, Loss function: 10.120, Average Loss: 1.497, avg. samples / sec: 51404.97
Iteration:    100, Loss function: 9.067, Average Loss: 1.480, avg. samples / sec: 51298.52
Iteration:    100, Loss function: 9.657, Average Loss: 1.472, avg. samples / sec: 51451.28
Iteration:    100, Loss function: 8.530, Average Loss: 1.473, avg. samples / sec: 51544.70
Iteration:    100, Loss function: 10.101, Average Loss: 1.477, avg. samples / sec: 51221.87
Iteration:    100, Loss function: 9.796, Average Loss: 1.481, avg. samples / sec: 51120.77
Iteration:    100, Loss function: 9.328, Average Loss: 1.482, avg. samples / sec: 52080.32
Iteration:    100, Loss function: 10.362, Average Loss: 1.482, avg. samples / sec: 50853.81
Iteration:    120, Loss function: 9.120, Average Loss: 1.634, avg. samples / sec: 52043.32
Iteration:    120, Loss function: 9.601, Average Loss: 1.653, avg. samples / sec: 52350.37
Iteration:    120, Loss function: 8.817, Average Loss: 1.634, avg. samples / sec: 52619.68
Iteration:    120, Loss function: 9.058, Average Loss: 1.625, avg. samples / sec: 52020.80
Iteration:    120, Loss function: 9.017, Average Loss: 1.644, avg. samples / sec: 51792.64
Iteration:    120, Loss function: 8.668, Average Loss: 1.638, avg. samples / sec: 52211.79
Iteration:    120, Loss function: 9.224, Average Loss: 1.652, avg. samples / sec: 51676.45
Iteration:    120, Loss function: 8.250, Average Loss: 1.629, avg. samples / sec: 52611.08
Iteration:    120, Loss function: 9.957, Average Loss: 1.629, avg. samples / sec: 52324.73
Iteration:    120, Loss function: 9.083, Average Loss: 1.631, avg. samples / sec: 52093.51
Iteration:    120, Loss function: 9.380, Average Loss: 1.631, avg. samples / sec: 52200.79
Iteration:    120, Loss function: 9.844, Average Loss: 1.637, avg. samples / sec: 51910.12
Iteration:    120, Loss function: 9.229, Average Loss: 1.632, avg. samples / sec: 51863.91
Iteration:    120, Loss function: 9.531, Average Loss: 1.634, avg. samples / sec: 51543.77
Iteration:    120, Loss function: 9.116, Average Loss: 1.630, avg. samples / sec: 51801.67
Iteration:    120, Loss function: 9.259, Average Loss: 1.643, avg. samples / sec: 51439.15
Iteration:    120, Loss function: 9.066, Average Loss: 1.632, avg. samples / sec: 51730.78
Iteration:    120, Loss function: 9.319, Average Loss: 1.615, avg. samples / sec: 51863.32
Iteration:    120, Loss function: 8.692, Average Loss: 1.626, avg. samples / sec: 51719.26
Iteration:    120, Loss function: 9.079, Average Loss: 1.638, avg. samples / sec: 51378.88
Iteration:    120, Loss function: 8.036, Average Loss: 1.636, avg. samples / sec: 51232.72
Iteration:    120, Loss function: 9.651, Average Loss: 1.629, avg. samples / sec: 51284.64
Iteration:    120, Loss function: 9.197, Average Loss: 1.631, avg. samples / sec: 51254.30
Iteration:    120, Loss function: 9.510, Average Loss: 1.636, avg. samples / sec: 51408.92
Iteration:    120, Loss function: 9.381, Average Loss: 1.639, avg. samples / sec: 50939.85
Iteration:    120, Loss function: 9.225, Average Loss: 1.637, avg. samples / sec: 51597.20
Iteration:    120, Loss function: 7.957, Average Loss: 1.622, avg. samples / sec: 51381.37
Iteration:    120, Loss function: 10.313, Average Loss: 1.626, avg. samples / sec: 51296.33
Iteration:    120, Loss function: 8.118, Average Loss: 1.641, avg. samples / sec: 50653.30
Iteration:    120, Loss function: 10.366, Average Loss: 1.629, avg. samples / sec: 50094.43
:::MLL 1558640570.268 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558640570.269 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 9.285, Average Loss: 1.772, avg. samples / sec: 50982.60
Iteration:    140, Loss function: 8.592, Average Loss: 1.795, avg. samples / sec: 50510.26
Iteration:    140, Loss function: 8.265, Average Loss: 1.768, avg. samples / sec: 50621.95
Iteration:    140, Loss function: 8.494, Average Loss: 1.771, avg. samples / sec: 50695.59
Iteration:    140, Loss function: 8.700, Average Loss: 1.776, avg. samples / sec: 51918.33
Iteration:    140, Loss function: 8.542, Average Loss: 1.791, avg. samples / sec: 50766.54
Iteration:    140, Loss function: 8.986, Average Loss: 1.781, avg. samples / sec: 50899.34
Iteration:    140, Loss function: 8.868, Average Loss: 1.778, avg. samples / sec: 50458.03
Iteration:    140, Loss function: 7.456, Average Loss: 1.769, avg. samples / sec: 50460.20
Iteration:    140, Loss function: 9.856, Average Loss: 1.771, avg. samples / sec: 51449.25
Iteration:    140, Loss function: 9.856, Average Loss: 1.765, avg. samples / sec: 51361.13
Iteration:    140, Loss function: 9.923, Average Loss: 1.778, avg. samples / sec: 50504.55
Iteration:    140, Loss function: 9.665, Average Loss: 1.777, avg. samples / sec: 50528.98
Iteration:    140, Loss function: 8.884, Average Loss: 1.770, avg. samples / sec: 50468.16
Iteration:    140, Loss function: 8.621, Average Loss: 1.774, avg. samples / sec: 50520.90
Iteration:    140, Loss function: 9.054, Average Loss: 1.778, avg. samples / sec: 50555.92
Iteration:    140, Loss function: 8.643, Average Loss: 1.778, avg. samples / sec: 50624.37
Iteration:    140, Loss function: 9.146, Average Loss: 1.773, avg. samples / sec: 50534.91
Iteration:    140, Loss function: 8.701, Average Loss: 1.780, avg. samples / sec: 51188.64
Iteration:    140, Loss function: 8.700, Average Loss: 1.778, avg. samples / sec: 51182.99
Iteration:    140, Loss function: 8.578, Average Loss: 1.780, avg. samples / sec: 50700.90
Iteration:    140, Loss function: 8.687, Average Loss: 1.783, avg. samples / sec: 50261.21
Iteration:    140, Loss function: 8.883, Average Loss: 1.757, avg. samples / sec: 50492.61
Iteration:    140, Loss function: 9.242, Average Loss: 1.778, avg. samples / sec: 51034.28
Iteration:    140, Loss function: 8.667, Average Loss: 1.772, avg. samples / sec: 50583.72
Iteration:    140, Loss function: 8.886, Average Loss: 1.773, avg. samples / sec: 50407.55
Iteration:    140, Loss function: 8.386, Average Loss: 1.798, avg. samples / sec: 49792.59
Iteration:    140, Loss function: 8.837, Average Loss: 1.782, avg. samples / sec: 50684.39
Iteration:    140, Loss function: 9.438, Average Loss: 1.785, avg. samples / sec: 49570.89
Iteration:    140, Loss function: 9.019, Average Loss: 1.776, avg. samples / sec: 49151.86
Iteration:    160, Loss function: 8.987, Average Loss: 1.916, avg. samples / sec: 53341.08
Iteration:    160, Loss function: 8.545, Average Loss: 1.927, avg. samples / sec: 51846.24
Iteration:    160, Loss function: 8.010, Average Loss: 1.913, avg. samples / sec: 52026.35
Iteration:    160, Loss function: 8.724, Average Loss: 1.906, avg. samples / sec: 51757.44
Iteration:    160, Loss function: 8.082, Average Loss: 1.914, avg. samples / sec: 52862.40
Iteration:    160, Loss function: 9.212, Average Loss: 1.913, avg. samples / sec: 51926.23
Iteration:    160, Loss function: 8.376, Average Loss: 1.913, avg. samples / sec: 51861.28
Iteration:    160, Loss function: 8.298, Average Loss: 1.910, avg. samples / sec: 51897.74
Iteration:    160, Loss function: 8.961, Average Loss: 1.909, avg. samples / sec: 51913.07
Iteration:    160, Loss function: 7.886, Average Loss: 1.905, avg. samples / sec: 51689.08
Iteration:    160, Loss function: 9.115, Average Loss: 1.905, avg. samples / sec: 51848.95
Iteration:    160, Loss function: 7.968, Average Loss: 1.925, avg. samples / sec: 52019.99
Iteration:    160, Loss function: 7.533, Average Loss: 1.910, avg. samples / sec: 51822.81
Iteration:    160, Loss function: 8.148, Average Loss: 1.924, avg. samples / sec: 51655.58
Iteration:    160, Loss function: 7.809, Average Loss: 1.935, avg. samples / sec: 52464.69
Iteration:    160, Loss function: 9.235, Average Loss: 1.918, avg. samples / sec: 51844.41
Iteration:    160, Loss function: 9.272, Average Loss: 1.914, avg. samples / sec: 51602.53
Iteration:    160, Loss function: 8.427, Average Loss: 1.893, avg. samples / sec: 51912.67
Iteration:    160, Loss function: 8.571, Average Loss: 1.904, avg. samples / sec: 51700.93
Iteration:    160, Loss function: 7.840, Average Loss: 1.907, avg. samples / sec: 51905.17
Iteration:    160, Loss function: 9.129, Average Loss: 1.908, avg. samples / sec: 52366.50
Iteration:    160, Loss function: 8.602, Average Loss: 1.902, avg. samples / sec: 51453.39
Iteration:    160, Loss function: 8.322, Average Loss: 1.918, avg. samples / sec: 52467.43
Iteration:    160, Loss function: 8.802, Average Loss: 1.912, avg. samples / sec: 51703.93
Iteration:    160, Loss function: 7.618, Average Loss: 1.918, avg. samples / sec: 51718.54
Iteration:    160, Loss function: 7.704, Average Loss: 1.913, avg. samples / sec: 51630.51
Iteration:    160, Loss function: 9.097, Average Loss: 1.918, avg. samples / sec: 51350.50
Iteration:    160, Loss function: 9.115, Average Loss: 1.911, avg. samples / sec: 51564.90
Iteration:    160, Loss function: 8.200, Average Loss: 1.919, avg. samples / sec: 51054.14
Iteration:    160, Loss function: 8.768, Average Loss: 1.903, avg. samples / sec: 49710.32
Iteration:    180, Loss function: 7.970, Average Loss: 2.040, avg. samples / sec: 51695.81
Iteration:    180, Loss function: 8.376, Average Loss: 2.047, avg. samples / sec: 51394.04
Iteration:    180, Loss function: 8.356, Average Loss: 2.059, avg. samples / sec: 51397.13
Iteration:    180, Loss function: 8.621, Average Loss: 2.045, avg. samples / sec: 51489.46
Iteration:    180, Loss function: 8.493, Average Loss: 2.045, avg. samples / sec: 51617.95
Iteration:    180, Loss function: 8.568, Average Loss: 2.039, avg. samples / sec: 51441.29
Iteration:    180, Loss function: 8.609, Average Loss: 2.035, avg. samples / sec: 51543.45
Iteration:    180, Loss function: 8.093, Average Loss: 2.046, avg. samples / sec: 52190.37
Iteration:    180, Loss function: 7.642, Average Loss: 2.044, avg. samples / sec: 51397.86
Iteration:    180, Loss function: 6.855, Average Loss: 2.040, avg. samples / sec: 51763.16
Iteration:    180, Loss function: 8.800, Average Loss: 2.038, avg. samples / sec: 51575.39
Iteration:    180, Loss function: 8.737, Average Loss: 2.042, avg. samples / sec: 51369.66
Iteration:    180, Loss function: 9.384, Average Loss: 2.050, avg. samples / sec: 51619.59
Iteration:    180, Loss function: 8.166, Average Loss: 2.025, avg. samples / sec: 51548.00
Iteration:    180, Loss function: 8.570, Average Loss: 2.061, avg. samples / sec: 51425.90
Iteration:    180, Loss function: 9.470, Average Loss: 2.032, avg. samples / sec: 51310.90
Iteration:    180, Loss function: 7.515, Average Loss: 2.022, avg. samples / sec: 51432.36
Iteration:    180, Loss function: 9.478, Average Loss: 2.036, avg. samples / sec: 51206.27
Iteration:    180, Loss function: 8.204, Average Loss: 2.034, avg. samples / sec: 51418.24
Iteration:    180, Loss function: 8.693, Average Loss: 2.041, avg. samples / sec: 51517.43
Iteration:    180, Loss function: 8.422, Average Loss: 2.040, avg. samples / sec: 51427.25
Iteration:    180, Loss function: 9.187, Average Loss: 2.048, avg. samples / sec: 51364.91
Iteration:    180, Loss function: 9.397, Average Loss: 2.056, avg. samples / sec: 51268.00
Iteration:    180, Loss function: 8.441, Average Loss: 2.034, avg. samples / sec: 53466.20
Iteration:    180, Loss function: 7.910, Average Loss: 2.041, avg. samples / sec: 51815.13
Iteration:    180, Loss function: 8.402, Average Loss: 2.035, avg. samples / sec: 51210.60
Iteration:    180, Loss function: 9.586, Average Loss: 2.055, avg. samples / sec: 51304.27
Iteration:    180, Loss function: 8.877, Average Loss: 2.047, avg. samples / sec: 50730.35
Iteration:    180, Loss function: 8.824, Average Loss: 2.044, avg. samples / sec: 50338.79
Iteration:    180, Loss function: 8.195, Average Loss: 2.045, avg. samples / sec: 50763.74
Iteration:    200, Loss function: 9.648, Average Loss: 2.190, avg. samples / sec: 51855.32
Iteration:    200, Loss function: 8.640, Average Loss: 2.173, avg. samples / sec: 51682.12
Iteration:    200, Loss function: 8.054, Average Loss: 2.164, avg. samples / sec: 51888.05
Iteration:    200, Loss function: 8.625, Average Loss: 2.164, avg. samples / sec: 52020.07
Iteration:    200, Loss function: 7.941, Average Loss: 2.173, avg. samples / sec: 51774.59
Iteration:    200, Loss function: 7.971, Average Loss: 2.167, avg. samples / sec: 51546.15
Iteration:    200, Loss function: 7.598, Average Loss: 2.172, avg. samples / sec: 51979.80
Iteration:    200, Loss function: 8.947, Average Loss: 2.174, avg. samples / sec: 51778.77
Iteration:    200, Loss function: 8.338, Average Loss: 2.175, avg. samples / sec: 51666.72
Iteration:    200, Loss function: 8.421, Average Loss: 2.164, avg. samples / sec: 51889.16
Iteration:    200, Loss function: 7.756, Average Loss: 2.171, avg. samples / sec: 51717.74
Iteration:    200, Loss function: 8.364, Average Loss: 2.174, avg. samples / sec: 51754.32
Iteration:    200, Loss function: 8.619, Average Loss: 2.195, avg. samples / sec: 51854.35
Iteration:    200, Loss function: 8.169, Average Loss: 2.165, avg. samples / sec: 51681.76
Iteration:    200, Loss function: 8.843, Average Loss: 2.171, avg. samples / sec: 52910.57
Iteration:    200, Loss function: 8.664, Average Loss: 2.185, avg. samples / sec: 51850.27
Iteration:    200, Loss function: 8.796, Average Loss: 2.172, avg. samples / sec: 52655.37
Iteration:    200, Loss function: 9.100, Average Loss: 2.162, avg. samples / sec: 51769.36
Iteration:    200, Loss function: 9.128, Average Loss: 2.179, avg. samples / sec: 52613.32
Iteration:    200, Loss function: 7.784, Average Loss: 2.172, avg. samples / sec: 51563.35
Iteration:    200, Loss function: 8.266, Average Loss: 2.185, avg. samples / sec: 51639.78
Iteration:    200, Loss function: 7.497, Average Loss: 2.178, avg. samples / sec: 51765.17
Iteration:    200, Loss function: 8.414, Average Loss: 2.191, avg. samples / sec: 51774.78
Iteration:    200, Loss function: 8.558, Average Loss: 2.152, avg. samples / sec: 51618.84
Iteration:    200, Loss function: 9.299, Average Loss: 2.153, avg. samples / sec: 51694.95
Iteration:    200, Loss function: 8.943, Average Loss: 2.167, avg. samples / sec: 51648.14
Iteration:    200, Loss function: 8.609, Average Loss: 2.170, avg. samples / sec: 51548.90
Iteration:    200, Loss function: 8.717, Average Loss: 2.172, avg. samples / sec: 51465.83
Iteration:    200, Loss function: 8.908, Average Loss: 2.166, avg. samples / sec: 51118.17
Iteration:    200, Loss function: 9.407, Average Loss: 2.166, avg. samples / sec: 51137.19
:::MLL 1558640572.543 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558640572.543 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 8.535, Average Loss: 2.289, avg. samples / sec: 51667.85
Iteration:    220, Loss function: 7.336, Average Loss: 2.309, avg. samples / sec: 50936.32
Iteration:    220, Loss function: 7.200, Average Loss: 2.283, avg. samples / sec: 51988.37
Iteration:    220, Loss function: 7.493, Average Loss: 2.292, avg. samples / sec: 50995.78
Iteration:    220, Loss function: 7.488, Average Loss: 2.291, avg. samples / sec: 50991.33
Iteration:    220, Loss function: 8.110, Average Loss: 2.314, avg. samples / sec: 51092.32
Iteration:    220, Loss function: 7.929, Average Loss: 2.284, avg. samples / sec: 50952.38
Iteration:    220, Loss function: 7.696, Average Loss: 2.284, avg. samples / sec: 51699.75
Iteration:    220, Loss function: 8.432, Average Loss: 2.279, avg. samples / sec: 50916.68
Iteration:    220, Loss function: 7.961, Average Loss: 2.283, avg. samples / sec: 51000.59
Iteration:    220, Loss function: 8.890, Average Loss: 2.296, avg. samples / sec: 50943.92
Iteration:    220, Loss function: 8.861, Average Loss: 2.289, avg. samples / sec: 50884.56
Iteration:    220, Loss function: 8.224, Average Loss: 2.293, avg. samples / sec: 50974.47
Iteration:    220, Loss function: 8.511, Average Loss: 2.291, avg. samples / sec: 51111.83
Iteration:    220, Loss function: 8.457, Average Loss: 2.274, avg. samples / sec: 51048.50
Iteration:    220, Loss function: 7.998, Average Loss: 2.294, avg. samples / sec: 50745.90
Iteration:    220, Loss function: 8.127, Average Loss: 2.294, avg. samples / sec: 51297.95
Iteration:    220, Loss function: 7.945, Average Loss: 2.282, avg. samples / sec: 50932.32
Iteration:    220, Loss function: 8.293, Average Loss: 2.293, avg. samples / sec: 50922.42
Iteration:    220, Loss function: 8.148, Average Loss: 2.289, avg. samples / sec: 51140.99
Iteration:    220, Loss function: 8.132, Average Loss: 2.287, avg. samples / sec: 50875.47
Iteration:    220, Loss function: 8.679, Average Loss: 2.318, avg. samples / sec: 50920.42
Iteration:    220, Loss function: 7.387, Average Loss: 2.303, avg. samples / sec: 50876.81
Iteration:    220, Loss function: 7.765, Average Loss: 2.289, avg. samples / sec: 50624.55
Iteration:    220, Loss function: 8.628, Average Loss: 2.276, avg. samples / sec: 50831.98
Iteration:    220, Loss function: 8.299, Average Loss: 2.297, avg. samples / sec: 50522.82
Iteration:    220, Loss function: 7.620, Average Loss: 2.286, avg. samples / sec: 50384.30
Iteration:    220, Loss function: 8.286, Average Loss: 2.289, avg. samples / sec: 50251.68
Iteration:    220, Loss function: 7.757, Average Loss: 2.299, avg. samples / sec: 50185.04
Iteration:    220, Loss function: 8.659, Average Loss: 2.303, avg. samples / sec: 49635.44
Iteration:    240, Loss function: 7.627, Average Loss: 2.420, avg. samples / sec: 51984.90
Iteration:    240, Loss function: 7.434, Average Loss: 2.398, avg. samples / sec: 52033.21
Iteration:    240, Loss function: 7.443, Average Loss: 2.423, avg. samples / sec: 51986.32
Iteration:    240, Loss function: 7.687, Average Loss: 2.393, avg. samples / sec: 51975.02
Iteration:    240, Loss function: 7.652, Average Loss: 2.399, avg. samples / sec: 52050.22
Iteration:    240, Loss function: 7.791, Average Loss: 2.395, avg. samples / sec: 52696.85
Iteration:    240, Loss function: 7.301, Average Loss: 2.389, avg. samples / sec: 51955.56
Iteration:    240, Loss function: 7.973, Average Loss: 2.395, avg. samples / sec: 51964.87
Iteration:    240, Loss function: 7.953, Average Loss: 2.382, avg. samples / sec: 52131.87
Iteration:    240, Loss function: 7.398, Average Loss: 2.404, avg. samples / sec: 51977.46
Iteration:    240, Loss function: 8.083, Average Loss: 2.396, avg. samples / sec: 52007.55
Iteration:    240, Loss function: 6.810, Average Loss: 2.390, avg. samples / sec: 51760.72
Iteration:    240, Loss function: 7.679, Average Loss: 2.394, avg. samples / sec: 51851.49
Iteration:    240, Loss function: 7.045, Average Loss: 2.401, avg. samples / sec: 51761.39
Iteration:    240, Loss function: 7.804, Average Loss: 2.404, avg. samples / sec: 52251.15
Iteration:    240, Loss function: 6.968, Average Loss: 2.407, avg. samples / sec: 52902.40
Iteration:    240, Loss function: 8.055, Average Loss: 2.417, avg. samples / sec: 53484.77
Iteration:    240, Loss function: 7.756, Average Loss: 2.398, avg. samples / sec: 51838.46
Iteration:    240, Loss function: 8.333, Average Loss: 2.405, avg. samples / sec: 52011.74
Iteration:    240, Loss function: 8.341, Average Loss: 2.400, avg. samples / sec: 52055.27
Iteration:    240, Loss function: 7.230, Average Loss: 2.410, avg. samples / sec: 52455.75
Iteration:    240, Loss function: 8.702, Average Loss: 2.407, avg. samples / sec: 51999.61
Iteration:    240, Loss function: 8.687, Average Loss: 2.398, avg. samples / sec: 51999.72
Iteration:    240, Loss function: 8.130, Average Loss: 2.402, avg. samples / sec: 51997.12
Iteration:    240, Loss function: 7.961, Average Loss: 2.399, avg. samples / sec: 51386.32
Iteration:    240, Loss function: 8.138, Average Loss: 2.382, avg. samples / sec: 52136.25
Iteration:    240, Loss function: 6.800, Average Loss: 2.427, avg. samples / sec: 52006.23
Iteration:    240, Loss function: 7.800, Average Loss: 2.401, avg. samples / sec: 52469.58
Iteration:    240, Loss function: 7.685, Average Loss: 2.403, avg. samples / sec: 51829.04
Iteration:    240, Loss function: 7.838, Average Loss: 2.411, avg. samples / sec: 51292.82
Iteration:    260, Loss function: 7.172, Average Loss: 2.509, avg. samples / sec: 53725.88
Iteration:    260, Loss function: 7.679, Average Loss: 2.529, avg. samples / sec: 53415.19
Iteration:    260, Loss function: 7.713, Average Loss: 2.509, avg. samples / sec: 53506.03
Iteration:    260, Loss function: 7.526, Average Loss: 2.509, avg. samples / sec: 53818.16
Iteration:    260, Loss function: 7.917, Average Loss: 2.511, avg. samples / sec: 53372.79
Iteration:    260, Loss function: 7.905, Average Loss: 2.504, avg. samples / sec: 53534.46
Iteration:    260, Loss function: 7.090, Average Loss: 2.502, avg. samples / sec: 53585.94
Iteration:    260, Loss function: 7.049, Average Loss: 2.498, avg. samples / sec: 53482.39
Iteration:    260, Loss function: 6.912, Average Loss: 2.507, avg. samples / sec: 53867.33
Iteration:    260, Loss function: 7.938, Average Loss: 2.506, avg. samples / sec: 53445.70
Iteration:    260, Loss function: 8.053, Average Loss: 2.509, avg. samples / sec: 53489.70
Iteration:    260, Loss function: 7.248, Average Loss: 2.526, avg. samples / sec: 53376.57
Iteration:    260, Loss function: 8.389, Average Loss: 2.508, avg. samples / sec: 53632.48
Iteration:    260, Loss function: 7.766, Average Loss: 2.501, avg. samples / sec: 53477.66
Iteration:    260, Loss function: 7.897, Average Loss: 2.500, avg. samples / sec: 53362.69
Iteration:    260, Loss function: 7.869, Average Loss: 2.508, avg. samples / sec: 53530.80
Iteration:    260, Loss function: 7.371, Average Loss: 2.501, avg. samples / sec: 53322.69
Iteration:    260, Loss function: 8.202, Average Loss: 2.511, avg. samples / sec: 53459.12
Iteration:    260, Loss function: 7.845, Average Loss: 2.515, avg. samples / sec: 53485.31
Iteration:    260, Loss function: 8.780, Average Loss: 2.517, avg. samples / sec: 53503.71
Iteration:    260, Loss function: 6.657, Average Loss: 2.487, avg. samples / sec: 53520.90
Iteration:    260, Loss function: 8.040, Average Loss: 2.493, avg. samples / sec: 53256.98
Iteration:    260, Loss function: 7.308, Average Loss: 2.535, avg. samples / sec: 53509.62
Iteration:    260, Loss function: 7.781, Average Loss: 2.523, avg. samples / sec: 53440.53
Iteration:    260, Loss function: 8.730, Average Loss: 2.523, avg. samples / sec: 54301.03
Iteration:    260, Loss function: 7.628, Average Loss: 2.509, avg. samples / sec: 53423.76
Iteration:    260, Loss function: 8.570, Average Loss: 2.512, avg. samples / sec: 53405.50
Iteration:    260, Loss function: 8.760, Average Loss: 2.511, avg. samples / sec: 53310.65
Iteration:    260, Loss function: 8.459, Average Loss: 2.513, avg. samples / sec: 53004.81
Iteration:    260, Loss function: 7.495, Average Loss: 2.527, avg. samples / sec: 52086.34
:::MLL 1558640574.811 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558640574.812 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 7.392, Average Loss: 2.626, avg. samples / sec: 51094.41
Iteration:    280, Loss function: 8.081, Average Loss: 2.612, avg. samples / sec: 51162.90
Iteration:    280, Loss function: 7.871, Average Loss: 2.610, avg. samples / sec: 51153.97
Iteration:    280, Loss function: 7.873, Average Loss: 2.626, avg. samples / sec: 51183.00
Iteration:    280, Loss function: 7.577, Average Loss: 2.598, avg. samples / sec: 51163.25
Iteration:    280, Loss function: 8.186, Average Loss: 2.618, avg. samples / sec: 51267.20
Iteration:    280, Loss function: 8.023, Average Loss: 2.605, avg. samples / sec: 51114.52
Iteration:    280, Loss function: 7.782, Average Loss: 2.626, avg. samples / sec: 51301.95
Iteration:    280, Loss function: 7.127, Average Loss: 2.606, avg. samples / sec: 51207.07
Iteration:    280, Loss function: 7.754, Average Loss: 2.604, avg. samples / sec: 50876.06
Iteration:    280, Loss function: 9.441, Average Loss: 2.607, avg. samples / sec: 50796.67
Iteration:    280, Loss function: 8.378, Average Loss: 2.605, avg. samples / sec: 50740.69
Iteration:    280, Loss function: 7.212, Average Loss: 2.597, avg. samples / sec: 50669.81
Iteration:    280, Loss function: 7.579, Average Loss: 2.611, avg. samples / sec: 51112.26
Iteration:    280, Loss function: 6.834, Average Loss: 2.603, avg. samples / sec: 50463.12
Iteration:    280, Loss function: 7.594, Average Loss: 2.605, avg. samples / sec: 50277.28
Iteration:    280, Loss function: 7.995, Average Loss: 2.637, avg. samples / sec: 50608.59
Iteration:    280, Loss function: 8.005, Average Loss: 2.590, avg. samples / sec: 50580.67
Iteration:    280, Loss function: 7.246, Average Loss: 2.612, avg. samples / sec: 50474.60
Iteration:    280, Loss function: 7.754, Average Loss: 2.611, avg. samples / sec: 50405.76
Iteration:    280, Loss function: 7.450, Average Loss: 2.597, avg. samples / sec: 50395.07
Iteration:    280, Loss function: 7.622, Average Loss: 2.610, avg. samples / sec: 50517.63
Iteration:    280, Loss function: 7.679, Average Loss: 2.622, avg. samples / sec: 50427.62
Iteration:    280, Loss function: 8.232, Average Loss: 2.603, avg. samples / sec: 50184.18
Iteration:    280, Loss function: 7.199, Average Loss: 2.610, avg. samples / sec: 50105.80
Iteration:    280, Loss function: 7.651, Average Loss: 2.623, avg. samples / sec: 51521.16
Iteration:    280, Loss function: 7.740, Average Loss: 2.605, avg. samples / sec: 50062.06
Iteration:    280, Loss function: 8.909, Average Loss: 2.594, avg. samples / sec: 50203.91
Iteration:    280, Loss function: 7.087, Average Loss: 2.611, avg. samples / sec: 49460.37
Iteration:    280, Loss function: 7.625, Average Loss: 2.611, avg. samples / sec: 49451.40
Iteration:    300, Loss function: 7.962, Average Loss: 2.700, avg. samples / sec: 53090.74
Iteration:    300, Loss function: 7.761, Average Loss: 2.719, avg. samples / sec: 52188.59
Iteration:    300, Loss function: 7.604, Average Loss: 2.710, avg. samples / sec: 52157.44
Iteration:    300, Loss function: 6.982, Average Loss: 2.688, avg. samples / sec: 52990.60
Iteration:    300, Loss function: 6.446, Average Loss: 2.703, avg. samples / sec: 52128.07
Iteration:    300, Loss function: 8.273, Average Loss: 2.703, avg. samples / sec: 53185.93
Iteration:    300, Loss function: 8.756, Average Loss: 2.704, avg. samples / sec: 53336.01
Iteration:    300, Loss function: 7.212, Average Loss: 2.702, avg. samples / sec: 52849.65
Iteration:    300, Loss function: 7.330, Average Loss: 2.691, avg. samples / sec: 52675.13
Iteration:    300, Loss function: 8.584, Average Loss: 2.700, avg. samples / sec: 52312.50
Iteration:    300, Loss function: 7.770, Average Loss: 2.719, avg. samples / sec: 52063.93
Iteration:    300, Loss function: 8.282, Average Loss: 2.708, avg. samples / sec: 53010.81
Iteration:    300, Loss function: 8.832, Average Loss: 2.706, avg. samples / sec: 52432.02
Iteration:    300, Loss function: 7.638, Average Loss: 2.705, avg. samples / sec: 53200.28
Iteration:    300, Loss function: 8.069, Average Loss: 2.708, avg. samples / sec: 52689.31
Iteration:    300, Loss function: 8.092, Average Loss: 2.706, avg. samples / sec: 52558.99
Iteration:    300, Loss function: 7.329, Average Loss: 2.706, avg. samples / sec: 54008.18
Iteration:    300, Loss function: 7.182, Average Loss: 2.719, avg. samples / sec: 53057.90
Iteration:    300, Loss function: 7.826, Average Loss: 2.709, avg. samples / sec: 52780.10
Iteration:    300, Loss function: 7.912, Average Loss: 2.702, avg. samples / sec: 52092.24
Iteration:    300, Loss function: 7.508, Average Loss: 2.717, avg. samples / sec: 51943.51
Iteration:    300, Loss function: 7.752, Average Loss: 2.733, avg. samples / sec: 52671.46
Iteration:    300, Loss function: 7.389, Average Loss: 2.697, avg. samples / sec: 51954.73
Iteration:    300, Loss function: 8.145, Average Loss: 2.725, avg. samples / sec: 51956.72
Iteration:    300, Loss function: 7.740, Average Loss: 2.699, avg. samples / sec: 51817.55
Iteration:    300, Loss function: 9.085, Average Loss: 2.707, avg. samples / sec: 54113.71
Iteration:    300, Loss function: 7.915, Average Loss: 2.721, avg. samples / sec: 52764.82
Iteration:    300, Loss function: 7.629, Average Loss: 2.693, avg. samples / sec: 52696.54
Iteration:    300, Loss function: 7.217, Average Loss: 2.690, avg. samples / sec: 52438.11
Iteration:    300, Loss function: 7.852, Average Loss: 2.707, avg. samples / sec: 52065.60
Iteration:    320, Loss function: 8.073, Average Loss: 2.825, avg. samples / sec: 53910.13
Iteration:    320, Loss function: 8.165, Average Loss: 2.825, avg. samples / sec: 53519.03
Iteration:    320, Loss function: 7.635, Average Loss: 2.803, avg. samples / sec: 53388.22
Iteration:    320, Loss function: 6.488, Average Loss: 2.820, avg. samples / sec: 53279.13
Iteration:    320, Loss function: 6.635, Average Loss: 2.802, avg. samples / sec: 53223.37
Iteration:    320, Loss function: 7.469, Average Loss: 2.804, avg. samples / sec: 53697.32
Iteration:    320, Loss function: 7.980, Average Loss: 2.809, avg. samples / sec: 53433.52
Iteration:    320, Loss function: 7.397, Average Loss: 2.804, avg. samples / sec: 53321.52
Iteration:    320, Loss function: 7.701, Average Loss: 2.804, avg. samples / sec: 53348.55
Iteration:    320, Loss function: 7.219, Average Loss: 2.794, avg. samples / sec: 53329.99
Iteration:    320, Loss function: 6.007, Average Loss: 2.796, avg. samples / sec: 53566.84
Iteration:    320, Loss function: 6.917, Average Loss: 2.814, avg. samples / sec: 53214.47
Iteration:    320, Loss function: 8.147, Average Loss: 2.799, avg. samples / sec: 53692.20
Iteration:    320, Loss function: 8.507, Average Loss: 2.802, avg. samples / sec: 53238.89
Iteration:    320, Loss function: 7.646, Average Loss: 2.802, avg. samples / sec: 53317.89
Iteration:    320, Loss function: 7.507, Average Loss: 2.803, avg. samples / sec: 53286.20
Iteration:    320, Loss function: 6.813, Average Loss: 2.807, avg. samples / sec: 53337.78
Iteration:    320, Loss function: 8.102, Average Loss: 2.810, avg. samples / sec: 53382.03
Iteration:    320, Loss function: 8.011, Average Loss: 2.807, avg. samples / sec: 53180.29
Iteration:    320, Loss function: 7.676, Average Loss: 2.793, avg. samples / sec: 53068.60
Iteration:    320, Loss function: 8.239, Average Loss: 2.805, avg. samples / sec: 53273.75
Iteration:    320, Loss function: 7.181, Average Loss: 2.819, avg. samples / sec: 53283.07
Iteration:    320, Loss function: 9.422, Average Loss: 2.819, avg. samples / sec: 53318.13
Iteration:    320, Loss function: 7.411, Average Loss: 2.809, avg. samples / sec: 54092.53
Iteration:    320, Loss function: 8.104, Average Loss: 2.823, avg. samples / sec: 53387.31
Iteration:    320, Loss function: 7.949, Average Loss: 2.835, avg. samples / sec: 53260.42
Iteration:    320, Loss function: 7.361, Average Loss: 2.808, avg. samples / sec: 53247.04
Iteration:    320, Loss function: 7.480, Average Loss: 2.803, avg. samples / sec: 53259.90
Iteration:    320, Loss function: 6.987, Average Loss: 2.808, avg. samples / sec: 52590.80
Iteration:    320, Loss function: 7.320, Average Loss: 2.789, avg. samples / sec: 53255.03
Iteration:    340, Loss function: 7.147, Average Loss: 2.892, avg. samples / sec: 54346.31
Iteration:    340, Loss function: 5.809, Average Loss: 2.899, avg. samples / sec: 53954.52
Iteration:    340, Loss function: 6.793, Average Loss: 2.905, avg. samples / sec: 53808.94
Iteration:    340, Loss function: 7.267, Average Loss: 2.893, avg. samples / sec: 53866.07
Iteration:    340, Loss function: 6.984, Average Loss: 2.888, avg. samples / sec: 53782.03
Iteration:    340, Loss function: 7.894, Average Loss: 2.883, avg. samples / sec: 53894.13
Iteration:    340, Loss function: 7.590, Average Loss: 2.891, avg. samples / sec: 54245.02
Iteration:    340, Loss function: 7.238, Average Loss: 2.908, avg. samples / sec: 53517.47
Iteration:    340, Loss function: 6.274, Average Loss: 2.884, avg. samples / sec: 53861.48
Iteration:    340, Loss function: 6.357, Average Loss: 2.891, avg. samples / sec: 53743.66
Iteration:    340, Loss function: 6.991, Average Loss: 2.895, avg. samples / sec: 54629.83
Iteration:    340, Loss function: 7.631, Average Loss: 2.894, avg. samples / sec: 53986.72
Iteration:    340, Loss function: 7.018, Average Loss: 2.890, avg. samples / sec: 53804.33
Iteration:    340, Loss function: 7.183, Average Loss: 2.894, avg. samples / sec: 53836.73
Iteration:    340, Loss function: 6.847, Average Loss: 2.883, avg. samples / sec: 53796.80
Iteration:    340, Loss function: 7.462, Average Loss: 2.897, avg. samples / sec: 53691.94
Iteration:    340, Loss function: 6.650, Average Loss: 2.909, avg. samples / sec: 54019.69
Iteration:    340, Loss function: 8.264, Average Loss: 2.892, avg. samples / sec: 53656.33
Iteration:    340, Loss function: 7.363, Average Loss: 2.897, avg. samples / sec: 53927.27
Iteration:    340, Loss function: 6.838, Average Loss: 2.908, avg. samples / sec: 53858.70
Iteration:    340, Loss function: 6.590, Average Loss: 2.895, avg. samples / sec: 53897.22
Iteration:    340, Loss function: 7.901, Average Loss: 2.881, avg. samples / sec: 53767.63
Iteration:    340, Loss function: 7.847, Average Loss: 2.904, avg. samples / sec: 53816.83
Iteration:    340, Loss function: 6.718, Average Loss: 2.874, avg. samples / sec: 54617.99
Iteration:    340, Loss function: 7.300, Average Loss: 2.887, avg. samples / sec: 53563.15
Iteration:    340, Loss function: 6.759, Average Loss: 2.914, avg. samples / sec: 53374.47
Iteration:    340, Loss function: 7.865, Average Loss: 2.922, avg. samples / sec: 53788.05
Iteration:    340, Loss function: 6.596, Average Loss: 2.895, avg. samples / sec: 53609.91
Iteration:    340, Loss function: 7.469, Average Loss: 2.893, avg. samples / sec: 53262.59
Iteration:    340, Loss function: 6.519, Average Loss: 2.891, avg. samples / sec: 53059.33
:::MLL 1558640577.023 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558640577.024 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 6.015, Average Loss: 2.992, avg. samples / sec: 53921.08
Iteration:    360, Loss function: 6.860, Average Loss: 2.968, avg. samples / sec: 53885.00
Iteration:    360, Loss function: 7.721, Average Loss: 2.976, avg. samples / sec: 54573.26
Iteration:    360, Loss function: 6.327, Average Loss: 2.961, avg. samples / sec: 53815.76
Iteration:    360, Loss function: 7.495, Average Loss: 2.993, avg. samples / sec: 53974.73
Iteration:    360, Loss function: 7.677, Average Loss: 2.963, avg. samples / sec: 53882.71
Iteration:    360, Loss function: 6.512, Average Loss: 2.963, avg. samples / sec: 54093.54
Iteration:    360, Loss function: 7.840, Average Loss: 2.972, avg. samples / sec: 53756.04
Iteration:    360, Loss function: 7.576, Average Loss: 2.976, avg. samples / sec: 53830.80
Iteration:    360, Loss function: 7.590, Average Loss: 2.972, avg. samples / sec: 53830.68
Iteration:    360, Loss function: 6.402, Average Loss: 2.973, avg. samples / sec: 53818.90
Iteration:    360, Loss function: 7.933, Average Loss: 2.989, avg. samples / sec: 54034.93
Iteration:    360, Loss function: 6.617, Average Loss: 2.978, avg. samples / sec: 53784.99
Iteration:    360, Loss function: 7.988, Average Loss: 2.976, avg. samples / sec: 54376.40
Iteration:    360, Loss function: 7.339, Average Loss: 2.974, avg. samples / sec: 53665.26
Iteration:    360, Loss function: 7.802, Average Loss: 2.976, avg. samples / sec: 53719.02
Iteration:    360, Loss function: 6.569, Average Loss: 2.983, avg. samples / sec: 53726.37
Iteration:    360, Loss function: 7.177, Average Loss: 2.974, avg. samples / sec: 53345.36
Iteration:    360, Loss function: 7.639, Average Loss: 2.957, avg. samples / sec: 53848.16
Iteration:    360, Loss function: 6.504, Average Loss: 2.970, avg. samples / sec: 53818.70
Iteration:    360, Loss function: 7.766, Average Loss: 2.982, avg. samples / sec: 53784.76
Iteration:    360, Loss function: 6.881, Average Loss: 2.976, avg. samples / sec: 53948.26
Iteration:    360, Loss function: 6.915, Average Loss: 2.994, avg. samples / sec: 53840.78
Iteration:    360, Loss function: 6.785, Average Loss: 2.976, avg. samples / sec: 53751.08
Iteration:    360, Loss function: 7.040, Average Loss: 3.008, avg. samples / sec: 53898.31
Iteration:    360, Loss function: 6.479, Average Loss: 2.978, avg. samples / sec: 53490.90
Iteration:    360, Loss function: 6.295, Average Loss: 2.981, avg. samples / sec: 53385.35
Iteration:    360, Loss function: 6.679, Average Loss: 2.990, avg. samples / sec: 53005.19
Iteration:    360, Loss function: 6.053, Average Loss: 2.967, avg. samples / sec: 53072.24
Iteration:    360, Loss function: 5.849, Average Loss: 2.985, avg. samples / sec: 52348.25
Iteration:    380, Loss function: 6.452, Average Loss: 3.064, avg. samples / sec: 53051.34
Iteration:    380, Loss function: 6.905, Average Loss: 3.055, avg. samples / sec: 52634.87
Iteration:    380, Loss function: 7.166, Average Loss: 3.050, avg. samples / sec: 52609.37
Iteration:    380, Loss function: 6.601, Average Loss: 3.046, avg. samples / sec: 52605.23
Iteration:    380, Loss function: 6.753, Average Loss: 3.054, avg. samples / sec: 52635.84
Iteration:    380, Loss function: 6.729, Average Loss: 3.037, avg. samples / sec: 52571.02
Iteration:    380, Loss function: 6.965, Average Loss: 3.054, avg. samples / sec: 52598.49
Iteration:    380, Loss function: 6.288, Average Loss: 3.056, avg. samples / sec: 52834.61
Iteration:    380, Loss function: 6.564, Average Loss: 3.067, avg. samples / sec: 52620.41
Iteration:    380, Loss function: 6.833, Average Loss: 3.064, avg. samples / sec: 52839.58
Iteration:    380, Loss function: 6.141, Average Loss: 3.049, avg. samples / sec: 52641.15
Iteration:    380, Loss function: 6.020, Average Loss: 3.043, avg. samples / sec: 52551.64
Iteration:    380, Loss function: 6.728, Average Loss: 3.054, avg. samples / sec: 52576.08
Iteration:    380, Loss function: 7.096, Average Loss: 3.059, avg. samples / sec: 52659.64
Iteration:    380, Loss function: 7.198, Average Loss: 3.056, avg. samples / sec: 52574.02
Iteration:    380, Loss function: 7.892, Average Loss: 3.051, avg. samples / sec: 52742.61
Iteration:    380, Loss function: 6.973, Average Loss: 3.054, avg. samples / sec: 52605.64
Iteration:    380, Loss function: 6.224, Average Loss: 3.063, avg. samples / sec: 54092.05
Iteration:    380, Loss function: 6.524, Average Loss: 3.069, avg. samples / sec: 53153.07
Iteration:    380, Loss function: 6.872, Average Loss: 3.063, avg. samples / sec: 52596.25
Iteration:    380, Loss function: 6.447, Average Loss: 3.054, avg. samples / sec: 52401.60
Iteration:    380, Loss function: 6.261, Average Loss: 3.069, avg. samples / sec: 52306.48
Iteration:    380, Loss function: 6.411, Average Loss: 3.076, avg. samples / sec: 52578.75
Iteration:    380, Loss function: 7.059, Average Loss: 3.085, avg. samples / sec: 52552.69
Iteration:    380, Loss function: 7.183, Average Loss: 3.061, avg. samples / sec: 52574.95
Iteration:    380, Loss function: 6.530, Average Loss: 3.050, avg. samples / sec: 53270.95
Iteration:    380, Loss function: 7.525, Average Loss: 3.041, avg. samples / sec: 52341.88
Iteration:    380, Loss function: 7.822, Average Loss: 3.061, avg. samples / sec: 52191.51
Iteration:    380, Loss function: 6.507, Average Loss: 3.074, avg. samples / sec: 51838.88
Iteration:    380, Loss function: 6.401, Average Loss: 3.043, avg. samples / sec: 51485.38
Iteration:    400, Loss function: 7.341, Average Loss: 3.145, avg. samples / sec: 54416.35
Iteration:    400, Loss function: 8.048, Average Loss: 3.135, avg. samples / sec: 53491.71
Iteration:    400, Loss function: 6.061, Average Loss: 3.128, avg. samples / sec: 53454.78
Iteration:    400, Loss function: 6.337, Average Loss: 3.140, avg. samples / sec: 53700.72
Iteration:    400, Loss function: 7.342, Average Loss: 3.126, avg. samples / sec: 53459.49
Iteration:    400, Loss function: 7.964, Average Loss: 3.134, avg. samples / sec: 53518.38
Iteration:    400, Loss function: 7.402, Average Loss: 3.135, avg. samples / sec: 53441.50
Iteration:    400, Loss function: 6.794, Average Loss: 3.107, avg. samples / sec: 53446.49
Iteration:    400, Loss function: 6.037, Average Loss: 3.127, avg. samples / sec: 53538.06
Iteration:    400, Loss function: 6.937, Average Loss: 3.126, avg. samples / sec: 53410.01
Iteration:    400, Loss function: 6.435, Average Loss: 3.144, avg. samples / sec: 53454.86
Iteration:    400, Loss function: 5.383, Average Loss: 3.120, avg. samples / sec: 53482.78
Iteration:    400, Loss function: 6.322, Average Loss: 3.116, avg. samples / sec: 53453.12
Iteration:    400, Loss function: 7.464, Average Loss: 3.134, avg. samples / sec: 53597.66
Iteration:    400, Loss function: 7.513, Average Loss: 3.130, avg. samples / sec: 53483.06
Iteration:    400, Loss function: 6.636, Average Loss: 3.123, avg. samples / sec: 53320.43
Iteration:    400, Loss function: 6.990, Average Loss: 3.133, avg. samples / sec: 53877.01
Iteration:    400, Loss function: 7.361, Average Loss: 3.141, avg. samples / sec: 53497.62
Iteration:    400, Loss function: 6.707, Average Loss: 3.128, avg. samples / sec: 53517.51
Iteration:    400, Loss function: 7.877, Average Loss: 3.133, avg. samples / sec: 53285.65
Iteration:    400, Loss function: 7.062, Average Loss: 3.138, avg. samples / sec: 53568.65
Iteration:    400, Loss function: 7.572, Average Loss: 3.144, avg. samples / sec: 53505.62
Iteration:    400, Loss function: 6.858, Average Loss: 3.133, avg. samples / sec: 53239.53
Iteration:    400, Loss function: 6.823, Average Loss: 3.118, avg. samples / sec: 54382.10
Iteration:    400, Loss function: 7.940, Average Loss: 3.122, avg. samples / sec: 53545.36
Iteration:    400, Loss function: 6.706, Average Loss: 3.151, avg. samples / sec: 53491.85
Iteration:    400, Loss function: 6.499, Average Loss: 3.159, avg. samples / sec: 53520.15
Iteration:    400, Loss function: 6.187, Average Loss: 3.131, avg. samples / sec: 53223.77
Iteration:    400, Loss function: 6.925, Average Loss: 3.145, avg. samples / sec: 53383.57
Iteration:    400, Loss function: 5.792, Average Loss: 3.115, avg. samples / sec: 53208.64
:::MLL 1558640579.229 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558640579.232 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 7.507, Average Loss: 3.190, avg. samples / sec: 53597.29
Iteration:    420, Loss function: 7.358, Average Loss: 3.186, avg. samples / sec: 54257.22
Iteration:    420, Loss function: 6.974, Average Loss: 3.207, avg. samples / sec: 53489.31
Iteration:    420, Loss function: 6.915, Average Loss: 3.215, avg. samples / sec: 53432.43
Iteration:    420, Loss function: 7.093, Average Loss: 3.200, avg. samples / sec: 53477.52
Iteration:    420, Loss function: 6.732, Average Loss: 3.221, avg. samples / sec: 53124.46
Iteration:    420, Loss function: 7.380, Average Loss: 3.201, avg. samples / sec: 53376.15
Iteration:    420, Loss function: 8.965, Average Loss: 3.203, avg. samples / sec: 53417.56
Iteration:    420, Loss function: 8.148, Average Loss: 3.206, avg. samples / sec: 53575.29
Iteration:    420, Loss function: 7.116, Average Loss: 3.200, avg. samples / sec: 53387.61
Iteration:    420, Loss function: 6.801, Average Loss: 3.197, avg. samples / sec: 53414.77
Iteration:    420, Loss function: 8.067, Average Loss: 3.207, avg. samples / sec: 53366.08
Iteration:    420, Loss function: 6.766, Average Loss: 3.208, avg. samples / sec: 53140.12
Iteration:    420, Loss function: 7.439, Average Loss: 3.182, avg. samples / sec: 53322.14
Iteration:    420, Loss function: 7.112, Average Loss: 3.208, avg. samples / sec: 53539.10
Iteration:    420, Loss function: 5.827, Average Loss: 3.210, avg. samples / sec: 53488.07
Iteration:    420, Loss function: 6.603, Average Loss: 3.204, avg. samples / sec: 53497.39
Iteration:    420, Loss function: 6.028, Average Loss: 3.195, avg. samples / sec: 53287.28
Iteration:    420, Loss function: 7.445, Average Loss: 3.227, avg. samples / sec: 53514.80
Iteration:    420, Loss function: 7.802, Average Loss: 3.208, avg. samples / sec: 53462.77
Iteration:    420, Loss function: 6.279, Average Loss: 3.203, avg. samples / sec: 53445.68
Iteration:    420, Loss function: 6.939, Average Loss: 3.218, avg. samples / sec: 53506.62
Iteration:    420, Loss function: 6.450, Average Loss: 3.217, avg. samples / sec: 53395.12
Iteration:    420, Loss function: 6.667, Average Loss: 3.191, avg. samples / sec: 53397.46
Iteration:    420, Loss function: 6.470, Average Loss: 3.199, avg. samples / sec: 53209.20
Iteration:    420, Loss function: 6.512, Average Loss: 3.206, avg. samples / sec: 53179.95
Iteration:    420, Loss function: 6.619, Average Loss: 3.216, avg. samples / sec: 53120.93
Iteration:    420, Loss function: 5.323, Average Loss: 3.232, avg. samples / sec: 53282.93
Iteration:    420, Loss function: 7.923, Average Loss: 3.211, avg. samples / sec: 53210.11
Iteration:    420, Loss function: 7.414, Average Loss: 3.194, avg. samples / sec: 52812.18
Iteration:    440, Loss function: 5.917, Average Loss: 3.289, avg. samples / sec: 54655.86
Iteration:    440, Loss function: 6.006, Average Loss: 3.280, avg. samples / sec: 54469.73
Iteration:    440, Loss function: 6.690, Average Loss: 3.273, avg. samples / sec: 54254.48
Iteration:    440, Loss function: 6.116, Average Loss: 3.270, avg. samples / sec: 54242.91
Iteration:    440, Loss function: 5.674, Average Loss: 3.276, avg. samples / sec: 54242.87
Iteration:    440, Loss function: 6.247, Average Loss: 3.275, avg. samples / sec: 54388.88
Iteration:    440, Loss function: 6.555, Average Loss: 3.272, avg. samples / sec: 54208.00
Iteration:    440, Loss function: 6.108, Average Loss: 3.272, avg. samples / sec: 54061.26
Iteration:    440, Loss function: 6.677, Average Loss: 3.277, avg. samples / sec: 54125.31
Iteration:    440, Loss function: 7.246, Average Loss: 3.260, avg. samples / sec: 54011.05
Iteration:    440, Loss function: 5.383, Average Loss: 3.261, avg. samples / sec: 54239.63
Iteration:    440, Loss function: 5.310, Average Loss: 3.262, avg. samples / sec: 53942.50
Iteration:    440, Loss function: 6.840, Average Loss: 3.286, avg. samples / sec: 54043.10
Iteration:    440, Loss function: 5.102, Average Loss: 3.273, avg. samples / sec: 54088.11
Iteration:    440, Loss function: 6.821, Average Loss: 3.268, avg. samples / sec: 54947.96
Iteration:    440, Loss function: 6.469, Average Loss: 3.286, avg. samples / sec: 53984.59
Iteration:    440, Loss function: 6.983, Average Loss: 3.297, avg. samples / sec: 54099.44
Iteration:    440, Loss function: 6.645, Average Loss: 3.280, avg. samples / sec: 54026.58
Iteration:    440, Loss function: 5.934, Average Loss: 3.276, avg. samples / sec: 53819.62
Iteration:    440, Loss function: 6.222, Average Loss: 3.276, avg. samples / sec: 54174.08
Iteration:    440, Loss function: 7.391, Average Loss: 3.282, avg. samples / sec: 54005.42
Iteration:    440, Loss function: 6.073, Average Loss: 3.261, avg. samples / sec: 54136.93
Iteration:    440, Loss function: 6.432, Average Loss: 3.272, avg. samples / sec: 53983.95
Iteration:    440, Loss function: 5.922, Average Loss: 3.290, avg. samples / sec: 54086.71
Iteration:    440, Loss function: 6.014, Average Loss: 3.304, avg. samples / sec: 54224.92
Iteration:    440, Loss function: 8.108, Average Loss: 3.285, avg. samples / sec: 54240.99
Iteration:    440, Loss function: 6.360, Average Loss: 3.288, avg. samples / sec: 54033.67
Iteration:    440, Loss function: 6.489, Average Loss: 3.250, avg. samples / sec: 53865.82
Iteration:    440, Loss function: 7.258, Average Loss: 3.277, avg. samples / sec: 53887.33
Iteration:    440, Loss function: 6.842, Average Loss: 3.275, avg. samples / sec: 53494.33
Iteration:    460, Loss function: 6.867, Average Loss: 3.337, avg. samples / sec: 53736.96
Iteration:    460, Loss function: 7.233, Average Loss: 3.313, avg. samples / sec: 54160.15
Iteration:    460, Loss function: 6.945, Average Loss: 3.327, avg. samples / sec: 53954.69
Iteration:    460, Loss function: 7.150, Average Loss: 3.344, avg. samples / sec: 53969.91
Iteration:    460, Loss function: 7.307, Average Loss: 3.339, avg. samples / sec: 53914.13
Iteration:    460, Loss function: 8.375, Average Loss: 3.348, avg. samples / sec: 53696.56
Iteration:    460, Loss function: 7.108, Average Loss: 3.340, avg. samples / sec: 53497.01
Iteration:    460, Loss function: 7.957, Average Loss: 3.328, avg. samples / sec: 53497.31
Iteration:    460, Loss function: 6.554, Average Loss: 3.344, avg. samples / sec: 53669.30
Iteration:    460, Loss function: 6.256, Average Loss: 3.328, avg. samples / sec: 53452.75
Iteration:    460, Loss function: 6.288, Average Loss: 3.357, avg. samples / sec: 53404.46
Iteration:    460, Loss function: 7.613, Average Loss: 3.346, avg. samples / sec: 53152.41
Iteration:    460, Loss function: 5.859, Average Loss: 3.337, avg. samples / sec: 53213.32
Iteration:    460, Loss function: 6.260, Average Loss: 3.352, avg. samples / sec: 53466.89
Iteration:    460, Loss function: 6.303, Average Loss: 3.352, avg. samples / sec: 53177.52
Iteration:    460, Loss function: 6.896, Average Loss: 3.344, avg. samples / sec: 52952.79
Iteration:    460, Loss function: 7.611, Average Loss: 3.374, avg. samples / sec: 53408.41
Iteration:    460, Loss function: 6.603, Average Loss: 3.349, avg. samples / sec: 53445.52
Iteration:    460, Loss function: 6.645, Average Loss: 3.340, avg. samples / sec: 53039.34
Iteration:    460, Loss function: 6.439, Average Loss: 3.337, avg. samples / sec: 53149.36
Iteration:    460, Loss function: 6.804, Average Loss: 3.340, avg. samples / sec: 53575.47
Iteration:    460, Loss function: 7.116, Average Loss: 3.342, avg. samples / sec: 53596.17
Iteration:    460, Loss function: 7.105, Average Loss: 3.358, avg. samples / sec: 53266.78
Iteration:    460, Loss function: 7.623, Average Loss: 3.336, avg. samples / sec: 52959.88
Iteration:    460, Loss function: 6.945, Average Loss: 3.358, avg. samples / sec: 52697.44
Iteration:    460, Loss function: 7.095, Average Loss: 3.347, avg. samples / sec: 53121.45
Iteration:    460, Loss function: 6.385, Average Loss: 3.339, avg. samples / sec: 52794.71
Iteration:    460, Loss function: 7.287, Average Loss: 3.329, avg. samples / sec: 52714.43
Iteration:    460, Loss function: 5.912, Average Loss: 3.364, avg. samples / sec: 52817.54
Iteration:    460, Loss function: 7.201, Average Loss: 3.345, avg. samples / sec: 52767.65
Iteration:    480, Loss function: 6.189, Average Loss: 3.432, avg. samples / sec: 54266.53
Iteration:    480, Loss function: 6.933, Average Loss: 3.409, avg. samples / sec: 53815.57
Iteration:    480, Loss function: 7.041, Average Loss: 3.404, avg. samples / sec: 52979.51
Iteration:    480, Loss function: 7.380, Average Loss: 3.398, avg. samples / sec: 54102.29
Iteration:    480, Loss function: 7.338, Average Loss: 3.409, avg. samples / sec: 53653.18
Iteration:    480, Loss function: 8.053, Average Loss: 3.404, avg. samples / sec: 53553.95
Iteration:    480, Loss function: 6.730, Average Loss: 3.381, avg. samples / sec: 52917.18
Iteration:    480, Loss function: 5.462, Average Loss: 3.407, avg. samples / sec: 53628.48
Iteration:    480, Loss function: 6.254, Average Loss: 3.408, avg. samples / sec: 53758.22
Iteration:    480, Loss function: 6.877, Average Loss: 3.426, avg. samples / sec: 53372.59
Iteration:    480, Loss function: 6.062, Average Loss: 3.416, avg. samples / sec: 53554.50
Iteration:    480, Loss function: 6.705, Average Loss: 3.414, avg. samples / sec: 53029.11
Iteration:    480, Loss function: 6.118, Average Loss: 3.396, avg. samples / sec: 53255.51
Iteration:    480, Loss function: 5.652, Average Loss: 3.409, avg. samples / sec: 53185.33
Iteration:    480, Loss function: 5.560, Average Loss: 3.404, avg. samples / sec: 52964.04
Iteration:    480, Loss function: 7.375, Average Loss: 3.425, avg. samples / sec: 53750.28
Iteration:    480, Loss function: 6.639, Average Loss: 3.442, avg. samples / sec: 53503.45
Iteration:    480, Loss function: 6.073, Average Loss: 3.420, avg. samples / sec: 53304.56
Iteration:    480, Loss function: 5.570, Average Loss: 3.390, avg. samples / sec: 52818.95
Iteration:    480, Loss function: 5.455, Average Loss: 3.414, avg. samples / sec: 53035.09
Iteration:    480, Loss function: 7.039, Average Loss: 3.407, avg. samples / sec: 53392.35
Iteration:    480, Loss function: 6.286, Average Loss: 3.422, avg. samples / sec: 53294.18
Iteration:    480, Loss function: 6.659, Average Loss: 3.410, avg. samples / sec: 53627.13
Iteration:    480, Loss function: 7.887, Average Loss: 3.414, avg. samples / sec: 53912.29
Iteration:    480, Loss function: 6.687, Average Loss: 3.428, avg. samples / sec: 53411.22
Iteration:    480, Loss function: 6.506, Average Loss: 3.422, avg. samples / sec: 53282.41
Iteration:    480, Loss function: 5.835, Average Loss: 3.413, avg. samples / sec: 52703.47
Iteration:    480, Loss function: 7.027, Average Loss: 3.400, avg. samples / sec: 52910.68
Iteration:    480, Loss function: 6.749, Average Loss: 3.423, avg. samples / sec: 53208.56
Iteration:    480, Loss function: 6.131, Average Loss: 3.415, avg. samples / sec: 52689.98
:::MLL 1558640581.426 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558640581.427 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 5.967, Average Loss: 3.458, avg. samples / sec: 53993.11
Iteration:    500, Loss function: 6.790, Average Loss: 3.464, avg. samples / sec: 54125.87
Iteration:    500, Loss function: 6.111, Average Loss: 3.441, avg. samples / sec: 54049.00
Iteration:    500, Loss function: 6.192, Average Loss: 3.462, avg. samples / sec: 54004.97
Iteration:    500, Loss function: 6.419, Average Loss: 3.468, avg. samples / sec: 53913.05
Iteration:    500, Loss function: 6.309, Average Loss: 3.487, avg. samples / sec: 54055.53
Iteration:    500, Loss function: 6.434, Average Loss: 3.478, avg. samples / sec: 54333.13
Iteration:    500, Loss function: 6.227, Average Loss: 3.473, avg. samples / sec: 54015.24
Iteration:    500, Loss function: 7.049, Average Loss: 3.475, avg. samples / sec: 54008.38
Iteration:    500, Loss function: 6.269, Average Loss: 3.461, avg. samples / sec: 53950.53
Iteration:    500, Loss function: 6.324, Average Loss: 3.460, avg. samples / sec: 53994.48
Iteration:    500, Loss function: 5.767, Average Loss: 3.470, avg. samples / sec: 53872.56
Iteration:    500, Loss function: 6.342, Average Loss: 3.483, avg. samples / sec: 53983.81
Iteration:    500, Loss function: 6.433, Average Loss: 3.467, avg. samples / sec: 53921.70
Iteration:    500, Loss function: 6.322, Average Loss: 3.458, avg. samples / sec: 53967.74
Iteration:    500, Loss function: 6.280, Average Loss: 3.483, avg. samples / sec: 54097.88
Iteration:    500, Loss function: 6.405, Average Loss: 3.461, avg. samples / sec: 53848.88
Iteration:    500, Loss function: 5.953, Average Loss: 3.471, avg. samples / sec: 54934.56
Iteration:    500, Loss function: 6.501, Average Loss: 3.471, avg. samples / sec: 53965.78
Iteration:    500, Loss function: 5.941, Average Loss: 3.471, avg. samples / sec: 54075.78
Iteration:    500, Loss function: 6.078, Average Loss: 3.473, avg. samples / sec: 54018.32
Iteration:    500, Loss function: 6.106, Average Loss: 3.465, avg. samples / sec: 53973.12
Iteration:    500, Loss function: 5.766, Average Loss: 3.484, avg. samples / sec: 54001.18
Iteration:    500, Loss function: 7.912, Average Loss: 3.449, avg. samples / sec: 53911.80
Iteration:    500, Loss function: 5.748, Average Loss: 3.491, avg. samples / sec: 53525.56
Iteration:    500, Loss function: 7.198, Average Loss: 3.460, avg. samples / sec: 54009.90
Iteration:    500, Loss function: 6.832, Average Loss: 3.467, avg. samples / sec: 53953.72
Iteration:    500, Loss function: 6.098, Average Loss: 3.487, avg. samples / sec: 53979.20
Iteration:    500, Loss function: 5.672, Average Loss: 3.500, avg. samples / sec: 53761.39
Iteration:    500, Loss function: 5.016, Average Loss: 3.483, avg. samples / sec: 53965.72
Iteration:    520, Loss function: 5.279, Average Loss: 3.512, avg. samples / sec: 53529.62
Iteration:    520, Loss function: 6.811, Average Loss: 3.530, avg. samples / sec: 53661.23
Iteration:    520, Loss function: 6.498, Average Loss: 3.524, avg. samples / sec: 53540.28
Iteration:    520, Loss function: 7.281, Average Loss: 3.544, avg. samples / sec: 53894.02
Iteration:    520, Loss function: 7.872, Average Loss: 3.523, avg. samples / sec: 53562.70
Iteration:    520, Loss function: 6.821, Average Loss: 3.526, avg. samples / sec: 53675.44
Iteration:    520, Loss function: 5.772, Average Loss: 3.521, avg. samples / sec: 53536.78
Iteration:    520, Loss function: 6.274, Average Loss: 3.495, avg. samples / sec: 53475.21
Iteration:    520, Loss function: 5.774, Average Loss: 3.512, avg. samples / sec: 53828.67
Iteration:    520, Loss function: 6.217, Average Loss: 3.515, avg. samples / sec: 53542.88
Iteration:    520, Loss function: 5.971, Average Loss: 3.518, avg. samples / sec: 53523.99
Iteration:    520, Loss function: 6.366, Average Loss: 3.531, avg. samples / sec: 53553.28
Iteration:    520, Loss function: 5.519, Average Loss: 3.516, avg. samples / sec: 53552.45
Iteration:    520, Loss function: 6.131, Average Loss: 3.540, avg. samples / sec: 53555.27
Iteration:    520, Loss function: 5.530, Average Loss: 3.545, avg. samples / sec: 53420.34
Iteration:    520, Loss function: 5.509, Average Loss: 3.512, avg. samples / sec: 53548.48
Iteration:    520, Loss function: 6.881, Average Loss: 3.533, avg. samples / sec: 53448.86
Iteration:    520, Loss function: 6.617, Average Loss: 3.525, avg. samples / sec: 53528.63
Iteration:    520, Loss function: 6.080, Average Loss: 3.506, avg. samples / sec: 53557.33
Iteration:    520, Loss function: 6.588, Average Loss: 3.526, avg. samples / sec: 53520.68
Iteration:    520, Loss function: 6.301, Average Loss: 3.522, avg. samples / sec: 53528.30
Iteration:    520, Loss function: 6.169, Average Loss: 3.532, avg. samples / sec: 53522.41
Iteration:    520, Loss function: 6.681, Average Loss: 3.529, avg. samples / sec: 53500.10
Iteration:    520, Loss function: 5.575, Average Loss: 3.549, avg. samples / sec: 53557.98
Iteration:    520, Loss function: 6.584, Average Loss: 3.532, avg. samples / sec: 53211.61
Iteration:    520, Loss function: 5.929, Average Loss: 3.523, avg. samples / sec: 53519.64
Iteration:    520, Loss function: 6.629, Average Loss: 3.547, avg. samples / sec: 53529.72
Iteration:    520, Loss function: 7.312, Average Loss: 3.540, avg. samples / sec: 53572.58
Iteration:    520, Loss function: 5.832, Average Loss: 3.541, avg. samples / sec: 52944.14
Iteration:    520, Loss function: 6.640, Average Loss: 3.537, avg. samples / sec: 52318.34
Iteration:    540, Loss function: 6.286, Average Loss: 3.586, avg. samples / sec: 53948.30
Iteration:    540, Loss function: 6.782, Average Loss: 3.599, avg. samples / sec: 53729.83
Iteration:    540, Loss function: 5.566, Average Loss: 3.572, avg. samples / sec: 53831.56
Iteration:    540, Loss function: 7.123, Average Loss: 3.570, avg. samples / sec: 53651.92
Iteration:    540, Loss function: 5.672, Average Loss: 3.581, avg. samples / sec: 53692.70
Iteration:    540, Loss function: 6.371, Average Loss: 3.579, avg. samples / sec: 53641.44
Iteration:    540, Loss function: 5.229, Average Loss: 3.600, avg. samples / sec: 53755.65
Iteration:    540, Loss function: 6.936, Average Loss: 3.570, avg. samples / sec: 53681.71
Iteration:    540, Loss function: 6.003, Average Loss: 3.585, avg. samples / sec: 53704.38
Iteration:    540, Loss function: 6.737, Average Loss: 3.549, avg. samples / sec: 53622.97
Iteration:    540, Loss function: 5.890, Average Loss: 3.563, avg. samples / sec: 53694.88
Iteration:    540, Loss function: 7.000, Average Loss: 3.563, avg. samples / sec: 53631.52
Iteration:    540, Loss function: 5.706, Average Loss: 3.584, avg. samples / sec: 53858.68
Iteration:    540, Loss function: 5.752, Average Loss: 3.582, avg. samples / sec: 53519.72
Iteration:    540, Loss function: 6.492, Average Loss: 3.585, avg. samples / sec: 53867.94
Iteration:    540, Loss function: 6.120, Average Loss: 3.571, avg. samples / sec: 53919.30
Iteration:    540, Loss function: 5.578, Average Loss: 3.578, avg. samples / sec: 53495.91
Iteration:    540, Loss function: 5.436, Average Loss: 3.595, avg. samples / sec: 54847.60
Iteration:    540, Loss function: 6.991, Average Loss: 3.594, avg. samples / sec: 53828.03
Iteration:    540, Loss function: 7.683, Average Loss: 3.604, avg. samples / sec: 53823.51
Iteration:    540, Loss function: 5.298, Average Loss: 3.571, avg. samples / sec: 53694.99
Iteration:    540, Loss function: 6.564, Average Loss: 3.579, avg. samples / sec: 53668.51
Iteration:    540, Loss function: 5.958, Average Loss: 3.583, avg. samples / sec: 53713.67
Iteration:    540, Loss function: 4.647, Average Loss: 3.594, avg. samples / sec: 54274.48
Iteration:    540, Loss function: 6.272, Average Loss: 3.559, avg. samples / sec: 53636.42
Iteration:    540, Loss function: 6.070, Average Loss: 3.601, avg. samples / sec: 53648.91
Iteration:    540, Loss function: 6.547, Average Loss: 3.589, avg. samples / sec: 53587.39
Iteration:    540, Loss function: 5.553, Average Loss: 3.581, avg. samples / sec: 53052.20
Iteration:    540, Loss function: 7.045, Average Loss: 3.572, avg. samples / sec: 53213.20
Iteration:    540, Loss function: 5.610, Average Loss: 3.597, avg. samples / sec: 52980.62
:::MLL 1558640583.616 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558640583.617 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 5.784, Average Loss: 3.619, avg. samples / sec: 53550.84
Iteration:    560, Loss function: 6.515, Average Loss: 3.625, avg. samples / sec: 53415.86
Iteration:    560, Loss function: 6.014, Average Loss: 3.629, avg. samples / sec: 53444.93
Iteration:    560, Loss function: 5.983, Average Loss: 3.629, avg. samples / sec: 53423.47
Iteration:    560, Loss function: 4.684, Average Loss: 3.650, avg. samples / sec: 53364.40
Iteration:    560, Loss function: 6.647, Average Loss: 3.652, avg. samples / sec: 53470.97
Iteration:    560, Loss function: 6.394, Average Loss: 3.631, avg. samples / sec: 54004.54
Iteration:    560, Loss function: 5.459, Average Loss: 3.625, avg. samples / sec: 53574.59
Iteration:    560, Loss function: 5.284, Average Loss: 3.626, avg. samples / sec: 53342.53
Iteration:    560, Loss function: 5.850, Average Loss: 3.644, avg. samples / sec: 54183.97
Iteration:    560, Loss function: 6.273, Average Loss: 3.649, avg. samples / sec: 53601.88
Iteration:    560, Loss function: 6.873, Average Loss: 3.634, avg. samples / sec: 53210.07
Iteration:    560, Loss function: 5.813, Average Loss: 3.610, avg. samples / sec: 53414.69
Iteration:    560, Loss function: 7.153, Average Loss: 3.639, avg. samples / sec: 53395.30
Iteration:    560, Loss function: 5.482, Average Loss: 3.621, avg. samples / sec: 53561.67
Iteration:    560, Loss function: 6.972, Average Loss: 3.624, avg. samples / sec: 53817.71
Iteration:    560, Loss function: 6.269, Average Loss: 3.632, avg. samples / sec: 53563.09
Iteration:    560, Loss function: 5.513, Average Loss: 3.642, avg. samples / sec: 53621.64
Iteration:    560, Loss function: 6.348, Average Loss: 3.625, avg. samples / sec: 53347.76
Iteration:    560, Loss function: 5.913, Average Loss: 3.632, avg. samples / sec: 53324.28
Iteration:    560, Loss function: 6.008, Average Loss: 3.656, avg. samples / sec: 53422.20
Iteration:    560, Loss function: 5.613, Average Loss: 3.649, avg. samples / sec: 53425.42
Iteration:    560, Loss function: 6.058, Average Loss: 3.636, avg. samples / sec: 53306.71
Iteration:    560, Loss function: 6.725, Average Loss: 3.650, avg. samples / sec: 53493.17
Iteration:    560, Loss function: 5.405, Average Loss: 3.636, avg. samples / sec: 53232.48
Iteration:    560, Loss function: 7.497, Average Loss: 3.600, avg. samples / sec: 53201.43
Iteration:    560, Loss function: 5.222, Average Loss: 3.615, avg. samples / sec: 53192.35
Iteration:    560, Loss function: 5.940, Average Loss: 3.638, avg. samples / sec: 53389.21
Iteration:    560, Loss function: 6.132, Average Loss: 3.615, avg. samples / sec: 53404.06
Iteration:    560, Loss function: 5.737, Average Loss: 3.649, avg. samples / sec: 53381.83
Iteration:    580, Loss function: 5.608, Average Loss: 3.676, avg. samples / sec: 54061.38
Iteration:    580, Loss function: 5.369, Average Loss: 3.701, avg. samples / sec: 53948.28
Iteration:    580, Loss function: 5.699, Average Loss: 3.677, avg. samples / sec: 53925.27
Iteration:    580, Loss function: 6.362, Average Loss: 3.675, avg. samples / sec: 53958.36
Iteration:    580, Loss function: 6.501, Average Loss: 3.690, avg. samples / sec: 54236.33
Iteration:    580, Loss function: 6.684, Average Loss: 3.679, avg. samples / sec: 53877.81
Iteration:    580, Loss function: 5.926, Average Loss: 3.681, avg. samples / sec: 53814.28
Iteration:    580, Loss function: 6.733, Average Loss: 3.670, avg. samples / sec: 54065.94
Iteration:    580, Loss function: 6.864, Average Loss: 3.690, avg. samples / sec: 53920.13
Iteration:    580, Loss function: 6.658, Average Loss: 3.671, avg. samples / sec: 53766.19
Iteration:    580, Loss function: 6.680, Average Loss: 3.681, avg. samples / sec: 53814.63
Iteration:    580, Loss function: 6.669, Average Loss: 3.665, avg. samples / sec: 53910.52
Iteration:    580, Loss function: 6.094, Average Loss: 3.684, avg. samples / sec: 54028.18
Iteration:    580, Loss function: 6.137, Average Loss: 3.689, avg. samples / sec: 54153.30
Iteration:    580, Loss function: 6.864, Average Loss: 3.687, avg. samples / sec: 53855.92
Iteration:    580, Loss function: 5.293, Average Loss: 3.696, avg. samples / sec: 53728.95
Iteration:    580, Loss function: 5.545, Average Loss: 3.696, avg. samples / sec: 53783.90
Iteration:    580, Loss function: 5.874, Average Loss: 3.704, avg. samples / sec: 53906.83
Iteration:    580, Loss function: 5.803, Average Loss: 3.697, avg. samples / sec: 53664.19
Iteration:    580, Loss function: 5.851, Average Loss: 3.671, avg. samples / sec: 53755.04
Iteration:    580, Loss function: 7.496, Average Loss: 3.689, avg. samples / sec: 53798.27
Iteration:    580, Loss function: 5.637, Average Loss: 3.685, avg. samples / sec: 53758.69
Iteration:    580, Loss function: 6.260, Average Loss: 3.682, avg. samples / sec: 53822.11
Iteration:    580, Loss function: 6.001, Average Loss: 3.670, avg. samples / sec: 53930.80
Iteration:    580, Loss function: 5.973, Average Loss: 3.668, avg. samples / sec: 53896.08
Iteration:    580, Loss function: 6.279, Average Loss: 3.702, avg. samples / sec: 53964.19
Iteration:    580, Loss function: 6.189, Average Loss: 3.647, avg. samples / sec: 53796.30
Iteration:    580, Loss function: 5.816, Average Loss: 3.703, avg. samples / sec: 53645.71
Iteration:    580, Loss function: 5.057, Average Loss: 3.704, avg. samples / sec: 53621.97
Iteration:    580, Loss function: 5.929, Average Loss: 3.673, avg. samples / sec: 53452.79
Iteration:    600, Loss function: 7.255, Average Loss: 3.749, avg. samples / sec: 53032.16
Iteration:    600, Loss function: 6.341, Average Loss: 3.720, avg. samples / sec: 53036.21
Iteration:    600, Loss function: 6.069, Average Loss: 3.723, avg. samples / sec: 52909.77
Iteration:    600, Loss function: 6.026, Average Loss: 3.694, avg. samples / sec: 53443.02
Iteration:    600, Loss function: 6.235, Average Loss: 3.728, avg. samples / sec: 52928.35
Iteration:    600, Loss function: 5.167, Average Loss: 3.730, avg. samples / sec: 53065.27
Iteration:    600, Loss function: 7.180, Average Loss: 3.722, avg. samples / sec: 52971.12
Iteration:    600, Loss function: 6.010, Average Loss: 3.746, avg. samples / sec: 53174.97
Iteration:    600, Loss function: 5.336, Average Loss: 3.741, avg. samples / sec: 53024.66
Iteration:    600, Loss function: 5.773, Average Loss: 3.726, avg. samples / sec: 52915.06
Iteration:    600, Loss function: 5.434, Average Loss: 3.730, avg. samples / sec: 52928.59
Iteration:    600, Loss function: 5.790, Average Loss: 3.722, avg. samples / sec: 53464.09
Iteration:    600, Loss function: 6.543, Average Loss: 3.731, avg. samples / sec: 52935.89
Iteration:    600, Loss function: 6.765, Average Loss: 3.742, avg. samples / sec: 52897.24
Iteration:    600, Loss function: 5.974, Average Loss: 3.737, avg. samples / sec: 53076.64
Iteration:    600, Loss function: 5.668, Average Loss: 3.748, avg. samples / sec: 53011.19
Iteration:    600, Loss function: 5.321, Average Loss: 3.706, avg. samples / sec: 52810.40
Iteration:    600, Loss function: 4.634, Average Loss: 3.715, avg. samples / sec: 53018.93
Iteration:    600, Loss function: 5.841, Average Loss: 3.733, avg. samples / sec: 52639.04
Iteration:    600, Loss function: 5.974, Average Loss: 3.739, avg. samples / sec: 52955.24
Iteration:    600, Loss function: 5.511, Average Loss: 3.716, avg. samples / sec: 52932.98
Iteration:    600, Loss function: 6.349, Average Loss: 3.736, avg. samples / sec: 52742.59
Iteration:    600, Loss function: 6.755, Average Loss: 3.732, avg. samples / sec: 52937.00
Iteration:    600, Loss function: 5.816, Average Loss: 3.742, avg. samples / sec: 52781.09
Iteration:    600, Loss function: 5.235, Average Loss: 3.750, avg. samples / sec: 53101.38
Iteration:    600, Loss function: 5.759, Average Loss: 3.749, avg. samples / sec: 52950.46
Iteration:    600, Loss function: 6.520, Average Loss: 3.749, avg. samples / sec: 53081.56
Iteration:    600, Loss function: 5.537, Average Loss: 3.714, avg. samples / sec: 52942.95
Iteration:    600, Loss function: 6.732, Average Loss: 3.720, avg. samples / sec: 52654.44
Iteration:    600, Loss function: 6.677, Average Loss: 3.726, avg. samples / sec: 52074.83
Iteration:    620, Loss function: 5.935, Average Loss: 3.761, avg. samples / sec: 53332.50
Iteration:    620, Loss function: 4.980, Average Loss: 3.771, avg. samples / sec: 54264.97
Iteration:    620, Loss function: 6.599, Average Loss: 3.775, avg. samples / sec: 53479.55
Iteration:    620, Loss function: 7.277, Average Loss: 3.771, avg. samples / sec: 53279.51
Iteration:    620, Loss function: 7.268, Average Loss: 3.797, avg. samples / sec: 53188.76
Iteration:    620, Loss function: 5.531, Average Loss: 3.771, avg. samples / sec: 53359.53
Iteration:    620, Loss function: 6.206, Average Loss: 3.786, avg. samples / sec: 53467.54
Iteration:    620, Loss function: 5.552, Average Loss: 3.772, avg. samples / sec: 53629.64
Iteration:    620, Loss function: 5.310, Average Loss: 3.789, avg. samples / sec: 53343.26
Iteration:    620, Loss function: 4.390, Average Loss: 3.769, avg. samples / sec: 53304.66
Iteration:    620, Loss function: 5.824, Average Loss: 3.769, avg. samples / sec: 53349.07
Iteration:    620, Loss function: 6.268, Average Loss: 3.736, avg. samples / sec: 53184.94
Iteration:    620, Loss function: 5.719, Average Loss: 3.762, avg. samples / sec: 53366.38
Iteration:    620, Loss function: 5.136, Average Loss: 3.762, avg. samples / sec: 53618.89
Iteration:    620, Loss function: 5.261, Average Loss: 3.788, avg. samples / sec: 53329.09
Iteration:    620, Loss function: 6.785, Average Loss: 3.772, avg. samples / sec: 53358.97
Iteration:    620, Loss function: 5.811, Average Loss: 3.750, avg. samples / sec: 53468.98
Iteration:    620, Loss function: 5.980, Average Loss: 3.783, avg. samples / sec: 53405.36
Iteration:    620, Loss function: 7.430, Average Loss: 3.769, avg. samples / sec: 53247.74
Iteration:    620, Loss function: 5.659, Average Loss: 3.791, avg. samples / sec: 53528.75
Iteration:    620, Loss function: 5.910, Average Loss: 3.759, avg. samples / sec: 53385.79
Iteration:    620, Loss function: 6.888, Average Loss: 3.787, avg. samples / sec: 53298.67
Iteration:    620, Loss function: 6.256, Average Loss: 3.785, avg. samples / sec: 53406.23
Iteration:    620, Loss function: 5.720, Average Loss: 3.781, avg. samples / sec: 53340.45
Iteration:    620, Loss function: 6.039, Average Loss: 3.756, avg. samples / sec: 53388.74
Iteration:    620, Loss function: 6.952, Average Loss: 3.790, avg. samples / sec: 53371.92
Iteration:    620, Loss function: 5.509, Average Loss: 3.761, avg. samples / sec: 53344.08
Iteration:    620, Loss function: 5.649, Average Loss: 3.778, avg. samples / sec: 53350.24
Iteration:    620, Loss function: 5.830, Average Loss: 3.778, avg. samples / sec: 53338.13
Iteration:    620, Loss function: 6.649, Average Loss: 3.795, avg. samples / sec: 53316.29
:::MLL 1558640585.822 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558640585.822 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 5.525, Average Loss: 3.801, avg. samples / sec: 53695.46
Iteration:    640, Loss function: 5.265, Average Loss: 3.838, avg. samples / sec: 53784.72
Iteration:    640, Loss function: 5.560, Average Loss: 3.779, avg. samples / sec: 53836.83
Iteration:    640, Loss function: 5.993, Average Loss: 3.809, avg. samples / sec: 53680.71
Iteration:    640, Loss function: 5.598, Average Loss: 3.813, avg. samples / sec: 53682.61
Iteration:    640, Loss function: 6.629, Average Loss: 3.831, avg. samples / sec: 53777.36
Iteration:    640, Loss function: 5.312, Average Loss: 3.826, avg. samples / sec: 54025.71
Iteration:    640, Loss function: 4.955, Average Loss: 3.814, avg. samples / sec: 53761.25
Iteration:    640, Loss function: 5.213, Average Loss: 3.818, avg. samples / sec: 53640.85
Iteration:    640, Loss function: 5.174, Average Loss: 3.807, avg. samples / sec: 53821.14
Iteration:    640, Loss function: 5.981, Average Loss: 3.793, avg. samples / sec: 53789.32
Iteration:    640, Loss function: 5.939, Average Loss: 3.824, avg. samples / sec: 53756.33
Iteration:    640, Loss function: 5.652, Average Loss: 3.824, avg. samples / sec: 53652.71
Iteration:    640, Loss function: 5.000, Average Loss: 3.815, avg. samples / sec: 53654.80
Iteration:    640, Loss function: 5.748, Average Loss: 3.810, avg. samples / sec: 53720.69
Iteration:    640, Loss function: 5.536, Average Loss: 3.812, avg. samples / sec: 53739.66
Iteration:    640, Loss function: 6.117, Average Loss: 3.806, avg. samples / sec: 53687.95
Iteration:    640, Loss function: 5.552, Average Loss: 3.826, avg. samples / sec: 53681.90
Iteration:    640, Loss function: 6.385, Average Loss: 3.824, avg. samples / sec: 53485.80
Iteration:    640, Loss function: 5.807, Average Loss: 3.820, avg. samples / sec: 53781.50
Iteration:    640, Loss function: 4.332, Average Loss: 3.824, avg. samples / sec: 53697.83
Iteration:    640, Loss function: 5.478, Average Loss: 3.803, avg. samples / sec: 53639.28
Iteration:    640, Loss function: 5.864, Average Loss: 3.809, avg. samples / sec: 53740.32
Iteration:    640, Loss function: 5.828, Average Loss: 3.832, avg. samples / sec: 53578.61
Iteration:    640, Loss function: 6.268, Average Loss: 3.818, avg. samples / sec: 53736.90
Iteration:    640, Loss function: 5.612, Average Loss: 3.796, avg. samples / sec: 53706.47
Iteration:    640, Loss function: 6.900, Average Loss: 3.799, avg. samples / sec: 53474.27
Iteration:    640, Loss function: 5.273, Average Loss: 3.828, avg. samples / sec: 53713.96
Iteration:    640, Loss function: 4.764, Average Loss: 3.837, avg. samples / sec: 53762.93
Iteration:    640, Loss function: 6.626, Average Loss: 3.831, avg. samples / sec: 53604.12
Iteration:    660, Loss function: 5.723, Average Loss: 3.853, avg. samples / sec: 53475.07
Iteration:    660, Loss function: 5.531, Average Loss: 3.857, avg. samples / sec: 53429.83
Iteration:    660, Loss function: 4.847, Average Loss: 3.878, avg. samples / sec: 53313.99
Iteration:    660, Loss function: 7.419, Average Loss: 3.848, avg. samples / sec: 53684.04
Iteration:    660, Loss function: 6.317, Average Loss: 3.838, avg. samples / sec: 53353.78
Iteration:    660, Loss function: 5.866, Average Loss: 3.855, avg. samples / sec: 53350.08
Iteration:    660, Loss function: 5.189, Average Loss: 3.846, avg. samples / sec: 53171.12
Iteration:    660, Loss function: 4.871, Average Loss: 3.814, avg. samples / sec: 53249.61
Iteration:    660, Loss function: 4.834, Average Loss: 3.854, avg. samples / sec: 53343.92
Iteration:    660, Loss function: 4.928, Average Loss: 3.846, avg. samples / sec: 53338.13
Iteration:    660, Loss function: 4.813, Average Loss: 3.847, avg. samples / sec: 53371.80
Iteration:    660, Loss function: 6.348, Average Loss: 3.868, avg. samples / sec: 53551.75
Iteration:    660, Loss function: 5.666, Average Loss: 3.844, avg. samples / sec: 53290.81
Iteration:    660, Loss function: 6.255, Average Loss: 3.861, avg. samples / sec: 53286.46
Iteration:    660, Loss function: 6.309, Average Loss: 3.855, avg. samples / sec: 53272.32
Iteration:    660, Loss function: 6.777, Average Loss: 3.869, avg. samples / sec: 53379.97
Iteration:    660, Loss function: 5.649, Average Loss: 3.861, avg. samples / sec: 53252.83
Iteration:    660, Loss function: 4.855, Average Loss: 3.837, avg. samples / sec: 53509.56
Iteration:    660, Loss function: 5.101, Average Loss: 3.867, avg. samples / sec: 53144.05
Iteration:    660, Loss function: 7.857, Average Loss: 3.871, avg. samples / sec: 53353.19
Iteration:    660, Loss function: 6.488, Average Loss: 3.881, avg. samples / sec: 53428.96
Iteration:    660, Loss function: 7.042, Average Loss: 3.841, avg. samples / sec: 53406.43
Iteration:    660, Loss function: 5.806, Average Loss: 3.861, avg. samples / sec: 53392.63
Iteration:    660, Loss function: 5.547, Average Loss: 3.851, avg. samples / sec: 53367.01
Iteration:    660, Loss function: 5.899, Average Loss: 3.867, avg. samples / sec: 53063.29
Iteration:    660, Loss function: 5.910, Average Loss: 3.873, avg. samples / sec: 53334.35
Iteration:    660, Loss function: 4.635, Average Loss: 3.872, avg. samples / sec: 53351.98
Iteration:    660, Loss function: 5.782, Average Loss: 3.849, avg. samples / sec: 52946.05
Iteration:    660, Loss function: 5.790, Average Loss: 3.864, avg. samples / sec: 53313.57
Iteration:    660, Loss function: 5.019, Average Loss: 3.859, avg. samples / sec: 53158.42
Iteration:    680, Loss function: 5.718, Average Loss: 3.880, avg. samples / sec: 54361.06
Iteration:    680, Loss function: 6.501, Average Loss: 3.895, avg. samples / sec: 54421.06
Iteration:    680, Loss function: 5.069, Average Loss: 3.888, avg. samples / sec: 54619.60
Iteration:    680, Loss function: 3.818, Average Loss: 3.849, avg. samples / sec: 54288.32
Iteration:    680, Loss function: 7.059, Average Loss: 3.920, avg. samples / sec: 54176.48
Iteration:    680, Loss function: 5.480, Average Loss: 3.884, avg. samples / sec: 54285.03
Iteration:    680, Loss function: 4.329, Average Loss: 3.878, avg. samples / sec: 54285.95
Iteration:    680, Loss function: 5.350, Average Loss: 3.877, avg. samples / sec: 54213.16
Iteration:    680, Loss function: 4.889, Average Loss: 3.890, avg. samples / sec: 54057.84
Iteration:    680, Loss function: 4.972, Average Loss: 3.901, avg. samples / sec: 54368.87
Iteration:    680, Loss function: 6.213, Average Loss: 3.894, avg. samples / sec: 54271.19
Iteration:    680, Loss function: 5.070, Average Loss: 3.889, avg. samples / sec: 54206.17
Iteration:    680, Loss function: 6.493, Average Loss: 3.888, avg. samples / sec: 54261.92
Iteration:    680, Loss function: 6.494, Average Loss: 3.895, avg. samples / sec: 54029.34
Iteration:    680, Loss function: 6.413, Average Loss: 3.892, avg. samples / sec: 54147.94
Iteration:    680, Loss function: 6.111, Average Loss: 3.904, avg. samples / sec: 54219.43
Iteration:    680, Loss function: 4.369, Average Loss: 3.901, avg. samples / sec: 54411.39
Iteration:    680, Loss function: 5.634, Average Loss: 3.901, avg. samples / sec: 54227.67
Iteration:    680, Loss function: 4.656, Average Loss: 3.903, avg. samples / sec: 54272.72
Iteration:    680, Loss function: 6.077, Average Loss: 3.889, avg. samples / sec: 54250.85
Iteration:    680, Loss function: 6.937, Average Loss: 3.906, avg. samples / sec: 54040.15
Iteration:    680, Loss function: 4.206, Average Loss: 3.896, avg. samples / sec: 54207.57
Iteration:    680, Loss function: 6.114, Average Loss: 3.917, avg. samples / sec: 54182.22
Iteration:    680, Loss function: 6.160, Average Loss: 3.878, avg. samples / sec: 54080.82
Iteration:    680, Loss function: 5.781, Average Loss: 3.898, avg. samples / sec: 54385.80
Iteration:    680, Loss function: 4.255, Average Loss: 3.879, avg. samples / sec: 53853.58
Iteration:    680, Loss function: 6.762, Average Loss: 3.884, avg. samples / sec: 54157.97
Iteration:    680, Loss function: 5.026, Average Loss: 3.913, avg. samples / sec: 54217.12
Iteration:    680, Loss function: 5.931, Average Loss: 3.909, avg. samples / sec: 54226.92
Iteration:    680, Loss function: 4.954, Average Loss: 3.885, avg. samples / sec: 53952.91
:::MLL 1558640588.005 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558640588.005 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 6.685, Average Loss: 3.928, avg. samples / sec: 53957.45
Iteration:    700, Loss function: 7.925, Average Loss: 3.931, avg. samples / sec: 53899.73
Iteration:    700, Loss function: 7.508, Average Loss: 3.883, avg. samples / sec: 53817.48
Iteration:    700, Loss function: 6.060, Average Loss: 3.931, avg. samples / sec: 53903.67
Iteration:    700, Loss function: 7.099, Average Loss: 3.921, avg. samples / sec: 53833.33
Iteration:    700, Loss function: 7.720, Average Loss: 3.934, avg. samples / sec: 53852.69
Iteration:    700, Loss function: 7.343, Average Loss: 3.959, avg. samples / sec: 53766.77
Iteration:    700, Loss function: 7.567, Average Loss: 3.924, avg. samples / sec: 53791.46
Iteration:    700, Loss function: 7.091, Average Loss: 3.946, avg. samples / sec: 53861.15
Iteration:    700, Loss function: 8.330, Average Loss: 3.933, avg. samples / sec: 53678.50
Iteration:    700, Loss function: 6.581, Average Loss: 3.934, avg. samples / sec: 53801.03
Iteration:    700, Loss function: 6.694, Average Loss: 3.929, avg. samples / sec: 53674.23
Iteration:    700, Loss function: 6.220, Average Loss: 3.917, avg. samples / sec: 53940.42
Iteration:    700, Loss function: 6.971, Average Loss: 3.935, avg. samples / sec: 53678.20
Iteration:    700, Loss function: 7.269, Average Loss: 3.930, avg. samples / sec: 53711.69
Iteration:    700, Loss function: 7.292, Average Loss: 3.956, avg. samples / sec: 53899.24
Iteration:    700, Loss function: 7.777, Average Loss: 3.927, avg. samples / sec: 53846.29
Iteration:    700, Loss function: 7.022, Average Loss: 3.932, avg. samples / sec: 53874.74
Iteration:    700, Loss function: 8.330, Average Loss: 3.949, avg. samples / sec: 53914.72
Iteration:    700, Loss function: 7.599, Average Loss: 3.943, avg. samples / sec: 53824.00
Iteration:    700, Loss function: 6.931, Average Loss: 3.956, avg. samples / sec: 53852.32
Iteration:    700, Loss function: 7.723, Average Loss: 3.920, avg. samples / sec: 53800.99
Iteration:    700, Loss function: 7.680, Average Loss: 3.942, avg. samples / sec: 53678.89
Iteration:    700, Loss function: 8.734, Average Loss: 3.945, avg. samples / sec: 53651.00
Iteration:    700, Loss function: 6.034, Average Loss: 3.943, avg. samples / sec: 53574.47
Iteration:    700, Loss function: 6.913, Average Loss: 3.921, avg. samples / sec: 53711.67
Iteration:    700, Loss function: 7.645, Average Loss: 3.937, avg. samples / sec: 53684.27
Iteration:    700, Loss function: 6.761, Average Loss: 3.925, avg. samples / sec: 53692.90
Iteration:    700, Loss function: 6.525, Average Loss: 3.913, avg. samples / sec: 52999.83
Iteration:    700, Loss function: 8.311, Average Loss: 3.923, avg. samples / sec: 52644.10
Iteration:    720, Loss function: 6.705, Average Loss: 3.981, avg. samples / sec: 54313.59
Iteration:    720, Loss function: 6.824, Average Loss: 4.000, avg. samples / sec: 53631.68
Iteration:    720, Loss function: 6.473, Average Loss: 3.950, avg. samples / sec: 53490.47
Iteration:    720, Loss function: 7.125, Average Loss: 4.002, avg. samples / sec: 53681.00
Iteration:    720, Loss function: 8.179, Average Loss: 4.027, avg. samples / sec: 53512.69
Iteration:    720, Loss function: 7.409, Average Loss: 3.998, avg. samples / sec: 53698.44
Iteration:    720, Loss function: 5.938, Average Loss: 3.990, avg. samples / sec: 53406.53
Iteration:    720, Loss function: 6.794, Average Loss: 3.987, avg. samples / sec: 53418.03
Iteration:    720, Loss function: 6.623, Average Loss: 3.986, avg. samples / sec: 53851.07
Iteration:    720, Loss function: 6.909, Average Loss: 3.997, avg. samples / sec: 53423.51
Iteration:    720, Loss function: 6.604, Average Loss: 3.988, avg. samples / sec: 53408.88
Iteration:    720, Loss function: 5.634, Average Loss: 3.995, avg. samples / sec: 53470.64
Iteration:    720, Loss function: 7.095, Average Loss: 3.988, avg. samples / sec: 53420.58
Iteration:    720, Loss function: 7.104, Average Loss: 3.998, avg. samples / sec: 53340.23
Iteration:    720, Loss function: 6.325, Average Loss: 4.000, avg. samples / sec: 53521.86
Iteration:    720, Loss function: 7.413, Average Loss: 3.994, avg. samples / sec: 53747.55
Iteration:    720, Loss function: 6.474, Average Loss: 4.014, avg. samples / sec: 53317.63
Iteration:    720, Loss function: 7.735, Average Loss: 4.013, avg. samples / sec: 53451.17
Iteration:    720, Loss function: 6.691, Average Loss: 4.006, avg. samples / sec: 53595.27
Iteration:    720, Loss function: 6.940, Average Loss: 4.011, avg. samples / sec: 53543.49
Iteration:    720, Loss function: 5.472, Average Loss: 4.026, avg. samples / sec: 53449.25
Iteration:    720, Loss function: 6.395, Average Loss: 3.985, avg. samples / sec: 53313.83
Iteration:    720, Loss function: 6.204, Average Loss: 4.012, avg. samples / sec: 53370.41
Iteration:    720, Loss function: 7.204, Average Loss: 4.014, avg. samples / sec: 53534.50
Iteration:    720, Loss function: 7.620, Average Loss: 3.993, avg. samples / sec: 53311.19
Iteration:    720, Loss function: 6.550, Average Loss: 4.019, avg. samples / sec: 53303.21
Iteration:    720, Loss function: 7.249, Average Loss: 3.986, avg. samples / sec: 53432.61
Iteration:    720, Loss function: 6.090, Average Loss: 3.997, avg. samples / sec: 53155.03
Iteration:    720, Loss function: 7.326, Average Loss: 3.987, avg. samples / sec: 53856.02
Iteration:    720, Loss function: 6.733, Average Loss: 4.015, avg. samples / sec: 52759.71
Iteration:    740, Loss function: 5.258, Average Loss: 4.038, avg. samples / sec: 53943.14
Iteration:    740, Loss function: 5.694, Average Loss: 4.042, avg. samples / sec: 54335.98
Iteration:    740, Loss function: 7.189, Average Loss: 4.072, avg. samples / sec: 54078.60
Iteration:    740, Loss function: 6.332, Average Loss: 3.992, avg. samples / sec: 53667.08
Iteration:    740, Loss function: 6.938, Average Loss: 4.038, avg. samples / sec: 53712.42
Iteration:    740, Loss function: 5.967, Average Loss: 4.040, avg. samples / sec: 53777.56
Iteration:    740, Loss function: 6.606, Average Loss: 4.058, avg. samples / sec: 54799.30
Iteration:    740, Loss function: 6.513, Average Loss: 4.031, avg. samples / sec: 53649.55
Iteration:    740, Loss function: 6.081, Average Loss: 4.031, avg. samples / sec: 53856.81
Iteration:    740, Loss function: 5.442, Average Loss: 4.026, avg. samples / sec: 53412.20
Iteration:    740, Loss function: 5.025, Average Loss: 4.035, avg. samples / sec: 53885.08
Iteration:    740, Loss function: 6.335, Average Loss: 4.063, avg. samples / sec: 53837.92
Iteration:    740, Loss function: 5.967, Average Loss: 4.046, avg. samples / sec: 53429.59
Iteration:    740, Loss function: 6.445, Average Loss: 4.042, avg. samples / sec: 53553.28
Iteration:    740, Loss function: 6.356, Average Loss: 4.044, avg. samples / sec: 53519.91
Iteration:    740, Loss function: 6.386, Average Loss: 4.032, avg. samples / sec: 54222.56
Iteration:    740, Loss function: 4.594, Average Loss: 4.057, avg. samples / sec: 53602.78
Iteration:    740, Loss function: 5.928, Average Loss: 4.059, avg. samples / sec: 53677.62
Iteration:    740, Loss function: 6.298, Average Loss: 4.034, avg. samples / sec: 53383.99
Iteration:    740, Loss function: 6.060, Average Loss: 4.032, avg. samples / sec: 53382.64
Iteration:    740, Loss function: 6.380, Average Loss: 4.030, avg. samples / sec: 53604.29
Iteration:    740, Loss function: 7.267, Average Loss: 4.046, avg. samples / sec: 53140.20
Iteration:    740, Loss function: 5.768, Average Loss: 4.035, avg. samples / sec: 53269.52
Iteration:    740, Loss function: 5.547, Average Loss: 4.069, avg. samples / sec: 53158.40
Iteration:    740, Loss function: 5.263, Average Loss: 4.035, avg. samples / sec: 53177.52
Iteration:    740, Loss function: 5.361, Average Loss: 4.049, avg. samples / sec: 53436.50
Iteration:    740, Loss function: 5.009, Average Loss: 4.061, avg. samples / sec: 53409.65
Iteration:    740, Loss function: 5.998, Average Loss: 4.043, avg. samples / sec: 53256.47
Iteration:    740, Loss function: 5.822, Average Loss: 4.061, avg. samples / sec: 53283.82
Iteration:    740, Loss function: 5.780, Average Loss: 4.059, avg. samples / sec: 53151.61
Iteration:    760, Loss function: 5.216, Average Loss: 4.078, avg. samples / sec: 54105.20
Iteration:    760, Loss function: 4.401, Average Loss: 4.071, avg. samples / sec: 53875.34
Iteration:    760, Loss function: 6.858, Average Loss: 4.069, avg. samples / sec: 53479.85
Iteration:    760, Loss function: 5.098, Average Loss: 4.102, avg. samples / sec: 53421.94
Iteration:    760, Loss function: 6.090, Average Loss: 4.099, avg. samples / sec: 54007.80
Iteration:    760, Loss function: 5.299, Average Loss: 4.062, avg. samples / sec: 53625.91
Iteration:    760, Loss function: 5.840, Average Loss: 4.073, avg. samples / sec: 53227.55
Iteration:    760, Loss function: 6.480, Average Loss: 4.031, avg. samples / sec: 53383.37
Iteration:    760, Loss function: 6.879, Average Loss: 4.075, avg. samples / sec: 53395.66
Iteration:    760, Loss function: 4.274, Average Loss: 4.061, avg. samples / sec: 53761.42
Iteration:    760, Loss function: 6.397, Average Loss: 4.064, avg. samples / sec: 53447.63
Iteration:    760, Loss function: 4.548, Average Loss: 4.070, avg. samples / sec: 53681.75
Iteration:    760, Loss function: 5.029, Average Loss: 4.067, avg. samples / sec: 53876.49
Iteration:    760, Loss function: 5.783, Average Loss: 4.078, avg. samples / sec: 53608.24
Iteration:    760, Loss function: 4.566, Average Loss: 4.079, avg. samples / sec: 53587.67
Iteration:    760, Loss function: 6.226, Average Loss: 4.066, avg. samples / sec: 53708.78
Iteration:    760, Loss function: 6.273, Average Loss: 4.086, avg. samples / sec: 53561.32
Iteration:    760, Loss function: 3.423, Average Loss: 4.063, avg. samples / sec: 53710.27
Iteration:    760, Loss function: 6.077, Average Loss: 4.089, avg. samples / sec: 53241.93
Iteration:    760, Loss function: 5.749, Average Loss: 4.091, avg. samples / sec: 53786.71
Iteration:    760, Loss function: 5.783, Average Loss: 4.069, avg. samples / sec: 53324.40
Iteration:    760, Loss function: 6.402, Average Loss: 4.066, avg. samples / sec: 53299.94
Iteration:    760, Loss function: 5.702, Average Loss: 4.072, avg. samples / sec: 52867.85
Iteration:    760, Loss function: 5.146, Average Loss: 4.081, avg. samples / sec: 53677.50
Iteration:    760, Loss function: 6.849, Average Loss: 4.090, avg. samples / sec: 53791.01
Iteration:    760, Loss function: 5.097, Average Loss: 4.089, avg. samples / sec: 53998.49
Iteration:    760, Loss function: 4.962, Average Loss: 4.095, avg. samples / sec: 53334.68
Iteration:    760, Loss function: 4.928, Average Loss: 4.074, avg. samples / sec: 53689.57
Iteration:    760, Loss function: 5.366, Average Loss: 4.092, avg. samples / sec: 53423.09
Iteration:    760, Loss function: 5.059, Average Loss: 4.070, avg. samples / sec: 53603.45
:::MLL 1558640590.203 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558640590.203 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 5.125, Average Loss: 4.111, avg. samples / sec: 53394.73
Iteration:    780, Loss function: 4.673, Average Loss: 4.095, avg. samples / sec: 53782.92
Iteration:    780, Loss function: 5.002, Average Loss: 4.097, avg. samples / sec: 53408.07
Iteration:    780, Loss function: 5.421, Average Loss: 4.090, avg. samples / sec: 53403.47
Iteration:    780, Loss function: 4.924, Average Loss: 4.124, avg. samples / sec: 53716.68
Iteration:    780, Loss function: 5.370, Average Loss: 4.061, avg. samples / sec: 53386.60
Iteration:    780, Loss function: 5.528, Average Loss: 4.104, avg. samples / sec: 53434.41
Iteration:    780, Loss function: 4.421, Average Loss: 4.108, avg. samples / sec: 53428.86
Iteration:    780, Loss function: 5.020, Average Loss: 4.098, avg. samples / sec: 53433.08
Iteration:    780, Loss function: 5.708, Average Loss: 4.087, avg. samples / sec: 53365.37
Iteration:    780, Loss function: 5.235, Average Loss: 4.094, avg. samples / sec: 53384.36
Iteration:    780, Loss function: 5.807, Average Loss: 4.116, avg. samples / sec: 53634.70
Iteration:    780, Loss function: 5.552, Average Loss: 4.102, avg. samples / sec: 53333.67
Iteration:    780, Loss function: 5.194, Average Loss: 4.094, avg. samples / sec: 53140.94
Iteration:    780, Loss function: 5.333, Average Loss: 4.097, avg. samples / sec: 53281.80
Iteration:    780, Loss function: 4.439, Average Loss: 4.096, avg. samples / sec: 53235.27
Iteration:    780, Loss function: 6.179, Average Loss: 4.116, avg. samples / sec: 53385.51
Iteration:    780, Loss function: 6.477, Average Loss: 4.110, avg. samples / sec: 53480.42
Iteration:    780, Loss function: 6.048, Average Loss: 4.120, avg. samples / sec: 53396.88
Iteration:    780, Loss function: 5.005, Average Loss: 4.099, avg. samples / sec: 53418.27
Iteration:    780, Loss function: 5.582, Average Loss: 4.098, avg. samples / sec: 53475.84
Iteration:    780, Loss function: 5.298, Average Loss: 4.126, avg. samples / sec: 53045.53
Iteration:    780, Loss function: 5.648, Average Loss: 4.118, avg. samples / sec: 53310.28
Iteration:    780, Loss function: 4.202, Average Loss: 4.095, avg. samples / sec: 53385.87
Iteration:    780, Loss function: 5.955, Average Loss: 4.098, avg. samples / sec: 53464.13
Iteration:    780, Loss function: 5.550, Average Loss: 4.125, avg. samples / sec: 53453.91
Iteration:    780, Loss function: 5.746, Average Loss: 4.128, avg. samples / sec: 53406.23
Iteration:    780, Loss function: 5.944, Average Loss: 4.091, avg. samples / sec: 53218.83
Iteration:    780, Loss function: 5.686, Average Loss: 4.102, avg. samples / sec: 52983.95
Iteration:    780, Loss function: 5.645, Average Loss: 4.127, avg. samples / sec: 52833.96
Iteration:    800, Loss function: 5.747, Average Loss: 4.138, avg. samples / sec: 53572.31
Iteration:    800, Loss function: 4.724, Average Loss: 4.125, avg. samples / sec: 53601.49
Iteration:    800, Loss function: 6.727, Average Loss: 4.121, avg. samples / sec: 53790.43
Iteration:    800, Loss function: 4.877, Average Loss: 4.157, avg. samples / sec: 54094.67
Iteration:    800, Loss function: 5.590, Average Loss: 4.089, avg. samples / sec: 53593.42
Iteration:    800, Loss function: 5.433, Average Loss: 4.109, avg. samples / sec: 53621.83
Iteration:    800, Loss function: 6.666, Average Loss: 4.122, avg. samples / sec: 53611.36
Iteration:    800, Loss function: 5.136, Average Loss: 4.128, avg. samples / sec: 53595.23
Iteration:    800, Loss function: 5.158, Average Loss: 4.110, avg. samples / sec: 53869.41
Iteration:    800, Loss function: 6.047, Average Loss: 4.127, avg. samples / sec: 53623.74
Iteration:    800, Loss function: 4.005, Average Loss: 4.123, avg. samples / sec: 53935.15
Iteration:    800, Loss function: 4.692, Average Loss: 4.125, avg. samples / sec: 53631.36
Iteration:    800, Loss function: 5.774, Average Loss: 4.125, avg. samples / sec: 53356.16
Iteration:    800, Loss function: 6.090, Average Loss: 4.141, avg. samples / sec: 53589.61
Iteration:    800, Loss function: 4.927, Average Loss: 4.136, avg. samples / sec: 53400.19
Iteration:    800, Loss function: 5.933, Average Loss: 4.143, avg. samples / sec: 53399.77
Iteration:    800, Loss function: 5.238, Average Loss: 4.147, avg. samples / sec: 53555.99
Iteration:    800, Loss function: 5.963, Average Loss: 4.146, avg. samples / sec: 53609.02
Iteration:    800, Loss function: 5.065, Average Loss: 4.126, avg. samples / sec: 53594.13
Iteration:    800, Loss function: 5.673, Average Loss: 4.119, avg. samples / sec: 53605.47
Iteration:    800, Loss function: 4.882, Average Loss: 4.156, avg. samples / sec: 53580.79
Iteration:    800, Loss function: 6.463, Average Loss: 4.137, avg. samples / sec: 53506.70
Iteration:    800, Loss function: 6.528, Average Loss: 4.154, avg. samples / sec: 53580.48
Iteration:    800, Loss function: 5.372, Average Loss: 4.155, avg. samples / sec: 53282.85
Iteration:    800, Loss function: 5.283, Average Loss: 4.131, avg. samples / sec: 53539.32
Iteration:    800, Loss function: 5.846, Average Loss: 4.134, avg. samples / sec: 53283.48
Iteration:    800, Loss function: 5.545, Average Loss: 4.154, avg. samples / sec: 53542.52
Iteration:    800, Loss function: 4.843, Average Loss: 4.129, avg. samples / sec: 53277.33
Iteration:    800, Loss function: 5.245, Average Loss: 4.123, avg. samples / sec: 53435.43
Iteration:    800, Loss function: 5.406, Average Loss: 4.119, avg. samples / sec: 52733.94
Iteration:    820, Loss function: 5.745, Average Loss: 4.144, avg. samples / sec: 54953.00
Iteration:    820, Loss function: 5.422, Average Loss: 4.167, avg. samples / sec: 53895.63
Iteration:    820, Loss function: 5.252, Average Loss: 4.182, avg. samples / sec: 54014.70
Iteration:    820, Loss function: 5.986, Average Loss: 4.151, avg. samples / sec: 53869.88
Iteration:    820, Loss function: 5.226, Average Loss: 4.161, avg. samples / sec: 54175.89
Iteration:    820, Loss function: 5.739, Average Loss: 4.151, avg. samples / sec: 54043.90
Iteration:    820, Loss function: 5.676, Average Loss: 4.116, avg. samples / sec: 53937.11
Iteration:    820, Loss function: 4.910, Average Loss: 4.156, avg. samples / sec: 54011.86
Iteration:    820, Loss function: 7.083, Average Loss: 4.135, avg. samples / sec: 53925.99
Iteration:    820, Loss function: 5.451, Average Loss: 4.152, avg. samples / sec: 53941.26
Iteration:    820, Loss function: 5.061, Average Loss: 4.171, avg. samples / sec: 54154.28
Iteration:    820, Loss function: 5.415, Average Loss: 4.154, avg. samples / sec: 53768.45
Iteration:    820, Loss function: 5.199, Average Loss: 4.158, avg. samples / sec: 54326.03
Iteration:    820, Loss function: 4.825, Average Loss: 4.156, avg. samples / sec: 54264.19
Iteration:    820, Loss function: 4.982, Average Loss: 4.146, avg. samples / sec: 53979.61
Iteration:    820, Loss function: 5.287, Average Loss: 4.184, avg. samples / sec: 54139.45
Iteration:    820, Loss function: 4.876, Average Loss: 4.165, avg. samples / sec: 54024.20
Iteration:    820, Loss function: 5.561, Average Loss: 4.155, avg. samples / sec: 54101.58
Iteration:    820, Loss function: 4.991, Average Loss: 4.148, avg. samples / sec: 53916.04
Iteration:    820, Loss function: 4.935, Average Loss: 4.159, avg. samples / sec: 54097.03
Iteration:    820, Loss function: 6.563, Average Loss: 4.175, avg. samples / sec: 53968.92
Iteration:    820, Loss function: 4.760, Average Loss: 4.154, avg. samples / sec: 54035.39
Iteration:    820, Loss function: 6.886, Average Loss: 4.157, avg. samples / sec: 53962.21
Iteration:    820, Loss function: 5.452, Average Loss: 4.171, avg. samples / sec: 53942.17
Iteration:    820, Loss function: 5.498, Average Loss: 4.182, avg. samples / sec: 54021.26
Iteration:    820, Loss function: 5.970, Average Loss: 4.141, avg. samples / sec: 53732.88
Iteration:    820, Loss function: 5.561, Average Loss: 4.183, avg. samples / sec: 53955.10
Iteration:    820, Loss function: 5.058, Average Loss: 4.161, avg. samples / sec: 53996.47
Iteration:    820, Loss function: 5.650, Average Loss: 4.180, avg. samples / sec: 53913.55
Iteration:    820, Loss function: 4.912, Average Loss: 4.154, avg. samples / sec: 53315.65
:::MLL 1558640592.392 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558640592.393 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 5.474, Average Loss: 4.210, avg. samples / sec: 53777.36
Iteration:    840, Loss function: 5.199, Average Loss: 4.175, avg. samples / sec: 53761.07
Iteration:    840, Loss function: 4.423, Average Loss: 4.161, avg. samples / sec: 53791.19
Iteration:    840, Loss function: 5.196, Average Loss: 4.180, avg. samples / sec: 54427.28
Iteration:    840, Loss function: 5.254, Average Loss: 4.193, avg. samples / sec: 53614.09
Iteration:    840, Loss function: 4.921, Average Loss: 4.173, avg. samples / sec: 53781.23
Iteration:    840, Loss function: 5.068, Average Loss: 4.174, avg. samples / sec: 53735.67
Iteration:    840, Loss function: 6.066, Average Loss: 4.171, avg. samples / sec: 53552.97
Iteration:    840, Loss function: 5.384, Average Loss: 4.191, avg. samples / sec: 53817.89
Iteration:    840, Loss function: 5.566, Average Loss: 4.171, avg. samples / sec: 53793.59
Iteration:    840, Loss function: 4.725, Average Loss: 4.183, avg. samples / sec: 53674.90
Iteration:    840, Loss function: 6.076, Average Loss: 4.179, avg. samples / sec: 53632.46
Iteration:    840, Loss function: 5.771, Average Loss: 4.183, avg. samples / sec: 53681.65
Iteration:    840, Loss function: 5.026, Average Loss: 4.207, avg. samples / sec: 53691.08
Iteration:    840, Loss function: 6.132, Average Loss: 4.186, avg. samples / sec: 53577.61
Iteration:    840, Loss function: 4.867, Average Loss: 4.167, avg. samples / sec: 53702.56
Iteration:    840, Loss function: 4.363, Average Loss: 4.195, avg. samples / sec: 53609.81
Iteration:    840, Loss function: 6.084, Average Loss: 4.175, avg. samples / sec: 53805.38
Iteration:    840, Loss function: 6.077, Average Loss: 4.202, avg. samples / sec: 53777.50
Iteration:    840, Loss function: 4.906, Average Loss: 4.204, avg. samples / sec: 53710.64
Iteration:    840, Loss function: 5.321, Average Loss: 4.183, avg. samples / sec: 53599.82
Iteration:    840, Loss function: 4.606, Average Loss: 4.207, avg. samples / sec: 53772.86
Iteration:    840, Loss function: 4.789, Average Loss: 4.166, avg. samples / sec: 53740.20
Iteration:    840, Loss function: 5.457, Average Loss: 4.139, avg. samples / sec: 53458.29
Iteration:    840, Loss function: 5.080, Average Loss: 4.196, avg. samples / sec: 53714.02
Iteration:    840, Loss function: 4.998, Average Loss: 4.181, avg. samples / sec: 53460.26
Iteration:    840, Loss function: 4.675, Average Loss: 4.185, avg. samples / sec: 53526.37
Iteration:    840, Loss function: 4.710, Average Loss: 4.172, avg. samples / sec: 53603.98
Iteration:    840, Loss function: 6.001, Average Loss: 4.206, avg. samples / sec: 53646.40
Iteration:    840, Loss function: 5.263, Average Loss: 4.185, avg. samples / sec: 53566.00
Iteration:    860, Loss function: 6.193, Average Loss: 4.219, avg. samples / sec: 54218.93
Iteration:    860, Loss function: 4.895, Average Loss: 4.218, avg. samples / sec: 54337.92
Iteration:    860, Loss function: 5.839, Average Loss: 4.199, avg. samples / sec: 54067.85
Iteration:    860, Loss function: 6.726, Average Loss: 4.238, avg. samples / sec: 53993.22
Iteration:    860, Loss function: 5.627, Average Loss: 4.195, avg. samples / sec: 54020.56
Iteration:    860, Loss function: 6.244, Average Loss: 4.203, avg. samples / sec: 54043.53
Iteration:    860, Loss function: 4.419, Average Loss: 4.217, avg. samples / sec: 54385.84
Iteration:    860, Loss function: 6.129, Average Loss: 4.202, avg. samples / sec: 54380.05
Iteration:    860, Loss function: 4.218, Average Loss: 4.186, avg. samples / sec: 54168.23
Iteration:    860, Loss function: 4.537, Average Loss: 4.208, avg. samples / sec: 54136.66
Iteration:    860, Loss function: 5.437, Average Loss: 4.202, avg. samples / sec: 53968.22
Iteration:    860, Loss function: 3.842, Average Loss: 4.194, avg. samples / sec: 54002.76
Iteration:    860, Loss function: 5.652, Average Loss: 4.209, avg. samples / sec: 54097.03
Iteration:    860, Loss function: 6.109, Average Loss: 4.196, avg. samples / sec: 53974.34
Iteration:    860, Loss function: 4.953, Average Loss: 4.206, avg. samples / sec: 54078.58
Iteration:    860, Loss function: 3.869, Average Loss: 4.215, avg. samples / sec: 53955.12
Iteration:    860, Loss function: 6.452, Average Loss: 4.214, avg. samples / sec: 53951.81
Iteration:    860, Loss function: 3.829, Average Loss: 4.227, avg. samples / sec: 54073.95
Iteration:    860, Loss function: 6.964, Average Loss: 4.163, avg. samples / sec: 54087.23
Iteration:    860, Loss function: 6.581, Average Loss: 4.225, avg. samples / sec: 54079.95
Iteration:    860, Loss function: 6.016, Average Loss: 4.205, avg. samples / sec: 54125.44
Iteration:    860, Loss function: 5.468, Average Loss: 4.228, avg. samples / sec: 54006.83
Iteration:    860, Loss function: 6.716, Average Loss: 4.210, avg. samples / sec: 54242.08
Iteration:    860, Loss function: 6.478, Average Loss: 4.199, avg. samples / sec: 53949.25
Iteration:    860, Loss function: 4.671, Average Loss: 4.226, avg. samples / sec: 53891.22
Iteration:    860, Loss function: 5.580, Average Loss: 4.233, avg. samples / sec: 54155.28
Iteration:    860, Loss function: 5.721, Average Loss: 4.208, avg. samples / sec: 53991.96
Iteration:    860, Loss function: 6.748, Average Loss: 4.230, avg. samples / sec: 53983.27
Iteration:    860, Loss function: 5.568, Average Loss: 4.187, avg. samples / sec: 53944.69
Iteration:    860, Loss function: 6.830, Average Loss: 4.190, avg. samples / sec: 52919.71
Iteration:    880, Loss function: 5.137, Average Loss: 4.260, avg. samples / sec: 53374.00
Iteration:    880, Loss function: 4.534, Average Loss: 4.240, avg. samples / sec: 53213.80
Iteration:    880, Loss function: 6.227, Average Loss: 4.227, avg. samples / sec: 53359.17
Iteration:    880, Loss function: 4.539, Average Loss: 4.215, avg. samples / sec: 53339.62
Iteration:    880, Loss function: 5.441, Average Loss: 4.232, avg. samples / sec: 53345.21
Iteration:    880, Loss function: 4.882, Average Loss: 4.223, avg. samples / sec: 53165.82
Iteration:    880, Loss function: 4.987, Average Loss: 4.233, avg. samples / sec: 53305.38
Iteration:    880, Loss function: 4.116, Average Loss: 4.217, avg. samples / sec: 53337.44
Iteration:    880, Loss function: 4.797, Average Loss: 4.237, avg. samples / sec: 53280.17
Iteration:    880, Loss function: 4.700, Average Loss: 4.214, avg. samples / sec: 54339.62
Iteration:    880, Loss function: 4.988, Average Loss: 4.233, avg. samples / sec: 53299.03
Iteration:    880, Loss function: 4.357, Average Loss: 4.232, avg. samples / sec: 53311.66
Iteration:    880, Loss function: 5.510, Average Loss: 4.246, avg. samples / sec: 53418.25
Iteration:    880, Loss function: 5.829, Average Loss: 4.243, avg. samples / sec: 53079.84
Iteration:    880, Loss function: 4.381, Average Loss: 4.224, avg. samples / sec: 53264.12
Iteration:    880, Loss function: 5.038, Average Loss: 4.236, avg. samples / sec: 53288.96
Iteration:    880, Loss function: 6.529, Average Loss: 4.224, avg. samples / sec: 53166.18
Iteration:    880, Loss function: 5.733, Average Loss: 4.255, avg. samples / sec: 53292.93
Iteration:    880, Loss function: 4.540, Average Loss: 4.231, avg. samples / sec: 53319.32
Iteration:    880, Loss function: 6.254, Average Loss: 4.251, avg. samples / sec: 53300.95
Iteration:    880, Loss function: 6.753, Average Loss: 4.226, avg. samples / sec: 53328.54
Iteration:    880, Loss function: 5.868, Average Loss: 4.190, avg. samples / sec: 53300.99
Iteration:    880, Loss function: 4.696, Average Loss: 4.251, avg. samples / sec: 53298.89
Iteration:    880, Loss function: 4.429, Average Loss: 4.245, avg. samples / sec: 53030.28
Iteration:    880, Loss function: 5.314, Average Loss: 4.219, avg. samples / sec: 53390.00
Iteration:    880, Loss function: 5.759, Average Loss: 4.227, avg. samples / sec: 53310.14
Iteration:    880, Loss function: 5.622, Average Loss: 4.258, avg. samples / sec: 53277.11
Iteration:    880, Loss function: 5.578, Average Loss: 4.251, avg. samples / sec: 53254.10
Iteration:    880, Loss function: 5.167, Average Loss: 4.257, avg. samples / sec: 53268.29
Iteration:    880, Loss function: 6.246, Average Loss: 4.235, avg. samples / sec: 52873.09
Iteration:    900, Loss function: 4.449, Average Loss: 4.275, avg. samples / sec: 54228.76
Iteration:    900, Loss function: 3.941, Average Loss: 4.260, avg. samples / sec: 54234.16
Iteration:    900, Loss function: 5.104, Average Loss: 4.260, avg. samples / sec: 54422.01
Iteration:    900, Loss function: 5.673, Average Loss: 4.245, avg. samples / sec: 54292.14
Iteration:    900, Loss function: 5.928, Average Loss: 4.278, avg. samples / sec: 54448.08
Iteration:    900, Loss function: 4.147, Average Loss: 4.248, avg. samples / sec: 54206.32
Iteration:    900, Loss function: 3.574, Average Loss: 4.241, avg. samples / sec: 54191.20
Iteration:    900, Loss function: 3.874, Average Loss: 4.259, avg. samples / sec: 54226.28
Iteration:    900, Loss function: 5.178, Average Loss: 4.234, avg. samples / sec: 54139.49
Iteration:    900, Loss function: 5.088, Average Loss: 4.239, avg. samples / sec: 54177.10
Iteration:    900, Loss function: 5.145, Average Loss: 4.245, avg. samples / sec: 54283.59
Iteration:    900, Loss function: 4.921, Average Loss: 4.231, avg. samples / sec: 54208.21
Iteration:    900, Loss function: 5.455, Average Loss: 4.252, avg. samples / sec: 54202.15
Iteration:    900, Loss function: 4.188, Average Loss: 4.247, avg. samples / sec: 54131.80
Iteration:    900, Loss function: 5.166, Average Loss: 4.254, avg. samples / sec: 54191.22
Iteration:    900, Loss function: 5.342, Average Loss: 4.265, avg. samples / sec: 54201.42
Iteration:    900, Loss function: 5.255, Average Loss: 4.250, avg. samples / sec: 54156.13
Iteration:    900, Loss function: 5.385, Average Loss: 4.247, avg. samples / sec: 54325.40
Iteration:    900, Loss function: 5.698, Average Loss: 4.257, avg. samples / sec: 54264.51
Iteration:    900, Loss function: 5.005, Average Loss: 4.272, avg. samples / sec: 54358.93
Iteration:    900, Loss function: 3.717, Average Loss: 4.243, avg. samples / sec: 53906.00
Iteration:    900, Loss function: 4.840, Average Loss: 4.212, avg. samples / sec: 54199.64
Iteration:    900, Loss function: 4.053, Average Loss: 4.269, avg. samples / sec: 54169.15
Iteration:    900, Loss function: 4.271, Average Loss: 4.247, avg. samples / sec: 54175.54
Iteration:    900, Loss function: 6.111, Average Loss: 4.263, avg. samples / sec: 54197.35
Iteration:    900, Loss function: 5.022, Average Loss: 4.270, avg. samples / sec: 54171.60
Iteration:    900, Loss function: 5.259, Average Loss: 4.233, avg. samples / sec: 54168.83
Iteration:    900, Loss function: 4.767, Average Loss: 4.281, avg. samples / sec: 54219.56
Iteration:    900, Loss function: 6.079, Average Loss: 4.277, avg. samples / sec: 54195.14
Iteration:    900, Loss function: 5.072, Average Loss: 4.251, avg. samples / sec: 54558.72
:::MLL 1558640594.580 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558640594.580 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 4.479, Average Loss: 4.294, avg. samples / sec: 53936.31
Iteration:    920, Loss function: 5.113, Average Loss: 4.265, avg. samples / sec: 54005.80
Iteration:    920, Loss function: 5.461, Average Loss: 4.278, avg. samples / sec: 53975.58
Iteration:    920, Loss function: 4.330, Average Loss: 4.282, avg. samples / sec: 53994.67
Iteration:    920, Loss function: 5.186, Average Loss: 4.252, avg. samples / sec: 54107.40
Iteration:    920, Loss function: 4.143, Average Loss: 4.280, avg. samples / sec: 54009.98
Iteration:    920, Loss function: 5.188, Average Loss: 4.252, avg. samples / sec: 53789.22
Iteration:    920, Loss function: 5.967, Average Loss: 4.273, avg. samples / sec: 53759.24
Iteration:    920, Loss function: 4.849, Average Loss: 4.289, avg. samples / sec: 53988.69
Iteration:    920, Loss function: 5.580, Average Loss: 4.269, avg. samples / sec: 53859.38
Iteration:    920, Loss function: 4.148, Average Loss: 4.272, avg. samples / sec: 54027.70
Iteration:    920, Loss function: 5.189, Average Loss: 4.298, avg. samples / sec: 53598.94
Iteration:    920, Loss function: 4.953, Average Loss: 4.294, avg. samples / sec: 53916.93
Iteration:    920, Loss function: 5.048, Average Loss: 4.274, avg. samples / sec: 53609.51
Iteration:    920, Loss function: 4.493, Average Loss: 4.268, avg. samples / sec: 53566.69
Iteration:    920, Loss function: 4.718, Average Loss: 4.264, avg. samples / sec: 53498.02
Iteration:    920, Loss function: 5.327, Average Loss: 4.269, avg. samples / sec: 53624.80
Iteration:    920, Loss function: 5.193, Average Loss: 4.253, avg. samples / sec: 53509.74
Iteration:    920, Loss function: 5.891, Average Loss: 4.280, avg. samples / sec: 53278.86
Iteration:    920, Loss function: 4.750, Average Loss: 4.282, avg. samples / sec: 53676.46
Iteration:    920, Loss function: 5.073, Average Loss: 4.278, avg. samples / sec: 53241.79
Iteration:    920, Loss function: 5.588, Average Loss: 4.259, avg. samples / sec: 53335.22
Iteration:    920, Loss function: 5.785, Average Loss: 4.238, avg. samples / sec: 53530.78
Iteration:    920, Loss function: 5.747, Average Loss: 4.261, avg. samples / sec: 53488.68
Iteration:    920, Loss function: 6.239, Average Loss: 4.256, avg. samples / sec: 53264.55
Iteration:    920, Loss function: 4.787, Average Loss: 4.266, avg. samples / sec: 53205.18
Iteration:    920, Loss function: 4.439, Average Loss: 4.276, avg. samples / sec: 53359.56
Iteration:    920, Loss function: 3.974, Average Loss: 4.291, avg. samples / sec: 53347.40
Iteration:    920, Loss function: 4.335, Average Loss: 4.263, avg. samples / sec: 53164.14
Iteration:    920, Loss function: 6.682, Average Loss: 4.292, avg. samples / sec: 53011.61
Iteration:    940, Loss function: 4.164, Average Loss: 4.294, avg. samples / sec: 54730.66
Iteration:    940, Loss function: 4.784, Average Loss: 4.303, avg. samples / sec: 54555.07
Iteration:    940, Loss function: 6.599, Average Loss: 4.281, avg. samples / sec: 54789.39
Iteration:    940, Loss function: 6.439, Average Loss: 4.279, avg. samples / sec: 54614.07
Iteration:    940, Loss function: 4.637, Average Loss: 4.288, avg. samples / sec: 54238.78
Iteration:    940, Loss function: 5.814, Average Loss: 4.301, avg. samples / sec: 54007.91
Iteration:    940, Loss function: 5.545, Average Loss: 4.304, avg. samples / sec: 54892.15
Iteration:    940, Loss function: 5.148, Average Loss: 4.291, avg. samples / sec: 54355.34
Iteration:    940, Loss function: 5.457, Average Loss: 4.289, avg. samples / sec: 54395.45
Iteration:    940, Loss function: 5.104, Average Loss: 4.292, avg. samples / sec: 54375.89
Iteration:    940, Loss function: 3.887, Average Loss: 4.266, avg. samples / sec: 54416.14
Iteration:    940, Loss function: 5.011, Average Loss: 4.312, avg. samples / sec: 53746.57
Iteration:    940, Loss function: 5.589, Average Loss: 4.275, avg. samples / sec: 54644.99
Iteration:    940, Loss function: 5.448, Average Loss: 4.279, avg. samples / sec: 53893.57
Iteration:    940, Loss function: 4.758, Average Loss: 4.272, avg. samples / sec: 54014.04
Iteration:    940, Loss function: 4.914, Average Loss: 4.305, avg. samples / sec: 54113.84
Iteration:    940, Loss function: 4.956, Average Loss: 4.283, avg. samples / sec: 54319.33
Iteration:    940, Loss function: 5.129, Average Loss: 4.279, avg. samples / sec: 54481.76
Iteration:    940, Loss function: 5.893, Average Loss: 4.297, avg. samples / sec: 53963.32
Iteration:    940, Loss function: 4.383, Average Loss: 4.314, avg. samples / sec: 54117.74
Iteration:    940, Loss function: 5.092, Average Loss: 4.279, avg. samples / sec: 54823.66
Iteration:    940, Loss function: 5.843, Average Loss: 4.288, avg. samples / sec: 54506.22
Iteration:    940, Loss function: 4.731, Average Loss: 4.256, avg. samples / sec: 54387.52
Iteration:    940, Loss function: 4.980, Average Loss: 4.293, avg. samples / sec: 53953.94
Iteration:    940, Loss function: 5.767, Average Loss: 4.296, avg. samples / sec: 53702.76
Iteration:    940, Loss function: 5.165, Average Loss: 4.306, avg. samples / sec: 54838.64
Iteration:    940, Loss function: 5.565, Average Loss: 4.297, avg. samples / sec: 54245.54
Iteration:    940, Loss function: 5.648, Average Loss: 4.310, avg. samples / sec: 54035.93
Iteration:    940, Loss function: 4.553, Average Loss: 4.285, avg. samples / sec: 53932.37
Iteration:    940, Loss function: 5.930, Average Loss: 4.268, avg. samples / sec: 53843.41
Iteration:    960, Loss function: 4.977, Average Loss: 4.314, avg. samples / sec: 54279.74
Iteration:    960, Loss function: 4.801, Average Loss: 4.327, avg. samples / sec: 54525.79
Iteration:    960, Loss function: 4.290, Average Loss: 4.296, avg. samples / sec: 54535.92
Iteration:    960, Loss function: 6.107, Average Loss: 4.319, avg. samples / sec: 54264.69
Iteration:    960, Loss function: 5.446, Average Loss: 4.296, avg. samples / sec: 54288.32
Iteration:    960, Loss function: 5.397, Average Loss: 4.318, avg. samples / sec: 54278.38
Iteration:    960, Loss function: 5.904, Average Loss: 4.285, avg. samples / sec: 54603.64
Iteration:    960, Loss function: 3.613, Average Loss: 4.279, avg. samples / sec: 54310.22
Iteration:    960, Loss function: 7.359, Average Loss: 4.308, avg. samples / sec: 54306.91
Iteration:    960, Loss function: 4.535, Average Loss: 4.327, avg. samples / sec: 54552.62
Iteration:    960, Loss function: 6.180, Average Loss: 4.295, avg. samples / sec: 54319.26
Iteration:    960, Loss function: 5.114, Average Loss: 4.299, avg. samples / sec: 54193.06
Iteration:    960, Loss function: 4.739, Average Loss: 4.306, avg. samples / sec: 54349.18
Iteration:    960, Loss function: 5.217, Average Loss: 4.312, avg. samples / sec: 54512.82
Iteration:    960, Loss function: 4.263, Average Loss: 4.289, avg. samples / sec: 54287.71
Iteration:    960, Loss function: 5.077, Average Loss: 4.309, avg. samples / sec: 54229.72
Iteration:    960, Loss function: 4.100, Average Loss: 4.319, avg. samples / sec: 54276.29
Iteration:    960, Loss function: 5.967, Average Loss: 4.309, avg. samples / sec: 54205.04
Iteration:    960, Loss function: 5.170, Average Loss: 4.332, avg. samples / sec: 54272.11
Iteration:    960, Loss function: 4.826, Average Loss: 4.316, avg. samples / sec: 54243.68
Iteration:    960, Loss function: 5.071, Average Loss: 4.269, avg. samples / sec: 54272.87
Iteration:    960, Loss function: 6.903, Average Loss: 4.302, avg. samples / sec: 54020.81
Iteration:    960, Loss function: 5.568, Average Loss: 4.320, avg. samples / sec: 54292.23
Iteration:    960, Loss function: 5.812, Average Loss: 4.304, avg. samples / sec: 54245.60
Iteration:    960, Loss function: 5.122, Average Loss: 4.299, avg. samples / sec: 54333.25
Iteration:    960, Loss function: 5.340, Average Loss: 4.318, avg. samples / sec: 54021.05
Iteration:    960, Loss function: 5.785, Average Loss: 4.292, avg. samples / sec: 54101.48
Iteration:    960, Loss function: 4.763, Average Loss: 4.314, avg. samples / sec: 54280.73
Iteration:    960, Loss function: 5.228, Average Loss: 4.297, avg. samples / sec: 54218.26
Iteration:    960, Loss function: 6.106, Average Loss: 4.312, avg. samples / sec: 53484.99
:::MLL 1558640596.754 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558640596.754 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 4.714, Average Loss: 4.328, avg. samples / sec: 53703.60
Iteration:    980, Loss function: 4.863, Average Loss: 4.319, avg. samples / sec: 53920.34
Iteration:    980, Loss function: 5.205, Average Loss: 4.341, avg. samples / sec: 53693.94
Iteration:    980, Loss function: 5.761, Average Loss: 4.310, avg. samples / sec: 53831.44
Iteration:    980, Loss function: 5.882, Average Loss: 4.292, avg. samples / sec: 53849.97
Iteration:    980, Loss function: 4.850, Average Loss: 4.305, avg. samples / sec: 53889.76
Iteration:    980, Loss function: 5.134, Average Loss: 4.313, avg. samples / sec: 53852.32
Iteration:    980, Loss function: 5.149, Average Loss: 4.336, avg. samples / sec: 53820.75
Iteration:    980, Loss function: 4.265, Average Loss: 4.329, avg. samples / sec: 54854.39
Iteration:    980, Loss function: 5.998, Average Loss: 4.322, avg. samples / sec: 53769.60
Iteration:    980, Loss function: 4.385, Average Loss: 4.322, avg. samples / sec: 53842.42
Iteration:    980, Loss function: 4.486, Average Loss: 4.322, avg. samples / sec: 53800.99
Iteration:    980, Loss function: 5.918, Average Loss: 4.318, avg. samples / sec: 54000.35
Iteration:    980, Loss function: 5.019, Average Loss: 4.345, avg. samples / sec: 53929.85
Iteration:    980, Loss function: 4.606, Average Loss: 4.298, avg. samples / sec: 53694.84
Iteration:    980, Loss function: 5.887, Average Loss: 4.330, avg. samples / sec: 53942.87
Iteration:    980, Loss function: 3.854, Average Loss: 4.311, avg. samples / sec: 53693.53
Iteration:    980, Loss function: 4.687, Average Loss: 4.329, avg. samples / sec: 53694.86
Iteration:    980, Loss function: 6.474, Average Loss: 4.314, avg. samples / sec: 53549.05
Iteration:    980, Loss function: 3.923, Average Loss: 4.309, avg. samples / sec: 53887.97
Iteration:    980, Loss function: 4.944, Average Loss: 4.338, avg. samples / sec: 53576.81
Iteration:    980, Loss function: 4.050, Average Loss: 4.336, avg. samples / sec: 53685.88
Iteration:    980, Loss function: 5.963, Average Loss: 4.319, avg. samples / sec: 53817.18
Iteration:    980, Loss function: 4.662, Average Loss: 4.330, avg. samples / sec: 53832.24
Iteration:    980, Loss function: 6.527, Average Loss: 4.335, avg. samples / sec: 53733.66
Iteration:    980, Loss function: 4.728, Average Loss: 4.320, avg. samples / sec: 53761.09
Iteration:    980, Loss function: 4.763, Average Loss: 4.284, avg. samples / sec: 53727.70
Iteration:    980, Loss function: 4.061, Average Loss: 4.312, avg. samples / sec: 53715.90
Iteration:    980, Loss function: 3.888, Average Loss: 4.323, avg. samples / sec: 53706.75
Iteration:    980, Loss function: 4.132, Average Loss: 4.337, avg. samples / sec: 53425.60
Iteration:   1000, Loss function: 4.897, Average Loss: 4.348, avg. samples / sec: 54584.69
Iteration:   1000, Loss function: 5.234, Average Loss: 4.360, avg. samples / sec: 54561.02
Iteration:   1000, Loss function: 5.551, Average Loss: 4.349, avg. samples / sec: 54782.26
Iteration:   1000, Loss function: 5.480, Average Loss: 4.329, avg. samples / sec: 54519.34
Iteration:   1000, Loss function: 6.073, Average Loss: 4.361, avg. samples / sec: 54790.09
Iteration:   1000, Loss function: 4.374, Average Loss: 4.324, avg. samples / sec: 54546.92
Iteration:   1000, Loss function: 4.366, Average Loss: 4.329, avg. samples / sec: 54500.26
Iteration:   1000, Loss function: 4.703, Average Loss: 4.325, avg. samples / sec: 54508.60
Iteration:   1000, Loss function: 6.272, Average Loss: 4.313, avg. samples / sec: 54658.00
Iteration:   1000, Loss function: 5.225, Average Loss: 4.341, avg. samples / sec: 54551.29
Iteration:   1000, Loss function: 4.061, Average Loss: 4.325, avg. samples / sec: 54722.18
Iteration:   1000, Loss function: 5.285, Average Loss: 4.352, avg. samples / sec: 54493.24
Iteration:   1000, Loss function: 5.472, Average Loss: 4.338, avg. samples / sec: 54579.49
Iteration:   1000, Loss function: 5.766, Average Loss: 4.345, avg. samples / sec: 54589.60
Iteration:   1000, Loss function: 4.856, Average Loss: 4.308, avg. samples / sec: 54463.31
Iteration:   1000, Loss function: 4.665, Average Loss: 4.339, avg. samples / sec: 54487.44
Iteration:   1000, Loss function: 4.412, Average Loss: 4.339, avg. samples / sec: 54444.92
Iteration:   1000, Loss function: 5.041, Average Loss: 4.367, avg. samples / sec: 54453.51
Iteration:   1000, Loss function: 4.283, Average Loss: 4.300, avg. samples / sec: 54692.67
Iteration:   1000, Loss function: 4.963, Average Loss: 4.323, avg. samples / sec: 54544.11
Iteration:   1000, Loss function: 5.112, Average Loss: 4.347, avg. samples / sec: 54580.15
Iteration:   1000, Loss function: 5.163, Average Loss: 4.341, avg. samples / sec: 54646.20
Iteration:   1000, Loss function: 5.804, Average Loss: 4.350, avg. samples / sec: 54552.77
Iteration:   1000, Loss function: 5.127, Average Loss: 4.345, avg. samples / sec: 54593.49
Iteration:   1000, Loss function: 5.332, Average Loss: 4.334, avg. samples / sec: 54533.49
Iteration:   1000, Loss function: 3.585, Average Loss: 4.340, avg. samples / sec: 54673.93
Iteration:   1000, Loss function: 4.417, Average Loss: 4.345, avg. samples / sec: 54398.77
Iteration:   1000, Loss function: 6.637, Average Loss: 4.329, avg. samples / sec: 54635.50
Iteration:   1000, Loss function: 6.065, Average Loss: 4.357, avg. samples / sec: 54673.95
Iteration:   1000, Loss function: 4.341, Average Loss: 4.330, avg. samples / sec: 54088.96
Iteration:   1020, Loss function: 4.828, Average Loss: 4.363, avg. samples / sec: 54333.97
Iteration:   1020, Loss function: 4.104, Average Loss: 4.378, avg. samples / sec: 54285.49
Iteration:   1020, Loss function: 5.231, Average Loss: 4.343, avg. samples / sec: 54292.56
Iteration:   1020, Loss function: 4.373, Average Loss: 4.346, avg. samples / sec: 54882.08
Iteration:   1020, Loss function: 5.147, Average Loss: 4.350, avg. samples / sec: 54374.34
Iteration:   1020, Loss function: 4.436, Average Loss: 4.339, avg. samples / sec: 54273.28
Iteration:   1020, Loss function: 5.198, Average Loss: 4.341, avg. samples / sec: 54207.19
Iteration:   1020, Loss function: 4.237, Average Loss: 4.341, avg. samples / sec: 54528.64
Iteration:   1020, Loss function: 5.077, Average Loss: 4.340, avg. samples / sec: 54217.74
Iteration:   1020, Loss function: 4.830, Average Loss: 4.369, avg. samples / sec: 54255.67
Iteration:   1020, Loss function: 5.882, Average Loss: 4.361, avg. samples / sec: 54250.11
Iteration:   1020, Loss function: 4.688, Average Loss: 4.349, avg. samples / sec: 54250.34
Iteration:   1020, Loss function: 4.186, Average Loss: 4.359, avg. samples / sec: 54135.06
Iteration:   1020, Loss function: 5.332, Average Loss: 4.353, avg. samples / sec: 54229.32
Iteration:   1020, Loss function: 4.752, Average Loss: 4.321, avg. samples / sec: 54210.38
Iteration:   1020, Loss function: 4.207, Average Loss: 4.377, avg. samples / sec: 54141.26
Iteration:   1020, Loss function: 5.026, Average Loss: 4.336, avg. samples / sec: 54263.88
Iteration:   1020, Loss function: 5.136, Average Loss: 4.362, avg. samples / sec: 54318.11
Iteration:   1020, Loss function: 4.866, Average Loss: 4.316, avg. samples / sec: 54243.98
Iteration:   1020, Loss function: 5.385, Average Loss: 4.385, avg. samples / sec: 54224.19
Iteration:   1020, Loss function: 5.475, Average Loss: 4.358, avg. samples / sec: 54217.18
Iteration:   1020, Loss function: 4.643, Average Loss: 4.346, avg. samples / sec: 54274.41
Iteration:   1020, Loss function: 6.267, Average Loss: 4.357, avg. samples / sec: 54273.64
Iteration:   1020, Loss function: 3.063, Average Loss: 4.361, avg. samples / sec: 54239.97
Iteration:   1020, Loss function: 5.047, Average Loss: 4.363, avg. samples / sec: 54270.19
Iteration:   1020, Loss function: 5.581, Average Loss: 4.339, avg. samples / sec: 54004.35
Iteration:   1020, Loss function: 4.370, Average Loss: 4.375, avg. samples / sec: 54259.45
Iteration:   1020, Loss function: 4.082, Average Loss: 4.365, avg. samples / sec: 54182.54
Iteration:   1020, Loss function: 5.120, Average Loss: 4.352, avg. samples / sec: 54109.97
Iteration:   1020, Loss function: 5.168, Average Loss: 4.326, avg. samples / sec: 53604.75
Iteration:   1040, Loss function: 4.220, Average Loss: 4.384, avg. samples / sec: 53340.61
Iteration:   1040, Loss function: 6.624, Average Loss: 4.356, avg. samples / sec: 53403.51
Iteration:   1040, Loss function: 3.875, Average Loss: 4.362, avg. samples / sec: 53388.20
Iteration:   1040, Loss function: 6.591, Average Loss: 4.377, avg. samples / sec: 53389.23
Iteration:   1040, Loss function: 4.289, Average Loss: 4.352, avg. samples / sec: 53279.61
Iteration:   1040, Loss function: 5.806, Average Loss: 4.335, avg. samples / sec: 53362.14
Iteration:   1040, Loss function: 5.712, Average Loss: 4.376, avg. samples / sec: 53344.83
Iteration:   1040, Loss function: 5.461, Average Loss: 4.382, avg. samples / sec: 53361.80
Iteration:   1040, Loss function: 5.209, Average Loss: 4.354, avg. samples / sec: 53282.21
Iteration:   1040, Loss function: 4.850, Average Loss: 4.370, avg. samples / sec: 53472.79
Iteration:   1040, Loss function: 6.388, Average Loss: 4.349, avg. samples / sec: 53265.79
Iteration:   1040, Loss function: 4.870, Average Loss: 4.363, avg. samples / sec: 53257.54
Iteration:   1040, Loss function: 5.200, Average Loss: 4.385, avg. samples / sec: 53291.60
Iteration:   1040, Loss function: 5.055, Average Loss: 4.367, avg. samples / sec: 53244.90
Iteration:   1040, Loss function: 5.683, Average Loss: 4.365, avg. samples / sec: 53280.47
Iteration:   1040, Loss function: 3.972, Average Loss: 4.346, avg. samples / sec: 53340.63
Iteration:   1040, Loss function: 4.669, Average Loss: 4.373, avg. samples / sec: 53363.86
Iteration:   1040, Loss function: 4.538, Average Loss: 4.334, avg. samples / sec: 53320.27
Iteration:   1040, Loss function: 5.067, Average Loss: 4.378, avg. samples / sec: 53396.92
Iteration:   1040, Loss function: 4.282, Average Loss: 4.366, avg. samples / sec: 53475.21
Iteration:   1040, Loss function: 4.912, Average Loss: 4.387, avg. samples / sec: 53310.83
Iteration:   1040, Loss function: 4.487, Average Loss: 4.370, avg. samples / sec: 53312.08
Iteration:   1040, Loss function: 4.302, Average Loss: 4.356, avg. samples / sec: 53343.92
Iteration:   1040, Loss function: 4.502, Average Loss: 4.388, avg. samples / sec: 53340.91
Iteration:   1040, Loss function: 5.972, Average Loss: 4.371, avg. samples / sec: 53297.50
Iteration:   1040, Loss function: 5.645, Average Loss: 4.361, avg. samples / sec: 53291.84
Iteration:   1040, Loss function: 5.356, Average Loss: 4.377, avg. samples / sec: 52860.41
Iteration:   1040, Loss function: 4.644, Average Loss: 4.351, avg. samples / sec: 53054.56
Iteration:   1040, Loss function: 5.490, Average Loss: 4.379, avg. samples / sec: 53292.95
Iteration:   1040, Loss function: 3.914, Average Loss: 4.339, avg. samples / sec: 53580.79
:::MLL 1558640598.932 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558640598.933 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 4.518, Average Loss: 4.399, avg. samples / sec: 53769.74
Iteration:   1060, Loss function: 5.146, Average Loss: 4.353, avg. samples / sec: 54319.68
Iteration:   1060, Loss function: 4.448, Average Loss: 4.388, avg. samples / sec: 53811.13
Iteration:   1060, Loss function: 4.541, Average Loss: 4.388, avg. samples / sec: 53871.94
Iteration:   1060, Loss function: 4.650, Average Loss: 4.382, avg. samples / sec: 53892.44
Iteration:   1060, Loss function: 6.196, Average Loss: 4.367, avg. samples / sec: 53755.69
Iteration:   1060, Loss function: 5.811, Average Loss: 4.368, avg. samples / sec: 53812.37
Iteration:   1060, Loss function: 4.208, Average Loss: 4.349, avg. samples / sec: 53815.88
Iteration:   1060, Loss function: 4.739, Average Loss: 4.397, avg. samples / sec: 53829.90
Iteration:   1060, Loss function: 5.386, Average Loss: 4.378, avg. samples / sec: 53768.74
Iteration:   1060, Loss function: 6.284, Average Loss: 4.365, avg. samples / sec: 54043.61
Iteration:   1060, Loss function: 4.747, Average Loss: 4.364, avg. samples / sec: 54015.84
Iteration:   1060, Loss function: 4.931, Average Loss: 4.393, avg. samples / sec: 53761.87
Iteration:   1060, Loss function: 5.176, Average Loss: 4.389, avg. samples / sec: 53779.55
Iteration:   1060, Loss function: 5.998, Average Loss: 4.364, avg. samples / sec: 53721.60
Iteration:   1060, Loss function: 5.111, Average Loss: 4.372, avg. samples / sec: 53708.14
Iteration:   1060, Loss function: 5.024, Average Loss: 4.363, avg. samples / sec: 53829.96
Iteration:   1060, Loss function: 5.354, Average Loss: 4.348, avg. samples / sec: 53847.83
Iteration:   1060, Loss function: 6.122, Average Loss: 4.380, avg. samples / sec: 53730.75
Iteration:   1060, Loss function: 5.704, Average Loss: 4.375, avg. samples / sec: 53695.58
Iteration:   1060, Loss function: 5.487, Average Loss: 4.378, avg. samples / sec: 53836.42
Iteration:   1060, Loss function: 5.375, Average Loss: 4.390, avg. samples / sec: 53815.94
Iteration:   1060, Loss function: 5.700, Average Loss: 4.404, avg. samples / sec: 53857.38
Iteration:   1060, Loss function: 4.887, Average Loss: 4.373, avg. samples / sec: 53887.90
Iteration:   1060, Loss function: 4.997, Average Loss: 4.389, avg. samples / sec: 53886.79
Iteration:   1060, Loss function: 5.384, Average Loss: 4.392, avg. samples / sec: 53810.74
Iteration:   1060, Loss function: 5.309, Average Loss: 4.386, avg. samples / sec: 53848.88
Iteration:   1060, Loss function: 4.275, Average Loss: 4.404, avg. samples / sec: 53843.74
Iteration:   1060, Loss function: 4.834, Average Loss: 4.391, avg. samples / sec: 53844.89
Iteration:   1060, Loss function: 6.076, Average Loss: 4.386, avg. samples / sec: 53816.41
Iteration:   1080, Loss function: 5.985, Average Loss: 4.391, avg. samples / sec: 54560.96
Iteration:   1080, Loss function: 5.052, Average Loss: 4.393, avg. samples / sec: 54335.91
Iteration:   1080, Loss function: 4.956, Average Loss: 4.390, avg. samples / sec: 54496.02
Iteration:   1080, Loss function: 5.833, Average Loss: 4.390, avg. samples / sec: 54352.64
Iteration:   1080, Loss function: 4.740, Average Loss: 4.381, avg. samples / sec: 54309.47
Iteration:   1080, Loss function: 4.465, Average Loss: 4.378, avg. samples / sec: 54454.18
Iteration:   1080, Loss function: 5.931, Average Loss: 4.407, avg. samples / sec: 54287.54
Iteration:   1080, Loss function: 4.101, Average Loss: 4.407, avg. samples / sec: 54505.57
Iteration:   1080, Loss function: 6.062, Average Loss: 4.414, avg. samples / sec: 54294.32
Iteration:   1080, Loss function: 5.059, Average Loss: 4.406, avg. samples / sec: 54356.87
Iteration:   1080, Loss function: 6.745, Average Loss: 4.408, avg. samples / sec: 54350.73
Iteration:   1080, Loss function: 4.419, Average Loss: 4.397, avg. samples / sec: 54427.74
Iteration:   1080, Loss function: 4.399, Average Loss: 4.414, avg. samples / sec: 54140.12
Iteration:   1080, Loss function: 5.289, Average Loss: 4.409, avg. samples / sec: 54299.97
Iteration:   1080, Loss function: 4.924, Average Loss: 4.380, avg. samples / sec: 54268.29
Iteration:   1080, Loss function: 5.164, Average Loss: 4.421, avg. samples / sec: 54299.93
Iteration:   1080, Loss function: 4.476, Average Loss: 4.368, avg. samples / sec: 54260.91
Iteration:   1080, Loss function: 4.357, Average Loss: 4.392, avg. samples / sec: 54264.61
Iteration:   1080, Loss function: 4.563, Average Loss: 4.387, avg. samples / sec: 54271.59
Iteration:   1080, Loss function: 5.154, Average Loss: 4.388, avg. samples / sec: 54089.83
Iteration:   1080, Loss function: 5.086, Average Loss: 4.404, avg. samples / sec: 54241.32
Iteration:   1080, Loss function: 5.004, Average Loss: 4.391, avg. samples / sec: 54221.77
Iteration:   1080, Loss function: 5.314, Average Loss: 4.409, avg. samples / sec: 54244.35
Iteration:   1080, Loss function: 5.430, Average Loss: 4.411, avg. samples / sec: 54287.65
Iteration:   1080, Loss function: 4.483, Average Loss: 4.423, avg. samples / sec: 54256.13
Iteration:   1080, Loss function: 3.990, Average Loss: 4.407, avg. samples / sec: 54281.31
Iteration:   1080, Loss function: 4.429, Average Loss: 4.383, avg. samples / sec: 54075.36
Iteration:   1080, Loss function: 4.788, Average Loss: 4.364, avg. samples / sec: 54012.19
Iteration:   1080, Loss function: 5.924, Average Loss: 4.410, avg. samples / sec: 53966.75
Iteration:   1080, Loss function: 4.959, Average Loss: 4.371, avg. samples / sec: 53900.35
Iteration:   1100, Loss function: 5.177, Average Loss: 4.414, avg. samples / sec: 54471.06
Iteration:   1100, Loss function: 5.511, Average Loss: 4.427, avg. samples / sec: 54527.35
Iteration:   1100, Loss function: 4.566, Average Loss: 4.410, avg. samples / sec: 54142.42
Iteration:   1100, Loss function: 5.791, Average Loss: 4.412, avg. samples / sec: 54331.33
Iteration:   1100, Loss function: 4.038, Average Loss: 4.383, avg. samples / sec: 54701.05
Iteration:   1100, Loss function: 5.061, Average Loss: 4.410, avg. samples / sec: 54280.06
Iteration:   1100, Loss function: 4.718, Average Loss: 4.376, avg. samples / sec: 54615.22
Iteration:   1100, Loss function: 5.500, Average Loss: 4.427, avg. samples / sec: 54323.51
Iteration:   1100, Loss function: 5.422, Average Loss: 4.390, avg. samples / sec: 54285.24
Iteration:   1100, Loss function: 4.658, Average Loss: 4.418, avg. samples / sec: 54312.96
Iteration:   1100, Loss function: 5.265, Average Loss: 4.426, avg. samples / sec: 54592.01
Iteration:   1100, Loss function: 5.240, Average Loss: 4.413, avg. samples / sec: 54269.06
Iteration:   1100, Loss function: 4.417, Average Loss: 4.394, avg. samples / sec: 54344.92
Iteration:   1100, Loss function: 4.419, Average Loss: 4.378, avg. samples / sec: 54360.98
Iteration:   1100, Loss function: 5.418, Average Loss: 4.435, avg. samples / sec: 54327.77
Iteration:   1100, Loss function: 4.426, Average Loss: 4.396, avg. samples / sec: 54110.64
Iteration:   1100, Loss function: 4.971, Average Loss: 4.400, avg. samples / sec: 54352.64
Iteration:   1100, Loss function: 4.652, Average Loss: 4.400, avg. samples / sec: 54343.04
Iteration:   1100, Loss function: 4.267, Average Loss: 4.405, avg. samples / sec: 54374.99
Iteration:   1100, Loss function: 6.371, Average Loss: 4.423, avg. samples / sec: 54386.37
Iteration:   1100, Loss function: 3.767, Average Loss: 4.418, avg. samples / sec: 54286.31
Iteration:   1100, Loss function: 5.649, Average Loss: 4.400, avg. samples / sec: 54390.06
Iteration:   1100, Loss function: 4.539, Average Loss: 4.401, avg. samples / sec: 54054.25
Iteration:   1100, Loss function: 5.864, Average Loss: 4.431, avg. samples / sec: 54358.38
Iteration:   1100, Loss function: 5.200, Average Loss: 4.400, avg. samples / sec: 54345.76
Iteration:   1100, Loss function: 5.434, Average Loss: 4.422, avg. samples / sec: 54346.89
Iteration:   1100, Loss function: 5.015, Average Loss: 4.422, avg. samples / sec: 54080.92
Iteration:   1100, Loss function: 4.612, Average Loss: 4.437, avg. samples / sec: 54174.95
Iteration:   1100, Loss function: 5.330, Average Loss: 4.418, avg. samples / sec: 54093.42
Iteration:   1100, Loss function: 4.144, Average Loss: 4.418, avg. samples / sec: 53711.97
:::MLL 1558640601.109 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558640601.110 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 4.192, Average Loss: 4.404, avg. samples / sec: 53597.39
Iteration:   1120, Loss function: 4.070, Average Loss: 4.387, avg. samples / sec: 53523.97
Iteration:   1120, Loss function: 6.340, Average Loss: 4.435, avg. samples / sec: 53414.63
Iteration:   1120, Loss function: 4.343, Average Loss: 4.401, avg. samples / sec: 53737.90
Iteration:   1120, Loss function: 5.007, Average Loss: 4.437, avg. samples / sec: 53588.92
Iteration:   1120, Loss function: 4.850, Average Loss: 4.431, avg. samples / sec: 53557.25
Iteration:   1120, Loss function: 3.482, Average Loss: 4.419, avg. samples / sec: 53467.09
Iteration:   1120, Loss function: 4.766, Average Loss: 4.420, avg. samples / sec: 53383.04
Iteration:   1120, Loss function: 3.843, Average Loss: 4.422, avg. samples / sec: 53470.70
Iteration:   1120, Loss function: 5.420, Average Loss: 4.420, avg. samples / sec: 53400.03
Iteration:   1120, Loss function: 4.061, Average Loss: 4.428, avg. samples / sec: 54106.94
Iteration:   1120, Loss function: 3.837, Average Loss: 4.424, avg. samples / sec: 53531.74
Iteration:   1120, Loss function: 4.549, Average Loss: 4.425, avg. samples / sec: 53453.16
Iteration:   1120, Loss function: 6.228, Average Loss: 4.435, avg. samples / sec: 53644.75
Iteration:   1120, Loss function: 5.901, Average Loss: 4.404, avg. samples / sec: 53542.03
Iteration:   1120, Loss function: 4.165, Average Loss: 4.382, avg. samples / sec: 53376.94
Iteration:   1120, Loss function: 5.524, Average Loss: 4.426, avg. samples / sec: 53542.39
Iteration:   1120, Loss function: 5.457, Average Loss: 4.409, avg. samples / sec: 53509.62
Iteration:   1120, Loss function: 4.025, Average Loss: 4.436, avg. samples / sec: 53521.57
Iteration:   1120, Loss function: 4.593, Average Loss: 4.447, avg. samples / sec: 53438.83
Iteration:   1120, Loss function: 4.598, Average Loss: 4.411, avg. samples / sec: 53434.15
Iteration:   1120, Loss function: 5.464, Average Loss: 4.426, avg. samples / sec: 53684.13
Iteration:   1120, Loss function: 5.157, Average Loss: 4.433, avg. samples / sec: 53425.82
Iteration:   1120, Loss function: 4.465, Average Loss: 4.390, avg. samples / sec: 53371.01
Iteration:   1120, Loss function: 4.992, Average Loss: 4.410, avg. samples / sec: 53390.79
Iteration:   1120, Loss function: 3.321, Average Loss: 4.409, avg. samples / sec: 53378.80
Iteration:   1120, Loss function: 4.128, Average Loss: 4.408, avg. samples / sec: 53380.41
Iteration:   1120, Loss function: 5.706, Average Loss: 4.408, avg. samples / sec: 53375.54
Iteration:   1120, Loss function: 4.715, Average Loss: 4.429, avg. samples / sec: 53369.70
Iteration:   1120, Loss function: 4.498, Average Loss: 4.450, avg. samples / sec: 53531.03
Iteration:   1140, Loss function: 5.200, Average Loss: 4.426, avg. samples / sec: 54547.00
Iteration:   1140, Loss function: 4.690, Average Loss: 4.441, avg. samples / sec: 54468.13
Iteration:   1140, Loss function: 4.359, Average Loss: 4.434, avg. samples / sec: 54547.72
Iteration:   1140, Loss function: 4.384, Average Loss: 4.454, avg. samples / sec: 54742.72
Iteration:   1140, Loss function: 4.375, Average Loss: 4.445, avg. samples / sec: 54394.34
Iteration:   1140, Loss function: 6.001, Average Loss: 4.431, avg. samples / sec: 54414.02
Iteration:   1140, Loss function: 5.698, Average Loss: 4.431, avg. samples / sec: 54477.54
Iteration:   1140, Loss function: 4.244, Average Loss: 4.429, avg. samples / sec: 54501.75
Iteration:   1140, Loss function: 6.091, Average Loss: 4.387, avg. samples / sec: 54520.81
Iteration:   1140, Loss function: 5.632, Average Loss: 4.411, avg. samples / sec: 54328.25
Iteration:   1140, Loss function: 4.340, Average Loss: 4.438, avg. samples / sec: 54417.95
Iteration:   1140, Loss function: 4.675, Average Loss: 4.427, avg. samples / sec: 54642.05
Iteration:   1140, Loss function: 5.854, Average Loss: 4.399, avg. samples / sec: 54288.11
Iteration:   1140, Loss function: 5.567, Average Loss: 4.438, avg. samples / sec: 54306.39
Iteration:   1140, Loss function: 6.043, Average Loss: 4.435, avg. samples / sec: 54408.79
Iteration:   1140, Loss function: 5.621, Average Loss: 4.460, avg. samples / sec: 54643.57
Iteration:   1140, Loss function: 4.387, Average Loss: 4.422, avg. samples / sec: 54548.92
Iteration:   1140, Loss function: 5.385, Average Loss: 4.398, avg. samples / sec: 54528.47
Iteration:   1140, Loss function: 5.982, Average Loss: 4.435, avg. samples / sec: 54470.09
Iteration:   1140, Loss function: 5.926, Average Loss: 4.415, avg. samples / sec: 54526.40
Iteration:   1140, Loss function: 4.769, Average Loss: 4.444, avg. samples / sec: 54460.62
Iteration:   1140, Loss function: 4.915, Average Loss: 4.417, avg. samples / sec: 54477.97
Iteration:   1140, Loss function: 5.662, Average Loss: 4.417, avg. samples / sec: 54515.98
Iteration:   1140, Loss function: 6.562, Average Loss: 4.415, avg. samples / sec: 54329.82
Iteration:   1140, Loss function: 4.948, Average Loss: 4.437, avg. samples / sec: 54318.45
Iteration:   1140, Loss function: 4.717, Average Loss: 4.437, avg. samples / sec: 54241.05
Iteration:   1140, Loss function: 4.806, Average Loss: 4.444, avg. samples / sec: 54331.07
Iteration:   1140, Loss function: 5.782, Average Loss: 4.413, avg. samples / sec: 54026.05
Iteration:   1140, Loss function: 4.534, Average Loss: 4.436, avg. samples / sec: 54485.23
Iteration:   1140, Loss function: 4.269, Average Loss: 4.415, avg. samples / sec: 54008.94
Iteration:   1160, Loss function: 5.662, Average Loss: 4.457, avg. samples / sec: 54280.33
Iteration:   1160, Loss function: 4.693, Average Loss: 4.435, avg. samples / sec: 54105.61
Iteration:   1160, Loss function: 4.296, Average Loss: 4.447, avg. samples / sec: 54334.01
Iteration:   1160, Loss function: 5.340, Average Loss: 4.458, avg. samples / sec: 54228.47
Iteration:   1160, Loss function: 4.764, Average Loss: 4.441, avg. samples / sec: 54232.87
Iteration:   1160, Loss function: 5.531, Average Loss: 4.439, avg. samples / sec: 54217.18
Iteration:   1160, Loss function: 4.625, Average Loss: 4.440, avg. samples / sec: 54420.24
Iteration:   1160, Loss function: 5.287, Average Loss: 4.442, avg. samples / sec: 54118.97
Iteration:   1160, Loss function: 4.583, Average Loss: 4.440, avg. samples / sec: 54190.68
Iteration:   1160, Loss function: 5.286, Average Loss: 4.422, avg. samples / sec: 54258.20
Iteration:   1160, Loss function: 4.479, Average Loss: 4.443, avg. samples / sec: 54289.76
Iteration:   1160, Loss function: 4.424, Average Loss: 4.413, avg. samples / sec: 54271.42
Iteration:   1160, Loss function: 4.721, Average Loss: 4.424, avg. samples / sec: 54477.27
Iteration:   1160, Loss function: 4.757, Average Loss: 4.421, avg. samples / sec: 54512.65
Iteration:   1160, Loss function: 3.634, Average Loss: 4.451, avg. samples / sec: 54218.74
Iteration:   1160, Loss function: 3.684, Average Loss: 4.403, avg. samples / sec: 54212.57
Iteration:   1160, Loss function: 4.605, Average Loss: 4.438, avg. samples / sec: 54188.06
Iteration:   1160, Loss function: 4.439, Average Loss: 4.451, avg. samples / sec: 54383.49
Iteration:   1160, Loss function: 4.594, Average Loss: 4.424, avg. samples / sec: 54582.20
Iteration:   1160, Loss function: 5.471, Average Loss: 4.464, avg. samples / sec: 53975.99
Iteration:   1160, Loss function: 5.841, Average Loss: 4.411, avg. samples / sec: 54222.58
Iteration:   1160, Loss function: 5.228, Average Loss: 4.435, avg. samples / sec: 54285.66
Iteration:   1160, Loss function: 4.707, Average Loss: 4.445, avg. samples / sec: 54244.77
Iteration:   1160, Loss function: 4.766, Average Loss: 4.446, avg. samples / sec: 54316.46
Iteration:   1160, Loss function: 5.375, Average Loss: 4.456, avg. samples / sec: 54249.72
Iteration:   1160, Loss function: 4.798, Average Loss: 4.453, avg. samples / sec: 54295.34
Iteration:   1160, Loss function: 3.464, Average Loss: 4.428, avg. samples / sec: 54252.39
Iteration:   1160, Loss function: 4.732, Average Loss: 4.450, avg. samples / sec: 54256.19
Iteration:   1160, Loss function: 4.472, Average Loss: 4.431, avg. samples / sec: 54189.35
Iteration:   1160, Loss function: 5.512, Average Loss: 4.474, avg. samples / sec: 54116.52
Iteration:   1180, Loss function: 5.493, Average Loss: 4.449, avg. samples / sec: 55066.09
Iteration:   1180, Loss function: 4.676, Average Loss: 4.468, avg. samples / sec: 54880.24
Iteration:   1180, Loss function: 5.140, Average Loss: 4.463, avg. samples / sec: 55013.32
Iteration:   1180, Loss function: 6.443, Average Loss: 4.433, avg. samples / sec: 54926.66
Iteration:   1180, Loss function: 3.600, Average Loss: 4.418, avg. samples / sec: 54914.54
Iteration:   1180, Loss function: 4.975, Average Loss: 4.430, avg. samples / sec: 54920.79
Iteration:   1180, Loss function: 5.567, Average Loss: 4.449, avg. samples / sec: 54862.79
Iteration:   1180, Loss function: 5.012, Average Loss: 4.447, avg. samples / sec: 54891.29
Iteration:   1180, Loss function: 5.013, Average Loss: 4.457, avg. samples / sec: 55115.00
Iteration:   1180, Loss function: 3.813, Average Loss: 4.445, avg. samples / sec: 54862.83
Iteration:   1180, Loss function: 4.467, Average Loss: 4.415, avg. samples / sec: 54912.98
Iteration:   1180, Loss function: 3.959, Average Loss: 4.461, avg. samples / sec: 54813.19
Iteration:   1180, Loss function: 4.978, Average Loss: 4.452, avg. samples / sec: 54854.07
Iteration:   1180, Loss function: 5.351, Average Loss: 4.444, avg. samples / sec: 54832.69
Iteration:   1180, Loss function: 4.946, Average Loss: 4.421, avg. samples / sec: 54921.35
Iteration:   1180, Loss function: 5.023, Average Loss: 4.433, avg. samples / sec: 54883.81
Iteration:   1180, Loss function: 3.863, Average Loss: 4.465, avg. samples / sec: 54901.45
Iteration:   1180, Loss function: 5.041, Average Loss: 4.469, avg. samples / sec: 54848.86
Iteration:   1180, Loss function: 3.880, Average Loss: 4.462, avg. samples / sec: 54900.21
Iteration:   1180, Loss function: 3.894, Average Loss: 4.437, avg. samples / sec: 54678.98
Iteration:   1180, Loss function: 4.279, Average Loss: 4.440, avg. samples / sec: 54933.38
Iteration:   1180, Loss function: 5.059, Average Loss: 4.460, avg. samples / sec: 54902.52
Iteration:   1180, Loss function: 4.776, Average Loss: 4.443, avg. samples / sec: 54848.48
Iteration:   1180, Loss function: 4.490, Average Loss: 4.434, avg. samples / sec: 54883.36
Iteration:   1180, Loss function: 4.281, Average Loss: 4.444, avg. samples / sec: 54717.09
Iteration:   1180, Loss function: 6.168, Average Loss: 4.451, avg. samples / sec: 54601.04
Iteration:   1180, Loss function: 4.885, Average Loss: 4.456, avg. samples / sec: 54836.44
Iteration:   1180, Loss function: 5.223, Average Loss: 4.483, avg. samples / sec: 54875.67
Iteration:   1180, Loss function: 5.508, Average Loss: 4.469, avg. samples / sec: 54505.21
Iteration:   1180, Loss function: 5.332, Average Loss: 4.461, avg. samples / sec: 53836.03
:::MLL 1558640603.273 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558640603.273 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 4.644, Average Loss: 4.428, avg. samples / sec: 54293.38
Iteration:   1200, Loss function: 5.488, Average Loss: 4.451, avg. samples / sec: 54481.99
Iteration:   1200, Loss function: 5.509, Average Loss: 4.444, avg. samples / sec: 54125.12
Iteration:   1200, Loss function: 5.336, Average Loss: 4.460, avg. samples / sec: 54179.75
Iteration:   1200, Loss function: 5.370, Average Loss: 4.476, avg. samples / sec: 54043.18
Iteration:   1200, Loss function: 4.383, Average Loss: 4.431, avg. samples / sec: 54101.37
Iteration:   1200, Loss function: 5.225, Average Loss: 4.480, avg. samples / sec: 53904.06
Iteration:   1200, Loss function: 3.525, Average Loss: 4.451, avg. samples / sec: 54024.89
Iteration:   1200, Loss function: 4.231, Average Loss: 4.451, avg. samples / sec: 54227.51
Iteration:   1200, Loss function: 4.698, Average Loss: 4.459, avg. samples / sec: 54178.79
Iteration:   1200, Loss function: 4.941, Average Loss: 4.432, avg. samples / sec: 54069.66
Iteration:   1200, Loss function: 4.946, Average Loss: 4.461, avg. samples / sec: 54177.52
Iteration:   1200, Loss function: 5.056, Average Loss: 4.442, avg. samples / sec: 54148.42
Iteration:   1200, Loss function: 3.866, Average Loss: 4.465, avg. samples / sec: 54118.06
Iteration:   1200, Loss function: 4.945, Average Loss: 4.491, avg. samples / sec: 54194.56
Iteration:   1200, Loss function: 5.507, Average Loss: 4.456, avg. samples / sec: 53878.18
Iteration:   1200, Loss function: 5.476, Average Loss: 4.461, avg. samples / sec: 53767.47
Iteration:   1200, Loss function: 4.760, Average Loss: 4.478, avg. samples / sec: 53906.12
Iteration:   1200, Loss function: 4.641, Average Loss: 4.462, avg. samples / sec: 53693.15
Iteration:   1200, Loss function: 3.953, Average Loss: 4.448, avg. samples / sec: 53862.24
Iteration:   1200, Loss function: 4.628, Average Loss: 4.468, avg. samples / sec: 53643.93
Iteration:   1200, Loss function: 4.315, Average Loss: 4.455, avg. samples / sec: 53379.81
Iteration:   1200, Loss function: 4.558, Average Loss: 4.441, avg. samples / sec: 53591.42
Iteration:   1200, Loss function: 4.706, Average Loss: 4.456, avg. samples / sec: 53585.70
Iteration:   1200, Loss function: 5.410, Average Loss: 4.466, avg. samples / sec: 53788.93
Iteration:   1200, Loss function: 4.390, Average Loss: 4.444, avg. samples / sec: 53699.49
Iteration:   1200, Loss function: 4.290, Average Loss: 4.474, avg. samples / sec: 53699.02
Iteration:   1200, Loss function: 5.349, Average Loss: 4.470, avg. samples / sec: 54631.92
Iteration:   1200, Loss function: 3.926, Average Loss: 4.472, avg. samples / sec: 53776.43
Iteration:   1200, Loss function: 4.518, Average Loss: 4.445, avg. samples / sec: 53641.46
Iteration:   1220, Loss function: 4.207, Average Loss: 4.463, avg. samples / sec: 55184.60
Iteration:   1220, Loss function: 4.842, Average Loss: 4.493, avg. samples / sec: 54571.33
Iteration:   1220, Loss function: 4.751, Average Loss: 4.441, avg. samples / sec: 54453.17
Iteration:   1220, Loss function: 4.848, Average Loss: 4.473, avg. samples / sec: 54795.48
Iteration:   1220, Loss function: 4.815, Average Loss: 4.460, avg. samples / sec: 54684.58
Iteration:   1220, Loss function: 4.649, Average Loss: 4.476, avg. samples / sec: 54945.82
Iteration:   1220, Loss function: 4.206, Average Loss: 4.457, avg. samples / sec: 54556.17
Iteration:   1220, Loss function: 4.424, Average Loss: 4.466, avg. samples / sec: 54971.56
Iteration:   1220, Loss function: 5.508, Average Loss: 4.485, avg. samples / sec: 54395.27
Iteration:   1220, Loss function: 3.721, Average Loss: 4.482, avg. samples / sec: 55041.70
Iteration:   1220, Loss function: 4.917, Average Loss: 4.453, avg. samples / sec: 54910.60
Iteration:   1220, Loss function: 5.125, Average Loss: 4.449, avg. samples / sec: 54322.17
Iteration:   1220, Loss function: 4.624, Average Loss: 4.479, avg. samples / sec: 54578.69
Iteration:   1220, Loss function: 5.802, Average Loss: 4.476, avg. samples / sec: 54319.12
Iteration:   1220, Loss function: 4.161, Average Loss: 4.451, avg. samples / sec: 54839.83
Iteration:   1220, Loss function: 5.258, Average Loss: 4.460, avg. samples / sec: 54136.21
Iteration:   1220, Loss function: 3.446, Average Loss: 4.480, avg. samples / sec: 54673.10
Iteration:   1220, Loss function: 5.396, Average Loss: 4.443, avg. samples / sec: 54440.02
Iteration:   1220, Loss function: 4.421, Average Loss: 4.478, avg. samples / sec: 54879.04
Iteration:   1220, Loss function: 4.185, Average Loss: 4.451, avg. samples / sec: 54421.06
Iteration:   1220, Loss function: 3.959, Average Loss: 4.461, avg. samples / sec: 54411.18
Iteration:   1220, Loss function: 6.147, Average Loss: 4.456, avg. samples / sec: 54914.18
Iteration:   1220, Loss function: 4.367, Average Loss: 4.452, avg. samples / sec: 54682.27
Iteration:   1220, Loss function: 6.177, Average Loss: 4.475, avg. samples / sec: 54759.84
Iteration:   1220, Loss function: 4.808, Average Loss: 4.473, avg. samples / sec: 54396.00
Iteration:   1220, Loss function: 4.919, Average Loss: 4.467, avg. samples / sec: 54618.24
Iteration:   1220, Loss function: 3.860, Average Loss: 4.503, avg. samples / sec: 54386.07
Iteration:   1220, Loss function: 5.171, Average Loss: 4.463, avg. samples / sec: 54298.98
Iteration:   1220, Loss function: 5.193, Average Loss: 4.483, avg. samples / sec: 54822.09
Iteration:   1220, Loss function: 3.352, Average Loss: 4.439, avg. samples / sec: 53969.15
Iteration:   1240, Loss function: 4.629, Average Loss: 4.469, avg. samples / sec: 54998.34
Iteration:   1240, Loss function: 4.172, Average Loss: 4.498, avg. samples / sec: 55088.89
Iteration:   1240, Loss function: 4.693, Average Loss: 4.464, avg. samples / sec: 55135.44
Iteration:   1240, Loss function: 3.447, Average Loss: 4.460, avg. samples / sec: 55161.10
Iteration:   1240, Loss function: 5.386, Average Loss: 4.448, avg. samples / sec: 55060.03
Iteration:   1240, Loss function: 5.272, Average Loss: 4.467, avg. samples / sec: 55062.01
Iteration:   1240, Loss function: 5.598, Average Loss: 4.477, avg. samples / sec: 55069.71
Iteration:   1240, Loss function: 4.496, Average Loss: 4.435, avg. samples / sec: 55389.20
Iteration:   1240, Loss function: 4.693, Average Loss: 4.485, avg. samples / sec: 55383.95
Iteration:   1240, Loss function: 4.275, Average Loss: 4.484, avg. samples / sec: 55333.24
Iteration:   1240, Loss function: 4.091, Average Loss: 4.477, avg. samples / sec: 55053.08
Iteration:   1240, Loss function: 5.086, Average Loss: 4.474, avg. samples / sec: 55069.75
Iteration:   1240, Loss function: 5.325, Average Loss: 4.481, avg. samples / sec: 55113.62
Iteration:   1240, Loss function: 4.984, Average Loss: 4.464, avg. samples / sec: 55065.34
Iteration:   1240, Loss function: 4.755, Average Loss: 4.487, avg. samples / sec: 55047.12
Iteration:   1240, Loss function: 3.744, Average Loss: 4.487, avg. samples / sec: 55031.69
Iteration:   1240, Loss function: 4.314, Average Loss: 4.459, avg. samples / sec: 55122.39
Iteration:   1240, Loss function: 4.215, Average Loss: 4.452, avg. samples / sec: 55055.79
Iteration:   1240, Loss function: 4.653, Average Loss: 4.468, avg. samples / sec: 55113.47
Iteration:   1240, Loss function: 6.230, Average Loss: 4.493, avg. samples / sec: 55037.62
Iteration:   1240, Loss function: 4.928, Average Loss: 4.485, avg. samples / sec: 55047.55
Iteration:   1240, Loss function: 4.469, Average Loss: 4.479, avg. samples / sec: 55070.68
Iteration:   1240, Loss function: 5.665, Average Loss: 4.486, avg. samples / sec: 54903.42
Iteration:   1240, Loss function: 6.532, Average Loss: 4.460, avg. samples / sec: 55060.65
Iteration:   1240, Loss function: 4.820, Average Loss: 4.465, avg. samples / sec: 55053.98
Iteration:   1240, Loss function: 4.729, Average Loss: 4.471, avg. samples / sec: 55042.71
Iteration:   1240, Loss function: 4.308, Average Loss: 4.465, avg. samples / sec: 55048.20
Iteration:   1240, Loss function: 4.568, Average Loss: 4.509, avg. samples / sec: 55048.24
Iteration:   1240, Loss function: 4.089, Average Loss: 4.466, avg. samples / sec: 54986.60
Iteration:   1240, Loss function: 5.044, Average Loss: 4.456, avg. samples / sec: 55010.81
:::MLL 1558640605.428 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558640605.429 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 4.824, Average Loss: 4.501, avg. samples / sec: 54112.01
Iteration:   1260, Loss function: 4.579, Average Loss: 4.494, avg. samples / sec: 54192.16
Iteration:   1260, Loss function: 4.822, Average Loss: 4.472, avg. samples / sec: 54179.72
Iteration:   1260, Loss function: 4.486, Average Loss: 4.495, avg. samples / sec: 54252.58
Iteration:   1260, Loss function: 4.860, Average Loss: 4.453, avg. samples / sec: 54146.42
Iteration:   1260, Loss function: 4.416, Average Loss: 4.469, avg. samples / sec: 54111.47
Iteration:   1260, Loss function: 5.582, Average Loss: 4.472, avg. samples / sec: 54201.85
Iteration:   1260, Loss function: 4.724, Average Loss: 4.475, avg. samples / sec: 53986.78
Iteration:   1260, Loss function: 4.981, Average Loss: 4.437, avg. samples / sec: 54123.71
Iteration:   1260, Loss function: 5.488, Average Loss: 4.495, avg. samples / sec: 54327.68
Iteration:   1260, Loss function: 3.683, Average Loss: 4.465, avg. samples / sec: 54065.51
Iteration:   1260, Loss function: 4.557, Average Loss: 4.487, avg. samples / sec: 54105.05
Iteration:   1260, Loss function: 4.585, Average Loss: 4.488, avg. samples / sec: 54043.61
Iteration:   1260, Loss function: 6.410, Average Loss: 4.488, avg. samples / sec: 54017.64
Iteration:   1260, Loss function: 4.844, Average Loss: 4.485, avg. samples / sec: 54239.99
Iteration:   1260, Loss function: 5.061, Average Loss: 4.480, avg. samples / sec: 53992.37
Iteration:   1260, Loss function: 3.763, Average Loss: 4.463, avg. samples / sec: 54118.18
Iteration:   1260, Loss function: 6.045, Average Loss: 4.492, avg. samples / sec: 54025.71
Iteration:   1260, Loss function: 6.608, Average Loss: 4.466, avg. samples / sec: 54198.98
Iteration:   1260, Loss function: 4.488, Average Loss: 4.475, avg. samples / sec: 54151.41
Iteration:   1260, Loss function: 5.770, Average Loss: 4.480, avg. samples / sec: 54090.87
Iteration:   1260, Loss function: 3.956, Average Loss: 4.465, avg. samples / sec: 54063.97
Iteration:   1260, Loss function: 3.853, Average Loss: 4.479, avg. samples / sec: 54082.34
Iteration:   1260, Loss function: 4.929, Average Loss: 4.473, avg. samples / sec: 54065.72
Iteration:   1260, Loss function: 5.027, Average Loss: 4.494, avg. samples / sec: 54046.83
Iteration:   1260, Loss function: 5.139, Average Loss: 4.496, avg. samples / sec: 54039.14
Iteration:   1260, Loss function: 4.256, Average Loss: 4.466, avg. samples / sec: 54094.73
Iteration:   1260, Loss function: 4.476, Average Loss: 4.495, avg. samples / sec: 53769.02
Iteration:   1260, Loss function: 5.593, Average Loss: 4.466, avg. samples / sec: 54042.35
Iteration:   1260, Loss function: 5.353, Average Loss: 4.514, avg. samples / sec: 54046.18
Iteration:   1280, Loss function: 5.706, Average Loss: 4.492, avg. samples / sec: 54509.66
Iteration:   1280, Loss function: 4.045, Average Loss: 4.489, avg. samples / sec: 54544.89
Iteration:   1280, Loss function: 4.655, Average Loss: 4.506, avg. samples / sec: 54380.76
Iteration:   1280, Loss function: 3.889, Average Loss: 4.494, avg. samples / sec: 54563.98
Iteration:   1280, Loss function: 6.151, Average Loss: 4.469, avg. samples / sec: 54414.34
Iteration:   1280, Loss function: 4.911, Average Loss: 4.475, avg. samples / sec: 54483.02
Iteration:   1280, Loss function: 4.469, Average Loss: 4.442, avg. samples / sec: 54424.28
Iteration:   1280, Loss function: 5.152, Average Loss: 4.482, avg. samples / sec: 54389.98
Iteration:   1280, Loss function: 5.466, Average Loss: 4.477, avg. samples / sec: 54372.50
Iteration:   1280, Loss function: 5.062, Average Loss: 4.508, avg. samples / sec: 54332.48
Iteration:   1280, Loss function: 5.365, Average Loss: 4.506, avg. samples / sec: 54336.63
Iteration:   1280, Loss function: 4.693, Average Loss: 4.498, avg. samples / sec: 54550.15
Iteration:   1280, Loss function: 5.939, Average Loss: 4.497, avg. samples / sec: 54467.56
Iteration:   1280, Loss function: 3.550, Average Loss: 4.499, avg. samples / sec: 54523.77
Iteration:   1280, Loss function: 4.456, Average Loss: 4.494, avg. samples / sec: 54416.25
Iteration:   1280, Loss function: 4.326, Average Loss: 4.477, avg. samples / sec: 54397.01
Iteration:   1280, Loss function: 4.697, Average Loss: 4.477, avg. samples / sec: 54519.65
Iteration:   1280, Loss function: 5.075, Average Loss: 4.512, avg. samples / sec: 54539.21
Iteration:   1280, Loss function: 4.261, Average Loss: 4.503, avg. samples / sec: 54563.94
Iteration:   1280, Loss function: 4.622, Average Loss: 4.509, avg. samples / sec: 54227.07
Iteration:   1280, Loss function: 3.682, Average Loss: 4.478, avg. samples / sec: 54360.92
Iteration:   1280, Loss function: 4.984, Average Loss: 4.492, avg. samples / sec: 54446.71
Iteration:   1280, Loss function: 6.086, Average Loss: 4.489, avg. samples / sec: 54479.12
Iteration:   1280, Loss function: 4.352, Average Loss: 4.485, avg. samples / sec: 54486.45
Iteration:   1280, Loss function: 3.923, Average Loss: 4.527, avg. samples / sec: 54530.75
Iteration:   1280, Loss function: 5.490, Average Loss: 4.484, avg. samples / sec: 54524.04
Iteration:   1280, Loss function: 4.347, Average Loss: 4.508, avg. samples / sec: 54485.97
Iteration:   1280, Loss function: 5.465, Average Loss: 4.497, avg. samples / sec: 54289.53
Iteration:   1280, Loss function: 4.148, Average Loss: 4.473, avg. samples / sec: 54462.77
Iteration:   1280, Loss function: 3.930, Average Loss: 4.487, avg. samples / sec: 54393.36
Iteration:   1300, Loss function: 4.793, Average Loss: 4.511, avg. samples / sec: 53964.11
Iteration:   1300, Loss function: 4.778, Average Loss: 4.512, avg. samples / sec: 53942.79
Iteration:   1300, Loss function: 4.127, Average Loss: 4.505, avg. samples / sec: 54132.13
Iteration:   1300, Loss function: 6.186, Average Loss: 4.488, avg. samples / sec: 54172.81
Iteration:   1300, Loss function: 4.316, Average Loss: 4.484, avg. samples / sec: 53868.85
Iteration:   1300, Loss function: 4.772, Average Loss: 4.503, avg. samples / sec: 53917.55
Iteration:   1300, Loss function: 4.318, Average Loss: 4.447, avg. samples / sec: 53874.51
Iteration:   1300, Loss function: 4.963, Average Loss: 4.488, avg. samples / sec: 53881.37
Iteration:   1300, Loss function: 6.084, Average Loss: 4.482, avg. samples / sec: 53832.33
Iteration:   1300, Loss function: 5.904, Average Loss: 4.506, avg. samples / sec: 53888.95
Iteration:   1300, Loss function: 4.187, Average Loss: 4.484, avg. samples / sec: 53865.37
Iteration:   1300, Loss function: 3.527, Average Loss: 4.514, avg. samples / sec: 53871.38
Iteration:   1300, Loss function: 4.891, Average Loss: 4.504, avg. samples / sec: 53913.61
Iteration:   1300, Loss function: 3.205, Average Loss: 4.498, avg. samples / sec: 53892.70
Iteration:   1300, Loss function: 3.453, Average Loss: 4.497, avg. samples / sec: 53655.33
Iteration:   1300, Loss function: 5.043, Average Loss: 4.516, avg. samples / sec: 53936.97
Iteration:   1300, Loss function: 5.057, Average Loss: 4.497, avg. samples / sec: 53960.64
Iteration:   1300, Loss function: 4.839, Average Loss: 4.486, avg. samples / sec: 53886.07
Iteration:   1300, Loss function: 3.865, Average Loss: 4.493, avg. samples / sec: 53555.21
Iteration:   1300, Loss function: 5.845, Average Loss: 4.513, avg. samples / sec: 53948.43
Iteration:   1300, Loss function: 5.404, Average Loss: 4.501, avg. samples / sec: 53650.77
Iteration:   1300, Loss function: 4.704, Average Loss: 4.483, avg. samples / sec: 53869.96
Iteration:   1300, Loss function: 5.642, Average Loss: 4.484, avg. samples / sec: 53906.43
Iteration:   1300, Loss function: 4.412, Average Loss: 4.491, avg. samples / sec: 53903.57
Iteration:   1300, Loss function: 4.217, Average Loss: 4.490, avg. samples / sec: 53900.45
Iteration:   1300, Loss function: 3.985, Average Loss: 4.503, avg. samples / sec: 53896.85
Iteration:   1300, Loss function: 5.435, Average Loss: 4.490, avg. samples / sec: 53909.44
Iteration:   1300, Loss function: 4.209, Average Loss: 4.531, avg. samples / sec: 53873.07
Iteration:   1300, Loss function: 4.798, Average Loss: 4.481, avg. samples / sec: 53882.24
Iteration:   1300, Loss function: 4.968, Average Loss: 4.514, avg. samples / sec: 53752.23
Iteration:   1320, Loss function: 5.554, Average Loss: 4.488, avg. samples / sec: 54934.56
Iteration:   1320, Loss function: 4.515, Average Loss: 4.512, avg. samples / sec: 54486.64
Iteration:   1320, Loss function: 4.310, Average Loss: 4.500, avg. samples / sec: 54677.94
Iteration:   1320, Loss function: 6.249, Average Loss: 4.495, avg. samples / sec: 54613.19
Iteration:   1320, Loss function: 3.917, Average Loss: 4.510, avg. samples / sec: 54586.91
Iteration:   1320, Loss function: 5.327, Average Loss: 4.492, avg. samples / sec: 54609.63
Iteration:   1320, Loss function: 4.797, Average Loss: 4.514, avg. samples / sec: 54534.99
Iteration:   1320, Loss function: 3.843, Average Loss: 4.507, avg. samples / sec: 54593.93
Iteration:   1320, Loss function: 5.183, Average Loss: 4.456, avg. samples / sec: 54567.04
Iteration:   1320, Loss function: 4.974, Average Loss: 4.492, avg. samples / sec: 54544.32
Iteration:   1320, Loss function: 4.690, Average Loss: 4.482, avg. samples / sec: 54572.03
Iteration:   1320, Loss function: 5.695, Average Loss: 4.513, avg. samples / sec: 54584.78
Iteration:   1320, Loss function: 4.233, Average Loss: 4.508, avg. samples / sec: 54470.39
Iteration:   1320, Loss function: 3.332, Average Loss: 4.504, avg. samples / sec: 54551.14
Iteration:   1320, Loss function: 4.353, Average Loss: 4.518, avg. samples / sec: 54812.04
Iteration:   1320, Loss function: 3.950, Average Loss: 4.497, avg. samples / sec: 54565.10
Iteration:   1320, Loss function: 4.677, Average Loss: 4.487, avg. samples / sec: 54589.26
Iteration:   1320, Loss function: 5.838, Average Loss: 4.491, avg. samples / sec: 54648.42
Iteration:   1320, Loss function: 4.550, Average Loss: 4.522, avg. samples / sec: 54494.84
Iteration:   1320, Loss function: 3.909, Average Loss: 4.491, avg. samples / sec: 54583.85
Iteration:   1320, Loss function: 5.142, Average Loss: 4.505, avg. samples / sec: 54510.08
Iteration:   1320, Loss function: 4.209, Average Loss: 4.514, avg. samples / sec: 54583.70
Iteration:   1320, Loss function: 4.944, Average Loss: 4.516, avg. samples / sec: 54531.70
Iteration:   1320, Loss function: 4.880, Average Loss: 4.495, avg. samples / sec: 54294.63
Iteration:   1320, Loss function: 4.337, Average Loss: 4.492, avg. samples / sec: 54555.19
Iteration:   1320, Loss function: 5.169, Average Loss: 4.508, avg. samples / sec: 54525.75
Iteration:   1320, Loss function: 5.715, Average Loss: 4.535, avg. samples / sec: 54568.23
Iteration:   1320, Loss function: 4.186, Average Loss: 4.488, avg. samples / sec: 54513.68
Iteration:   1320, Loss function: 4.984, Average Loss: 4.494, avg. samples / sec: 54405.16
Iteration:   1320, Loss function: 4.380, Average Loss: 4.521, avg. samples / sec: 54230.68
:::MLL 1558640607.599 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558640607.600 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 4.933, Average Loss: 4.522, avg. samples / sec: 54542.08
Iteration:   1340, Loss function: 4.488, Average Loss: 4.486, avg. samples / sec: 54178.87
Iteration:   1340, Loss function: 4.653, Average Loss: 4.511, avg. samples / sec: 54085.78
Iteration:   1340, Loss function: 3.542, Average Loss: 4.521, avg. samples / sec: 54098.20
Iteration:   1340, Loss function: 4.704, Average Loss: 4.458, avg. samples / sec: 54119.51
Iteration:   1340, Loss function: 4.684, Average Loss: 4.513, avg. samples / sec: 54175.70
Iteration:   1340, Loss function: 4.246, Average Loss: 4.512, avg. samples / sec: 54099.42
Iteration:   1340, Loss function: 5.365, Average Loss: 4.497, avg. samples / sec: 54116.44
Iteration:   1340, Loss function: 4.069, Average Loss: 4.502, avg. samples / sec: 54073.89
Iteration:   1340, Loss function: 3.829, Average Loss: 4.498, avg. samples / sec: 54057.59
Iteration:   1340, Loss function: 3.150, Average Loss: 4.516, avg. samples / sec: 54043.68
Iteration:   1340, Loss function: 4.599, Average Loss: 4.522, avg. samples / sec: 54064.91
Iteration:   1340, Loss function: 4.099, Average Loss: 4.521, avg. samples / sec: 54264.21
Iteration:   1340, Loss function: 3.969, Average Loss: 4.511, avg. samples / sec: 54079.04
Iteration:   1340, Loss function: 6.397, Average Loss: 4.526, avg. samples / sec: 54181.33
Iteration:   1340, Loss function: 5.161, Average Loss: 4.503, avg. samples / sec: 54137.06
Iteration:   1340, Loss function: 3.886, Average Loss: 4.501, avg. samples / sec: 54272.34
Iteration:   1340, Loss function: 4.492, Average Loss: 4.505, avg. samples / sec: 54149.39
Iteration:   1340, Loss function: 4.862, Average Loss: 4.496, avg. samples / sec: 54114.38
Iteration:   1340, Loss function: 5.822, Average Loss: 4.495, avg. samples / sec: 54073.91
Iteration:   1340, Loss function: 4.262, Average Loss: 4.522, avg. samples / sec: 54021.99
Iteration:   1340, Loss function: 3.923, Average Loss: 4.494, avg. samples / sec: 54156.47
Iteration:   1340, Loss function: 5.192, Average Loss: 4.504, avg. samples / sec: 54126.29
Iteration:   1340, Loss function: 3.728, Average Loss: 4.514, avg. samples / sec: 54099.65
Iteration:   1340, Loss function: 4.217, Average Loss: 4.498, avg. samples / sec: 54105.53
Iteration:   1340, Loss function: 5.070, Average Loss: 4.493, avg. samples / sec: 53792.48
Iteration:   1340, Loss function: 4.383, Average Loss: 4.497, avg. samples / sec: 54041.96
Iteration:   1340, Loss function: 4.546, Average Loss: 4.515, avg. samples / sec: 54088.85
Iteration:   1340, Loss function: 4.045, Average Loss: 4.541, avg. samples / sec: 54078.85
Iteration:   1340, Loss function: 4.274, Average Loss: 4.511, avg. samples / sec: 53528.50
Iteration:   1360, Loss function: 4.590, Average Loss: 4.517, avg. samples / sec: 53831.85
Iteration:   1360, Loss function: 4.686, Average Loss: 4.511, avg. samples / sec: 54265.51
Iteration:   1360, Loss function: 4.034, Average Loss: 4.516, avg. samples / sec: 53732.62
Iteration:   1360, Loss function: 4.840, Average Loss: 4.489, avg. samples / sec: 53686.29
Iteration:   1360, Loss function: 4.003, Average Loss: 4.516, avg. samples / sec: 53711.30
Iteration:   1360, Loss function: 4.249, Average Loss: 4.504, avg. samples / sec: 53728.76
Iteration:   1360, Loss function: 4.909, Average Loss: 4.517, avg. samples / sec: 53795.73
Iteration:   1360, Loss function: 4.492, Average Loss: 4.525, avg. samples / sec: 53744.15
Iteration:   1360, Loss function: 3.756, Average Loss: 4.513, avg. samples / sec: 53671.45
Iteration:   1360, Loss function: 4.081, Average Loss: 4.501, avg. samples / sec: 53656.57
Iteration:   1360, Loss function: 4.077, Average Loss: 4.504, avg. samples / sec: 53668.87
Iteration:   1360, Loss function: 3.893, Average Loss: 4.522, avg. samples / sec: 53521.39
Iteration:   1360, Loss function: 4.368, Average Loss: 4.523, avg. samples / sec: 53580.11
Iteration:   1360, Loss function: 5.067, Average Loss: 4.526, avg. samples / sec: 53687.70
Iteration:   1360, Loss function: 4.378, Average Loss: 4.505, avg. samples / sec: 53687.75
Iteration:   1360, Loss function: 4.787, Average Loss: 4.461, avg. samples / sec: 53514.01
Iteration:   1360, Loss function: 4.459, Average Loss: 4.516, avg. samples / sec: 53704.50
Iteration:   1360, Loss function: 5.574, Average Loss: 4.531, avg. samples / sec: 53733.78
Iteration:   1360, Loss function: 5.311, Average Loss: 4.498, avg. samples / sec: 53728.35
Iteration:   1360, Loss function: 4.732, Average Loss: 4.500, avg. samples / sec: 53745.36
Iteration:   1360, Loss function: 7.588, Average Loss: 4.503, avg. samples / sec: 53713.43
Iteration:   1360, Loss function: 4.475, Average Loss: 4.520, avg. samples / sec: 53571.38
Iteration:   1360, Loss function: 5.351, Average Loss: 4.504, avg. samples / sec: 53673.13
Iteration:   1360, Loss function: 3.642, Average Loss: 4.510, avg. samples / sec: 53719.61
Iteration:   1360, Loss function: 6.754, Average Loss: 4.506, avg. samples / sec: 53693.96
Iteration:   1360, Loss function: 4.386, Average Loss: 4.496, avg. samples / sec: 53685.29
Iteration:   1360, Loss function: 4.372, Average Loss: 4.543, avg. samples / sec: 53734.75
Iteration:   1360, Loss function: 4.386, Average Loss: 4.498, avg. samples / sec: 53676.56
Iteration:   1360, Loss function: 4.091, Average Loss: 4.519, avg. samples / sec: 53691.71
Iteration:   1360, Loss function: 3.915, Average Loss: 4.500, avg. samples / sec: 53671.55
Iteration:   1380, Loss function: 4.369, Average Loss: 4.519, avg. samples / sec: 54985.33
Iteration:   1380, Loss function: 6.152, Average Loss: 4.522, avg. samples / sec: 54992.35
Iteration:   1380, Loss function: 3.747, Average Loss: 4.520, avg. samples / sec: 55107.54
Iteration:   1380, Loss function: 4.298, Average Loss: 4.525, avg. samples / sec: 54976.47
Iteration:   1380, Loss function: 4.086, Average Loss: 4.470, avg. samples / sec: 55144.96
Iteration:   1380, Loss function: 5.250, Average Loss: 4.509, avg. samples / sec: 54960.84
Iteration:   1380, Loss function: 3.969, Average Loss: 4.504, avg. samples / sec: 55189.40
Iteration:   1380, Loss function: 4.733, Average Loss: 4.500, avg. samples / sec: 54935.54
Iteration:   1380, Loss function: 4.448, Average Loss: 4.506, avg. samples / sec: 54871.67
Iteration:   1380, Loss function: 5.843, Average Loss: 4.511, avg. samples / sec: 55067.28
Iteration:   1380, Loss function: 3.956, Average Loss: 4.527, avg. samples / sec: 54996.66
Iteration:   1380, Loss function: 3.677, Average Loss: 4.498, avg. samples / sec: 55053.47
Iteration:   1380, Loss function: 4.050, Average Loss: 4.502, avg. samples / sec: 54996.34
Iteration:   1380, Loss function: 5.084, Average Loss: 4.512, avg. samples / sec: 55018.80
Iteration:   1380, Loss function: 5.297, Average Loss: 4.524, avg. samples / sec: 54883.89
Iteration:   1380, Loss function: 4.110, Average Loss: 4.518, avg. samples / sec: 55056.35
Iteration:   1380, Loss function: 4.942, Average Loss: 4.494, avg. samples / sec: 54661.59
Iteration:   1380, Loss function: 4.570, Average Loss: 4.545, avg. samples / sec: 54961.38
Iteration:   1380, Loss function: 3.840, Average Loss: 4.506, avg. samples / sec: 54883.68
Iteration:   1380, Loss function: 4.806, Average Loss: 4.523, avg. samples / sec: 54659.64
Iteration:   1380, Loss function: 4.553, Average Loss: 4.517, avg. samples / sec: 54599.56
Iteration:   1380, Loss function: 3.887, Average Loss: 4.510, avg. samples / sec: 54874.11
Iteration:   1380, Loss function: 4.484, Average Loss: 4.509, avg. samples / sec: 54812.02
Iteration:   1380, Loss function: 3.698, Average Loss: 4.520, avg. samples / sec: 54726.18
Iteration:   1380, Loss function: 5.307, Average Loss: 4.524, avg. samples / sec: 54422.62
Iteration:   1380, Loss function: 4.404, Average Loss: 4.524, avg. samples / sec: 54724.65
Iteration:   1380, Loss function: 3.656, Average Loss: 4.508, avg. samples / sec: 54673.36
Iteration:   1380, Loss function: 3.309, Average Loss: 4.514, avg. samples / sec: 54501.96
Iteration:   1380, Loss function: 4.852, Average Loss: 4.534, avg. samples / sec: 54511.32
Iteration:   1380, Loss function: 4.237, Average Loss: 4.505, avg. samples / sec: 54560.28
:::MLL 1558640609.761 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558640609.762 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 6.194, Average Loss: 4.515, avg. samples / sec: 54704.28
Iteration:   1400, Loss function: 4.336, Average Loss: 4.519, avg. samples / sec: 54502.45
Iteration:   1400, Loss function: 4.144, Average Loss: 4.527, avg. samples / sec: 54971.67
Iteration:   1400, Loss function: 4.594, Average Loss: 4.499, avg. samples / sec: 54556.52
Iteration:   1400, Loss function: 4.898, Average Loss: 4.510, avg. samples / sec: 54546.49
Iteration:   1400, Loss function: 6.105, Average Loss: 4.520, avg. samples / sec: 54778.34
Iteration:   1400, Loss function: 3.807, Average Loss: 4.520, avg. samples / sec: 54436.07
Iteration:   1400, Loss function: 5.093, Average Loss: 4.528, avg. samples / sec: 54581.56
Iteration:   1400, Loss function: 3.886, Average Loss: 4.507, avg. samples / sec: 54414.23
Iteration:   1400, Loss function: 4.128, Average Loss: 4.531, avg. samples / sec: 54643.06
Iteration:   1400, Loss function: 6.037, Average Loss: 4.522, avg. samples / sec: 54267.29
Iteration:   1400, Loss function: 4.743, Average Loss: 4.528, avg. samples / sec: 54291.04
Iteration:   1400, Loss function: 3.140, Average Loss: 4.495, avg. samples / sec: 54549.62
Iteration:   1400, Loss function: 5.085, Average Loss: 4.518, avg. samples / sec: 54772.29
Iteration:   1400, Loss function: 3.331, Average Loss: 4.470, avg. samples / sec: 54279.93
Iteration:   1400, Loss function: 5.512, Average Loss: 4.538, avg. samples / sec: 54874.13
Iteration:   1400, Loss function: 4.307, Average Loss: 4.512, avg. samples / sec: 54673.82
Iteration:   1400, Loss function: 4.273, Average Loss: 4.513, avg. samples / sec: 54440.11
Iteration:   1400, Loss function: 5.169, Average Loss: 4.533, avg. samples / sec: 54265.47
Iteration:   1400, Loss function: 4.581, Average Loss: 4.514, avg. samples / sec: 54308.42
Iteration:   1400, Loss function: 4.236, Average Loss: 4.509, avg. samples / sec: 54816.78
Iteration:   1400, Loss function: 4.226, Average Loss: 4.515, avg. samples / sec: 54469.38
Iteration:   1400, Loss function: 4.583, Average Loss: 4.505, avg. samples / sec: 54254.52
Iteration:   1400, Loss function: 4.068, Average Loss: 4.502, avg. samples / sec: 54207.94
Iteration:   1400, Loss function: 3.392, Average Loss: 4.520, avg. samples / sec: 54249.78
Iteration:   1400, Loss function: 4.362, Average Loss: 4.523, avg. samples / sec: 54471.35
Iteration:   1400, Loss function: 4.131, Average Loss: 4.507, avg. samples / sec: 54110.66
Iteration:   1400, Loss function: 4.366, Average Loss: 4.512, avg. samples / sec: 54353.77
Iteration:   1400, Loss function: 4.962, Average Loss: 4.530, avg. samples / sec: 54477.92
Iteration:   1400, Loss function: 4.369, Average Loss: 4.546, avg. samples / sec: 54288.96
Iteration:   1420, Loss function: 4.436, Average Loss: 4.530, avg. samples / sec: 55036.59
Iteration:   1420, Loss function: 4.836, Average Loss: 4.510, avg. samples / sec: 54957.73
Iteration:   1420, Loss function: 3.460, Average Loss: 4.499, avg. samples / sec: 54932.07
Iteration:   1420, Loss function: 5.578, Average Loss: 4.526, avg. samples / sec: 54948.67
Iteration:   1420, Loss function: 3.898, Average Loss: 4.515, avg. samples / sec: 55383.84
Iteration:   1420, Loss function: 5.821, Average Loss: 4.521, avg. samples / sec: 55118.58
Iteration:   1420, Loss function: 5.030, Average Loss: 4.528, avg. samples / sec: 55104.25
Iteration:   1420, Loss function: 4.516, Average Loss: 4.534, avg. samples / sec: 54867.87
Iteration:   1420, Loss function: 6.139, Average Loss: 4.527, avg. samples / sec: 55057.83
Iteration:   1420, Loss function: 4.484, Average Loss: 4.506, avg. samples / sec: 55002.24
Iteration:   1420, Loss function: 4.887, Average Loss: 4.497, avg. samples / sec: 55049.66
Iteration:   1420, Loss function: 5.495, Average Loss: 4.529, avg. samples / sec: 54983.47
Iteration:   1420, Loss function: 4.398, Average Loss: 4.473, avg. samples / sec: 55051.64
Iteration:   1420, Loss function: 4.232, Average Loss: 4.522, avg. samples / sec: 54743.04
Iteration:   1420, Loss function: 4.371, Average Loss: 4.518, avg. samples / sec: 54973.75
Iteration:   1420, Loss function: 4.251, Average Loss: 4.523, avg. samples / sec: 54599.35
Iteration:   1420, Loss function: 4.460, Average Loss: 4.515, avg. samples / sec: 55076.60
Iteration:   1420, Loss function: 5.438, Average Loss: 4.537, avg. samples / sec: 55048.82
Iteration:   1420, Loss function: 3.470, Average Loss: 4.519, avg. samples / sec: 54705.11
Iteration:   1420, Loss function: 5.841, Average Loss: 4.511, avg. samples / sec: 55043.73
Iteration:   1420, Loss function: 4.895, Average Loss: 4.515, avg. samples / sec: 54998.66
Iteration:   1420, Loss function: 5.221, Average Loss: 4.537, avg. samples / sec: 55136.35
Iteration:   1420, Loss function: 4.329, Average Loss: 4.541, avg. samples / sec: 54926.78
Iteration:   1420, Loss function: 5.811, Average Loss: 4.522, avg. samples / sec: 55103.51
Iteration:   1420, Loss function: 4.758, Average Loss: 4.509, avg. samples / sec: 55097.91
Iteration:   1420, Loss function: 4.411, Average Loss: 4.511, avg. samples / sec: 55068.61
Iteration:   1420, Loss function: 4.112, Average Loss: 4.527, avg. samples / sec: 55095.67
Iteration:   1420, Loss function: 3.955, Average Loss: 4.514, avg. samples / sec: 55002.22
Iteration:   1420, Loss function: 4.393, Average Loss: 4.544, avg. samples / sec: 55090.98
Iteration:   1420, Loss function: 4.733, Average Loss: 4.512, avg. samples / sec: 54965.45
Iteration:   1440, Loss function: 4.535, Average Loss: 4.524, avg. samples / sec: 54990.44
Iteration:   1440, Loss function: 4.490, Average Loss: 4.508, avg. samples / sec: 54876.91
Iteration:   1440, Loss function: 4.040, Average Loss: 4.530, avg. samples / sec: 54838.64
Iteration:   1440, Loss function: 4.578, Average Loss: 4.530, avg. samples / sec: 54854.03
Iteration:   1440, Loss function: 4.114, Average Loss: 4.493, avg. samples / sec: 54924.28
Iteration:   1440, Loss function: 5.600, Average Loss: 4.511, avg. samples / sec: 54830.85
Iteration:   1440, Loss function: 4.268, Average Loss: 4.524, avg. samples / sec: 54854.65
Iteration:   1440, Loss function: 6.093, Average Loss: 4.539, avg. samples / sec: 54845.34
Iteration:   1440, Loss function: 4.592, Average Loss: 4.512, avg. samples / sec: 54856.14
Iteration:   1440, Loss function: 5.077, Average Loss: 4.532, avg. samples / sec: 54835.87
Iteration:   1440, Loss function: 4.955, Average Loss: 4.518, avg. samples / sec: 55048.46
Iteration:   1440, Loss function: 4.435, Average Loss: 4.538, avg. samples / sec: 54885.69
Iteration:   1440, Loss function: 4.372, Average Loss: 4.482, avg. samples / sec: 54885.41
Iteration:   1440, Loss function: 4.069, Average Loss: 4.527, avg. samples / sec: 54806.71
Iteration:   1440, Loss function: 5.033, Average Loss: 4.542, avg. samples / sec: 54916.19
Iteration:   1440, Loss function: 4.226, Average Loss: 4.529, avg. samples / sec: 54887.66
Iteration:   1440, Loss function: 4.041, Average Loss: 4.522, avg. samples / sec: 54885.22
Iteration:   1440, Loss function: 4.459, Average Loss: 4.524, avg. samples / sec: 54872.65
Iteration:   1440, Loss function: 6.783, Average Loss: 4.535, avg. samples / sec: 54916.25
Iteration:   1440, Loss function: 4.546, Average Loss: 4.513, avg. samples / sec: 54891.03
Iteration:   1440, Loss function: 3.981, Average Loss: 4.521, avg. samples / sec: 54884.36
Iteration:   1440, Loss function: 4.527, Average Loss: 4.550, avg. samples / sec: 54874.15
Iteration:   1440, Loss function: 4.536, Average Loss: 4.515, avg. samples / sec: 54605.33
Iteration:   1440, Loss function: 4.782, Average Loss: 4.530, avg. samples / sec: 54848.59
Iteration:   1440, Loss function: 4.302, Average Loss: 4.514, avg. samples / sec: 54985.59
Iteration:   1440, Loss function: 3.916, Average Loss: 4.512, avg. samples / sec: 54841.35
Iteration:   1440, Loss function: 3.755, Average Loss: 4.523, avg. samples / sec: 54833.26
Iteration:   1440, Loss function: 4.031, Average Loss: 4.539, avg. samples / sec: 54832.94
Iteration:   1440, Loss function: 4.190, Average Loss: 4.517, avg. samples / sec: 54849.46
Iteration:   1440, Loss function: 4.026, Average Loss: 4.547, avg. samples / sec: 54851.98
Iteration:   1460, Loss function: 4.104, Average Loss: 4.513, avg. samples / sec: 55097.31
Iteration:   1460, Loss function: 4.487, Average Loss: 4.529, avg. samples / sec: 55070.89
Iteration:   1460, Loss function: 4.352, Average Loss: 4.507, avg. samples / sec: 55044.95
Iteration:   1460, Loss function: 4.929, Average Loss: 4.514, avg. samples / sec: 55126.53
Iteration:   1460, Loss function: 3.765, Average Loss: 4.511, avg. samples / sec: 55325.01
Iteration:   1460, Loss function: 4.149, Average Loss: 4.501, avg. samples / sec: 55053.53
Iteration:   1460, Loss function: 4.941, Average Loss: 4.527, avg. samples / sec: 55007.89
Iteration:   1460, Loss function: 3.757, Average Loss: 4.529, avg. samples / sec: 55317.58
Iteration:   1460, Loss function: 3.352, Average Loss: 4.532, avg. samples / sec: 55041.27
Iteration:   1460, Loss function: 4.869, Average Loss: 4.534, avg. samples / sec: 55077.20
Iteration:   1460, Loss function: 4.927, Average Loss: 4.525, avg. samples / sec: 55058.58
Iteration:   1460, Loss function: 4.557, Average Loss: 4.482, avg. samples / sec: 55048.22
Iteration:   1460, Loss function: 4.932, Average Loss: 4.521, avg. samples / sec: 55197.38
Iteration:   1460, Loss function: 4.369, Average Loss: 4.517, avg. samples / sec: 55018.71
Iteration:   1460, Loss function: 4.387, Average Loss: 4.539, avg. samples / sec: 54984.09
Iteration:   1460, Loss function: 5.717, Average Loss: 4.537, avg. samples / sec: 55005.89
Iteration:   1460, Loss function: 4.431, Average Loss: 4.518, avg. samples / sec: 54959.47
Iteration:   1460, Loss function: 4.185, Average Loss: 4.514, avg. samples / sec: 55212.84
Iteration:   1460, Loss function: 4.070, Average Loss: 4.527, avg. samples / sec: 55035.77
Iteration:   1460, Loss function: 5.161, Average Loss: 4.551, avg. samples / sec: 55070.40
Iteration:   1460, Loss function: 5.044, Average Loss: 4.519, avg. samples / sec: 55062.09
Iteration:   1460, Loss function: 5.383, Average Loss: 4.519, avg. samples / sec: 55019.87
Iteration:   1460, Loss function: 3.644, Average Loss: 4.535, avg. samples / sec: 55028.12
Iteration:   1460, Loss function: 4.739, Average Loss: 4.525, avg. samples / sec: 55024.21
Iteration:   1460, Loss function: 5.255, Average Loss: 4.543, avg. samples / sec: 55072.63
Iteration:   1460, Loss function: 5.504, Average Loss: 4.544, avg. samples / sec: 54958.57
Iteration:   1460, Loss function: 4.083, Average Loss: 4.523, avg. samples / sec: 55060.76
Iteration:   1460, Loss function: 4.609, Average Loss: 4.518, avg. samples / sec: 55061.98
Iteration:   1460, Loss function: 3.757, Average Loss: 4.512, avg. samples / sec: 55034.65
Iteration:   1460, Loss function: 3.601, Average Loss: 4.546, avg. samples / sec: 55050.76
:::MLL 1558640611.904 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558640611.905 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.895, Average Loss: 4.516, avg. samples / sec: 54575.73
Iteration:   1480, Loss function: 4.852, Average Loss: 4.504, avg. samples / sec: 54599.98
Iteration:   1480, Loss function: 4.024, Average Loss: 4.518, avg. samples / sec: 54546.11
Iteration:   1480, Loss function: 4.931, Average Loss: 4.505, avg. samples / sec: 54531.45
Iteration:   1480, Loss function: 4.875, Average Loss: 4.530, avg. samples / sec: 54522.86
Iteration:   1480, Loss function: 3.710, Average Loss: 4.479, avg. samples / sec: 54606.96
Iteration:   1480, Loss function: 4.371, Average Loss: 4.540, avg. samples / sec: 54607.45
Iteration:   1480, Loss function: 5.124, Average Loss: 4.537, avg. samples / sec: 54542.23
Iteration:   1480, Loss function: 4.245, Average Loss: 4.517, avg. samples / sec: 54586.28
Iteration:   1480, Loss function: 4.047, Average Loss: 4.537, avg. samples / sec: 54607.70
Iteration:   1480, Loss function: 5.217, Average Loss: 4.517, avg. samples / sec: 54614.07
Iteration:   1480, Loss function: 4.690, Average Loss: 4.532, avg. samples / sec: 54504.98
Iteration:   1480, Loss function: 3.846, Average Loss: 4.524, avg. samples / sec: 54551.63
Iteration:   1480, Loss function: 5.151, Average Loss: 4.535, avg. samples / sec: 54674.08
Iteration:   1480, Loss function: 4.596, Average Loss: 4.525, avg. samples / sec: 54463.69
Iteration:   1480, Loss function: 4.854, Average Loss: 4.527, avg. samples / sec: 54599.22
Iteration:   1480, Loss function: 5.092, Average Loss: 4.531, avg. samples / sec: 54567.04
Iteration:   1480, Loss function: 4.254, Average Loss: 4.522, avg. samples / sec: 54612.25
Iteration:   1480, Loss function: 3.346, Average Loss: 4.525, avg. samples / sec: 54575.18
Iteration:   1480, Loss function: 5.033, Average Loss: 4.520, avg. samples / sec: 54550.36
Iteration:   1480, Loss function: 5.746, Average Loss: 4.550, avg. samples / sec: 54595.27
Iteration:   1480, Loss function: 4.597, Average Loss: 4.550, avg. samples / sec: 54543.67
Iteration:   1480, Loss function: 4.467, Average Loss: 4.510, avg. samples / sec: 54310.41
Iteration:   1480, Loss function: 4.228, Average Loss: 4.524, avg. samples / sec: 54317.99
Iteration:   1480, Loss function: 5.591, Average Loss: 4.520, avg. samples / sec: 54591.56
Iteration:   1480, Loss function: 3.931, Average Loss: 4.514, avg. samples / sec: 54598.42
Iteration:   1480, Loss function: 4.883, Average Loss: 4.521, avg. samples / sec: 54425.41
Iteration:   1480, Loss function: 4.102, Average Loss: 4.528, avg. samples / sec: 54313.70
Iteration:   1480, Loss function: 4.768, Average Loss: 4.542, avg. samples / sec: 54561.26
Iteration:   1480, Loss function: 4.572, Average Loss: 4.548, avg. samples / sec: 54577.31
Iteration:   1500, Loss function: 5.130, Average Loss: 4.517, avg. samples / sec: 54797.23
Iteration:   1500, Loss function: 3.280, Average Loss: 4.553, avg. samples / sec: 55034.78
Iteration:   1500, Loss function: 5.178, Average Loss: 4.511, avg. samples / sec: 54743.78
Iteration:   1500, Loss function: 3.501, Average Loss: 4.539, avg. samples / sec: 54774.97
Iteration:   1500, Loss function: 4.428, Average Loss: 4.546, avg. samples / sec: 54762.35
Iteration:   1500, Loss function: 3.598, Average Loss: 4.521, avg. samples / sec: 54895.33
Iteration:   1500, Loss function: 4.810, Average Loss: 4.522, avg. samples / sec: 54780.96
Iteration:   1500, Loss function: 4.983, Average Loss: 4.529, avg. samples / sec: 54754.48
Iteration:   1500, Loss function: 5.314, Average Loss: 4.504, avg. samples / sec: 54652.05
Iteration:   1500, Loss function: 4.045, Average Loss: 4.525, avg. samples / sec: 54734.77
Iteration:   1500, Loss function: 5.466, Average Loss: 4.524, avg. samples / sec: 54674.88
Iteration:   1500, Loss function: 4.570, Average Loss: 4.545, avg. samples / sec: 54725.29
Iteration:   1500, Loss function: 4.182, Average Loss: 4.518, avg. samples / sec: 54610.58
Iteration:   1500, Loss function: 4.092, Average Loss: 4.521, avg. samples / sec: 54785.32
Iteration:   1500, Loss function: 4.755, Average Loss: 4.528, avg. samples / sec: 54702.11
Iteration:   1500, Loss function: 4.488, Average Loss: 4.549, avg. samples / sec: 54747.44
Iteration:   1500, Loss function: 5.910, Average Loss: 4.525, avg. samples / sec: 54733.13
Iteration:   1500, Loss function: 4.826, Average Loss: 4.529, avg. samples / sec: 54698.42
Iteration:   1500, Loss function: 4.268, Average Loss: 4.522, avg. samples / sec: 54722.67
Iteration:   1500, Loss function: 4.994, Average Loss: 4.517, avg. samples / sec: 54744.65
Iteration:   1500, Loss function: 4.484, Average Loss: 4.548, avg. samples / sec: 54724.50
Iteration:   1500, Loss function: 5.246, Average Loss: 4.523, avg. samples / sec: 54737.79
Iteration:   1500, Loss function: 4.526, Average Loss: 4.527, avg. samples / sec: 54714.47
Iteration:   1500, Loss function: 4.153, Average Loss: 4.538, avg. samples / sec: 54743.99
Iteration:   1500, Loss function: 4.396, Average Loss: 4.539, avg. samples / sec: 54602.52
Iteration:   1500, Loss function: 5.014, Average Loss: 4.531, avg. samples / sec: 54487.09
Iteration:   1500, Loss function: 4.911, Average Loss: 4.529, avg. samples / sec: 54718.28
Iteration:   1500, Loss function: 3.245, Average Loss: 4.512, avg. samples / sec: 54693.47
Iteration:   1500, Loss function: 4.495, Average Loss: 4.518, avg. samples / sec: 54666.97
Iteration:   1500, Loss function: 4.176, Average Loss: 4.482, avg. samples / sec: 54417.66
Iteration:   1520, Loss function: 5.609, Average Loss: 4.508, avg. samples / sec: 54862.19
Iteration:   1520, Loss function: 5.439, Average Loss: 4.546, avg. samples / sec: 54838.32
Iteration:   1520, Loss function: 5.063, Average Loss: 4.540, avg. samples / sec: 54830.87
Iteration:   1520, Loss function: 4.923, Average Loss: 4.535, avg. samples / sec: 55073.71
Iteration:   1520, Loss function: 4.272, Average Loss: 4.529, avg. samples / sec: 54835.12
Iteration:   1520, Loss function: 5.776, Average Loss: 4.517, avg. samples / sec: 54792.01
Iteration:   1520, Loss function: 3.076, Average Loss: 4.539, avg. samples / sec: 55048.93
Iteration:   1520, Loss function: 4.105, Average Loss: 4.519, avg. samples / sec: 54851.43
Iteration:   1520, Loss function: 5.107, Average Loss: 4.523, avg. samples / sec: 54824.90
Iteration:   1520, Loss function: 4.038, Average Loss: 4.524, avg. samples / sec: 54777.06
Iteration:   1520, Loss function: 4.921, Average Loss: 4.480, avg. samples / sec: 55100.73
Iteration:   1520, Loss function: 4.317, Average Loss: 4.521, avg. samples / sec: 54729.33
Iteration:   1520, Loss function: 3.090, Average Loss: 4.524, avg. samples / sec: 54784.83
Iteration:   1520, Loss function: 3.719, Average Loss: 4.545, avg. samples / sec: 54771.50
Iteration:   1520, Loss function: 2.780, Average Loss: 4.539, avg. samples / sec: 54881.39
Iteration:   1520, Loss function: 4.962, Average Loss: 4.523, avg. samples / sec: 54818.35
Iteration:   1520, Loss function: 4.289, Average Loss: 4.513, avg. samples / sec: 54869.68
Iteration:   1520, Loss function: 3.920, Average Loss: 4.526, avg. samples / sec: 54817.99
Iteration:   1520, Loss function: 4.953, Average Loss: 4.526, avg. samples / sec: 54802.54
Iteration:   1520, Loss function: 3.617, Average Loss: 4.552, avg. samples / sec: 54812.15
Iteration:   1520, Loss function: 5.001, Average Loss: 4.525, avg. samples / sec: 54823.28
Iteration:   1520, Loss function: 4.523, Average Loss: 4.524, avg. samples / sec: 54593.23
Iteration:   1520, Loss function: 3.932, Average Loss: 4.518, avg. samples / sec: 54803.13
Iteration:   1520, Loss function: 5.085, Average Loss: 4.537, avg. samples / sec: 54810.21
Iteration:   1520, Loss function: 4.520, Average Loss: 4.517, avg. samples / sec: 54757.14
Iteration:   1520, Loss function: 4.134, Average Loss: 4.531, avg. samples / sec: 54816.12
Iteration:   1520, Loss function: 4.956, Average Loss: 4.523, avg. samples / sec: 54859.39
Iteration:   1520, Loss function: 4.797, Average Loss: 4.514, avg. samples / sec: 54780.15
Iteration:   1520, Loss function: 5.717, Average Loss: 4.525, avg. samples / sec: 54784.36
Iteration:   1520, Loss function: 4.310, Average Loss: 4.555, avg. samples / sec: 54371.85
:::MLL 1558640614.058 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558640614.058 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.684, Average Loss: 4.532, avg. samples / sec: 54340.42
Iteration:   1540, Loss function: 4.654, Average Loss: 4.537, avg. samples / sec: 54322.11
Iteration:   1540, Loss function: 5.995, Average Loss: 4.525, avg. samples / sec: 54338.34
Iteration:   1540, Loss function: 4.896, Average Loss: 4.505, avg. samples / sec: 54243.95
Iteration:   1540, Loss function: 5.009, Average Loss: 4.548, avg. samples / sec: 54320.92
Iteration:   1540, Loss function: 4.275, Average Loss: 4.518, avg. samples / sec: 54236.59
Iteration:   1540, Loss function: 4.350, Average Loss: 4.542, avg. samples / sec: 54175.91
Iteration:   1540, Loss function: 4.683, Average Loss: 4.526, avg. samples / sec: 54239.59
Iteration:   1540, Loss function: 3.771, Average Loss: 4.521, avg. samples / sec: 54192.04
Iteration:   1540, Loss function: 5.340, Average Loss: 4.525, avg. samples / sec: 54240.55
Iteration:   1540, Loss function: 5.062, Average Loss: 4.519, avg. samples / sec: 54178.93
Iteration:   1540, Loss function: 4.776, Average Loss: 4.485, avg. samples / sec: 54162.36
Iteration:   1540, Loss function: 4.076, Average Loss: 4.524, avg. samples / sec: 54325.36
Iteration:   1540, Loss function: 4.968, Average Loss: 4.538, avg. samples / sec: 54264.11
Iteration:   1540, Loss function: 4.857, Average Loss: 4.519, avg. samples / sec: 54349.41
Iteration:   1540, Loss function: 4.868, Average Loss: 4.528, avg. samples / sec: 54298.84
Iteration:   1540, Loss function: 4.743, Average Loss: 4.546, avg. samples / sec: 54057.36
Iteration:   1540, Loss function: 4.952, Average Loss: 4.527, avg. samples / sec: 54295.51
Iteration:   1540, Loss function: 4.839, Average Loss: 4.511, avg. samples / sec: 54311.96
Iteration:   1540, Loss function: 4.700, Average Loss: 4.511, avg. samples / sec: 54261.41
Iteration:   1540, Loss function: 4.026, Average Loss: 4.526, avg. samples / sec: 54283.57
Iteration:   1540, Loss function: 4.748, Average Loss: 4.537, avg. samples / sec: 54198.06
Iteration:   1540, Loss function: 4.988, Average Loss: 4.524, avg. samples / sec: 54166.13
Iteration:   1540, Loss function: 4.077, Average Loss: 4.540, avg. samples / sec: 53973.94
Iteration:   1540, Loss function: 4.756, Average Loss: 4.533, avg. samples / sec: 54162.19
Iteration:   1540, Loss function: 4.441, Average Loss: 4.549, avg. samples / sec: 54157.07
Iteration:   1540, Loss function: 4.477, Average Loss: 4.515, avg. samples / sec: 54119.95
Iteration:   1540, Loss function: 4.795, Average Loss: 4.514, avg. samples / sec: 54141.20
Iteration:   1540, Loss function: 4.437, Average Loss: 4.527, avg. samples / sec: 54112.30
Iteration:   1540, Loss function: 4.767, Average Loss: 4.556, avg. samples / sec: 54264.92
Iteration:   1560, Loss function: 5.228, Average Loss: 4.529, avg. samples / sec: 54299.38
Iteration:   1560, Loss function: 3.029, Average Loss: 4.542, avg. samples / sec: 54265.64
Iteration:   1560, Loss function: 3.637, Average Loss: 4.524, avg. samples / sec: 54140.66
Iteration:   1560, Loss function: 5.934, Average Loss: 4.520, avg. samples / sec: 54198.48
Iteration:   1560, Loss function: 4.027, Average Loss: 4.519, avg. samples / sec: 54323.20
Iteration:   1560, Loss function: 3.739, Average Loss: 4.536, avg. samples / sec: 54078.23
Iteration:   1560, Loss function: 4.989, Average Loss: 4.490, avg. samples / sec: 54291.79
Iteration:   1560, Loss function: 5.285, Average Loss: 4.524, avg. samples / sec: 54241.39
Iteration:   1560, Loss function: 4.689, Average Loss: 4.551, avg. samples / sec: 54260.31
Iteration:   1560, Loss function: 5.171, Average Loss: 4.551, avg. samples / sec: 54091.36
Iteration:   1560, Loss function: 3.677, Average Loss: 4.531, avg. samples / sec: 53984.84
Iteration:   1560, Loss function: 4.289, Average Loss: 4.533, avg. samples / sec: 54317.57
Iteration:   1560, Loss function: 4.336, Average Loss: 4.528, avg. samples / sec: 54090.80
Iteration:   1560, Loss function: 5.365, Average Loss: 4.529, avg. samples / sec: 54182.20
Iteration:   1560, Loss function: 3.092, Average Loss: 4.547, avg. samples / sec: 54305.20
Iteration:   1560, Loss function: 4.215, Average Loss: 4.528, avg. samples / sec: 54290.05
Iteration:   1560, Loss function: 5.029, Average Loss: 4.539, avg. samples / sec: 54139.24
Iteration:   1560, Loss function: 4.791, Average Loss: 4.541, avg. samples / sec: 54273.43
Iteration:   1560, Loss function: 3.121, Average Loss: 4.510, avg. samples / sec: 54346.79
Iteration:   1560, Loss function: 6.083, Average Loss: 4.522, avg. samples / sec: 54129.09
Iteration:   1560, Loss function: 5.136, Average Loss: 4.520, avg. samples / sec: 54331.12
Iteration:   1560, Loss function: 4.558, Average Loss: 4.529, avg. samples / sec: 54354.21
Iteration:   1560, Loss function: 5.304, Average Loss: 4.542, avg. samples / sec: 54242.81
Iteration:   1560, Loss function: 4.530, Average Loss: 4.531, avg. samples / sec: 54179.70
Iteration:   1560, Loss function: 4.250, Average Loss: 4.516, avg. samples / sec: 54056.88
Iteration:   1560, Loss function: 3.750, Average Loss: 4.514, avg. samples / sec: 54139.20
Iteration:   1560, Loss function: 4.223, Average Loss: 4.558, avg. samples / sec: 54329.50
Iteration:   1560, Loss function: 3.817, Average Loss: 4.514, avg. samples / sec: 54100.52
Iteration:   1560, Loss function: 4.443, Average Loss: 4.524, avg. samples / sec: 53984.55
Iteration:   1560, Loss function: 5.028, Average Loss: 4.502, avg. samples / sec: 53772.08
Iteration:   1580, Loss function: 4.243, Average Loss: 4.537, avg. samples / sec: 54885.73
Iteration:   1580, Loss function: 4.006, Average Loss: 4.501, avg. samples / sec: 55246.56
Iteration:   1580, Loss function: 5.593, Average Loss: 4.527, avg. samples / sec: 54849.20
Iteration:   1580, Loss function: 5.132, Average Loss: 4.543, avg. samples / sec: 54780.77
Iteration:   1580, Loss function: 5.024, Average Loss: 4.531, avg. samples / sec: 54979.07
Iteration:   1580, Loss function: 4.831, Average Loss: 4.486, avg. samples / sec: 54827.57
Iteration:   1580, Loss function: 4.322, Average Loss: 4.527, avg. samples / sec: 54745.57
Iteration:   1580, Loss function: 3.121, Average Loss: 4.532, avg. samples / sec: 54910.50
Iteration:   1580, Loss function: 4.799, Average Loss: 4.511, avg. samples / sec: 55073.95
Iteration:   1580, Loss function: 4.031, Average Loss: 4.513, avg. samples / sec: 55025.26
Iteration:   1580, Loss function: 5.219, Average Loss: 4.551, avg. samples / sec: 54878.21
Iteration:   1580, Loss function: 4.292, Average Loss: 4.553, avg. samples / sec: 54837.12
Iteration:   1580, Loss function: 3.693, Average Loss: 4.516, avg. samples / sec: 54753.59
Iteration:   1580, Loss function: 4.537, Average Loss: 4.531, avg. samples / sec: 54720.93
Iteration:   1580, Loss function: 3.390, Average Loss: 4.525, avg. samples / sec: 55090.50
Iteration:   1580, Loss function: 3.870, Average Loss: 4.546, avg. samples / sec: 54836.48
Iteration:   1580, Loss function: 4.892, Average Loss: 4.534, avg. samples / sec: 54799.55
Iteration:   1580, Loss function: 5.301, Average Loss: 4.533, avg. samples / sec: 54791.33
Iteration:   1580, Loss function: 4.994, Average Loss: 4.535, avg. samples / sec: 54808.74
Iteration:   1580, Loss function: 5.416, Average Loss: 4.523, avg. samples / sec: 54805.56
Iteration:   1580, Loss function: 3.953, Average Loss: 4.513, avg. samples / sec: 54831.62
Iteration:   1580, Loss function: 3.867, Average Loss: 4.537, avg. samples / sec: 54780.77
Iteration:   1580, Loss function: 3.691, Average Loss: 4.528, avg. samples / sec: 54802.00
Iteration:   1580, Loss function: 5.123, Average Loss: 4.528, avg. samples / sec: 54759.61
Iteration:   1580, Loss function: 5.365, Average Loss: 4.529, avg. samples / sec: 54779.96
Iteration:   1580, Loss function: 4.173, Average Loss: 4.514, avg. samples / sec: 54771.38
Iteration:   1580, Loss function: 3.986, Average Loss: 4.551, avg. samples / sec: 54815.41
Iteration:   1580, Loss function: 3.650, Average Loss: 4.515, avg. samples / sec: 54561.76
Iteration:   1580, Loss function: 3.475, Average Loss: 4.529, avg. samples / sec: 54779.21
Iteration:   1580, Loss function: 4.507, Average Loss: 4.540, avg. samples / sec: 54777.49
Iteration:   1600, Loss function: 4.152, Average Loss: 4.537, avg. samples / sec: 55105.99
Iteration:   1600, Loss function: 4.557, Average Loss: 4.544, avg. samples / sec: 55018.84
Iteration:   1600, Loss function: 6.083, Average Loss: 4.511, avg. samples / sec: 55065.64
Iteration:   1600, Loss function: 4.548, Average Loss: 4.532, avg. samples / sec: 54994.47
Iteration:   1600, Loss function: 4.592, Average Loss: 4.504, avg. samples / sec: 54960.95
Iteration:   1600, Loss function: 4.799, Average Loss: 4.527, avg. samples / sec: 54948.09
Iteration:   1600, Loss function: 5.935, Average Loss: 4.549, avg. samples / sec: 55026.19
Iteration:   1600, Loss function: 4.783, Average Loss: 4.533, avg. samples / sec: 54960.76
Iteration:   1600, Loss function: 5.912, Average Loss: 4.553, avg. samples / sec: 54975.31
Iteration:   1600, Loss function: 3.955, Average Loss: 4.513, avg. samples / sec: 54959.92
Iteration:   1600, Loss function: 4.090, Average Loss: 4.529, avg. samples / sec: 54943.02
Iteration:   1600, Loss function: 5.911, Average Loss: 4.531, avg. samples / sec: 54987.22
Iteration:   1600, Loss function: 5.019, Average Loss: 4.489, avg. samples / sec: 54925.16
Iteration:   1600, Loss function: 4.127, Average Loss: 4.538, avg. samples / sec: 55021.29
Iteration:   1600, Loss function: 5.325, Average Loss: 4.549, avg. samples / sec: 54960.29
Iteration:   1600, Loss function: 4.236, Average Loss: 4.523, avg. samples / sec: 54888.38
Iteration:   1600, Loss function: 4.827, Average Loss: 4.512, avg. samples / sec: 55035.56
Iteration:   1600, Loss function: 4.757, Average Loss: 4.522, avg. samples / sec: 54987.26
Iteration:   1600, Loss function: 5.058, Average Loss: 4.535, avg. samples / sec: 54969.93
Iteration:   1600, Loss function: 5.002, Average Loss: 4.526, avg. samples / sec: 55009.61
Iteration:   1600, Loss function: 4.047, Average Loss: 4.530, avg. samples / sec: 54935.13
Iteration:   1600, Loss function: 5.359, Average Loss: 4.536, avg. samples / sec: 54988.55
Iteration:   1600, Loss function: 4.440, Average Loss: 4.527, avg. samples / sec: 54999.75
Iteration:   1600, Loss function: 4.944, Average Loss: 4.530, avg. samples / sec: 55004.41
Iteration:   1600, Loss function: 3.697, Average Loss: 4.513, avg. samples / sec: 54995.09
Iteration:   1600, Loss function: 3.753, Average Loss: 4.529, avg. samples / sec: 54984.99
Iteration:   1600, Loss function: 5.727, Average Loss: 4.554, avg. samples / sec: 54980.81
Iteration:   1600, Loss function: 4.824, Average Loss: 4.509, avg. samples / sec: 54944.47
Iteration:   1600, Loss function: 4.011, Average Loss: 4.515, avg. samples / sec: 54736.55
Iteration:   1600, Loss function: 4.174, Average Loss: 4.544, avg. samples / sec: 54922.03
:::MLL 1558640616.211 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558640616.212 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 4.143, Average Loss: 4.533, avg. samples / sec: 54840.77
Iteration:   1620, Loss function: 5.052, Average Loss: 4.504, avg. samples / sec: 54515.39
Iteration:   1620, Loss function: 3.107, Average Loss: 4.533, avg. samples / sec: 54510.50
Iteration:   1620, Loss function: 4.179, Average Loss: 4.540, avg. samples / sec: 54466.03
Iteration:   1620, Loss function: 4.196, Average Loss: 4.536, avg. samples / sec: 54332.79
Iteration:   1620, Loss function: 3.966, Average Loss: 4.536, avg. samples / sec: 54561.76
Iteration:   1620, Loss function: 3.975, Average Loss: 4.535, avg. samples / sec: 54526.11
Iteration:   1620, Loss function: 4.059, Average Loss: 4.514, avg. samples / sec: 54538.62
Iteration:   1620, Loss function: 3.728, Average Loss: 4.493, avg. samples / sec: 54538.16
Iteration:   1620, Loss function: 4.108, Average Loss: 4.553, avg. samples / sec: 54496.31
Iteration:   1620, Loss function: 3.557, Average Loss: 4.523, avg. samples / sec: 54525.56
Iteration:   1620, Loss function: 4.818, Average Loss: 4.528, avg. samples / sec: 54474.20
Iteration:   1620, Loss function: 4.239, Average Loss: 4.510, avg. samples / sec: 54421.56
Iteration:   1620, Loss function: 4.162, Average Loss: 4.548, avg. samples / sec: 54484.96
Iteration:   1620, Loss function: 4.383, Average Loss: 4.529, avg. samples / sec: 54560.07
Iteration:   1620, Loss function: 4.554, Average Loss: 4.526, avg. samples / sec: 54526.61
Iteration:   1620, Loss function: 5.527, Average Loss: 4.514, avg. samples / sec: 54508.52
Iteration:   1620, Loss function: 4.266, Average Loss: 4.533, avg. samples / sec: 54522.33
Iteration:   1620, Loss function: 4.515, Average Loss: 4.545, avg. samples / sec: 54495.07
Iteration:   1620, Loss function: 6.378, Average Loss: 4.544, avg. samples / sec: 54624.87
Iteration:   1620, Loss function: 4.413, Average Loss: 4.535, avg. samples / sec: 54516.62
Iteration:   1620, Loss function: 5.355, Average Loss: 4.529, avg. samples / sec: 54521.17
Iteration:   1620, Loss function: 4.924, Average Loss: 4.518, avg. samples / sec: 54468.51
Iteration:   1620, Loss function: 3.673, Average Loss: 4.511, avg. samples / sec: 54532.78
Iteration:   1620, Loss function: 4.797, Average Loss: 4.517, avg. samples / sec: 54523.37
Iteration:   1620, Loss function: 3.792, Average Loss: 4.522, avg. samples / sec: 54469.12
Iteration:   1620, Loss function: 4.093, Average Loss: 4.530, avg. samples / sec: 54476.98
Iteration:   1620, Loss function: 4.859, Average Loss: 4.512, avg. samples / sec: 54477.54
Iteration:   1620, Loss function: 4.601, Average Loss: 4.557, avg. samples / sec: 54473.97
Iteration:   1620, Loss function: 4.982, Average Loss: 4.527, avg. samples / sec: 54452.87
Iteration:   1640, Loss function: 6.571, Average Loss: 4.531, avg. samples / sec: 54940.00
Iteration:   1640, Loss function: 3.068, Average Loss: 4.501, avg. samples / sec: 54927.51
Iteration:   1640, Loss function: 3.616, Average Loss: 4.537, avg. samples / sec: 54924.11
Iteration:   1640, Loss function: 3.162, Average Loss: 4.554, avg. samples / sec: 54949.83
Iteration:   1640, Loss function: 4.836, Average Loss: 4.533, avg. samples / sec: 54926.44
Iteration:   1640, Loss function: 3.803, Average Loss: 4.525, avg. samples / sec: 54929.80
Iteration:   1640, Loss function: 3.633, Average Loss: 4.507, avg. samples / sec: 54956.19
Iteration:   1640, Loss function: 5.355, Average Loss: 4.539, avg. samples / sec: 54874.79
Iteration:   1640, Loss function: 5.000, Average Loss: 4.546, avg. samples / sec: 54934.79
Iteration:   1640, Loss function: 3.862, Average Loss: 4.514, avg. samples / sec: 54874.15
Iteration:   1640, Loss function: 3.800, Average Loss: 4.524, avg. samples / sec: 54879.09
Iteration:   1640, Loss function: 4.342, Average Loss: 4.525, avg. samples / sec: 54800.92
Iteration:   1640, Loss function: 4.116, Average Loss: 4.530, avg. samples / sec: 54899.44
Iteration:   1640, Loss function: 4.197, Average Loss: 4.541, avg. samples / sec: 54914.67
Iteration:   1640, Loss function: 4.603, Average Loss: 4.526, avg. samples / sec: 54946.57
Iteration:   1640, Loss function: 3.992, Average Loss: 4.520, avg. samples / sec: 54895.63
Iteration:   1640, Loss function: 3.929, Average Loss: 4.520, avg. samples / sec: 54932.89
Iteration:   1640, Loss function: 6.158, Average Loss: 4.496, avg. samples / sec: 54715.68
Iteration:   1640, Loss function: 4.266, Average Loss: 4.516, avg. samples / sec: 54951.56
Iteration:   1640, Loss function: 4.114, Average Loss: 4.533, avg. samples / sec: 54897.62
Iteration:   1640, Loss function: 4.084, Average Loss: 4.547, avg. samples / sec: 54866.52
Iteration:   1640, Loss function: 5.087, Average Loss: 4.515, avg. samples / sec: 54853.54
Iteration:   1640, Loss function: 4.093, Average Loss: 4.527, avg. samples / sec: 54910.13
Iteration:   1640, Loss function: 3.737, Average Loss: 4.518, avg. samples / sec: 54891.53
Iteration:   1640, Loss function: 3.802, Average Loss: 4.527, avg. samples / sec: 54924.45
Iteration:   1640, Loss function: 3.374, Average Loss: 4.533, avg. samples / sec: 54825.65
Iteration:   1640, Loss function: 5.106, Average Loss: 4.513, avg. samples / sec: 54858.36
Iteration:   1640, Loss function: 4.281, Average Loss: 4.534, avg. samples / sec: 54613.78
Iteration:   1640, Loss function: 4.637, Average Loss: 4.518, avg. samples / sec: 54856.06
Iteration:   1640, Loss function: 3.954, Average Loss: 4.552, avg. samples / sec: 54897.43
Iteration:   1660, Loss function: 4.761, Average Loss: 4.527, avg. samples / sec: 53153.81
Iteration:   1660, Loss function: 4.841, Average Loss: 4.530, avg. samples / sec: 53571.50
Iteration:   1660, Loss function: 5.318, Average Loss: 4.541, avg. samples / sec: 53198.03
Iteration:   1660, Loss function: 5.469, Average Loss: 4.528, avg. samples / sec: 53192.99
Iteration:   1660, Loss function: 3.850, Average Loss: 4.534, avg. samples / sec: 53456.26
Iteration:   1660, Loss function: 4.700, Average Loss: 4.522, avg. samples / sec: 53252.27
Iteration:   1660, Loss function: 5.161, Average Loss: 4.502, avg. samples / sec: 53131.39
Iteration:   1660, Loss function: 4.248, Average Loss: 4.534, avg. samples / sec: 53198.48
Iteration:   1660, Loss function: 4.995, Average Loss: 4.510, avg. samples / sec: 53178.20
Iteration:   1660, Loss function: 4.936, Average Loss: 4.524, avg. samples / sec: 53166.20
Iteration:   1660, Loss function: 4.262, Average Loss: 4.549, avg. samples / sec: 53139.44
Iteration:   1660, Loss function: 4.023, Average Loss: 4.522, avg. samples / sec: 53219.09
Iteration:   1660, Loss function: 4.652, Average Loss: 4.491, avg. samples / sec: 53339.99
Iteration:   1660, Loss function: 3.782, Average Loss: 4.513, avg. samples / sec: 53163.32
Iteration:   1660, Loss function: 5.902, Average Loss: 4.547, avg. samples / sec: 53141.18
Iteration:   1660, Loss function: 4.034, Average Loss: 4.515, avg. samples / sec: 53190.12
Iteration:   1660, Loss function: 3.352, Average Loss: 4.535, avg. samples / sec: 53170.70
Iteration:   1660, Loss function: 2.883, Average Loss: 4.522, avg. samples / sec: 53172.50
Iteration:   1660, Loss function: 4.238, Average Loss: 4.548, avg. samples / sec: 53216.84
Iteration:   1660, Loss function: 5.363, Average Loss: 4.515, avg. samples / sec: 53189.64
Iteration:   1660, Loss function: 3.627, Average Loss: 4.525, avg. samples / sec: 53202.67
Iteration:   1660, Loss function: 3.557, Average Loss: 4.531, avg. samples / sec: 53128.22
Iteration:   1660, Loss function: 3.879, Average Loss: 4.545, avg. samples / sec: 53241.06
Iteration:   1660, Loss function: 5.386, Average Loss: 4.515, avg. samples / sec: 53152.31
Iteration:   1660, Loss function: 3.931, Average Loss: 4.528, avg. samples / sec: 53216.41
Iteration:   1660, Loss function: 4.618, Average Loss: 4.527, avg. samples / sec: 53197.59
Iteration:   1660, Loss function: 4.514, Average Loss: 4.511, avg. samples / sec: 53210.95
Iteration:   1660, Loss function: 4.208, Average Loss: 4.516, avg. samples / sec: 53166.85
Iteration:   1660, Loss function: 3.279, Average Loss: 4.531, avg. samples / sec: 53126.62
Iteration:   1660, Loss function: 2.640, Average Loss: 4.511, avg. samples / sec: 53172.92
:::MLL 1558640618.378 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558640618.379 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 4.970, Average Loss: 4.525, avg. samples / sec: 54442.44
Iteration:   1680, Loss function: 4.124, Average Loss: 4.532, avg. samples / sec: 54635.40
Iteration:   1680, Loss function: 2.978, Average Loss: 4.521, avg. samples / sec: 54591.46
Iteration:   1680, Loss function: 4.456, Average Loss: 4.508, avg. samples / sec: 54623.39
Iteration:   1680, Loss function: 5.548, Average Loss: 4.500, avg. samples / sec: 54615.79
Iteration:   1680, Loss function: 3.501, Average Loss: 4.535, avg. samples / sec: 54610.48
Iteration:   1680, Loss function: 4.329, Average Loss: 4.537, avg. samples / sec: 54522.65
Iteration:   1680, Loss function: 3.546, Average Loss: 4.546, avg. samples / sec: 54625.57
Iteration:   1680, Loss function: 3.943, Average Loss: 4.513, avg. samples / sec: 54748.35
Iteration:   1680, Loss function: 4.066, Average Loss: 4.524, avg. samples / sec: 54527.12
Iteration:   1680, Loss function: 3.844, Average Loss: 4.517, avg. samples / sec: 54477.42
Iteration:   1680, Loss function: 5.128, Average Loss: 4.488, avg. samples / sec: 54502.79
Iteration:   1680, Loss function: 5.184, Average Loss: 4.530, avg. samples / sec: 54311.18
Iteration:   1680, Loss function: 5.210, Average Loss: 4.518, avg. samples / sec: 54471.25
Iteration:   1680, Loss function: 5.245, Average Loss: 4.514, avg. samples / sec: 54489.28
Iteration:   1680, Loss function: 4.046, Average Loss: 4.551, avg. samples / sec: 54443.56
Iteration:   1680, Loss function: 3.310, Average Loss: 4.521, avg. samples / sec: 54589.43
Iteration:   1680, Loss function: 3.350, Average Loss: 4.510, avg. samples / sec: 54629.11
Iteration:   1680, Loss function: 5.839, Average Loss: 4.513, avg. samples / sec: 54561.91
Iteration:   1680, Loss function: 4.300, Average Loss: 4.522, avg. samples / sec: 54571.21
Iteration:   1680, Loss function: 3.809, Average Loss: 4.519, avg. samples / sec: 54514.13
Iteration:   1680, Loss function: 4.304, Average Loss: 4.529, avg. samples / sec: 54555.22
Iteration:   1680, Loss function: 3.991, Average Loss: 4.535, avg. samples / sec: 54443.62
Iteration:   1680, Loss function: 5.508, Average Loss: 4.513, avg. samples / sec: 54518.11
Iteration:   1680, Loss function: 3.702, Average Loss: 4.510, avg. samples / sec: 54462.11
Iteration:   1680, Loss function: 3.970, Average Loss: 4.529, avg. samples / sec: 54447.72
Iteration:   1680, Loss function: 3.958, Average Loss: 4.510, avg. samples / sec: 54518.89
Iteration:   1680, Loss function: 3.782, Average Loss: 4.519, avg. samples / sec: 54451.34
Iteration:   1680, Loss function: 4.380, Average Loss: 4.546, avg. samples / sec: 54392.87
Iteration:   1680, Loss function: 4.753, Average Loss: 4.549, avg. samples / sec: 54403.35
Iteration:   1700, Loss function: 3.256, Average Loss: 4.531, avg. samples / sec: 55179.70
Iteration:   1700, Loss function: 3.903, Average Loss: 4.525, avg. samples / sec: 54950.28
Iteration:   1700, Loss function: 4.174, Average Loss: 4.514, avg. samples / sec: 55240.82
Iteration:   1700, Loss function: 3.731, Average Loss: 4.505, avg. samples / sec: 55228.03
Iteration:   1700, Loss function: 4.570, Average Loss: 4.500, avg. samples / sec: 54832.60
Iteration:   1700, Loss function: 4.394, Average Loss: 4.526, avg. samples / sec: 54780.72
Iteration:   1700, Loss function: 3.713, Average Loss: 4.520, avg. samples / sec: 54894.86
Iteration:   1700, Loss function: 3.217, Average Loss: 4.514, avg. samples / sec: 54772.16
Iteration:   1700, Loss function: 4.828, Average Loss: 4.513, avg. samples / sec: 54942.05
Iteration:   1700, Loss function: 3.654, Average Loss: 4.513, avg. samples / sec: 54910.50
Iteration:   1700, Loss function: 4.915, Average Loss: 4.536, avg. samples / sec: 54796.27
Iteration:   1700, Loss function: 3.723, Average Loss: 4.532, avg. samples / sec: 54764.57
Iteration:   1700, Loss function: 4.079, Average Loss: 4.544, avg. samples / sec: 54946.81
Iteration:   1700, Loss function: 4.971, Average Loss: 4.502, avg. samples / sec: 54746.38
Iteration:   1700, Loss function: 5.678, Average Loss: 4.544, avg. samples / sec: 54801.39
Iteration:   1700, Loss function: 3.661, Average Loss: 4.507, avg. samples / sec: 54914.48
Iteration:   1700, Loss function: 3.692, Average Loss: 4.511, avg. samples / sec: 54793.48
Iteration:   1700, Loss function: 2.603, Average Loss: 4.482, avg. samples / sec: 54875.05
Iteration:   1700, Loss function: 4.253, Average Loss: 4.523, avg. samples / sec: 54995.61
Iteration:   1700, Loss function: 5.067, Average Loss: 4.532, avg. samples / sec: 54970.02
Iteration:   1700, Loss function: 4.674, Average Loss: 4.508, avg. samples / sec: 54962.96
Iteration:   1700, Loss function: 4.343, Average Loss: 4.528, avg. samples / sec: 54918.78
Iteration:   1700, Loss function: 6.103, Average Loss: 4.518, avg. samples / sec: 54835.63
Iteration:   1700, Loss function: 4.949, Average Loss: 4.552, avg. samples / sec: 54999.90
Iteration:   1700, Loss function: 4.633, Average Loss: 4.506, avg. samples / sec: 54917.64
Iteration:   1700, Loss function: 4.473, Average Loss: 4.545, avg. samples / sec: 54965.92
Iteration:   1700, Loss function: 4.771, Average Loss: 4.505, avg. samples / sec: 54766.57
Iteration:   1700, Loss function: 4.221, Average Loss: 4.514, avg. samples / sec: 54852.73
Iteration:   1700, Loss function: 4.286, Average Loss: 4.518, avg. samples / sec: 54797.42
Iteration:   1700, Loss function: 4.815, Average Loss: 4.521, avg. samples / sec: 54725.35
Iteration:   1720, Loss function: 3.979, Average Loss: 4.525, avg. samples / sec: 55098.69
Iteration:   1720, Loss function: 3.561, Average Loss: 4.517, avg. samples / sec: 55265.34
Iteration:   1720, Loss function: 3.643, Average Loss: 4.514, avg. samples / sec: 55149.51
Iteration:   1720, Loss function: 3.887, Average Loss: 4.509, avg. samples / sec: 55153.74
Iteration:   1720, Loss function: 4.750, Average Loss: 4.517, avg. samples / sec: 55143.01
Iteration:   1720, Loss function: 5.450, Average Loss: 4.501, avg. samples / sec: 55174.64
Iteration:   1720, Loss function: 5.947, Average Loss: 4.501, avg. samples / sec: 55076.96
Iteration:   1720, Loss function: 3.843, Average Loss: 4.523, avg. samples / sec: 55086.09
Iteration:   1720, Loss function: 4.323, Average Loss: 4.537, avg. samples / sec: 55113.30
Iteration:   1720, Loss function: 5.387, Average Loss: 4.485, avg. samples / sec: 55151.58
Iteration:   1720, Loss function: 3.436, Average Loss: 4.502, avg. samples / sec: 55121.32
Iteration:   1720, Loss function: 3.078, Average Loss: 4.526, avg. samples / sec: 55083.46
Iteration:   1720, Loss function: 2.895, Average Loss: 4.546, avg. samples / sec: 55061.06
Iteration:   1720, Loss function: 5.116, Average Loss: 4.533, avg. samples / sec: 54996.96
Iteration:   1720, Loss function: 4.610, Average Loss: 4.535, avg. samples / sec: 54704.15
Iteration:   1720, Loss function: 3.698, Average Loss: 4.505, avg. samples / sec: 55117.54
Iteration:   1720, Loss function: 5.068, Average Loss: 4.514, avg. samples / sec: 54843.74
Iteration:   1720, Loss function: 4.103, Average Loss: 4.512, avg. samples / sec: 55140.60
Iteration:   1720, Loss function: 5.954, Average Loss: 4.508, avg. samples / sec: 54940.10
Iteration:   1720, Loss function: 4.312, Average Loss: 4.514, avg. samples / sec: 55100.65
Iteration:   1720, Loss function: 4.632, Average Loss: 4.545, avg. samples / sec: 55136.28
Iteration:   1720, Loss function: 4.544, Average Loss: 4.509, avg. samples / sec: 55122.09
Iteration:   1720, Loss function: 3.653, Average Loss: 4.521, avg. samples / sec: 55055.25
Iteration:   1720, Loss function: 3.476, Average Loss: 4.528, avg. samples / sec: 55075.80
Iteration:   1720, Loss function: 4.705, Average Loss: 4.529, avg. samples / sec: 55045.25
Iteration:   1720, Loss function: 3.366, Average Loss: 4.502, avg. samples / sec: 54798.10
Iteration:   1720, Loss function: 4.609, Average Loss: 4.515, avg. samples / sec: 55121.25
Iteration:   1720, Loss function: 4.104, Average Loss: 4.516, avg. samples / sec: 55069.69
Iteration:   1720, Loss function: 4.794, Average Loss: 4.501, avg. samples / sec: 54952.42
Iteration:   1720, Loss function: 4.863, Average Loss: 4.550, avg. samples / sec: 54902.54
Iteration:   1740, Loss function: 5.537, Average Loss: 4.528, avg. samples / sec: 55338.04
Iteration:   1740, Loss function: 4.816, Average Loss: 4.511, avg. samples / sec: 55340.06
Iteration:   1740, Loss function: 4.721, Average Loss: 4.523, avg. samples / sec: 55343.67
Iteration:   1740, Loss function: 4.217, Average Loss: 4.500, avg. samples / sec: 55332.65
Iteration:   1740, Loss function: 5.189, Average Loss: 4.523, avg. samples / sec: 55290.65
Iteration:   1740, Loss function: 3.415, Average Loss: 4.484, avg. samples / sec: 55334.59
Iteration:   1740, Loss function: 5.426, Average Loss: 4.523, avg. samples / sec: 55358.52
Iteration:   1740, Loss function: 4.804, Average Loss: 4.512, avg. samples / sec: 55248.92
Iteration:   1740, Loss function: 5.635, Average Loss: 4.515, avg. samples / sec: 55134.26
Iteration:   1740, Loss function: 5.000, Average Loss: 4.535, avg. samples / sec: 55306.05
Iteration:   1740, Loss function: 3.838, Average Loss: 4.528, avg. samples / sec: 55418.91
Iteration:   1740, Loss function: 5.175, Average Loss: 4.501, avg. samples / sec: 55315.50
Iteration:   1740, Loss function: 4.992, Average Loss: 4.547, avg. samples / sec: 55330.46
Iteration:   1740, Loss function: 2.914, Average Loss: 4.529, avg. samples / sec: 55493.04
Iteration:   1740, Loss function: 4.412, Average Loss: 4.502, avg. samples / sec: 55207.43
Iteration:   1740, Loss function: 5.028, Average Loss: 4.506, avg. samples / sec: 55399.84
Iteration:   1740, Loss function: 3.287, Average Loss: 4.503, avg. samples / sec: 55334.04
Iteration:   1740, Loss function: 4.626, Average Loss: 4.517, avg. samples / sec: 55359.04
Iteration:   1740, Loss function: 5.434, Average Loss: 4.510, avg. samples / sec: 55378.64
Iteration:   1740, Loss function: 3.303, Average Loss: 4.509, avg. samples / sec: 55315.56
Iteration:   1740, Loss function: 4.139, Average Loss: 4.528, avg. samples / sec: 55328.48
Iteration:   1740, Loss function: 3.691, Average Loss: 4.531, avg. samples / sec: 55255.59
Iteration:   1740, Loss function: 3.726, Average Loss: 4.553, avg. samples / sec: 55513.36
Iteration:   1740, Loss function: 5.639, Average Loss: 4.514, avg. samples / sec: 55293.29
Iteration:   1740, Loss function: 4.795, Average Loss: 4.509, avg. samples / sec: 55297.05
Iteration:   1740, Loss function: 4.110, Average Loss: 4.514, avg. samples / sec: 55363.15
Iteration:   1740, Loss function: 6.410, Average Loss: 4.517, avg. samples / sec: 55292.58
Iteration:   1740, Loss function: 4.433, Average Loss: 4.501, avg. samples / sec: 55457.59
Iteration:   1740, Loss function: 3.429, Average Loss: 4.500, avg. samples / sec: 55319.16
Iteration:   1740, Loss function: 3.215, Average Loss: 4.534, avg. samples / sec: 55112.74
:::MLL 1558640620.517 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558640620.518 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 4.762, Average Loss: 4.525, avg. samples / sec: 54766.03
Iteration:   1760, Loss function: 5.091, Average Loss: 4.499, avg. samples / sec: 54815.56
Iteration:   1760, Loss function: 3.780, Average Loss: 4.509, avg. samples / sec: 54780.17
Iteration:   1760, Loss function: 4.039, Average Loss: 4.525, avg. samples / sec: 54827.80
Iteration:   1760, Loss function: 4.642, Average Loss: 4.498, avg. samples / sec: 54879.56
Iteration:   1760, Loss function: 4.426, Average Loss: 4.518, avg. samples / sec: 54766.99
Iteration:   1760, Loss function: 5.352, Average Loss: 4.514, avg. samples / sec: 54817.93
Iteration:   1760, Loss function: 3.879, Average Loss: 4.484, avg. samples / sec: 54791.56
Iteration:   1760, Loss function: 4.591, Average Loss: 4.508, avg. samples / sec: 54808.01
Iteration:   1760, Loss function: 4.627, Average Loss: 4.504, avg. samples / sec: 55052.93
Iteration:   1760, Loss function: 4.786, Average Loss: 4.535, avg. samples / sec: 54807.08
Iteration:   1760, Loss function: 3.891, Average Loss: 4.496, avg. samples / sec: 54817.97
Iteration:   1760, Loss function: 3.924, Average Loss: 4.520, avg. samples / sec: 54798.96
Iteration:   1760, Loss function: 4.606, Average Loss: 4.540, avg. samples / sec: 54829.98
Iteration:   1760, Loss function: 4.124, Average Loss: 4.520, avg. samples / sec: 54732.58
Iteration:   1760, Loss function: 5.368, Average Loss: 4.510, avg. samples / sec: 54884.90
Iteration:   1760, Loss function: 5.347, Average Loss: 4.525, avg. samples / sec: 54701.16
Iteration:   1760, Loss function: 4.064, Average Loss: 4.518, avg. samples / sec: 54792.93
Iteration:   1760, Loss function: 3.664, Average Loss: 4.515, avg. samples / sec: 54857.04
Iteration:   1760, Loss function: 5.164, Average Loss: 4.501, avg. samples / sec: 54769.65
Iteration:   1760, Loss function: 3.313, Average Loss: 4.509, avg. samples / sec: 54820.21
Iteration:   1760, Loss function: 4.825, Average Loss: 4.508, avg. samples / sec: 54816.88
Iteration:   1760, Loss function: 4.846, Average Loss: 4.528, avg. samples / sec: 54799.55
Iteration:   1760, Loss function: 3.954, Average Loss: 4.531, avg. samples / sec: 54809.21
Iteration:   1760, Loss function: 4.458, Average Loss: 4.509, avg. samples / sec: 54696.27
Iteration:   1760, Loss function: 4.424, Average Loss: 4.510, avg. samples / sec: 54812.58
Iteration:   1760, Loss function: 4.295, Average Loss: 4.536, avg. samples / sec: 54977.74
Iteration:   1760, Loss function: 4.875, Average Loss: 4.511, avg. samples / sec: 54753.18
Iteration:   1760, Loss function: 4.368, Average Loss: 4.548, avg. samples / sec: 54754.71
Iteration:   1760, Loss function: 4.897, Average Loss: 4.499, avg. samples / sec: 54762.46
Iteration:   1780, Loss function: 3.455, Average Loss: 4.513, avg. samples / sec: 55631.19
Iteration:   1780, Loss function: 4.556, Average Loss: 4.523, avg. samples / sec: 55143.92
Iteration:   1780, Loss function: 4.279, Average Loss: 4.495, avg. samples / sec: 55174.12
Iteration:   1780, Loss function: 4.946, Average Loss: 4.505, avg. samples / sec: 55224.50
Iteration:   1780, Loss function: 3.499, Average Loss: 4.519, avg. samples / sec: 55216.17
Iteration:   1780, Loss function: 3.646, Average Loss: 4.504, avg. samples / sec: 55179.09
Iteration:   1780, Loss function: 5.029, Average Loss: 4.497, avg. samples / sec: 55196.62
Iteration:   1780, Loss function: 3.764, Average Loss: 4.523, avg. samples / sec: 55151.80
Iteration:   1780, Loss function: 4.856, Average Loss: 4.498, avg. samples / sec: 55170.54
Iteration:   1780, Loss function: 5.659, Average Loss: 4.533, avg. samples / sec: 55187.17
Iteration:   1780, Loss function: 4.187, Average Loss: 4.541, avg. samples / sec: 55202.87
Iteration:   1780, Loss function: 3.699, Average Loss: 4.503, avg. samples / sec: 55101.64
Iteration:   1780, Loss function: 4.681, Average Loss: 4.519, avg. samples / sec: 55204.21
Iteration:   1780, Loss function: 3.973, Average Loss: 4.523, avg. samples / sec: 55266.93
Iteration:   1780, Loss function: 3.582, Average Loss: 4.499, avg. samples / sec: 55022.81
Iteration:   1780, Loss function: 4.331, Average Loss: 4.499, avg. samples / sec: 55175.10
Iteration:   1780, Loss function: 5.020, Average Loss: 4.529, avg. samples / sec: 55189.79
Iteration:   1780, Loss function: 4.366, Average Loss: 4.498, avg. samples / sec: 55171.57
Iteration:   1780, Loss function: 5.018, Average Loss: 4.504, avg. samples / sec: 55173.54
Iteration:   1780, Loss function: 3.957, Average Loss: 4.506, avg. samples / sec: 55187.02
Iteration:   1780, Loss function: 4.365, Average Loss: 4.503, avg. samples / sec: 55080.13
Iteration:   1780, Loss function: 4.346, Average Loss: 4.547, avg. samples / sec: 55208.04
Iteration:   1780, Loss function: 3.382, Average Loss: 4.512, avg. samples / sec: 55117.82
Iteration:   1780, Loss function: 3.763, Average Loss: 4.501, avg. samples / sec: 55219.70
Iteration:   1780, Loss function: 4.234, Average Loss: 4.531, avg. samples / sec: 55144.80
Iteration:   1780, Loss function: 3.754, Average Loss: 4.505, avg. samples / sec: 55140.30
Iteration:   1780, Loss function: 3.722, Average Loss: 4.508, avg. samples / sec: 55154.26
Iteration:   1780, Loss function: 5.592, Average Loss: 4.536, avg. samples / sec: 55146.29
Iteration:   1780, Loss function: 4.643, Average Loss: 4.485, avg. samples / sec: 54882.93
Iteration:   1780, Loss function: 2.979, Average Loss: 4.518, avg. samples / sec: 54741.40
Iteration:   1800, Loss function: 4.893, Average Loss: 4.514, avg. samples / sec: 55275.49
Iteration:   1800, Loss function: 4.266, Average Loss: 4.511, avg. samples / sec: 55115.63
Iteration:   1800, Loss function: 4.569, Average Loss: 4.518, avg. samples / sec: 55666.20
Iteration:   1800, Loss function: 4.000, Average Loss: 4.495, avg. samples / sec: 55157.99
Iteration:   1800, Loss function: 3.356, Average Loss: 4.518, avg. samples / sec: 55173.82
Iteration:   1800, Loss function: 4.120, Average Loss: 4.507, avg. samples / sec: 55213.59
Iteration:   1800, Loss function: 4.997, Average Loss: 4.498, avg. samples / sec: 55132.23
Iteration:   1800, Loss function: 3.815, Average Loss: 4.492, avg. samples / sec: 55183.43
Iteration:   1800, Loss function: 4.527, Average Loss: 4.478, avg. samples / sec: 55465.52
Iteration:   1800, Loss function: 3.997, Average Loss: 4.534, avg. samples / sec: 55164.51
Iteration:   1800, Loss function: 4.026, Average Loss: 4.514, avg. samples / sec: 55116.64
Iteration:   1800, Loss function: 4.800, Average Loss: 4.519, avg. samples / sec: 55150.37
Iteration:   1800, Loss function: 4.206, Average Loss: 4.544, avg. samples / sec: 55093.48
Iteration:   1800, Loss function: 4.558, Average Loss: 4.497, avg. samples / sec: 55337.50
Iteration:   1800, Loss function: 3.650, Average Loss: 4.502, avg. samples / sec: 55001.45
Iteration:   1800, Loss function: 4.681, Average Loss: 4.505, avg. samples / sec: 55273.28
Iteration:   1800, Loss function: 4.822, Average Loss: 4.494, avg. samples / sec: 54981.60
Iteration:   1800, Loss function: 4.201, Average Loss: 4.502, avg. samples / sec: 55223.76
Iteration:   1800, Loss function: 4.988, Average Loss: 4.502, avg. samples / sec: 55210.96
Iteration:   1800, Loss function: 4.060, Average Loss: 4.513, avg. samples / sec: 55209.72
Iteration:   1800, Loss function: 3.502, Average Loss: 4.524, avg. samples / sec: 55214.16
Iteration:   1800, Loss function: 4.549, Average Loss: 4.496, avg. samples / sec: 55158.62
Iteration:   1800, Loss function: 3.710, Average Loss: 4.549, avg. samples / sec: 55200.25
Iteration:   1800, Loss function: 4.245, Average Loss: 4.504, avg. samples / sec: 55228.48
Iteration:   1800, Loss function: 3.974, Average Loss: 4.537, avg. samples / sec: 55221.25
Iteration:   1800, Loss function: 4.675, Average Loss: 4.501, avg. samples / sec: 55103.75
Iteration:   1800, Loss function: 4.726, Average Loss: 4.526, avg. samples / sec: 55148.93
Iteration:   1800, Loss function: 3.694, Average Loss: 4.498, avg. samples / sec: 55149.77
Iteration:   1800, Loss function: 3.909, Average Loss: 4.527, avg. samples / sec: 55012.96
Iteration:   1800, Loss function: 3.539, Average Loss: 4.503, avg. samples / sec: 55145.52
:::MLL 1558640622.650 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558640622.650 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 4.067, Average Loss: 4.495, avg. samples / sec: 55272.69
Iteration:   1820, Loss function: 4.628, Average Loss: 4.514, avg. samples / sec: 55015.21
Iteration:   1820, Loss function: 4.758, Average Loss: 4.511, avg. samples / sec: 55000.74
Iteration:   1820, Loss function: 4.212, Average Loss: 4.511, avg. samples / sec: 55091.82
Iteration:   1820, Loss function: 3.808, Average Loss: 4.507, avg. samples / sec: 55128.48
Iteration:   1820, Loss function: 3.856, Average Loss: 4.493, avg. samples / sec: 55085.23
Iteration:   1820, Loss function: 6.013, Average Loss: 4.493, avg. samples / sec: 55102.80
Iteration:   1820, Loss function: 4.702, Average Loss: 4.513, avg. samples / sec: 55148.02
Iteration:   1820, Loss function: 3.945, Average Loss: 4.541, avg. samples / sec: 55173.06
Iteration:   1820, Loss function: 4.155, Average Loss: 4.520, avg. samples / sec: 55117.80
Iteration:   1820, Loss function: 4.927, Average Loss: 4.503, avg. samples / sec: 55195.43
Iteration:   1820, Loss function: 4.552, Average Loss: 4.507, avg. samples / sec: 54989.94
Iteration:   1820, Loss function: 4.407, Average Loss: 4.530, avg. samples / sec: 54990.12
Iteration:   1820, Loss function: 5.156, Average Loss: 4.504, avg. samples / sec: 55148.49
Iteration:   1820, Loss function: 3.983, Average Loss: 4.492, avg. samples / sec: 55145.75
Iteration:   1820, Loss function: 4.521, Average Loss: 4.479, avg. samples / sec: 54970.45
Iteration:   1820, Loss function: 4.536, Average Loss: 4.519, avg. samples / sec: 55185.27
Iteration:   1820, Loss function: 2.800, Average Loss: 4.499, avg. samples / sec: 55156.18
Iteration:   1820, Loss function: 4.806, Average Loss: 4.499, avg. samples / sec: 55093.88
Iteration:   1820, Loss function: 6.187, Average Loss: 4.503, avg. samples / sec: 55109.14
Iteration:   1820, Loss function: 3.846, Average Loss: 4.516, avg. samples / sec: 55135.79
Iteration:   1820, Loss function: 4.238, Average Loss: 4.501, avg. samples / sec: 55137.62
Iteration:   1820, Loss function: 5.126, Average Loss: 4.528, avg. samples / sec: 55045.94
Iteration:   1820, Loss function: 4.691, Average Loss: 4.493, avg. samples / sec: 55009.09
Iteration:   1820, Loss function: 4.361, Average Loss: 4.494, avg. samples / sec: 55019.38
Iteration:   1820, Loss function: 3.962, Average Loss: 4.509, avg. samples / sec: 54984.28
Iteration:   1820, Loss function: 3.986, Average Loss: 4.506, avg. samples / sec: 55012.33
Iteration:   1820, Loss function: 4.597, Average Loss: 4.532, avg. samples / sec: 54993.12
Iteration:   1820, Loss function: 3.562, Average Loss: 4.550, avg. samples / sec: 54969.98
Iteration:   1820, Loss function: 5.360, Average Loss: 4.498, avg. samples / sec: 54831.19
Iteration:   1840, Loss function: 4.884, Average Loss: 4.509, avg. samples / sec: 55018.80
Iteration:   1840, Loss function: 4.452, Average Loss: 4.503, avg. samples / sec: 55172.68
Iteration:   1840, Loss function: 5.559, Average Loss: 4.531, avg. samples / sec: 55170.17
Iteration:   1840, Loss function: 4.279, Average Loss: 4.490, avg. samples / sec: 55014.03
Iteration:   1840, Loss function: 6.321, Average Loss: 4.506, avg. samples / sec: 54952.83
Iteration:   1840, Loss function: 4.897, Average Loss: 4.527, avg. samples / sec: 55236.14
Iteration:   1840, Loss function: 4.062, Average Loss: 4.502, avg. samples / sec: 55258.99
Iteration:   1840, Loss function: 4.228, Average Loss: 4.499, avg. samples / sec: 54962.17
Iteration:   1840, Loss function: 4.507, Average Loss: 4.489, avg. samples / sec: 54849.95
Iteration:   1840, Loss function: 3.012, Average Loss: 4.512, avg. samples / sec: 54685.77
Iteration:   1840, Loss function: 4.759, Average Loss: 4.493, avg. samples / sec: 54671.21
Iteration:   1840, Loss function: 5.242, Average Loss: 4.496, avg. samples / sec: 55033.67
Iteration:   1840, Loss function: 4.889, Average Loss: 4.479, avg. samples / sec: 54948.39
Iteration:   1840, Loss function: 4.405, Average Loss: 4.513, avg. samples / sec: 54842.12
Iteration:   1840, Loss function: 5.279, Average Loss: 4.514, avg. samples / sec: 54989.88
Iteration:   1840, Loss function: 4.642, Average Loss: 4.501, avg. samples / sec: 54923.38
Iteration:   1840, Loss function: 4.687, Average Loss: 4.507, avg. samples / sec: 55133.76
Iteration:   1840, Loss function: 3.726, Average Loss: 4.489, avg. samples / sec: 55099.40
Iteration:   1840, Loss function: 4.699, Average Loss: 4.490, avg. samples / sec: 54907.27
Iteration:   1840, Loss function: 4.173, Average Loss: 4.498, avg. samples / sec: 54957.82
Iteration:   1840, Loss function: 3.524, Average Loss: 4.504, avg. samples / sec: 54927.83
Iteration:   1840, Loss function: 3.768, Average Loss: 4.528, avg. samples / sec: 55095.78
Iteration:   1840, Loss function: 5.673, Average Loss: 4.490, avg. samples / sec: 55077.82
Iteration:   1840, Loss function: 4.885, Average Loss: 4.496, avg. samples / sec: 55106.16
Iteration:   1840, Loss function: 3.720, Average Loss: 4.542, avg. samples / sec: 55084.17
Iteration:   1840, Loss function: 4.280, Average Loss: 4.514, avg. samples / sec: 54670.07
Iteration:   1840, Loss function: 5.104, Average Loss: 4.539, avg. samples / sec: 54725.52
Iteration:   1840, Loss function: 4.959, Average Loss: 4.516, avg. samples / sec: 54825.95
Iteration:   1840, Loss function: 3.860, Average Loss: 4.502, avg. samples / sec: 54816.33
Iteration:   1840, Loss function: 5.186, Average Loss: 4.510, avg. samples / sec: 54420.26
Iteration:   1860, Loss function: 3.600, Average Loss: 4.509, avg. samples / sec: 55361.93
Iteration:   1860, Loss function: 3.496, Average Loss: 4.507, avg. samples / sec: 55621.20
Iteration:   1860, Loss function: 4.838, Average Loss: 4.512, avg. samples / sec: 55712.70
Iteration:   1860, Loss function: 4.345, Average Loss: 4.510, avg. samples / sec: 55572.62
Iteration:   1860, Loss function: 4.250, Average Loss: 4.484, avg. samples / sec: 55408.21
Iteration:   1860, Loss function: 5.852, Average Loss: 4.491, avg. samples / sec: 55482.88
Iteration:   1860, Loss function: 3.002, Average Loss: 4.501, avg. samples / sec: 55245.33
Iteration:   1860, Loss function: 4.189, Average Loss: 4.493, avg. samples / sec: 55403.11
Iteration:   1860, Loss function: 4.930, Average Loss: 4.503, avg. samples / sec: 55847.77
Iteration:   1860, Loss function: 5.724, Average Loss: 4.488, avg. samples / sec: 55201.05
Iteration:   1860, Loss function: 4.227, Average Loss: 4.491, avg. samples / sec: 55389.87
Iteration:   1860, Loss function: 5.135, Average Loss: 4.504, avg. samples / sec: 55422.79
Iteration:   1860, Loss function: 5.125, Average Loss: 4.474, avg. samples / sec: 55395.88
Iteration:   1860, Loss function: 4.889, Average Loss: 4.493, avg. samples / sec: 55310.20
Iteration:   1860, Loss function: 4.997, Average Loss: 4.529, avg. samples / sec: 55144.96
Iteration:   1860, Loss function: 6.684, Average Loss: 4.500, avg. samples / sec: 55090.91
Iteration:   1860, Loss function: 4.383, Average Loss: 4.537, avg. samples / sec: 55444.26
Iteration:   1860, Loss function: 4.656, Average Loss: 4.487, avg. samples / sec: 55261.57
Iteration:   1860, Loss function: 4.288, Average Loss: 4.524, avg. samples / sec: 55108.21
Iteration:   1860, Loss function: 3.449, Average Loss: 4.512, avg. samples / sec: 55223.16
Iteration:   1860, Loss function: 3.057, Average Loss: 4.494, avg. samples / sec: 55252.69
Iteration:   1860, Loss function: 4.239, Average Loss: 4.500, avg. samples / sec: 55097.16
Iteration:   1860, Loss function: 4.213, Average Loss: 4.525, avg. samples / sec: 55256.91
Iteration:   1860, Loss function: 4.458, Average Loss: 4.502, avg. samples / sec: 55387.89
Iteration:   1860, Loss function: 4.373, Average Loss: 4.536, avg. samples / sec: 55283.36
Iteration:   1860, Loss function: 4.336, Average Loss: 4.501, avg. samples / sec: 55241.08
Iteration:   1860, Loss function: 4.160, Average Loss: 4.503, avg. samples / sec: 55202.61
Iteration:   1860, Loss function: 3.236, Average Loss: 4.492, avg. samples / sec: 55248.29
Iteration:   1860, Loss function: 3.824, Average Loss: 4.501, avg. samples / sec: 55201.94
Iteration:   1860, Loss function: 4.463, Average Loss: 4.498, avg. samples / sec: 55252.41
Iteration:   1880, Loss function: 4.289, Average Loss: 4.503, avg. samples / sec: 54028.24
Iteration:   1880, Loss function: 4.400, Average Loss: 4.509, avg. samples / sec: 53967.76
Iteration:   1880, Loss function: 4.296, Average Loss: 4.498, avg. samples / sec: 54216.07
Iteration:   1880, Loss function: 4.404, Average Loss: 4.506, avg. samples / sec: 54092.44
Iteration:   1880, Loss function: 3.310, Average Loss: 4.496, avg. samples / sec: 54123.75
Iteration:   1880, Loss function: 3.508, Average Loss: 4.526, avg. samples / sec: 54146.92
Iteration:   1880, Loss function: 4.502, Average Loss: 4.480, avg. samples / sec: 54046.68
Iteration:   1880, Loss function: 3.733, Average Loss: 4.467, avg. samples / sec: 54119.97
Iteration:   1880, Loss function: 5.358, Average Loss: 4.502, avg. samples / sec: 54076.13
Iteration:   1880, Loss function: 4.949, Average Loss: 4.497, avg. samples / sec: 54113.55
Iteration:   1880, Loss function: 4.430, Average Loss: 4.482, avg. samples / sec: 54084.37
Iteration:   1880, Loss function: 4.030, Average Loss: 4.503, avg. samples / sec: 54081.96
Iteration:   1880, Loss function: 5.587, Average Loss: 4.493, avg. samples / sec: 54307.08
Iteration:   1880, Loss function: 4.414, Average Loss: 4.497, avg. samples / sec: 54044.53
Iteration:   1880, Loss function: 4.879, Average Loss: 4.489, avg. samples / sec: 54033.03
Iteration:   1880, Loss function: 4.041, Average Loss: 4.538, avg. samples / sec: 54119.43
Iteration:   1880, Loss function: 4.891, Average Loss: 4.486, avg. samples / sec: 54102.68
Iteration:   1880, Loss function: 4.060, Average Loss: 4.485, avg. samples / sec: 53924.85
Iteration:   1880, Loss function: 4.674, Average Loss: 4.522, avg. samples / sec: 54108.08
Iteration:   1880, Loss function: 5.055, Average Loss: 4.511, avg. samples / sec: 53780.00
Iteration:   1880, Loss function: 3.940, Average Loss: 4.499, avg. samples / sec: 54126.83
Iteration:   1880, Loss function: 3.792, Average Loss: 4.497, avg. samples / sec: 54128.26
Iteration:   1880, Loss function: 5.604, Average Loss: 4.535, avg. samples / sec: 54109.72
Iteration:   1880, Loss function: 3.955, Average Loss: 4.503, avg. samples / sec: 54120.95
Iteration:   1880, Loss function: 3.241, Average Loss: 4.487, avg. samples / sec: 54096.47
Iteration:   1880, Loss function: 4.643, Average Loss: 4.488, avg. samples / sec: 54109.64
Iteration:   1880, Loss function: 3.517, Average Loss: 4.504, avg. samples / sec: 54085.24
Iteration:   1880, Loss function: 4.534, Average Loss: 4.518, avg. samples / sec: 54079.04
Iteration:   1880, Loss function: 4.510, Average Loss: 4.497, avg. samples / sec: 54065.57
Iteration:   1880, Loss function: 4.349, Average Loss: 4.497, avg. samples / sec: 54078.23
:::MLL 1558640624.799 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558640624.800 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 4.930, Average Loss: 4.504, avg. samples / sec: 54453.44
Iteration:   1900, Loss function: 4.007, Average Loss: 4.505, avg. samples / sec: 54467.54
Iteration:   1900, Loss function: 4.573, Average Loss: 4.521, avg. samples / sec: 54447.24
Iteration:   1900, Loss function: 5.149, Average Loss: 4.491, avg. samples / sec: 54402.49
Iteration:   1900, Loss function: 2.987, Average Loss: 4.500, avg. samples / sec: 54391.91
Iteration:   1900, Loss function: 5.246, Average Loss: 4.500, avg. samples / sec: 54439.50
Iteration:   1900, Loss function: 4.740, Average Loss: 4.507, avg. samples / sec: 54621.40
Iteration:   1900, Loss function: 4.651, Average Loss: 4.494, avg. samples / sec: 54456.52
Iteration:   1900, Loss function: 4.783, Average Loss: 4.482, avg. samples / sec: 54469.59
Iteration:   1900, Loss function: 3.982, Average Loss: 4.464, avg. samples / sec: 54409.17
Iteration:   1900, Loss function: 3.795, Average Loss: 4.477, avg. samples / sec: 54402.32
Iteration:   1900, Loss function: 4.061, Average Loss: 4.488, avg. samples / sec: 54409.69
Iteration:   1900, Loss function: 3.338, Average Loss: 4.480, avg. samples / sec: 54406.88
Iteration:   1900, Loss function: 4.070, Average Loss: 4.500, avg. samples / sec: 54384.18
Iteration:   1900, Loss function: 4.045, Average Loss: 4.489, avg. samples / sec: 54308.15
Iteration:   1900, Loss function: 4.605, Average Loss: 4.518, avg. samples / sec: 54524.57
Iteration:   1900, Loss function: 3.734, Average Loss: 4.531, avg. samples / sec: 54399.80
Iteration:   1900, Loss function: 3.863, Average Loss: 4.480, avg. samples / sec: 54460.30
Iteration:   1900, Loss function: 4.441, Average Loss: 4.478, avg. samples / sec: 54427.34
Iteration:   1900, Loss function: 3.500, Average Loss: 4.498, avg. samples / sec: 54418.62
Iteration:   1900, Loss function: 3.812, Average Loss: 4.475, avg. samples / sec: 54389.16
Iteration:   1900, Loss function: 4.119, Average Loss: 4.491, avg. samples / sec: 54396.17
Iteration:   1900, Loss function: 3.700, Average Loss: 4.481, avg. samples / sec: 54420.35
Iteration:   1900, Loss function: 3.267, Average Loss: 4.515, avg. samples / sec: 54439.77
Iteration:   1900, Loss function: 4.797, Average Loss: 4.493, avg. samples / sec: 54448.60
Iteration:   1900, Loss function: 4.091, Average Loss: 4.498, avg. samples / sec: 54414.15
Iteration:   1900, Loss function: 2.779, Average Loss: 4.490, avg. samples / sec: 54392.60
Iteration:   1900, Loss function: 3.378, Average Loss: 4.491, avg. samples / sec: 54438.91
Iteration:   1900, Loss function: 3.210, Average Loss: 4.493, avg. samples / sec: 54204.98
Iteration:   1900, Loss function: 5.191, Average Loss: 4.526, avg. samples / sec: 54351.44
Iteration:   1920, Loss function: 6.117, Average Loss: 4.502, avg. samples / sec: 54671.34
Iteration:   1920, Loss function: 4.954, Average Loss: 4.499, avg. samples / sec: 54648.83
Iteration:   1920, Loss function: 4.325, Average Loss: 4.490, avg. samples / sec: 54694.87
Iteration:   1920, Loss function: 4.451, Average Loss: 4.486, avg. samples / sec: 54760.91
Iteration:   1920, Loss function: 5.208, Average Loss: 4.493, avg. samples / sec: 54688.63
Iteration:   1920, Loss function: 3.903, Average Loss: 4.473, avg. samples / sec: 54720.38
Iteration:   1920, Loss function: 5.041, Average Loss: 4.525, avg. samples / sec: 54770.04
Iteration:   1920, Loss function: 3.704, Average Loss: 4.517, avg. samples / sec: 54635.52
Iteration:   1920, Loss function: 3.270, Average Loss: 4.472, avg. samples / sec: 54684.58
Iteration:   1920, Loss function: 4.244, Average Loss: 4.496, avg. samples / sec: 54641.77
Iteration:   1920, Loss function: 6.046, Average Loss: 4.484, avg. samples / sec: 54674.95
Iteration:   1920, Loss function: 4.006, Average Loss: 4.477, avg. samples / sec: 54641.24
Iteration:   1920, Loss function: 3.826, Average Loss: 4.496, avg. samples / sec: 54658.98
Iteration:   1920, Loss function: 4.512, Average Loss: 4.490, avg. samples / sec: 54811.38
Iteration:   1920, Loss function: 4.154, Average Loss: 4.475, avg. samples / sec: 54659.93
Iteration:   1920, Loss function: 3.655, Average Loss: 4.487, avg. samples / sec: 54688.53
Iteration:   1920, Loss function: 4.093, Average Loss: 4.507, avg. samples / sec: 54445.68
Iteration:   1920, Loss function: 3.742, Average Loss: 4.480, avg. samples / sec: 54671.05
Iteration:   1920, Loss function: 4.826, Average Loss: 4.484, avg. samples / sec: 54669.94
Iteration:   1920, Loss function: 6.161, Average Loss: 4.489, avg. samples / sec: 54678.02
Iteration:   1920, Loss function: 3.350, Average Loss: 4.513, avg. samples / sec: 54531.15
Iteration:   1920, Loss function: 3.813, Average Loss: 4.497, avg. samples / sec: 54644.91
Iteration:   1920, Loss function: 5.430, Average Loss: 4.497, avg. samples / sec: 54612.87
Iteration:   1920, Loss function: 3.818, Average Loss: 4.512, avg. samples / sec: 54619.45
Iteration:   1920, Loss function: 3.596, Average Loss: 4.472, avg. samples / sec: 54566.05
Iteration:   1920, Loss function: 4.625, Average Loss: 4.467, avg. samples / sec: 54601.99
Iteration:   1920, Loss function: 3.806, Average Loss: 4.494, avg. samples / sec: 54338.83
Iteration:   1920, Loss function: 4.336, Average Loss: 4.460, avg. samples / sec: 54372.98
Iteration:   1920, Loss function: 3.789, Average Loss: 4.521, avg. samples / sec: 54630.74
Iteration:   1920, Loss function: 3.246, Average Loss: 4.489, avg. samples / sec: 54603.92
Iteration:   1940, Loss function: 4.659, Average Loss: 4.495, avg. samples / sec: 54910.26
Iteration:   1940, Loss function: 4.260, Average Loss: 4.502, avg. samples / sec: 54754.12
Iteration:   1940, Loss function: 4.422, Average Loss: 4.482, avg. samples / sec: 54806.74
Iteration:   1940, Loss function: 4.786, Average Loss: 4.470, avg. samples / sec: 54855.35
Iteration:   1940, Loss function: 3.895, Average Loss: 4.486, avg. samples / sec: 55139.65
Iteration:   1940, Loss function: 3.983, Average Loss: 4.477, avg. samples / sec: 54789.84
Iteration:   1940, Loss function: 3.775, Average Loss: 4.513, avg. samples / sec: 54803.96
Iteration:   1940, Loss function: 4.567, Average Loss: 4.469, avg. samples / sec: 54802.54
Iteration:   1940, Loss function: 3.697, Average Loss: 4.493, avg. samples / sec: 54818.35
Iteration:   1940, Loss function: 3.825, Average Loss: 4.475, avg. samples / sec: 54820.89
Iteration:   1940, Loss function: 4.953, Average Loss: 4.463, avg. samples / sec: 55102.67
Iteration:   1940, Loss function: 3.513, Average Loss: 4.490, avg. samples / sec: 54855.78
Iteration:   1940, Loss function: 4.404, Average Loss: 4.487, avg. samples / sec: 54749.46
Iteration:   1940, Loss function: 5.381, Average Loss: 4.482, avg. samples / sec: 54780.02
Iteration:   1940, Loss function: 3.877, Average Loss: 4.463, avg. samples / sec: 55023.09
Iteration:   1940, Loss function: 3.350, Average Loss: 4.522, avg. samples / sec: 54710.44
Iteration:   1940, Loss function: 3.946, Average Loss: 4.473, avg. samples / sec: 54807.35
Iteration:   1940, Loss function: 3.876, Average Loss: 4.507, avg. samples / sec: 54847.03
Iteration:   1940, Loss function: 4.597, Average Loss: 4.505, avg. samples / sec: 54827.67
Iteration:   1940, Loss function: 4.108, Average Loss: 4.489, avg. samples / sec: 54852.15
Iteration:   1940, Loss function: 4.037, Average Loss: 4.479, avg. samples / sec: 54813.94
Iteration:   1940, Loss function: 4.299, Average Loss: 4.479, avg. samples / sec: 54805.01
Iteration:   1940, Loss function: 4.597, Average Loss: 4.509, avg. samples / sec: 54845.73
Iteration:   1940, Loss function: 3.717, Average Loss: 4.488, avg. samples / sec: 54799.57
Iteration:   1940, Loss function: 3.479, Average Loss: 4.495, avg. samples / sec: 54827.40
Iteration:   1940, Loss function: 4.695, Average Loss: 4.491, avg. samples / sec: 54634.93
Iteration:   1940, Loss function: 5.555, Average Loss: 4.492, avg. samples / sec: 54872.68
Iteration:   1940, Loss function: 5.248, Average Loss: 4.521, avg. samples / sec: 54867.46
Iteration:   1940, Loss function: 5.580, Average Loss: 4.469, avg. samples / sec: 54823.19
Iteration:   1940, Loss function: 4.441, Average Loss: 4.481, avg. samples / sec: 54759.31
:::MLL 1558640626.950 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558640626.950 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 3.607, Average Loss: 4.490, avg. samples / sec: 54621.19
Iteration:   1960, Loss function: 4.431, Average Loss: 4.484, avg. samples / sec: 54794.59
Iteration:   1960, Loss function: 4.390, Average Loss: 4.494, avg. samples / sec: 54614.67
Iteration:   1960, Loss function: 4.672, Average Loss: 4.474, avg. samples / sec: 54726.46
Iteration:   1960, Loss function: 4.508, Average Loss: 4.471, avg. samples / sec: 54744.61
Iteration:   1960, Loss function: 4.854, Average Loss: 4.466, avg. samples / sec: 54732.22
Iteration:   1960, Loss function: 3.920, Average Loss: 4.483, avg. samples / sec: 54738.08
Iteration:   1960, Loss function: 3.217, Average Loss: 4.513, avg. samples / sec: 54784.62
Iteration:   1960, Loss function: 4.838, Average Loss: 4.479, avg. samples / sec: 54697.36
Iteration:   1960, Loss function: 3.973, Average Loss: 4.477, avg. samples / sec: 54603.49
Iteration:   1960, Loss function: 3.759, Average Loss: 4.456, avg. samples / sec: 54646.81
Iteration:   1960, Loss function: 4.831, Average Loss: 4.487, avg. samples / sec: 54649.76
Iteration:   1960, Loss function: 3.405, Average Loss: 4.473, avg. samples / sec: 54657.31
Iteration:   1960, Loss function: 4.484, Average Loss: 4.467, avg. samples / sec: 54617.93
Iteration:   1960, Loss function: 4.698, Average Loss: 4.508, avg. samples / sec: 54595.14
Iteration:   1960, Loss function: 3.964, Average Loss: 4.485, avg. samples / sec: 54814.11
Iteration:   1960, Loss function: 4.504, Average Loss: 4.480, avg. samples / sec: 54798.79
Iteration:   1960, Loss function: 4.843, Average Loss: 4.502, avg. samples / sec: 54734.68
Iteration:   1960, Loss function: 4.082, Average Loss: 4.474, avg. samples / sec: 54802.17
Iteration:   1960, Loss function: 4.584, Average Loss: 4.457, avg. samples / sec: 54588.16
Iteration:   1960, Loss function: 4.286, Average Loss: 4.463, avg. samples / sec: 54749.86
Iteration:   1960, Loss function: 3.648, Average Loss: 4.502, avg. samples / sec: 54643.95
Iteration:   1960, Loss function: 3.444, Average Loss: 4.481, avg. samples / sec: 54698.35
Iteration:   1960, Loss function: 4.586, Average Loss: 4.470, avg. samples / sec: 54581.35
Iteration:   1960, Loss function: 5.258, Average Loss: 4.485, avg. samples / sec: 54637.20
Iteration:   1960, Loss function: 3.830, Average Loss: 4.475, avg. samples / sec: 54584.82
Iteration:   1960, Loss function: 4.350, Average Loss: 4.493, avg. samples / sec: 54609.61
Iteration:   1960, Loss function: 3.995, Average Loss: 4.518, avg. samples / sec: 54601.40
Iteration:   1960, Loss function: 5.023, Average Loss: 4.493, avg. samples / sec: 54594.14
Iteration:   1960, Loss function: 5.365, Average Loss: 4.504, avg. samples / sec: 54553.21
Iteration:   1980, Loss function: 3.184, Average Loss: 4.487, avg. samples / sec: 54954.95
Iteration:   1980, Loss function: 4.576, Average Loss: 4.485, avg. samples / sec: 54799.85
Iteration:   1980, Loss function: 3.911, Average Loss: 4.469, avg. samples / sec: 54733.85
Iteration:   1980, Loss function: 4.968, Average Loss: 4.480, avg. samples / sec: 54845.62
Iteration:   1980, Loss function: 5.446, Average Loss: 4.463, avg. samples / sec: 54721.53
Iteration:   1980, Loss function: 4.666, Average Loss: 4.483, avg. samples / sec: 54650.08
Iteration:   1980, Loss function: 5.024, Average Loss: 4.467, avg. samples / sec: 54844.04
Iteration:   1980, Loss function: 4.632, Average Loss: 4.509, avg. samples / sec: 54746.50
Iteration:   1980, Loss function: 2.836, Average Loss: 4.466, avg. samples / sec: 54782.41
Iteration:   1980, Loss function: 3.824, Average Loss: 4.500, avg. samples / sec: 54844.15
Iteration:   1980, Loss function: 3.520, Average Loss: 4.463, avg. samples / sec: 54685.94
Iteration:   1980, Loss function: 3.989, Average Loss: 4.470, avg. samples / sec: 55037.90
Iteration:   1980, Loss function: 2.861, Average Loss: 4.478, avg. samples / sec: 54668.95
Iteration:   1980, Loss function: 3.686, Average Loss: 4.483, avg. samples / sec: 54764.20
Iteration:   1980, Loss function: 3.544, Average Loss: 4.481, avg. samples / sec: 54984.92
Iteration:   1980, Loss function: 4.166, Average Loss: 4.452, avg. samples / sec: 54715.96
Iteration:   1980, Loss function: 3.666, Average Loss: 4.462, avg. samples / sec: 54704.47
Iteration:   1980, Loss function: 3.954, Average Loss: 4.465, avg. samples / sec: 54907.78
Iteration:   1980, Loss function: 3.719, Average Loss: 4.498, avg. samples / sec: 54823.11
Iteration:   1980, Loss function: 5.051, Average Loss: 4.496, avg. samples / sec: 54717.98
Iteration:   1980, Loss function: 5.267, Average Loss: 4.480, avg. samples / sec: 54642.87
Iteration:   1980, Loss function: 3.585, Average Loss: 4.457, avg. samples / sec: 54726.35
Iteration:   1980, Loss function: 5.914, Average Loss: 4.473, avg. samples / sec: 54666.32
Iteration:   1980, Loss function: 2.947, Average Loss: 4.499, avg. samples / sec: 54912.14
Iteration:   1980, Loss function: 5.187, Average Loss: 4.469, avg. samples / sec: 54687.59
Iteration:   1980, Loss function: 4.409, Average Loss: 4.460, avg. samples / sec: 54742.42
Iteration:   1980, Loss function: 4.220, Average Loss: 4.478, avg. samples / sec: 54759.61
Iteration:   1980, Loss function: 2.812, Average Loss: 4.511, avg. samples / sec: 54872.44
Iteration:   1980, Loss function: 4.080, Average Loss: 4.489, avg. samples / sec: 54849.82
Iteration:   1980, Loss function: 4.370, Average Loss: 4.492, avg. samples / sec: 54833.16
Iteration:   2000, Loss function: 3.960, Average Loss: 4.479, avg. samples / sec: 54864.17
Iteration:   2000, Loss function: 4.962, Average Loss: 4.481, avg. samples / sec: 54782.32
Iteration:   2000, Loss function: 2.452, Average Loss: 4.475, avg. samples / sec: 54871.14
Iteration:   2000, Loss function: 4.964, Average Loss: 4.465, avg. samples / sec: 54892.55
Iteration:   2000, Loss function: 3.519, Average Loss: 4.443, avg. samples / sec: 54969.42
Iteration:   2000, Loss function: 3.653, Average Loss: 4.453, avg. samples / sec: 54880.60
Iteration:   2000, Loss function: 4.670, Average Loss: 4.475, avg. samples / sec: 54790.82
Iteration:   2000, Loss function: 3.672, Average Loss: 4.493, avg. samples / sec: 54845.98
Iteration:   2000, Loss function: 4.338, Average Loss: 4.452, avg. samples / sec: 54964.06
Iteration:   2000, Loss function: 5.337, Average Loss: 4.463, avg. samples / sec: 54805.78
Iteration:   2000, Loss function: 4.858, Average Loss: 4.475, avg. samples / sec: 54844.34
Iteration:   2000, Loss function: 4.211, Average Loss: 4.469, avg. samples / sec: 54727.16
Iteration:   2000, Loss function: 5.110, Average Loss: 4.502, avg. samples / sec: 54767.03
Iteration:   2000, Loss function: 4.194, Average Loss: 4.479, avg. samples / sec: 54793.59
Iteration:   2000, Loss function: 4.332, Average Loss: 4.465, avg. samples / sec: 54688.10
Iteration:   2000, Loss function: 3.905, Average Loss: 4.490, avg. samples / sec: 54859.33
Iteration:   2000, Loss function: 3.773, Average Loss: 4.452, avg. samples / sec: 54853.94
Iteration:   2000, Loss function: 4.469, Average Loss: 4.491, avg. samples / sec: 54809.27
Iteration:   2000, Loss function: 4.057, Average Loss: 4.489, avg. samples / sec: 54869.68
Iteration:   2000, Loss function: 3.813, Average Loss: 4.497, avg. samples / sec: 54850.40
Iteration:   2000, Loss function: 3.145, Average Loss: 4.473, avg. samples / sec: 54832.32
Iteration:   2000, Loss function: 4.141, Average Loss: 4.456, avg. samples / sec: 54767.80
Iteration:   2000, Loss function: 4.049, Average Loss: 4.472, avg. samples / sec: 54837.85
Iteration:   2000, Loss function: 4.270, Average Loss: 4.505, avg. samples / sec: 54837.36
Iteration:   2000, Loss function: 4.893, Average Loss: 4.464, avg. samples / sec: 54817.84
Iteration:   2000, Loss function: 3.257, Average Loss: 4.471, avg. samples / sec: 54679.08
Iteration:   2000, Loss function: 5.209, Average Loss: 4.452, avg. samples / sec: 54807.93
Iteration:   2000, Loss function: 4.724, Average Loss: 4.489, avg. samples / sec: 54856.12
Iteration:   2000, Loss function: 4.603, Average Loss: 4.462, avg. samples / sec: 54807.65
Iteration:   2000, Loss function: 2.918, Average Loss: 4.467, avg. samples / sec: 54586.66
Iteration:   2020, Loss function: 4.083, Average Loss: 4.477, avg. samples / sec: 54782.21
Iteration:   2020, Loss function: 4.861, Average Loss: 4.477, avg. samples / sec: 54614.96
Iteration:   2020, Loss function: 3.558, Average Loss: 4.469, avg. samples / sec: 54885.65
Iteration:   2020, Loss function: 6.254, Average Loss: 4.441, avg. samples / sec: 54800.96
Iteration:   2020, Loss function: 5.008, Average Loss: 4.467, avg. samples / sec: 54839.73
Iteration:   2020, Loss function: 3.941, Average Loss: 4.457, avg. samples / sec: 54800.79
Iteration:   2020, Loss function: 4.916, Average Loss: 4.448, avg. samples / sec: 54759.01
Iteration:   2020, Loss function: 3.093, Average Loss: 4.477, avg. samples / sec: 54883.72
Iteration:   2020, Loss function: 4.486, Average Loss: 4.466, avg. samples / sec: 54770.35
Iteration:   2020, Loss function: 5.604, Average Loss: 4.491, avg. samples / sec: 54753.46
Iteration:   2020, Loss function: 4.487, Average Loss: 4.467, avg. samples / sec: 54704.32
Iteration:   2020, Loss function: 4.265, Average Loss: 4.496, avg. samples / sec: 54796.89
Iteration:   2020, Loss function: 4.607, Average Loss: 4.464, avg. samples / sec: 54849.76
Iteration:   2020, Loss function: 4.575, Average Loss: 4.450, avg. samples / sec: 54696.80
Iteration:   2020, Loss function: 4.778, Average Loss: 4.476, avg. samples / sec: 54625.72
Iteration:   2020, Loss function: 3.838, Average Loss: 4.482, avg. samples / sec: 54842.27
Iteration:   2020, Loss function: 4.576, Average Loss: 4.453, avg. samples / sec: 54778.42
Iteration:   2020, Loss function: 4.500, Average Loss: 4.487, avg. samples / sec: 54786.84
Iteration:   2020, Loss function: 5.635, Average Loss: 4.493, avg. samples / sec: 54788.43
Iteration:   2020, Loss function: 4.913, Average Loss: 4.488, avg. samples / sec: 54770.91
Iteration:   2020, Loss function: 4.614, Average Loss: 4.457, avg. samples / sec: 54865.90
Iteration:   2020, Loss function: 5.044, Average Loss: 4.452, avg. samples / sec: 54774.14
Iteration:   2020, Loss function: 3.492, Average Loss: 4.462, avg. samples / sec: 54778.30
Iteration:   2020, Loss function: 3.327, Average Loss: 4.501, avg. samples / sec: 54773.34
Iteration:   2020, Loss function: 3.099, Average Loss: 4.466, avg. samples / sec: 54781.87
Iteration:   2020, Loss function: 3.953, Average Loss: 4.467, avg. samples / sec: 54751.03
Iteration:   2020, Loss function: 3.028, Average Loss: 4.460, avg. samples / sec: 54766.16
Iteration:   2020, Loss function: 6.198, Average Loss: 4.464, avg. samples / sec: 54793.69
Iteration:   2020, Loss function: 4.774, Average Loss: 4.484, avg. samples / sec: 54790.61
Iteration:   2020, Loss function: 5.544, Average Loss: 4.451, avg. samples / sec: 54779.49
:::MLL 1558640629.100 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558640629.100 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 3.131, Average Loss: 4.475, avg. samples / sec: 54101.50
Iteration:   2040, Loss function: 4.028, Average Loss: 4.460, avg. samples / sec: 54537.27
Iteration:   2040, Loss function: 3.483, Average Loss: 4.470, avg. samples / sec: 54117.27
Iteration:   2040, Loss function: 4.788, Average Loss: 4.463, avg. samples / sec: 54060.32
Iteration:   2040, Loss function: 4.571, Average Loss: 4.440, avg. samples / sec: 54070.18
Iteration:   2040, Loss function: 5.079, Average Loss: 4.464, avg. samples / sec: 54112.30
Iteration:   2040, Loss function: 4.497, Average Loss: 4.454, avg. samples / sec: 54091.26
Iteration:   2040, Loss function: 4.179, Average Loss: 4.485, avg. samples / sec: 54122.82
Iteration:   2040, Loss function: 4.781, Average Loss: 4.463, avg. samples / sec: 54081.51
Iteration:   2040, Loss function: 4.203, Average Loss: 4.462, avg. samples / sec: 54123.50
Iteration:   2040, Loss function: 4.854, Average Loss: 4.474, avg. samples / sec: 54193.95
Iteration:   2040, Loss function: 4.596, Average Loss: 4.461, avg. samples / sec: 54170.39
Iteration:   2040, Loss function: 3.984, Average Loss: 4.445, avg. samples / sec: 54147.89
Iteration:   2040, Loss function: 4.745, Average Loss: 4.446, avg. samples / sec: 54059.25
Iteration:   2040, Loss function: 3.992, Average Loss: 4.492, avg. samples / sec: 54101.60
Iteration:   2040, Loss function: 4.199, Average Loss: 4.472, avg. samples / sec: 54027.45
Iteration:   2040, Loss function: 5.622, Average Loss: 4.452, avg. samples / sec: 54137.08
Iteration:   2040, Loss function: 4.747, Average Loss: 4.452, avg. samples / sec: 54156.32
Iteration:   2040, Loss function: 3.601, Average Loss: 4.465, avg. samples / sec: 54159.28
Iteration:   2040, Loss function: 3.365, Average Loss: 4.477, avg. samples / sec: 54030.56
Iteration:   2040, Loss function: 4.708, Average Loss: 4.486, avg. samples / sec: 54110.60
Iteration:   2040, Loss function: 3.613, Average Loss: 4.453, avg. samples / sec: 54105.49
Iteration:   2040, Loss function: 4.891, Average Loss: 4.482, avg. samples / sec: 54087.71
Iteration:   2040, Loss function: 4.583, Average Loss: 4.493, avg. samples / sec: 54075.45
Iteration:   2040, Loss function: 5.030, Average Loss: 4.456, avg. samples / sec: 54105.26
Iteration:   2040, Loss function: 4.882, Average Loss: 4.458, avg. samples / sec: 54109.47
Iteration:   2040, Loss function: 3.432, Average Loss: 4.446, avg. samples / sec: 54110.04
Iteration:   2040, Loss function: 5.054, Average Loss: 4.465, avg. samples / sec: 54099.98
Iteration:   2040, Loss function: 3.974, Average Loss: 4.474, avg. samples / sec: 54081.15
Iteration:   2040, Loss function: 5.573, Average Loss: 4.500, avg. samples / sec: 54060.16
Iteration:   2060, Loss function: 4.344, Average Loss: 4.468, avg. samples / sec: 54902.45
Iteration:   2060, Loss function: 4.488, Average Loss: 4.461, avg. samples / sec: 55016.93
Iteration:   2060, Loss function: 5.065, Average Loss: 4.448, avg. samples / sec: 54951.39
Iteration:   2060, Loss function: 4.586, Average Loss: 4.463, avg. samples / sec: 54940.15
Iteration:   2060, Loss function: 4.827, Average Loss: 4.477, avg. samples / sec: 54927.77
Iteration:   2060, Loss function: 4.038, Average Loss: 4.439, avg. samples / sec: 54952.33
Iteration:   2060, Loss function: 4.408, Average Loss: 4.460, avg. samples / sec: 54896.51
Iteration:   2060, Loss function: 4.865, Average Loss: 4.453, avg. samples / sec: 54904.14
Iteration:   2060, Loss function: 3.927, Average Loss: 4.455, avg. samples / sec: 54887.91
Iteration:   2060, Loss function: 3.781, Average Loss: 4.437, avg. samples / sec: 54912.77
Iteration:   2060, Loss function: 4.605, Average Loss: 4.463, avg. samples / sec: 54846.15
Iteration:   2060, Loss function: 3.910, Average Loss: 4.468, avg. samples / sec: 54917.82
Iteration:   2060, Loss function: 3.796, Average Loss: 4.485, avg. samples / sec: 54884.60
Iteration:   2060, Loss function: 5.253, Average Loss: 4.445, avg. samples / sec: 54965.71
Iteration:   2060, Loss function: 3.252, Average Loss: 4.446, avg. samples / sec: 54881.50
Iteration:   2060, Loss function: 5.555, Average Loss: 4.474, avg. samples / sec: 54895.61
Iteration:   2060, Loss function: 3.214, Average Loss: 4.459, avg. samples / sec: 54931.47
Iteration:   2060, Loss function: 3.838, Average Loss: 4.483, avg. samples / sec: 54875.54
Iteration:   2060, Loss function: 5.238, Average Loss: 4.461, avg. samples / sec: 54855.61
Iteration:   2060, Loss function: 3.409, Average Loss: 4.456, avg. samples / sec: 54467.42
Iteration:   2060, Loss function: 4.715, Average Loss: 4.451, avg. samples / sec: 54881.61
Iteration:   2060, Loss function: 3.693, Average Loss: 4.447, avg. samples / sec: 54859.20
Iteration:   2060, Loss function: 3.376, Average Loss: 4.487, avg. samples / sec: 54877.76
Iteration:   2060, Loss function: 5.088, Average Loss: 4.446, avg. samples / sec: 54889.32
Iteration:   2060, Loss function: 3.371, Average Loss: 4.473, avg. samples / sec: 54860.39
Iteration:   2060, Loss function: 3.880, Average Loss: 4.493, avg. samples / sec: 54918.35
Iteration:   2060, Loss function: 3.611, Average Loss: 4.463, avg. samples / sec: 54864.11
Iteration:   2060, Loss function: 5.457, Average Loss: 4.475, avg. samples / sec: 54620.61
Iteration:   2060, Loss function: 3.576, Average Loss: 4.471, avg. samples / sec: 54884.75
Iteration:   2060, Loss function: 4.233, Average Loss: 4.435, avg. samples / sec: 54536.64
Iteration:   2080, Loss function: 4.285, Average Loss: 4.461, avg. samples / sec: 55130.59
Iteration:   2080, Loss function: 3.927, Average Loss: 4.455, avg. samples / sec: 55115.04
Iteration:   2080, Loss function: 4.059, Average Loss: 4.453, avg. samples / sec: 55266.49
Iteration:   2080, Loss function: 4.159, Average Loss: 4.439, avg. samples / sec: 55262.48
Iteration:   2080, Loss function: 5.287, Average Loss: 4.461, avg. samples / sec: 55258.97
Iteration:   2080, Loss function: 4.407, Average Loss: 4.466, avg. samples / sec: 55550.72
Iteration:   2080, Loss function: 3.882, Average Loss: 4.442, avg. samples / sec: 55190.33
Iteration:   2080, Loss function: 5.088, Average Loss: 4.436, avg. samples / sec: 55284.96
Iteration:   2080, Loss function: 5.056, Average Loss: 4.451, avg. samples / sec: 55259.54
Iteration:   2080, Loss function: 4.309, Average Loss: 4.462, avg. samples / sec: 55291.34
Iteration:   2080, Loss function: 4.892, Average Loss: 4.468, avg. samples / sec: 55307.01
Iteration:   2080, Loss function: 4.258, Average Loss: 4.475, avg. samples / sec: 55210.44
Iteration:   2080, Loss function: 4.256, Average Loss: 4.448, avg. samples / sec: 55218.87
Iteration:   2080, Loss function: 3.323, Average Loss: 4.429, avg. samples / sec: 55561.43
Iteration:   2080, Loss function: 4.222, Average Loss: 4.486, avg. samples / sec: 55225.43
Iteration:   2080, Loss function: 2.914, Average Loss: 4.450, avg. samples / sec: 55306.10
Iteration:   2080, Loss function: 5.532, Average Loss: 4.477, avg. samples / sec: 55293.47
Iteration:   2080, Loss function: 2.943, Average Loss: 4.464, avg. samples / sec: 55242.94
Iteration:   2080, Loss function: 3.942, Average Loss: 4.435, avg. samples / sec: 55128.11
Iteration:   2080, Loss function: 5.628, Average Loss: 4.442, avg. samples / sec: 55294.23
Iteration:   2080, Loss function: 5.907, Average Loss: 4.459, avg. samples / sec: 55267.23
Iteration:   2080, Loss function: 4.463, Average Loss: 4.487, avg. samples / sec: 55279.13
Iteration:   2080, Loss function: 4.173, Average Loss: 4.440, avg. samples / sec: 55207.93
Iteration:   2080, Loss function: 3.491, Average Loss: 4.467, avg. samples / sec: 55268.33
Iteration:   2080, Loss function: 4.027, Average Loss: 4.460, avg. samples / sec: 55277.72
Iteration:   2080, Loss function: 4.303, Average Loss: 4.447, avg. samples / sec: 55244.81
Iteration:   2080, Loss function: 4.320, Average Loss: 4.441, avg. samples / sec: 55239.98
Iteration:   2080, Loss function: 2.887, Average Loss: 4.470, avg. samples / sec: 55280.71
Iteration:   2080, Loss function: 3.848, Average Loss: 4.460, avg. samples / sec: 55185.10
Iteration:   2080, Loss function: 4.234, Average Loss: 4.486, avg. samples / sec: 55178.08
:::MLL 1558640631.249 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558640631.250 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 4.853, Average Loss: 4.440, avg. samples / sec: 54465.27
Iteration:   2100, Loss function: 3.896, Average Loss: 4.459, avg. samples / sec: 54451.15
Iteration:   2100, Loss function: 3.616, Average Loss: 4.454, avg. samples / sec: 54339.85
Iteration:   2100, Loss function: 5.076, Average Loss: 4.454, avg. samples / sec: 54436.85
Iteration:   2100, Loss function: 4.290, Average Loss: 4.450, avg. samples / sec: 54349.53
Iteration:   2100, Loss function: 3.379, Average Loss: 4.459, avg. samples / sec: 54401.69
Iteration:   2100, Loss function: 4.569, Average Loss: 4.476, avg. samples / sec: 54476.30
Iteration:   2100, Loss function: 3.292, Average Loss: 4.428, avg. samples / sec: 54367.88
Iteration:   2100, Loss function: 3.438, Average Loss: 4.435, avg. samples / sec: 54339.75
Iteration:   2100, Loss function: 3.767, Average Loss: 4.483, avg. samples / sec: 54561.55
Iteration:   2100, Loss function: 4.487, Average Loss: 4.462, avg. samples / sec: 54316.56
Iteration:   2100, Loss function: 4.586, Average Loss: 4.450, avg. samples / sec: 54313.80
Iteration:   2100, Loss function: 5.340, Average Loss: 4.455, avg. samples / sec: 54234.79
Iteration:   2100, Loss function: 4.229, Average Loss: 4.445, avg. samples / sec: 54316.37
Iteration:   2100, Loss function: 4.285, Average Loss: 4.470, avg. samples / sec: 54280.08
Iteration:   2100, Loss function: 3.981, Average Loss: 4.420, avg. samples / sec: 54309.87
Iteration:   2100, Loss function: 3.209, Average Loss: 4.425, avg. samples / sec: 54466.98
Iteration:   2100, Loss function: 4.506, Average Loss: 4.453, avg. samples / sec: 54484.83
Iteration:   2100, Loss function: 4.345, Average Loss: 4.455, avg. samples / sec: 54413.71
Iteration:   2100, Loss function: 4.224, Average Loss: 4.448, avg. samples / sec: 54373.25
Iteration:   2100, Loss function: 4.326, Average Loss: 4.457, avg. samples / sec: 54394.80
Iteration:   2100, Loss function: 3.337, Average Loss: 4.435, avg. samples / sec: 54370.80
Iteration:   2100, Loss function: 4.179, Average Loss: 4.441, avg. samples / sec: 54400.37
Iteration:   2100, Loss function: 3.444, Average Loss: 4.441, avg. samples / sec: 54360.08
Iteration:   2100, Loss function: 3.439, Average Loss: 4.469, avg. samples / sec: 54302.10
Iteration:   2100, Loss function: 3.970, Average Loss: 4.453, avg. samples / sec: 54351.50
Iteration:   2100, Loss function: 4.387, Average Loss: 4.438, avg. samples / sec: 54340.80
Iteration:   2100, Loss function: 3.945, Average Loss: 4.458, avg. samples / sec: 54304.13
Iteration:   2100, Loss function: 3.984, Average Loss: 4.465, avg. samples / sec: 54303.42
Iteration:   2100, Loss function: 3.943, Average Loss: 4.477, avg. samples / sec: 54370.65
Iteration:   2120, Loss function: 4.020, Average Loss: 4.445, avg. samples / sec: 55345.84
Iteration:   2120, Loss function: 5.715, Average Loss: 4.450, avg. samples / sec: 55211.50
Iteration:   2120, Loss function: 3.262, Average Loss: 4.456, avg. samples / sec: 55129.66
Iteration:   2120, Loss function: 6.110, Average Loss: 4.453, avg. samples / sec: 55244.33
Iteration:   2120, Loss function: 4.214, Average Loss: 4.454, avg. samples / sec: 55223.79
Iteration:   2120, Loss function: 5.052, Average Loss: 4.453, avg. samples / sec: 55087.29
Iteration:   2120, Loss function: 3.065, Average Loss: 4.424, avg. samples / sec: 55280.93
Iteration:   2120, Loss function: 3.728, Average Loss: 4.439, avg. samples / sec: 55225.71
Iteration:   2120, Loss function: 4.587, Average Loss: 4.461, avg. samples / sec: 55104.83
Iteration:   2120, Loss function: 4.409, Average Loss: 4.472, avg. samples / sec: 55239.85
Iteration:   2120, Loss function: 4.869, Average Loss: 4.413, avg. samples / sec: 55245.84
Iteration:   2120, Loss function: 4.021, Average Loss: 4.439, avg. samples / sec: 55029.58
Iteration:   2120, Loss function: 4.704, Average Loss: 4.445, avg. samples / sec: 55182.76
Iteration:   2120, Loss function: 4.602, Average Loss: 4.419, avg. samples / sec: 55110.91
Iteration:   2120, Loss function: 4.800, Average Loss: 4.438, avg. samples / sec: 55126.92
Iteration:   2120, Loss function: 5.091, Average Loss: 4.469, avg. samples / sec: 55042.59
Iteration:   2120, Loss function: 4.143, Average Loss: 4.438, avg. samples / sec: 55209.70
Iteration:   2120, Loss function: 5.196, Average Loss: 4.473, avg. samples / sec: 55216.58
Iteration:   2120, Loss function: 3.175, Average Loss: 4.438, avg. samples / sec: 55171.34
Iteration:   2120, Loss function: 4.260, Average Loss: 4.443, avg. samples / sec: 55124.16
Iteration:   2120, Loss function: 4.631, Average Loss: 4.453, avg. samples / sec: 55095.46
Iteration:   2120, Loss function: 4.172, Average Loss: 4.474, avg. samples / sec: 54960.46
Iteration:   2120, Loss function: 4.697, Average Loss: 4.474, avg. samples / sec: 55267.06
Iteration:   2120, Loss function: 4.311, Average Loss: 4.454, avg. samples / sec: 55233.01
Iteration:   2120, Loss function: 4.996, Average Loss: 4.446, avg. samples / sec: 55193.77
Iteration:   2120, Loss function: 4.698, Average Loss: 4.432, avg. samples / sec: 55205.51
Iteration:   2120, Loss function: 4.481, Average Loss: 4.448, avg. samples / sec: 55107.50
Iteration:   2120, Loss function: 4.829, Average Loss: 4.458, avg. samples / sec: 55247.60
Iteration:   2120, Loss function: 4.253, Average Loss: 4.431, avg. samples / sec: 55112.59
Iteration:   2120, Loss function: 4.277, Average Loss: 4.442, avg. samples / sec: 55049.34
Iteration:   2140, Loss function: 3.995, Average Loss: 4.444, avg. samples / sec: 54928.20
Iteration:   2140, Loss function: 3.064, Average Loss: 4.431, avg. samples / sec: 54723.37
Iteration:   2140, Loss function: 4.347, Average Loss: 4.452, avg. samples / sec: 54859.58
Iteration:   2140, Loss function: 4.252, Average Loss: 4.443, avg. samples / sec: 54907.44
Iteration:   2140, Loss function: 6.066, Average Loss: 4.467, avg. samples / sec: 54888.28
Iteration:   2140, Loss function: 4.268, Average Loss: 4.436, avg. samples / sec: 54882.63
Iteration:   2140, Loss function: 3.694, Average Loss: 4.429, avg. samples / sec: 54894.50
Iteration:   2140, Loss function: 4.589, Average Loss: 4.415, avg. samples / sec: 54866.61
Iteration:   2140, Loss function: 4.417, Average Loss: 4.451, avg. samples / sec: 54780.79
Iteration:   2140, Loss function: 4.346, Average Loss: 4.451, avg. samples / sec: 54831.53
Iteration:   2140, Loss function: 5.550, Average Loss: 4.458, avg. samples / sec: 54816.05
Iteration:   2140, Loss function: 3.986, Average Loss: 4.448, avg. samples / sec: 54773.21
Iteration:   2140, Loss function: 3.910, Average Loss: 4.430, avg. samples / sec: 54794.80
Iteration:   2140, Loss function: 4.586, Average Loss: 4.410, avg. samples / sec: 54806.18
Iteration:   2140, Loss function: 4.685, Average Loss: 4.463, avg. samples / sec: 54849.16
Iteration:   2140, Loss function: 3.601, Average Loss: 4.442, avg. samples / sec: 54902.60
Iteration:   2140, Loss function: 5.142, Average Loss: 4.437, avg. samples / sec: 54845.90
Iteration:   2140, Loss function: 5.096, Average Loss: 4.448, avg. samples / sec: 54891.89
Iteration:   2140, Loss function: 3.518, Average Loss: 4.469, avg. samples / sec: 54838.70
Iteration:   2140, Loss function: 3.410, Average Loss: 4.452, avg. samples / sec: 54848.59
Iteration:   2140, Loss function: 4.637, Average Loss: 4.472, avg. samples / sec: 54850.36
Iteration:   2140, Loss function: 3.816, Average Loss: 4.436, avg. samples / sec: 54839.86
Iteration:   2140, Loss function: 2.851, Average Loss: 4.464, avg. samples / sec: 54850.51
Iteration:   2140, Loss function: 5.025, Average Loss: 4.425, avg. samples / sec: 54599.54
Iteration:   2140, Loss function: 4.436, Average Loss: 4.428, avg. samples / sec: 54842.72
Iteration:   2140, Loss function: 3.659, Average Loss: 4.452, avg. samples / sec: 54819.76
Iteration:   2140, Loss function: 5.696, Average Loss: 4.451, avg. samples / sec: 54831.21
Iteration:   2140, Loss function: 5.234, Average Loss: 4.423, avg. samples / sec: 54831.24
Iteration:   2140, Loss function: 3.789, Average Loss: 4.435, avg. samples / sec: 54814.32
Iteration:   2140, Loss function: 4.977, Average Loss: 4.430, avg. samples / sec: 54761.42
Iteration:   2160, Loss function: 3.968, Average Loss: 4.425, avg. samples / sec: 55090.05
Iteration:   2160, Loss function: 3.081, Average Loss: 4.438, avg. samples / sec: 54926.95
Iteration:   2160, Loss function: 4.585, Average Loss: 4.448, avg. samples / sec: 55033.54
Iteration:   2160, Loss function: 4.373, Average Loss: 4.443, avg. samples / sec: 55053.04
Iteration:   2160, Loss function: 2.571, Average Loss: 4.402, avg. samples / sec: 55114.42
Iteration:   2160, Loss function: 4.868, Average Loss: 4.465, avg. samples / sec: 54998.01
Iteration:   2160, Loss function: 4.008, Average Loss: 4.452, avg. samples / sec: 55007.44
Iteration:   2160, Loss function: 3.769, Average Loss: 4.435, avg. samples / sec: 54981.23
Iteration:   2160, Loss function: 4.951, Average Loss: 4.437, avg. samples / sec: 54960.31
Iteration:   2160, Loss function: 3.459, Average Loss: 4.425, avg. samples / sec: 55057.83
Iteration:   2160, Loss function: 4.017, Average Loss: 4.416, avg. samples / sec: 54979.11
Iteration:   2160, Loss function: 4.946, Average Loss: 4.426, avg. samples / sec: 54977.57
Iteration:   2160, Loss function: 3.837, Average Loss: 4.447, avg. samples / sec: 55048.37
Iteration:   2160, Loss function: 3.156, Average Loss: 4.459, avg. samples / sec: 55068.22
Iteration:   2160, Loss function: 4.550, Average Loss: 4.458, avg. samples / sec: 55011.93
Iteration:   2160, Loss function: 4.601, Average Loss: 4.434, avg. samples / sec: 55021.98
Iteration:   2160, Loss function: 3.306, Average Loss: 4.424, avg. samples / sec: 55048.56
Iteration:   2160, Loss function: 4.729, Average Loss: 4.464, avg. samples / sec: 55009.22
Iteration:   2160, Loss function: 3.341, Average Loss: 4.422, avg. samples / sec: 55043.92
Iteration:   2160, Loss function: 3.007, Average Loss: 4.445, avg. samples / sec: 54987.84
Iteration:   2160, Loss function: 4.281, Average Loss: 4.442, avg. samples / sec: 55000.44
Iteration:   2160, Loss function: 3.982, Average Loss: 4.469, avg. samples / sec: 55007.09
Iteration:   2160, Loss function: 4.027, Average Loss: 4.454, avg. samples / sec: 55036.63
Iteration:   2160, Loss function: 4.262, Average Loss: 4.421, avg. samples / sec: 55047.40
Iteration:   2160, Loss function: 4.450, Average Loss: 4.457, avg. samples / sec: 55004.39
Iteration:   2160, Loss function: 3.864, Average Loss: 4.436, avg. samples / sec: 55068.50
Iteration:   2160, Loss function: 3.385, Average Loss: 4.440, avg. samples / sec: 54945.84
Iteration:   2160, Loss function: 4.136, Average Loss: 4.444, avg. samples / sec: 55017.70
Iteration:   2160, Loss function: 4.944, Average Loss: 4.431, avg. samples / sec: 54969.87
Iteration:   2160, Loss function: 3.839, Average Loss: 4.429, avg. samples / sec: 55004.60
:::MLL 1558640633.389 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558640633.390 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 4.198, Average Loss: 4.433, avg. samples / sec: 54907.95
Iteration:   2180, Loss function: 4.187, Average Loss: 4.461, avg. samples / sec: 54981.11
Iteration:   2180, Loss function: 3.867, Average Loss: 4.445, avg. samples / sec: 54896.57
Iteration:   2180, Loss function: 4.135, Average Loss: 4.446, avg. samples / sec: 54951.88
Iteration:   2180, Loss function: 3.343, Average Loss: 4.418, avg. samples / sec: 54973.17
Iteration:   2180, Loss function: 5.419, Average Loss: 4.421, avg. samples / sec: 54744.42
Iteration:   2180, Loss function: 3.722, Average Loss: 4.413, avg. samples / sec: 54965.88
Iteration:   2180, Loss function: 4.764, Average Loss: 4.447, avg. samples / sec: 54959.36
Iteration:   2180, Loss function: 4.123, Average Loss: 4.425, avg. samples / sec: 54939.78
Iteration:   2180, Loss function: 5.124, Average Loss: 4.454, avg. samples / sec: 54959.04
Iteration:   2180, Loss function: 3.991, Average Loss: 4.437, avg. samples / sec: 54875.30
Iteration:   2180, Loss function: 4.910, Average Loss: 4.429, avg. samples / sec: 54926.21
Iteration:   2180, Loss function: 4.899, Average Loss: 4.418, avg. samples / sec: 54931.24
Iteration:   2180, Loss function: 3.816, Average Loss: 4.393, avg. samples / sec: 54868.96
Iteration:   2180, Loss function: 3.708, Average Loss: 4.448, avg. samples / sec: 54887.89
Iteration:   2180, Loss function: 4.096, Average Loss: 4.444, avg. samples / sec: 55085.66
Iteration:   2180, Loss function: 5.297, Average Loss: 4.428, avg. samples / sec: 54956.51
Iteration:   2180, Loss function: 4.620, Average Loss: 4.450, avg. samples / sec: 54983.59
Iteration:   2180, Loss function: 3.711, Average Loss: 4.431, avg. samples / sec: 54975.46
Iteration:   2180, Loss function: 4.360, Average Loss: 4.421, avg. samples / sec: 54940.42
Iteration:   2180, Loss function: 4.361, Average Loss: 4.435, avg. samples / sec: 54976.54
Iteration:   2180, Loss function: 3.935, Average Loss: 4.443, avg. samples / sec: 54945.61
Iteration:   2180, Loss function: 3.590, Average Loss: 4.424, avg. samples / sec: 54973.90
Iteration:   2180, Loss function: 3.662, Average Loss: 4.452, avg. samples / sec: 54944.15
Iteration:   2180, Loss function: 3.668, Average Loss: 4.459, avg. samples / sec: 54928.41
Iteration:   2180, Loss function: 4.968, Average Loss: 4.460, avg. samples / sec: 54895.01
Iteration:   2180, Loss function: 3.550, Average Loss: 4.419, avg. samples / sec: 54912.36
Iteration:   2180, Loss function: 3.733, Average Loss: 4.426, avg. samples / sec: 54969.74
Iteration:   2180, Loss function: 3.255, Average Loss: 4.436, avg. samples / sec: 54889.71
Iteration:   2180, Loss function: 5.375, Average Loss: 4.415, avg. samples / sec: 54846.17
Iteration:   2200, Loss function: 3.316, Average Loss: 4.427, avg. samples / sec: 55570.45
Iteration:   2200, Loss function: 3.903, Average Loss: 4.422, avg. samples / sec: 55654.70
Iteration:   2200, Loss function: 4.073, Average Loss: 4.409, avg. samples / sec: 55454.60
Iteration:   2200, Loss function: 3.847, Average Loss: 4.435, avg. samples / sec: 55444.31
Iteration:   2200, Loss function: 3.230, Average Loss: 4.423, avg. samples / sec: 55455.80
Iteration:   2200, Loss function: 4.675, Average Loss: 4.390, avg. samples / sec: 55488.40
Iteration:   2200, Loss function: 3.396, Average Loss: 4.424, avg. samples / sec: 55455.32
Iteration:   2200, Loss function: 4.334, Average Loss: 4.444, avg. samples / sec: 55429.89
Iteration:   2200, Loss function: 4.613, Average Loss: 4.458, avg. samples / sec: 55357.67
Iteration:   2200, Loss function: 4.909, Average Loss: 4.434, avg. samples / sec: 55438.92
Iteration:   2200, Loss function: 4.948, Average Loss: 4.416, avg. samples / sec: 55405.85
Iteration:   2200, Loss function: 3.818, Average Loss: 4.444, avg. samples / sec: 55458.82
Iteration:   2200, Loss function: 3.887, Average Loss: 4.448, avg. samples / sec: 55346.91
Iteration:   2200, Loss function: 4.072, Average Loss: 4.450, avg. samples / sec: 55555.78
Iteration:   2200, Loss function: 4.041, Average Loss: 4.419, avg. samples / sec: 55438.18
Iteration:   2200, Loss function: 3.547, Average Loss: 4.421, avg. samples / sec: 55389.00
Iteration:   2200, Loss function: 3.641, Average Loss: 4.456, avg. samples / sec: 55448.71
Iteration:   2200, Loss function: 3.966, Average Loss: 4.438, avg. samples / sec: 55419.54
Iteration:   2200, Loss function: 5.036, Average Loss: 4.418, avg. samples / sec: 55420.32
Iteration:   2200, Loss function: 5.165, Average Loss: 4.433, avg. samples / sec: 55400.37
Iteration:   2200, Loss function: 4.663, Average Loss: 4.416, avg. samples / sec: 55500.95
Iteration:   2200, Loss function: 4.339, Average Loss: 4.410, avg. samples / sec: 55449.61
Iteration:   2200, Loss function: 3.492, Average Loss: 4.428, avg. samples / sec: 55487.79
Iteration:   2200, Loss function: 3.768, Average Loss: 4.437, avg. samples / sec: 55281.56
Iteration:   2200, Loss function: 4.609, Average Loss: 4.424, avg. samples / sec: 55371.98
Iteration:   2200, Loss function: 3.796, Average Loss: 4.417, avg. samples / sec: 55442.19
Iteration:   2200, Loss function: 3.537, Average Loss: 4.452, avg. samples / sec: 55382.10
Iteration:   2200, Loss function: 4.952, Average Loss: 4.444, avg. samples / sec: 55324.70
Iteration:   2200, Loss function: 4.583, Average Loss: 4.408, avg. samples / sec: 55117.26
Iteration:   2200, Loss function: 4.198, Average Loss: 4.436, avg. samples / sec: 55105.80
Iteration:   2220, Loss function: 4.721, Average Loss: 4.418, avg. samples / sec: 54558.62
Iteration:   2220, Loss function: 3.550, Average Loss: 4.424, avg. samples / sec: 54515.12
Iteration:   2220, Loss function: 5.416, Average Loss: 4.434, avg. samples / sec: 54648.78
Iteration:   2220, Loss function: 3.384, Average Loss: 4.418, avg. samples / sec: 54627.01
Iteration:   2220, Loss function: 4.169, Average Loss: 4.432, avg. samples / sec: 54585.47
Iteration:   2220, Loss function: 3.395, Average Loss: 4.429, avg. samples / sec: 54913.69
Iteration:   2220, Loss function: 3.722, Average Loss: 4.418, avg. samples / sec: 54589.87
Iteration:   2220, Loss function: 2.678, Average Loss: 4.402, avg. samples / sec: 54898.95
Iteration:   2220, Loss function: 4.766, Average Loss: 4.407, avg. samples / sec: 54555.11
Iteration:   2220, Loss function: 5.734, Average Loss: 4.417, avg. samples / sec: 54609.97
Iteration:   2220, Loss function: 4.693, Average Loss: 4.383, avg. samples / sec: 54552.60
Iteration:   2220, Loss function: 4.011, Average Loss: 4.446, avg. samples / sec: 54559.21
Iteration:   2220, Loss function: 4.030, Average Loss: 4.437, avg. samples / sec: 54547.61
Iteration:   2220, Loss function: 4.502, Average Loss: 4.439, avg. samples / sec: 54609.74
Iteration:   2220, Loss function: 4.498, Average Loss: 4.449, avg. samples / sec: 54786.22
Iteration:   2220, Loss function: 4.003, Average Loss: 4.438, avg. samples / sec: 54556.63
Iteration:   2220, Loss function: 5.245, Average Loss: 4.447, avg. samples / sec: 54541.43
Iteration:   2220, Loss function: 3.901, Average Loss: 4.419, avg. samples / sec: 54608.30
Iteration:   2220, Loss function: 4.346, Average Loss: 4.422, avg. samples / sec: 54656.69
Iteration:   2220, Loss function: 4.794, Average Loss: 4.415, avg. samples / sec: 54620.57
Iteration:   2220, Loss function: 4.756, Average Loss: 4.416, avg. samples / sec: 54621.82
Iteration:   2220, Loss function: 3.311, Average Loss: 4.435, avg. samples / sec: 54606.41
Iteration:   2220, Loss function: 4.077, Average Loss: 4.453, avg. samples / sec: 54597.49
Iteration:   2220, Loss function: 3.050, Average Loss: 4.406, avg. samples / sec: 54606.22
Iteration:   2220, Loss function: 5.222, Average Loss: 4.415, avg. samples / sec: 54564.19
Iteration:   2220, Loss function: 3.684, Average Loss: 4.411, avg. samples / sec: 54632.66
Iteration:   2220, Loss function: 4.414, Average Loss: 4.430, avg. samples / sec: 54603.45
Iteration:   2220, Loss function: 5.172, Average Loss: 4.434, avg. samples / sec: 54594.97
Iteration:   2220, Loss function: 3.766, Average Loss: 4.438, avg. samples / sec: 54580.44
Iteration:   2220, Loss function: 4.195, Average Loss: 4.443, avg. samples / sec: 54610.29
:::MLL 1558640635.528 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558640635.529 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 4.026, Average Loss: 4.417, avg. samples / sec: 54799.81
Iteration:   2240, Loss function: 3.663, Average Loss: 4.420, avg. samples / sec: 54798.40
Iteration:   2240, Loss function: 5.388, Average Loss: 4.427, avg. samples / sec: 54920.25
Iteration:   2240, Loss function: 3.107, Average Loss: 4.405, avg. samples / sec: 54904.91
Iteration:   2240, Loss function: 2.904, Average Loss: 4.412, avg. samples / sec: 54859.00
Iteration:   2240, Loss function: 3.824, Average Loss: 4.430, avg. samples / sec: 54926.08
Iteration:   2240, Loss function: 3.973, Average Loss: 4.433, avg. samples / sec: 54898.95
Iteration:   2240, Loss function: 2.293, Average Loss: 4.434, avg. samples / sec: 54896.40
Iteration:   2240, Loss function: 3.733, Average Loss: 4.429, avg. samples / sec: 54787.45
Iteration:   2240, Loss function: 4.128, Average Loss: 4.377, avg. samples / sec: 54821.06
Iteration:   2240, Loss function: 4.164, Average Loss: 4.427, avg. samples / sec: 54740.02
Iteration:   2240, Loss function: 3.684, Average Loss: 4.409, avg. samples / sec: 54765.23
Iteration:   2240, Loss function: 3.896, Average Loss: 4.438, avg. samples / sec: 54760.57
Iteration:   2240, Loss function: 4.237, Average Loss: 4.396, avg. samples / sec: 54703.98
Iteration:   2240, Loss function: 3.949, Average Loss: 4.428, avg. samples / sec: 54923.91
Iteration:   2240, Loss function: 3.578, Average Loss: 4.408, avg. samples / sec: 54664.03
Iteration:   2240, Loss function: 3.638, Average Loss: 4.410, avg. samples / sec: 54905.02
Iteration:   2240, Loss function: 3.513, Average Loss: 4.414, avg. samples / sec: 54850.81
Iteration:   2240, Loss function: 4.864, Average Loss: 4.429, avg. samples / sec: 54873.49
Iteration:   2240, Loss function: 4.379, Average Loss: 4.397, avg. samples / sec: 54867.31
Iteration:   2240, Loss function: 4.928, Average Loss: 4.407, avg. samples / sec: 54854.73
Iteration:   2240, Loss function: 3.418, Average Loss: 4.412, avg. samples / sec: 54778.19
Iteration:   2240, Loss function: 5.275, Average Loss: 4.409, avg. samples / sec: 54790.82
Iteration:   2240, Loss function: 3.154, Average Loss: 4.444, avg. samples / sec: 54778.42
Iteration:   2240, Loss function: 3.243, Average Loss: 4.424, avg. samples / sec: 54767.99
Iteration:   2240, Loss function: 4.901, Average Loss: 4.409, avg. samples / sec: 54735.87
Iteration:   2240, Loss function: 4.162, Average Loss: 4.441, avg. samples / sec: 54708.70
Iteration:   2240, Loss function: 4.000, Average Loss: 4.434, avg. samples / sec: 54754.12
Iteration:   2240, Loss function: 5.031, Average Loss: 4.443, avg. samples / sec: 54561.49
Iteration:   2240, Loss function: 4.426, Average Loss: 4.433, avg. samples / sec: 54742.89
Iteration:   2260, Loss function: 4.233, Average Loss: 4.415, avg. samples / sec: 54844.36
Iteration:   2260, Loss function: 4.017, Average Loss: 4.411, avg. samples / sec: 54808.61
Iteration:   2260, Loss function: 3.541, Average Loss: 4.433, avg. samples / sec: 55024.43
Iteration:   2260, Loss function: 4.442, Average Loss: 4.405, avg. samples / sec: 54845.64
Iteration:   2260, Loss function: 3.897, Average Loss: 4.424, avg. samples / sec: 54873.15
Iteration:   2260, Loss function: 4.119, Average Loss: 4.374, avg. samples / sec: 54900.53
Iteration:   2260, Loss function: 3.243, Average Loss: 4.426, avg. samples / sec: 54826.05
Iteration:   2260, Loss function: 4.512, Average Loss: 4.406, avg. samples / sec: 54912.85
Iteration:   2260, Loss function: 4.630, Average Loss: 4.423, avg. samples / sec: 54703.11
Iteration:   2260, Loss function: 4.482, Average Loss: 4.421, avg. samples / sec: 54877.48
Iteration:   2260, Loss function: 4.573, Average Loss: 4.403, avg. samples / sec: 54942.03
Iteration:   2260, Loss function: 3.920, Average Loss: 4.400, avg. samples / sec: 54718.51
Iteration:   2260, Loss function: 3.663, Average Loss: 4.433, avg. samples / sec: 54786.11
Iteration:   2260, Loss function: 4.010, Average Loss: 4.410, avg. samples / sec: 55088.33
Iteration:   2260, Loss function: 4.293, Average Loss: 4.419, avg. samples / sec: 54763.65
Iteration:   2260, Loss function: 4.053, Average Loss: 4.432, avg. samples / sec: 55027.65
Iteration:   2260, Loss function: 2.744, Average Loss: 4.391, avg. samples / sec: 54814.05
Iteration:   2260, Loss function: 4.193, Average Loss: 4.406, avg. samples / sec: 54909.94
Iteration:   2260, Loss function: 4.151, Average Loss: 4.422, avg. samples / sec: 54786.73
Iteration:   2260, Loss function: 4.861, Average Loss: 4.406, avg. samples / sec: 54908.89
Iteration:   2260, Loss function: 4.341, Average Loss: 4.440, avg. samples / sec: 54915.40
Iteration:   2260, Loss function: 5.021, Average Loss: 4.425, avg. samples / sec: 54828.10
Iteration:   2260, Loss function: 4.087, Average Loss: 4.403, avg. samples / sec: 54775.93
Iteration:   2260, Loss function: 5.001, Average Loss: 4.407, avg. samples / sec: 54789.80
Iteration:   2260, Loss function: 3.630, Average Loss: 4.437, avg. samples / sec: 54958.85
Iteration:   2260, Loss function: 4.029, Average Loss: 4.418, avg. samples / sec: 54909.75
Iteration:   2260, Loss function: 5.054, Average Loss: 4.430, avg. samples / sec: 54943.98
Iteration:   2260, Loss function: 5.613, Average Loss: 4.399, avg. samples / sec: 54801.83
Iteration:   2260, Loss function: 3.724, Average Loss: 4.391, avg. samples / sec: 54760.05
Iteration:   2260, Loss function: 4.022, Average Loss: 4.430, avg. samples / sec: 54908.40
Iteration:   2280, Loss function: 4.592, Average Loss: 4.413, avg. samples / sec: 55063.34
Iteration:   2280, Loss function: 3.226, Average Loss: 4.404, avg. samples / sec: 55039.92
Iteration:   2280, Loss function: 4.364, Average Loss: 4.417, avg. samples / sec: 55115.80
Iteration:   2280, Loss function: 3.622, Average Loss: 4.418, avg. samples / sec: 55079.57
Iteration:   2280, Loss function: 4.498, Average Loss: 4.420, avg. samples / sec: 55055.53
Iteration:   2280, Loss function: 4.971, Average Loss: 4.397, avg. samples / sec: 55090.27
Iteration:   2280, Loss function: 4.350, Average Loss: 4.399, avg. samples / sec: 54974.63
Iteration:   2280, Loss function: 3.494, Average Loss: 4.421, avg. samples / sec: 54967.85
Iteration:   2280, Loss function: 4.542, Average Loss: 4.397, avg. samples / sec: 55032.96
Iteration:   2280, Loss function: 3.994, Average Loss: 4.426, avg. samples / sec: 54926.12
Iteration:   2280, Loss function: 3.935, Average Loss: 4.385, avg. samples / sec: 55148.08
Iteration:   2280, Loss function: 4.369, Average Loss: 4.399, avg. samples / sec: 54989.94
Iteration:   2280, Loss function: 2.760, Average Loss: 4.414, avg. samples / sec: 55014.89
Iteration:   2280, Loss function: 4.075, Average Loss: 4.373, avg. samples / sec: 54930.47
Iteration:   2280, Loss function: 3.945, Average Loss: 4.430, avg. samples / sec: 54997.78
Iteration:   2280, Loss function: 4.184, Average Loss: 4.401, avg. samples / sec: 55131.00
Iteration:   2280, Loss function: 4.446, Average Loss: 4.415, avg. samples / sec: 55028.14
Iteration:   2280, Loss function: 3.858, Average Loss: 4.400, avg. samples / sec: 55007.59
Iteration:   2280, Loss function: 3.629, Average Loss: 4.406, avg. samples / sec: 54881.37
Iteration:   2280, Loss function: 5.398, Average Loss: 4.430, avg. samples / sec: 54949.04
Iteration:   2280, Loss function: 3.551, Average Loss: 4.432, avg. samples / sec: 55028.34
Iteration:   2280, Loss function: 5.255, Average Loss: 4.400, avg. samples / sec: 55014.22
Iteration:   2280, Loss function: 4.050, Average Loss: 4.428, avg. samples / sec: 54994.49
Iteration:   2280, Loss function: 4.824, Average Loss: 4.426, avg. samples / sec: 54995.57
Iteration:   2280, Loss function: 3.660, Average Loss: 4.400, avg. samples / sec: 55011.24
Iteration:   2280, Loss function: 4.716, Average Loss: 4.393, avg. samples / sec: 55052.00
Iteration:   2280, Loss function: 5.545, Average Loss: 4.412, avg. samples / sec: 54998.14
Iteration:   2280, Loss function: 4.050, Average Loss: 4.394, avg. samples / sec: 55012.42
Iteration:   2280, Loss function: 4.347, Average Loss: 4.426, avg. samples / sec: 55003.77
Iteration:   2280, Loss function: 4.915, Average Loss: 4.421, avg. samples / sec: 55004.30
:::MLL 1558640636.966 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.40s)
DONE (t=0.39s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.39s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.39s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.48s)
DONE (t=2.42s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.14860
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.27958
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.14615
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03365
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.15838
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.24304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.16604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24074
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.25237
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06073
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26123
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.39525
Current AP: 0.14860 AP goal: 0.23000
:::MLL 1558640640.883 eval_accuracy: {"value": 0.14859554022493757, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558640641.005 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558640641.011 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558640641.012 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 4.256, Average Loss: 4.414, avg. samples / sec: 7117.38
Iteration:   2300, Loss function: 4.503, Average Loss: 4.410, avg. samples / sec: 7111.17
Iteration:   2300, Loss function: 4.039, Average Loss: 4.402, avg. samples / sec: 7108.15
Iteration:   2300, Loss function: 3.903, Average Loss: 4.406, avg. samples / sec: 7106.74
Iteration:   2300, Loss function: 3.511, Average Loss: 4.395, avg. samples / sec: 7110.13
Iteration:   2300, Loss function: 3.259, Average Loss: 4.400, avg. samples / sec: 7113.20
Iteration:   2300, Loss function: 3.679, Average Loss: 4.402, avg. samples / sec: 7110.83
Iteration:   2300, Loss function: 5.203, Average Loss: 4.416, avg. samples / sec: 7109.06
Iteration:   2300, Loss function: 5.968, Average Loss: 4.396, avg. samples / sec: 7109.27
Iteration:   2300, Loss function: 4.790, Average Loss: 4.413, avg. samples / sec: 7108.45
Iteration:   2300, Loss function: 4.217, Average Loss: 4.417, avg. samples / sec: 7109.69
Iteration:   2300, Loss function: 3.618, Average Loss: 4.414, avg. samples / sec: 7109.25
Iteration:   2300, Loss function: 5.666, Average Loss: 4.398, avg. samples / sec: 7108.91
Iteration:   2300, Loss function: 3.498, Average Loss: 4.384, avg. samples / sec: 7109.37
Iteration:   2300, Loss function: 3.756, Average Loss: 4.394, avg. samples / sec: 7109.43
Iteration:   2300, Loss function: 4.000, Average Loss: 4.369, avg. samples / sec: 7109.59
Iteration:   2300, Loss function: 3.891, Average Loss: 4.428, avg. samples / sec: 7109.64
Iteration:   2300, Loss function: 4.379, Average Loss: 4.395, avg. samples / sec: 7109.07
Iteration:   2300, Loss function: 3.320, Average Loss: 4.399, avg. samples / sec: 7109.36
Iteration:   2300, Loss function: 3.538, Average Loss: 4.421, avg. samples / sec: 7108.72
Iteration:   2300, Loss function: 4.130, Average Loss: 4.401, avg. samples / sec: 7106.67
Iteration:   2300, Loss function: 4.255, Average Loss: 4.392, avg. samples / sec: 7109.17
Iteration:   2300, Loss function: 4.303, Average Loss: 4.402, avg. samples / sec: 7107.81
Iteration:   2300, Loss function: 4.850, Average Loss: 4.425, avg. samples / sec: 7108.77
Iteration:   2300, Loss function: 4.387, Average Loss: 4.421, avg. samples / sec: 7108.67
Iteration:   2300, Loss function: 3.877, Average Loss: 4.387, avg. samples / sec: 7108.86
Iteration:   2300, Loss function: 4.232, Average Loss: 4.428, avg. samples / sec: 7108.36
Iteration:   2300, Loss function: 3.532, Average Loss: 4.387, avg. samples / sec: 7108.69
Iteration:   2300, Loss function: 4.224, Average Loss: 4.406, avg. samples / sec: 7108.67
Iteration:   2300, Loss function: 4.127, Average Loss: 4.426, avg. samples / sec: 7108.47
:::MLL 1558640641.802 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558640641.802 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 4.338, Average Loss: 4.406, avg. samples / sec: 52125.16
Iteration:   2320, Loss function: 4.501, Average Loss: 4.411, avg. samples / sec: 52085.02
Iteration:   2320, Loss function: 4.698, Average Loss: 4.390, avg. samples / sec: 52096.65
Iteration:   2320, Loss function: 5.587, Average Loss: 4.395, avg. samples / sec: 52126.74
Iteration:   2320, Loss function: 4.636, Average Loss: 4.402, avg. samples / sec: 52074.06
Iteration:   2320, Loss function: 4.583, Average Loss: 4.415, avg. samples / sec: 52079.24
Iteration:   2320, Loss function: 4.466, Average Loss: 4.396, avg. samples / sec: 52009.99
Iteration:   2320, Loss function: 3.575, Average Loss: 4.391, avg. samples / sec: 52103.42
Iteration:   2320, Loss function: 5.210, Average Loss: 4.389, avg. samples / sec: 52086.42
Iteration:   2320, Loss function: 4.318, Average Loss: 4.411, avg. samples / sec: 52047.58
Iteration:   2320, Loss function: 4.892, Average Loss: 4.413, avg. samples / sec: 52075.80
Iteration:   2320, Loss function: 3.792, Average Loss: 4.398, avg. samples / sec: 52041.39
Iteration:   2320, Loss function: 6.077, Average Loss: 4.410, avg. samples / sec: 52034.63
Iteration:   2320, Loss function: 3.751, Average Loss: 4.366, avg. samples / sec: 52079.41
Iteration:   2320, Loss function: 3.797, Average Loss: 4.422, avg. samples / sec: 52068.62
Iteration:   2320, Loss function: 3.698, Average Loss: 4.391, avg. samples / sec: 52093.81
Iteration:   2320, Loss function: 4.475, Average Loss: 4.424, avg. samples / sec: 52082.55
Iteration:   2320, Loss function: 4.074, Average Loss: 4.398, avg. samples / sec: 52100.02
Iteration:   2320, Loss function: 5.109, Average Loss: 4.394, avg. samples / sec: 52051.62
Iteration:   2320, Loss function: 4.520, Average Loss: 4.405, avg. samples / sec: 51814.52
Iteration:   2320, Loss function: 4.178, Average Loss: 4.390, avg. samples / sec: 51843.25
Iteration:   2320, Loss function: 4.255, Average Loss: 4.383, avg. samples / sec: 52080.11
Iteration:   2320, Loss function: 3.788, Average Loss: 4.382, avg. samples / sec: 52102.98
Iteration:   2320, Loss function: 4.808, Average Loss: 4.396, avg. samples / sec: 52051.85
Iteration:   2320, Loss function: 4.274, Average Loss: 4.423, avg. samples / sec: 52075.32
Iteration:   2320, Loss function: 4.650, Average Loss: 4.417, avg. samples / sec: 52077.66
Iteration:   2320, Loss function: 5.261, Average Loss: 4.385, avg. samples / sec: 52079.30
Iteration:   2320, Loss function: 4.583, Average Loss: 4.424, avg. samples / sec: 52080.38
Iteration:   2320, Loss function: 3.833, Average Loss: 4.424, avg. samples / sec: 52094.76
Iteration:   2320, Loss function: 4.090, Average Loss: 4.409, avg. samples / sec: 52063.16
Iteration:   2340, Loss function: 3.929, Average Loss: 4.391, avg. samples / sec: 53051.48
Iteration:   2340, Loss function: 4.410, Average Loss: 4.407, avg. samples / sec: 52886.68
Iteration:   2340, Loss function: 4.213, Average Loss: 4.394, avg. samples / sec: 52917.18
Iteration:   2340, Loss function: 3.842, Average Loss: 4.406, avg. samples / sec: 52914.18
Iteration:   2340, Loss function: 3.873, Average Loss: 4.385, avg. samples / sec: 52834.79
Iteration:   2340, Loss function: 4.560, Average Loss: 4.364, avg. samples / sec: 52917.36
Iteration:   2340, Loss function: 4.239, Average Loss: 4.394, avg. samples / sec: 52840.52
Iteration:   2340, Loss function: 4.692, Average Loss: 4.410, avg. samples / sec: 52864.20
Iteration:   2340, Loss function: 2.671, Average Loss: 4.384, avg. samples / sec: 52849.89
Iteration:   2340, Loss function: 3.179, Average Loss: 4.390, avg. samples / sec: 52844.87
Iteration:   2340, Loss function: 3.961, Average Loss: 4.409, avg. samples / sec: 52815.88
Iteration:   2340, Loss function: 4.381, Average Loss: 4.415, avg. samples / sec: 52878.92
Iteration:   2340, Loss function: 3.585, Average Loss: 4.401, avg. samples / sec: 52628.15
Iteration:   2340, Loss function: 4.837, Average Loss: 4.398, avg. samples / sec: 52925.33
Iteration:   2340, Loss function: 4.440, Average Loss: 4.380, avg. samples / sec: 52894.88
Iteration:   2340, Loss function: 3.034, Average Loss: 4.392, avg. samples / sec: 52865.79
Iteration:   2340, Loss function: 3.819, Average Loss: 4.401, avg. samples / sec: 52854.49
Iteration:   2340, Loss function: 4.193, Average Loss: 4.391, avg. samples / sec: 52872.23
Iteration:   2340, Loss function: 4.600, Average Loss: 4.390, avg. samples / sec: 52817.96
Iteration:   2340, Loss function: 3.616, Average Loss: 4.416, avg. samples / sec: 52873.92
Iteration:   2340, Loss function: 4.756, Average Loss: 4.415, avg. samples / sec: 52871.62
Iteration:   2340, Loss function: 3.627, Average Loss: 4.418, avg. samples / sec: 52862.12
Iteration:   2340, Loss function: 5.301, Average Loss: 4.407, avg. samples / sec: 52891.52
Iteration:   2340, Loss function: 4.121, Average Loss: 4.387, avg. samples / sec: 52832.20
Iteration:   2340, Loss function: 3.194, Average Loss: 4.418, avg. samples / sec: 52804.56
Iteration:   2340, Loss function: 3.204, Average Loss: 4.373, avg. samples / sec: 52825.11
Iteration:   2340, Loss function: 4.634, Average Loss: 4.377, avg. samples / sec: 52836.71
Iteration:   2340, Loss function: 4.013, Average Loss: 4.404, avg. samples / sec: 52591.50
Iteration:   2340, Loss function: 3.363, Average Loss: 4.414, avg. samples / sec: 52839.09
Iteration:   2340, Loss function: 4.608, Average Loss: 4.386, avg. samples / sec: 52517.23
Iteration:   2360, Loss function: 2.813, Average Loss: 4.400, avg. samples / sec: 52554.61
Iteration:   2360, Loss function: 5.247, Average Loss: 4.395, avg. samples / sec: 52762.14
Iteration:   2360, Loss function: 3.679, Average Loss: 4.387, avg. samples / sec: 52565.96
Iteration:   2360, Loss function: 4.125, Average Loss: 4.388, avg. samples / sec: 52588.35
Iteration:   2360, Loss function: 4.145, Average Loss: 4.404, avg. samples / sec: 52613.67
Iteration:   2360, Loss function: 3.974, Average Loss: 4.400, avg. samples / sec: 52859.19
Iteration:   2360, Loss function: 3.738, Average Loss: 4.402, avg. samples / sec: 52522.39
Iteration:   2360, Loss function: 3.227, Average Loss: 4.385, avg. samples / sec: 52588.66
Iteration:   2360, Loss function: 3.945, Average Loss: 4.381, avg. samples / sec: 52334.66
Iteration:   2360, Loss function: 3.534, Average Loss: 4.377, avg. samples / sec: 52532.93
Iteration:   2360, Loss function: 3.316, Average Loss: 4.382, avg. samples / sec: 52904.87
Iteration:   2360, Loss function: 5.118, Average Loss: 4.365, avg. samples / sec: 52518.70
Iteration:   2360, Loss function: 4.048, Average Loss: 4.375, avg. samples / sec: 52553.18
Iteration:   2360, Loss function: 4.499, Average Loss: 4.406, avg. samples / sec: 52539.57
Iteration:   2360, Loss function: 3.010, Average Loss: 4.410, avg. samples / sec: 52541.53
Iteration:   2360, Loss function: 3.999, Average Loss: 4.390, avg. samples / sec: 52612.73
Iteration:   2360, Loss function: 3.790, Average Loss: 4.371, avg. samples / sec: 52551.71
Iteration:   2360, Loss function: 3.981, Average Loss: 4.392, avg. samples / sec: 52512.37
Iteration:   2360, Loss function: 4.256, Average Loss: 4.395, avg. samples / sec: 52576.59
Iteration:   2360, Loss function: 4.830, Average Loss: 4.390, avg. samples / sec: 52582.60
Iteration:   2360, Loss function: 4.062, Average Loss: 4.412, avg. samples / sec: 52597.51
Iteration:   2360, Loss function: 4.046, Average Loss: 4.381, avg. samples / sec: 52574.99
Iteration:   2360, Loss function: 4.266, Average Loss: 4.383, avg. samples / sec: 52585.48
Iteration:   2360, Loss function: 3.948, Average Loss: 4.413, avg. samples / sec: 52599.79
Iteration:   2360, Loss function: 3.795, Average Loss: 4.410, avg. samples / sec: 52572.40
Iteration:   2360, Loss function: 3.214, Average Loss: 4.371, avg. samples / sec: 52587.23
Iteration:   2360, Loss function: 4.167, Average Loss: 4.402, avg. samples / sec: 52618.27
Iteration:   2360, Loss function: 3.899, Average Loss: 4.366, avg. samples / sec: 52590.74
Iteration:   2360, Loss function: 3.471, Average Loss: 4.409, avg. samples / sec: 52554.28
Iteration:   2360, Loss function: 4.209, Average Loss: 4.405, avg. samples / sec: 52507.58
:::MLL 1558640644.039 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558640644.040 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 3.098, Average Loss: 4.393, avg. samples / sec: 52371.32
Iteration:   2380, Loss function: 2.776, Average Loss: 4.390, avg. samples / sec: 52341.31
Iteration:   2380, Loss function: 3.831, Average Loss: 4.379, avg. samples / sec: 52414.64
Iteration:   2380, Loss function: 4.563, Average Loss: 4.395, avg. samples / sec: 52413.59
Iteration:   2380, Loss function: 3.929, Average Loss: 4.377, avg. samples / sec: 52417.80
Iteration:   2380, Loss function: 3.741, Average Loss: 4.385, avg. samples / sec: 52375.37
Iteration:   2380, Loss function: 4.282, Average Loss: 4.409, avg. samples / sec: 52445.23
Iteration:   2380, Loss function: 2.552, Average Loss: 4.359, avg. samples / sec: 52403.38
Iteration:   2380, Loss function: 4.608, Average Loss: 4.380, avg. samples / sec: 52363.38
Iteration:   2380, Loss function: 4.292, Average Loss: 4.378, avg. samples / sec: 52553.54
Iteration:   2380, Loss function: 5.151, Average Loss: 4.397, avg. samples / sec: 52322.71
Iteration:   2380, Loss function: 3.789, Average Loss: 4.375, avg. samples / sec: 52329.81
Iteration:   2380, Loss function: 4.250, Average Loss: 4.365, avg. samples / sec: 52339.89
Iteration:   2380, Loss function: 3.859, Average Loss: 4.399, avg. samples / sec: 52345.67
Iteration:   2380, Loss function: 6.026, Average Loss: 4.379, avg. samples / sec: 52325.30
Iteration:   2380, Loss function: 4.247, Average Loss: 4.389, avg. samples / sec: 52297.20
Iteration:   2380, Loss function: 4.382, Average Loss: 4.381, avg. samples / sec: 52508.15
Iteration:   2380, Loss function: 3.480, Average Loss: 4.360, avg. samples / sec: 52486.50
Iteration:   2380, Loss function: 3.962, Average Loss: 4.388, avg. samples / sec: 52436.49
Iteration:   2380, Loss function: 4.031, Average Loss: 4.368, avg. samples / sec: 52410.22
Iteration:   2380, Loss function: 4.170, Average Loss: 4.387, avg. samples / sec: 52415.46
Iteration:   2380, Loss function: 4.599, Average Loss: 4.406, avg. samples / sec: 52415.11
Iteration:   2380, Loss function: 5.001, Average Loss: 4.387, avg. samples / sec: 52384.72
Iteration:   2380, Loss function: 3.056, Average Loss: 4.390, avg. samples / sec: 52335.93
Iteration:   2380, Loss function: 4.185, Average Loss: 4.368, avg. samples / sec: 52412.89
Iteration:   2380, Loss function: 3.983, Average Loss: 4.405, avg. samples / sec: 52362.28
Iteration:   2380, Loss function: 4.483, Average Loss: 4.404, avg. samples / sec: 52346.54
Iteration:   2380, Loss function: 3.436, Average Loss: 4.400, avg. samples / sec: 52390.68
Iteration:   2380, Loss function: 4.489, Average Loss: 4.398, avg. samples / sec: 52312.34
Iteration:   2380, Loss function: 5.496, Average Loss: 4.394, avg. samples / sec: 52293.30
Iteration:   2400, Loss function: 5.795, Average Loss: 4.393, avg. samples / sec: 52392.82
Iteration:   2400, Loss function: 3.328, Average Loss: 4.372, avg. samples / sec: 52332.02
Iteration:   2400, Loss function: 5.230, Average Loss: 4.397, avg. samples / sec: 52491.64
Iteration:   2400, Loss function: 4.035, Average Loss: 4.386, avg. samples / sec: 52283.13
Iteration:   2400, Loss function: 2.930, Average Loss: 4.366, avg. samples / sec: 52439.57
Iteration:   2400, Loss function: 5.082, Average Loss: 4.372, avg. samples / sec: 52404.90
Iteration:   2400, Loss function: 3.924, Average Loss: 4.379, avg. samples / sec: 52325.36
Iteration:   2400, Loss function: 4.260, Average Loss: 4.382, avg. samples / sec: 52429.46
Iteration:   2400, Loss function: 3.739, Average Loss: 4.358, avg. samples / sec: 52349.56
Iteration:   2400, Loss function: 3.660, Average Loss: 4.395, avg. samples / sec: 52385.98
Iteration:   2400, Loss function: 3.060, Average Loss: 4.360, avg. samples / sec: 52404.94
Iteration:   2400, Loss function: 4.046, Average Loss: 4.405, avg. samples / sec: 52342.05
Iteration:   2400, Loss function: 3.529, Average Loss: 4.369, avg. samples / sec: 52296.42
Iteration:   2400, Loss function: 3.927, Average Loss: 4.375, avg. samples / sec: 52378.04
Iteration:   2400, Loss function: 3.177, Average Loss: 4.382, avg. samples / sec: 52344.13
Iteration:   2400, Loss function: 3.172, Average Loss: 4.376, avg. samples / sec: 52349.17
Iteration:   2400, Loss function: 4.744, Average Loss: 4.397, avg. samples / sec: 52386.74
Iteration:   2400, Loss function: 4.646, Average Loss: 4.383, avg. samples / sec: 52336.41
Iteration:   2400, Loss function: 4.463, Average Loss: 4.378, avg. samples / sec: 52222.86
Iteration:   2400, Loss function: 3.698, Average Loss: 4.396, avg. samples / sec: 52419.38
Iteration:   2400, Loss function: 2.827, Average Loss: 4.366, avg. samples / sec: 52294.85
Iteration:   2400, Loss function: 3.009, Average Loss: 4.360, avg. samples / sec: 52332.66
Iteration:   2400, Loss function: 4.290, Average Loss: 4.391, avg. samples / sec: 52417.12
Iteration:   2400, Loss function: 4.344, Average Loss: 4.397, avg. samples / sec: 52397.59
Iteration:   2400, Loss function: 5.673, Average Loss: 4.393, avg. samples / sec: 52067.99
Iteration:   2400, Loss function: 4.042, Average Loss: 4.397, avg. samples / sec: 52438.57
Iteration:   2400, Loss function: 4.519, Average Loss: 4.381, avg. samples / sec: 52255.86
Iteration:   2400, Loss function: 5.566, Average Loss: 4.355, avg. samples / sec: 52235.17
Iteration:   2400, Loss function: 3.245, Average Loss: 4.395, avg. samples / sec: 52265.97
Iteration:   2400, Loss function: 4.286, Average Loss: 4.379, avg. samples / sec: 52120.29
Iteration:   2420, Loss function: 4.051, Average Loss: 4.390, avg. samples / sec: 52747.29
Iteration:   2420, Loss function: 4.553, Average Loss: 4.381, avg. samples / sec: 52844.24
Iteration:   2420, Loss function: 3.475, Average Loss: 4.361, avg. samples / sec: 52731.61
Iteration:   2420, Loss function: 4.081, Average Loss: 4.366, avg. samples / sec: 52782.75
Iteration:   2420, Loss function: 4.503, Average Loss: 4.391, avg. samples / sec: 52763.34
Iteration:   2420, Loss function: 4.275, Average Loss: 4.367, avg. samples / sec: 52671.72
Iteration:   2420, Loss function: 5.193, Average Loss: 4.398, avg. samples / sec: 52747.46
Iteration:   2420, Loss function: 4.784, Average Loss: 4.372, avg. samples / sec: 52695.22
Iteration:   2420, Loss function: 4.270, Average Loss: 4.377, avg. samples / sec: 52732.36
Iteration:   2420, Loss function: 3.579, Average Loss: 4.383, avg. samples / sec: 52976.70
Iteration:   2420, Loss function: 3.820, Average Loss: 4.393, avg. samples / sec: 52661.11
Iteration:   2420, Loss function: 4.395, Average Loss: 4.372, avg. samples / sec: 52713.09
Iteration:   2420, Loss function: 4.615, Average Loss: 4.373, avg. samples / sec: 52727.94
Iteration:   2420, Loss function: 4.079, Average Loss: 4.375, avg. samples / sec: 53008.44
Iteration:   2420, Loss function: 4.305, Average Loss: 4.360, avg. samples / sec: 52705.19
Iteration:   2420, Loss function: 4.424, Average Loss: 4.353, avg. samples / sec: 52674.06
Iteration:   2420, Loss function: 4.267, Average Loss: 4.391, avg. samples / sec: 52901.87
Iteration:   2420, Loss function: 3.940, Average Loss: 4.372, avg. samples / sec: 52780.73
Iteration:   2420, Loss function: 3.763, Average Loss: 4.390, avg. samples / sec: 52774.45
Iteration:   2420, Loss function: 3.083, Average Loss: 4.390, avg. samples / sec: 52768.75
Iteration:   2420, Loss function: 3.984, Average Loss: 4.370, avg. samples / sec: 52754.39
Iteration:   2420, Loss function: 4.421, Average Loss: 4.384, avg. samples / sec: 52781.66
Iteration:   2420, Loss function: 4.544, Average Loss: 4.382, avg. samples / sec: 52737.34
Iteration:   2420, Loss function: 4.389, Average Loss: 4.364, avg. samples / sec: 52744.98
Iteration:   2420, Loss function: 4.296, Average Loss: 4.377, avg. samples / sec: 52697.31
Iteration:   2420, Loss function: 4.543, Average Loss: 4.392, avg. samples / sec: 52763.40
Iteration:   2420, Loss function: 4.740, Average Loss: 4.359, avg. samples / sec: 52727.33
Iteration:   2420, Loss function: 4.651, Average Loss: 4.352, avg. samples / sec: 52743.73
Iteration:   2420, Loss function: 4.674, Average Loss: 4.389, avg. samples / sec: 52702.27
Iteration:   2420, Loss function: 4.066, Average Loss: 4.395, avg. samples / sec: 52690.74
Iteration:   2440, Loss function: 5.012, Average Loss: 4.379, avg. samples / sec: 52689.07
Iteration:   2440, Loss function: 3.649, Average Loss: 4.372, avg. samples / sec: 52703.99
Iteration:   2440, Loss function: 6.175, Average Loss: 4.381, avg. samples / sec: 52780.49
Iteration:   2440, Loss function: 5.325, Average Loss: 4.360, avg. samples / sec: 52727.67
Iteration:   2440, Loss function: 4.538, Average Loss: 4.364, avg. samples / sec: 52741.19
Iteration:   2440, Loss function: 4.190, Average Loss: 4.368, avg. samples / sec: 52777.67
Iteration:   2440, Loss function: 4.645, Average Loss: 4.351, avg. samples / sec: 52806.38
Iteration:   2440, Loss function: 4.224, Average Loss: 4.359, avg. samples / sec: 52725.93
Iteration:   2440, Loss function: 3.909, Average Loss: 4.386, avg. samples / sec: 52706.21
Iteration:   2440, Loss function: 5.250, Average Loss: 4.362, avg. samples / sec: 52681.39
Iteration:   2440, Loss function: 4.456, Average Loss: 4.372, avg. samples / sec: 52717.43
Iteration:   2440, Loss function: 3.330, Average Loss: 4.366, avg. samples / sec: 52735.72
Iteration:   2440, Loss function: 4.382, Average Loss: 4.369, avg. samples / sec: 52715.91
Iteration:   2440, Loss function: 5.063, Average Loss: 4.357, avg. samples / sec: 52735.19
Iteration:   2440, Loss function: 3.442, Average Loss: 4.391, avg. samples / sec: 52684.91
Iteration:   2440, Loss function: 4.372, Average Loss: 4.387, avg. samples / sec: 52676.50
Iteration:   2440, Loss function: 4.818, Average Loss: 4.367, avg. samples / sec: 52692.10
Iteration:   2440, Loss function: 4.556, Average Loss: 4.386, avg. samples / sec: 52731.59
Iteration:   2440, Loss function: 4.326, Average Loss: 4.382, avg. samples / sec: 52696.79
Iteration:   2440, Loss function: 4.397, Average Loss: 4.375, avg. samples / sec: 52728.95
Iteration:   2440, Loss function: 4.600, Average Loss: 4.359, avg. samples / sec: 52734.22
Iteration:   2440, Loss function: 5.142, Average Loss: 4.385, avg. samples / sec: 52746.02
Iteration:   2440, Loss function: 2.427, Average Loss: 4.372, avg. samples / sec: 52723.82
Iteration:   2440, Loss function: 3.864, Average Loss: 4.363, avg. samples / sec: 52718.20
Iteration:   2440, Loss function: 3.650, Average Loss: 4.385, avg. samples / sec: 52541.09
Iteration:   2440, Loss function: 3.523, Average Loss: 4.377, avg. samples / sec: 52689.92
Iteration:   2440, Loss function: 4.887, Average Loss: 4.346, avg. samples / sec: 52732.88
Iteration:   2440, Loss function: 4.357, Average Loss: 4.354, avg. samples / sec: 52710.51
Iteration:   2440, Loss function: 4.639, Average Loss: 4.392, avg. samples / sec: 52744.66
Iteration:   2440, Loss function: 4.458, Average Loss: 4.383, avg. samples / sec: 52712.27
:::MLL 1558640646.279 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558640646.279 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 6.336, Average Loss: 4.374, avg. samples / sec: 52223.25
Iteration:   2460, Loss function: 4.337, Average Loss: 4.366, avg. samples / sec: 52225.26
Iteration:   2460, Loss function: 3.349, Average Loss: 4.381, avg. samples / sec: 52216.44
Iteration:   2460, Loss function: 5.198, Average Loss: 4.368, avg. samples / sec: 52280.34
Iteration:   2460, Loss function: 6.303, Average Loss: 4.353, avg. samples / sec: 52199.22
Iteration:   2460, Loss function: 3.412, Average Loss: 4.366, avg. samples / sec: 52251.73
Iteration:   2460, Loss function: 4.822, Average Loss: 4.356, avg. samples / sec: 52231.57
Iteration:   2460, Loss function: 5.541, Average Loss: 4.360, avg. samples / sec: 52202.01
Iteration:   2460, Loss function: 4.176, Average Loss: 4.378, avg. samples / sec: 52276.73
Iteration:   2460, Loss function: 4.157, Average Loss: 4.347, avg. samples / sec: 52196.15
Iteration:   2460, Loss function: 3.878, Average Loss: 4.379, avg. samples / sec: 52208.10
Iteration:   2460, Loss function: 3.596, Average Loss: 4.360, avg. samples / sec: 52182.83
Iteration:   2460, Loss function: 4.346, Average Loss: 4.363, avg. samples / sec: 52228.36
Iteration:   2460, Loss function: 4.207, Average Loss: 4.354, avg. samples / sec: 52209.01
Iteration:   2460, Loss function: 3.785, Average Loss: 4.344, avg. samples / sec: 52219.22
Iteration:   2460, Loss function: 3.820, Average Loss: 4.384, avg. samples / sec: 52196.07
Iteration:   2460, Loss function: 3.908, Average Loss: 4.338, avg. samples / sec: 52412.67
Iteration:   2460, Loss function: 5.581, Average Loss: 4.381, avg. samples / sec: 52314.32
Iteration:   2460, Loss function: 5.607, Average Loss: 4.378, avg. samples / sec: 52214.00
Iteration:   2460, Loss function: 3.552, Average Loss: 4.361, avg. samples / sec: 52202.61
Iteration:   2460, Loss function: 5.064, Average Loss: 4.353, avg. samples / sec: 52223.21
Iteration:   2460, Loss function: 3.306, Average Loss: 4.372, avg. samples / sec: 52220.64
Iteration:   2460, Loss function: 3.853, Average Loss: 4.379, avg. samples / sec: 52215.80
Iteration:   2460, Loss function: 4.347, Average Loss: 4.370, avg. samples / sec: 52218.51
Iteration:   2460, Loss function: 3.424, Average Loss: 4.380, avg. samples / sec: 52196.46
Iteration:   2460, Loss function: 4.157, Average Loss: 4.347, avg. samples / sec: 52250.20
Iteration:   2460, Loss function: 3.596, Average Loss: 4.379, avg. samples / sec: 52273.96
Iteration:   2460, Loss function: 4.579, Average Loss: 4.373, avg. samples / sec: 52232.60
Iteration:   2460, Loss function: 4.230, Average Loss: 4.365, avg. samples / sec: 52196.03
Iteration:   2460, Loss function: 2.857, Average Loss: 4.387, avg. samples / sec: 52228.22
Iteration:   2480, Loss function: 3.064, Average Loss: 4.371, avg. samples / sec: 52811.70
Iteration:   2480, Loss function: 4.612, Average Loss: 4.375, avg. samples / sec: 52752.14
Iteration:   2480, Loss function: 4.609, Average Loss: 4.343, avg. samples / sec: 52746.83
Iteration:   2480, Loss function: 4.467, Average Loss: 4.360, avg. samples / sec: 52748.07
Iteration:   2480, Loss function: 4.523, Average Loss: 4.358, avg. samples / sec: 52724.16
Iteration:   2480, Loss function: 3.339, Average Loss: 4.370, avg. samples / sec: 52608.11
Iteration:   2480, Loss function: 4.529, Average Loss: 4.352, avg. samples / sec: 52776.36
Iteration:   2480, Loss function: 4.185, Average Loss: 4.355, avg. samples / sec: 52748.83
Iteration:   2480, Loss function: 4.511, Average Loss: 4.365, avg. samples / sec: 52570.51
Iteration:   2480, Loss function: 4.135, Average Loss: 4.349, avg. samples / sec: 52710.18
Iteration:   2480, Loss function: 4.062, Average Loss: 4.377, avg. samples / sec: 52720.13
Iteration:   2480, Loss function: 4.111, Average Loss: 4.341, avg. samples / sec: 52727.29
Iteration:   2480, Loss function: 4.040, Average Loss: 4.340, avg. samples / sec: 52738.28
Iteration:   2480, Loss function: 3.960, Average Loss: 4.377, avg. samples / sec: 52757.24
Iteration:   2480, Loss function: 3.174, Average Loss: 4.356, avg. samples / sec: 52608.09
Iteration:   2480, Loss function: 4.907, Average Loss: 4.359, avg. samples / sec: 52817.62
Iteration:   2480, Loss function: 5.437, Average Loss: 4.364, avg. samples / sec: 52769.72
Iteration:   2480, Loss function: 3.305, Average Loss: 4.360, avg. samples / sec: 52520.48
Iteration:   2480, Loss function: 4.210, Average Loss: 4.373, avg. samples / sec: 52759.09
Iteration:   2480, Loss function: 4.739, Average Loss: 4.358, avg. samples / sec: 52760.56
Iteration:   2480, Loss function: 4.779, Average Loss: 4.373, avg. samples / sec: 52734.38
Iteration:   2480, Loss function: 4.670, Average Loss: 4.371, avg. samples / sec: 52733.11
Iteration:   2480, Loss function: 4.572, Average Loss: 4.330, avg. samples / sec: 52566.12
Iteration:   2480, Loss function: 4.148, Average Loss: 4.372, avg. samples / sec: 52717.31
Iteration:   2480, Loss function: 4.304, Average Loss: 4.352, avg. samples / sec: 52704.79
Iteration:   2480, Loss function: 3.707, Average Loss: 4.375, avg. samples / sec: 52720.90
Iteration:   2480, Loss function: 3.347, Average Loss: 4.375, avg. samples / sec: 52644.65
Iteration:   2480, Loss function: 4.649, Average Loss: 4.367, avg. samples / sec: 52725.97
Iteration:   2480, Loss function: 3.702, Average Loss: 4.342, avg. samples / sec: 52708.54
Iteration:   2480, Loss function: 4.694, Average Loss: 4.385, avg. samples / sec: 52720.04
Iteration:   2500, Loss function: 4.156, Average Loss: 4.353, avg. samples / sec: 52786.23
Iteration:   2500, Loss function: 4.165, Average Loss: 4.371, avg. samples / sec: 52689.84
Iteration:   2500, Loss function: 3.745, Average Loss: 4.349, avg. samples / sec: 52661.33
Iteration:   2500, Loss function: 5.803, Average Loss: 4.358, avg. samples / sec: 52630.04
Iteration:   2500, Loss function: 3.984, Average Loss: 4.372, avg. samples / sec: 52589.21
Iteration:   2500, Loss function: 4.218, Average Loss: 4.334, avg. samples / sec: 52666.60
Iteration:   2500, Loss function: 3.628, Average Loss: 4.349, avg. samples / sec: 52617.95
Iteration:   2500, Loss function: 3.502, Average Loss: 4.340, avg. samples / sec: 52609.41
Iteration:   2500, Loss function: 2.899, Average Loss: 4.344, avg. samples / sec: 52651.00
Iteration:   2500, Loss function: 3.978, Average Loss: 4.354, avg. samples / sec: 52774.74
Iteration:   2500, Loss function: 3.508, Average Loss: 4.354, avg. samples / sec: 52598.06
Iteration:   2500, Loss function: 4.963, Average Loss: 4.368, avg. samples / sec: 52590.33
Iteration:   2500, Loss function: 4.604, Average Loss: 4.338, avg. samples / sec: 52642.54
Iteration:   2500, Loss function: 2.889, Average Loss: 4.368, avg. samples / sec: 52658.93
Iteration:   2500, Loss function: 4.388, Average Loss: 4.364, avg. samples / sec: 52551.52
Iteration:   2500, Loss function: 3.838, Average Loss: 4.357, avg. samples / sec: 52676.41
Iteration:   2500, Loss function: 4.090, Average Loss: 4.359, avg. samples / sec: 52633.50
Iteration:   2500, Loss function: 3.956, Average Loss: 4.368, avg. samples / sec: 52678.08
Iteration:   2500, Loss function: 3.584, Average Loss: 4.360, avg. samples / sec: 52644.47
Iteration:   2500, Loss function: 3.641, Average Loss: 4.367, avg. samples / sec: 52675.50
Iteration:   2500, Loss function: 4.645, Average Loss: 4.360, avg. samples / sec: 52598.30
Iteration:   2500, Loss function: 4.620, Average Loss: 4.371, avg. samples / sec: 52618.19
Iteration:   2500, Loss function: 3.223, Average Loss: 4.367, avg. samples / sec: 52635.78
Iteration:   2500, Loss function: 4.040, Average Loss: 4.364, avg. samples / sec: 52663.97
Iteration:   2500, Loss function: 4.684, Average Loss: 4.371, avg. samples / sec: 52632.75
Iteration:   2500, Loss function: 5.056, Average Loss: 4.338, avg. samples / sec: 52664.63
Iteration:   2500, Loss function: 2.882, Average Loss: 4.376, avg. samples / sec: 52657.55
Iteration:   2500, Loss function: 6.596, Average Loss: 4.325, avg. samples / sec: 52622.94
Iteration:   2500, Loss function: 3.672, Average Loss: 4.377, avg. samples / sec: 52677.92
Iteration:   2500, Loss function: 3.941, Average Loss: 4.355, avg. samples / sec: 52633.36
:::MLL 1558640648.518 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558640648.518 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 5.289, Average Loss: 4.364, avg. samples / sec: 52376.74
Iteration:   2520, Loss function: 4.641, Average Loss: 4.345, avg. samples / sec: 52227.84
Iteration:   2520, Loss function: 3.956, Average Loss: 4.356, avg. samples / sec: 52338.08
Iteration:   2520, Loss function: 5.257, Average Loss: 4.363, avg. samples / sec: 52530.77
Iteration:   2520, Loss function: 3.976, Average Loss: 4.354, avg. samples / sec: 52286.80
Iteration:   2520, Loss function: 3.619, Average Loss: 4.360, avg. samples / sec: 52302.27
Iteration:   2520, Loss function: 3.034, Average Loss: 4.331, avg. samples / sec: 52267.70
Iteration:   2520, Loss function: 4.082, Average Loss: 4.355, avg. samples / sec: 52265.61
Iteration:   2520, Loss function: 4.830, Average Loss: 4.346, avg. samples / sec: 52250.63
Iteration:   2520, Loss function: 5.142, Average Loss: 4.330, avg. samples / sec: 52229.87
Iteration:   2520, Loss function: 3.973, Average Loss: 4.335, avg. samples / sec: 52239.08
Iteration:   2520, Loss function: 4.220, Average Loss: 4.345, avg. samples / sec: 52225.44
Iteration:   2520, Loss function: 3.006, Average Loss: 4.343, avg. samples / sec: 52193.48
Iteration:   2520, Loss function: 4.844, Average Loss: 4.340, avg. samples / sec: 52197.31
Iteration:   2520, Loss function: 4.228, Average Loss: 4.367, avg. samples / sec: 52139.74
Iteration:   2520, Loss function: 3.315, Average Loss: 4.341, avg. samples / sec: 52167.98
Iteration:   2520, Loss function: 5.608, Average Loss: 4.354, avg. samples / sec: 52349.71
Iteration:   2520, Loss function: 3.767, Average Loss: 4.363, avg. samples / sec: 52344.21
Iteration:   2520, Loss function: 4.629, Average Loss: 4.357, avg. samples / sec: 52343.47
Iteration:   2520, Loss function: 4.092, Average Loss: 4.351, avg. samples / sec: 52334.92
Iteration:   2520, Loss function: 3.305, Average Loss: 4.328, avg. samples / sec: 52315.35
Iteration:   2520, Loss function: 3.867, Average Loss: 4.315, avg. samples / sec: 52321.88
Iteration:   2520, Loss function: 4.788, Average Loss: 4.354, avg. samples / sec: 52271.17
Iteration:   2520, Loss function: 5.497, Average Loss: 4.353, avg. samples / sec: 52234.94
Iteration:   2520, Loss function: 3.713, Average Loss: 4.349, avg. samples / sec: 52192.05
Iteration:   2520, Loss function: 3.437, Average Loss: 4.360, avg. samples / sec: 52215.22
Iteration:   2520, Loss function: 3.087, Average Loss: 4.361, avg. samples / sec: 52204.48
Iteration:   2520, Loss function: 4.204, Average Loss: 4.367, avg. samples / sec: 52210.15
Iteration:   2520, Loss function: 3.963, Average Loss: 4.370, avg. samples / sec: 52186.85
Iteration:   2520, Loss function: 3.506, Average Loss: 4.364, avg. samples / sec: 52201.06
Iteration:   2540, Loss function: 2.780, Average Loss: 4.333, avg. samples / sec: 52529.21
Iteration:   2540, Loss function: 3.237, Average Loss: 4.325, avg. samples / sec: 52471.82
Iteration:   2540, Loss function: 3.954, Average Loss: 4.329, avg. samples / sec: 52540.62
Iteration:   2540, Loss function: 3.590, Average Loss: 4.340, avg. samples / sec: 52487.93
Iteration:   2540, Loss function: 3.807, Average Loss: 4.350, avg. samples / sec: 52389.08
Iteration:   2540, Loss function: 3.446, Average Loss: 4.349, avg. samples / sec: 52387.19
Iteration:   2540, Loss function: 4.006, Average Loss: 4.349, avg. samples / sec: 52444.00
Iteration:   2540, Loss function: 3.950, Average Loss: 4.330, avg. samples / sec: 52467.23
Iteration:   2540, Loss function: 3.721, Average Loss: 4.340, avg. samples / sec: 52508.38
Iteration:   2540, Loss function: 3.577, Average Loss: 4.357, avg. samples / sec: 52500.83
Iteration:   2540, Loss function: 3.690, Average Loss: 4.339, avg. samples / sec: 52446.32
Iteration:   2540, Loss function: 3.819, Average Loss: 4.322, avg. samples / sec: 52398.86
Iteration:   2540, Loss function: 3.557, Average Loss: 4.357, avg. samples / sec: 52351.87
Iteration:   2540, Loss function: 4.546, Average Loss: 4.362, avg. samples / sec: 52401.78
Iteration:   2540, Loss function: 4.127, Average Loss: 4.345, avg. samples / sec: 52435.94
Iteration:   2540, Loss function: 5.316, Average Loss: 4.357, avg. samples / sec: 52207.52
Iteration:   2540, Loss function: 3.118, Average Loss: 4.352, avg. samples / sec: 52503.79
Iteration:   2540, Loss function: 3.794, Average Loss: 4.346, avg. samples / sec: 52461.57
Iteration:   2540, Loss function: 4.485, Average Loss: 4.347, avg. samples / sec: 52428.25
Iteration:   2540, Loss function: 4.188, Average Loss: 4.344, avg. samples / sec: 52469.48
Iteration:   2540, Loss function: 3.877, Average Loss: 4.327, avg. samples / sec: 52415.83
Iteration:   2540, Loss function: 3.422, Average Loss: 4.364, avg. samples / sec: 52535.55
Iteration:   2540, Loss function: 5.355, Average Loss: 4.352, avg. samples / sec: 52361.71
Iteration:   2540, Loss function: 3.082, Average Loss: 4.353, avg. samples / sec: 52081.45
Iteration:   2540, Loss function: 5.006, Average Loss: 4.348, avg. samples / sec: 52330.17
Iteration:   2540, Loss function: 3.382, Average Loss: 4.351, avg. samples / sec: 52466.22
Iteration:   2540, Loss function: 3.441, Average Loss: 4.364, avg. samples / sec: 52479.44
Iteration:   2540, Loss function: 5.124, Average Loss: 4.316, avg. samples / sec: 52372.57
Iteration:   2540, Loss function: 3.868, Average Loss: 4.337, avg. samples / sec: 52221.08
Iteration:   2540, Loss function: 4.075, Average Loss: 4.362, avg. samples / sec: 52492.68
Iteration:   2560, Loss function: 4.843, Average Loss: 4.327, avg. samples / sec: 52423.34
Iteration:   2560, Loss function: 3.341, Average Loss: 4.333, avg. samples / sec: 52621.51
Iteration:   2560, Loss function: 2.689, Average Loss: 4.336, avg. samples / sec: 52595.23
Iteration:   2560, Loss function: 3.483, Average Loss: 4.352, avg. samples / sec: 52815.92
Iteration:   2560, Loss function: 3.269, Average Loss: 4.321, avg. samples / sec: 52515.80
Iteration:   2560, Loss function: 3.749, Average Loss: 4.342, avg. samples / sec: 52573.02
Iteration:   2560, Loss function: 5.176, Average Loss: 4.353, avg. samples / sec: 52568.93
Iteration:   2560, Loss function: 4.898, Average Loss: 4.345, avg. samples / sec: 52549.34
Iteration:   2560, Loss function: 3.861, Average Loss: 4.344, avg. samples / sec: 52528.89
Iteration:   2560, Loss function: 4.903, Average Loss: 4.325, avg. samples / sec: 52489.78
Iteration:   2560, Loss function: 3.927, Average Loss: 4.331, avg. samples / sec: 52498.45
Iteration:   2560, Loss function: 4.828, Average Loss: 4.355, avg. samples / sec: 52601.44
Iteration:   2560, Loss function: 4.413, Average Loss: 4.322, avg. samples / sec: 52532.42
Iteration:   2560, Loss function: 4.299, Average Loss: 4.320, avg. samples / sec: 52574.49
Iteration:   2560, Loss function: 4.218, Average Loss: 4.332, avg. samples / sec: 52773.54
Iteration:   2560, Loss function: 4.393, Average Loss: 4.349, avg. samples / sec: 52550.24
Iteration:   2560, Loss function: 3.463, Average Loss: 4.347, avg. samples / sec: 52572.04
Iteration:   2560, Loss function: 4.771, Average Loss: 4.352, avg. samples / sec: 52532.50
Iteration:   2560, Loss function: 4.206, Average Loss: 4.340, avg. samples / sec: 52540.57
Iteration:   2560, Loss function: 4.489, Average Loss: 4.345, avg. samples / sec: 52541.92
Iteration:   2560, Loss function: 3.746, Average Loss: 4.348, avg. samples / sec: 52519.01
Iteration:   2560, Loss function: 3.733, Average Loss: 4.353, avg. samples / sec: 52512.75
Iteration:   2560, Loss function: 2.944, Average Loss: 4.356, avg. samples / sec: 52587.68
Iteration:   2560, Loss function: 3.721, Average Loss: 4.343, avg. samples / sec: 52549.52
Iteration:   2560, Loss function: 4.858, Average Loss: 4.308, avg. samples / sec: 52567.40
Iteration:   2560, Loss function: 4.596, Average Loss: 4.355, avg. samples / sec: 52521.24
Iteration:   2560, Loss function: 4.327, Average Loss: 4.345, avg. samples / sec: 52548.19
Iteration:   2560, Loss function: 4.180, Average Loss: 4.325, avg. samples / sec: 52513.45
Iteration:   2560, Loss function: 4.499, Average Loss: 4.359, avg. samples / sec: 52537.75
Iteration:   2560, Loss function: 3.635, Average Loss: 4.345, avg. samples / sec: 52414.76
Iteration:   2580, Loss function: 4.507, Average Loss: 4.322, avg. samples / sec: 52361.52
Iteration:   2580, Loss function: 3.686, Average Loss: 4.325, avg. samples / sec: 52253.90
Iteration:   2580, Loss function: 4.325, Average Loss: 4.312, avg. samples / sec: 52269.04
Iteration:   2580, Loss function: 4.551, Average Loss: 4.339, avg. samples / sec: 52262.89
Iteration:   2580, Loss function: 4.504, Average Loss: 4.330, avg. samples / sec: 52267.45
Iteration:   2580, Loss function: 3.751, Average Loss: 4.352, avg. samples / sec: 52193.29
Iteration:   2580, Loss function: 3.757, Average Loss: 4.351, avg. samples / sec: 52223.17
Iteration:   2580, Loss function: 4.331, Average Loss: 4.329, avg. samples / sec: 52165.43
Iteration:   2580, Loss function: 4.482, Average Loss: 4.314, avg. samples / sec: 52229.19
Iteration:   2580, Loss function: 4.578, Average Loss: 4.341, avg. samples / sec: 52184.96
Iteration:   2580, Loss function: 4.920, Average Loss: 4.330, avg. samples / sec: 52165.95
Iteration:   2580, Loss function: 4.500, Average Loss: 4.326, avg. samples / sec: 52209.76
Iteration:   2580, Loss function: 3.922, Average Loss: 4.315, avg. samples / sec: 52220.29
Iteration:   2580, Loss function: 3.729, Average Loss: 4.344, avg. samples / sec: 52197.87
Iteration:   2580, Loss function: 3.708, Average Loss: 4.344, avg. samples / sec: 52171.96
Iteration:   2580, Loss function: 4.625, Average Loss: 4.331, avg. samples / sec: 52227.35
Iteration:   2580, Loss function: 3.285, Average Loss: 4.346, avg. samples / sec: 52232.29
Iteration:   2580, Loss function: 4.100, Average Loss: 4.344, avg. samples / sec: 52230.37
Iteration:   2580, Loss function: 3.741, Average Loss: 4.347, avg. samples / sec: 52210.77
Iteration:   2580, Loss function: 4.383, Average Loss: 4.341, avg. samples / sec: 52318.58
Iteration:   2580, Loss function: 3.652, Average Loss: 4.348, avg. samples / sec: 52199.92
Iteration:   2580, Loss function: 3.366, Average Loss: 4.352, avg. samples / sec: 52231.09
Iteration:   2580, Loss function: 4.155, Average Loss: 4.340, avg. samples / sec: 52237.96
Iteration:   2580, Loss function: 3.239, Average Loss: 4.353, avg. samples / sec: 52202.30
Iteration:   2580, Loss function: 3.794, Average Loss: 4.347, avg. samples / sec: 52206.67
Iteration:   2580, Loss function: 2.835, Average Loss: 4.342, avg. samples / sec: 52175.07
Iteration:   2580, Loss function: 4.094, Average Loss: 4.337, avg. samples / sec: 52206.55
Iteration:   2580, Loss function: 3.134, Average Loss: 4.320, avg. samples / sec: 52211.66
Iteration:   2580, Loss function: 3.690, Average Loss: 4.303, avg. samples / sec: 52197.83
Iteration:   2580, Loss function: 3.331, Average Loss: 4.353, avg. samples / sec: 52226.40
:::MLL 1558640650.765 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558640650.765 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 4.346, Average Loss: 4.322, avg. samples / sec: 52227.60
Iteration:   2600, Loss function: 4.663, Average Loss: 4.347, avg. samples / sec: 52471.51
Iteration:   2600, Loss function: 4.723, Average Loss: 4.315, avg. samples / sec: 52210.73
Iteration:   2600, Loss function: 4.539, Average Loss: 4.308, avg. samples / sec: 52094.14
Iteration:   2600, Loss function: 4.071, Average Loss: 4.335, avg. samples / sec: 52184.28
Iteration:   2600, Loss function: 6.095, Average Loss: 4.325, avg. samples / sec: 52141.25
Iteration:   2600, Loss function: 3.952, Average Loss: 4.331, avg. samples / sec: 52109.17
Iteration:   2600, Loss function: 3.127, Average Loss: 4.324, avg. samples / sec: 52171.26
Iteration:   2600, Loss function: 2.958, Average Loss: 4.318, avg. samples / sec: 52171.40
Iteration:   2600, Loss function: 5.102, Average Loss: 4.319, avg. samples / sec: 52151.92
Iteration:   2600, Loss function: 3.135, Average Loss: 4.350, avg. samples / sec: 52137.08
Iteration:   2600, Loss function: 3.678, Average Loss: 4.304, avg. samples / sec: 52150.16
Iteration:   2600, Loss function: 3.777, Average Loss: 4.336, avg. samples / sec: 52152.54
Iteration:   2600, Loss function: 4.085, Average Loss: 4.343, avg. samples / sec: 52121.17
Iteration:   2600, Loss function: 3.609, Average Loss: 4.341, avg. samples / sec: 52162.21
Iteration:   2600, Loss function: 3.674, Average Loss: 4.318, avg. samples / sec: 51875.27
Iteration:   2600, Loss function: 3.381, Average Loss: 4.319, avg. samples / sec: 52190.04
Iteration:   2600, Loss function: 4.088, Average Loss: 4.341, avg. samples / sec: 52179.49
Iteration:   2600, Loss function: 4.601, Average Loss: 4.341, avg. samples / sec: 52168.60
Iteration:   2600, Loss function: 4.419, Average Loss: 4.332, avg. samples / sec: 52198.68
Iteration:   2600, Loss function: 4.257, Average Loss: 4.341, avg. samples / sec: 52169.66
Iteration:   2600, Loss function: 3.958, Average Loss: 4.345, avg. samples / sec: 52173.00
Iteration:   2600, Loss function: 3.951, Average Loss: 4.334, avg. samples / sec: 52159.48
Iteration:   2600, Loss function: 3.123, Average Loss: 4.337, avg. samples / sec: 52150.93
Iteration:   2600, Loss function: 3.506, Average Loss: 4.351, avg. samples / sec: 52169.54
Iteration:   2600, Loss function: 3.404, Average Loss: 4.342, avg. samples / sec: 52158.33
Iteration:   2600, Loss function: 3.466, Average Loss: 4.302, avg. samples / sec: 52180.84
Iteration:   2600, Loss function: 3.956, Average Loss: 4.338, avg. samples / sec: 52149.81
Iteration:   2600, Loss function: 5.265, Average Loss: 4.318, avg. samples / sec: 52138.72
Iteration:   2600, Loss function: 4.841, Average Loss: 4.340, avg. samples / sec: 52048.85
Iteration:   2620, Loss function: 3.866, Average Loss: 4.328, avg. samples / sec: 52506.09
Iteration:   2620, Loss function: 2.566, Average Loss: 4.342, avg. samples / sec: 52422.07
Iteration:   2620, Loss function: 3.035, Average Loss: 4.331, avg. samples / sec: 52499.74
Iteration:   2620, Loss function: 4.041, Average Loss: 4.328, avg. samples / sec: 52461.92
Iteration:   2620, Loss function: 3.753, Average Loss: 4.315, avg. samples / sec: 52454.89
Iteration:   2620, Loss function: 4.279, Average Loss: 4.323, avg. samples / sec: 52453.15
Iteration:   2620, Loss function: 2.989, Average Loss: 4.315, avg. samples / sec: 52455.11
Iteration:   2620, Loss function: 5.386, Average Loss: 4.320, avg. samples / sec: 52432.16
Iteration:   2620, Loss function: 4.103, Average Loss: 4.311, avg. samples / sec: 52403.69
Iteration:   2620, Loss function: 3.747, Average Loss: 4.340, avg. samples / sec: 52464.50
Iteration:   2620, Loss function: 4.210, Average Loss: 4.344, avg. samples / sec: 52438.71
Iteration:   2620, Loss function: 4.297, Average Loss: 4.305, avg. samples / sec: 52441.77
Iteration:   2620, Loss function: 3.914, Average Loss: 4.325, avg. samples / sec: 52419.65
Iteration:   2620, Loss function: 4.073, Average Loss: 4.313, avg. samples / sec: 52185.89
Iteration:   2620, Loss function: 5.308, Average Loss: 4.312, avg. samples / sec: 52440.54
Iteration:   2620, Loss function: 4.572, Average Loss: 4.302, avg. samples / sec: 52240.52
Iteration:   2620, Loss function: 4.272, Average Loss: 4.310, avg. samples / sec: 52394.71
Iteration:   2620, Loss function: 2.840, Average Loss: 4.333, avg. samples / sec: 52544.76
Iteration:   2620, Loss function: 3.553, Average Loss: 4.330, avg. samples / sec: 52441.87
Iteration:   2620, Loss function: 4.091, Average Loss: 4.335, avg. samples / sec: 52387.31
Iteration:   2620, Loss function: 3.561, Average Loss: 4.336, avg. samples / sec: 52397.94
Iteration:   2620, Loss function: 4.222, Average Loss: 4.336, avg. samples / sec: 52411.27
Iteration:   2620, Loss function: 3.942, Average Loss: 4.332, avg. samples / sec: 52423.28
Iteration:   2620, Loss function: 3.462, Average Loss: 4.342, avg. samples / sec: 52404.08
Iteration:   2620, Loss function: 4.286, Average Loss: 4.302, avg. samples / sec: 52406.40
Iteration:   2620, Loss function: 4.309, Average Loss: 4.332, avg. samples / sec: 52429.95
Iteration:   2620, Loss function: 3.381, Average Loss: 4.341, avg. samples / sec: 52392.60
Iteration:   2620, Loss function: 3.606, Average Loss: 4.313, avg. samples / sec: 52440.21
Iteration:   2620, Loss function: 3.965, Average Loss: 4.326, avg. samples / sec: 52368.33
Iteration:   2620, Loss function: 2.585, Average Loss: 4.326, avg. samples / sec: 52373.29
Iteration:   2640, Loss function: 4.348, Average Loss: 4.308, avg. samples / sec: 52774.98
Iteration:   2640, Loss function: 4.042, Average Loss: 4.303, avg. samples / sec: 52821.82
Iteration:   2640, Loss function: 4.029, Average Loss: 4.322, avg. samples / sec: 52506.58
Iteration:   2640, Loss function: 3.830, Average Loss: 4.319, avg. samples / sec: 52511.51
Iteration:   2640, Loss function: 3.939, Average Loss: 4.334, avg. samples / sec: 52478.02
Iteration:   2640, Loss function: 4.961, Average Loss: 4.307, avg. samples / sec: 52518.09
Iteration:   2640, Loss function: 3.898, Average Loss: 4.314, avg. samples / sec: 52506.66
Iteration:   2640, Loss function: 4.834, Average Loss: 4.308, avg. samples / sec: 52495.94
Iteration:   2640, Loss function: 5.248, Average Loss: 4.340, avg. samples / sec: 52503.96
Iteration:   2640, Loss function: 3.784, Average Loss: 4.314, avg. samples / sec: 52495.02
Iteration:   2640, Loss function: 5.064, Average Loss: 4.324, avg. samples / sec: 52450.69
Iteration:   2640, Loss function: 4.605, Average Loss: 4.344, avg. samples / sec: 52487.85
Iteration:   2640, Loss function: 4.037, Average Loss: 4.318, avg. samples / sec: 52493.79
Iteration:   2640, Loss function: 3.480, Average Loss: 4.304, avg. samples / sec: 52447.47
Iteration:   2640, Loss function: 4.226, Average Loss: 4.324, avg. samples / sec: 52347.01
Iteration:   2640, Loss function: 4.056, Average Loss: 4.314, avg. samples / sec: 52472.39
Iteration:   2640, Loss function: 4.816, Average Loss: 4.331, avg. samples / sec: 52537.82
Iteration:   2640, Loss function: 3.615, Average Loss: 4.326, avg. samples / sec: 52527.41
Iteration:   2640, Loss function: 3.894, Average Loss: 4.331, avg. samples / sec: 52543.17
Iteration:   2640, Loss function: 4.469, Average Loss: 4.301, avg. samples / sec: 52497.61
Iteration:   2640, Loss function: 4.231, Average Loss: 4.326, avg. samples / sec: 52516.54
Iteration:   2640, Loss function: 3.946, Average Loss: 4.329, avg. samples / sec: 52543.41
Iteration:   2640, Loss function: 4.458, Average Loss: 4.338, avg. samples / sec: 52532.12
Iteration:   2640, Loss function: 4.225, Average Loss: 4.333, avg. samples / sec: 52513.78
Iteration:   2640, Loss function: 3.762, Average Loss: 4.300, avg. samples / sec: 52537.82
Iteration:   2640, Loss function: 3.204, Average Loss: 4.321, avg. samples / sec: 52557.16
Iteration:   2640, Loss function: 3.772, Average Loss: 4.326, avg. samples / sec: 52536.14
Iteration:   2640, Loss function: 4.431, Average Loss: 4.336, avg. samples / sec: 52535.22
Iteration:   2640, Loss function: 4.058, Average Loss: 4.320, avg. samples / sec: 52539.04
Iteration:   2640, Loss function: 5.243, Average Loss: 4.309, avg. samples / sec: 52510.91
:::MLL 1558640653.010 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558640653.011 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 4.543, Average Loss: 4.299, avg. samples / sec: 52125.30
Iteration:   2660, Loss function: 4.250, Average Loss: 4.303, avg. samples / sec: 52207.64
Iteration:   2660, Loss function: 3.179, Average Loss: 4.315, avg. samples / sec: 52408.50
Iteration:   2660, Loss function: 4.484, Average Loss: 4.314, avg. samples / sec: 52241.60
Iteration:   2660, Loss function: 4.830, Average Loss: 4.336, avg. samples / sec: 52263.34
Iteration:   2660, Loss function: 4.317, Average Loss: 4.312, avg. samples / sec: 52252.31
Iteration:   2660, Loss function: 3.754, Average Loss: 4.300, avg. samples / sec: 52215.33
Iteration:   2660, Loss function: 3.091, Average Loss: 4.336, avg. samples / sec: 52201.83
Iteration:   2660, Loss function: 3.151, Average Loss: 4.307, avg. samples / sec: 52196.19
Iteration:   2660, Loss function: 4.283, Average Loss: 4.340, avg. samples / sec: 52214.93
Iteration:   2660, Loss function: 4.315, Average Loss: 4.307, avg. samples / sec: 52200.21
Iteration:   2660, Loss function: 4.484, Average Loss: 4.313, avg. samples / sec: 52177.23
Iteration:   2660, Loss function: 4.614, Average Loss: 4.315, avg. samples / sec: 52127.69
Iteration:   2660, Loss function: 4.389, Average Loss: 4.295, avg. samples / sec: 52229.23
Iteration:   2660, Loss function: 3.633, Average Loss: 4.318, avg. samples / sec: 52181.15
Iteration:   2660, Loss function: 2.102, Average Loss: 4.321, avg. samples / sec: 52370.60
Iteration:   2660, Loss function: 3.700, Average Loss: 4.295, avg. samples / sec: 52284.05
Iteration:   2660, Loss function: 4.695, Average Loss: 4.320, avg. samples / sec: 52284.14
Iteration:   2660, Loss function: 4.148, Average Loss: 4.324, avg. samples / sec: 52258.96
Iteration:   2660, Loss function: 4.059, Average Loss: 4.325, avg. samples / sec: 52240.52
Iteration:   2660, Loss function: 4.180, Average Loss: 4.320, avg. samples / sec: 52240.52
Iteration:   2660, Loss function: 4.097, Average Loss: 4.295, avg. samples / sec: 52261.34
Iteration:   2660, Loss function: 4.025, Average Loss: 4.310, avg. samples / sec: 52297.92
Iteration:   2660, Loss function: 4.871, Average Loss: 4.326, avg. samples / sec: 52252.27
Iteration:   2660, Loss function: 4.820, Average Loss: 4.308, avg. samples / sec: 52192.13
Iteration:   2660, Loss function: 3.664, Average Loss: 4.325, avg. samples / sec: 52198.80
Iteration:   2660, Loss function: 2.464, Average Loss: 4.323, avg. samples / sec: 52176.42
Iteration:   2660, Loss function: 4.034, Average Loss: 4.333, avg. samples / sec: 52185.06
Iteration:   2660, Loss function: 4.101, Average Loss: 4.334, avg. samples / sec: 52155.02
Iteration:   2660, Loss function: 4.077, Average Loss: 4.315, avg. samples / sec: 52187.26
Iteration:   2680, Loss function: 4.375, Average Loss: 4.302, avg. samples / sec: 52536.06
Iteration:   2680, Loss function: 4.056, Average Loss: 4.297, avg. samples / sec: 52494.63
Iteration:   2680, Loss function: 4.672, Average Loss: 4.331, avg. samples / sec: 52468.19
Iteration:   2680, Loss function: 3.745, Average Loss: 4.292, avg. samples / sec: 52472.62
Iteration:   2680, Loss function: 5.427, Average Loss: 4.310, avg. samples / sec: 52412.69
Iteration:   2680, Loss function: 3.142, Average Loss: 4.298, avg. samples / sec: 52484.55
Iteration:   2680, Loss function: 4.012, Average Loss: 4.331, avg. samples / sec: 52465.73
Iteration:   2680, Loss function: 2.913, Average Loss: 4.333, avg. samples / sec: 52486.11
Iteration:   2680, Loss function: 4.912, Average Loss: 4.311, avg. samples / sec: 52405.87
Iteration:   2680, Loss function: 4.146, Average Loss: 4.290, avg. samples / sec: 52507.82
Iteration:   2680, Loss function: 3.446, Average Loss: 4.311, avg. samples / sec: 52413.84
Iteration:   2680, Loss function: 4.238, Average Loss: 4.310, avg. samples / sec: 52426.75
Iteration:   2680, Loss function: 4.707, Average Loss: 4.308, avg. samples / sec: 52400.88
Iteration:   2680, Loss function: 3.245, Average Loss: 4.308, avg. samples / sec: 52447.55
Iteration:   2680, Loss function: 3.404, Average Loss: 4.312, avg. samples / sec: 52531.97
Iteration:   2680, Loss function: 3.716, Average Loss: 4.319, avg. samples / sec: 52417.67
Iteration:   2680, Loss function: 3.515, Average Loss: 4.298, avg. samples / sec: 52475.28
Iteration:   2680, Loss function: 4.844, Average Loss: 4.315, avg. samples / sec: 52473.62
Iteration:   2680, Loss function: 4.872, Average Loss: 4.316, avg. samples / sec: 52427.34
Iteration:   2680, Loss function: 4.101, Average Loss: 4.329, avg. samples / sec: 52537.53
Iteration:   2680, Loss function: 4.745, Average Loss: 4.322, avg. samples / sec: 52440.62
Iteration:   2680, Loss function: 4.282, Average Loss: 4.315, avg. samples / sec: 52381.25
Iteration:   2680, Loss function: 2.761, Average Loss: 4.289, avg. samples / sec: 52367.24
Iteration:   2680, Loss function: 4.848, Average Loss: 4.326, avg. samples / sec: 52493.05
Iteration:   2680, Loss function: 4.421, Average Loss: 4.307, avg. samples / sec: 52407.16
Iteration:   2680, Loss function: 4.160, Average Loss: 4.313, avg. samples / sec: 52289.44
Iteration:   2680, Loss function: 4.572, Average Loss: 4.310, avg. samples / sec: 52495.79
Iteration:   2680, Loss function: 3.791, Average Loss: 4.289, avg. samples / sec: 52390.29
Iteration:   2680, Loss function: 4.615, Average Loss: 4.314, avg. samples / sec: 52248.88
Iteration:   2680, Loss function: 4.081, Average Loss: 4.301, avg. samples / sec: 52207.48
Iteration:   2700, Loss function: 4.112, Average Loss: 4.300, avg. samples / sec: 52641.42
Iteration:   2700, Loss function: 4.587, Average Loss: 4.308, avg. samples / sec: 52782.89
Iteration:   2700, Loss function: 4.250, Average Loss: 4.294, avg. samples / sec: 52553.30
Iteration:   2700, Loss function: 5.312, Average Loss: 4.308, avg. samples / sec: 52948.14
Iteration:   2700, Loss function: 4.586, Average Loss: 4.299, avg. samples / sec: 52665.84
Iteration:   2700, Loss function: 4.645, Average Loss: 4.325, avg. samples / sec: 52629.90
Iteration:   2700, Loss function: 4.335, Average Loss: 4.305, avg. samples / sec: 52772.88
Iteration:   2700, Loss function: 4.654, Average Loss: 4.331, avg. samples / sec: 52665.72
Iteration:   2700, Loss function: 5.033, Average Loss: 4.303, avg. samples / sec: 52707.77
Iteration:   2700, Loss function: 4.503, Average Loss: 4.310, avg. samples / sec: 52650.98
Iteration:   2700, Loss function: 3.324, Average Loss: 4.294, avg. samples / sec: 52936.38
Iteration:   2700, Loss function: 4.132, Average Loss: 4.289, avg. samples / sec: 52627.78
Iteration:   2700, Loss function: 4.049, Average Loss: 4.286, avg. samples / sec: 52654.99
Iteration:   2700, Loss function: 3.590, Average Loss: 4.303, avg. samples / sec: 52647.77
Iteration:   2700, Loss function: 3.330, Average Loss: 4.326, avg. samples / sec: 52628.96
Iteration:   2700, Loss function: 4.512, Average Loss: 4.292, avg. samples / sec: 52705.11
Iteration:   2700, Loss function: 4.184, Average Loss: 4.305, avg. samples / sec: 52687.04
Iteration:   2700, Loss function: 3.715, Average Loss: 4.306, avg. samples / sec: 52661.56
Iteration:   2700, Loss function: 4.520, Average Loss: 4.306, avg. samples / sec: 52660.38
Iteration:   2700, Loss function: 4.430, Average Loss: 4.313, avg. samples / sec: 52704.42
Iteration:   2700, Loss function: 2.923, Average Loss: 4.310, avg. samples / sec: 52660.17
Iteration:   2700, Loss function: 3.831, Average Loss: 4.284, avg. samples / sec: 52681.78
Iteration:   2700, Loss function: 3.382, Average Loss: 4.310, avg. samples / sec: 52634.30
Iteration:   2700, Loss function: 3.815, Average Loss: 4.318, avg. samples / sec: 52645.24
Iteration:   2700, Loss function: 3.356, Average Loss: 4.307, avg. samples / sec: 52652.16
Iteration:   2700, Loss function: 5.272, Average Loss: 4.307, avg. samples / sec: 52668.96
Iteration:   2700, Loss function: 3.222, Average Loss: 4.288, avg. samples / sec: 52676.58
Iteration:   2700, Loss function: 3.575, Average Loss: 4.325, avg. samples / sec: 52646.02
Iteration:   2700, Loss function: 4.091, Average Loss: 4.302, avg. samples / sec: 52651.59
Iteration:   2700, Loss function: 4.026, Average Loss: 4.328, avg. samples / sec: 52573.20
Iteration:   2720, Loss function: 4.484, Average Loss: 4.298, avg. samples / sec: 52595.08
Iteration:   2720, Loss function: 5.315, Average Loss: 4.288, avg. samples / sec: 52637.39
Iteration:   2720, Loss function: 4.456, Average Loss: 4.307, avg. samples / sec: 52552.60
Iteration:   2720, Loss function: 5.102, Average Loss: 4.292, avg. samples / sec: 52591.98
Iteration:   2720, Loss function: 4.713, Average Loss: 4.324, avg. samples / sec: 52590.21
Iteration:   2720, Loss function: 3.099, Average Loss: 4.302, avg. samples / sec: 52624.26
Iteration:   2720, Loss function: 4.645, Average Loss: 4.298, avg. samples / sec: 52574.49
Iteration:   2720, Loss function: 3.400, Average Loss: 4.296, avg. samples / sec: 52570.40
Iteration:   2720, Loss function: 4.468, Average Loss: 4.302, avg. samples / sec: 52550.44
Iteration:   2720, Loss function: 4.359, Average Loss: 4.288, avg. samples / sec: 52575.97
Iteration:   2720, Loss function: 3.151, Average Loss: 4.279, avg. samples / sec: 52571.34
Iteration:   2720, Loss function: 4.524, Average Loss: 4.323, avg. samples / sec: 52595.53
Iteration:   2720, Loss function: 3.675, Average Loss: 4.309, avg. samples / sec: 52551.30
Iteration:   2720, Loss function: 3.000, Average Loss: 4.315, avg. samples / sec: 52535.77
Iteration:   2720, Loss function: 3.694, Average Loss: 4.281, avg. samples / sec: 52487.30
Iteration:   2720, Loss function: 4.113, Average Loss: 4.289, avg. samples / sec: 52540.25
Iteration:   2720, Loss function: 4.296, Average Loss: 4.302, avg. samples / sec: 52604.74
Iteration:   2720, Loss function: 4.079, Average Loss: 4.308, avg. samples / sec: 52593.51
Iteration:   2720, Loss function: 4.796, Average Loss: 4.304, avg. samples / sec: 52541.49
Iteration:   2720, Loss function: 3.364, Average Loss: 4.304, avg. samples / sec: 52570.67
Iteration:   2720, Loss function: 3.465, Average Loss: 4.318, avg. samples / sec: 52611.39
Iteration:   2720, Loss function: 2.996, Average Loss: 4.286, avg. samples / sec: 52587.03
Iteration:   2720, Loss function: 3.700, Average Loss: 4.308, avg. samples / sec: 52548.01
Iteration:   2720, Loss function: 4.226, Average Loss: 4.307, avg. samples / sec: 52576.24
Iteration:   2720, Loss function: 3.792, Average Loss: 4.303, avg. samples / sec: 52549.50
Iteration:   2720, Loss function: 3.817, Average Loss: 4.295, avg. samples / sec: 52602.38
Iteration:   2720, Loss function: 4.409, Average Loss: 4.282, avg. samples / sec: 52541.82
Iteration:   2720, Loss function: 3.743, Average Loss: 4.303, avg. samples / sec: 52526.51
Iteration:   2720, Loss function: 4.875, Average Loss: 4.328, avg. samples / sec: 52611.47
Iteration:   2720, Loss function: 4.636, Average Loss: 4.303, avg. samples / sec: 52537.98
:::MLL 1558640655.251 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558640655.252 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 4.518, Average Loss: 4.295, avg. samples / sec: 52236.66
Iteration:   2740, Loss function: 3.685, Average Loss: 4.281, avg. samples / sec: 52094.12
Iteration:   2740, Loss function: 3.654, Average Loss: 4.292, avg. samples / sec: 51983.67
Iteration:   2740, Loss function: 2.850, Average Loss: 4.292, avg. samples / sec: 52074.01
Iteration:   2740, Loss function: 4.053, Average Loss: 4.299, avg. samples / sec: 52106.03
Iteration:   2740, Loss function: 4.833, Average Loss: 4.291, avg. samples / sec: 52072.06
Iteration:   2740, Loss function: 3.196, Average Loss: 4.298, avg. samples / sec: 52055.46
Iteration:   2740, Loss function: 4.655, Average Loss: 4.325, avg. samples / sec: 52052.04
Iteration:   2740, Loss function: 3.055, Average Loss: 4.269, avg. samples / sec: 52084.98
Iteration:   2740, Loss function: 4.237, Average Loss: 4.308, avg. samples / sec: 52085.98
Iteration:   2740, Loss function: 3.764, Average Loss: 4.290, avg. samples / sec: 52050.31
Iteration:   2740, Loss function: 4.372, Average Loss: 4.299, avg. samples / sec: 52068.93
Iteration:   2740, Loss function: 4.661, Average Loss: 4.286, avg. samples / sec: 52052.39
Iteration:   2740, Loss function: 4.232, Average Loss: 4.318, avg. samples / sec: 52032.57
Iteration:   2740, Loss function: 3.939, Average Loss: 4.270, avg. samples / sec: 52110.30
Iteration:   2740, Loss function: 4.102, Average Loss: 4.285, avg. samples / sec: 52061.87
Iteration:   2740, Loss function: 3.740, Average Loss: 4.301, avg. samples / sec: 52077.24
Iteration:   2740, Loss function: 4.115, Average Loss: 4.301, avg. samples / sec: 52064.33
Iteration:   2740, Loss function: 3.799, Average Loss: 4.295, avg. samples / sec: 52052.64
Iteration:   2740, Loss function: 3.625, Average Loss: 4.301, avg. samples / sec: 52087.02
Iteration:   2740, Loss function: 3.947, Average Loss: 4.296, avg. samples / sec: 52059.89
Iteration:   2740, Loss function: 4.836, Average Loss: 4.312, avg. samples / sec: 52062.60
Iteration:   2740, Loss function: 3.219, Average Loss: 4.301, avg. samples / sec: 52078.78
Iteration:   2740, Loss function: 4.139, Average Loss: 4.302, avg. samples / sec: 52046.22
Iteration:   2740, Loss function: 5.084, Average Loss: 4.321, avg. samples / sec: 52091.33
Iteration:   2740, Loss function: 3.750, Average Loss: 4.272, avg. samples / sec: 52074.41
Iteration:   2740, Loss function: 4.519, Average Loss: 4.296, avg. samples / sec: 52074.47
Iteration:   2740, Loss function: 2.586, Average Loss: 4.299, avg. samples / sec: 52087.65
Iteration:   2740, Loss function: 4.258, Average Loss: 4.284, avg. samples / sec: 52057.33
Iteration:   2740, Loss function: 3.385, Average Loss: 4.279, avg. samples / sec: 52027.37
Iteration:   2760, Loss function: 5.097, Average Loss: 4.289, avg. samples / sec: 52606.25
Iteration:   2760, Loss function: 3.687, Average Loss: 4.323, avg. samples / sec: 52562.65
Iteration:   2760, Loss function: 2.977, Average Loss: 4.292, avg. samples / sec: 52522.24
Iteration:   2760, Loss function: 4.066, Average Loss: 4.287, avg. samples / sec: 52507.66
Iteration:   2760, Loss function: 3.722, Average Loss: 4.267, avg. samples / sec: 52587.31
Iteration:   2760, Loss function: 3.343, Average Loss: 4.265, avg. samples / sec: 52522.77
Iteration:   2760, Loss function: 3.954, Average Loss: 4.297, avg. samples / sec: 52333.83
Iteration:   2760, Loss function: 4.720, Average Loss: 4.288, avg. samples / sec: 52480.77
Iteration:   2760, Loss function: 3.659, Average Loss: 4.283, avg. samples / sec: 52534.18
Iteration:   2760, Loss function: 3.457, Average Loss: 4.302, avg. samples / sec: 52506.02
Iteration:   2760, Loss function: 4.210, Average Loss: 4.293, avg. samples / sec: 52517.46
Iteration:   2760, Loss function: 4.307, Average Loss: 4.289, avg. samples / sec: 52519.83
Iteration:   2760, Loss function: 4.467, Average Loss: 4.294, avg. samples / sec: 52458.60
Iteration:   2760, Loss function: 5.838, Average Loss: 4.278, avg. samples / sec: 52315.22
Iteration:   2760, Loss function: 3.959, Average Loss: 4.270, avg. samples / sec: 52612.57
Iteration:   2760, Loss function: 3.798, Average Loss: 4.314, avg. samples / sec: 52406.22
Iteration:   2760, Loss function: 3.680, Average Loss: 4.285, avg. samples / sec: 52545.27
Iteration:   2760, Loss function: 3.890, Average Loss: 4.314, avg. samples / sec: 52549.93
Iteration:   2760, Loss function: 3.869, Average Loss: 4.291, avg. samples / sec: 52500.05
Iteration:   2760, Loss function: 3.657, Average Loss: 4.286, avg. samples / sec: 52499.60
Iteration:   2760, Loss function: 4.531, Average Loss: 4.301, avg. samples / sec: 52498.80
Iteration:   2760, Loss function: 3.478, Average Loss: 4.288, avg. samples / sec: 52492.42
Iteration:   2760, Loss function: 4.070, Average Loss: 4.291, avg. samples / sec: 52489.32
Iteration:   2760, Loss function: 3.436, Average Loss: 4.292, avg. samples / sec: 52525.39
Iteration:   2760, Loss function: 3.185, Average Loss: 4.296, avg. samples / sec: 52484.13
Iteration:   2760, Loss function: 4.087, Average Loss: 4.297, avg. samples / sec: 52479.31
Iteration:   2760, Loss function: 3.866, Average Loss: 4.278, avg. samples / sec: 52530.56
Iteration:   2760, Loss function: 2.635, Average Loss: 4.298, avg. samples / sec: 52488.06
Iteration:   2760, Loss function: 3.910, Average Loss: 4.279, avg. samples / sec: 52501.63
Iteration:   2760, Loss function: 5.570, Average Loss: 4.291, avg. samples / sec: 52490.35
Iteration:   2780, Loss function: 3.948, Average Loss: 4.287, avg. samples / sec: 52427.20
Iteration:   2780, Loss function: 3.520, Average Loss: 4.272, avg. samples / sec: 52674.24
Iteration:   2780, Loss function: 3.505, Average Loss: 4.256, avg. samples / sec: 52498.37
Iteration:   2780, Loss function: 4.331, Average Loss: 4.293, avg. samples / sec: 52503.92
Iteration:   2780, Loss function: 4.031, Average Loss: 4.293, avg. samples / sec: 52474.34
Iteration:   2780, Loss function: 3.848, Average Loss: 4.295, avg. samples / sec: 52520.20
Iteration:   2780, Loss function: 3.699, Average Loss: 4.311, avg. samples / sec: 52662.67
Iteration:   2780, Loss function: 3.655, Average Loss: 4.317, avg. samples / sec: 52431.28
Iteration:   2780, Loss function: 2.407, Average Loss: 4.289, avg. samples / sec: 52502.36
Iteration:   2780, Loss function: 3.975, Average Loss: 4.293, avg. samples / sec: 52506.90
Iteration:   2780, Loss function: 4.507, Average Loss: 4.286, avg. samples / sec: 52457.29
Iteration:   2780, Loss function: 3.771, Average Loss: 4.279, avg. samples / sec: 52481.38
Iteration:   2780, Loss function: 4.757, Average Loss: 4.285, avg. samples / sec: 52458.33
Iteration:   2780, Loss function: 5.678, Average Loss: 4.263, avg. samples / sec: 52451.75
Iteration:   2780, Loss function: 4.266, Average Loss: 4.284, avg. samples / sec: 52473.27
Iteration:   2780, Loss function: 4.012, Average Loss: 4.287, avg. samples / sec: 52467.90
Iteration:   2780, Loss function: 3.535, Average Loss: 4.287, avg. samples / sec: 52536.30
Iteration:   2780, Loss function: 4.227, Average Loss: 4.267, avg. samples / sec: 52434.54
Iteration:   2780, Loss function: 4.066, Average Loss: 4.293, avg. samples / sec: 52542.05
Iteration:   2780, Loss function: 5.609, Average Loss: 4.283, avg. samples / sec: 52524.47
Iteration:   2780, Loss function: 3.917, Average Loss: 4.291, avg. samples / sec: 52526.84
Iteration:   2780, Loss function: 4.176, Average Loss: 4.297, avg. samples / sec: 52529.11
Iteration:   2780, Loss function: 4.503, Average Loss: 4.294, avg. samples / sec: 52512.43
Iteration:   2780, Loss function: 4.548, Average Loss: 4.286, avg. samples / sec: 52499.07
Iteration:   2780, Loss function: 3.653, Average Loss: 4.281, avg. samples / sec: 52510.10
Iteration:   2780, Loss function: 3.538, Average Loss: 4.273, avg. samples / sec: 52494.24
Iteration:   2780, Loss function: 3.120, Average Loss: 4.282, avg. samples / sec: 52472.61
Iteration:   2780, Loss function: 4.707, Average Loss: 4.304, avg. samples / sec: 52431.76
Iteration:   2780, Loss function: 4.454, Average Loss: 4.284, avg. samples / sec: 52510.89
Iteration:   2780, Loss function: 5.198, Average Loss: 4.273, avg. samples / sec: 52490.82
:::MLL 1558640657.496 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558640657.496 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 4.915, Average Loss: 4.280, avg. samples / sec: 52393.66
Iteration:   2800, Loss function: 2.931, Average Loss: 4.270, avg. samples / sec: 52370.72
Iteration:   2800, Loss function: 4.803, Average Loss: 4.285, avg. samples / sec: 52420.82
Iteration:   2800, Loss function: 2.821, Average Loss: 4.279, avg. samples / sec: 52403.38
Iteration:   2800, Loss function: 3.224, Average Loss: 4.290, avg. samples / sec: 52349.92
Iteration:   2800, Loss function: 4.158, Average Loss: 4.260, avg. samples / sec: 52389.29
Iteration:   2800, Loss function: 3.452, Average Loss: 4.284, avg. samples / sec: 52363.52
Iteration:   2800, Loss function: 4.123, Average Loss: 4.294, avg. samples / sec: 52327.86
Iteration:   2800, Loss function: 4.077, Average Loss: 4.283, avg. samples / sec: 52348.70
Iteration:   2800, Loss function: 3.508, Average Loss: 4.284, avg. samples / sec: 52335.19
Iteration:   2800, Loss function: 4.603, Average Loss: 4.310, avg. samples / sec: 52321.00
Iteration:   2800, Loss function: 3.485, Average Loss: 4.271, avg. samples / sec: 52322.07
Iteration:   2800, Loss function: 2.793, Average Loss: 4.251, avg. samples / sec: 52280.44
Iteration:   2800, Loss function: 4.241, Average Loss: 4.281, avg. samples / sec: 52313.51
Iteration:   2800, Loss function: 4.919, Average Loss: 4.306, avg. samples / sec: 52265.72
Iteration:   2800, Loss function: 4.266, Average Loss: 4.284, avg. samples / sec: 52467.74
Iteration:   2800, Loss function: 4.391, Average Loss: 4.280, avg. samples / sec: 52425.68
Iteration:   2800, Loss function: 4.439, Average Loss: 4.260, avg. samples / sec: 52402.93
Iteration:   2800, Loss function: 3.392, Average Loss: 4.293, avg. samples / sec: 52416.69
Iteration:   2800, Loss function: 4.160, Average Loss: 4.287, avg. samples / sec: 52372.24
Iteration:   2800, Loss function: 4.169, Average Loss: 4.278, avg. samples / sec: 52441.56
Iteration:   2800, Loss function: 3.704, Average Loss: 4.268, avg. samples / sec: 52427.03
Iteration:   2800, Loss function: 5.519, Average Loss: 4.281, avg. samples / sec: 52401.27
Iteration:   2800, Loss function: 3.348, Average Loss: 4.281, avg. samples / sec: 52375.90
Iteration:   2800, Loss function: 2.558, Average Loss: 4.288, avg. samples / sec: 52342.94
Iteration:   2800, Loss function: 2.384, Average Loss: 4.274, avg. samples / sec: 52330.31
Iteration:   2800, Loss function: 4.511, Average Loss: 4.277, avg. samples / sec: 52396.19
Iteration:   2800, Loss function: 5.035, Average Loss: 4.292, avg. samples / sec: 52321.35
Iteration:   2800, Loss function: 4.234, Average Loss: 4.295, avg. samples / sec: 52304.36
Iteration:   2800, Loss function: 4.827, Average Loss: 4.268, avg. samples / sec: 52293.51
Iteration:   2820, Loss function: 4.378, Average Loss: 4.265, avg. samples / sec: 52580.71
Iteration:   2820, Loss function: 3.989, Average Loss: 4.276, avg. samples / sec: 52514.25
Iteration:   2820, Loss function: 4.906, Average Loss: 4.291, avg. samples / sec: 52533.34
Iteration:   2820, Loss function: 4.320, Average Loss: 4.303, avg. samples / sec: 52571.30
Iteration:   2820, Loss function: 3.444, Average Loss: 4.276, avg. samples / sec: 52594.02
Iteration:   2820, Loss function: 4.551, Average Loss: 4.280, avg. samples / sec: 52523.78
Iteration:   2820, Loss function: 3.761, Average Loss: 4.306, avg. samples / sec: 52590.45
Iteration:   2820, Loss function: 3.433, Average Loss: 4.254, avg. samples / sec: 52500.50
Iteration:   2820, Loss function: 3.825, Average Loss: 4.291, avg. samples / sec: 52523.14
Iteration:   2820, Loss function: 4.316, Average Loss: 4.277, avg. samples / sec: 52527.07
Iteration:   2820, Loss function: 5.033, Average Loss: 4.277, avg. samples / sec: 52410.10
Iteration:   2820, Loss function: 2.977, Average Loss: 4.248, avg. samples / sec: 52535.79
Iteration:   2820, Loss function: 3.915, Average Loss: 4.273, avg. samples / sec: 52430.48
Iteration:   2820, Loss function: 3.442, Average Loss: 4.251, avg. samples / sec: 52479.58
Iteration:   2820, Loss function: 3.038, Average Loss: 4.265, avg. samples / sec: 52526.70
Iteration:   2820, Loss function: 3.831, Average Loss: 4.275, avg. samples / sec: 52413.51
Iteration:   2820, Loss function: 3.511, Average Loss: 4.269, avg. samples / sec: 52514.51
Iteration:   2820, Loss function: 3.308, Average Loss: 4.276, avg. samples / sec: 52291.50
Iteration:   2820, Loss function: 4.578, Average Loss: 4.272, avg. samples / sec: 52425.00
Iteration:   2820, Loss function: 3.827, Average Loss: 4.272, avg. samples / sec: 52457.94
Iteration:   2820, Loss function: 4.541, Average Loss: 4.292, avg. samples / sec: 52445.15
Iteration:   2820, Loss function: 3.913, Average Loss: 4.273, avg. samples / sec: 52474.66
Iteration:   2820, Loss function: 4.192, Average Loss: 4.284, avg. samples / sec: 52445.21
Iteration:   2820, Loss function: 3.136, Average Loss: 4.284, avg. samples / sec: 52486.70
Iteration:   2820, Loss function: 4.454, Average Loss: 4.273, avg. samples / sec: 52596.20
Iteration:   2820, Loss function: 2.719, Average Loss: 4.286, avg. samples / sec: 52577.52
Iteration:   2820, Loss function: 3.581, Average Loss: 4.269, avg. samples / sec: 52441.33
Iteration:   2820, Loss function: 3.937, Average Loss: 4.261, avg. samples / sec: 52430.15
Iteration:   2820, Loss function: 4.012, Average Loss: 4.285, avg. samples / sec: 52508.19
Iteration:   2820, Loss function: 4.560, Average Loss: 4.270, avg. samples / sec: 52296.89
Iteration:   2840, Loss function: 3.623, Average Loss: 4.267, avg. samples / sec: 52589.56
Iteration:   2840, Loss function: 4.104, Average Loss: 4.257, avg. samples / sec: 52496.98
Iteration:   2840, Loss function: 4.519, Average Loss: 4.290, avg. samples / sec: 52534.28
Iteration:   2840, Loss function: 5.143, Average Loss: 4.275, avg. samples / sec: 52765.95
Iteration:   2840, Loss function: 3.415, Average Loss: 4.271, avg. samples / sec: 52510.99
Iteration:   2840, Loss function: 4.657, Average Loss: 4.296, avg. samples / sec: 52531.03
Iteration:   2840, Loss function: 3.941, Average Loss: 4.238, avg. samples / sec: 52542.94
Iteration:   2840, Loss function: 3.030, Average Loss: 4.269, avg. samples / sec: 52573.46
Iteration:   2840, Loss function: 4.410, Average Loss: 4.280, avg. samples / sec: 52513.00
Iteration:   2840, Loss function: 2.208, Average Loss: 4.274, avg. samples / sec: 52524.92
Iteration:   2840, Loss function: 3.771, Average Loss: 4.265, avg. samples / sec: 52762.49
Iteration:   2840, Loss function: 4.442, Average Loss: 4.288, avg. samples / sec: 52504.76
Iteration:   2840, Loss function: 3.601, Average Loss: 4.270, avg. samples / sec: 52512.96
Iteration:   2840, Loss function: 3.754, Average Loss: 4.245, avg. samples / sec: 52491.62
Iteration:   2840, Loss function: 4.343, Average Loss: 4.269, avg. samples / sec: 52576.55
Iteration:   2840, Loss function: 4.602, Average Loss: 4.266, avg. samples / sec: 52557.57
Iteration:   2840, Loss function: 4.642, Average Loss: 4.277, avg. samples / sec: 52532.36
Iteration:   2840, Loss function: 4.258, Average Loss: 4.244, avg. samples / sec: 52504.06
Iteration:   2840, Loss function: 4.582, Average Loss: 4.270, avg. samples / sec: 52566.16
Iteration:   2840, Loss function: 4.576, Average Loss: 4.259, avg. samples / sec: 52570.73
Iteration:   2840, Loss function: 4.620, Average Loss: 4.256, avg. samples / sec: 52511.24
Iteration:   2840, Loss function: 3.592, Average Loss: 4.264, avg. samples / sec: 52528.23
Iteration:   2840, Loss function: 2.759, Average Loss: 4.279, avg. samples / sec: 52541.35
Iteration:   2840, Loss function: 4.388, Average Loss: 4.289, avg. samples / sec: 52529.36
Iteration:   2840, Loss function: 3.895, Average Loss: 4.268, avg. samples / sec: 52540.51
Iteration:   2840, Loss function: 4.156, Average Loss: 4.266, avg. samples / sec: 52519.05
Iteration:   2840, Loss function: 3.590, Average Loss: 4.279, avg. samples / sec: 52554.01
Iteration:   2840, Loss function: 5.657, Average Loss: 4.284, avg. samples / sec: 52532.44
Iteration:   2840, Loss function: 4.292, Average Loss: 4.277, avg. samples / sec: 52515.15
Iteration:   2840, Loss function: 3.457, Average Loss: 4.298, avg. samples / sec: 52238.52
Iteration:   2860, Loss function: 4.906, Average Loss: 4.249, avg. samples / sec: 53482.13
Iteration:   2860, Loss function: 5.641, Average Loss: 4.267, avg. samples / sec: 53346.37
Iteration:   2860, Loss function: 3.409, Average Loss: 4.262, avg. samples / sec: 53538.67
Iteration:   2860, Loss function: 3.331, Average Loss: 4.282, avg. samples / sec: 53541.11
Iteration:   2860, Loss function: 4.138, Average Loss: 4.276, avg. samples / sec: 53518.81
Iteration:   2860, Loss function: 4.280, Average Loss: 4.268, avg. samples / sec: 53521.84
Iteration:   2860, Loss function: 3.861, Average Loss: 4.229, avg. samples / sec: 53507.83
Iteration:   2860, Loss function: 3.780, Average Loss: 4.275, avg. samples / sec: 53467.56
Iteration:   2860, Loss function: 4.254, Average Loss: 4.242, avg. samples / sec: 53524.46
Iteration:   2860, Loss function: 6.093, Average Loss: 4.264, avg. samples / sec: 53498.02
Iteration:   2860, Loss function: 3.389, Average Loss: 4.291, avg. samples / sec: 53467.52
Iteration:   2860, Loss function: 3.260, Average Loss: 4.288, avg. samples / sec: 53400.50
Iteration:   2860, Loss function: 4.822, Average Loss: 4.265, avg. samples / sec: 53424.08
Iteration:   2860, Loss function: 3.043, Average Loss: 4.261, avg. samples / sec: 53431.45
Iteration:   2860, Loss function: 4.597, Average Loss: 4.249, avg. samples / sec: 53516.02
Iteration:   2860, Loss function: 4.921, Average Loss: 4.266, avg. samples / sec: 53461.39
Iteration:   2860, Loss function: 4.669, Average Loss: 4.262, avg. samples / sec: 53461.74
Iteration:   2860, Loss function: 4.684, Average Loss: 4.261, avg. samples / sec: 53502.86
Iteration:   2860, Loss function: 4.650, Average Loss: 4.259, avg. samples / sec: 53497.66
Iteration:   2860, Loss function: 4.079, Average Loss: 4.280, avg. samples / sec: 53504.04
Iteration:   2860, Loss function: 4.145, Average Loss: 4.278, avg. samples / sec: 53457.84
Iteration:   2860, Loss function: 4.122, Average Loss: 4.282, avg. samples / sec: 53488.68
Iteration:   2860, Loss function: 3.238, Average Loss: 4.273, avg. samples / sec: 53474.33
Iteration:   2860, Loss function: 4.185, Average Loss: 4.264, avg. samples / sec: 53453.02
Iteration:   2860, Loss function: 5.491, Average Loss: 4.261, avg. samples / sec: 53457.50
Iteration:   2860, Loss function: 4.247, Average Loss: 4.260, avg. samples / sec: 53473.12
Iteration:   2860, Loss function: 4.296, Average Loss: 4.238, avg. samples / sec: 53434.45
Iteration:   2860, Loss function: 3.612, Average Loss: 4.283, avg. samples / sec: 53450.56
Iteration:   2860, Loss function: 3.887, Average Loss: 4.293, avg. samples / sec: 53480.32
Iteration:   2860, Loss function: 3.199, Average Loss: 4.275, avg. samples / sec: 53326.40
:::MLL 1558640659.716 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558640659.716 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 4.654, Average Loss: 4.263, avg. samples / sec: 54312.00
Iteration:   2880, Loss function: 4.298, Average Loss: 4.246, avg. samples / sec: 54178.62
Iteration:   2880, Loss function: 3.829, Average Loss: 4.267, avg. samples / sec: 54263.88
Iteration:   2880, Loss function: 4.799, Average Loss: 4.252, avg. samples / sec: 54200.02
Iteration:   2880, Loss function: 3.331, Average Loss: 4.259, avg. samples / sec: 54244.66
Iteration:   2880, Loss function: 3.440, Average Loss: 4.256, avg. samples / sec: 54279.70
Iteration:   2880, Loss function: 2.710, Average Loss: 4.259, avg. samples / sec: 54199.81
Iteration:   2880, Loss function: 3.091, Average Loss: 4.225, avg. samples / sec: 54194.93
Iteration:   2880, Loss function: 4.036, Average Loss: 4.258, avg. samples / sec: 54273.10
Iteration:   2880, Loss function: 3.757, Average Loss: 4.270, avg. samples / sec: 54194.27
Iteration:   2880, Loss function: 3.604, Average Loss: 4.284, avg. samples / sec: 54208.48
Iteration:   2880, Loss function: 3.592, Average Loss: 4.276, avg. samples / sec: 54166.52
Iteration:   2880, Loss function: 2.686, Average Loss: 4.236, avg. samples / sec: 54183.16
Iteration:   2880, Loss function: 4.358, Average Loss: 4.278, avg. samples / sec: 54206.61
Iteration:   2880, Loss function: 3.519, Average Loss: 4.258, avg. samples / sec: 54216.80
Iteration:   2880, Loss function: 4.715, Average Loss: 4.265, avg. samples / sec: 54249.03
Iteration:   2880, Loss function: 3.937, Average Loss: 4.270, avg. samples / sec: 54243.27
Iteration:   2880, Loss function: 4.184, Average Loss: 4.277, avg. samples / sec: 54241.14
Iteration:   2880, Loss function: 3.575, Average Loss: 4.245, avg. samples / sec: 54190.81
Iteration:   2880, Loss function: 3.533, Average Loss: 4.274, avg. samples / sec: 54219.18
Iteration:   2880, Loss function: 4.101, Average Loss: 4.281, avg. samples / sec: 54264.30
Iteration:   2880, Loss function: 3.084, Average Loss: 4.260, avg. samples / sec: 54193.58
Iteration:   2880, Loss function: 4.497, Average Loss: 4.229, avg. samples / sec: 54251.79
Iteration:   2880, Loss function: 4.463, Average Loss: 4.261, avg. samples / sec: 54203.27
Iteration:   2880, Loss function: 3.780, Average Loss: 4.255, avg. samples / sec: 54224.69
Iteration:   2880, Loss function: 3.790, Average Loss: 4.263, avg. samples / sec: 54219.37
Iteration:   2880, Loss function: 3.154, Average Loss: 4.269, avg. samples / sec: 54394.47
Iteration:   2880, Loss function: 5.226, Average Loss: 4.291, avg. samples / sec: 54246.71
Iteration:   2880, Loss function: 3.893, Average Loss: 4.257, avg. samples / sec: 54166.85
Iteration:   2880, Loss function: 4.474, Average Loss: 4.253, avg. samples / sec: 54194.91
Iteration:   2900, Loss function: 4.865, Average Loss: 4.259, avg. samples / sec: 54673.29
Iteration:   2900, Loss function: 4.150, Average Loss: 4.246, avg. samples / sec: 54699.84
Iteration:   2900, Loss function: 2.144, Average Loss: 4.273, avg. samples / sec: 54774.08
Iteration:   2900, Loss function: 4.736, Average Loss: 4.224, avg. samples / sec: 54689.88
Iteration:   2900, Loss function: 3.444, Average Loss: 4.226, avg. samples / sec: 54706.04
Iteration:   2900, Loss function: 4.236, Average Loss: 4.269, avg. samples / sec: 54679.40
Iteration:   2900, Loss function: 3.956, Average Loss: 4.281, avg. samples / sec: 54688.93
Iteration:   2900, Loss function: 4.305, Average Loss: 4.261, avg. samples / sec: 54592.45
Iteration:   2900, Loss function: 4.668, Average Loss: 4.256, avg. samples / sec: 54656.48
Iteration:   2900, Loss function: 3.518, Average Loss: 4.257, avg. samples / sec: 54666.38
Iteration:   2900, Loss function: 5.566, Average Loss: 4.274, avg. samples / sec: 54670.83
Iteration:   2900, Loss function: 3.582, Average Loss: 4.252, avg. samples / sec: 54614.77
Iteration:   2900, Loss function: 4.868, Average Loss: 4.242, avg. samples / sec: 54469.00
Iteration:   2900, Loss function: 4.657, Average Loss: 4.251, avg. samples / sec: 54614.52
Iteration:   2900, Loss function: 3.987, Average Loss: 4.240, avg. samples / sec: 54702.56
Iteration:   2900, Loss function: 3.182, Average Loss: 4.251, avg. samples / sec: 54672.40
Iteration:   2900, Loss function: 4.213, Average Loss: 4.260, avg. samples / sec: 54685.66
Iteration:   2900, Loss function: 4.962, Average Loss: 4.260, avg. samples / sec: 54654.55
Iteration:   2900, Loss function: 3.675, Average Loss: 4.263, avg. samples / sec: 54653.81
Iteration:   2900, Loss function: 3.762, Average Loss: 4.269, avg. samples / sec: 54693.68
Iteration:   2900, Loss function: 5.081, Average Loss: 4.276, avg. samples / sec: 54660.06
Iteration:   2900, Loss function: 4.714, Average Loss: 4.254, avg. samples / sec: 54694.81
Iteration:   2900, Loss function: 4.942, Average Loss: 4.259, avg. samples / sec: 54655.57
Iteration:   2900, Loss function: 2.594, Average Loss: 4.242, avg. samples / sec: 54697.31
Iteration:   2900, Loss function: 3.674, Average Loss: 4.229, avg. samples / sec: 54653.02
Iteration:   2900, Loss function: 3.917, Average Loss: 4.264, avg. samples / sec: 54634.44
Iteration:   2900, Loss function: 4.034, Average Loss: 4.268, avg. samples / sec: 54626.99
Iteration:   2900, Loss function: 4.092, Average Loss: 4.257, avg. samples / sec: 54653.62
Iteration:   2900, Loss function: 3.495, Average Loss: 4.287, avg. samples / sec: 54667.04
Iteration:   2900, Loss function: 4.301, Average Loss: 4.250, avg. samples / sec: 54608.76
Iteration:   2920, Loss function: 5.230, Average Loss: 4.256, avg. samples / sec: 54567.97
Iteration:   2920, Loss function: 3.305, Average Loss: 4.238, avg. samples / sec: 54713.39
Iteration:   2920, Loss function: 3.030, Average Loss: 4.241, avg. samples / sec: 54533.58
Iteration:   2920, Loss function: 2.925, Average Loss: 4.267, avg. samples / sec: 54606.10
Iteration:   2920, Loss function: 3.161, Average Loss: 4.261, avg. samples / sec: 54574.50
Iteration:   2920, Loss function: 3.255, Average Loss: 4.222, avg. samples / sec: 54560.39
Iteration:   2920, Loss function: 4.210, Average Loss: 4.246, avg. samples / sec: 54566.75
Iteration:   2920, Loss function: 4.082, Average Loss: 4.244, avg. samples / sec: 54591.35
Iteration:   2920, Loss function: 3.960, Average Loss: 4.269, avg. samples / sec: 54503.44
Iteration:   2920, Loss function: 3.589, Average Loss: 4.217, avg. samples / sec: 54526.89
Iteration:   2920, Loss function: 3.319, Average Loss: 4.242, avg. samples / sec: 54582.96
Iteration:   2920, Loss function: 4.151, Average Loss: 4.250, avg. samples / sec: 54541.15
Iteration:   2920, Loss function: 4.260, Average Loss: 4.262, avg. samples / sec: 54512.10
Iteration:   2920, Loss function: 4.105, Average Loss: 4.283, avg. samples / sec: 54500.66
Iteration:   2920, Loss function: 3.563, Average Loss: 4.262, avg. samples / sec: 54625.38
Iteration:   2920, Loss function: 3.905, Average Loss: 4.247, avg. samples / sec: 54584.46
Iteration:   2920, Loss function: 3.534, Average Loss: 4.239, avg. samples / sec: 54567.47
Iteration:   2920, Loss function: 4.007, Average Loss: 4.261, avg. samples / sec: 54603.35
Iteration:   2920, Loss function: 2.645, Average Loss: 4.256, avg. samples / sec: 54579.89
Iteration:   2920, Loss function: 3.295, Average Loss: 4.254, avg. samples / sec: 54579.83
Iteration:   2920, Loss function: 4.664, Average Loss: 4.253, avg. samples / sec: 54579.39
Iteration:   2920, Loss function: 3.147, Average Loss: 4.223, avg. samples / sec: 54582.96
Iteration:   2920, Loss function: 4.039, Average Loss: 4.260, avg. samples / sec: 54585.41
Iteration:   2920, Loss function: 4.874, Average Loss: 4.275, avg. samples / sec: 54563.12
Iteration:   2920, Loss function: 2.906, Average Loss: 4.250, avg. samples / sec: 54581.94
Iteration:   2920, Loss function: 4.033, Average Loss: 4.256, avg. samples / sec: 54559.80
Iteration:   2920, Loss function: 4.822, Average Loss: 4.242, avg. samples / sec: 54610.62
Iteration:   2920, Loss function: 5.060, Average Loss: 4.267, avg. samples / sec: 54554.27
Iteration:   2920, Loss function: 4.296, Average Loss: 4.237, avg. samples / sec: 54540.48
Iteration:   2920, Loss function: 3.849, Average Loss: 4.285, avg. samples / sec: 54551.01
:::MLL 1558640661.873 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558640661.874 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.973, Average Loss: 4.248, avg. samples / sec: 54262.02
Iteration:   2940, Loss function: 4.276, Average Loss: 4.266, avg. samples / sec: 54318.36
Iteration:   2940, Loss function: 3.327, Average Loss: 4.232, avg. samples / sec: 54172.81
Iteration:   2940, Loss function: 3.870, Average Loss: 4.240, avg. samples / sec: 54265.89
Iteration:   2940, Loss function: 4.665, Average Loss: 4.235, avg. samples / sec: 54235.23
Iteration:   2940, Loss function: 3.002, Average Loss: 4.211, avg. samples / sec: 54234.29
Iteration:   2940, Loss function: 4.015, Average Loss: 4.246, avg. samples / sec: 54259.85
Iteration:   2940, Loss function: 4.897, Average Loss: 4.255, avg. samples / sec: 54201.40
Iteration:   2940, Loss function: 4.879, Average Loss: 4.237, avg. samples / sec: 54204.92
Iteration:   2940, Loss function: 3.325, Average Loss: 4.257, avg. samples / sec: 54236.63
Iteration:   2940, Loss function: 4.629, Average Loss: 4.262, avg. samples / sec: 54160.65
Iteration:   2940, Loss function: 3.583, Average Loss: 4.235, avg. samples / sec: 54373.25
Iteration:   2940, Loss function: 4.660, Average Loss: 4.280, avg. samples / sec: 54239.72
Iteration:   2940, Loss function: 4.154, Average Loss: 4.237, avg. samples / sec: 54185.18
Iteration:   2940, Loss function: 4.408, Average Loss: 4.218, avg. samples / sec: 54151.33
Iteration:   2940, Loss function: 4.294, Average Loss: 4.257, avg. samples / sec: 54286.16
Iteration:   2940, Loss function: 4.236, Average Loss: 4.220, avg. samples / sec: 54332.12
Iteration:   2940, Loss function: 3.549, Average Loss: 4.271, avg. samples / sec: 54340.27
Iteration:   2940, Loss function: 4.070, Average Loss: 4.245, avg. samples / sec: 54308.38
Iteration:   2940, Loss function: 3.600, Average Loss: 4.250, avg. samples / sec: 54259.85
Iteration:   2940, Loss function: 3.572, Average Loss: 4.241, avg. samples / sec: 54308.27
Iteration:   2940, Loss function: 4.254, Average Loss: 4.250, avg. samples / sec: 54303.46
Iteration:   2940, Loss function: 3.207, Average Loss: 4.237, avg. samples / sec: 54314.32
Iteration:   2940, Loss function: 4.584, Average Loss: 4.279, avg. samples / sec: 54303.98
Iteration:   2940, Loss function: 4.456, Average Loss: 4.239, avg. samples / sec: 54281.58
Iteration:   2940, Loss function: 3.683, Average Loss: 4.236, avg. samples / sec: 54198.48
Iteration:   2940, Loss function: 5.005, Average Loss: 4.256, avg. samples / sec: 54185.85
Iteration:   2940, Loss function: 4.605, Average Loss: 4.262, avg. samples / sec: 54234.89
Iteration:   2940, Loss function: 2.574, Average Loss: 4.248, avg. samples / sec: 54195.60
Iteration:   2940, Loss function: 3.669, Average Loss: 4.257, avg. samples / sec: 54170.39
Iteration:   2960, Loss function: 5.498, Average Loss: 4.246, avg. samples / sec: 54122.30
Iteration:   2960, Loss function: 5.242, Average Loss: 4.230, avg. samples / sec: 54223.08
Iteration:   2960, Loss function: 3.819, Average Loss: 4.252, avg. samples / sec: 54204.31
Iteration:   2960, Loss function: 3.664, Average Loss: 4.260, avg. samples / sec: 54088.89
Iteration:   2960, Loss function: 3.950, Average Loss: 4.215, avg. samples / sec: 54257.61
Iteration:   2960, Loss function: 3.843, Average Loss: 4.235, avg. samples / sec: 54127.06
Iteration:   2960, Loss function: 3.762, Average Loss: 4.232, avg. samples / sec: 54121.36
Iteration:   2960, Loss function: 3.764, Average Loss: 4.207, avg. samples / sec: 54110.53
Iteration:   2960, Loss function: 4.203, Average Loss: 4.273, avg. samples / sec: 54170.50
Iteration:   2960, Loss function: 2.415, Average Loss: 4.235, avg. samples / sec: 54172.08
Iteration:   2960, Loss function: 3.336, Average Loss: 4.255, avg. samples / sec: 54124.83
Iteration:   2960, Loss function: 2.946, Average Loss: 4.239, avg. samples / sec: 54066.13
Iteration:   2960, Loss function: 4.620, Average Loss: 4.213, avg. samples / sec: 54111.59
Iteration:   2960, Loss function: 4.136, Average Loss: 4.235, avg. samples / sec: 54158.13
Iteration:   2960, Loss function: 3.134, Average Loss: 4.245, avg. samples / sec: 54114.81
Iteration:   2960, Loss function: 3.279, Average Loss: 4.230, avg. samples / sec: 53987.05
Iteration:   2960, Loss function: 4.705, Average Loss: 4.248, avg. samples / sec: 54181.72
Iteration:   2960, Loss function: 4.435, Average Loss: 4.249, avg. samples / sec: 54095.21
Iteration:   2960, Loss function: 4.500, Average Loss: 4.240, avg. samples / sec: 54058.44
Iteration:   2960, Loss function: 2.853, Average Loss: 4.246, avg. samples / sec: 54207.50
Iteration:   2960, Loss function: 3.434, Average Loss: 4.257, avg. samples / sec: 54177.20
Iteration:   2960, Loss function: 4.234, Average Loss: 4.262, avg. samples / sec: 54045.91
Iteration:   2960, Loss function: 3.819, Average Loss: 4.235, avg. samples / sec: 54110.91
Iteration:   2960, Loss function: 5.540, Average Loss: 4.240, avg. samples / sec: 54066.17
Iteration:   2960, Loss function: 4.043, Average Loss: 4.256, avg. samples / sec: 54011.22
Iteration:   2960, Loss function: 3.392, Average Loss: 4.230, avg. samples / sec: 54068.00
Iteration:   2960, Loss function: 4.189, Average Loss: 4.246, avg. samples / sec: 54132.13
Iteration:   2960, Loss function: 3.418, Average Loss: 4.233, avg. samples / sec: 53879.11
Iteration:   2960, Loss function: 3.666, Average Loss: 4.275, avg. samples / sec: 54056.76
Iteration:   2960, Loss function: 5.556, Average Loss: 4.256, avg. samples / sec: 53886.36
Iteration:   2980, Loss function: 4.034, Average Loss: 4.240, avg. samples / sec: 54629.47
Iteration:   2980, Loss function: 3.426, Average Loss: 4.228, avg. samples / sec: 54675.78
Iteration:   2980, Loss function: 3.256, Average Loss: 4.252, avg. samples / sec: 54666.17
Iteration:   2980, Loss function: 4.870, Average Loss: 4.247, avg. samples / sec: 54639.76
Iteration:   2980, Loss function: 4.349, Average Loss: 4.255, avg. samples / sec: 54988.83
Iteration:   2980, Loss function: 2.987, Average Loss: 4.228, avg. samples / sec: 54657.67
Iteration:   2980, Loss function: 5.197, Average Loss: 4.226, avg. samples / sec: 54654.57
Iteration:   2980, Loss function: 3.232, Average Loss: 4.210, avg. samples / sec: 54644.25
Iteration:   2980, Loss function: 3.529, Average Loss: 4.251, avg. samples / sec: 54728.33
Iteration:   2980, Loss function: 4.289, Average Loss: 4.230, avg. samples / sec: 54967.15
Iteration:   2980, Loss function: 3.445, Average Loss: 4.231, avg. samples / sec: 54695.15
Iteration:   2980, Loss function: 4.038, Average Loss: 4.206, avg. samples / sec: 54669.71
Iteration:   2980, Loss function: 3.188, Average Loss: 4.268, avg. samples / sec: 54648.04
Iteration:   2980, Loss function: 3.532, Average Loss: 4.239, avg. samples / sec: 54610.39
Iteration:   2980, Loss function: 3.570, Average Loss: 4.226, avg. samples / sec: 54685.77
Iteration:   2980, Loss function: 4.468, Average Loss: 4.241, avg. samples / sec: 54693.54
Iteration:   2980, Loss function: 3.577, Average Loss: 4.206, avg. samples / sec: 54624.89
Iteration:   2980, Loss function: 2.950, Average Loss: 4.238, avg. samples / sec: 54668.54
Iteration:   2980, Loss function: 4.232, Average Loss: 4.234, avg. samples / sec: 54658.79
Iteration:   2980, Loss function: 3.715, Average Loss: 4.243, avg. samples / sec: 54655.50
Iteration:   2980, Loss function: 3.497, Average Loss: 4.228, avg. samples / sec: 54686.32
Iteration:   2980, Loss function: 4.114, Average Loss: 4.231, avg. samples / sec: 54698.91
Iteration:   2980, Loss function: 4.132, Average Loss: 4.236, avg. samples / sec: 54657.56
Iteration:   2980, Loss function: 4.681, Average Loss: 4.249, avg. samples / sec: 54659.79
Iteration:   2980, Loss function: 4.790, Average Loss: 4.253, avg. samples / sec: 54659.66
Iteration:   2980, Loss function: 4.126, Average Loss: 4.236, avg. samples / sec: 54654.38
Iteration:   2980, Loss function: 4.053, Average Loss: 4.248, avg. samples / sec: 54660.57
Iteration:   2980, Loss function: 4.496, Average Loss: 4.244, avg. samples / sec: 54689.86
Iteration:   2980, Loss function: 4.106, Average Loss: 4.228, avg. samples / sec: 54647.73
Iteration:   2980, Loss function: 4.000, Average Loss: 4.265, avg. samples / sec: 54688.74
Iteration:   3000, Loss function: 3.812, Average Loss: 4.235, avg. samples / sec: 54610.14
Iteration:   3000, Loss function: 3.957, Average Loss: 4.230, avg. samples / sec: 54627.71
Iteration:   3000, Loss function: 4.481, Average Loss: 4.222, avg. samples / sec: 54584.40
Iteration:   3000, Loss function: 4.506, Average Loss: 4.204, avg. samples / sec: 54615.89
Iteration:   3000, Loss function: 3.152, Average Loss: 4.242, avg. samples / sec: 54576.38
Iteration:   3000, Loss function: 3.428, Average Loss: 4.249, avg. samples / sec: 54549.03
Iteration:   3000, Loss function: 4.024, Average Loss: 4.208, avg. samples / sec: 54582.26
Iteration:   3000, Loss function: 5.359, Average Loss: 4.222, avg. samples / sec: 54575.65
Iteration:   3000, Loss function: 3.637, Average Loss: 4.223, avg. samples / sec: 54572.33
Iteration:   3000, Loss function: 2.924, Average Loss: 4.241, avg. samples / sec: 54566.31
Iteration:   3000, Loss function: 4.893, Average Loss: 4.243, avg. samples / sec: 54552.93
Iteration:   3000, Loss function: 3.914, Average Loss: 4.225, avg. samples / sec: 54568.42
Iteration:   3000, Loss function: 3.356, Average Loss: 4.266, avg. samples / sec: 54579.17
Iteration:   3000, Loss function: 3.170, Average Loss: 4.221, avg. samples / sec: 54569.20
Iteration:   3000, Loss function: 3.310, Average Loss: 4.234, avg. samples / sec: 54568.35
Iteration:   3000, Loss function: 3.556, Average Loss: 4.227, avg. samples / sec: 54581.39
Iteration:   3000, Loss function: 4.455, Average Loss: 4.204, avg. samples / sec: 54561.30
Iteration:   3000, Loss function: 2.487, Average Loss: 4.244, avg. samples / sec: 54584.33
Iteration:   3000, Loss function: 2.902, Average Loss: 4.224, avg. samples / sec: 54575.35
Iteration:   3000, Loss function: 3.990, Average Loss: 4.232, avg. samples / sec: 54542.74
Iteration:   3000, Loss function: 3.483, Average Loss: 4.252, avg. samples / sec: 54582.05
Iteration:   3000, Loss function: 4.515, Average Loss: 4.236, avg. samples / sec: 54584.44
Iteration:   3000, Loss function: 4.419, Average Loss: 4.227, avg. samples / sec: 54577.29
Iteration:   3000, Loss function: 3.457, Average Loss: 4.235, avg. samples / sec: 54546.22
Iteration:   3000, Loss function: 3.919, Average Loss: 4.237, avg. samples / sec: 54455.38
Iteration:   3000, Loss function: 3.690, Average Loss: 4.221, avg. samples / sec: 54581.46
Iteration:   3000, Loss function: 3.684, Average Loss: 4.227, avg. samples / sec: 54543.12
Iteration:   3000, Loss function: 3.100, Average Loss: 4.236, avg. samples / sec: 54561.34
Iteration:   3000, Loss function: 4.317, Average Loss: 4.263, avg. samples / sec: 54569.39
Iteration:   3000, Loss function: 4.289, Average Loss: 4.243, avg. samples / sec: 54519.42
:::MLL 1558640664.036 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558640664.037 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 4.232, Average Loss: 4.228, avg. samples / sec: 54191.37
Iteration:   3020, Loss function: 4.194, Average Loss: 4.222, avg. samples / sec: 54175.35
Iteration:   3020, Loss function: 3.803, Average Loss: 4.218, avg. samples / sec: 54230.32
Iteration:   3020, Loss function: 2.626, Average Loss: 4.238, avg. samples / sec: 54199.83
Iteration:   3020, Loss function: 4.093, Average Loss: 4.235, avg. samples / sec: 54210.67
Iteration:   3020, Loss function: 3.298, Average Loss: 4.201, avg. samples / sec: 54179.89
Iteration:   3020, Loss function: 3.616, Average Loss: 4.196, avg. samples / sec: 54171.52
Iteration:   3020, Loss function: 2.629, Average Loss: 4.258, avg. samples / sec: 54225.27
Iteration:   3020, Loss function: 3.876, Average Loss: 4.245, avg. samples / sec: 54175.16
Iteration:   3020, Loss function: 5.007, Average Loss: 4.219, avg. samples / sec: 54178.20
Iteration:   3020, Loss function: 3.306, Average Loss: 4.237, avg. samples / sec: 54185.02
Iteration:   3020, Loss function: 4.726, Average Loss: 4.224, avg. samples / sec: 54174.37
Iteration:   3020, Loss function: 5.402, Average Loss: 4.217, avg. samples / sec: 54121.32
Iteration:   3020, Loss function: 3.621, Average Loss: 4.204, avg. samples / sec: 54325.06
Iteration:   3020, Loss function: 3.884, Average Loss: 4.217, avg. samples / sec: 54212.93
Iteration:   3020, Loss function: 3.728, Average Loss: 4.223, avg. samples / sec: 54202.27
Iteration:   3020, Loss function: 3.538, Average Loss: 4.236, avg. samples / sec: 54222.96
Iteration:   3020, Loss function: 4.420, Average Loss: 4.236, avg. samples / sec: 54232.56
Iteration:   3020, Loss function: 4.159, Average Loss: 4.227, avg. samples / sec: 54216.28
Iteration:   3020, Loss function: 4.843, Average Loss: 4.219, avg. samples / sec: 54200.06
Iteration:   3020, Loss function: 4.064, Average Loss: 4.238, avg. samples / sec: 54281.33
Iteration:   3020, Loss function: 3.529, Average Loss: 4.249, avg. samples / sec: 54197.52
Iteration:   3020, Loss function: 4.220, Average Loss: 4.230, avg. samples / sec: 54206.21
Iteration:   3020, Loss function: 4.995, Average Loss: 4.232, avg. samples / sec: 54185.20
Iteration:   3020, Loss function: 2.912, Average Loss: 4.234, avg. samples / sec: 54219.52
Iteration:   3020, Loss function: 3.930, Average Loss: 4.230, avg. samples / sec: 54163.38
Iteration:   3020, Loss function: 4.101, Average Loss: 4.229, avg. samples / sec: 54195.29
Iteration:   3020, Loss function: 4.120, Average Loss: 4.211, avg. samples / sec: 54199.27
Iteration:   3020, Loss function: 4.666, Average Loss: 4.226, avg. samples / sec: 54174.52
Iteration:   3020, Loss function: 5.447, Average Loss: 4.260, avg. samples / sec: 54149.95
Iteration:   3040, Loss function: 4.309, Average Loss: 4.220, avg. samples / sec: 54780.38
Iteration:   3040, Loss function: 4.235, Average Loss: 4.231, avg. samples / sec: 54843.59
Iteration:   3040, Loss function: 4.800, Average Loss: 4.242, avg. samples / sec: 54830.60
Iteration:   3040, Loss function: 3.325, Average Loss: 4.192, avg. samples / sec: 54807.37
Iteration:   3040, Loss function: 3.517, Average Loss: 4.251, avg. samples / sec: 54793.25
Iteration:   3040, Loss function: 3.370, Average Loss: 4.234, avg. samples / sec: 54766.12
Iteration:   3040, Loss function: 4.792, Average Loss: 4.218, avg. samples / sec: 54737.28
Iteration:   3040, Loss function: 3.507, Average Loss: 4.213, avg. samples / sec: 54770.80
Iteration:   3040, Loss function: 3.598, Average Loss: 4.232, avg. samples / sec: 54719.17
Iteration:   3040, Loss function: 4.051, Average Loss: 4.199, avg. samples / sec: 54747.31
Iteration:   3040, Loss function: 4.655, Average Loss: 4.220, avg. samples / sec: 54772.02
Iteration:   3040, Loss function: 3.625, Average Loss: 4.216, avg. samples / sec: 54780.60
Iteration:   3040, Loss function: 3.455, Average Loss: 4.216, avg. samples / sec: 54547.06
Iteration:   3040, Loss function: 4.435, Average Loss: 4.221, avg. samples / sec: 54940.62
Iteration:   3040, Loss function: 2.997, Average Loss: 4.209, avg. samples / sec: 54774.83
Iteration:   3040, Loss function: 5.345, Average Loss: 4.229, avg. samples / sec: 54806.46
Iteration:   3040, Loss function: 3.786, Average Loss: 4.222, avg. samples / sec: 54770.31
Iteration:   3040, Loss function: 3.551, Average Loss: 4.227, avg. samples / sec: 54803.18
Iteration:   3040, Loss function: 3.380, Average Loss: 4.218, avg. samples / sec: 54747.55
Iteration:   3040, Loss function: 4.494, Average Loss: 4.237, avg. samples / sec: 54758.57
Iteration:   3040, Loss function: 4.381, Average Loss: 4.214, avg. samples / sec: 54767.82
Iteration:   3040, Loss function: 3.860, Average Loss: 4.241, avg. samples / sec: 54753.67
Iteration:   3040, Loss function: 4.903, Average Loss: 4.231, avg. samples / sec: 54766.18
Iteration:   3040, Loss function: 3.431, Average Loss: 4.233, avg. samples / sec: 54718.23
Iteration:   3040, Loss function: 4.100, Average Loss: 4.255, avg. samples / sec: 54853.41
Iteration:   3040, Loss function: 5.182, Average Loss: 4.207, avg. samples / sec: 54773.21
Iteration:   3040, Loss function: 3.954, Average Loss: 4.231, avg. samples / sec: 54762.16
Iteration:   3040, Loss function: 3.753, Average Loss: 4.201, avg. samples / sec: 54595.88
Iteration:   3040, Loss function: 3.210, Average Loss: 4.245, avg. samples / sec: 54740.61
Iteration:   3040, Loss function: 3.720, Average Loss: 4.225, avg. samples / sec: 54789.65
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558640665.223 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.48s)
DONE (t=2.29s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17170
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32036
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.16914
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04529
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.17715
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.27274
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18012
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27941
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07830
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.42250
Current AP: 0.17170 AP goal: 0.23000
:::MLL 1558640668.616 eval_accuracy: {"value": 0.17169890000485524, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558640668.692 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558640668.698 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558640668.699 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 3.781, Average Loss: 4.209, avg. samples / sec: 8172.11
Iteration:   3060, Loss function: 4.196, Average Loss: 4.208, avg. samples / sec: 8177.20
Iteration:   3060, Loss function: 4.904, Average Loss: 4.232, avg. samples / sec: 8176.64
Iteration:   3060, Loss function: 3.913, Average Loss: 4.202, avg. samples / sec: 8178.37
Iteration:   3060, Loss function: 4.788, Average Loss: 4.224, avg. samples / sec: 8180.06
Iteration:   3060, Loss function: 3.678, Average Loss: 4.248, avg. samples / sec: 8173.65
Iteration:   3060, Loss function: 4.075, Average Loss: 4.207, avg. samples / sec: 8174.97
Iteration:   3060, Loss function: 3.323, Average Loss: 4.229, avg. samples / sec: 8174.40
Iteration:   3060, Loss function: 2.830, Average Loss: 4.190, avg. samples / sec: 8172.44
Iteration:   3060, Loss function: 3.605, Average Loss: 4.235, avg. samples / sec: 8172.03
Iteration:   3060, Loss function: 4.076, Average Loss: 4.196, avg. samples / sec: 8173.68
Iteration:   3060, Loss function: 4.175, Average Loss: 4.229, avg. samples / sec: 8171.18
Iteration:   3060, Loss function: 4.315, Average Loss: 4.212, avg. samples / sec: 8172.94
Iteration:   3060, Loss function: 3.000, Average Loss: 4.251, avg. samples / sec: 8176.50
Iteration:   3060, Loss function: 4.447, Average Loss: 4.213, avg. samples / sec: 8174.16
Iteration:   3060, Loss function: 3.189, Average Loss: 4.215, avg. samples / sec: 8173.62
Iteration:   3060, Loss function: 3.717, Average Loss: 4.209, avg. samples / sec: 8168.69
Iteration:   3060, Loss function: 4.151, Average Loss: 4.200, avg. samples / sec: 8174.36
Iteration:   3060, Loss function: 3.290, Average Loss: 4.223, avg. samples / sec: 8174.05
Iteration:   3060, Loss function: 4.452, Average Loss: 4.218, avg. samples / sec: 8173.12
Iteration:   3060, Loss function: 3.561, Average Loss: 4.219, avg. samples / sec: 8172.69
Iteration:   3060, Loss function: 4.248, Average Loss: 4.216, avg. samples / sec: 8170.17
Iteration:   3060, Loss function: 4.296, Average Loss: 4.223, avg. samples / sec: 8173.07
Iteration:   3060, Loss function: 4.140, Average Loss: 4.235, avg. samples / sec: 8173.35
Iteration:   3060, Loss function: 3.080, Average Loss: 4.235, avg. samples / sec: 8173.63
Iteration:   3060, Loss function: 3.188, Average Loss: 4.216, avg. samples / sec: 8173.54
Iteration:   3060, Loss function: 3.122, Average Loss: 4.206, avg. samples / sec: 8173.36
Iteration:   3060, Loss function: 3.392, Average Loss: 4.205, avg. samples / sec: 8172.68
Iteration:   3060, Loss function: 4.850, Average Loss: 4.226, avg. samples / sec: 8173.12
Iteration:   3060, Loss function: 3.274, Average Loss: 4.215, avg. samples / sec: 8167.78
:::MLL 1558640669.694 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558640669.695 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 4.014, Average Loss: 4.196, avg. samples / sec: 53909.05
Iteration:   3080, Loss function: 3.621, Average Loss: 4.205, avg. samples / sec: 53751.57
Iteration:   3080, Loss function: 3.570, Average Loss: 4.219, avg. samples / sec: 53755.61
Iteration:   3080, Loss function: 4.207, Average Loss: 4.201, avg. samples / sec: 53740.48
Iteration:   3080, Loss function: 4.211, Average Loss: 4.225, avg. samples / sec: 53828.11
Iteration:   3080, Loss function: 2.694, Average Loss: 4.218, avg. samples / sec: 53822.05
Iteration:   3080, Loss function: 3.770, Average Loss: 4.181, avg. samples / sec: 53791.66
Iteration:   3080, Loss function: 4.554, Average Loss: 4.195, avg. samples / sec: 53983.00
Iteration:   3080, Loss function: 3.683, Average Loss: 4.203, avg. samples / sec: 53826.24
Iteration:   3080, Loss function: 3.178, Average Loss: 4.190, avg. samples / sec: 53711.34
Iteration:   3080, Loss function: 3.621, Average Loss: 4.210, avg. samples / sec: 53715.25
Iteration:   3080, Loss function: 2.973, Average Loss: 4.219, avg. samples / sec: 53711.91
Iteration:   3080, Loss function: 3.470, Average Loss: 4.189, avg. samples / sec: 53752.13
Iteration:   3080, Loss function: 2.689, Average Loss: 4.236, avg. samples / sec: 53660.48
Iteration:   3080, Loss function: 2.800, Average Loss: 4.214, avg. samples / sec: 53922.71
Iteration:   3080, Loss function: 3.159, Average Loss: 4.224, avg. samples / sec: 53888.29
Iteration:   3080, Loss function: 3.056, Average Loss: 4.225, avg. samples / sec: 53884.65
Iteration:   3080, Loss function: 3.058, Average Loss: 4.213, avg. samples / sec: 53872.02
Iteration:   3080, Loss function: 2.847, Average Loss: 4.206, avg. samples / sec: 53854.87
Iteration:   3080, Loss function: 3.428, Average Loss: 4.199, avg. samples / sec: 53827.86
Iteration:   3080, Loss function: 2.617, Average Loss: 4.196, avg. samples / sec: 53857.07
Iteration:   3080, Loss function: 4.059, Average Loss: 4.207, avg. samples / sec: 53823.75
Iteration:   3080, Loss function: 4.273, Average Loss: 4.203, avg. samples / sec: 53842.71
Iteration:   3080, Loss function: 5.750, Average Loss: 4.239, avg. samples / sec: 53708.08
Iteration:   3080, Loss function: 3.266, Average Loss: 4.195, avg. samples / sec: 53832.70
Iteration:   3080, Loss function: 3.162, Average Loss: 4.202, avg. samples / sec: 53753.44
Iteration:   3080, Loss function: 3.106, Average Loss: 4.209, avg. samples / sec: 53793.20
Iteration:   3080, Loss function: 3.043, Average Loss: 4.205, avg. samples / sec: 53762.32
Iteration:   3080, Loss function: 3.282, Average Loss: 4.213, avg. samples / sec: 53701.94
Iteration:   3080, Loss function: 3.810, Average Loss: 4.205, avg. samples / sec: 53748.64
Iteration:   3100, Loss function: 3.470, Average Loss: 4.191, avg. samples / sec: 54439.77
Iteration:   3100, Loss function: 4.933, Average Loss: 4.183, avg. samples / sec: 54409.78
Iteration:   3100, Loss function: 3.746, Average Loss: 4.178, avg. samples / sec: 54508.90
Iteration:   3100, Loss function: 4.397, Average Loss: 4.210, avg. samples / sec: 54530.33
Iteration:   3100, Loss function: 4.213, Average Loss: 4.192, avg. samples / sec: 54466.03
Iteration:   3100, Loss function: 2.974, Average Loss: 4.197, avg. samples / sec: 54441.41
Iteration:   3100, Loss function: 4.465, Average Loss: 4.192, avg. samples / sec: 54292.27
Iteration:   3100, Loss function: 3.084, Average Loss: 4.174, avg. samples / sec: 54447.36
Iteration:   3100, Loss function: 2.736, Average Loss: 4.209, avg. samples / sec: 54345.89
Iteration:   3100, Loss function: 3.529, Average Loss: 4.170, avg. samples / sec: 54378.29
Iteration:   3100, Loss function: 2.465, Average Loss: 4.207, avg. samples / sec: 54370.38
Iteration:   3100, Loss function: 3.882, Average Loss: 4.223, avg. samples / sec: 54466.95
Iteration:   3100, Loss function: 2.688, Average Loss: 4.198, avg. samples / sec: 54624.43
Iteration:   3100, Loss function: 3.218, Average Loss: 4.188, avg. samples / sec: 54214.70
Iteration:   3100, Loss function: 3.361, Average Loss: 4.190, avg. samples / sec: 54421.88
Iteration:   3100, Loss function: 3.488, Average Loss: 4.198, avg. samples / sec: 54313.53
Iteration:   3100, Loss function: 4.224, Average Loss: 4.197, avg. samples / sec: 54403.75
Iteration:   3100, Loss function: 3.038, Average Loss: 4.192, avg. samples / sec: 54328.10
Iteration:   3100, Loss function: 5.209, Average Loss: 4.187, avg. samples / sec: 54349.87
Iteration:   3100, Loss function: 3.881, Average Loss: 4.196, avg. samples / sec: 54383.91
Iteration:   3100, Loss function: 2.795, Average Loss: 4.182, avg. samples / sec: 54370.52
Iteration:   3100, Loss function: 3.454, Average Loss: 4.210, avg. samples / sec: 54304.91
Iteration:   3100, Loss function: 2.748, Average Loss: 4.191, avg. samples / sec: 54319.77
Iteration:   3100, Loss function: 3.403, Average Loss: 4.217, avg. samples / sec: 54299.28
Iteration:   3100, Loss function: 3.438, Average Loss: 4.200, avg. samples / sec: 54337.38
Iteration:   3100, Loss function: 4.276, Average Loss: 4.202, avg. samples / sec: 54299.93
Iteration:   3100, Loss function: 2.907, Average Loss: 4.196, avg. samples / sec: 54450.52
Iteration:   3100, Loss function: 3.130, Average Loss: 4.206, avg. samples / sec: 53993.20
Iteration:   3100, Loss function: 3.161, Average Loss: 4.229, avg. samples / sec: 54308.84
Iteration:   3100, Loss function: 3.719, Average Loss: 4.199, avg. samples / sec: 54282.84
Iteration:   3120, Loss function: 4.886, Average Loss: 4.192, avg. samples / sec: 53954.48
Iteration:   3120, Loss function: 2.703, Average Loss: 4.172, avg. samples / sec: 53458.29
Iteration:   3120, Loss function: 4.082, Average Loss: 4.196, avg. samples / sec: 53467.05
Iteration:   3120, Loss function: 3.273, Average Loss: 4.169, avg. samples / sec: 53382.50
Iteration:   3120, Loss function: 3.995, Average Loss: 4.177, avg. samples / sec: 53492.20
Iteration:   3120, Loss function: 3.564, Average Loss: 4.165, avg. samples / sec: 53439.26
Iteration:   3120, Loss function: 3.374, Average Loss: 4.177, avg. samples / sec: 53515.41
Iteration:   3120, Loss function: 2.813, Average Loss: 4.190, avg. samples / sec: 53529.83
Iteration:   3120, Loss function: 3.636, Average Loss: 4.190, avg. samples / sec: 53533.51
Iteration:   3120, Loss function: 3.201, Average Loss: 4.190, avg. samples / sec: 53475.71
Iteration:   3120, Loss function: 2.674, Average Loss: 4.212, avg. samples / sec: 53516.80
Iteration:   3120, Loss function: 3.408, Average Loss: 4.157, avg. samples / sec: 53490.10
Iteration:   3120, Loss function: 3.028, Average Loss: 4.164, avg. samples / sec: 53451.92
Iteration:   3120, Loss function: 4.770, Average Loss: 4.191, avg. samples / sec: 53535.60
Iteration:   3120, Loss function: 3.089, Average Loss: 4.176, avg. samples / sec: 53502.09
Iteration:   3120, Loss function: 3.877, Average Loss: 4.181, avg. samples / sec: 53539.83
Iteration:   3120, Loss function: 2.937, Average Loss: 4.176, avg. samples / sec: 53482.25
Iteration:   3120, Loss function: 4.496, Average Loss: 4.188, avg. samples / sec: 53360.89
Iteration:   3120, Loss function: 4.253, Average Loss: 4.190, avg. samples / sec: 53523.79
Iteration:   3120, Loss function: 3.481, Average Loss: 4.185, avg. samples / sec: 53526.63
Iteration:   3120, Loss function: 3.698, Average Loss: 4.202, avg. samples / sec: 53512.55
Iteration:   3120, Loss function: 3.799, Average Loss: 4.177, avg. samples / sec: 53498.78
Iteration:   3120, Loss function: 4.824, Average Loss: 4.181, avg. samples / sec: 53516.31
Iteration:   3120, Loss function: 5.865, Average Loss: 4.174, avg. samples / sec: 53486.00
Iteration:   3120, Loss function: 4.644, Average Loss: 4.219, avg. samples / sec: 53527.49
Iteration:   3120, Loss function: 2.715, Average Loss: 4.199, avg. samples / sec: 53483.45
Iteration:   3120, Loss function: 3.210, Average Loss: 4.181, avg. samples / sec: 53485.86
Iteration:   3120, Loss function: 4.461, Average Loss: 4.181, avg. samples / sec: 53469.97
Iteration:   3120, Loss function: 3.467, Average Loss: 4.191, avg. samples / sec: 53445.72
Iteration:   3120, Loss function: 3.602, Average Loss: 4.187, avg. samples / sec: 53539.14
Iteration:   3140, Loss function: 3.929, Average Loss: 4.178, avg. samples / sec: 53560.67
Iteration:   3140, Loss function: 3.062, Average Loss: 4.154, avg. samples / sec: 53665.18
Iteration:   3140, Loss function: 3.261, Average Loss: 4.158, avg. samples / sec: 53549.35
Iteration:   3140, Loss function: 5.067, Average Loss: 4.157, avg. samples / sec: 53576.02
Iteration:   3140, Loss function: 3.083, Average Loss: 4.174, avg. samples / sec: 53616.30
Iteration:   3140, Loss function: 3.469, Average Loss: 4.177, avg. samples / sec: 53547.50
Iteration:   3140, Loss function: 3.258, Average Loss: 4.177, avg. samples / sec: 53586.21
Iteration:   3140, Loss function: 3.191, Average Loss: 4.168, avg. samples / sec: 53531.29
Iteration:   3140, Loss function: 3.303, Average Loss: 4.175, avg. samples / sec: 53538.79
Iteration:   3140, Loss function: 1.924, Average Loss: 4.162, avg. samples / sec: 53510.29
Iteration:   3140, Loss function: 3.604, Average Loss: 4.139, avg. samples / sec: 53555.44
Iteration:   3140, Loss function: 4.255, Average Loss: 4.200, avg. samples / sec: 53541.78
Iteration:   3140, Loss function: 4.217, Average Loss: 4.151, avg. samples / sec: 53574.49
Iteration:   3140, Loss function: 2.982, Average Loss: 4.181, avg. samples / sec: 53527.55
Iteration:   3140, Loss function: 3.161, Average Loss: 4.165, avg. samples / sec: 53601.66
Iteration:   3140, Loss function: 3.810, Average Loss: 4.158, avg. samples / sec: 53524.23
Iteration:   3140, Loss function: 2.365, Average Loss: 4.174, avg. samples / sec: 53548.60
Iteration:   3140, Loss function: 3.706, Average Loss: 4.174, avg. samples / sec: 53552.24
Iteration:   3140, Loss function: 3.792, Average Loss: 4.164, avg. samples / sec: 53522.61
Iteration:   3140, Loss function: 2.894, Average Loss: 4.182, avg. samples / sec: 53541.72
Iteration:   3140, Loss function: 2.847, Average Loss: 4.173, avg. samples / sec: 53587.78
Iteration:   3140, Loss function: 3.589, Average Loss: 4.166, avg. samples / sec: 53547.54
Iteration:   3140, Loss function: 3.088, Average Loss: 4.176, avg. samples / sec: 53570.91
Iteration:   3140, Loss function: 3.485, Average Loss: 4.185, avg. samples / sec: 53552.40
Iteration:   3140, Loss function: 4.986, Average Loss: 4.163, avg. samples / sec: 53512.22
Iteration:   3140, Loss function: 3.778, Average Loss: 4.209, avg. samples / sec: 53543.98
Iteration:   3140, Loss function: 3.097, Average Loss: 4.170, avg. samples / sec: 53539.89
Iteration:   3140, Loss function: 3.446, Average Loss: 4.169, avg. samples / sec: 53541.21
Iteration:   3140, Loss function: 4.833, Average Loss: 4.158, avg. samples / sec: 53532.29
Iteration:   3140, Loss function: 3.818, Average Loss: 4.191, avg. samples / sec: 53492.36
:::MLL 1558640671.883 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558640671.883 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 2.528, Average Loss: 4.159, avg. samples / sec: 53429.02
Iteration:   3160, Loss function: 3.984, Average Loss: 4.147, avg. samples / sec: 53436.80
Iteration:   3160, Loss function: 4.759, Average Loss: 4.145, avg. samples / sec: 53403.05
Iteration:   3160, Loss function: 2.784, Average Loss: 4.161, avg. samples / sec: 53435.87
Iteration:   3160, Loss function: 3.314, Average Loss: 4.157, avg. samples / sec: 53464.39
Iteration:   3160, Loss function: 5.103, Average Loss: 4.157, avg. samples / sec: 53439.62
Iteration:   3160, Loss function: 2.945, Average Loss: 4.147, avg. samples / sec: 53408.65
Iteration:   3160, Loss function: 2.790, Average Loss: 4.146, avg. samples / sec: 53481.19
Iteration:   3160, Loss function: 3.931, Average Loss: 4.126, avg. samples / sec: 53486.82
Iteration:   3160, Loss function: 3.487, Average Loss: 4.137, avg. samples / sec: 53478.43
Iteration:   3160, Loss function: 3.005, Average Loss: 4.186, avg. samples / sec: 53461.15
Iteration:   3160, Loss function: 2.630, Average Loss: 4.161, avg. samples / sec: 53380.64
Iteration:   3160, Loss function: 2.890, Average Loss: 4.158, avg. samples / sec: 53357.25
Iteration:   3160, Loss function: 2.639, Average Loss: 4.169, avg. samples / sec: 53548.64
Iteration:   3160, Loss function: 3.277, Average Loss: 4.146, avg. samples / sec: 53487.34
Iteration:   3160, Loss function: 3.978, Average Loss: 4.160, avg. samples / sec: 53490.98
Iteration:   3160, Loss function: 2.736, Average Loss: 4.148, avg. samples / sec: 53442.82
Iteration:   3160, Loss function: 4.914, Average Loss: 4.151, avg. samples / sec: 53483.89
Iteration:   3160, Loss function: 3.046, Average Loss: 4.179, avg. samples / sec: 53525.05
Iteration:   3160, Loss function: 3.665, Average Loss: 4.153, avg. samples / sec: 53458.37
Iteration:   3160, Loss function: 3.997, Average Loss: 4.165, avg. samples / sec: 53450.12
Iteration:   3160, Loss function: 3.244, Average Loss: 4.176, avg. samples / sec: 53419.42
Iteration:   3160, Loss function: 3.033, Average Loss: 4.161, avg. samples / sec: 53434.41
Iteration:   3160, Loss function: 4.746, Average Loss: 4.163, avg. samples / sec: 53460.56
Iteration:   3160, Loss function: 3.412, Average Loss: 4.161, avg. samples / sec: 53432.43
Iteration:   3160, Loss function: 4.575, Average Loss: 4.161, avg. samples / sec: 53459.14
Iteration:   3160, Loss function: 3.446, Average Loss: 4.197, avg. samples / sec: 53453.97
Iteration:   3160, Loss function: 3.689, Average Loss: 4.162, avg. samples / sec: 53438.10
Iteration:   3160, Loss function: 3.790, Average Loss: 4.160, avg. samples / sec: 53417.24
Iteration:   3160, Loss function: 4.663, Average Loss: 4.147, avg. samples / sec: 53458.05
Iteration:   3180, Loss function: 4.572, Average Loss: 4.146, avg. samples / sec: 53754.14
Iteration:   3180, Loss function: 2.544, Average Loss: 4.133, avg. samples / sec: 53758.03
Iteration:   3180, Loss function: 4.061, Average Loss: 4.143, avg. samples / sec: 53771.94
Iteration:   3180, Loss function: 3.236, Average Loss: 4.155, avg. samples / sec: 53807.21
Iteration:   3180, Loss function: 3.688, Average Loss: 4.150, avg. samples / sec: 53734.07
Iteration:   3180, Loss function: 4.135, Average Loss: 4.148, avg. samples / sec: 53727.60
Iteration:   3180, Loss function: 2.939, Average Loss: 4.136, avg. samples / sec: 53733.41
Iteration:   3180, Loss function: 3.462, Average Loss: 4.133, avg. samples / sec: 53702.29
Iteration:   3180, Loss function: 3.217, Average Loss: 4.130, avg. samples / sec: 53710.31
Iteration:   3180, Loss function: 4.643, Average Loss: 4.111, avg. samples / sec: 53671.04
Iteration:   3180, Loss function: 4.423, Average Loss: 4.138, avg. samples / sec: 53514.70
Iteration:   3180, Loss function: 4.804, Average Loss: 4.143, avg. samples / sec: 53765.19
Iteration:   3180, Loss function: 2.008, Average Loss: 4.133, avg. samples / sec: 53704.13
Iteration:   3180, Loss function: 3.543, Average Loss: 4.137, avg. samples / sec: 53742.10
Iteration:   3180, Loss function: 4.158, Average Loss: 4.144, avg. samples / sec: 53767.55
Iteration:   3180, Loss function: 2.691, Average Loss: 4.161, avg. samples / sec: 53736.80
Iteration:   3180, Loss function: 3.442, Average Loss: 4.157, avg. samples / sec: 53654.02
Iteration:   3180, Loss function: 3.872, Average Loss: 4.169, avg. samples / sec: 53725.22
Iteration:   3180, Loss function: 3.387, Average Loss: 4.151, avg. samples / sec: 53746.26
Iteration:   3180, Loss function: 4.837, Average Loss: 4.149, avg. samples / sec: 53741.49
Iteration:   3180, Loss function: 3.647, Average Loss: 4.135, avg. samples / sec: 53749.67
Iteration:   3180, Loss function: 3.820, Average Loss: 4.154, avg. samples / sec: 53722.80
Iteration:   3180, Loss function: 4.548, Average Loss: 4.135, avg. samples / sec: 53691.94
Iteration:   3180, Loss function: 4.508, Average Loss: 4.148, avg. samples / sec: 53726.57
Iteration:   3180, Loss function: 3.697, Average Loss: 4.150, avg. samples / sec: 53508.85
Iteration:   3180, Loss function: 7.110, Average Loss: 4.151, avg. samples / sec: 53659.25
Iteration:   3180, Loss function: 3.064, Average Loss: 4.170, avg. samples / sec: 53458.17
Iteration:   3180, Loss function: 3.355, Average Loss: 4.183, avg. samples / sec: 53697.32
Iteration:   3180, Loss function: 2.998, Average Loss: 4.153, avg. samples / sec: 53688.89
Iteration:   3180, Loss function: 3.547, Average Loss: 4.146, avg. samples / sec: 53656.39
Iteration:   3200, Loss function: 3.016, Average Loss: 4.127, avg. samples / sec: 54149.04
Iteration:   3200, Loss function: 3.438, Average Loss: 4.134, avg. samples / sec: 53822.05
Iteration:   3200, Loss function: 3.523, Average Loss: 4.115, avg. samples / sec: 53746.24
Iteration:   3200, Loss function: 3.775, Average Loss: 4.131, avg. samples / sec: 53812.12
Iteration:   3200, Loss function: 3.460, Average Loss: 4.145, avg. samples / sec: 53810.31
Iteration:   3200, Loss function: 2.769, Average Loss: 4.139, avg. samples / sec: 53806.76
Iteration:   3200, Loss function: 4.233, Average Loss: 4.137, avg. samples / sec: 53817.54
Iteration:   3200, Loss function: 3.764, Average Loss: 4.141, avg. samples / sec: 54083.06
Iteration:   3200, Loss function: 3.775, Average Loss: 4.162, avg. samples / sec: 54091.57
Iteration:   3200, Loss function: 3.204, Average Loss: 4.101, avg. samples / sec: 53851.81
Iteration:   3200, Loss function: 2.810, Average Loss: 4.113, avg. samples / sec: 53788.52
Iteration:   3200, Loss function: 4.807, Average Loss: 4.125, avg. samples / sec: 53776.21
Iteration:   3200, Loss function: 2.661, Average Loss: 4.125, avg. samples / sec: 53721.64
Iteration:   3200, Loss function: 3.693, Average Loss: 4.146, avg. samples / sec: 53862.92
Iteration:   3200, Loss function: 4.474, Average Loss: 4.124, avg. samples / sec: 53832.39
Iteration:   3200, Loss function: 3.508, Average Loss: 4.122, avg. samples / sec: 53818.24
Iteration:   3200, Loss function: 4.898, Average Loss: 4.123, avg. samples / sec: 53859.30
Iteration:   3200, Loss function: 3.355, Average Loss: 4.132, avg. samples / sec: 53824.84
Iteration:   3200, Loss function: 3.890, Average Loss: 4.160, avg. samples / sec: 53828.99
Iteration:   3200, Loss function: 2.545, Average Loss: 4.141, avg. samples / sec: 53822.95
Iteration:   3200, Loss function: 2.945, Average Loss: 4.140, avg. samples / sec: 53831.28
Iteration:   3200, Loss function: 4.043, Average Loss: 4.137, avg. samples / sec: 53897.32
Iteration:   3200, Loss function: 5.259, Average Loss: 4.142, avg. samples / sec: 53853.27
Iteration:   3200, Loss function: 3.563, Average Loss: 4.136, avg. samples / sec: 53819.70
Iteration:   3200, Loss function: 4.064, Average Loss: 4.130, avg. samples / sec: 53768.27
Iteration:   3200, Loss function: 3.400, Average Loss: 4.138, avg. samples / sec: 53868.44
Iteration:   3200, Loss function: 3.667, Average Loss: 4.139, avg. samples / sec: 53805.85
Iteration:   3200, Loss function: 2.906, Average Loss: 4.124, avg. samples / sec: 53807.81
Iteration:   3200, Loss function: 3.672, Average Loss: 4.166, avg. samples / sec: 53853.27
Iteration:   3200, Loss function: 3.117, Average Loss: 4.136, avg. samples / sec: 53813.11
:::MLL 1558640674.074 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558640674.075 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 2.800, Average Loss: 4.104, avg. samples / sec: 53629.95
Iteration:   3220, Loss function: 2.935, Average Loss: 4.119, avg. samples / sec: 53468.49
Iteration:   3220, Loss function: 4.294, Average Loss: 4.111, avg. samples / sec: 53723.17
Iteration:   3220, Loss function: 2.685, Average Loss: 4.113, avg. samples / sec: 53392.28
Iteration:   3220, Loss function: 3.112, Average Loss: 4.128, avg. samples / sec: 53531.11
Iteration:   3220, Loss function: 4.620, Average Loss: 4.113, avg. samples / sec: 53600.86
Iteration:   3220, Loss function: 4.383, Average Loss: 4.091, avg. samples / sec: 53507.14
Iteration:   3220, Loss function: 3.702, Average Loss: 4.127, avg. samples / sec: 53477.42
Iteration:   3220, Loss function: 4.862, Average Loss: 4.128, avg. samples / sec: 53447.24
Iteration:   3220, Loss function: 2.480, Average Loss: 4.152, avg. samples / sec: 53472.91
Iteration:   3220, Loss function: 3.506, Average Loss: 4.135, avg. samples / sec: 53416.35
Iteration:   3220, Loss function: 3.019, Average Loss: 4.101, avg. samples / sec: 53500.62
Iteration:   3220, Loss function: 3.310, Average Loss: 4.118, avg. samples / sec: 53399.57
Iteration:   3220, Loss function: 3.891, Average Loss: 4.128, avg. samples / sec: 53620.68
Iteration:   3220, Loss function: 3.663, Average Loss: 4.114, avg. samples / sec: 53585.37
Iteration:   3220, Loss function: 3.150, Average Loss: 4.132, avg. samples / sec: 53586.55
Iteration:   3220, Loss function: 2.833, Average Loss: 4.124, avg. samples / sec: 53590.91
Iteration:   3220, Loss function: 3.024, Average Loss: 4.153, avg. samples / sec: 53570.40
Iteration:   3220, Loss function: 3.843, Average Loss: 4.114, avg. samples / sec: 53558.98
Iteration:   3220, Loss function: 4.392, Average Loss: 4.117, avg. samples / sec: 53557.94
Iteration:   3220, Loss function: 3.741, Average Loss: 4.132, avg. samples / sec: 53513.14
Iteration:   3220, Loss function: 2.463, Average Loss: 4.109, avg. samples / sec: 53586.41
Iteration:   3220, Loss function: 3.407, Average Loss: 4.119, avg. samples / sec: 53558.35
Iteration:   3220, Loss function: 3.899, Average Loss: 4.129, avg. samples / sec: 53578.10
Iteration:   3220, Loss function: 2.914, Average Loss: 4.129, avg. samples / sec: 53570.56
Iteration:   3220, Loss function: 3.320, Average Loss: 4.151, avg. samples / sec: 53560.08
Iteration:   3220, Loss function: 3.128, Average Loss: 4.109, avg. samples / sec: 53475.65
Iteration:   3220, Loss function: 3.167, Average Loss: 4.125, avg. samples / sec: 53515.15
Iteration:   3220, Loss function: 4.185, Average Loss: 4.126, avg. samples / sec: 53456.22
Iteration:   3220, Loss function: 2.160, Average Loss: 4.125, avg. samples / sec: 53449.37
Iteration:   3240, Loss function: 4.067, Average Loss: 4.092, avg. samples / sec: 53798.79
Iteration:   3240, Loss function: 4.240, Average Loss: 4.100, avg. samples / sec: 53858.27
Iteration:   3240, Loss function: 3.960, Average Loss: 4.117, avg. samples / sec: 53913.61
Iteration:   3240, Loss function: 2.911, Average Loss: 4.107, avg. samples / sec: 53917.76
Iteration:   3240, Loss function: 3.560, Average Loss: 4.103, avg. samples / sec: 53829.45
Iteration:   3240, Loss function: 3.541, Average Loss: 4.136, avg. samples / sec: 53860.08
Iteration:   3240, Loss function: 3.190, Average Loss: 4.117, avg. samples / sec: 53838.50
Iteration:   3240, Loss function: 4.674, Average Loss: 4.117, avg. samples / sec: 53768.47
Iteration:   3240, Loss function: 4.651, Average Loss: 4.101, avg. samples / sec: 53652.30
Iteration:   3240, Loss function: 4.323, Average Loss: 4.085, avg. samples / sec: 53811.87
Iteration:   3240, Loss function: 3.257, Average Loss: 4.086, avg. samples / sec: 53851.74
Iteration:   3240, Loss function: 2.601, Average Loss: 4.120, avg. samples / sec: 53813.17
Iteration:   3240, Loss function: 2.752, Average Loss: 4.095, avg. samples / sec: 53870.93
Iteration:   3240, Loss function: 3.735, Average Loss: 4.098, avg. samples / sec: 53785.91
Iteration:   3240, Loss function: 3.288, Average Loss: 4.119, avg. samples / sec: 53798.32
Iteration:   3240, Loss function: 4.060, Average Loss: 4.112, avg. samples / sec: 53750.61
Iteration:   3240, Loss function: 2.797, Average Loss: 4.104, avg. samples / sec: 53737.20
Iteration:   3240, Loss function: 3.848, Average Loss: 4.114, avg. samples / sec: 53887.18
Iteration:   3240, Loss function: 4.674, Average Loss: 4.113, avg. samples / sec: 53782.01
Iteration:   3240, Loss function: 3.442, Average Loss: 4.108, avg. samples / sec: 53422.16
Iteration:   3240, Loss function: 2.642, Average Loss: 4.102, avg. samples / sec: 53744.99
Iteration:   3240, Loss function: 3.387, Average Loss: 4.138, avg. samples / sec: 53738.66
Iteration:   3240, Loss function: 4.091, Average Loss: 4.113, avg. samples / sec: 53806.55
Iteration:   3240, Loss function: 3.576, Average Loss: 4.115, avg. samples / sec: 53696.75
Iteration:   3240, Loss function: 4.344, Average Loss: 4.113, avg. samples / sec: 53853.74
Iteration:   3240, Loss function: 3.153, Average Loss: 4.118, avg. samples / sec: 53709.45
Iteration:   3240, Loss function: 3.506, Average Loss: 4.119, avg. samples / sec: 53753.46
Iteration:   3240, Loss function: 3.143, Average Loss: 4.120, avg. samples / sec: 53734.60
Iteration:   3240, Loss function: 2.485, Average Loss: 4.137, avg. samples / sec: 53744.25
Iteration:   3240, Loss function: 3.178, Average Loss: 4.098, avg. samples / sec: 53666.46
Iteration:   3260, Loss function: 4.058, Average Loss: 4.097, avg. samples / sec: 53888.05
Iteration:   3260, Loss function: 4.403, Average Loss: 4.096, avg. samples / sec: 54266.07
Iteration:   3260, Loss function: 3.702, Average Loss: 4.077, avg. samples / sec: 53833.48
Iteration:   3260, Loss function: 2.930, Average Loss: 4.102, avg. samples / sec: 53824.33
Iteration:   3260, Loss function: 2.775, Average Loss: 4.076, avg. samples / sec: 53884.07
Iteration:   3260, Loss function: 5.384, Average Loss: 4.096, avg. samples / sec: 53813.41
Iteration:   3260, Loss function: 3.757, Average Loss: 4.076, avg. samples / sec: 53871.01
Iteration:   3260, Loss function: 3.667, Average Loss: 4.087, avg. samples / sec: 53845.61
Iteration:   3260, Loss function: 3.600, Average Loss: 4.108, avg. samples / sec: 53892.07
Iteration:   3260, Loss function: 4.547, Average Loss: 4.093, avg. samples / sec: 53806.57
Iteration:   3260, Loss function: 3.738, Average Loss: 4.106, avg. samples / sec: 53824.76
Iteration:   3260, Loss function: 3.712, Average Loss: 4.114, avg. samples / sec: 53805.34
Iteration:   3260, Loss function: 3.269, Average Loss: 4.127, avg. samples / sec: 53796.49
Iteration:   3260, Loss function: 3.400, Average Loss: 4.086, avg. samples / sec: 53826.36
Iteration:   3260, Loss function: 3.775, Average Loss: 4.087, avg. samples / sec: 53817.52
Iteration:   3260, Loss function: 3.106, Average Loss: 4.103, avg. samples / sec: 53861.77
Iteration:   3260, Loss function: 3.556, Average Loss: 4.095, avg. samples / sec: 53850.30
Iteration:   3260, Loss function: 3.146, Average Loss: 4.103, avg. samples / sec: 53872.43
Iteration:   3260, Loss function: 4.115, Average Loss: 4.122, avg. samples / sec: 53858.66
Iteration:   3260, Loss function: 3.940, Average Loss: 4.108, avg. samples / sec: 53872.00
Iteration:   3260, Loss function: 3.847, Average Loss: 4.086, avg. samples / sec: 53940.68
Iteration:   3260, Loss function: 2.818, Average Loss: 4.107, avg. samples / sec: 53881.23
Iteration:   3260, Loss function: 3.375, Average Loss: 4.101, avg. samples / sec: 53857.84
Iteration:   3260, Loss function: 3.423, Average Loss: 4.091, avg. samples / sec: 53841.77
Iteration:   3260, Loss function: 5.375, Average Loss: 4.103, avg. samples / sec: 53829.32
Iteration:   3260, Loss function: 2.772, Average Loss: 4.109, avg. samples / sec: 53857.75
Iteration:   3260, Loss function: 2.982, Average Loss: 4.103, avg. samples / sec: 53795.95
Iteration:   3260, Loss function: 3.435, Average Loss: 4.095, avg. samples / sec: 53816.19
Iteration:   3260, Loss function: 2.616, Average Loss: 4.125, avg. samples / sec: 53845.80
Iteration:   3260, Loss function: 3.519, Average Loss: 4.104, avg. samples / sec: 53807.78
Iteration:   3280, Loss function: 3.175, Average Loss: 4.083, avg. samples / sec: 54077.56
Iteration:   3280, Loss function: 3.537, Average Loss: 4.074, avg. samples / sec: 54051.43
Iteration:   3280, Loss function: 3.491, Average Loss: 4.088, avg. samples / sec: 53975.70
Iteration:   3280, Loss function: 3.662, Average Loss: 4.088, avg. samples / sec: 54081.11
Iteration:   3280, Loss function: 3.570, Average Loss: 4.085, avg. samples / sec: 54072.48
Iteration:   3280, Loss function: 3.077, Average Loss: 4.078, avg. samples / sec: 54074.16
Iteration:   3280, Loss function: 3.187, Average Loss: 4.092, avg. samples / sec: 54066.94
Iteration:   3280, Loss function: 4.821, Average Loss: 4.077, avg. samples / sec: 54060.41
Iteration:   3280, Loss function: 3.909, Average Loss: 4.069, avg. samples / sec: 54025.94
Iteration:   3280, Loss function: 3.299, Average Loss: 4.062, avg. samples / sec: 54027.33
Iteration:   3280, Loss function: 3.657, Average Loss: 4.122, avg. samples / sec: 54071.38
Iteration:   3280, Loss function: 3.179, Average Loss: 4.103, avg. samples / sec: 54050.77
Iteration:   3280, Loss function: 3.255, Average Loss: 4.103, avg. samples / sec: 54023.83
Iteration:   3280, Loss function: 3.975, Average Loss: 4.073, avg. samples / sec: 54050.87
Iteration:   3280, Loss function: 4.031, Average Loss: 4.088, avg. samples / sec: 54064.70
Iteration:   3280, Loss function: 2.893, Average Loss: 4.072, avg. samples / sec: 54055.41
Iteration:   3280, Loss function: 2.648, Average Loss: 4.094, avg. samples / sec: 54075.13
Iteration:   3280, Loss function: 3.338, Average Loss: 4.092, avg. samples / sec: 54036.92
Iteration:   3280, Loss function: 4.792, Average Loss: 4.093, avg. samples / sec: 54068.06
Iteration:   3280, Loss function: 3.642, Average Loss: 4.080, avg. samples / sec: 54070.13
Iteration:   3280, Loss function: 2.790, Average Loss: 4.093, avg. samples / sec: 54050.21
Iteration:   3280, Loss function: 3.106, Average Loss: 4.096, avg. samples / sec: 54051.16
Iteration:   3280, Loss function: 3.565, Average Loss: 4.091, avg. samples / sec: 54038.35
Iteration:   3280, Loss function: 2.477, Average Loss: 4.108, avg. samples / sec: 54038.52
Iteration:   3280, Loss function: 3.683, Average Loss: 4.089, avg. samples / sec: 54089.58
Iteration:   3280, Loss function: 3.533, Average Loss: 4.080, avg. samples / sec: 54033.11
Iteration:   3280, Loss function: 3.360, Average Loss: 4.087, avg. samples / sec: 54027.02
Iteration:   3280, Loss function: 4.192, Average Loss: 4.099, avg. samples / sec: 54025.84
Iteration:   3280, Loss function: 4.305, Average Loss: 4.117, avg. samples / sec: 54031.95
Iteration:   3280, Loss function: 4.320, Average Loss: 4.076, avg. samples / sec: 53986.47
:::MLL 1558640676.259 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558640676.260 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 3.066, Average Loss: 4.078, avg. samples / sec: 53158.58
Iteration:   3300, Loss function: 3.231, Average Loss: 4.066, avg. samples / sec: 53039.26
Iteration:   3300, Loss function: 2.514, Average Loss: 4.064, avg. samples / sec: 53056.40
Iteration:   3300, Loss function: 2.750, Average Loss: 4.062, avg. samples / sec: 53085.88
Iteration:   3300, Loss function: 3.955, Average Loss: 4.072, avg. samples / sec: 53026.37
Iteration:   3300, Loss function: 4.166, Average Loss: 4.076, avg. samples / sec: 53070.10
Iteration:   3300, Loss function: 3.514, Average Loss: 4.113, avg. samples / sec: 53107.54
Iteration:   3300, Loss function: 5.922, Average Loss: 4.062, avg. samples / sec: 53068.74
Iteration:   3300, Loss function: 2.286, Average Loss: 4.048, avg. samples / sec: 53078.66
Iteration:   3300, Loss function: 3.049, Average Loss: 4.074, avg. samples / sec: 53029.74
Iteration:   3300, Loss function: 4.088, Average Loss: 4.089, avg. samples / sec: 53104.64
Iteration:   3300, Loss function: 3.460, Average Loss: 4.093, avg. samples / sec: 53092.84
Iteration:   3300, Loss function: 3.169, Average Loss: 4.069, avg. samples / sec: 53014.26
Iteration:   3300, Loss function: 3.183, Average Loss: 4.062, avg. samples / sec: 53072.98
Iteration:   3300, Loss function: 3.305, Average Loss: 4.083, avg. samples / sec: 53087.36
Iteration:   3300, Loss function: 3.226, Average Loss: 4.071, avg. samples / sec: 53096.70
Iteration:   3300, Loss function: 3.920, Average Loss: 4.061, avg. samples / sec: 53073.40
Iteration:   3300, Loss function: 3.440, Average Loss: 4.069, avg. samples / sec: 53111.92
Iteration:   3300, Loss function: 2.731, Average Loss: 4.076, avg. samples / sec: 53053.26
Iteration:   3300, Loss function: 4.352, Average Loss: 4.104, avg. samples / sec: 53078.64
Iteration:   3300, Loss function: 2.536, Average Loss: 4.080, avg. samples / sec: 53068.14
Iteration:   3300, Loss function: 2.763, Average Loss: 4.063, avg. samples / sec: 53131.37
Iteration:   3300, Loss function: 2.848, Average Loss: 4.076, avg. samples / sec: 53073.80
Iteration:   3300, Loss function: 3.319, Average Loss: 4.078, avg. samples / sec: 53087.96
Iteration:   3300, Loss function: 4.488, Average Loss: 4.087, avg. samples / sec: 53053.08
Iteration:   3300, Loss function: 4.297, Average Loss: 4.079, avg. samples / sec: 53044.16
Iteration:   3300, Loss function: 3.866, Average Loss: 4.092, avg. samples / sec: 53083.98
Iteration:   3300, Loss function: 3.120, Average Loss: 4.086, avg. samples / sec: 53031.54
Iteration:   3300, Loss function: 3.553, Average Loss: 4.107, avg. samples / sec: 53089.56
Iteration:   3300, Loss function: 2.529, Average Loss: 4.076, avg. samples / sec: 53017.38
Iteration:   3320, Loss function: 4.056, Average Loss: 4.053, avg. samples / sec: 53698.18
Iteration:   3320, Loss function: 3.945, Average Loss: 4.056, avg. samples / sec: 53630.64
Iteration:   3320, Loss function: 3.164, Average Loss: 4.062, avg. samples / sec: 53715.76
Iteration:   3320, Loss function: 3.371, Average Loss: 4.048, avg. samples / sec: 53692.61
Iteration:   3320, Loss function: 3.508, Average Loss: 4.057, avg. samples / sec: 53671.90
Iteration:   3320, Loss function: 5.009, Average Loss: 4.083, avg. samples / sec: 53719.86
Iteration:   3320, Loss function: 3.267, Average Loss: 4.066, avg. samples / sec: 53704.05
Iteration:   3320, Loss function: 4.727, Average Loss: 4.044, avg. samples / sec: 53689.10
Iteration:   3320, Loss function: 2.757, Average Loss: 4.055, avg. samples / sec: 53706.98
Iteration:   3320, Loss function: 4.658, Average Loss: 4.056, avg. samples / sec: 53663.30
Iteration:   3320, Loss function: 4.452, Average Loss: 4.066, avg. samples / sec: 53398.98
Iteration:   3320, Loss function: 3.470, Average Loss: 4.075, avg. samples / sec: 53665.11
Iteration:   3320, Loss function: 3.751, Average Loss: 4.049, avg. samples / sec: 53644.79
Iteration:   3320, Loss function: 5.309, Average Loss: 4.082, avg. samples / sec: 53461.72
Iteration:   3320, Loss function: 4.638, Average Loss: 4.065, avg. samples / sec: 53697.22
Iteration:   3320, Loss function: 2.640, Average Loss: 4.074, avg. samples / sec: 53714.53
Iteration:   3320, Loss function: 1.961, Average Loss: 4.059, avg. samples / sec: 53665.20
Iteration:   3320, Loss function: 3.150, Average Loss: 4.062, avg. samples / sec: 53736.69
Iteration:   3320, Loss function: 2.757, Average Loss: 4.051, avg. samples / sec: 53641.03
Iteration:   3320, Loss function: 3.699, Average Loss: 4.058, avg. samples / sec: 53638.05
Iteration:   3320, Loss function: 3.374, Average Loss: 4.077, avg. samples / sec: 53686.54
Iteration:   3320, Loss function: 4.038, Average Loss: 4.090, avg. samples / sec: 53658.41
Iteration:   3320, Loss function: 3.181, Average Loss: 4.072, avg. samples / sec: 53659.33
Iteration:   3320, Loss function: 3.499, Average Loss: 4.061, avg. samples / sec: 53646.81
Iteration:   3320, Loss function: 3.481, Average Loss: 4.070, avg. samples / sec: 53666.93
Iteration:   3320, Loss function: 3.441, Average Loss: 4.064, avg. samples / sec: 53652.65
Iteration:   3320, Loss function: 3.262, Average Loss: 4.100, avg. samples / sec: 53391.46
Iteration:   3320, Loss function: 4.631, Average Loss: 4.097, avg. samples / sec: 53687.79
Iteration:   3320, Loss function: 2.712, Average Loss: 4.084, avg. samples / sec: 53663.19
Iteration:   3320, Loss function: 2.794, Average Loss: 4.050, avg. samples / sec: 53604.08
Iteration:   3340, Loss function: 2.765, Average Loss: 4.044, avg. samples / sec: 54712.24
Iteration:   3340, Loss function: 2.782, Average Loss: 4.052, avg. samples / sec: 54900.27
Iteration:   3340, Loss function: 4.341, Average Loss: 4.042, avg. samples / sec: 54567.97
Iteration:   3340, Loss function: 3.926, Average Loss: 4.036, avg. samples / sec: 54653.36
Iteration:   3340, Loss function: 3.357, Average Loss: 4.051, avg. samples / sec: 54620.64
Iteration:   3340, Loss function: 4.436, Average Loss: 4.048, avg. samples / sec: 54645.06
Iteration:   3340, Loss function: 3.278, Average Loss: 4.067, avg. samples / sec: 54642.36
Iteration:   3340, Loss function: 4.317, Average Loss: 4.091, avg. samples / sec: 54955.46
Iteration:   3340, Loss function: 4.022, Average Loss: 4.056, avg. samples / sec: 54632.43
Iteration:   3340, Loss function: 2.844, Average Loss: 4.039, avg. samples / sec: 54641.58
Iteration:   3340, Loss function: 3.499, Average Loss: 4.044, avg. samples / sec: 54650.78
Iteration:   3340, Loss function: 2.668, Average Loss: 4.076, avg. samples / sec: 54856.74
Iteration:   3340, Loss function: 3.445, Average Loss: 4.041, avg. samples / sec: 54617.78
Iteration:   3340, Loss function: 3.157, Average Loss: 4.063, avg. samples / sec: 54733.51
Iteration:   3340, Loss function: 2.925, Average Loss: 4.037, avg. samples / sec: 54707.08
Iteration:   3340, Loss function: 4.623, Average Loss: 4.036, avg. samples / sec: 54680.10
Iteration:   3340, Loss function: 1.838, Average Loss: 4.051, avg. samples / sec: 54717.00
Iteration:   3340, Loss function: 3.192, Average Loss: 4.078, avg. samples / sec: 54689.25
Iteration:   3340, Loss function: 3.796, Average Loss: 4.062, avg. samples / sec: 54642.39
Iteration:   3340, Loss function: 3.649, Average Loss: 4.052, avg. samples / sec: 54655.38
Iteration:   3340, Loss function: 3.451, Average Loss: 4.071, avg. samples / sec: 54697.42
Iteration:   3340, Loss function: 2.145, Average Loss: 4.048, avg. samples / sec: 54661.97
Iteration:   3340, Loss function: 3.579, Average Loss: 4.044, avg. samples / sec: 54647.60
Iteration:   3340, Loss function: 3.009, Average Loss: 4.062, avg. samples / sec: 54620.64
Iteration:   3340, Loss function: 3.197, Average Loss: 4.057, avg. samples / sec: 54655.91
Iteration:   3340, Loss function: 4.086, Average Loss: 4.053, avg. samples / sec: 54604.21
Iteration:   3340, Loss function: 3.163, Average Loss: 4.066, avg. samples / sec: 54620.36
Iteration:   3340, Loss function: 4.057, Average Loss: 4.046, avg. samples / sec: 54599.77
Iteration:   3340, Loss function: 3.648, Average Loss: 4.037, avg. samples / sec: 54677.75
Iteration:   3340, Loss function: 3.881, Average Loss: 4.083, avg. samples / sec: 54477.10
:::MLL 1558640678.438 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558640678.439 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 3.075, Average Loss: 4.028, avg. samples / sec: 54263.82
Iteration:   3360, Loss function: 2.612, Average Loss: 4.040, avg. samples / sec: 54179.25
Iteration:   3360, Loss function: 3.534, Average Loss: 4.054, avg. samples / sec: 54269.88
Iteration:   3360, Loss function: 2.891, Average Loss: 4.027, avg. samples / sec: 54327.74
Iteration:   3360, Loss function: 3.720, Average Loss: 4.036, avg. samples / sec: 54214.55
Iteration:   3360, Loss function: 5.390, Average Loss: 4.078, avg. samples / sec: 54215.68
Iteration:   3360, Loss function: 2.470, Average Loss: 4.029, avg. samples / sec: 54221.92
Iteration:   3360, Loss function: 3.441, Average Loss: 4.021, avg. samples / sec: 54161.84
Iteration:   3360, Loss function: 3.718, Average Loss: 4.036, avg. samples / sec: 54018.53
Iteration:   3360, Loss function: 2.774, Average Loss: 4.041, avg. samples / sec: 54210.28
Iteration:   3360, Loss function: 4.922, Average Loss: 4.036, avg. samples / sec: 54208.67
Iteration:   3360, Loss function: 3.799, Average Loss: 4.040, avg. samples / sec: 54159.86
Iteration:   3360, Loss function: 4.018, Average Loss: 4.066, avg. samples / sec: 54196.93
Iteration:   3360, Loss function: 3.486, Average Loss: 4.025, avg. samples / sec: 54304.36
Iteration:   3360, Loss function: 3.613, Average Loss: 4.065, avg. samples / sec: 54301.20
Iteration:   3360, Loss function: 3.164, Average Loss: 4.050, avg. samples / sec: 54351.69
Iteration:   3360, Loss function: 3.231, Average Loss: 4.039, avg. samples / sec: 54322.03
Iteration:   3360, Loss function: 3.490, Average Loss: 4.051, avg. samples / sec: 54358.26
Iteration:   3360, Loss function: 4.144, Average Loss: 4.030, avg. samples / sec: 54337.00
Iteration:   3360, Loss function: 3.410, Average Loss: 4.053, avg. samples / sec: 54296.87
Iteration:   3360, Loss function: 2.541, Average Loss: 4.059, avg. samples / sec: 54297.69
Iteration:   3360, Loss function: 4.364, Average Loss: 4.031, avg. samples / sec: 54335.24
Iteration:   3360, Loss function: 3.656, Average Loss: 4.040, avg. samples / sec: 54276.19
Iteration:   3360, Loss function: 3.319, Average Loss: 4.034, avg. samples / sec: 54319.95
Iteration:   3360, Loss function: 3.573, Average Loss: 4.069, avg. samples / sec: 54482.62
Iteration:   3360, Loss function: 3.622, Average Loss: 4.020, avg. samples / sec: 54201.90
Iteration:   3360, Loss function: 3.549, Average Loss: 4.045, avg. samples / sec: 54257.40
Iteration:   3360, Loss function: 3.046, Average Loss: 4.044, avg. samples / sec: 54258.07
Iteration:   3360, Loss function: 4.050, Average Loss: 4.039, avg. samples / sec: 54151.91
Iteration:   3360, Loss function: 2.850, Average Loss: 4.053, avg. samples / sec: 54081.77
Iteration:   3380, Loss function: 4.266, Average Loss: 4.018, avg. samples / sec: 54666.44
Iteration:   3380, Loss function: 3.067, Average Loss: 4.024, avg. samples / sec: 54548.31
Iteration:   3380, Loss function: 2.295, Average Loss: 4.026, avg. samples / sec: 54661.08
Iteration:   3380, Loss function: 2.450, Average Loss: 4.011, avg. samples / sec: 54674.74
Iteration:   3380, Loss function: 3.582, Average Loss: 4.056, avg. samples / sec: 54706.15
Iteration:   3380, Loss function: 4.776, Average Loss: 4.034, avg. samples / sec: 54669.22
Iteration:   3380, Loss function: 4.391, Average Loss: 4.046, avg. samples / sec: 54570.38
Iteration:   3380, Loss function: 2.685, Average Loss: 4.066, avg. samples / sec: 54611.68
Iteration:   3380, Loss function: 3.893, Average Loss: 4.012, avg. samples / sec: 54551.27
Iteration:   3380, Loss function: 2.935, Average Loss: 4.014, avg. samples / sec: 54608.28
Iteration:   3380, Loss function: 3.395, Average Loss: 4.028, avg. samples / sec: 54614.33
Iteration:   3380, Loss function: 3.674, Average Loss: 4.034, avg. samples / sec: 54451.91
Iteration:   3380, Loss function: 3.175, Average Loss: 4.037, avg. samples / sec: 54568.61
Iteration:   3380, Loss function: 3.662, Average Loss: 4.022, avg. samples / sec: 54567.36
Iteration:   3380, Loss function: 3.725, Average Loss: 4.037, avg. samples / sec: 54533.91
Iteration:   3380, Loss function: 3.305, Average Loss: 4.024, avg. samples / sec: 54394.64
Iteration:   3380, Loss function: 2.947, Average Loss: 4.013, avg. samples / sec: 54510.31
Iteration:   3380, Loss function: 2.986, Average Loss: 4.026, avg. samples / sec: 54536.02
Iteration:   3380, Loss function: 3.440, Average Loss: 4.050, avg. samples / sec: 54532.23
Iteration:   3380, Loss function: 3.903, Average Loss: 4.043, avg. samples / sec: 54714.81
Iteration:   3380, Loss function: 3.202, Average Loss: 4.042, avg. samples / sec: 54540.52
Iteration:   3380, Loss function: 4.248, Average Loss: 4.036, avg. samples / sec: 54619.62
Iteration:   3380, Loss function: 4.044, Average Loss: 4.045, avg. samples / sec: 54543.10
Iteration:   3380, Loss function: 2.925, Average Loss: 4.026, avg. samples / sec: 54558.95
Iteration:   3380, Loss function: 4.374, Average Loss: 4.024, avg. samples / sec: 54657.18
Iteration:   3380, Loss function: 2.742, Average Loss: 4.007, avg. samples / sec: 54587.61
Iteration:   3380, Loss function: 3.326, Average Loss: 4.020, avg. samples / sec: 54548.16
Iteration:   3380, Loss function: 3.175, Average Loss: 4.036, avg. samples / sec: 54595.33
Iteration:   3380, Loss function: 3.757, Average Loss: 4.056, avg. samples / sec: 54545.97
Iteration:   3380, Loss function: 3.394, Average Loss: 4.025, avg. samples / sec: 54547.49
Iteration:   3400, Loss function: 3.452, Average Loss: 4.014, avg. samples / sec: 54677.73
Iteration:   3400, Loss function: 4.434, Average Loss: 4.014, avg. samples / sec: 54495.18
Iteration:   3400, Loss function: 3.247, Average Loss: 4.012, avg. samples / sec: 54506.12
Iteration:   3400, Loss function: 4.195, Average Loss: 4.012, avg. samples / sec: 54797.53
Iteration:   3400, Loss function: 4.343, Average Loss: 4.021, avg. samples / sec: 54583.78
Iteration:   3400, Loss function: 3.544, Average Loss: 4.033, avg. samples / sec: 54534.08
Iteration:   3400, Loss function: 3.310, Average Loss: 4.024, avg. samples / sec: 54718.83
Iteration:   3400, Loss function: 3.945, Average Loss: 4.056, avg. samples / sec: 54528.34
Iteration:   3400, Loss function: 4.859, Average Loss: 4.001, avg. samples / sec: 54476.18
Iteration:   3400, Loss function: 3.531, Average Loss: 4.024, avg. samples / sec: 54497.83
Iteration:   3400, Loss function: 4.071, Average Loss: 4.044, avg. samples / sec: 54486.39
Iteration:   3400, Loss function: 2.064, Average Loss: 4.001, avg. samples / sec: 54486.71
Iteration:   3400, Loss function: 3.693, Average Loss: 4.000, avg. samples / sec: 54489.97
Iteration:   3400, Loss function: 3.703, Average Loss: 4.012, avg. samples / sec: 54568.38
Iteration:   3400, Loss function: 4.759, Average Loss: 4.003, avg. samples / sec: 54554.31
Iteration:   3400, Loss function: 3.294, Average Loss: 4.025, avg. samples / sec: 54520.69
Iteration:   3400, Loss function: 3.373, Average Loss: 4.025, avg. samples / sec: 54558.95
Iteration:   3400, Loss function: 3.578, Average Loss: 4.026, avg. samples / sec: 54548.39
Iteration:   3400, Loss function: 2.243, Average Loss: 4.011, avg. samples / sec: 54517.73
Iteration:   3400, Loss function: 2.464, Average Loss: 3.995, avg. samples / sec: 54567.07
Iteration:   3400, Loss function: 5.135, Average Loss: 4.033, avg. samples / sec: 54536.89
Iteration:   3400, Loss function: 4.499, Average Loss: 4.018, avg. samples / sec: 54547.49
Iteration:   3400, Loss function: 4.078, Average Loss: 4.011, avg. samples / sec: 54555.17
Iteration:   3400, Loss function: 4.224, Average Loss: 4.035, avg. samples / sec: 54531.19
Iteration:   3400, Loss function: 3.427, Average Loss: 4.043, avg. samples / sec: 54572.05
Iteration:   3400, Loss function: 3.106, Average Loss: 4.032, avg. samples / sec: 54525.73
Iteration:   3400, Loss function: 3.133, Average Loss: 4.024, avg. samples / sec: 54556.69
Iteration:   3400, Loss function: 4.309, Average Loss: 4.010, avg. samples / sec: 54527.50
Iteration:   3400, Loss function: 3.815, Average Loss: 4.010, avg. samples / sec: 54502.62
Iteration:   3400, Loss function: 3.237, Average Loss: 4.034, avg. samples / sec: 54443.32
Iteration:   3420, Loss function: 2.473, Average Loss: 4.003, avg. samples / sec: 54978.42
Iteration:   3420, Loss function: 3.162, Average Loss: 4.001, avg. samples / sec: 55008.23
Iteration:   3420, Loss function: 2.630, Average Loss: 4.000, avg. samples / sec: 55016.74
Iteration:   3420, Loss function: 3.098, Average Loss: 3.992, avg. samples / sec: 55022.28
Iteration:   3420, Loss function: 3.921, Average Loss: 4.022, avg. samples / sec: 54987.93
Iteration:   3420, Loss function: 2.672, Average Loss: 3.991, avg. samples / sec: 55057.40
Iteration:   3420, Loss function: 2.830, Average Loss: 4.010, avg. samples / sec: 54990.89
Iteration:   3420, Loss function: 3.396, Average Loss: 4.044, avg. samples / sec: 55004.45
Iteration:   3420, Loss function: 3.656, Average Loss: 4.010, avg. samples / sec: 54946.96
Iteration:   3420, Loss function: 2.542, Average Loss: 4.028, avg. samples / sec: 54975.74
Iteration:   3420, Loss function: 3.742, Average Loss: 4.011, avg. samples / sec: 54934.23
Iteration:   3420, Loss function: 2.766, Average Loss: 4.012, avg. samples / sec: 54934.94
Iteration:   3420, Loss function: 4.776, Average Loss: 3.988, avg. samples / sec: 54981.62
Iteration:   3420, Loss function: 2.485, Average Loss: 3.998, avg. samples / sec: 54996.10
Iteration:   3420, Loss function: 2.416, Average Loss: 3.990, avg. samples / sec: 54991.94
Iteration:   3420, Loss function: 3.667, Average Loss: 4.022, avg. samples / sec: 55008.17
Iteration:   3420, Loss function: 3.214, Average Loss: 4.004, avg. samples / sec: 54962.32
Iteration:   3420, Loss function: 4.295, Average Loss: 4.023, avg. samples / sec: 54995.03
Iteration:   3420, Loss function: 3.690, Average Loss: 4.014, avg. samples / sec: 54972.44
Iteration:   3420, Loss function: 3.841, Average Loss: 4.009, avg. samples / sec: 54983.34
Iteration:   3420, Loss function: 4.037, Average Loss: 3.994, avg. samples / sec: 54946.01
Iteration:   3420, Loss function: 3.723, Average Loss: 4.001, avg. samples / sec: 55043.98
Iteration:   3420, Loss function: 3.512, Average Loss: 4.014, avg. samples / sec: 54960.91
Iteration:   3420, Loss function: 3.253, Average Loss: 3.995, avg. samples / sec: 55005.44
Iteration:   3420, Loss function: 3.015, Average Loss: 4.021, avg. samples / sec: 54958.96
Iteration:   3420, Loss function: 2.693, Average Loss: 4.033, avg. samples / sec: 54969.01
Iteration:   3420, Loss function: 3.411, Average Loss: 4.023, avg. samples / sec: 55058.33
Iteration:   3420, Loss function: 3.266, Average Loss: 3.997, avg. samples / sec: 54950.21
Iteration:   3420, Loss function: 2.823, Average Loss: 4.012, avg. samples / sec: 54936.08
Iteration:   3420, Loss function: 3.853, Average Loss: 4.012, avg. samples / sec: 54956.13
:::MLL 1558640680.571 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.64s)
DONE (t=2.54s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22205
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38077
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22413
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05495
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23304
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31420
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32907
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09096
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.35397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.51982
Current AP: 0.22205 AP goal: 0.23000
:::MLL 1558640684.365 eval_accuracy: {"value": 0.22204588460349828, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558640684.466 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558640684.473 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558640684.473 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558640684.506 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558640684.507 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.179, Average Loss: 3.976, avg. samples / sec: 7405.56
Iteration:   3440, Loss function: 5.416, Average Loss: 3.996, avg. samples / sec: 7400.65
Iteration:   3440, Loss function: 3.631, Average Loss: 3.997, avg. samples / sec: 7403.57
Iteration:   3440, Loss function: 2.995, Average Loss: 3.988, avg. samples / sec: 7399.46
Iteration:   3440, Loss function: 3.715, Average Loss: 3.989, avg. samples / sec: 7401.70
Iteration:   3440, Loss function: 3.907, Average Loss: 3.979, avg. samples / sec: 7402.10
Iteration:   3440, Loss function: 4.318, Average Loss: 4.017, avg. samples / sec: 7403.18
Iteration:   3440, Loss function: 4.469, Average Loss: 4.012, avg. samples / sec: 7407.54
Iteration:   3440, Loss function: 3.618, Average Loss: 4.000, avg. samples / sec: 7403.22
Iteration:   3440, Loss function: 3.239, Average Loss: 3.991, avg. samples / sec: 7407.07
Iteration:   3440, Loss function: 3.737, Average Loss: 3.979, avg. samples / sec: 7403.46
Iteration:   3440, Loss function: 3.652, Average Loss: 4.014, avg. samples / sec: 7406.33
Iteration:   3440, Loss function: 3.513, Average Loss: 3.999, avg. samples / sec: 7401.77
Iteration:   3440, Loss function: 3.026, Average Loss: 4.008, avg. samples / sec: 7401.50
Iteration:   3440, Loss function: 3.769, Average Loss: 3.999, avg. samples / sec: 7402.87
Iteration:   3440, Loss function: 3.714, Average Loss: 4.031, avg. samples / sec: 7401.08
Iteration:   3440, Loss function: 2.509, Average Loss: 3.976, avg. samples / sec: 7402.17
Iteration:   3440, Loss function: 3.547, Average Loss: 3.990, avg. samples / sec: 7402.96
Iteration:   3440, Loss function: 2.466, Average Loss: 3.981, avg. samples / sec: 7402.60
Iteration:   3440, Loss function: 4.628, Average Loss: 3.986, avg. samples / sec: 7401.86
Iteration:   3440, Loss function: 2.776, Average Loss: 3.995, avg. samples / sec: 7402.71
Iteration:   3440, Loss function: 2.466, Average Loss: 4.009, avg. samples / sec: 7401.92
Iteration:   3440, Loss function: 3.871, Average Loss: 3.992, avg. samples / sec: 7401.68
Iteration:   3440, Loss function: 3.780, Average Loss: 4.001, avg. samples / sec: 7402.03
Iteration:   3440, Loss function: 2.153, Average Loss: 4.004, avg. samples / sec: 7401.89
Iteration:   3440, Loss function: 4.000, Average Loss: 4.002, avg. samples / sec: 7402.21
Iteration:   3440, Loss function: 3.761, Average Loss: 4.029, avg. samples / sec: 7402.19
Iteration:   3440, Loss function: 2.887, Average Loss: 4.011, avg. samples / sec: 7401.92
Iteration:   3440, Loss function: 3.431, Average Loss: 4.008, avg. samples / sec: 7402.01
Iteration:   3440, Loss function: 2.487, Average Loss: 3.989, avg. samples / sec: 7401.08
Iteration:   3460, Loss function: 4.491, Average Loss: 3.971, avg. samples / sec: 53722.97
Iteration:   3460, Loss function: 4.886, Average Loss: 4.003, avg. samples / sec: 53773.01
Iteration:   3460, Loss function: 3.450, Average Loss: 3.984, avg. samples / sec: 53776.10
Iteration:   3460, Loss function: 2.763, Average Loss: 3.968, avg. samples / sec: 53753.50
Iteration:   3460, Loss function: 3.503, Average Loss: 3.994, avg. samples / sec: 53763.71
Iteration:   3460, Loss function: 3.253, Average Loss: 3.987, avg. samples / sec: 53780.45
Iteration:   3460, Loss function: 4.026, Average Loss: 3.969, avg. samples / sec: 53754.14
Iteration:   3460, Loss function: 4.179, Average Loss: 3.985, avg. samples / sec: 53675.60
Iteration:   3460, Loss function: 3.043, Average Loss: 4.001, avg. samples / sec: 53768.16
Iteration:   3460, Loss function: 2.440, Average Loss: 4.025, avg. samples / sec: 53780.66
Iteration:   3460, Loss function: 2.864, Average Loss: 3.979, avg. samples / sec: 53690.40
Iteration:   3460, Loss function: 3.325, Average Loss: 4.005, avg. samples / sec: 53701.58
Iteration:   3460, Loss function: 3.008, Average Loss: 3.992, avg. samples / sec: 53723.46
Iteration:   3460, Loss function: 3.410, Average Loss: 3.985, avg. samples / sec: 53545.83
Iteration:   3460, Loss function: 3.769, Average Loss: 3.974, avg. samples / sec: 53606.41
Iteration:   3460, Loss function: 3.336, Average Loss: 3.961, avg. samples / sec: 53735.07
Iteration:   3460, Loss function: 2.810, Average Loss: 3.973, avg. samples / sec: 53739.79
Iteration:   3460, Loss function: 4.730, Average Loss: 3.989, avg. samples / sec: 53756.08
Iteration:   3460, Loss function: 4.161, Average Loss: 3.985, avg. samples / sec: 53755.20
Iteration:   3460, Loss function: 4.932, Average Loss: 3.982, avg. samples / sec: 53742.53
Iteration:   3460, Loss function: 3.503, Average Loss: 3.980, avg. samples / sec: 53713.92
Iteration:   3460, Loss function: 3.061, Average Loss: 4.017, avg. samples / sec: 53748.95
Iteration:   3460, Loss function: 4.024, Average Loss: 3.995, avg. samples / sec: 53734.52
Iteration:   3460, Loss function: 4.124, Average Loss: 3.996, avg. samples / sec: 53727.13
Iteration:   3460, Loss function: 4.058, Average Loss: 4.002, avg. samples / sec: 53768.51
Iteration:   3460, Loss function: 3.038, Average Loss: 3.993, avg. samples / sec: 53723.97
Iteration:   3460, Loss function: 3.797, Average Loss: 4.002, avg. samples / sec: 53728.78
Iteration:   3460, Loss function: 2.398, Average Loss: 3.977, avg. samples / sec: 53759.94
Iteration:   3460, Loss function: 4.117, Average Loss: 3.984, avg. samples / sec: 53678.11
Iteration:   3460, Loss function: 3.700, Average Loss: 4.007, avg. samples / sec: 53417.04
Iteration:   3480, Loss function: 3.522, Average Loss: 3.961, avg. samples / sec: 54070.65
Iteration:   3480, Loss function: 3.206, Average Loss: 3.973, avg. samples / sec: 54321.48
Iteration:   3480, Loss function: 4.853, Average Loss: 3.987, avg. samples / sec: 54034.19
Iteration:   3480, Loss function: 3.258, Average Loss: 3.994, avg. samples / sec: 54017.53
Iteration:   3480, Loss function: 3.746, Average Loss: 3.954, avg. samples / sec: 54022.05
Iteration:   3480, Loss function: 3.207, Average Loss: 3.968, avg. samples / sec: 54072.02
Iteration:   3480, Loss function: 4.092, Average Loss: 3.982, avg. samples / sec: 54091.61
Iteration:   3480, Loss function: 3.870, Average Loss: 3.961, avg. samples / sec: 54147.42
Iteration:   3480, Loss function: 3.668, Average Loss: 3.995, avg. samples / sec: 54350.44
Iteration:   3480, Loss function: 4.713, Average Loss: 3.990, avg. samples / sec: 54037.34
Iteration:   3480, Loss function: 3.098, Average Loss: 3.978, avg. samples / sec: 53986.47
Iteration:   3480, Loss function: 2.750, Average Loss: 3.972, avg. samples / sec: 54035.70
Iteration:   3480, Loss function: 2.555, Average Loss: 4.015, avg. samples / sec: 54046.21
Iteration:   3480, Loss function: 4.337, Average Loss: 3.997, avg. samples / sec: 54053.44
Iteration:   3480, Loss function: 3.384, Average Loss: 3.953, avg. samples / sec: 53915.47
Iteration:   3480, Loss function: 3.418, Average Loss: 3.982, avg. samples / sec: 53871.14
Iteration:   3480, Loss function: 3.077, Average Loss: 3.954, avg. samples / sec: 54043.37
Iteration:   3480, Loss function: 3.420, Average Loss: 3.967, avg. samples / sec: 54070.34
Iteration:   3480, Loss function: 3.175, Average Loss: 3.968, avg. samples / sec: 54063.83
Iteration:   3480, Loss function: 3.493, Average Loss: 3.981, avg. samples / sec: 54069.45
Iteration:   3480, Loss function: 4.185, Average Loss: 3.985, avg. samples / sec: 54062.98
Iteration:   3480, Loss function: 2.997, Average Loss: 3.979, avg. samples / sec: 54033.71
Iteration:   3480, Loss function: 3.125, Average Loss: 3.980, avg. samples / sec: 54032.76
Iteration:   3480, Loss function: 3.898, Average Loss: 4.004, avg. samples / sec: 54035.78
Iteration:   3480, Loss function: 2.836, Average Loss: 3.989, avg. samples / sec: 54040.61
Iteration:   3480, Loss function: 2.868, Average Loss: 3.963, avg. samples / sec: 54000.11
Iteration:   3480, Loss function: 3.984, Average Loss: 3.972, avg. samples / sec: 54075.09
Iteration:   3480, Loss function: 3.557, Average Loss: 3.969, avg. samples / sec: 54064.04
Iteration:   3480, Loss function: 4.072, Average Loss: 3.987, avg. samples / sec: 54024.24
Iteration:   3480, Loss function: 4.263, Average Loss: 3.996, avg. samples / sec: 54024.47
:::MLL 1558640686.690 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558640686.690 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 2.544, Average Loss: 3.954, avg. samples / sec: 53973.68
Iteration:   3500, Loss function: 4.774, Average Loss: 3.965, avg. samples / sec: 53900.23
Iteration:   3500, Loss function: 3.321, Average Loss: 3.949, avg. samples / sec: 54086.32
Iteration:   3500, Loss function: 4.380, Average Loss: 3.978, avg. samples / sec: 53995.04
Iteration:   3500, Loss function: 3.039, Average Loss: 3.954, avg. samples / sec: 54259.01
Iteration:   3500, Loss function: 3.289, Average Loss: 3.944, avg. samples / sec: 53966.77
Iteration:   3500, Loss function: 2.892, Average Loss: 3.983, avg. samples / sec: 53941.61
Iteration:   3500, Loss function: 3.419, Average Loss: 3.945, avg. samples / sec: 54088.08
Iteration:   3500, Loss function: 2.595, Average Loss: 3.961, avg. samples / sec: 53961.40
Iteration:   3500, Loss function: 4.195, Average Loss: 3.966, avg. samples / sec: 53951.15
Iteration:   3500, Loss function: 3.072, Average Loss: 3.978, avg. samples / sec: 53911.98
Iteration:   3500, Loss function: 3.098, Average Loss: 3.983, avg. samples / sec: 53971.59
Iteration:   3500, Loss function: 4.156, Average Loss: 3.987, avg. samples / sec: 53935.30
Iteration:   3500, Loss function: 2.762, Average Loss: 4.006, avg. samples / sec: 53924.42
Iteration:   3500, Loss function: 4.285, Average Loss: 3.958, avg. samples / sec: 53901.90
Iteration:   3500, Loss function: 2.245, Average Loss: 3.972, avg. samples / sec: 54048.92
Iteration:   3500, Loss function: 2.553, Average Loss: 3.970, avg. samples / sec: 53887.82
Iteration:   3500, Loss function: 3.938, Average Loss: 3.974, avg. samples / sec: 54081.38
Iteration:   3500, Loss function: 3.807, Average Loss: 3.976, avg. samples / sec: 54067.25
Iteration:   3500, Loss function: 3.053, Average Loss: 3.965, avg. samples / sec: 54052.13
Iteration:   3500, Loss function: 3.435, Average Loss: 3.993, avg. samples / sec: 54065.76
Iteration:   3500, Loss function: 2.832, Average Loss: 3.981, avg. samples / sec: 54104.70
Iteration:   3500, Loss function: 3.309, Average Loss: 3.960, avg. samples / sec: 54064.76
Iteration:   3500, Loss function: 4.529, Average Loss: 3.981, avg. samples / sec: 54058.23
Iteration:   3500, Loss function: 3.345, Average Loss: 3.967, avg. samples / sec: 54006.73
Iteration:   3500, Loss function: 4.609, Average Loss: 3.959, avg. samples / sec: 53953.76
Iteration:   3500, Loss function: 3.844, Average Loss: 3.943, avg. samples / sec: 53933.93
Iteration:   3500, Loss function: 4.742, Average Loss: 3.960, avg. samples / sec: 53969.23
Iteration:   3500, Loss function: 2.112, Average Loss: 3.982, avg. samples / sec: 53939.80
Iteration:   3500, Loss function: 2.851, Average Loss: 3.958, avg. samples / sec: 53900.45
Iteration:   3520, Loss function: 2.678, Average Loss: 3.945, avg. samples / sec: 54322.07
Iteration:   3520, Loss function: 2.997, Average Loss: 3.959, avg. samples / sec: 54328.48
Iteration:   3520, Loss function: 3.644, Average Loss: 3.958, avg. samples / sec: 54426.21
Iteration:   3520, Loss function: 2.787, Average Loss: 3.958, avg. samples / sec: 54415.43
Iteration:   3520, Loss function: 2.426, Average Loss: 3.972, avg. samples / sec: 54317.55
Iteration:   3520, Loss function: 2.633, Average Loss: 3.971, avg. samples / sec: 54327.77
Iteration:   3520, Loss function: 2.219, Average Loss: 3.932, avg. samples / sec: 54317.23
Iteration:   3520, Loss function: 4.194, Average Loss: 3.966, avg. samples / sec: 54348.91
Iteration:   3520, Loss function: 3.700, Average Loss: 3.940, avg. samples / sec: 54206.96
Iteration:   3520, Loss function: 3.013, Average Loss: 3.935, avg. samples / sec: 54287.27
Iteration:   3520, Loss function: 2.940, Average Loss: 3.995, avg. samples / sec: 54344.57
Iteration:   3520, Loss function: 4.127, Average Loss: 3.947, avg. samples / sec: 54342.70
Iteration:   3520, Loss function: 3.670, Average Loss: 3.972, avg. samples / sec: 54301.98
Iteration:   3520, Loss function: 3.730, Average Loss: 3.973, avg. samples / sec: 54294.21
Iteration:   3520, Loss function: 3.617, Average Loss: 3.959, avg. samples / sec: 54215.68
Iteration:   3520, Loss function: 2.800, Average Loss: 3.932, avg. samples / sec: 54394.66
Iteration:   3520, Loss function: 2.761, Average Loss: 3.963, avg. samples / sec: 54257.97
Iteration:   3520, Loss function: 2.902, Average Loss: 3.973, avg. samples / sec: 54306.60
Iteration:   3520, Loss function: 3.882, Average Loss: 3.963, avg. samples / sec: 54316.37
Iteration:   3520, Loss function: 3.572, Average Loss: 3.948, avg. samples / sec: 54353.98
Iteration:   3520, Loss function: 2.577, Average Loss: 3.971, avg. samples / sec: 54299.53
Iteration:   3520, Loss function: 4.639, Average Loss: 3.944, avg. samples / sec: 54081.19
Iteration:   3520, Loss function: 4.124, Average Loss: 3.951, avg. samples / sec: 54253.08
Iteration:   3520, Loss function: 3.921, Average Loss: 3.949, avg. samples / sec: 54384.48
Iteration:   3520, Loss function: 2.837, Average Loss: 3.961, avg. samples / sec: 54217.60
Iteration:   3520, Loss function: 3.601, Average Loss: 3.955, avg. samples / sec: 54342.35
Iteration:   3520, Loss function: 3.943, Average Loss: 3.946, avg. samples / sec: 54238.44
Iteration:   3520, Loss function: 3.488, Average Loss: 3.950, avg. samples / sec: 54052.24
Iteration:   3520, Loss function: 3.541, Average Loss: 3.971, avg. samples / sec: 54345.07
Iteration:   3520, Loss function: 3.617, Average Loss: 3.978, avg. samples / sec: 54212.01
Iteration:   3540, Loss function: 3.509, Average Loss: 3.946, avg. samples / sec: 54490.16
Iteration:   3540, Loss function: 2.792, Average Loss: 3.932, avg. samples / sec: 54397.20
Iteration:   3540, Loss function: 2.425, Average Loss: 3.940, avg. samples / sec: 54786.81
Iteration:   3540, Loss function: 3.485, Average Loss: 3.942, avg. samples / sec: 54391.99
Iteration:   3540, Loss function: 3.725, Average Loss: 3.962, avg. samples / sec: 54517.80
Iteration:   3540, Loss function: 3.704, Average Loss: 3.925, avg. samples / sec: 54451.21
Iteration:   3540, Loss function: 3.425, Average Loss: 3.956, avg. samples / sec: 54436.32
Iteration:   3540, Loss function: 3.627, Average Loss: 3.929, avg. samples / sec: 54469.16
Iteration:   3540, Loss function: 3.003, Average Loss: 3.959, avg. samples / sec: 54424.57
Iteration:   3540, Loss function: 3.297, Average Loss: 3.936, avg. samples / sec: 54470.62
Iteration:   3540, Loss function: 3.367, Average Loss: 3.934, avg. samples / sec: 54424.70
Iteration:   3540, Loss function: 3.745, Average Loss: 3.959, avg. samples / sec: 54386.13
Iteration:   3540, Loss function: 3.598, Average Loss: 3.990, avg. samples / sec: 54411.52
Iteration:   3540, Loss function: 2.709, Average Loss: 3.960, avg. samples / sec: 54416.63
Iteration:   3540, Loss function: 3.154, Average Loss: 3.948, avg. samples / sec: 54335.47
Iteration:   3540, Loss function: 2.915, Average Loss: 3.947, avg. samples / sec: 54448.63
Iteration:   3540, Loss function: 3.096, Average Loss: 3.934, avg. samples / sec: 54464.22
Iteration:   3540, Loss function: 2.930, Average Loss: 3.956, avg. samples / sec: 54457.15
Iteration:   3540, Loss function: 2.591, Average Loss: 3.935, avg. samples / sec: 54441.22
Iteration:   3540, Loss function: 3.072, Average Loss: 3.954, avg. samples / sec: 54396.82
Iteration:   3540, Loss function: 3.946, Average Loss: 3.920, avg. samples / sec: 54398.33
Iteration:   3540, Loss function: 5.192, Average Loss: 3.950, avg. samples / sec: 54449.72
Iteration:   3540, Loss function: 3.451, Average Loss: 3.941, avg. samples / sec: 54434.22
Iteration:   3540, Loss function: 1.982, Average Loss: 3.958, avg. samples / sec: 54471.80
Iteration:   3540, Loss function: 3.372, Average Loss: 3.958, avg. samples / sec: 54397.89
Iteration:   3540, Loss function: 3.589, Average Loss: 3.969, avg. samples / sec: 54463.80
Iteration:   3540, Loss function: 2.781, Average Loss: 3.942, avg. samples / sec: 54431.42
Iteration:   3540, Loss function: 3.016, Average Loss: 3.937, avg. samples / sec: 54402.45
Iteration:   3540, Loss function: 3.130, Average Loss: 3.935, avg. samples / sec: 54433.69
Iteration:   3540, Loss function: 3.238, Average Loss: 3.962, avg. samples / sec: 54306.27
:::MLL 1558640688.545 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558640688.546 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 3.382, Average Loss: 3.927, avg. samples / sec: 54368.61
Iteration:   3560, Loss function: 2.678, Average Loss: 3.933, avg. samples / sec: 54155.36
Iteration:   3560, Loss function: 2.140, Average Loss: 3.919, avg. samples / sec: 54174.27
Iteration:   3560, Loss function: 3.502, Average Loss: 3.948, avg. samples / sec: 54324.60
Iteration:   3560, Loss function: 2.919, Average Loss: 3.950, avg. samples / sec: 54313.74
Iteration:   3560, Loss function: 4.094, Average Loss: 3.932, avg. samples / sec: 54197.69
Iteration:   3560, Loss function: 3.562, Average Loss: 3.947, avg. samples / sec: 54210.07
Iteration:   3560, Loss function: 3.238, Average Loss: 3.920, avg. samples / sec: 54213.91
Iteration:   3560, Loss function: 3.708, Average Loss: 3.912, avg. samples / sec: 54187.22
Iteration:   3560, Loss function: 2.995, Average Loss: 3.929, avg. samples / sec: 54145.71
Iteration:   3560, Loss function: 3.376, Average Loss: 3.952, avg. samples / sec: 54205.40
Iteration:   3560, Loss function: 2.498, Average Loss: 3.947, avg. samples / sec: 54173.08
Iteration:   3560, Loss function: 4.719, Average Loss: 3.926, avg. samples / sec: 54201.06
Iteration:   3560, Loss function: 3.258, Average Loss: 3.937, avg. samples / sec: 54278.28
Iteration:   3560, Loss function: 4.732, Average Loss: 3.974, avg. samples / sec: 54227.30
Iteration:   3560, Loss function: 3.087, Average Loss: 3.941, avg. samples / sec: 54321.50
Iteration:   3560, Loss function: 3.833, Average Loss: 3.924, avg. samples / sec: 54339.58
Iteration:   3560, Loss function: 2.860, Average Loss: 3.920, avg. samples / sec: 54407.89
Iteration:   3560, Loss function: 2.744, Average Loss: 3.936, avg. samples / sec: 54335.93
Iteration:   3560, Loss function: 2.950, Average Loss: 3.953, avg. samples / sec: 54425.83
Iteration:   3560, Loss function: 2.391, Average Loss: 3.941, avg. samples / sec: 54345.74
Iteration:   3560, Loss function: 2.254, Average Loss: 3.959, avg. samples / sec: 54324.77
Iteration:   3560, Loss function: 2.950, Average Loss: 3.923, avg. samples / sec: 54298.65
Iteration:   3560, Loss function: 2.300, Average Loss: 3.942, avg. samples / sec: 54291.91
Iteration:   3560, Loss function: 2.966, Average Loss: 3.908, avg. samples / sec: 54261.60
Iteration:   3560, Loss function: 4.156, Average Loss: 3.943, avg. samples / sec: 54200.67
Iteration:   3560, Loss function: 3.299, Average Loss: 3.926, avg. samples / sec: 54255.21
Iteration:   3560, Loss function: 2.489, Average Loss: 3.927, avg. samples / sec: 54195.00
Iteration:   3560, Loss function: 3.610, Average Loss: 3.946, avg. samples / sec: 54190.02
Iteration:   3560, Loss function: 1.981, Average Loss: 3.934, avg. samples / sec: 54198.00
Iteration:   3580, Loss function: 4.370, Average Loss: 3.905, avg. samples / sec: 54784.49
Iteration:   3580, Loss function: 3.396, Average Loss: 3.921, avg. samples / sec: 54749.01
Iteration:   3580, Loss function: 4.689, Average Loss: 3.922, avg. samples / sec: 54806.16
Iteration:   3580, Loss function: 3.732, Average Loss: 3.938, avg. samples / sec: 54790.61
Iteration:   3580, Loss function: 4.318, Average Loss: 3.928, avg. samples / sec: 54716.02
Iteration:   3580, Loss function: 4.057, Average Loss: 3.914, avg. samples / sec: 54582.32
Iteration:   3580, Loss function: 3.774, Average Loss: 3.963, avg. samples / sec: 54781.40
Iteration:   3580, Loss function: 5.491, Average Loss: 3.906, avg. samples / sec: 54730.71
Iteration:   3580, Loss function: 4.438, Average Loss: 3.943, avg. samples / sec: 54732.49
Iteration:   3580, Loss function: 3.910, Average Loss: 3.939, avg. samples / sec: 54702.96
Iteration:   3580, Loss function: 2.981, Average Loss: 3.923, avg. samples / sec: 54743.70
Iteration:   3580, Loss function: 2.933, Average Loss: 3.933, avg. samples / sec: 54636.86
Iteration:   3580, Loss function: 3.179, Average Loss: 3.910, avg. samples / sec: 54717.57
Iteration:   3580, Loss function: 3.232, Average Loss: 3.941, avg. samples / sec: 54726.84
Iteration:   3580, Loss function: 3.618, Average Loss: 3.931, avg. samples / sec: 54767.74
Iteration:   3580, Loss function: 3.025, Average Loss: 3.915, avg. samples / sec: 54712.33
Iteration:   3580, Loss function: 4.070, Average Loss: 3.937, avg. samples / sec: 54832.26
Iteration:   3580, Loss function: 3.348, Average Loss: 3.912, avg. samples / sec: 54781.62
Iteration:   3580, Loss function: 3.662, Average Loss: 3.917, avg. samples / sec: 54614.26
Iteration:   3580, Loss function: 3.033, Average Loss: 3.926, avg. samples / sec: 54641.56
Iteration:   3580, Loss function: 3.199, Average Loss: 3.936, avg. samples / sec: 54684.66
Iteration:   3580, Loss function: 3.425, Average Loss: 3.898, avg. samples / sec: 54701.20
Iteration:   3580, Loss function: 3.795, Average Loss: 3.912, avg. samples / sec: 54667.52
Iteration:   3580, Loss function: 4.146, Average Loss: 3.915, avg. samples / sec: 54581.06
Iteration:   3580, Loss function: 3.363, Average Loss: 3.942, avg. samples / sec: 54609.57
Iteration:   3580, Loss function: 3.097, Average Loss: 3.911, avg. samples / sec: 54714.32
Iteration:   3580, Loss function: 2.947, Average Loss: 3.934, avg. samples / sec: 54748.55
Iteration:   3580, Loss function: 4.322, Average Loss: 3.951, avg. samples / sec: 54627.69
Iteration:   3580, Loss function: 5.917, Average Loss: 3.925, avg. samples / sec: 54755.84
Iteration:   3580, Loss function: 3.375, Average Loss: 3.932, avg. samples / sec: 54601.00
Iteration:   3600, Loss function: 2.912, Average Loss: 3.898, avg. samples / sec: 54278.41
Iteration:   3600, Loss function: 3.344, Average Loss: 3.923, avg. samples / sec: 54340.02
Iteration:   3600, Loss function: 3.842, Average Loss: 3.930, avg. samples / sec: 54275.63
Iteration:   3600, Loss function: 2.559, Average Loss: 3.897, avg. samples / sec: 54315.35
Iteration:   3600, Loss function: 3.067, Average Loss: 3.909, avg. samples / sec: 54221.54
Iteration:   3600, Loss function: 3.421, Average Loss: 3.923, avg. samples / sec: 54316.86
Iteration:   3600, Loss function: 3.649, Average Loss: 3.905, avg. samples / sec: 54325.00
Iteration:   3600, Loss function: 3.376, Average Loss: 3.934, avg. samples / sec: 54295.51
Iteration:   3600, Loss function: 5.394, Average Loss: 3.921, avg. samples / sec: 54280.04
Iteration:   3600, Loss function: 3.430, Average Loss: 3.895, avg. samples / sec: 54273.95
Iteration:   3600, Loss function: 4.144, Average Loss: 3.900, avg. samples / sec: 54242.12
Iteration:   3600, Loss function: 2.924, Average Loss: 3.913, avg. samples / sec: 54249.53
Iteration:   3600, Loss function: 2.822, Average Loss: 3.953, avg. samples / sec: 54230.85
Iteration:   3600, Loss function: 4.382, Average Loss: 3.934, avg. samples / sec: 54197.12
Iteration:   3600, Loss function: 3.833, Average Loss: 3.909, avg. samples / sec: 54265.99
Iteration:   3600, Loss function: 2.767, Average Loss: 3.934, avg. samples / sec: 54307.02
Iteration:   3600, Loss function: 3.199, Average Loss: 3.910, avg. samples / sec: 53910.81
Iteration:   3600, Loss function: 4.429, Average Loss: 3.901, avg. samples / sec: 54285.83
Iteration:   3600, Loss function: 2.668, Average Loss: 3.924, avg. samples / sec: 54261.12
Iteration:   3600, Loss function: 4.045, Average Loss: 3.911, avg. samples / sec: 54251.76
Iteration:   3600, Loss function: 2.844, Average Loss: 3.902, avg. samples / sec: 54278.72
Iteration:   3600, Loss function: 3.204, Average Loss: 3.928, avg. samples / sec: 54142.15
Iteration:   3600, Loss function: 2.366, Average Loss: 3.923, avg. samples / sec: 54282.63
Iteration:   3600, Loss function: 2.189, Average Loss: 3.930, avg. samples / sec: 54029.90
Iteration:   3600, Loss function: 2.998, Average Loss: 3.891, avg. samples / sec: 54231.37
Iteration:   3600, Loss function: 3.372, Average Loss: 3.941, avg. samples / sec: 54265.78
Iteration:   3600, Loss function: 2.913, Average Loss: 3.923, avg. samples / sec: 54256.03
Iteration:   3600, Loss function: 3.530, Average Loss: 3.911, avg. samples / sec: 54251.03
Iteration:   3600, Loss function: 2.142, Average Loss: 3.902, avg. samples / sec: 54225.19
Iteration:   3600, Loss function: 2.910, Average Loss: 3.900, avg. samples / sec: 54183.27
Iteration:   3620, Loss function: 4.473, Average Loss: 3.893, avg. samples / sec: 54060.74
Iteration:   3620, Loss function: 3.007, Average Loss: 3.894, avg. samples / sec: 54113.13
Iteration:   3620, Loss function: 3.404, Average Loss: 3.939, avg. samples / sec: 54152.06
Iteration:   3620, Loss function: 3.340, Average Loss: 3.923, avg. samples / sec: 54041.11
Iteration:   3620, Loss function: 2.792, Average Loss: 3.889, avg. samples / sec: 54067.31
Iteration:   3620, Loss function: 4.042, Average Loss: 3.911, avg. samples / sec: 54036.63
Iteration:   3620, Loss function: 3.493, Average Loss: 3.913, avg. samples / sec: 54108.71
Iteration:   3620, Loss function: 3.474, Average Loss: 3.924, avg. samples / sec: 54085.95
Iteration:   3620, Loss function: 4.721, Average Loss: 3.895, avg. samples / sec: 54119.86
Iteration:   3620, Loss function: 3.484, Average Loss: 3.928, avg. samples / sec: 54158.97
Iteration:   3620, Loss function: 3.130, Average Loss: 3.924, avg. samples / sec: 54324.06
Iteration:   3620, Loss function: 2.708, Average Loss: 3.905, avg. samples / sec: 54043.86
Iteration:   3620, Loss function: 2.463, Average Loss: 3.899, avg. samples / sec: 54083.39
Iteration:   3620, Loss function: 2.980, Average Loss: 3.885, avg. samples / sec: 54063.52
Iteration:   3620, Loss function: 3.518, Average Loss: 3.914, avg. samples / sec: 54009.75
Iteration:   3620, Loss function: 4.502, Average Loss: 3.900, avg. samples / sec: 54079.45
Iteration:   3620, Loss function: 4.167, Average Loss: 3.919, avg. samples / sec: 54115.25
Iteration:   3620, Loss function: 3.240, Average Loss: 3.904, avg. samples / sec: 54081.82
Iteration:   3620, Loss function: 2.692, Average Loss: 3.881, avg. samples / sec: 54106.40
Iteration:   3620, Loss function: 2.995, Average Loss: 3.896, avg. samples / sec: 54059.76
Iteration:   3620, Loss function: 2.617, Average Loss: 3.891, avg. samples / sec: 54124.65
Iteration:   3620, Loss function: 3.028, Average Loss: 3.931, avg. samples / sec: 54102.10
Iteration:   3620, Loss function: 3.812, Average Loss: 3.892, avg. samples / sec: 54120.20
Iteration:   3620, Loss function: 3.547, Average Loss: 3.912, avg. samples / sec: 54115.79
Iteration:   3620, Loss function: 4.207, Average Loss: 3.916, avg. samples / sec: 54078.66
Iteration:   3620, Loss function: 3.087, Average Loss: 3.890, avg. samples / sec: 54044.63
Iteration:   3620, Loss function: 2.971, Average Loss: 3.893, avg. samples / sec: 54072.79
Iteration:   3620, Loss function: 4.305, Average Loss: 3.902, avg. samples / sec: 54099.57
Iteration:   3620, Loss function: 2.670, Average Loss: 3.919, avg. samples / sec: 54037.07
Iteration:   3620, Loss function: 3.208, Average Loss: 3.920, avg. samples / sec: 54027.18
:::MLL 1558640690.716 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558640690.717 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 3.330, Average Loss: 3.928, avg. samples / sec: 53668.49
Iteration:   3640, Loss function: 3.589, Average Loss: 3.885, avg. samples / sec: 53524.99
Iteration:   3640, Loss function: 3.052, Average Loss: 3.884, avg. samples / sec: 53870.23
Iteration:   3640, Loss function: 4.059, Average Loss: 3.919, avg. samples / sec: 53554.05
Iteration:   3640, Loss function: 4.323, Average Loss: 3.885, avg. samples / sec: 53476.73
Iteration:   3640, Loss function: 3.893, Average Loss: 3.920, avg. samples / sec: 53501.88
Iteration:   3640, Loss function: 3.946, Average Loss: 3.912, avg. samples / sec: 53484.58
Iteration:   3640, Loss function: 4.161, Average Loss: 3.877, avg. samples / sec: 53538.61
Iteration:   3640, Loss function: 4.199, Average Loss: 3.903, avg. samples / sec: 53474.60
Iteration:   3640, Loss function: 2.926, Average Loss: 3.916, avg. samples / sec: 53499.95
Iteration:   3640, Loss function: 3.690, Average Loss: 3.902, avg. samples / sec: 53461.43
Iteration:   3640, Loss function: 3.420, Average Loss: 3.901, avg. samples / sec: 53535.17
Iteration:   3640, Loss function: 2.581, Average Loss: 3.890, avg. samples / sec: 53505.97
Iteration:   3640, Loss function: 3.030, Average Loss: 3.896, avg. samples / sec: 53482.47
Iteration:   3640, Loss function: 2.878, Average Loss: 3.886, avg. samples / sec: 53457.82
Iteration:   3640, Loss function: 4.757, Average Loss: 3.884, avg. samples / sec: 53431.37
Iteration:   3640, Loss function: 2.380, Average Loss: 3.873, avg. samples / sec: 53666.69
Iteration:   3640, Loss function: 2.479, Average Loss: 3.888, avg. samples / sec: 53493.58
Iteration:   3640, Loss function: 2.959, Average Loss: 3.882, avg. samples / sec: 53509.64
Iteration:   3640, Loss function: 2.623, Average Loss: 3.908, avg. samples / sec: 53535.15
Iteration:   3640, Loss function: 3.185, Average Loss: 3.892, avg. samples / sec: 53530.17
Iteration:   3640, Loss function: 2.783, Average Loss: 3.901, avg. samples / sec: 53508.57
Iteration:   3640, Loss function: 3.377, Average Loss: 3.892, avg. samples / sec: 53479.04
Iteration:   3640, Loss function: 2.536, Average Loss: 3.882, avg. samples / sec: 53505.62
Iteration:   3640, Loss function: 3.930, Average Loss: 3.910, avg. samples / sec: 53468.37
Iteration:   3640, Loss function: 2.147, Average Loss: 3.903, avg. samples / sec: 53497.60
Iteration:   3640, Loss function: 3.233, Average Loss: 3.880, avg. samples / sec: 53507.35
Iteration:   3640, Loss function: 3.442, Average Loss: 3.911, avg. samples / sec: 53513.00
Iteration:   3640, Loss function: 4.231, Average Loss: 3.926, avg. samples / sec: 53489.01
Iteration:   3640, Loss function: 3.797, Average Loss: 3.885, avg. samples / sec: 53465.77
Iteration:   3660, Loss function: 3.303, Average Loss: 3.880, avg. samples / sec: 53770.87
Iteration:   3660, Loss function: 2.814, Average Loss: 3.918, avg. samples / sec: 53720.39
Iteration:   3660, Loss function: 2.760, Average Loss: 3.881, avg. samples / sec: 53728.29
Iteration:   3660, Loss function: 3.280, Average Loss: 3.873, avg. samples / sec: 53791.66
Iteration:   3660, Loss function: 1.927, Average Loss: 3.889, avg. samples / sec: 53810.27
Iteration:   3660, Loss function: 3.310, Average Loss: 3.876, avg. samples / sec: 53823.53
Iteration:   3660, Loss function: 2.255, Average Loss: 3.897, avg. samples / sec: 53789.24
Iteration:   3660, Loss function: 2.934, Average Loss: 3.890, avg. samples / sec: 53795.38
Iteration:   3660, Loss function: 2.955, Average Loss: 3.904, avg. samples / sec: 53755.26
Iteration:   3660, Loss function: 3.768, Average Loss: 3.877, avg. samples / sec: 53814.48
Iteration:   3660, Loss function: 3.911, Average Loss: 3.868, avg. samples / sec: 53744.38
Iteration:   3660, Loss function: 3.640, Average Loss: 3.907, avg. samples / sec: 53732.80
Iteration:   3660, Loss function: 3.179, Average Loss: 3.909, avg. samples / sec: 53655.98
Iteration:   3660, Loss function: 3.496, Average Loss: 3.905, avg. samples / sec: 53660.60
Iteration:   3660, Loss function: 3.551, Average Loss: 3.883, avg. samples / sec: 53823.07
Iteration:   3660, Loss function: 4.170, Average Loss: 3.881, avg. samples / sec: 53790.10
Iteration:   3660, Loss function: 2.197, Average Loss: 3.864, avg. samples / sec: 53639.26
Iteration:   3660, Loss function: 4.251, Average Loss: 3.903, avg. samples / sec: 53805.59
Iteration:   3660, Loss function: 3.522, Average Loss: 3.892, avg. samples / sec: 53791.83
Iteration:   3660, Loss function: 2.755, Average Loss: 3.881, avg. samples / sec: 53574.53
Iteration:   3660, Loss function: 3.254, Average Loss: 3.916, avg. samples / sec: 53802.51
Iteration:   3660, Loss function: 3.627, Average Loss: 3.877, avg. samples / sec: 53789.79
Iteration:   3660, Loss function: 3.962, Average Loss: 3.874, avg. samples / sec: 53779.14
Iteration:   3660, Loss function: 3.506, Average Loss: 3.883, avg. samples / sec: 53762.67
Iteration:   3660, Loss function: 2.586, Average Loss: 3.897, avg. samples / sec: 53750.63
Iteration:   3660, Loss function: 3.701, Average Loss: 3.891, avg. samples / sec: 53764.76
Iteration:   3660, Loss function: 2.698, Average Loss: 3.873, avg. samples / sec: 53742.84
Iteration:   3660, Loss function: 2.416, Average Loss: 3.875, avg. samples / sec: 53789.92
Iteration:   3660, Loss function: 3.440, Average Loss: 3.901, avg. samples / sec: 53751.06
Iteration:   3660, Loss function: 3.397, Average Loss: 3.887, avg. samples / sec: 53520.64
Iteration:   3680, Loss function: 2.681, Average Loss: 3.874, avg. samples / sec: 53974.75
Iteration:   3680, Loss function: 3.751, Average Loss: 3.868, avg. samples / sec: 53812.16
Iteration:   3680, Loss function: 3.083, Average Loss: 3.906, avg. samples / sec: 53842.67
Iteration:   3680, Loss function: 2.968, Average Loss: 3.877, avg. samples / sec: 54182.41
Iteration:   3680, Loss function: 3.827, Average Loss: 3.864, avg. samples / sec: 53830.41
Iteration:   3680, Loss function: 3.462, Average Loss: 3.900, avg. samples / sec: 53866.54
Iteration:   3680, Loss function: 2.540, Average Loss: 3.898, avg. samples / sec: 53950.12
Iteration:   3680, Loss function: 3.478, Average Loss: 3.863, avg. samples / sec: 53852.46
Iteration:   3680, Loss function: 3.837, Average Loss: 3.881, avg. samples / sec: 53854.93
Iteration:   3680, Loss function: 3.407, Average Loss: 3.866, avg. samples / sec: 54107.83
Iteration:   3680, Loss function: 3.836, Average Loss: 3.866, avg. samples / sec: 53853.60
Iteration:   3680, Loss function: 3.259, Average Loss: 3.890, avg. samples / sec: 53835.39
Iteration:   3680, Loss function: 3.646, Average Loss: 3.880, avg. samples / sec: 53816.58
Iteration:   3680, Loss function: 3.789, Average Loss: 3.896, avg. samples / sec: 53930.69
Iteration:   3680, Loss function: 4.985, Average Loss: 3.855, avg. samples / sec: 53852.40
Iteration:   3680, Loss function: 3.248, Average Loss: 3.897, avg. samples / sec: 53821.45
Iteration:   3680, Loss function: 3.327, Average Loss: 3.857, avg. samples / sec: 53864.13
Iteration:   3680, Loss function: 4.517, Average Loss: 3.870, avg. samples / sec: 53880.36
Iteration:   3680, Loss function: 3.824, Average Loss: 3.892, avg. samples / sec: 53845.90
Iteration:   3680, Loss function: 3.112, Average Loss: 3.871, avg. samples / sec: 53864.46
Iteration:   3680, Loss function: 3.983, Average Loss: 3.865, avg. samples / sec: 53885.86
Iteration:   3680, Loss function: 4.563, Average Loss: 3.874, avg. samples / sec: 53866.17
Iteration:   3680, Loss function: 3.355, Average Loss: 3.871, avg. samples / sec: 53809.98
Iteration:   3680, Loss function: 3.450, Average Loss: 3.870, avg. samples / sec: 53810.31
Iteration:   3680, Loss function: 3.274, Average Loss: 3.892, avg. samples / sec: 53864.65
Iteration:   3680, Loss function: 2.720, Average Loss: 3.880, avg. samples / sec: 53817.67
Iteration:   3680, Loss function: 4.041, Average Loss: 3.877, avg. samples / sec: 53849.85
Iteration:   3680, Loss function: 3.187, Average Loss: 3.899, avg. samples / sec: 53805.98
Iteration:   3680, Loss function: 3.845, Average Loss: 3.889, avg. samples / sec: 53848.45
Iteration:   3680, Loss function: 1.998, Average Loss: 3.868, avg. samples / sec: 53798.91
:::MLL 1558640692.908 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558640692.908 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 2.874, Average Loss: 3.858, avg. samples / sec: 53338.15
Iteration:   3700, Loss function: 2.672, Average Loss: 3.894, avg. samples / sec: 53266.52
Iteration:   3700, Loss function: 3.098, Average Loss: 3.862, avg. samples / sec: 53175.21
Iteration:   3700, Loss function: 3.253, Average Loss: 3.851, avg. samples / sec: 53346.53
Iteration:   3700, Loss function: 3.367, Average Loss: 3.885, avg. samples / sec: 53364.83
Iteration:   3700, Loss function: 3.586, Average Loss: 3.889, avg. samples / sec: 53313.49
Iteration:   3700, Loss function: 4.752, Average Loss: 3.871, avg. samples / sec: 53256.01
Iteration:   3700, Loss function: 3.225, Average Loss: 3.848, avg. samples / sec: 53307.56
Iteration:   3700, Loss function: 2.837, Average Loss: 3.874, avg. samples / sec: 53282.51
Iteration:   3700, Loss function: 4.018, Average Loss: 3.854, avg. samples / sec: 53264.10
Iteration:   3700, Loss function: 3.148, Average Loss: 3.854, avg. samples / sec: 53239.80
Iteration:   3700, Loss function: 2.523, Average Loss: 3.886, avg. samples / sec: 53333.79
Iteration:   3700, Loss function: 2.916, Average Loss: 3.871, avg. samples / sec: 53255.25
Iteration:   3700, Loss function: 2.952, Average Loss: 3.885, avg. samples / sec: 53243.96
Iteration:   3700, Loss function: 4.122, Average Loss: 3.857, avg. samples / sec: 53214.81
Iteration:   3700, Loss function: 2.276, Average Loss: 3.860, avg. samples / sec: 53451.27
Iteration:   3700, Loss function: 3.253, Average Loss: 3.889, avg. samples / sec: 53147.84
Iteration:   3700, Loss function: 3.921, Average Loss: 3.893, avg. samples / sec: 53432.75
Iteration:   3700, Loss function: 3.045, Average Loss: 3.869, avg. samples / sec: 53403.07
Iteration:   3700, Loss function: 2.628, Average Loss: 3.859, avg. samples / sec: 53362.67
Iteration:   3700, Loss function: 3.496, Average Loss: 3.863, avg. samples / sec: 53443.15
Iteration:   3700, Loss function: 2.337, Average Loss: 3.881, avg. samples / sec: 53365.05
Iteration:   3700, Loss function: 3.315, Average Loss: 3.877, avg. samples / sec: 53392.81
Iteration:   3700, Loss function: 4.436, Average Loss: 3.863, avg. samples / sec: 53327.59
Iteration:   3700, Loss function: 3.472, Average Loss: 3.856, avg. samples / sec: 53258.02
Iteration:   3700, Loss function: 3.678, Average Loss: 3.850, avg. samples / sec: 53250.66
Iteration:   3700, Loss function: 2.829, Average Loss: 3.877, avg. samples / sec: 53272.04
Iteration:   3700, Loss function: 3.101, Average Loss: 3.855, avg. samples / sec: 53270.00
Iteration:   3700, Loss function: 3.516, Average Loss: 3.865, avg. samples / sec: 53256.01
Iteration:   3700, Loss function: 3.316, Average Loss: 3.865, avg. samples / sec: 53284.62
Iteration:   3720, Loss function: 3.500, Average Loss: 3.856, avg. samples / sec: 53808.69
Iteration:   3720, Loss function: 2.995, Average Loss: 3.883, avg. samples / sec: 53773.93
Iteration:   3720, Loss function: 3.196, Average Loss: 3.848, avg. samples / sec: 53615.03
Iteration:   3720, Loss function: 3.762, Average Loss: 3.874, avg. samples / sec: 53776.92
Iteration:   3720, Loss function: 2.882, Average Loss: 3.859, avg. samples / sec: 53699.96
Iteration:   3720, Loss function: 3.869, Average Loss: 3.850, avg. samples / sec: 53724.01
Iteration:   3720, Loss function: 3.899, Average Loss: 3.844, avg. samples / sec: 53614.60
Iteration:   3720, Loss function: 3.677, Average Loss: 3.882, avg. samples / sec: 53605.73
Iteration:   3720, Loss function: 3.253, Average Loss: 3.868, avg. samples / sec: 53688.05
Iteration:   3720, Loss function: 3.504, Average Loss: 3.859, avg. samples / sec: 53698.75
Iteration:   3720, Loss function: 3.624, Average Loss: 3.882, avg. samples / sec: 53789.22
Iteration:   3720, Loss function: 4.561, Average Loss: 3.856, avg. samples / sec: 53728.07
Iteration:   3720, Loss function: 3.220, Average Loss: 3.841, avg. samples / sec: 53652.86
Iteration:   3720, Loss function: 3.185, Average Loss: 3.880, avg. samples / sec: 53609.26
Iteration:   3720, Loss function: 2.902, Average Loss: 3.844, avg. samples / sec: 53661.27
Iteration:   3720, Loss function: 3.351, Average Loss: 3.877, avg. samples / sec: 53653.33
Iteration:   3720, Loss function: 3.361, Average Loss: 3.852, avg. samples / sec: 53555.13
Iteration:   3720, Loss function: 3.970, Average Loss: 3.846, avg. samples / sec: 53690.69
Iteration:   3720, Loss function: 3.912, Average Loss: 3.838, avg. samples / sec: 53686.48
Iteration:   3720, Loss function: 3.556, Average Loss: 3.848, avg. samples / sec: 53613.75
Iteration:   3720, Loss function: 3.192, Average Loss: 3.848, avg. samples / sec: 53706.26
Iteration:   3720, Loss function: 3.649, Average Loss: 3.857, avg. samples / sec: 53639.97
Iteration:   3720, Loss function: 4.298, Average Loss: 3.867, avg. samples / sec: 53691.41
Iteration:   3720, Loss function: 4.153, Average Loss: 3.865, avg. samples / sec: 53587.69
Iteration:   3720, Loss function: 2.873, Average Loss: 3.863, avg. samples / sec: 53615.20
Iteration:   3720, Loss function: 3.138, Average Loss: 3.883, avg. samples / sec: 53567.71
Iteration:   3720, Loss function: 3.645, Average Loss: 3.854, avg. samples / sec: 53596.42
Iteration:   3720, Loss function: 3.317, Average Loss: 3.869, avg. samples / sec: 53593.50
Iteration:   3720, Loss function: 3.246, Average Loss: 3.858, avg. samples / sec: 53679.24
Iteration:   3720, Loss function: 4.276, Average Loss: 3.861, avg. samples / sec: 53659.33
Iteration:   3740, Loss function: 3.871, Average Loss: 3.874, avg. samples / sec: 53760.16
Iteration:   3740, Loss function: 2.792, Average Loss: 3.838, avg. samples / sec: 53811.69
Iteration:   3740, Loss function: 1.685, Average Loss: 3.843, avg. samples / sec: 53806.49
Iteration:   3740, Loss function: 4.414, Average Loss: 3.872, avg. samples / sec: 53835.33
Iteration:   3740, Loss function: 4.680, Average Loss: 3.865, avg. samples / sec: 53801.07
Iteration:   3740, Loss function: 2.606, Average Loss: 3.851, avg. samples / sec: 53750.18
Iteration:   3740, Loss function: 3.331, Average Loss: 3.872, avg. samples / sec: 53791.83
Iteration:   3740, Loss function: 4.549, Average Loss: 3.850, avg. samples / sec: 53785.98
Iteration:   3740, Loss function: 3.199, Average Loss: 3.872, avg. samples / sec: 53767.36
Iteration:   3740, Loss function: 2.722, Average Loss: 3.869, avg. samples / sec: 53729.42
Iteration:   3740, Loss function: 3.401, Average Loss: 3.834, avg. samples / sec: 53797.27
Iteration:   3740, Loss function: 4.035, Average Loss: 3.853, avg. samples / sec: 53773.09
Iteration:   3740, Loss function: 2.724, Average Loss: 3.832, avg. samples / sec: 53794.33
Iteration:   3740, Loss function: 2.487, Average Loss: 3.843, avg. samples / sec: 53485.17
Iteration:   3740, Loss function: 3.130, Average Loss: 3.837, avg. samples / sec: 53678.34
Iteration:   3740, Loss function: 3.919, Average Loss: 3.869, avg. samples / sec: 53751.41
Iteration:   3740, Loss function: 2.816, Average Loss: 3.838, avg. samples / sec: 53764.08
Iteration:   3740, Loss function: 3.075, Average Loss: 3.845, avg. samples / sec: 53744.50
Iteration:   3740, Loss function: 4.200, Average Loss: 3.856, avg. samples / sec: 53776.19
Iteration:   3740, Loss function: 3.144, Average Loss: 3.857, avg. samples / sec: 53766.62
Iteration:   3740, Loss function: 3.692, Average Loss: 3.859, avg. samples / sec: 53783.68
Iteration:   3740, Loss function: 2.315, Average Loss: 3.857, avg. samples / sec: 53756.58
Iteration:   3740, Loss function: 3.963, Average Loss: 3.839, avg. samples / sec: 53745.44
Iteration:   3740, Loss function: 3.476, Average Loss: 3.828, avg. samples / sec: 53737.55
Iteration:   3740, Loss function: 3.820, Average Loss: 3.854, avg. samples / sec: 53805.59
Iteration:   3740, Loss function: 3.830, Average Loss: 3.851, avg. samples / sec: 53775.14
Iteration:   3740, Loss function: 4.289, Average Loss: 3.856, avg. samples / sec: 53750.75
Iteration:   3740, Loss function: 4.055, Average Loss: 3.877, avg. samples / sec: 53744.58
Iteration:   3740, Loss function: 2.777, Average Loss: 3.850, avg. samples / sec: 53733.76
Iteration:   3740, Loss function: 4.861, Average Loss: 3.841, avg. samples / sec: 53700.76
Iteration:   3760, Loss function: 4.030, Average Loss: 3.837, avg. samples / sec: 53725.73
Iteration:   3760, Loss function: 3.948, Average Loss: 3.829, avg. samples / sec: 53467.05
Iteration:   3760, Loss function: 4.529, Average Loss: 3.859, avg. samples / sec: 53554.97
Iteration:   3760, Loss function: 2.898, Average Loss: 3.857, avg. samples / sec: 53517.85
Iteration:   3760, Loss function: 3.519, Average Loss: 3.842, avg. samples / sec: 53520.27
Iteration:   3760, Loss function: 4.351, Average Loss: 3.861, avg. samples / sec: 53536.17
Iteration:   3760, Loss function: 4.020, Average Loss: 3.822, avg. samples / sec: 53596.15
Iteration:   3760, Loss function: 3.841, Average Loss: 3.865, avg. samples / sec: 53476.34
Iteration:   3760, Loss function: 3.301, Average Loss: 3.819, avg. samples / sec: 53528.83
Iteration:   3760, Loss function: 3.746, Average Loss: 3.837, avg. samples / sec: 53454.17
Iteration:   3760, Loss function: 3.265, Average Loss: 3.863, avg. samples / sec: 53292.16
Iteration:   3760, Loss function: 3.330, Average Loss: 3.844, avg. samples / sec: 53507.73
Iteration:   3760, Loss function: 2.871, Average Loss: 3.842, avg. samples / sec: 53737.43
Iteration:   3760, Loss function: 2.804, Average Loss: 3.838, avg. samples / sec: 53474.80
Iteration:   3760, Loss function: 3.124, Average Loss: 3.825, avg. samples / sec: 53486.73
Iteration:   3760, Loss function: 3.802, Average Loss: 3.864, avg. samples / sec: 53484.62
Iteration:   3760, Loss function: 3.134, Average Loss: 3.857, avg. samples / sec: 53478.45
Iteration:   3760, Loss function: 3.506, Average Loss: 3.829, avg. samples / sec: 53538.45
Iteration:   3760, Loss function: 4.369, Average Loss: 3.818, avg. samples / sec: 53550.06
Iteration:   3760, Loss function: 3.712, Average Loss: 3.827, avg. samples / sec: 53579.77
Iteration:   3760, Loss function: 3.568, Average Loss: 3.849, avg. samples / sec: 53526.27
Iteration:   3760, Loss function: 2.795, Average Loss: 3.870, avg. samples / sec: 53559.14
Iteration:   3760, Loss function: 2.472, Average Loss: 3.828, avg. samples / sec: 53532.84
Iteration:   3760, Loss function: 3.671, Average Loss: 3.847, avg. samples / sec: 53545.65
Iteration:   3760, Loss function: 3.942, Average Loss: 3.849, avg. samples / sec: 53525.66
Iteration:   3760, Loss function: 2.647, Average Loss: 3.836, avg. samples / sec: 53499.26
Iteration:   3760, Loss function: 3.585, Average Loss: 3.839, avg. samples / sec: 53503.39
Iteration:   3760, Loss function: 3.804, Average Loss: 3.841, avg. samples / sec: 53472.16
Iteration:   3760, Loss function: 2.925, Average Loss: 3.852, avg. samples / sec: 53511.59
Iteration:   3760, Loss function: 2.002, Average Loss: 3.844, avg. samples / sec: 53524.42
:::MLL 1558640695.104 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558640695.104 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 3.704, Average Loss: 3.853, avg. samples / sec: 53523.52
Iteration:   3780, Loss function: 3.944, Average Loss: 3.828, avg. samples / sec: 53322.57
Iteration:   3780, Loss function: 2.884, Average Loss: 3.822, avg. samples / sec: 53338.33
Iteration:   3780, Loss function: 3.568, Average Loss: 3.852, avg. samples / sec: 53312.54
Iteration:   3780, Loss function: 4.367, Average Loss: 3.852, avg. samples / sec: 53255.75
Iteration:   3780, Loss function: 3.409, Average Loss: 3.828, avg. samples / sec: 53301.51
Iteration:   3780, Loss function: 3.532, Average Loss: 3.831, avg. samples / sec: 53273.35
Iteration:   3780, Loss function: 3.857, Average Loss: 3.855, avg. samples / sec: 53292.14
Iteration:   3780, Loss function: 3.126, Average Loss: 3.814, avg. samples / sec: 53313.79
Iteration:   3780, Loss function: 3.280, Average Loss: 3.847, avg. samples / sec: 53247.76
Iteration:   3780, Loss function: 3.228, Average Loss: 3.811, avg. samples / sec: 53279.25
Iteration:   3780, Loss function: 4.844, Average Loss: 3.814, avg. samples / sec: 53274.07
Iteration:   3780, Loss function: 3.743, Average Loss: 3.833, avg. samples / sec: 53299.24
Iteration:   3780, Loss function: 3.531, Average Loss: 3.827, avg. samples / sec: 53297.40
Iteration:   3780, Loss function: 2.927, Average Loss: 3.837, avg. samples / sec: 53274.07
Iteration:   3780, Loss function: 3.760, Average Loss: 3.856, avg. samples / sec: 53255.59
Iteration:   3780, Loss function: 2.902, Average Loss: 3.848, avg. samples / sec: 53316.82
Iteration:   3780, Loss function: 3.763, Average Loss: 3.816, avg. samples / sec: 53311.78
Iteration:   3780, Loss function: 2.202, Average Loss: 3.818, avg. samples / sec: 53279.04
Iteration:   3780, Loss function: 3.127, Average Loss: 3.837, avg. samples / sec: 53351.54
Iteration:   3780, Loss function: 2.148, Average Loss: 3.818, avg. samples / sec: 53303.65
Iteration:   3780, Loss function: 2.940, Average Loss: 3.833, avg. samples / sec: 53312.74
Iteration:   3780, Loss function: 3.490, Average Loss: 3.819, avg. samples / sec: 53279.49
Iteration:   3780, Loss function: 2.572, Average Loss: 3.829, avg. samples / sec: 53310.24
Iteration:   3780, Loss function: 5.158, Average Loss: 3.843, avg. samples / sec: 53269.12
Iteration:   3780, Loss function: 3.931, Average Loss: 3.842, avg. samples / sec: 53265.13
Iteration:   3780, Loss function: 3.240, Average Loss: 3.856, avg. samples / sec: 53258.83
Iteration:   3780, Loss function: 4.057, Average Loss: 3.839, avg. samples / sec: 53260.80
Iteration:   3780, Loss function: 3.108, Average Loss: 3.825, avg. samples / sec: 53257.96
Iteration:   3780, Loss function: 2.580, Average Loss: 3.840, avg. samples / sec: 53288.07
Iteration:   3800, Loss function: 4.708, Average Loss: 3.821, avg. samples / sec: 53697.95
Iteration:   3800, Loss function: 3.149, Average Loss: 3.819, avg. samples / sec: 53619.38
Iteration:   3800, Loss function: 3.650, Average Loss: 3.849, avg. samples / sec: 53592.03
Iteration:   3800, Loss function: 3.119, Average Loss: 3.819, avg. samples / sec: 53712.98
Iteration:   3800, Loss function: 3.824, Average Loss: 3.850, avg. samples / sec: 53709.45
Iteration:   3800, Loss function: 4.169, Average Loss: 3.845, avg. samples / sec: 53694.58
Iteration:   3800, Loss function: 2.543, Average Loss: 3.828, avg. samples / sec: 53726.10
Iteration:   3800, Loss function: 3.476, Average Loss: 3.824, avg. samples / sec: 53698.34
Iteration:   3800, Loss function: 3.378, Average Loss: 3.840, avg. samples / sec: 53681.32
Iteration:   3800, Loss function: 2.842, Average Loss: 3.805, avg. samples / sec: 53685.58
Iteration:   3800, Loss function: 1.421, Average Loss: 3.849, avg. samples / sec: 53612.63
Iteration:   3800, Loss function: 3.155, Average Loss: 3.804, avg. samples / sec: 53660.99
Iteration:   3800, Loss function: 3.056, Average Loss: 3.816, avg. samples / sec: 53668.65
Iteration:   3800, Loss function: 3.088, Average Loss: 3.803, avg. samples / sec: 53644.67
Iteration:   3800, Loss function: 3.409, Average Loss: 3.848, avg. samples / sec: 53676.93
Iteration:   3800, Loss function: 2.788, Average Loss: 3.841, avg. samples / sec: 53703.21
Iteration:   3800, Loss function: 2.209, Average Loss: 3.809, avg. samples / sec: 53691.88
Iteration:   3800, Loss function: 2.601, Average Loss: 3.811, avg. samples / sec: 53701.35
Iteration:   3800, Loss function: 4.562, Average Loss: 3.833, avg. samples / sec: 53674.45
Iteration:   3800, Loss function: 2.475, Average Loss: 3.826, avg. samples / sec: 53679.85
Iteration:   3800, Loss function: 5.094, Average Loss: 3.833, avg. samples / sec: 53705.26
Iteration:   3800, Loss function: 3.364, Average Loss: 3.812, avg. samples / sec: 53644.42
Iteration:   3800, Loss function: 3.034, Average Loss: 3.832, avg. samples / sec: 53686.07
Iteration:   3800, Loss function: 1.891, Average Loss: 3.820, avg. samples / sec: 53679.61
Iteration:   3800, Loss function: 3.846, Average Loss: 3.822, avg. samples / sec: 53420.78
Iteration:   3800, Loss function: 3.029, Average Loss: 3.818, avg. samples / sec: 53693.17
Iteration:   3800, Loss function: 3.222, Average Loss: 3.847, avg. samples / sec: 53680.47
Iteration:   3800, Loss function: 3.802, Average Loss: 3.805, avg. samples / sec: 53613.09
Iteration:   3800, Loss function: 3.365, Average Loss: 3.833, avg. samples / sec: 53673.47
Iteration:   3800, Loss function: 2.169, Average Loss: 3.830, avg. samples / sec: 53661.29
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558640696.369 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.64s)
DONE (t=2.52s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22391
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38421
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22842
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21780
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31776
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09700
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.35650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52655
Current AP: 0.22391 AP goal: 0.23000
:::MLL 1558640700.187 eval_accuracy: {"value": 0.22391081910311536, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558640700.287 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558640700.294 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558640700.295 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 2.845, Average Loss: 3.818, avg. samples / sec: 7359.67
Iteration:   3820, Loss function: 3.285, Average Loss: 3.807, avg. samples / sec: 7358.67
Iteration:   3820, Loss function: 2.421, Average Loss: 3.839, avg. samples / sec: 7354.81
Iteration:   3820, Loss function: 3.687, Average Loss: 3.840, avg. samples / sec: 7352.37
Iteration:   3820, Loss function: 4.316, Average Loss: 3.815, avg. samples / sec: 7351.25
Iteration:   3820, Loss function: 3.710, Average Loss: 3.800, avg. samples / sec: 7351.84
Iteration:   3820, Loss function: 4.247, Average Loss: 3.825, avg. samples / sec: 7356.32
Iteration:   3820, Loss function: 4.331, Average Loss: 3.845, avg. samples / sec: 7349.50
Iteration:   3820, Loss function: 2.590, Average Loss: 3.835, avg. samples / sec: 7352.08
Iteration:   3820, Loss function: 3.347, Average Loss: 3.829, avg. samples / sec: 7352.85
Iteration:   3820, Loss function: 2.816, Average Loss: 3.817, avg. samples / sec: 7347.75
Iteration:   3820, Loss function: 2.593, Average Loss: 3.816, avg. samples / sec: 7351.32
Iteration:   3820, Loss function: 4.124, Average Loss: 3.800, avg. samples / sec: 7351.93
Iteration:   3820, Loss function: 2.797, Average Loss: 3.811, avg. samples / sec: 7351.91
Iteration:   3820, Loss function: 4.352, Average Loss: 3.792, avg. samples / sec: 7351.99
Iteration:   3820, Loss function: 2.634, Average Loss: 3.826, avg. samples / sec: 7351.16
Iteration:   3820, Loss function: 2.574, Average Loss: 3.819, avg. samples / sec: 7350.67
Iteration:   3820, Loss function: 2.701, Average Loss: 3.811, avg. samples / sec: 7347.97
Iteration:   3820, Loss function: 4.585, Average Loss: 3.800, avg. samples / sec: 7352.11
Iteration:   3820, Loss function: 3.500, Average Loss: 3.802, avg. samples / sec: 7351.71
Iteration:   3820, Loss function: 2.865, Average Loss: 3.796, avg. samples / sec: 7352.50
Iteration:   3820, Loss function: 3.562, Average Loss: 3.803, avg. samples / sec: 7352.00
Iteration:   3820, Loss function: 4.201, Average Loss: 3.817, avg. samples / sec: 7351.60
Iteration:   3820, Loss function: 4.545, Average Loss: 3.827, avg. samples / sec: 7351.72
Iteration:   3820, Loss function: 2.702, Average Loss: 3.824, avg. samples / sec: 7352.52
Iteration:   3820, Loss function: 4.645, Average Loss: 3.814, avg. samples / sec: 7351.39
Iteration:   3820, Loss function: 2.478, Average Loss: 3.828, avg. samples / sec: 7351.76
Iteration:   3820, Loss function: 4.452, Average Loss: 3.838, avg. samples / sec: 7351.55
Iteration:   3820, Loss function: 3.758, Average Loss: 3.821, avg. samples / sec: 7350.63
Iteration:   3820, Loss function: 2.850, Average Loss: 3.833, avg. samples / sec: 7345.52
:::MLL 1558640701.254 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558640701.255 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 3.331, Average Loss: 3.830, avg. samples / sec: 52529.13
Iteration:   3840, Loss function: 4.218, Average Loss: 3.830, avg. samples / sec: 52561.10
Iteration:   3840, Loss function: 2.457, Average Loss: 3.798, avg. samples / sec: 52499.60
Iteration:   3840, Loss function: 4.426, Average Loss: 3.808, avg. samples / sec: 52417.55
Iteration:   3840, Loss function: 4.488, Average Loss: 3.838, avg. samples / sec: 52508.64
Iteration:   3840, Loss function: 4.152, Average Loss: 3.818, avg. samples / sec: 52761.76
Iteration:   3840, Loss function: 3.132, Average Loss: 3.789, avg. samples / sec: 52474.81
Iteration:   3840, Loss function: 4.045, Average Loss: 3.795, avg. samples / sec: 52494.28
Iteration:   3840, Loss function: 3.800, Average Loss: 3.784, avg. samples / sec: 52507.62
Iteration:   3840, Loss function: 3.976, Average Loss: 3.810, avg. samples / sec: 52444.14
Iteration:   3840, Loss function: 2.164, Average Loss: 3.800, avg. samples / sec: 52481.48
Iteration:   3840, Loss function: 3.990, Average Loss: 3.826, avg. samples / sec: 52461.90
Iteration:   3840, Loss function: 3.100, Average Loss: 3.818, avg. samples / sec: 52456.26
Iteration:   3840, Loss function: 2.668, Average Loss: 3.815, avg. samples / sec: 52419.83
Iteration:   3840, Loss function: 4.019, Average Loss: 3.808, avg. samples / sec: 52436.53
Iteration:   3840, Loss function: 3.549, Average Loss: 3.800, avg. samples / sec: 52485.99
Iteration:   3840, Loss function: 2.588, Average Loss: 3.812, avg. samples / sec: 52434.48
Iteration:   3840, Loss function: 3.195, Average Loss: 3.792, avg. samples / sec: 52590.86
Iteration:   3840, Loss function: 3.333, Average Loss: 3.815, avg. samples / sec: 52391.38
Iteration:   3840, Loss function: 3.343, Average Loss: 3.818, avg. samples / sec: 52415.48
Iteration:   3840, Loss function: 3.508, Average Loss: 3.790, avg. samples / sec: 52543.66
Iteration:   3840, Loss function: 3.661, Average Loss: 3.808, avg. samples / sec: 52541.76
Iteration:   3840, Loss function: 3.809, Average Loss: 3.812, avg. samples / sec: 52556.79
Iteration:   3840, Loss function: 3.797, Average Loss: 3.821, avg. samples / sec: 52542.58
Iteration:   3840, Loss function: 5.715, Average Loss: 3.832, avg. samples / sec: 52556.69
Iteration:   3840, Loss function: 4.290, Average Loss: 3.789, avg. samples / sec: 52482.28
Iteration:   3840, Loss function: 2.610, Average Loss: 3.791, avg. samples / sec: 52460.16
Iteration:   3840, Loss function: 3.783, Average Loss: 3.818, avg. samples / sec: 52424.10
Iteration:   3840, Loss function: 2.754, Average Loss: 3.811, avg. samples / sec: 52454.79
Iteration:   3840, Loss function: 2.417, Average Loss: 3.823, avg. samples / sec: 52452.51
Iteration:   3860, Loss function: 3.031, Average Loss: 3.818, avg. samples / sec: 53272.02
Iteration:   3860, Loss function: 2.612, Average Loss: 3.802, avg. samples / sec: 53289.94
Iteration:   3860, Loss function: 2.903, Average Loss: 3.822, avg. samples / sec: 53200.52
Iteration:   3860, Loss function: 3.667, Average Loss: 3.788, avg. samples / sec: 53220.64
Iteration:   3860, Loss function: 3.989, Average Loss: 3.796, avg. samples / sec: 53265.33
Iteration:   3860, Loss function: 4.030, Average Loss: 3.782, avg. samples / sec: 53243.58
Iteration:   3860, Loss function: 2.090, Average Loss: 3.813, avg. samples / sec: 53218.50
Iteration:   3860, Loss function: 3.356, Average Loss: 3.783, avg. samples / sec: 53223.89
Iteration:   3860, Loss function: 3.217, Average Loss: 3.805, avg. samples / sec: 53251.40
Iteration:   3860, Loss function: 3.050, Average Loss: 3.807, avg. samples / sec: 53278.90
Iteration:   3860, Loss function: 2.921, Average Loss: 3.800, avg. samples / sec: 53209.86
Iteration:   3860, Loss function: 4.112, Average Loss: 3.832, avg. samples / sec: 53159.37
Iteration:   3860, Loss function: 4.411, Average Loss: 3.805, avg. samples / sec: 53270.47
Iteration:   3860, Loss function: 3.130, Average Loss: 3.795, avg. samples / sec: 53258.00
Iteration:   3860, Loss function: 4.187, Average Loss: 3.802, avg. samples / sec: 53251.77
Iteration:   3860, Loss function: 3.677, Average Loss: 3.790, avg. samples / sec: 53181.25
Iteration:   3860, Loss function: 3.260, Average Loss: 3.816, avg. samples / sec: 53187.01
Iteration:   3860, Loss function: 4.325, Average Loss: 3.807, avg. samples / sec: 53240.60
Iteration:   3860, Loss function: 3.547, Average Loss: 3.810, avg. samples / sec: 53225.48
Iteration:   3860, Loss function: 3.626, Average Loss: 3.802, avg. samples / sec: 53177.82
Iteration:   3860, Loss function: 3.040, Average Loss: 3.783, avg. samples / sec: 53090.36
Iteration:   3860, Loss function: 3.439, Average Loss: 3.781, avg. samples / sec: 53118.67
Iteration:   3860, Loss function: 2.701, Average Loss: 3.783, avg. samples / sec: 53211.63
Iteration:   3860, Loss function: 3.289, Average Loss: 3.806, avg. samples / sec: 53277.29
Iteration:   3860, Loss function: 3.252, Average Loss: 3.816, avg. samples / sec: 53149.42
Iteration:   3860, Loss function: 3.159, Average Loss: 3.819, avg. samples / sec: 53164.60
Iteration:   3860, Loss function: 2.236, Average Loss: 3.781, avg. samples / sec: 53212.68
Iteration:   3860, Loss function: 3.702, Average Loss: 3.805, avg. samples / sec: 53136.88
Iteration:   3860, Loss function: 2.826, Average Loss: 3.799, avg. samples / sec: 53263.72
Iteration:   3860, Loss function: 2.483, Average Loss: 3.813, avg. samples / sec: 53131.03
Iteration:   3880, Loss function: 3.395, Average Loss: 3.793, avg. samples / sec: 53419.67
Iteration:   3880, Loss function: 3.363, Average Loss: 3.809, avg. samples / sec: 53389.65
Iteration:   3880, Loss function: 4.780, Average Loss: 3.774, avg. samples / sec: 53511.80
Iteration:   3880, Loss function: 3.321, Average Loss: 3.774, avg. samples / sec: 53503.47
Iteration:   3880, Loss function: 4.122, Average Loss: 3.790, avg. samples / sec: 53514.48
Iteration:   3880, Loss function: 2.752, Average Loss: 3.783, avg. samples / sec: 53528.40
Iteration:   3880, Loss function: 4.112, Average Loss: 3.811, avg. samples / sec: 53343.94
Iteration:   3880, Loss function: 3.120, Average Loss: 3.806, avg. samples / sec: 53525.60
Iteration:   3880, Loss function: 2.499, Average Loss: 3.784, avg. samples / sec: 53499.75
Iteration:   3880, Loss function: 3.442, Average Loss: 3.797, avg. samples / sec: 53464.25
Iteration:   3880, Loss function: 2.890, Average Loss: 3.785, avg. samples / sec: 53426.80
Iteration:   3880, Loss function: 3.924, Average Loss: 3.800, avg. samples / sec: 53454.17
Iteration:   3880, Loss function: 2.954, Average Loss: 3.800, avg. samples / sec: 53524.09
Iteration:   3880, Loss function: 3.710, Average Loss: 3.783, avg. samples / sec: 53306.09
Iteration:   3880, Loss function: 3.275, Average Loss: 3.825, avg. samples / sec: 53462.95
Iteration:   3880, Loss function: 3.092, Average Loss: 3.804, avg. samples / sec: 53519.21
Iteration:   3880, Loss function: 3.231, Average Loss: 3.793, avg. samples / sec: 53453.99
Iteration:   3880, Loss function: 2.765, Average Loss: 3.792, avg. samples / sec: 53447.73
Iteration:   3880, Loss function: 2.956, Average Loss: 3.813, avg. samples / sec: 53487.12
Iteration:   3880, Loss function: 3.600, Average Loss: 3.798, avg. samples / sec: 53499.30
Iteration:   3880, Loss function: 4.016, Average Loss: 3.776, avg. samples / sec: 53457.84
Iteration:   3880, Loss function: 3.636, Average Loss: 3.769, avg. samples / sec: 53448.64
Iteration:   3880, Loss function: 1.782, Average Loss: 3.766, avg. samples / sec: 53483.37
Iteration:   3880, Loss function: 3.704, Average Loss: 3.805, avg. samples / sec: 53466.93
Iteration:   3880, Loss function: 3.381, Average Loss: 3.798, avg. samples / sec: 53442.32
Iteration:   3880, Loss function: 2.001, Average Loss: 3.792, avg. samples / sec: 53421.73
Iteration:   3880, Loss function: 3.865, Average Loss: 3.791, avg. samples / sec: 53452.37
Iteration:   3880, Loss function: 3.425, Average Loss: 3.772, avg. samples / sec: 53407.46
Iteration:   3880, Loss function: 2.948, Average Loss: 3.806, avg. samples / sec: 53595.21
Iteration:   3880, Loss function: 3.112, Average Loss: 3.804, avg. samples / sec: 53147.42
Iteration:   3900, Loss function: 2.889, Average Loss: 3.801, avg. samples / sec: 53630.50
Iteration:   3900, Loss function: 4.121, Average Loss: 3.806, avg. samples / sec: 53699.32
Iteration:   3900, Loss function: 3.310, Average Loss: 3.783, avg. samples / sec: 53556.92
Iteration:   3900, Loss function: 3.222, Average Loss: 3.777, avg. samples / sec: 53635.95
Iteration:   3900, Loss function: 3.449, Average Loss: 3.780, avg. samples / sec: 53563.25
Iteration:   3900, Loss function: 2.917, Average Loss: 3.781, avg. samples / sec: 53586.45
Iteration:   3900, Loss function: 3.788, Average Loss: 3.819, avg. samples / sec: 53603.90
Iteration:   3900, Loss function: 3.395, Average Loss: 3.780, avg. samples / sec: 53562.01
Iteration:   3900, Loss function: 2.915, Average Loss: 3.798, avg. samples / sec: 53531.80
Iteration:   3900, Loss function: 2.653, Average Loss: 3.764, avg. samples / sec: 53457.92
Iteration:   3900, Loss function: 3.837, Average Loss: 3.793, avg. samples / sec: 53540.10
Iteration:   3900, Loss function: 3.333, Average Loss: 3.768, avg. samples / sec: 53466.04
Iteration:   3900, Loss function: 3.299, Average Loss: 3.773, avg. samples / sec: 53486.11
Iteration:   3900, Loss function: 3.685, Average Loss: 3.782, avg. samples / sec: 53553.50
Iteration:   3900, Loss function: 2.816, Average Loss: 3.791, avg. samples / sec: 53503.22
Iteration:   3900, Loss function: 3.314, Average Loss: 3.797, avg. samples / sec: 53537.57
Iteration:   3900, Loss function: 3.167, Average Loss: 3.790, avg. samples / sec: 53540.36
Iteration:   3900, Loss function: 3.666, Average Loss: 3.790, avg. samples / sec: 53474.03
Iteration:   3900, Loss function: 3.190, Average Loss: 3.801, avg. samples / sec: 53722.58
Iteration:   3900, Loss function: 3.059, Average Loss: 3.766, avg. samples / sec: 53628.78
Iteration:   3900, Loss function: 2.547, Average Loss: 3.759, avg. samples / sec: 53566.67
Iteration:   3900, Loss function: 3.884, Average Loss: 3.757, avg. samples / sec: 53557.00
Iteration:   3900, Loss function: 4.584, Average Loss: 3.786, avg. samples / sec: 53562.05
Iteration:   3900, Loss function: 4.641, Average Loss: 3.795, avg. samples / sec: 53535.66
Iteration:   3900, Loss function: 2.743, Average Loss: 3.782, avg. samples / sec: 53574.49
Iteration:   3900, Loss function: 4.224, Average Loss: 3.798, avg. samples / sec: 53544.06
Iteration:   3900, Loss function: 2.530, Average Loss: 3.804, avg. samples / sec: 53510.58
Iteration:   3900, Loss function: 2.031, Average Loss: 3.782, avg. samples / sec: 53532.81
Iteration:   3900, Loss function: 4.010, Average Loss: 3.800, avg. samples / sec: 53535.34
Iteration:   3900, Loss function: 2.446, Average Loss: 3.766, avg. samples / sec: 53394.87
:::MLL 1558640703.460 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558640703.461 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 2.056, Average Loss: 3.774, avg. samples / sec: 53208.00
Iteration:   3920, Loss function: 2.544, Average Loss: 3.768, avg. samples / sec: 53269.92
Iteration:   3920, Loss function: 3.405, Average Loss: 3.794, avg. samples / sec: 53108.14
Iteration:   3920, Loss function: 2.744, Average Loss: 3.761, avg. samples / sec: 53236.38
Iteration:   3920, Loss function: 2.731, Average Loss: 3.784, avg. samples / sec: 53228.86
Iteration:   3920, Loss function: 4.313, Average Loss: 3.795, avg. samples / sec: 53308.49
Iteration:   3920, Loss function: 2.474, Average Loss: 3.788, avg. samples / sec: 52966.07
Iteration:   3920, Loss function: 3.562, Average Loss: 3.814, avg. samples / sec: 53136.56
Iteration:   3920, Loss function: 4.050, Average Loss: 3.767, avg. samples / sec: 53197.77
Iteration:   3920, Loss function: 2.593, Average Loss: 3.758, avg. samples / sec: 53176.66
Iteration:   3920, Loss function: 3.949, Average Loss: 3.776, avg. samples / sec: 53119.37
Iteration:   3920, Loss function: 3.393, Average Loss: 3.786, avg. samples / sec: 53155.05
Iteration:   3920, Loss function: 4.195, Average Loss: 3.772, avg. samples / sec: 53181.71
Iteration:   3920, Loss function: 2.919, Average Loss: 3.775, avg. samples / sec: 53112.85
Iteration:   3920, Loss function: 4.678, Average Loss: 3.783, avg. samples / sec: 53176.60
Iteration:   3920, Loss function: 4.719, Average Loss: 3.791, avg. samples / sec: 53149.70
Iteration:   3920, Loss function: 2.517, Average Loss: 3.781, avg. samples / sec: 53164.36
Iteration:   3920, Loss function: 4.360, Average Loss: 3.786, avg. samples / sec: 53185.85
Iteration:   3920, Loss function: 3.846, Average Loss: 3.778, avg. samples / sec: 53008.92
Iteration:   3920, Loss function: 3.379, Average Loss: 3.754, avg. samples / sec: 53163.30
Iteration:   3920, Loss function: 3.644, Average Loss: 3.758, avg. samples / sec: 53319.46
Iteration:   3920, Loss function: 3.633, Average Loss: 3.791, avg. samples / sec: 53183.28
Iteration:   3920, Loss function: 4.116, Average Loss: 3.758, avg. samples / sec: 53129.44
Iteration:   3920, Loss function: 2.270, Average Loss: 3.748, avg. samples / sec: 53157.84
Iteration:   3920, Loss function: 2.918, Average Loss: 3.785, avg. samples / sec: 53160.21
Iteration:   3920, Loss function: 3.100, Average Loss: 3.787, avg. samples / sec: 53163.20
Iteration:   3920, Loss function: 2.878, Average Loss: 3.792, avg. samples / sec: 53181.81
Iteration:   3920, Loss function: 3.202, Average Loss: 3.772, avg. samples / sec: 53142.11
Iteration:   3920, Loss function: 3.046, Average Loss: 3.770, avg. samples / sec: 53168.95
Iteration:   3920, Loss function: 4.125, Average Loss: 3.792, avg. samples / sec: 53174.17
Iteration:   3940, Loss function: 3.984, Average Loss: 3.759, avg. samples / sec: 53580.18
Iteration:   3940, Loss function: 3.108, Average Loss: 3.790, avg. samples / sec: 53628.91
Iteration:   3940, Loss function: 3.443, Average Loss: 3.781, avg. samples / sec: 53724.34
Iteration:   3940, Loss function: 2.686, Average Loss: 3.803, avg. samples / sec: 53618.75
Iteration:   3940, Loss function: 2.267, Average Loss: 3.747, avg. samples / sec: 53619.52
Iteration:   3940, Loss function: 2.485, Average Loss: 3.786, avg. samples / sec: 53584.27
Iteration:   3940, Loss function: 2.062, Average Loss: 3.770, avg. samples / sec: 53648.55
Iteration:   3940, Loss function: 2.212, Average Loss: 3.756, avg. samples / sec: 53531.70
Iteration:   3940, Loss function: 4.150, Average Loss: 3.769, avg. samples / sec: 53675.82
Iteration:   3940, Loss function: 4.589, Average Loss: 3.777, avg. samples / sec: 53543.41
Iteration:   3940, Loss function: 3.145, Average Loss: 3.762, avg. samples / sec: 53567.69
Iteration:   3940, Loss function: 4.459, Average Loss: 3.782, avg. samples / sec: 53600.88
Iteration:   3940, Loss function: 3.231, Average Loss: 3.769, avg. samples / sec: 53568.83
Iteration:   3940, Loss function: 2.866, Average Loss: 3.776, avg. samples / sec: 53609.38
Iteration:   3940, Loss function: 4.161, Average Loss: 3.774, avg. samples / sec: 53576.53
Iteration:   3940, Loss function: 2.496, Average Loss: 3.767, avg. samples / sec: 53562.81
Iteration:   3940, Loss function: 3.982, Average Loss: 3.762, avg. samples / sec: 53558.35
Iteration:   3940, Loss function: 2.402, Average Loss: 3.772, avg. samples / sec: 53490.71
Iteration:   3940, Loss function: 3.539, Average Loss: 3.744, avg. samples / sec: 53631.34
Iteration:   3940, Loss function: 4.421, Average Loss: 3.741, avg. samples / sec: 53627.11
Iteration:   3940, Loss function: 3.259, Average Loss: 3.749, avg. samples / sec: 53610.26
Iteration:   3940, Loss function: 3.757, Average Loss: 3.782, avg. samples / sec: 53601.88
Iteration:   3940, Loss function: 2.697, Average Loss: 3.762, avg. samples / sec: 53595.07
Iteration:   3940, Loss function: 4.450, Average Loss: 3.786, avg. samples / sec: 53562.54
Iteration:   3940, Loss function: 2.939, Average Loss: 3.775, avg. samples / sec: 53556.01
Iteration:   3940, Loss function: 3.247, Average Loss: 3.751, avg. samples / sec: 53541.76
Iteration:   3940, Loss function: 3.436, Average Loss: 3.762, avg. samples / sec: 53576.43
Iteration:   3940, Loss function: 2.699, Average Loss: 3.781, avg. samples / sec: 53540.73
Iteration:   3940, Loss function: 3.066, Average Loss: 3.761, avg. samples / sec: 53082.98
Iteration:   3940, Loss function: 2.608, Average Loss: 3.785, avg. samples / sec: 53516.84
Iteration:   3960, Loss function: 3.406, Average Loss: 3.777, avg. samples / sec: 53515.37
Iteration:   3960, Loss function: 2.770, Average Loss: 3.745, avg. samples / sec: 53481.66
Iteration:   3960, Loss function: 3.447, Average Loss: 3.781, avg. samples / sec: 53471.56
Iteration:   3960, Loss function: 2.968, Average Loss: 3.750, avg. samples / sec: 53520.33
Iteration:   3960, Loss function: 3.319, Average Loss: 3.751, avg. samples / sec: 53824.60
Iteration:   3960, Loss function: 4.938, Average Loss: 3.798, avg. samples / sec: 53450.12
Iteration:   3960, Loss function: 3.463, Average Loss: 3.767, avg. samples / sec: 53521.39
Iteration:   3960, Loss function: 3.717, Average Loss: 3.765, avg. samples / sec: 53580.99
Iteration:   3960, Loss function: 3.385, Average Loss: 3.763, avg. samples / sec: 53490.06
Iteration:   3960, Loss function: 3.422, Average Loss: 3.741, avg. samples / sec: 53439.88
Iteration:   3960, Loss function: 2.933, Average Loss: 3.753, avg. samples / sec: 53489.31
Iteration:   3960, Loss function: 3.853, Average Loss: 3.770, avg. samples / sec: 53486.29
Iteration:   3960, Loss function: 4.593, Average Loss: 3.782, avg. samples / sec: 53439.30
Iteration:   3960, Loss function: 2.786, Average Loss: 3.759, avg. samples / sec: 53498.45
Iteration:   3960, Loss function: 5.350, Average Loss: 3.763, avg. samples / sec: 53466.71
Iteration:   3960, Loss function: 2.890, Average Loss: 3.772, avg. samples / sec: 53463.83
Iteration:   3960, Loss function: 3.387, Average Loss: 3.765, avg. samples / sec: 53425.86
Iteration:   3960, Loss function: 2.797, Average Loss: 3.764, avg. samples / sec: 53464.07
Iteration:   3960, Loss function: 4.197, Average Loss: 3.754, avg. samples / sec: 53467.80
Iteration:   3960, Loss function: 3.246, Average Loss: 3.744, avg. samples / sec: 53557.45
Iteration:   3960, Loss function: 3.576, Average Loss: 3.732, avg. samples / sec: 53442.05
Iteration:   3960, Loss function: 2.698, Average Loss: 3.779, avg. samples / sec: 53505.60
Iteration:   3960, Loss function: 3.074, Average Loss: 3.735, avg. samples / sec: 53457.80
Iteration:   3960, Loss function: 4.235, Average Loss: 3.740, avg. samples / sec: 53422.24
Iteration:   3960, Loss function: 2.549, Average Loss: 3.754, avg. samples / sec: 53495.95
Iteration:   3960, Loss function: 2.857, Average Loss: 3.751, avg. samples / sec: 53510.88
Iteration:   3960, Loss function: 4.775, Average Loss: 3.761, avg. samples / sec: 53501.76
Iteration:   3960, Loss function: 4.361, Average Loss: 3.777, avg. samples / sec: 53431.78
Iteration:   3960, Loss function: 2.326, Average Loss: 3.768, avg. samples / sec: 53491.49
Iteration:   3960, Loss function: 2.966, Average Loss: 3.771, avg. samples / sec: 53511.11
:::MLL 1558640705.661 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558640705.662 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.816, Average Loss: 3.774, avg. samples / sec: 53162.96
Iteration:   3980, Loss function: 3.371, Average Loss: 3.770, avg. samples / sec: 53175.65
Iteration:   3980, Loss function: 4.222, Average Loss: 3.734, avg. samples / sec: 53088.72
Iteration:   3980, Loss function: 4.629, Average Loss: 3.757, avg. samples / sec: 53265.19
Iteration:   3980, Loss function: 2.486, Average Loss: 3.775, avg. samples / sec: 53232.94
Iteration:   3980, Loss function: 2.611, Average Loss: 3.738, avg. samples / sec: 53166.38
Iteration:   3980, Loss function: 3.678, Average Loss: 3.745, avg. samples / sec: 53126.54
Iteration:   3980, Loss function: 2.475, Average Loss: 3.735, avg. samples / sec: 53117.61
Iteration:   3980, Loss function: 3.853, Average Loss: 3.743, avg. samples / sec: 53156.86
Iteration:   3980, Loss function: 2.795, Average Loss: 3.753, avg. samples / sec: 53171.06
Iteration:   3980, Loss function: 2.951, Average Loss: 3.758, avg. samples / sec: 53171.14
Iteration:   3980, Loss function: 3.412, Average Loss: 3.790, avg. samples / sec: 53119.11
Iteration:   3980, Loss function: 3.764, Average Loss: 3.747, avg. samples / sec: 53186.81
Iteration:   3980, Loss function: 3.706, Average Loss: 3.757, avg. samples / sec: 53130.01
Iteration:   3980, Loss function: 4.497, Average Loss: 3.761, avg. samples / sec: 53167.03
Iteration:   3980, Loss function: 3.287, Average Loss: 3.760, avg. samples / sec: 53122.56
Iteration:   3980, Loss function: 2.886, Average Loss: 3.757, avg. samples / sec: 53147.34
Iteration:   3980, Loss function: 4.360, Average Loss: 3.761, avg. samples / sec: 53122.94
Iteration:   3980, Loss function: 3.304, Average Loss: 3.754, avg. samples / sec: 53050.13
Iteration:   3980, Loss function: 4.252, Average Loss: 3.759, avg. samples / sec: 53291.42
Iteration:   3980, Loss function: 4.381, Average Loss: 3.771, avg. samples / sec: 53239.55
Iteration:   3980, Loss function: 3.447, Average Loss: 3.737, avg. samples / sec: 53194.62
Iteration:   3980, Loss function: 4.583, Average Loss: 3.747, avg. samples / sec: 53235.33
Iteration:   3980, Loss function: 3.393, Average Loss: 3.727, avg. samples / sec: 53209.42
Iteration:   3980, Loss function: 2.202, Average Loss: 3.752, avg. samples / sec: 53214.67
Iteration:   3980, Loss function: 2.440, Average Loss: 3.776, avg. samples / sec: 53234.65
Iteration:   3980, Loss function: 2.285, Average Loss: 3.725, avg. samples / sec: 53184.14
Iteration:   3980, Loss function: 4.476, Average Loss: 3.737, avg. samples / sec: 53183.98
Iteration:   3980, Loss function: 2.500, Average Loss: 3.737, avg. samples / sec: 53189.60
Iteration:   3980, Loss function: 2.921, Average Loss: 3.758, avg. samples / sec: 53193.03
Iteration:   4000, Loss function: 3.883, Average Loss: 3.735, avg. samples / sec: 53700.94
Iteration:   4000, Loss function: 2.764, Average Loss: 3.765, avg. samples / sec: 53604.82
Iteration:   4000, Loss function: 2.994, Average Loss: 3.762, avg. samples / sec: 53615.87
Iteration:   4000, Loss function: 3.140, Average Loss: 3.769, avg. samples / sec: 53646.75
Iteration:   4000, Loss function: 2.749, Average Loss: 3.724, avg. samples / sec: 53676.97
Iteration:   4000, Loss function: 3.632, Average Loss: 3.750, avg. samples / sec: 53700.33
Iteration:   4000, Loss function: 2.726, Average Loss: 3.750, avg. samples / sec: 53773.15
Iteration:   4000, Loss function: 3.408, Average Loss: 3.758, avg. samples / sec: 53670.14
Iteration:   4000, Loss function: 3.063, Average Loss: 3.736, avg. samples / sec: 53645.14
Iteration:   4000, Loss function: 3.614, Average Loss: 3.734, avg. samples / sec: 53641.38
Iteration:   4000, Loss function: 3.775, Average Loss: 3.743, avg. samples / sec: 53647.97
Iteration:   4000, Loss function: 3.500, Average Loss: 3.736, avg. samples / sec: 53631.76
Iteration:   4000, Loss function: 2.852, Average Loss: 3.780, avg. samples / sec: 53640.44
Iteration:   4000, Loss function: 5.363, Average Loss: 3.743, avg. samples / sec: 53635.46
Iteration:   4000, Loss function: 3.085, Average Loss: 3.753, avg. samples / sec: 53622.30
Iteration:   4000, Loss function: 3.305, Average Loss: 3.740, avg. samples / sec: 53743.50
Iteration:   4000, Loss function: 3.874, Average Loss: 3.750, avg. samples / sec: 53583.46
Iteration:   4000, Loss function: 3.031, Average Loss: 3.755, avg. samples / sec: 53559.75
Iteration:   4000, Loss function: 4.637, Average Loss: 3.754, avg. samples / sec: 53411.04
Iteration:   4000, Loss function: 2.111, Average Loss: 3.726, avg. samples / sec: 53649.61
Iteration:   4000, Loss function: 3.047, Average Loss: 3.749, avg. samples / sec: 53439.66
Iteration:   4000, Loss function: 3.382, Average Loss: 3.723, avg. samples / sec: 53603.16
Iteration:   4000, Loss function: 3.499, Average Loss: 3.720, avg. samples / sec: 53620.30
Iteration:   4000, Loss function: 3.937, Average Loss: 3.772, avg. samples / sec: 53609.51
Iteration:   4000, Loss function: 4.202, Average Loss: 3.733, avg. samples / sec: 53557.70
Iteration:   4000, Loss function: 2.548, Average Loss: 3.750, avg. samples / sec: 53532.63
Iteration:   4000, Loss function: 3.619, Average Loss: 3.728, avg. samples / sec: 53592.87
Iteration:   4000, Loss function: 3.100, Average Loss: 3.747, avg. samples / sec: 53565.74
Iteration:   4000, Loss function: 3.425, Average Loss: 3.757, avg. samples / sec: 53513.18
Iteration:   4000, Loss function: 3.484, Average Loss: 3.749, avg. samples / sec: 53639.58
Iteration:   4020, Loss function: 3.828, Average Loss: 3.755, avg. samples / sec: 53471.86
Iteration:   4020, Loss function: 2.974, Average Loss: 3.715, avg. samples / sec: 53464.31
Iteration:   4020, Loss function: 2.525, Average Loss: 3.730, avg. samples / sec: 53453.32
Iteration:   4020, Loss function: 3.121, Average Loss: 3.739, avg. samples / sec: 53461.49
Iteration:   4020, Loss function: 3.337, Average Loss: 3.745, avg. samples / sec: 53432.12
Iteration:   4020, Loss function: 3.730, Average Loss: 3.749, avg. samples / sec: 53436.11
Iteration:   4020, Loss function: 3.385, Average Loss: 3.746, avg. samples / sec: 53416.16
Iteration:   4020, Loss function: 2.510, Average Loss: 3.751, avg. samples / sec: 53291.11
Iteration:   4020, Loss function: 3.826, Average Loss: 3.732, avg. samples / sec: 53433.46
Iteration:   4020, Loss function: 2.826, Average Loss: 3.726, avg. samples / sec: 53452.73
Iteration:   4020, Loss function: 3.755, Average Loss: 3.743, avg. samples / sec: 53532.08
Iteration:   4020, Loss function: 3.536, Average Loss: 3.743, avg. samples / sec: 53579.50
Iteration:   4020, Loss function: 2.931, Average Loss: 3.741, avg. samples / sec: 53631.31
Iteration:   4020, Loss function: 4.606, Average Loss: 3.734, avg. samples / sec: 53236.20
Iteration:   4020, Loss function: 3.624, Average Loss: 3.745, avg. samples / sec: 53467.88
Iteration:   4020, Loss function: 3.289, Average Loss: 3.735, avg. samples / sec: 53417.36
Iteration:   4020, Loss function: 3.283, Average Loss: 3.777, avg. samples / sec: 53409.73
Iteration:   4020, Loss function: 2.488, Average Loss: 3.745, avg. samples / sec: 53451.74
Iteration:   4020, Loss function: 4.452, Average Loss: 3.716, avg. samples / sec: 53445.03
Iteration:   4020, Loss function: 3.237, Average Loss: 3.712, avg. samples / sec: 53422.46
Iteration:   4020, Loss function: 3.707, Average Loss: 3.750, avg. samples / sec: 53469.97
Iteration:   4020, Loss function: 3.929, Average Loss: 3.737, avg. samples / sec: 53452.45
Iteration:   4020, Loss function: 3.165, Average Loss: 3.766, avg. samples / sec: 53409.89
Iteration:   4020, Loss function: 3.127, Average Loss: 3.744, avg. samples / sec: 53479.47
Iteration:   4020, Loss function: 2.748, Average Loss: 3.747, avg. samples / sec: 53427.93
Iteration:   4020, Loss function: 2.405, Average Loss: 3.719, avg. samples / sec: 53376.77
Iteration:   4020, Loss function: 3.642, Average Loss: 3.731, avg. samples / sec: 53222.16
Iteration:   4020, Loss function: 3.248, Average Loss: 3.725, avg. samples / sec: 53389.88
Iteration:   4020, Loss function: 3.399, Average Loss: 3.723, avg. samples / sec: 53418.41
Iteration:   4020, Loss function: 3.550, Average Loss: 3.761, avg. samples / sec: 53076.04
Iteration:   4040, Loss function: 3.140, Average Loss: 3.741, avg. samples / sec: 53684.13
Iteration:   4040, Loss function: 4.094, Average Loss: 3.727, avg. samples / sec: 53709.84
Iteration:   4040, Loss function: 3.487, Average Loss: 3.749, avg. samples / sec: 53443.23
Iteration:   4040, Loss function: 3.848, Average Loss: 3.711, avg. samples / sec: 53527.59
Iteration:   4040, Loss function: 3.682, Average Loss: 3.751, avg. samples / sec: 53864.67
Iteration:   4040, Loss function: 3.388, Average Loss: 3.723, avg. samples / sec: 53555.21
Iteration:   4040, Loss function: 3.936, Average Loss: 3.738, avg. samples / sec: 53532.75
Iteration:   4040, Loss function: 3.490, Average Loss: 3.722, avg. samples / sec: 53518.71
Iteration:   4040, Loss function: 3.693, Average Loss: 3.744, avg. samples / sec: 53535.50
Iteration:   4040, Loss function: 2.606, Average Loss: 3.731, avg. samples / sec: 53552.79
Iteration:   4040, Loss function: 4.091, Average Loss: 3.763, avg. samples / sec: 53569.12
Iteration:   4040, Loss function: 5.114, Average Loss: 3.741, avg. samples / sec: 53513.04
Iteration:   4040, Loss function: 3.610, Average Loss: 3.735, avg. samples / sec: 53542.70
Iteration:   4040, Loss function: 3.336, Average Loss: 3.720, avg. samples / sec: 53506.86
Iteration:   4040, Loss function: 3.056, Average Loss: 3.724, avg. samples / sec: 53545.69
Iteration:   4040, Loss function: 3.981, Average Loss: 3.738, avg. samples / sec: 53512.12
Iteration:   4040, Loss function: 3.585, Average Loss: 3.739, avg. samples / sec: 53551.24
Iteration:   4040, Loss function: 2.695, Average Loss: 3.736, avg. samples / sec: 53472.79
Iteration:   4040, Loss function: 2.356, Average Loss: 3.732, avg. samples / sec: 53352.14
Iteration:   4040, Loss function: 3.525, Average Loss: 3.707, avg. samples / sec: 53557.59
Iteration:   4040, Loss function: 3.384, Average Loss: 3.707, avg. samples / sec: 53535.84
Iteration:   4040, Loss function: 2.882, Average Loss: 3.717, avg. samples / sec: 53600.84
Iteration:   4040, Loss function: 3.776, Average Loss: 3.746, avg. samples / sec: 53557.72
Iteration:   4040, Loss function: 3.104, Average Loss: 3.730, avg. samples / sec: 53561.54
Iteration:   4040, Loss function: 3.936, Average Loss: 3.741, avg. samples / sec: 53561.85
Iteration:   4040, Loss function: 2.586, Average Loss: 3.712, avg. samples / sec: 53548.64
Iteration:   4040, Loss function: 3.034, Average Loss: 3.757, avg. samples / sec: 53536.43
Iteration:   4040, Loss function: 2.662, Average Loss: 3.721, avg. samples / sec: 53542.54
Iteration:   4040, Loss function: 3.491, Average Loss: 3.719, avg. samples / sec: 53544.43
Iteration:   4040, Loss function: 3.805, Average Loss: 3.736, avg. samples / sec: 53501.19
:::MLL 1558640707.863 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558640707.863 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 2.923, Average Loss: 3.740, avg. samples / sec: 53258.93
Iteration:   4060, Loss function: 3.874, Average Loss: 3.739, avg. samples / sec: 53187.63
Iteration:   4060, Loss function: 3.718, Average Loss: 3.725, avg. samples / sec: 53170.32
Iteration:   4060, Loss function: 3.537, Average Loss: 3.742, avg. samples / sec: 53161.53
Iteration:   4060, Loss function: 3.798, Average Loss: 3.718, avg. samples / sec: 53176.44
Iteration:   4060, Loss function: 3.085, Average Loss: 3.735, avg. samples / sec: 53220.13
Iteration:   4060, Loss function: 3.848, Average Loss: 3.706, avg. samples / sec: 53118.21
Iteration:   4060, Loss function: 2.858, Average Loss: 3.728, avg. samples / sec: 53171.82
Iteration:   4060, Loss function: 4.034, Average Loss: 3.715, avg. samples / sec: 53129.10
Iteration:   4060, Loss function: 3.829, Average Loss: 3.728, avg. samples / sec: 53170.38
Iteration:   4060, Loss function: 4.064, Average Loss: 3.732, avg. samples / sec: 53196.05
Iteration:   4060, Loss function: 3.183, Average Loss: 3.708, avg. samples / sec: 53171.92
Iteration:   4060, Loss function: 2.875, Average Loss: 3.735, avg. samples / sec: 53178.56
Iteration:   4060, Loss function: 3.765, Average Loss: 3.730, avg. samples / sec: 53111.74
Iteration:   4060, Loss function: 3.587, Average Loss: 3.717, avg. samples / sec: 53149.80
Iteration:   4060, Loss function: 3.891, Average Loss: 3.725, avg. samples / sec: 53138.10
Iteration:   4060, Loss function: 2.776, Average Loss: 3.760, avg. samples / sec: 53096.58
Iteration:   4060, Loss function: 3.298, Average Loss: 3.735, avg. samples / sec: 53313.39
Iteration:   4060, Loss function: 1.883, Average Loss: 3.737, avg. samples / sec: 53075.54
Iteration:   4060, Loss function: 2.912, Average Loss: 3.726, avg. samples / sec: 53174.83
Iteration:   4060, Loss function: 1.996, Average Loss: 3.700, avg. samples / sec: 53163.44
Iteration:   4060, Loss function: 3.213, Average Loss: 3.699, avg. samples / sec: 53155.03
Iteration:   4060, Loss function: 2.880, Average Loss: 3.704, avg. samples / sec: 53174.83
Iteration:   4060, Loss function: 3.102, Average Loss: 3.750, avg. samples / sec: 53180.95
Iteration:   4060, Loss function: 4.324, Average Loss: 3.714, avg. samples / sec: 53125.88
Iteration:   4060, Loss function: 2.632, Average Loss: 3.736, avg. samples / sec: 53144.31
Iteration:   4060, Loss function: 3.533, Average Loss: 3.731, avg. samples / sec: 53131.91
Iteration:   4060, Loss function: 3.316, Average Loss: 3.711, avg. samples / sec: 53143.77
Iteration:   4060, Loss function: 4.159, Average Loss: 3.712, avg. samples / sec: 53147.30
Iteration:   4060, Loss function: 2.258, Average Loss: 3.723, avg. samples / sec: 53123.42
Iteration:   4080, Loss function: 3.107, Average Loss: 3.733, avg. samples / sec: 53475.49
Iteration:   4080, Loss function: 2.263, Average Loss: 3.729, avg. samples / sec: 53454.05
Iteration:   4080, Loss function: 2.212, Average Loss: 3.711, avg. samples / sec: 53489.48
Iteration:   4080, Loss function: 3.542, Average Loss: 3.732, avg. samples / sec: 53485.15
Iteration:   4080, Loss function: 3.363, Average Loss: 3.698, avg. samples / sec: 53484.71
Iteration:   4080, Loss function: 3.095, Average Loss: 3.718, avg. samples / sec: 53531.29
Iteration:   4080, Loss function: 3.037, Average Loss: 3.717, avg. samples / sec: 53481.40
Iteration:   4080, Loss function: 4.156, Average Loss: 3.721, avg. samples / sec: 53483.39
Iteration:   4080, Loss function: 4.228, Average Loss: 3.720, avg. samples / sec: 53504.20
Iteration:   4080, Loss function: 3.437, Average Loss: 3.703, avg. samples / sec: 53466.81
Iteration:   4080, Loss function: 3.442, Average Loss: 3.724, avg. samples / sec: 53469.59
Iteration:   4080, Loss function: 3.069, Average Loss: 3.727, avg. samples / sec: 53426.55
Iteration:   4080, Loss function: 2.594, Average Loss: 3.728, avg. samples / sec: 53507.43
Iteration:   4080, Loss function: 3.496, Average Loss: 3.708, avg. samples / sec: 53467.88
Iteration:   4080, Loss function: 3.750, Average Loss: 3.723, avg. samples / sec: 53418.17
Iteration:   4080, Loss function: 2.109, Average Loss: 3.755, avg. samples / sec: 53457.58
Iteration:   4080, Loss function: 3.710, Average Loss: 3.691, avg. samples / sec: 53519.15
Iteration:   4080, Loss function: 4.004, Average Loss: 3.695, avg. samples / sec: 53530.48
Iteration:   4080, Loss function: 2.733, Average Loss: 3.717, avg. samples / sec: 53108.40
Iteration:   4080, Loss function: 4.552, Average Loss: 3.696, avg. samples / sec: 53469.02
Iteration:   4080, Loss function: 2.434, Average Loss: 3.708, avg. samples / sec: 53509.76
Iteration:   4080, Loss function: 3.641, Average Loss: 3.724, avg. samples / sec: 53331.49
Iteration:   4080, Loss function: 4.357, Average Loss: 3.746, avg. samples / sec: 53485.74
Iteration:   4080, Loss function: 2.775, Average Loss: 3.702, avg. samples / sec: 53518.62
Iteration:   4080, Loss function: 3.801, Average Loss: 3.719, avg. samples / sec: 53415.82
Iteration:   4080, Loss function: 3.735, Average Loss: 3.703, avg. samples / sec: 53502.17
Iteration:   4080, Loss function: 2.718, Average Loss: 3.706, avg. samples / sec: 53202.45
Iteration:   4080, Loss function: 3.487, Average Loss: 3.726, avg. samples / sec: 53459.87
Iteration:   4080, Loss function: 3.348, Average Loss: 3.727, avg. samples / sec: 53451.38
Iteration:   4080, Loss function: 3.357, Average Loss: 3.721, avg. samples / sec: 53457.60
Iteration:   4100, Loss function: 2.817, Average Loss: 3.708, avg. samples / sec: 53709.02
Iteration:   4100, Loss function: 2.991, Average Loss: 3.727, avg. samples / sec: 53301.07
Iteration:   4100, Loss function: 4.393, Average Loss: 3.688, avg. samples / sec: 53372.87
Iteration:   4100, Loss function: 2.810, Average Loss: 3.723, avg. samples / sec: 53208.96
Iteration:   4100, Loss function: 2.959, Average Loss: 3.696, avg. samples / sec: 53626.48
Iteration:   4100, Loss function: 3.850, Average Loss: 3.721, avg. samples / sec: 53310.65
Iteration:   4100, Loss function: 3.254, Average Loss: 3.707, avg. samples / sec: 53299.32
Iteration:   4100, Loss function: 3.345, Average Loss: 3.717, avg. samples / sec: 53370.91
Iteration:   4100, Loss function: 2.983, Average Loss: 3.719, avg. samples / sec: 53310.10
Iteration:   4100, Loss function: 2.570, Average Loss: 3.715, avg. samples / sec: 53334.94
Iteration:   4100, Loss function: 3.375, Average Loss: 3.711, avg. samples / sec: 53327.85
Iteration:   4100, Loss function: 4.877, Average Loss: 3.706, avg. samples / sec: 53347.74
Iteration:   4100, Loss function: 3.556, Average Loss: 3.711, avg. samples / sec: 53298.59
Iteration:   4100, Loss function: 3.315, Average Loss: 3.696, avg. samples / sec: 53316.27
Iteration:   4100, Loss function: 3.610, Average Loss: 3.711, avg. samples / sec: 53273.04
Iteration:   4100, Loss function: 3.882, Average Loss: 3.713, avg. samples / sec: 53295.45
Iteration:   4100, Loss function: 2.438, Average Loss: 3.748, avg. samples / sec: 53366.20
Iteration:   4100, Loss function: 4.135, Average Loss: 3.716, avg. samples / sec: 53287.85
Iteration:   4100, Loss function: 3.454, Average Loss: 3.689, avg. samples / sec: 53309.72
Iteration:   4100, Loss function: 2.994, Average Loss: 3.713, avg. samples / sec: 53372.75
Iteration:   4100, Loss function: 3.289, Average Loss: 3.719, avg. samples / sec: 53381.57
Iteration:   4100, Loss function: 3.560, Average Loss: 3.692, avg. samples / sec: 53320.89
Iteration:   4100, Loss function: 3.773, Average Loss: 3.741, avg. samples / sec: 53310.81
Iteration:   4100, Loss function: 4.260, Average Loss: 3.720, avg. samples / sec: 53300.81
Iteration:   4100, Loss function: 3.705, Average Loss: 3.702, avg. samples / sec: 53293.03
Iteration:   4100, Loss function: 3.076, Average Loss: 3.716, avg. samples / sec: 53355.29
Iteration:   4100, Loss function: 3.503, Average Loss: 3.697, avg. samples / sec: 53321.46
Iteration:   4100, Loss function: 3.422, Average Loss: 3.692, avg. samples / sec: 53328.42
Iteration:   4100, Loss function: 3.111, Average Loss: 3.720, avg. samples / sec: 53413.86
Iteration:   4100, Loss function: 3.098, Average Loss: 3.683, avg. samples / sec: 53175.19
:::MLL 1558640710.073 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558640710.074 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 2.698, Average Loss: 3.717, avg. samples / sec: 52745.27
Iteration:   4120, Loss function: 2.835, Average Loss: 3.699, avg. samples / sec: 52649.54
Iteration:   4120, Loss function: 3.135, Average Loss: 3.715, avg. samples / sec: 52687.12
Iteration:   4120, Loss function: 3.134, Average Loss: 3.683, avg. samples / sec: 52587.21
Iteration:   4120, Loss function: 3.823, Average Loss: 3.705, avg. samples / sec: 52741.82
Iteration:   4120, Loss function: 3.522, Average Loss: 3.693, avg. samples / sec: 52624.91
Iteration:   4120, Loss function: 3.659, Average Loss: 3.715, avg. samples / sec: 52617.31
Iteration:   4120, Loss function: 4.083, Average Loss: 3.704, avg. samples / sec: 52658.22
Iteration:   4120, Loss function: 2.580, Average Loss: 3.711, avg. samples / sec: 52643.88
Iteration:   4120, Loss function: 2.674, Average Loss: 3.740, avg. samples / sec: 52676.33
Iteration:   4120, Loss function: 3.625, Average Loss: 3.700, avg. samples / sec: 52608.49
Iteration:   4120, Loss function: 3.631, Average Loss: 3.709, avg. samples / sec: 52658.57
Iteration:   4120, Loss function: 3.321, Average Loss: 3.716, avg. samples / sec: 52624.44
Iteration:   4120, Loss function: 3.526, Average Loss: 3.686, avg. samples / sec: 52611.14
Iteration:   4120, Loss function: 3.697, Average Loss: 3.703, avg. samples / sec: 52593.04
Iteration:   4120, Loss function: 2.895, Average Loss: 3.709, avg. samples / sec: 52595.41
Iteration:   4120, Loss function: 2.586, Average Loss: 3.708, avg. samples / sec: 52574.14
Iteration:   4120, Loss function: 3.801, Average Loss: 3.699, avg. samples / sec: 52577.97
Iteration:   4120, Loss function: 4.759, Average Loss: 3.710, avg. samples / sec: 52732.13
Iteration:   4120, Loss function: 2.874, Average Loss: 3.691, avg. samples / sec: 52753.86
Iteration:   4120, Loss function: 3.151, Average Loss: 3.711, avg. samples / sec: 52735.50
Iteration:   4120, Loss function: 3.640, Average Loss: 3.713, avg. samples / sec: 52690.78
Iteration:   4120, Loss function: 4.206, Average Loss: 3.710, avg. samples / sec: 52695.73
Iteration:   4120, Loss function: 2.336, Average Loss: 3.676, avg. samples / sec: 52751.29
Iteration:   4120, Loss function: 3.493, Average Loss: 3.682, avg. samples / sec: 52628.05
Iteration:   4120, Loss function: 3.713, Average Loss: 3.693, avg. samples / sec: 52670.80
Iteration:   4120, Loss function: 4.044, Average Loss: 3.692, avg. samples / sec: 52633.01
Iteration:   4120, Loss function: 4.269, Average Loss: 3.734, avg. samples / sec: 52622.16
Iteration:   4120, Loss function: 4.055, Average Loss: 3.685, avg. samples / sec: 52620.15
Iteration:   4120, Loss function: 2.939, Average Loss: 3.717, avg. samples / sec: 52611.35
Iteration:   4140, Loss function: 3.308, Average Loss: 3.709, avg. samples / sec: 53551.98
Iteration:   4140, Loss function: 4.466, Average Loss: 3.717, avg. samples / sec: 53353.31
Iteration:   4140, Loss function: 3.829, Average Loss: 3.692, avg. samples / sec: 53418.47
Iteration:   4140, Loss function: 3.307, Average Loss: 3.694, avg. samples / sec: 53540.95
Iteration:   4140, Loss function: 3.657, Average Loss: 3.697, avg. samples / sec: 53539.32
Iteration:   4140, Loss function: 3.459, Average Loss: 3.675, avg. samples / sec: 53506.64
Iteration:   4140, Loss function: 4.487, Average Loss: 3.684, avg. samples / sec: 53506.15
Iteration:   4140, Loss function: 3.252, Average Loss: 3.712, avg. samples / sec: 53513.48
Iteration:   4140, Loss function: 2.321, Average Loss: 3.700, avg. samples / sec: 53573.88
Iteration:   4140, Loss function: 3.884, Average Loss: 3.707, avg. samples / sec: 53511.86
Iteration:   4140, Loss function: 4.429, Average Loss: 3.701, avg. samples / sec: 53523.40
Iteration:   4140, Loss function: 3.334, Average Loss: 3.698, avg. samples / sec: 53470.32
Iteration:   4140, Loss function: 4.764, Average Loss: 3.707, avg. samples / sec: 53490.98
Iteration:   4140, Loss function: 3.989, Average Loss: 3.728, avg. samples / sec: 53474.35
Iteration:   4140, Loss function: 2.935, Average Loss: 3.696, avg. samples / sec: 53521.86
Iteration:   4140, Loss function: 3.485, Average Loss: 3.706, avg. samples / sec: 53535.48
Iteration:   4140, Loss function: 3.045, Average Loss: 3.689, avg. samples / sec: 53536.09
Iteration:   4140, Loss function: 4.036, Average Loss: 3.683, avg. samples / sec: 53503.45
Iteration:   4140, Loss function: 3.575, Average Loss: 3.666, avg. samples / sec: 53534.97
Iteration:   4140, Loss function: 3.224, Average Loss: 3.705, avg. samples / sec: 53443.17
Iteration:   4140, Loss function: 3.102, Average Loss: 3.681, avg. samples / sec: 53528.89
Iteration:   4140, Loss function: 2.615, Average Loss: 3.701, avg. samples / sec: 53379.64
Iteration:   4140, Loss function: 2.579, Average Loss: 3.672, avg. samples / sec: 53488.46
Iteration:   4140, Loss function: 2.876, Average Loss: 3.685, avg. samples / sec: 53401.00
Iteration:   4140, Loss function: 3.286, Average Loss: 3.731, avg. samples / sec: 53524.26
Iteration:   4140, Loss function: 3.916, Average Loss: 3.689, avg. samples / sec: 53471.60
Iteration:   4140, Loss function: 4.041, Average Loss: 3.706, avg. samples / sec: 53388.60
Iteration:   4140, Loss function: 3.854, Average Loss: 3.701, avg. samples / sec: 53411.95
Iteration:   4140, Loss function: 2.524, Average Loss: 3.675, avg. samples / sec: 53469.32
Iteration:   4140, Loss function: 2.760, Average Loss: 3.709, avg. samples / sec: 53481.23
Iteration:   4160, Loss function: 4.059, Average Loss: 3.678, avg. samples / sec: 53833.25
Iteration:   4160, Loss function: 3.289, Average Loss: 3.712, avg. samples / sec: 53400.32
Iteration:   4160, Loss function: 3.921, Average Loss: 3.685, avg. samples / sec: 53381.81
Iteration:   4160, Loss function: 3.049, Average Loss: 3.669, avg. samples / sec: 53368.85
Iteration:   4160, Loss function: 2.968, Average Loss: 3.697, avg. samples / sec: 53387.57
Iteration:   4160, Loss function: 3.561, Average Loss: 3.688, avg. samples / sec: 53352.34
Iteration:   4160, Loss function: 3.154, Average Loss: 3.690, avg. samples / sec: 53378.29
Iteration:   4160, Loss function: 4.660, Average Loss: 3.688, avg. samples / sec: 53386.96
Iteration:   4160, Loss function: 2.746, Average Loss: 3.690, avg. samples / sec: 53406.02
Iteration:   4160, Loss function: 2.842, Average Loss: 3.688, avg. samples / sec: 53324.08
Iteration:   4160, Loss function: 3.917, Average Loss: 3.697, avg. samples / sec: 53403.53
Iteration:   4160, Loss function: 3.140, Average Loss: 3.724, avg. samples / sec: 53386.16
Iteration:   4160, Loss function: 2.052, Average Loss: 3.699, avg. samples / sec: 53330.74
Iteration:   4160, Loss function: 2.638, Average Loss: 3.685, avg. samples / sec: 53377.08
Iteration:   4160, Loss function: 3.417, Average Loss: 3.680, avg. samples / sec: 53382.11
Iteration:   4160, Loss function: 3.155, Average Loss: 3.698, avg. samples / sec: 53156.38
Iteration:   4160, Loss function: 3.427, Average Loss: 3.702, avg. samples / sec: 53348.85
Iteration:   4160, Loss function: 3.271, Average Loss: 3.685, avg. samples / sec: 53205.16
Iteration:   4160, Loss function: 3.587, Average Loss: 3.697, avg. samples / sec: 53405.52
Iteration:   4160, Loss function: 4.214, Average Loss: 3.679, avg. samples / sec: 53354.24
Iteration:   4160, Loss function: 2.866, Average Loss: 3.661, avg. samples / sec: 53305.32
Iteration:   4160, Loss function: 3.252, Average Loss: 3.696, avg. samples / sec: 53422.44
Iteration:   4160, Loss function: 3.630, Average Loss: 3.696, avg. samples / sec: 53412.97
Iteration:   4160, Loss function: 3.205, Average Loss: 3.672, avg. samples / sec: 53350.42
Iteration:   4160, Loss function: 4.009, Average Loss: 3.722, avg. samples / sec: 53361.68
Iteration:   4160, Loss function: 3.533, Average Loss: 3.697, avg. samples / sec: 53326.85
Iteration:   4160, Loss function: 3.500, Average Loss: 3.680, avg. samples / sec: 53348.93
Iteration:   4160, Loss function: 3.091, Average Loss: 3.665, avg. samples / sec: 53419.61
Iteration:   4160, Loss function: 3.267, Average Loss: 3.706, avg. samples / sec: 53043.10
Iteration:   4160, Loss function: 4.223, Average Loss: 3.703, avg. samples / sec: 53376.39
Iteration:   4180, Loss function: 4.357, Average Loss: 3.671, avg. samples / sec: 53516.78
Iteration:   4180, Loss function: 2.328, Average Loss: 3.691, avg. samples / sec: 53731.06
Iteration:   4180, Loss function: 2.955, Average Loss: 3.684, avg. samples / sec: 53729.52
Iteration:   4180, Loss function: 3.929, Average Loss: 3.702, avg. samples / sec: 53472.85
Iteration:   4180, Loss function: 3.555, Average Loss: 3.698, avg. samples / sec: 53553.67
Iteration:   4180, Loss function: 3.846, Average Loss: 3.678, avg. samples / sec: 53465.47
Iteration:   4180, Loss function: 2.670, Average Loss: 3.682, avg. samples / sec: 53481.27
Iteration:   4180, Loss function: 3.795, Average Loss: 3.682, avg. samples / sec: 53510.60
Iteration:   4180, Loss function: 3.520, Average Loss: 3.662, avg. samples / sec: 53458.05
Iteration:   4180, Loss function: 3.911, Average Loss: 3.693, avg. samples / sec: 53523.56
Iteration:   4180, Loss function: 3.088, Average Loss: 3.717, avg. samples / sec: 53507.00
Iteration:   4180, Loss function: 3.192, Average Loss: 3.679, avg. samples / sec: 53479.94
Iteration:   4180, Loss function: 4.267, Average Loss: 3.700, avg. samples / sec: 53793.43
Iteration:   4180, Loss function: 3.250, Average Loss: 3.683, avg. samples / sec: 53470.52
Iteration:   4180, Loss function: 2.739, Average Loss: 3.687, avg. samples / sec: 53482.78
Iteration:   4180, Loss function: 2.146, Average Loss: 3.671, avg. samples / sec: 53494.10
Iteration:   4180, Loss function: 5.673, Average Loss: 3.693, avg. samples / sec: 53433.01
Iteration:   4180, Loss function: 3.486, Average Loss: 3.678, avg. samples / sec: 53477.78
Iteration:   4180, Loss function: 3.628, Average Loss: 3.680, avg. samples / sec: 53408.59
Iteration:   4180, Loss function: 3.681, Average Loss: 3.648, avg. samples / sec: 53535.17
Iteration:   4180, Loss function: 3.073, Average Loss: 3.717, avg. samples / sec: 53545.65
Iteration:   4180, Loss function: 3.240, Average Loss: 3.668, avg. samples / sec: 53541.82
Iteration:   4180, Loss function: 3.778, Average Loss: 3.673, avg. samples / sec: 53503.37
Iteration:   4180, Loss function: 3.216, Average Loss: 3.684, avg. samples / sec: 53468.27
Iteration:   4180, Loss function: 3.369, Average Loss: 3.671, avg. samples / sec: 53526.51
Iteration:   4180, Loss function: 3.748, Average Loss: 3.689, avg. samples / sec: 53494.98
Iteration:   4180, Loss function: 3.635, Average Loss: 3.687, avg. samples / sec: 53476.40
Iteration:   4180, Loss function: 3.017, Average Loss: 3.662, avg. samples / sec: 53507.73
Iteration:   4180, Loss function: 3.356, Average Loss: 3.693, avg. samples / sec: 53479.94
Iteration:   4180, Loss function: 3.513, Average Loss: 3.701, avg. samples / sec: 53499.38
:::MLL 1558640712.278 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558640712.279 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558640712.349 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.64s)
DONE (t=2.54s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22920
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39005
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23344
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05800
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24020
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22031
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33830
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53318
Current AP: 0.22920 AP goal: 0.23000
:::MLL 1558640716.186 eval_accuracy: {"value": 0.22920303693358543, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558640716.275 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558640716.284 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558640716.285 block_start: {"value": null, "metadata": {"first_epoch_num": 61, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   4200, Loss function: 3.875, Average Loss: 3.666, avg. samples / sec: 7326.62
Iteration:   4200, Loss function: 3.530, Average Loss: 3.683, avg. samples / sec: 7326.55
Iteration:   4200, Loss function: 2.651, Average Loss: 3.674, avg. samples / sec: 7326.24
Iteration:   4200, Loss function: 4.006, Average Loss: 3.687, avg. samples / sec: 7328.38
Iteration:   4200, Loss function: 2.703, Average Loss: 3.710, avg. samples / sec: 7327.51
Iteration:   4200, Loss function: 3.787, Average Loss: 3.673, avg. samples / sec: 7326.61
Iteration:   4200, Loss function: 3.144, Average Loss: 3.674, avg. samples / sec: 7327.92
Iteration:   4200, Loss function: 3.435, Average Loss: 3.691, avg. samples / sec: 7326.79
Iteration:   4200, Loss function: 3.507, Average Loss: 3.671, avg. samples / sec: 7326.93
Iteration:   4200, Loss function: 2.980, Average Loss: 3.659, avg. samples / sec: 7326.60
Iteration:   4200, Loss function: 3.511, Average Loss: 3.687, avg. samples / sec: 7327.14
Iteration:   4200, Loss function: 4.043, Average Loss: 3.701, avg. samples / sec: 7323.82
Iteration:   4200, Loss function: 3.181, Average Loss: 3.674, avg. samples / sec: 7327.22
Iteration:   4200, Loss function: 2.623, Average Loss: 3.687, avg. samples / sec: 7326.36
Iteration:   4200, Loss function: 3.548, Average Loss: 3.666, avg. samples / sec: 7326.35
Iteration:   4200, Loss function: 2.415, Average Loss: 3.670, avg. samples / sec: 7325.87
Iteration:   4200, Loss function: 3.289, Average Loss: 3.660, avg. samples / sec: 7327.33
Iteration:   4200, Loss function: 3.142, Average Loss: 3.642, avg. samples / sec: 7326.72
Iteration:   4200, Loss function: 3.294, Average Loss: 3.665, avg. samples / sec: 7326.92
Iteration:   4200, Loss function: 3.159, Average Loss: 3.696, avg. samples / sec: 7328.49
Iteration:   4200, Loss function: 3.460, Average Loss: 3.671, avg. samples / sec: 7322.51
Iteration:   4200, Loss function: 3.470, Average Loss: 3.680, avg. samples / sec: 7326.66
Iteration:   4200, Loss function: 2.279, Average Loss: 3.680, avg. samples / sec: 7327.30
Iteration:   4200, Loss function: 3.019, Average Loss: 3.711, avg. samples / sec: 7326.25
Iteration:   4200, Loss function: 4.243, Average Loss: 3.679, avg. samples / sec: 7322.56
Iteration:   4200, Loss function: 3.882, Average Loss: 3.677, avg. samples / sec: 7322.18
Iteration:   4200, Loss function: 4.269, Average Loss: 3.659, avg. samples / sec: 7327.02
Iteration:   4200, Loss function: 3.421, Average Loss: 3.688, avg. samples / sec: 7326.86
Iteration:   4200, Loss function: 2.496, Average Loss: 3.661, avg. samples / sec: 7325.60
Iteration:   4200, Loss function: 2.575, Average Loss: 3.681, avg. samples / sec: 7325.29
Iteration:   4220, Loss function: 2.242, Average Loss: 3.657, avg. samples / sec: 53003.10
Iteration:   4220, Loss function: 3.742, Average Loss: 3.674, avg. samples / sec: 53002.50
Iteration:   4220, Loss function: 2.691, Average Loss: 3.660, avg. samples / sec: 53008.84
Iteration:   4220, Loss function: 3.508, Average Loss: 3.678, avg. samples / sec: 53039.36
Iteration:   4220, Loss function: 3.836, Average Loss: 3.696, avg. samples / sec: 53053.68
Iteration:   4220, Loss function: 2.701, Average Loss: 3.667, avg. samples / sec: 53026.45
Iteration:   4220, Loss function: 2.838, Average Loss: 3.671, avg. samples / sec: 53021.19
Iteration:   4220, Loss function: 3.305, Average Loss: 3.651, avg. samples / sec: 53007.19
Iteration:   4220, Loss function: 3.887, Average Loss: 3.664, avg. samples / sec: 53047.55
Iteration:   4220, Loss function: 3.700, Average Loss: 3.667, avg. samples / sec: 52994.41
Iteration:   4220, Loss function: 3.425, Average Loss: 3.680, avg. samples / sec: 53024.02
Iteration:   4220, Loss function: 2.945, Average Loss: 3.679, avg. samples / sec: 52989.75
Iteration:   4220, Loss function: 3.415, Average Loss: 3.702, avg. samples / sec: 52952.71
Iteration:   4220, Loss function: 2.178, Average Loss: 3.664, avg. samples / sec: 53001.54
Iteration:   4220, Loss function: 2.858, Average Loss: 3.660, avg. samples / sec: 53021.46
Iteration:   4220, Loss function: 4.391, Average Loss: 3.654, avg. samples / sec: 52999.53
Iteration:   4220, Loss function: 2.583, Average Loss: 3.654, avg. samples / sec: 53064.93
Iteration:   4220, Loss function: 3.157, Average Loss: 3.635, avg. samples / sec: 52985.24
Iteration:   4220, Loss function: 4.361, Average Loss: 3.658, avg. samples / sec: 53000.33
Iteration:   4220, Loss function: 2.326, Average Loss: 3.704, avg. samples / sec: 53011.77
Iteration:   4220, Loss function: 2.431, Average Loss: 3.668, avg. samples / sec: 52994.23
Iteration:   4220, Loss function: 1.848, Average Loss: 3.685, avg. samples / sec: 52969.33
Iteration:   4220, Loss function: 3.522, Average Loss: 3.659, avg. samples / sec: 52971.12
Iteration:   4220, Loss function: 2.380, Average Loss: 3.676, avg. samples / sec: 53067.15
Iteration:   4220, Loss function: 2.056, Average Loss: 3.674, avg. samples / sec: 52956.25
Iteration:   4220, Loss function: 3.199, Average Loss: 3.653, avg. samples / sec: 52976.82
Iteration:   4220, Loss function: 3.154, Average Loss: 3.673, avg. samples / sec: 52949.17
Iteration:   4220, Loss function: 2.800, Average Loss: 3.678, avg. samples / sec: 52973.71
Iteration:   4220, Loss function: 2.858, Average Loss: 3.670, avg. samples / sec: 52961.71
Iteration:   4220, Loss function: 3.332, Average Loss: 3.679, avg. samples / sec: 52703.83
Iteration:   4240, Loss function: 3.554, Average Loss: 3.646, avg. samples / sec: 53177.46
Iteration:   4240, Loss function: 2.342, Average Loss: 3.667, avg. samples / sec: 53209.54
Iteration:   4240, Loss function: 3.227, Average Loss: 3.670, avg. samples / sec: 53148.58
Iteration:   4240, Loss function: 3.164, Average Loss: 3.698, avg. samples / sec: 53273.69
Iteration:   4240, Loss function: 3.699, Average Loss: 3.654, avg. samples / sec: 53087.24
Iteration:   4240, Loss function: 3.866, Average Loss: 3.662, avg. samples / sec: 53220.03
Iteration:   4240, Loss function: 3.848, Average Loss: 3.648, avg. samples / sec: 53206.61
Iteration:   4240, Loss function: 3.707, Average Loss: 3.675, avg. samples / sec: 53191.73
Iteration:   4240, Loss function: 4.287, Average Loss: 3.666, avg. samples / sec: 53159.93
Iteration:   4240, Loss function: 2.559, Average Loss: 3.678, avg. samples / sec: 53191.61
Iteration:   4240, Loss function: 3.289, Average Loss: 3.671, avg. samples / sec: 53468.19
Iteration:   4240, Loss function: 2.902, Average Loss: 3.660, avg. samples / sec: 53172.88
Iteration:   4240, Loss function: 4.326, Average Loss: 3.661, avg. samples / sec: 53152.81
Iteration:   4240, Loss function: 3.933, Average Loss: 3.668, avg. samples / sec: 53051.34
Iteration:   4240, Loss function: 3.035, Average Loss: 3.648, avg. samples / sec: 53221.38
Iteration:   4240, Loss function: 2.920, Average Loss: 3.667, avg. samples / sec: 53275.08
Iteration:   4240, Loss function: 3.413, Average Loss: 3.652, avg. samples / sec: 53197.57
Iteration:   4240, Loss function: 1.801, Average Loss: 3.630, avg. samples / sec: 53215.17
Iteration:   4240, Loss function: 3.859, Average Loss: 3.671, avg. samples / sec: 53271.75
Iteration:   4240, Loss function: 3.686, Average Loss: 3.674, avg. samples / sec: 53241.97
Iteration:   4240, Loss function: 3.216, Average Loss: 3.649, avg. samples / sec: 53240.44
Iteration:   4240, Loss function: 3.571, Average Loss: 3.660, avg. samples / sec: 53232.23
Iteration:   4240, Loss function: 4.124, Average Loss: 3.704, avg. samples / sec: 53189.50
Iteration:   4240, Loss function: 2.083, Average Loss: 3.650, avg. samples / sec: 53179.39
Iteration:   4240, Loss function: 2.979, Average Loss: 3.650, avg. samples / sec: 53222.87
Iteration:   4240, Loss function: 3.456, Average Loss: 3.692, avg. samples / sec: 52922.84
Iteration:   4240, Loss function: 3.430, Average Loss: 3.658, avg. samples / sec: 53234.06
Iteration:   4240, Loss function: 2.839, Average Loss: 3.673, avg. samples / sec: 53222.12
Iteration:   4240, Loss function: 3.668, Average Loss: 3.653, avg. samples / sec: 52987.16
Iteration:   4240, Loss function: 4.277, Average Loss: 3.675, avg. samples / sec: 53203.78
:::MLL 1558640718.444 epoch_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 819}}
:::MLL 1558640718.445 epoch_start: {"value": null, "metadata": {"epoch_num": 62, "file": "train.py", "lineno": 673}}
Iteration:   4260, Loss function: 3.958, Average Loss: 3.645, avg. samples / sec: 53265.03
Iteration:   4260, Loss function: 3.187, Average Loss: 3.641, avg. samples / sec: 52977.56
Iteration:   4260, Loss function: 4.004, Average Loss: 3.661, avg. samples / sec: 52966.88
Iteration:   4260, Loss function: 3.113, Average Loss: 3.643, avg. samples / sec: 53112.79
Iteration:   4260, Loss function: 2.903, Average Loss: 3.666, avg. samples / sec: 52997.96
Iteration:   4260, Loss function: 2.946, Average Loss: 3.691, avg. samples / sec: 53032.28
Iteration:   4260, Loss function: 3.318, Average Loss: 3.661, avg. samples / sec: 53212.03
Iteration:   4260, Loss function: 3.505, Average Loss: 3.661, avg. samples / sec: 53065.83
Iteration:   4260, Loss function: 4.093, Average Loss: 3.657, avg. samples / sec: 53030.90
Iteration:   4260, Loss function: 2.794, Average Loss: 3.667, avg. samples / sec: 53052.98
Iteration:   4260, Loss function: 3.218, Average Loss: 3.661, avg. samples / sec: 53059.61
Iteration:   4260, Loss function: 3.562, Average Loss: 3.673, avg. samples / sec: 53022.48
Iteration:   4260, Loss function: 2.795, Average Loss: 3.656, avg. samples / sec: 53036.87
Iteration:   4260, Loss function: 2.903, Average Loss: 3.663, avg. samples / sec: 53158.34
Iteration:   4260, Loss function: 3.372, Average Loss: 3.663, avg. samples / sec: 53156.20
Iteration:   4260, Loss function: 2.588, Average Loss: 3.666, avg. samples / sec: 53200.34
Iteration:   4260, Loss function: 3.105, Average Loss: 3.652, avg. samples / sec: 53176.40
Iteration:   4260, Loss function: 3.890, Average Loss: 3.638, avg. samples / sec: 53135.83
Iteration:   4260, Loss function: 3.140, Average Loss: 3.644, avg. samples / sec: 53136.28
Iteration:   4260, Loss function: 3.231, Average Loss: 3.660, avg. samples / sec: 53093.74
Iteration:   4260, Loss function: 2.776, Average Loss: 3.637, avg. samples / sec: 53038.19
Iteration:   4260, Loss function: 4.015, Average Loss: 3.623, avg. samples / sec: 53046.51
Iteration:   4260, Loss function: 3.033, Average Loss: 3.654, avg. samples / sec: 52897.89
Iteration:   4260, Loss function: 3.206, Average Loss: 3.644, avg. samples / sec: 53030.54
Iteration:   4260, Loss function: 2.821, Average Loss: 3.698, avg. samples / sec: 53058.63
Iteration:   4260, Loss function: 2.832, Average Loss: 3.681, avg. samples / sec: 53067.43
Iteration:   4260, Loss function: 4.026, Average Loss: 3.658, avg. samples / sec: 53026.77
Iteration:   4260, Loss function: 3.465, Average Loss: 3.649, avg. samples / sec: 53061.75
Iteration:   4260, Loss function: 5.128, Average Loss: 3.647, avg. samples / sec: 53039.54
Iteration:   4260, Loss function: 4.063, Average Loss: 3.669, avg. samples / sec: 53019.79
Iteration:   4280, Loss function: 4.362, Average Loss: 3.635, avg. samples / sec: 53359.13
Iteration:   4280, Loss function: 3.240, Average Loss: 3.655, avg. samples / sec: 53331.87
Iteration:   4280, Loss function: 3.081, Average Loss: 3.640, avg. samples / sec: 53178.32
Iteration:   4280, Loss function: 3.400, Average Loss: 3.656, avg. samples / sec: 53374.67
Iteration:   4280, Loss function: 2.944, Average Loss: 3.686, avg. samples / sec: 53236.44
Iteration:   4280, Loss function: 2.080, Average Loss: 3.647, avg. samples / sec: 53285.63
Iteration:   4280, Loss function: 3.684, Average Loss: 3.667, avg. samples / sec: 53308.29
Iteration:   4280, Loss function: 4.015, Average Loss: 3.638, avg. samples / sec: 53189.38
Iteration:   4280, Loss function: 2.937, Average Loss: 3.658, avg. samples / sec: 53274.35
Iteration:   4280, Loss function: 2.668, Average Loss: 3.655, avg. samples / sec: 53218.54
Iteration:   4280, Loss function: 2.520, Average Loss: 3.655, avg. samples / sec: 53248.81
Iteration:   4280, Loss function: 3.379, Average Loss: 3.653, avg. samples / sec: 53258.77
Iteration:   4280, Loss function: 3.147, Average Loss: 3.649, avg. samples / sec: 53282.61
Iteration:   4280, Loss function: 2.433, Average Loss: 3.617, avg. samples / sec: 53281.26
Iteration:   4280, Loss function: 3.653, Average Loss: 3.657, avg. samples / sec: 53307.02
Iteration:   4280, Loss function: 3.577, Average Loss: 3.657, avg. samples / sec: 53223.29
Iteration:   4280, Loss function: 3.415, Average Loss: 3.628, avg. samples / sec: 53246.82
Iteration:   4280, Loss function: 3.439, Average Loss: 3.637, avg. samples / sec: 53250.72
Iteration:   4280, Loss function: 2.727, Average Loss: 3.655, avg. samples / sec: 53143.23
Iteration:   4280, Loss function: 4.410, Average Loss: 3.655, avg. samples / sec: 53161.41
Iteration:   4280, Loss function: 4.062, Average Loss: 3.633, avg. samples / sec: 53166.40
Iteration:   4280, Loss function: 2.876, Average Loss: 3.692, avg. samples / sec: 53260.00
Iteration:   4280, Loss function: 3.812, Average Loss: 3.674, avg. samples / sec: 53259.07
Iteration:   4280, Loss function: 3.887, Average Loss: 3.657, avg. samples / sec: 53109.14
Iteration:   4280, Loss function: 2.995, Average Loss: 3.636, avg. samples / sec: 53180.87
Iteration:   4280, Loss function: 2.718, Average Loss: 3.647, avg. samples / sec: 53226.67
Iteration:   4280, Loss function: 3.681, Average Loss: 3.662, avg. samples / sec: 53118.07
Iteration:   4280, Loss function: 3.669, Average Loss: 3.643, avg. samples / sec: 53247.36
Iteration:   4280, Loss function: 3.715, Average Loss: 3.662, avg. samples / sec: 53265.29
Iteration:   4280, Loss function: 3.190, Average Loss: 3.641, avg. samples / sec: 53193.50
Iteration:   4300, Loss function: 4.387, Average Loss: 3.626, avg. samples / sec: 53470.78
Iteration:   4300, Loss function: 2.471, Average Loss: 3.645, avg. samples / sec: 53536.29
Iteration:   4300, Loss function: 2.267, Average Loss: 3.677, avg. samples / sec: 53487.81
Iteration:   4300, Loss function: 3.184, Average Loss: 3.642, avg. samples / sec: 53475.41
Iteration:   4300, Loss function: 3.433, Average Loss: 3.646, avg. samples / sec: 53491.95
Iteration:   4300, Loss function: 3.695, Average Loss: 3.651, avg. samples / sec: 53288.78
Iteration:   4300, Loss function: 2.085, Average Loss: 3.629, avg. samples / sec: 53298.73
Iteration:   4300, Loss function: 3.029, Average Loss: 3.642, avg. samples / sec: 53497.88
Iteration:   4300, Loss function: 2.560, Average Loss: 3.650, avg. samples / sec: 53295.45
Iteration:   4300, Loss function: 2.684, Average Loss: 3.656, avg. samples / sec: 53453.08
Iteration:   4300, Loss function: 3.863, Average Loss: 3.652, avg. samples / sec: 53445.78
Iteration:   4300, Loss function: 5.640, Average Loss: 3.616, avg. samples / sec: 53501.23
Iteration:   4300, Loss function: 3.214, Average Loss: 3.651, avg. samples / sec: 53537.13
Iteration:   4300, Loss function: 4.066, Average Loss: 3.650, avg. samples / sec: 53519.17
Iteration:   4300, Loss function: 1.861, Average Loss: 3.640, avg. samples / sec: 53531.49
Iteration:   4300, Loss function: 3.082, Average Loss: 3.649, avg. samples / sec: 53508.10
Iteration:   4300, Loss function: 2.989, Average Loss: 3.625, avg. samples / sec: 53506.96
Iteration:   4300, Loss function: 2.237, Average Loss: 3.652, avg. samples / sec: 53484.52
Iteration:   4300, Loss function: 3.955, Average Loss: 3.651, avg. samples / sec: 53474.78
Iteration:   4300, Loss function: 3.713, Average Loss: 3.656, avg. samples / sec: 53527.49
Iteration:   4300, Loss function: 2.512, Average Loss: 3.634, avg. samples / sec: 53483.47
Iteration:   4300, Loss function: 3.942, Average Loss: 3.630, avg. samples / sec: 53496.54
Iteration:   4300, Loss function: 3.239, Average Loss: 3.630, avg. samples / sec: 53565.63
Iteration:   4300, Loss function: 2.719, Average Loss: 3.682, avg. samples / sec: 53479.57
Iteration:   4300, Loss function: 3.656, Average Loss: 3.624, avg. samples / sec: 53446.92
Iteration:   4300, Loss function: 2.718, Average Loss: 3.639, avg. samples / sec: 53505.95
Iteration:   4300, Loss function: 3.545, Average Loss: 3.636, avg. samples / sec: 53229.08
Iteration:   4300, Loss function: 3.057, Average Loss: 3.664, avg. samples / sec: 53451.72
Iteration:   4300, Loss function: 4.174, Average Loss: 3.655, avg. samples / sec: 53504.81
Iteration:   4300, Loss function: 4.155, Average Loss: 3.656, avg. samples / sec: 53191.57
Iteration:   4320, Loss function: 3.280, Average Loss: 3.622, avg. samples / sec: 53576.12
Iteration:   4320, Loss function: 3.244, Average Loss: 3.644, avg. samples / sec: 53803.35
Iteration:   4320, Loss function: 3.825, Average Loss: 3.643, avg. samples / sec: 53695.05
Iteration:   4320, Loss function: 3.038, Average Loss: 3.643, avg. samples / sec: 53655.31
Iteration:   4320, Loss function: 4.795, Average Loss: 3.665, avg. samples / sec: 53580.71
Iteration:   4320, Loss function: 3.771, Average Loss: 3.618, avg. samples / sec: 53615.07
Iteration:   4320, Loss function: 4.120, Average Loss: 3.632, avg. samples / sec: 53846.54
Iteration:   4320, Loss function: 2.182, Average Loss: 3.652, avg. samples / sec: 53871.53
Iteration:   4320, Loss function: 3.187, Average Loss: 3.638, avg. samples / sec: 53586.37
Iteration:   4320, Loss function: 3.389, Average Loss: 3.638, avg. samples / sec: 53548.88
Iteration:   4320, Loss function: 2.800, Average Loss: 3.641, avg. samples / sec: 53506.92
Iteration:   4320, Loss function: 3.664, Average Loss: 3.643, avg. samples / sec: 53602.59
Iteration:   4320, Loss function: 3.397, Average Loss: 3.646, avg. samples / sec: 53558.29
Iteration:   4320, Loss function: 3.868, Average Loss: 3.611, avg. samples / sec: 53559.83
Iteration:   4320, Loss function: 4.129, Average Loss: 3.643, avg. samples / sec: 53562.68
Iteration:   4320, Loss function: 3.363, Average Loss: 3.645, avg. samples / sec: 53569.83
Iteration:   4320, Loss function: 2.260, Average Loss: 3.644, avg. samples / sec: 53548.48
Iteration:   4320, Loss function: 3.879, Average Loss: 3.628, avg. samples / sec: 53586.67
Iteration:   4320, Loss function: 3.890, Average Loss: 3.617, avg. samples / sec: 53594.19
Iteration:   4320, Loss function: 4.385, Average Loss: 3.643, avg. samples / sec: 53561.75
Iteration:   4320, Loss function: 3.181, Average Loss: 3.619, avg. samples / sec: 53549.72
Iteration:   4320, Loss function: 4.442, Average Loss: 3.637, avg. samples / sec: 53552.47
Iteration:   4320, Loss function: 3.887, Average Loss: 3.658, avg. samples / sec: 53606.10
Iteration:   4320, Loss function: 4.420, Average Loss: 3.685, avg. samples / sec: 53565.39
Iteration:   4320, Loss function: 2.592, Average Loss: 3.636, avg. samples / sec: 53581.05
Iteration:   4320, Loss function: 3.943, Average Loss: 3.639, avg. samples / sec: 53528.61
Iteration:   4320, Loss function: 4.083, Average Loss: 3.627, avg. samples / sec: 53548.29
Iteration:   4320, Loss function: 3.944, Average Loss: 3.648, avg. samples / sec: 53530.25
Iteration:   4320, Loss function: 3.506, Average Loss: 3.647, avg. samples / sec: 53571.36
Iteration:   4320, Loss function: 3.709, Average Loss: 3.629, avg. samples / sec: 53523.85
:::MLL 1558640720.649 epoch_stop: {"value": null, "metadata": {"epoch_num": 62, "file": "train.py", "lineno": 819}}
:::MLL 1558640720.650 epoch_start: {"value": null, "metadata": {"epoch_num": 63, "file": "train.py", "lineno": 673}}
Iteration:   4340, Loss function: 4.342, Average Loss: 3.641, avg. samples / sec: 53041.58
Iteration:   4340, Loss function: 3.704, Average Loss: 3.640, avg. samples / sec: 53149.28
Iteration:   4340, Loss function: 3.250, Average Loss: 3.623, avg. samples / sec: 52948.73
Iteration:   4340, Loss function: 3.695, Average Loss: 3.629, avg. samples / sec: 53117.31
Iteration:   4340, Loss function: 2.518, Average Loss: 3.636, avg. samples / sec: 53147.18
Iteration:   4340, Loss function: 4.145, Average Loss: 3.612, avg. samples / sec: 53075.86
Iteration:   4340, Loss function: 2.957, Average Loss: 3.644, avg. samples / sec: 53100.24
Iteration:   4340, Loss function: 4.397, Average Loss: 3.636, avg. samples / sec: 53019.23
Iteration:   4340, Loss function: 2.665, Average Loss: 3.658, avg. samples / sec: 53056.44
Iteration:   4340, Loss function: 2.638, Average Loss: 3.638, avg. samples / sec: 53112.63
Iteration:   4340, Loss function: 3.529, Average Loss: 3.629, avg. samples / sec: 53080.84
Iteration:   4340, Loss function: 4.436, Average Loss: 3.644, avg. samples / sec: 53088.60
Iteration:   4340, Loss function: 4.738, Average Loss: 3.631, avg. samples / sec: 53051.38
Iteration:   4340, Loss function: 4.989, Average Loss: 3.641, avg. samples / sec: 53113.27
Iteration:   4340, Loss function: 2.789, Average Loss: 3.631, avg. samples / sec: 53107.92
Iteration:   4340, Loss function: 2.344, Average Loss: 3.612, avg. samples / sec: 53108.22
Iteration:   4340, Loss function: 4.077, Average Loss: 3.606, avg. samples / sec: 53074.06
Iteration:   4340, Loss function: 2.921, Average Loss: 3.622, avg. samples / sec: 53080.24
Iteration:   4340, Loss function: 3.187, Average Loss: 3.632, avg. samples / sec: 53076.38
Iteration:   4340, Loss function: 3.954, Average Loss: 3.678, avg. samples / sec: 53099.94
Iteration:   4340, Loss function: 3.710, Average Loss: 3.638, avg. samples / sec: 53059.01
Iteration:   4340, Loss function: 2.525, Average Loss: 3.629, avg. samples / sec: 53103.16
Iteration:   4340, Loss function: 3.481, Average Loss: 3.637, avg. samples / sec: 53054.24
Iteration:   4340, Loss function: 3.697, Average Loss: 3.623, avg. samples / sec: 53130.99
Iteration:   4340, Loss function: 2.758, Average Loss: 3.652, avg. samples / sec: 53075.80
Iteration:   4340, Loss function: 3.105, Average Loss: 3.624, avg. samples / sec: 53092.88
Iteration:   4340, Loss function: 3.688, Average Loss: 3.630, avg. samples / sec: 53073.22
Iteration:   4340, Loss function: 3.142, Average Loss: 3.612, avg. samples / sec: 53045.11
Iteration:   4340, Loss function: 4.031, Average Loss: 3.643, avg. samples / sec: 53059.41
Iteration:   4340, Loss function: 3.263, Average Loss: 3.639, avg. samples / sec: 52926.62
Iteration:   4360, Loss function: 3.543, Average Loss: 3.634, avg. samples / sec: 53360.65
Iteration:   4360, Loss function: 3.511, Average Loss: 3.635, avg. samples / sec: 53325.45
Iteration:   4360, Loss function: 3.232, Average Loss: 3.615, avg. samples / sec: 53387.47
Iteration:   4360, Loss function: 3.932, Average Loss: 3.621, avg. samples / sec: 53358.16
Iteration:   4360, Loss function: 4.398, Average Loss: 3.635, avg. samples / sec: 53371.78
Iteration:   4360, Loss function: 4.396, Average Loss: 3.611, avg. samples / sec: 53363.33
Iteration:   4360, Loss function: 3.619, Average Loss: 3.654, avg. samples / sec: 53362.20
Iteration:   4360, Loss function: 2.716, Average Loss: 3.639, avg. samples / sec: 53338.94
Iteration:   4360, Loss function: 3.493, Average Loss: 3.621, avg. samples / sec: 53358.91
Iteration:   4360, Loss function: 2.535, Average Loss: 3.639, avg. samples / sec: 53368.93
Iteration:   4360, Loss function: 3.557, Average Loss: 3.630, avg. samples / sec: 53307.58
Iteration:   4360, Loss function: 4.388, Average Loss: 3.626, avg. samples / sec: 53347.03
Iteration:   4360, Loss function: 3.603, Average Loss: 3.609, avg. samples / sec: 53427.04
Iteration:   4360, Loss function: 3.682, Average Loss: 3.618, avg. samples / sec: 53345.98
Iteration:   4360, Loss function: 3.536, Average Loss: 3.631, avg. samples / sec: 53330.03
Iteration:   4360, Loss function: 2.985, Average Loss: 3.672, avg. samples / sec: 53350.47
Iteration:   4360, Loss function: 3.516, Average Loss: 3.620, avg. samples / sec: 53363.25
Iteration:   4360, Loss function: 3.721, Average Loss: 3.603, avg. samples / sec: 53311.43
Iteration:   4360, Loss function: 2.539, Average Loss: 3.644, avg. samples / sec: 53355.13
Iteration:   4360, Loss function: 4.398, Average Loss: 3.635, avg. samples / sec: 53283.17
Iteration:   4360, Loss function: 3.254, Average Loss: 3.605, avg. samples / sec: 53300.42
Iteration:   4360, Loss function: 3.185, Average Loss: 3.624, avg. samples / sec: 53316.48
Iteration:   4360, Loss function: 2.863, Average Loss: 3.635, avg. samples / sec: 53306.37
Iteration:   4360, Loss function: 2.706, Average Loss: 3.632, avg. samples / sec: 53312.14
Iteration:   4360, Loss function: 2.956, Average Loss: 3.628, avg. samples / sec: 53297.90
Iteration:   4360, Loss function: 2.564, Average Loss: 3.619, avg. samples / sec: 53328.78
Iteration:   4360, Loss function: 2.308, Average Loss: 3.636, avg. samples / sec: 53352.69
Iteration:   4360, Loss function: 3.435, Average Loss: 3.636, avg. samples / sec: 53509.62
Iteration:   4360, Loss function: 3.604, Average Loss: 3.628, avg. samples / sec: 53041.38
Iteration:   4360, Loss function: 3.021, Average Loss: 3.620, avg. samples / sec: 53296.80
Iteration:   4380, Loss function: 2.687, Average Loss: 3.607, avg. samples / sec: 53743.39
Iteration:   4380, Loss function: 2.704, Average Loss: 3.623, avg. samples / sec: 53675.58
Iteration:   4380, Loss function: 2.190, Average Loss: 3.623, avg. samples / sec: 53679.10
Iteration:   4380, Loss function: 4.213, Average Loss: 3.629, avg. samples / sec: 53668.71
Iteration:   4380, Loss function: 2.785, Average Loss: 3.614, avg. samples / sec: 53634.21
Iteration:   4380, Loss function: 4.436, Average Loss: 3.604, avg. samples / sec: 53662.42
Iteration:   4380, Loss function: 3.491, Average Loss: 3.644, avg. samples / sec: 53671.22
Iteration:   4380, Loss function: 3.579, Average Loss: 3.623, avg. samples / sec: 53971.26
Iteration:   4380, Loss function: 3.249, Average Loss: 3.623, avg. samples / sec: 53723.93
Iteration:   4380, Loss function: 5.210, Average Loss: 3.620, avg. samples / sec: 53688.71
Iteration:   4380, Loss function: 4.821, Average Loss: 3.632, avg. samples / sec: 53659.02
Iteration:   4380, Loss function: 3.525, Average Loss: 3.624, avg. samples / sec: 53707.39
Iteration:   4380, Loss function: 2.449, Average Loss: 3.632, avg. samples / sec: 53656.53
Iteration:   4380, Loss function: 3.959, Average Loss: 3.596, avg. samples / sec: 53729.85
Iteration:   4380, Loss function: 3.522, Average Loss: 3.613, avg. samples / sec: 53705.63
Iteration:   4380, Loss function: 3.006, Average Loss: 3.594, avg. samples / sec: 53722.82
Iteration:   4380, Loss function: 2.423, Average Loss: 3.623, avg. samples / sec: 53687.64
Iteration:   4380, Loss function: 3.258, Average Loss: 3.602, avg. samples / sec: 53656.80
Iteration:   4380, Loss function: 3.084, Average Loss: 3.630, avg. samples / sec: 53714.18
Iteration:   4380, Loss function: 3.518, Average Loss: 3.633, avg. samples / sec: 53730.28
Iteration:   4380, Loss function: 3.252, Average Loss: 3.664, avg. samples / sec: 53675.25
Iteration:   4380, Loss function: 3.175, Average Loss: 3.612, avg. samples / sec: 53676.44
Iteration:   4380, Loss function: 3.030, Average Loss: 3.618, avg. samples / sec: 53736.96
Iteration:   4380, Loss function: 3.405, Average Loss: 3.621, avg. samples / sec: 53706.49
Iteration:   4380, Loss function: 3.400, Average Loss: 3.629, avg. samples / sec: 53711.52
Iteration:   4380, Loss function: 3.995, Average Loss: 3.628, avg. samples / sec: 53717.13
Iteration:   4380, Loss function: 3.350, Average Loss: 3.628, avg. samples / sec: 53709.25
Iteration:   4380, Loss function: 3.477, Average Loss: 3.616, avg. samples / sec: 53711.77
Iteration:   4380, Loss function: 4.231, Average Loss: 3.612, avg. samples / sec: 53708.90
Iteration:   4380, Loss function: 3.174, Average Loss: 3.639, avg. samples / sec: 53652.65
:::MLL 1558640722.853 epoch_stop: {"value": null, "metadata": {"epoch_num": 63, "file": "train.py", "lineno": 819}}
:::MLL 1558640722.854 epoch_start: {"value": null, "metadata": {"epoch_num": 64, "file": "train.py", "lineno": 673}}
Iteration:   4400, Loss function: 4.605, Average Loss: 3.600, avg. samples / sec: 53055.10
Iteration:   4400, Loss function: 2.840, Average Loss: 3.616, avg. samples / sec: 53085.10
Iteration:   4400, Loss function: 2.543, Average Loss: 3.617, avg. samples / sec: 52985.70
Iteration:   4400, Loss function: 2.726, Average Loss: 3.605, avg. samples / sec: 53124.80
Iteration:   4400, Loss function: 2.680, Average Loss: 3.643, avg. samples / sec: 53059.33
Iteration:   4400, Loss function: 2.613, Average Loss: 3.598, avg. samples / sec: 53048.61
Iteration:   4400, Loss function: 4.129, Average Loss: 3.631, avg. samples / sec: 53091.66
Iteration:   4400, Loss function: 3.048, Average Loss: 3.615, avg. samples / sec: 53048.59
Iteration:   4400, Loss function: 3.947, Average Loss: 3.621, avg. samples / sec: 53034.13
Iteration:   4400, Loss function: 3.771, Average Loss: 3.629, avg. samples / sec: 53006.61
Iteration:   4400, Loss function: 3.432, Average Loss: 3.615, avg. samples / sec: 53023.42
Iteration:   4400, Loss function: 1.976, Average Loss: 3.618, avg. samples / sec: 52993.53
Iteration:   4400, Loss function: 2.933, Average Loss: 3.625, avg. samples / sec: 52980.40
Iteration:   4400, Loss function: 3.504, Average Loss: 3.588, avg. samples / sec: 53139.98
Iteration:   4400, Loss function: 4.294, Average Loss: 3.624, avg. samples / sec: 53179.04
Iteration:   4400, Loss function: 4.119, Average Loss: 3.611, avg. samples / sec: 53178.14
Iteration:   4400, Loss function: 4.521, Average Loss: 3.627, avg. samples / sec: 53137.52
Iteration:   4400, Loss function: 3.679, Average Loss: 3.633, avg. samples / sec: 53131.41
Iteration:   4400, Loss function: 3.029, Average Loss: 3.603, avg. samples / sec: 53123.20
Iteration:   4400, Loss function: 4.926, Average Loss: 3.623, avg. samples / sec: 53126.50
Iteration:   4400, Loss function: 3.868, Average Loss: 3.660, avg. samples / sec: 53082.36
Iteration:   4400, Loss function: 3.861, Average Loss: 3.599, avg. samples / sec: 53055.72
Iteration:   4400, Loss function: 3.191, Average Loss: 3.603, avg. samples / sec: 53029.66
Iteration:   4400, Loss function: 2.531, Average Loss: 3.590, avg. samples / sec: 53014.84
Iteration:   4400, Loss function: 3.723, Average Loss: 3.619, avg. samples / sec: 53027.79
Iteration:   4400, Loss function: 3.202, Average Loss: 3.609, avg. samples / sec: 53057.72
Iteration:   4400, Loss function: 3.589, Average Loss: 3.613, avg. samples / sec: 53039.12
Iteration:   4400, Loss function: 2.689, Average Loss: 3.637, avg. samples / sec: 53073.40
Iteration:   4400, Loss function: 3.301, Average Loss: 3.610, avg. samples / sec: 53028.13
Iteration:   4400, Loss function: 4.317, Average Loss: 3.622, avg. samples / sec: 53029.19
Iteration:   4420, Loss function: 3.431, Average Loss: 3.601, avg. samples / sec: 53495.63
Iteration:   4420, Loss function: 4.193, Average Loss: 3.618, avg. samples / sec: 53566.08
Iteration:   4420, Loss function: 3.585, Average Loss: 3.611, avg. samples / sec: 53391.25
Iteration:   4420, Loss function: 3.291, Average Loss: 3.632, avg. samples / sec: 53496.18
Iteration:   4420, Loss function: 3.031, Average Loss: 3.611, avg. samples / sec: 53528.40
Iteration:   4420, Loss function: 3.297, Average Loss: 3.611, avg. samples / sec: 53531.19
Iteration:   4420, Loss function: 3.291, Average Loss: 3.622, avg. samples / sec: 53495.77
Iteration:   4420, Loss function: 3.001, Average Loss: 3.602, avg. samples / sec: 53388.04
Iteration:   4420, Loss function: 3.115, Average Loss: 3.615, avg. samples / sec: 53485.11
Iteration:   4420, Loss function: 3.063, Average Loss: 3.628, avg. samples / sec: 53452.51
Iteration:   4420, Loss function: 2.505, Average Loss: 3.598, avg. samples / sec: 53435.18
Iteration:   4420, Loss function: 2.745, Average Loss: 3.613, avg. samples / sec: 53538.33
Iteration:   4420, Loss function: 3.163, Average Loss: 3.609, avg. samples / sec: 53417.16
Iteration:   4420, Loss function: 2.465, Average Loss: 3.585, avg. samples / sec: 53526.25
Iteration:   4420, Loss function: 3.342, Average Loss: 3.594, avg. samples / sec: 53508.22
Iteration:   4420, Loss function: 2.993, Average Loss: 3.619, avg. samples / sec: 53415.72
Iteration:   4420, Loss function: 3.558, Average Loss: 3.582, avg. samples / sec: 53393.44
Iteration:   4420, Loss function: 3.401, Average Loss: 3.594, avg. samples / sec: 53479.43
Iteration:   4420, Loss function: 2.753, Average Loss: 3.653, avg. samples / sec: 53458.11
Iteration:   4420, Loss function: 2.116, Average Loss: 3.614, avg. samples / sec: 53372.53
Iteration:   4420, Loss function: 5.838, Average Loss: 3.611, avg. samples / sec: 53496.03
Iteration:   4420, Loss function: 2.869, Average Loss: 3.601, avg. samples / sec: 53412.56
Iteration:   4420, Loss function: 3.068, Average Loss: 3.619, avg. samples / sec: 53520.92
Iteration:   4420, Loss function: 3.906, Average Loss: 3.617, avg. samples / sec: 53473.62
Iteration:   4420, Loss function: 3.924, Average Loss: 3.631, avg. samples / sec: 53391.23
Iteration:   4420, Loss function: 2.529, Average Loss: 3.607, avg. samples / sec: 53360.67
Iteration:   4420, Loss function: 3.211, Average Loss: 3.615, avg. samples / sec: 53413.03
Iteration:   4420, Loss function: 2.657, Average Loss: 3.610, avg. samples / sec: 53470.66
Iteration:   4420, Loss function: 3.864, Average Loss: 3.634, avg. samples / sec: 53476.73
Iteration:   4420, Loss function: 4.216, Average Loss: 3.610, avg. samples / sec: 53464.80
Iteration:   4440, Loss function: 3.325, Average Loss: 3.594, avg. samples / sec: 53363.19
Iteration:   4440, Loss function: 3.649, Average Loss: 3.607, avg. samples / sec: 53458.29
Iteration:   4440, Loss function: 3.004, Average Loss: 3.614, avg. samples / sec: 53436.99
Iteration:   4440, Loss function: 2.778, Average Loss: 3.623, avg. samples / sec: 53382.15
Iteration:   4440, Loss function: 3.139, Average Loss: 3.613, avg. samples / sec: 53391.01
Iteration:   4440, Loss function: 3.290, Average Loss: 3.623, avg. samples / sec: 53409.83
Iteration:   4440, Loss function: 3.633, Average Loss: 3.605, avg. samples / sec: 53282.55
Iteration:   4440, Loss function: 2.813, Average Loss: 3.603, avg. samples / sec: 53343.94
Iteration:   4440, Loss function: 3.485, Average Loss: 3.599, avg. samples / sec: 53443.43
Iteration:   4440, Loss function: 3.786, Average Loss: 3.616, avg. samples / sec: 53174.53
Iteration:   4440, Loss function: 3.495, Average Loss: 3.596, avg. samples / sec: 53362.83
Iteration:   4440, Loss function: 3.515, Average Loss: 3.579, avg. samples / sec: 53421.35
Iteration:   4440, Loss function: 3.987, Average Loss: 3.616, avg. samples / sec: 53407.78
Iteration:   4440, Loss function: 3.758, Average Loss: 3.610, avg. samples / sec: 53451.74
Iteration:   4440, Loss function: 2.921, Average Loss: 3.609, avg. samples / sec: 53424.35
Iteration:   4440, Loss function: 4.186, Average Loss: 3.584, avg. samples / sec: 53377.80
Iteration:   4440, Loss function: 3.064, Average Loss: 3.609, avg. samples / sec: 53427.02
Iteration:   4440, Loss function: 2.649, Average Loss: 3.605, avg. samples / sec: 53409.26
Iteration:   4440, Loss function: 3.677, Average Loss: 3.645, avg. samples / sec: 53398.68
Iteration:   4440, Loss function: 3.879, Average Loss: 3.624, avg. samples / sec: 53413.49
Iteration:   4440, Loss function: 2.713, Average Loss: 3.611, avg. samples / sec: 53188.80
Iteration:   4440, Loss function: 3.330, Average Loss: 3.607, avg. samples / sec: 53406.67
Iteration:   4440, Loss function: 3.323, Average Loss: 3.588, avg. samples / sec: 53340.45
Iteration:   4440, Loss function: 3.636, Average Loss: 3.602, avg. samples / sec: 53390.65
Iteration:   4440, Loss function: 3.322, Average Loss: 3.585, avg. samples / sec: 53351.94
Iteration:   4440, Loss function: 3.025, Average Loss: 3.596, avg. samples / sec: 53141.87
Iteration:   4440, Loss function: 3.650, Average Loss: 3.592, avg. samples / sec: 53361.84
Iteration:   4440, Loss function: 3.692, Average Loss: 3.627, avg. samples / sec: 53370.33
Iteration:   4440, Loss function: 3.567, Average Loss: 3.605, avg. samples / sec: 53397.75
Iteration:   4440, Loss function: 5.978, Average Loss: 3.616, avg. samples / sec: 53336.31
Iteration:   4460, Loss function: 4.475, Average Loss: 3.588, avg. samples / sec: 53501.98
Iteration:   4460, Loss function: 2.621, Average Loss: 3.590, avg. samples / sec: 53709.74
Iteration:   4460, Loss function: 2.587, Average Loss: 3.614, avg. samples / sec: 53682.74
Iteration:   4460, Loss function: 3.779, Average Loss: 3.593, avg. samples / sec: 53792.79
Iteration:   4460, Loss function: 2.174, Average Loss: 3.590, avg. samples / sec: 53572.97
Iteration:   4460, Loss function: 3.488, Average Loss: 3.617, avg. samples / sec: 53489.11
Iteration:   4460, Loss function: 3.141, Average Loss: 3.615, avg. samples / sec: 53504.77
Iteration:   4460, Loss function: 3.655, Average Loss: 3.602, avg. samples / sec: 53422.12
Iteration:   4460, Loss function: 2.906, Average Loss: 3.606, avg. samples / sec: 53486.29
Iteration:   4460, Loss function: 4.200, Average Loss: 3.607, avg. samples / sec: 53716.60
Iteration:   4460, Loss function: 3.853, Average Loss: 3.610, avg. samples / sec: 53437.35
Iteration:   4460, Loss function: 4.367, Average Loss: 3.600, avg. samples / sec: 53497.33
Iteration:   4460, Loss function: 3.202, Average Loss: 3.595, avg. samples / sec: 53458.57
Iteration:   4460, Loss function: 3.542, Average Loss: 3.608, avg. samples / sec: 53529.13
Iteration:   4460, Loss function: 2.433, Average Loss: 3.579, avg. samples / sec: 53548.40
Iteration:   4460, Loss function: 2.873, Average Loss: 3.573, avg. samples / sec: 53468.49
Iteration:   4460, Loss function: 2.106, Average Loss: 3.582, avg. samples / sec: 53532.73
Iteration:   4460, Loss function: 4.446, Average Loss: 3.613, avg. samples / sec: 53443.29
Iteration:   4460, Loss function: 3.120, Average Loss: 3.600, avg. samples / sec: 53465.83
Iteration:   4460, Loss function: 2.761, Average Loss: 3.618, avg. samples / sec: 53492.97
Iteration:   4460, Loss function: 3.977, Average Loss: 3.580, avg. samples / sec: 53464.92
Iteration:   4460, Loss function: 2.879, Average Loss: 3.616, avg. samples / sec: 53545.22
Iteration:   4460, Loss function: 3.963, Average Loss: 3.643, avg. samples / sec: 53483.95
Iteration:   4460, Loss function: 3.860, Average Loss: 3.599, avg. samples / sec: 53510.23
Iteration:   4460, Loss function: 3.147, Average Loss: 3.598, avg. samples / sec: 53462.91
Iteration:   4460, Loss function: 2.731, Average Loss: 3.604, avg. samples / sec: 53490.57
Iteration:   4460, Loss function: 3.597, Average Loss: 3.589, avg. samples / sec: 53503.83
Iteration:   4460, Loss function: 2.910, Average Loss: 3.607, avg. samples / sec: 53421.10
Iteration:   4460, Loss function: 2.958, Average Loss: 3.606, avg. samples / sec: 53506.66
Iteration:   4460, Loss function: 3.482, Average Loss: 3.599, avg. samples / sec: 53492.22
:::MLL 1558640725.058 epoch_stop: {"value": null, "metadata": {"epoch_num": 64, "file": "train.py", "lineno": 819}}
:::MLL 1558640725.059 epoch_start: {"value": null, "metadata": {"epoch_num": 65, "file": "train.py", "lineno": 673}}
Iteration:   4480, Loss function: 3.750, Average Loss: 3.583, avg. samples / sec: 53171.40
Iteration:   4480, Loss function: 3.332, Average Loss: 3.586, avg. samples / sec: 53139.38
Iteration:   4480, Loss function: 3.624, Average Loss: 3.610, avg. samples / sec: 53153.37
Iteration:   4480, Loss function: 3.720, Average Loss: 3.595, avg. samples / sec: 53213.60
Iteration:   4480, Loss function: 3.531, Average Loss: 3.590, avg. samples / sec: 53145.53
Iteration:   4480, Loss function: 4.215, Average Loss: 3.613, avg. samples / sec: 53170.26
Iteration:   4480, Loss function: 3.947, Average Loss: 3.593, avg. samples / sec: 53220.29
Iteration:   4480, Loss function: 2.831, Average Loss: 3.603, avg. samples / sec: 53191.69
Iteration:   4480, Loss function: 3.818, Average Loss: 3.611, avg. samples / sec: 53148.92
Iteration:   4480, Loss function: 3.183, Average Loss: 3.586, avg. samples / sec: 53129.02
Iteration:   4480, Loss function: 3.714, Average Loss: 3.597, avg. samples / sec: 53166.67
Iteration:   4480, Loss function: 2.998, Average Loss: 3.592, avg. samples / sec: 53142.37
Iteration:   4480, Loss function: 3.659, Average Loss: 3.607, avg. samples / sec: 53102.52
Iteration:   4480, Loss function: 4.347, Average Loss: 3.570, avg. samples / sec: 53201.33
Iteration:   4480, Loss function: 2.523, Average Loss: 3.571, avg. samples / sec: 53187.05
Iteration:   4480, Loss function: 3.007, Average Loss: 3.568, avg. samples / sec: 53212.72
Iteration:   4480, Loss function: 3.124, Average Loss: 3.613, avg. samples / sec: 53202.51
Iteration:   4480, Loss function: 2.615, Average Loss: 3.597, avg. samples / sec: 53144.43
Iteration:   4480, Loss function: 3.005, Average Loss: 3.605, avg. samples / sec: 53221.14
Iteration:   4480, Loss function: 2.790, Average Loss: 3.613, avg. samples / sec: 53171.78
Iteration:   4480, Loss function: 3.211, Average Loss: 3.574, avg. samples / sec: 53142.51
Iteration:   4480, Loss function: 3.758, Average Loss: 3.636, avg. samples / sec: 53168.65
Iteration:   4480, Loss function: 3.267, Average Loss: 3.589, avg. samples / sec: 53182.07
Iteration:   4480, Loss function: 2.705, Average Loss: 3.579, avg. samples / sec: 53183.22
Iteration:   4480, Loss function: 2.815, Average Loss: 3.593, avg. samples / sec: 53193.19
Iteration:   4480, Loss function: 2.985, Average Loss: 3.594, avg. samples / sec: 53147.60
Iteration:   4480, Loss function: 3.107, Average Loss: 3.594, avg. samples / sec: 53135.93
Iteration:   4480, Loss function: 2.854, Average Loss: 3.610, avg. samples / sec: 53121.35
Iteration:   4480, Loss function: 2.883, Average Loss: 3.600, avg. samples / sec: 53144.21
Iteration:   4480, Loss function: 2.595, Average Loss: 3.601, avg. samples / sec: 53171.02
Iteration:   4500, Loss function: 3.794, Average Loss: 3.577, avg. samples / sec: 53639.30
Iteration:   4500, Loss function: 3.017, Average Loss: 3.586, avg. samples / sec: 53637.85
Iteration:   4500, Loss function: 4.126, Average Loss: 3.604, avg. samples / sec: 53631.46
Iteration:   4500, Loss function: 3.116, Average Loss: 3.611, avg. samples / sec: 53639.58
Iteration:   4500, Loss function: 3.586, Average Loss: 3.580, avg. samples / sec: 53666.99
Iteration:   4500, Loss function: 3.388, Average Loss: 3.584, avg. samples / sec: 53628.85
Iteration:   4500, Loss function: 4.449, Average Loss: 3.590, avg. samples / sec: 53600.92
Iteration:   4500, Loss function: 4.321, Average Loss: 3.593, avg. samples / sec: 53621.83
Iteration:   4500, Loss function: 2.785, Average Loss: 3.603, avg. samples / sec: 53615.60
Iteration:   4500, Loss function: 3.057, Average Loss: 3.597, avg. samples / sec: 53559.00
Iteration:   4500, Loss function: 3.474, Average Loss: 3.590, avg. samples / sec: 53585.33
Iteration:   4500, Loss function: 2.526, Average Loss: 3.605, avg. samples / sec: 53593.16
Iteration:   4500, Loss function: 3.478, Average Loss: 3.558, avg. samples / sec: 53608.57
Iteration:   4500, Loss function: 4.798, Average Loss: 3.569, avg. samples / sec: 53608.49
Iteration:   4500, Loss function: 2.730, Average Loss: 3.565, avg. samples / sec: 53576.63
Iteration:   4500, Loss function: 3.623, Average Loss: 3.596, avg. samples / sec: 53598.62
Iteration:   4500, Loss function: 4.179, Average Loss: 3.589, avg. samples / sec: 53652.18
Iteration:   4500, Loss function: 2.909, Average Loss: 3.633, avg. samples / sec: 53626.78
Iteration:   4500, Loss function: 2.558, Average Loss: 3.587, avg. samples / sec: 53638.13
Iteration:   4500, Loss function: 2.626, Average Loss: 3.605, avg. samples / sec: 53605.53
Iteration:   4500, Loss function: 3.233, Average Loss: 3.576, avg. samples / sec: 53616.91
Iteration:   4500, Loss function: 2.721, Average Loss: 3.607, avg. samples / sec: 53562.60
Iteration:   4500, Loss function: 3.486, Average Loss: 3.591, avg. samples / sec: 53630.36
Iteration:   4500, Loss function: 3.248, Average Loss: 3.597, avg. samples / sec: 53583.31
Iteration:   4500, Loss function: 2.605, Average Loss: 3.588, avg. samples / sec: 53597.68
Iteration:   4500, Loss function: 3.127, Average Loss: 3.601, avg. samples / sec: 53641.11
Iteration:   4500, Loss function: 3.283, Average Loss: 3.573, avg. samples / sec: 53585.80
Iteration:   4500, Loss function: 3.115, Average Loss: 3.589, avg. samples / sec: 53366.65
Iteration:   4500, Loss function: 4.265, Average Loss: 3.606, avg. samples / sec: 53616.71
Iteration:   4500, Loss function: 3.263, Average Loss: 3.600, avg. samples / sec: 53568.47
Iteration:   4520, Loss function: 2.250, Average Loss: 3.598, avg. samples / sec: 53615.22
Iteration:   4520, Loss function: 3.402, Average Loss: 3.583, avg. samples / sec: 53564.21
Iteration:   4520, Loss function: 2.567, Average Loss: 3.579, avg. samples / sec: 53635.36
Iteration:   4520, Loss function: 3.984, Average Loss: 3.586, avg. samples / sec: 53640.28
Iteration:   4520, Loss function: 3.800, Average Loss: 3.608, avg. samples / sec: 53597.84
Iteration:   4520, Loss function: 3.436, Average Loss: 3.591, avg. samples / sec: 53685.64
Iteration:   4520, Loss function: 2.823, Average Loss: 3.568, avg. samples / sec: 53588.88
Iteration:   4520, Loss function: 3.143, Average Loss: 3.582, avg. samples / sec: 53664.38
Iteration:   4520, Loss function: 2.945, Average Loss: 3.585, avg. samples / sec: 53607.08
Iteration:   4520, Loss function: 3.485, Average Loss: 3.582, avg. samples / sec: 53885.10
Iteration:   4520, Loss function: 2.603, Average Loss: 3.597, avg. samples / sec: 53694.11
Iteration:   4520, Loss function: 4.130, Average Loss: 3.572, avg. samples / sec: 53328.60
Iteration:   4520, Loss function: 4.487, Average Loss: 3.596, avg. samples / sec: 53586.17
Iteration:   4520, Loss function: 3.668, Average Loss: 3.559, avg. samples / sec: 53641.11
Iteration:   4520, Loss function: 3.095, Average Loss: 3.583, avg. samples / sec: 53673.19
Iteration:   4520, Loss function: 2.736, Average Loss: 3.603, avg. samples / sec: 53694.93
Iteration:   4520, Loss function: 3.259, Average Loss: 3.588, avg. samples / sec: 53633.42
Iteration:   4520, Loss function: 3.868, Average Loss: 3.555, avg. samples / sec: 53607.34
Iteration:   4520, Loss function: 3.206, Average Loss: 3.565, avg. samples / sec: 53604.73
Iteration:   4520, Loss function: 3.191, Average Loss: 3.582, avg. samples / sec: 53639.42
Iteration:   4520, Loss function: 4.011, Average Loss: 3.600, avg. samples / sec: 53644.67
Iteration:   4520, Loss function: 3.721, Average Loss: 3.570, avg. samples / sec: 53661.78
Iteration:   4520, Loss function: 3.413, Average Loss: 3.585, avg. samples / sec: 53635.91
Iteration:   4520, Loss function: 3.313, Average Loss: 3.568, avg. samples / sec: 53633.07
Iteration:   4520, Loss function: 2.970, Average Loss: 3.604, avg. samples / sec: 53617.17
Iteration:   4520, Loss function: 3.887, Average Loss: 3.632, avg. samples / sec: 53603.29
Iteration:   4520, Loss function: 3.303, Average Loss: 3.589, avg. samples / sec: 53613.83
Iteration:   4520, Loss function: 2.539, Average Loss: 3.580, avg. samples / sec: 53576.75
Iteration:   4520, Loss function: 3.561, Average Loss: 3.594, avg. samples / sec: 53609.91
Iteration:   4520, Loss function: 3.549, Average Loss: 3.596, avg. samples / sec: 53670.84
:::MLL 1558640727.255 epoch_stop: {"value": null, "metadata": {"epoch_num": 65, "file": "train.py", "lineno": 819}}
:::MLL 1558640727.256 epoch_start: {"value": null, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 673}}
Iteration:   4540, Loss function: 3.469, Average Loss: 3.580, avg. samples / sec: 53374.61
Iteration:   4540, Loss function: 3.459, Average Loss: 3.592, avg. samples / sec: 53326.56
Iteration:   4540, Loss function: 2.195, Average Loss: 3.578, avg. samples / sec: 53346.69
Iteration:   4540, Loss function: 3.742, Average Loss: 3.603, avg. samples / sec: 53331.45
Iteration:   4540, Loss function: 3.575, Average Loss: 3.576, avg. samples / sec: 53279.02
Iteration:   4540, Loss function: 2.855, Average Loss: 3.589, avg. samples / sec: 53350.38
Iteration:   4540, Loss function: 3.052, Average Loss: 3.579, avg. samples / sec: 53296.49
Iteration:   4540, Loss function: 3.609, Average Loss: 3.587, avg. samples / sec: 53275.90
Iteration:   4540, Loss function: 4.378, Average Loss: 3.578, avg. samples / sec: 53289.14
Iteration:   4540, Loss function: 4.700, Average Loss: 3.564, avg. samples / sec: 53266.10
Iteration:   4540, Loss function: 2.894, Average Loss: 3.575, avg. samples / sec: 53269.16
Iteration:   4540, Loss function: 2.638, Average Loss: 3.593, avg. samples / sec: 53277.29
Iteration:   4540, Loss function: 4.320, Average Loss: 3.596, avg. samples / sec: 53417.14
Iteration:   4540, Loss function: 3.143, Average Loss: 3.592, avg. samples / sec: 53388.93
Iteration:   4540, Loss function: 2.844, Average Loss: 3.577, avg. samples / sec: 53417.38
Iteration:   4540, Loss function: 3.752, Average Loss: 3.566, avg. samples / sec: 53411.37
Iteration:   4540, Loss function: 2.518, Average Loss: 3.552, avg. samples / sec: 53358.38
Iteration:   4540, Loss function: 3.259, Average Loss: 3.579, avg. samples / sec: 53376.96
Iteration:   4540, Loss function: 2.885, Average Loss: 3.585, avg. samples / sec: 53383.14
Iteration:   4540, Loss function: 4.208, Average Loss: 3.562, avg. samples / sec: 53340.01
Iteration:   4540, Loss function: 3.035, Average Loss: 3.554, avg. samples / sec: 53322.47
Iteration:   4540, Loss function: 3.362, Average Loss: 3.564, avg. samples / sec: 53316.17
Iteration:   4540, Loss function: 4.672, Average Loss: 3.583, avg. samples / sec: 53305.34
Iteration:   4540, Loss function: 3.938, Average Loss: 3.627, avg. samples / sec: 53336.23
Iteration:   4540, Loss function: 3.348, Average Loss: 3.572, avg. samples / sec: 53330.32
Iteration:   4540, Loss function: 4.185, Average Loss: 3.602, avg. samples / sec: 53305.08
Iteration:   4540, Loss function: 3.758, Average Loss: 3.589, avg. samples / sec: 53334.94
Iteration:   4540, Loss function: 3.447, Average Loss: 3.572, avg. samples / sec: 53257.44
Iteration:   4540, Loss function: 3.226, Average Loss: 3.590, avg. samples / sec: 53299.36
Iteration:   4540, Loss function: 3.542, Average Loss: 3.568, avg. samples / sec: 53074.86
Iteration:   4560, Loss function: 3.425, Average Loss: 3.575, avg. samples / sec: 53594.38
Iteration:   4560, Loss function: 4.404, Average Loss: 3.591, avg. samples / sec: 53601.33
Iteration:   4560, Loss function: 3.196, Average Loss: 3.578, avg. samples / sec: 53607.45
Iteration:   4560, Loss function: 3.738, Average Loss: 3.570, avg. samples / sec: 53637.99
Iteration:   4560, Loss function: 2.754, Average Loss: 3.572, avg. samples / sec: 53679.38
Iteration:   4560, Loss function: 3.027, Average Loss: 3.599, avg. samples / sec: 53601.49
Iteration:   4560, Loss function: 3.195, Average Loss: 3.583, avg. samples / sec: 53702.58
Iteration:   4560, Loss function: 2.693, Average Loss: 3.558, avg. samples / sec: 53674.72
Iteration:   4560, Loss function: 3.112, Average Loss: 3.582, avg. samples / sec: 53643.73
Iteration:   4560, Loss function: 3.814, Average Loss: 3.565, avg. samples / sec: 53666.05
Iteration:   4560, Loss function: 1.549, Average Loss: 3.572, avg. samples / sec: 53628.95
Iteration:   4560, Loss function: 2.549, Average Loss: 3.584, avg. samples / sec: 53577.14
Iteration:   4560, Loss function: 2.874, Average Loss: 3.551, avg. samples / sec: 53654.45
Iteration:   4560, Loss function: 2.119, Average Loss: 3.555, avg. samples / sec: 53620.70
Iteration:   4560, Loss function: 6.010, Average Loss: 3.544, avg. samples / sec: 53565.55
Iteration:   4560, Loss function: 2.440, Average Loss: 3.620, avg. samples / sec: 53637.85
Iteration:   4560, Loss function: 2.284, Average Loss: 3.593, avg. samples / sec: 53526.15
Iteration:   4560, Loss function: 3.229, Average Loss: 3.580, avg. samples / sec: 53624.32
Iteration:   4560, Loss function: 3.145, Average Loss: 3.584, avg. samples / sec: 53589.32
Iteration:   4560, Loss function: 2.781, Average Loss: 3.562, avg. samples / sec: 53618.68
Iteration:   4560, Loss function: 2.795, Average Loss: 3.569, avg. samples / sec: 53529.13
Iteration:   4560, Loss function: 5.256, Average Loss: 3.574, avg. samples / sec: 53659.52
Iteration:   4560, Loss function: 3.902, Average Loss: 3.589, avg. samples / sec: 53677.46
Iteration:   4560, Loss function: 4.116, Average Loss: 3.596, avg. samples / sec: 53637.93
Iteration:   4560, Loss function: 2.854, Average Loss: 3.566, avg. samples / sec: 53521.51
Iteration:   4560, Loss function: 3.674, Average Loss: 3.572, avg. samples / sec: 53538.18
Iteration:   4560, Loss function: 2.388, Average Loss: 3.580, avg. samples / sec: 53632.58
Iteration:   4560, Loss function: 3.893, Average Loss: 3.566, avg. samples / sec: 53682.82
Iteration:   4560, Loss function: 4.228, Average Loss: 3.591, avg. samples / sec: 53514.87
Iteration:   4560, Loss function: 3.656, Average Loss: 3.565, avg. samples / sec: 53611.06
:::MLL 1558640728.295 eval_start: {"value": null, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.71 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.60s)
DONE (t=0.64s)
DONE (t=2.55s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22939
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39152
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23243
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05829
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24098
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22060
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32241
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33826
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53183
Current AP: 0.22939 AP goal: 0.23000
:::MLL 1558640732.170 eval_accuracy: {"value": 0.22939434085492735, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 389}}
:::MLL 1558640732.257 eval_stop: {"value": null, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 392}}
:::MLL 1558640732.263 block_stop: {"value": null, "metadata": {"first_epoch_num": 61, "file": "train.py", "lineno": 804}}
:::MLL 1558640732.264 block_start: {"value": null, "metadata": {"first_epoch_num": 66, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   4580, Loss function: 2.841, Average Loss: 3.575, avg. samples / sec: 7289.72
Iteration:   4580, Loss function: 2.374, Average Loss: 3.574, avg. samples / sec: 7285.88
Iteration:   4580, Loss function: 5.074, Average Loss: 3.576, avg. samples / sec: 7281.99
Iteration:   4580, Loss function: 3.854, Average Loss: 3.570, avg. samples / sec: 7280.56
Iteration:   4580, Loss function: 3.730, Average Loss: 3.565, avg. samples / sec: 7281.75
Iteration:   4580, Loss function: 3.317, Average Loss: 3.591, avg. samples / sec: 7280.97
Iteration:   4580, Loss function: 3.134, Average Loss: 3.564, avg. samples / sec: 7280.74
Iteration:   4580, Loss function: 3.450, Average Loss: 3.561, avg. samples / sec: 7285.05
Iteration:   4580, Loss function: 3.551, Average Loss: 3.561, avg. samples / sec: 7285.71
Iteration:   4580, Loss function: 3.034, Average Loss: 3.577, avg. samples / sec: 7281.97
Iteration:   4580, Loss function: 4.168, Average Loss: 3.558, avg. samples / sec: 7280.64
Iteration:   4580, Loss function: 2.569, Average Loss: 3.565, avg. samples / sec: 7277.34
Iteration:   4580, Loss function: 3.280, Average Loss: 3.580, avg. samples / sec: 7277.01
Iteration:   4580, Loss function: 3.152, Average Loss: 3.587, avg. samples / sec: 7281.80
Iteration:   4580, Loss function: 3.240, Average Loss: 3.543, avg. samples / sec: 7281.54
Iteration:   4580, Loss function: 3.444, Average Loss: 3.572, avg. samples / sec: 7281.72
Iteration:   4580, Loss function: 2.369, Average Loss: 3.584, avg. samples / sec: 7281.74
Iteration:   4580, Loss function: 3.822, Average Loss: 3.580, avg. samples / sec: 7281.48
Iteration:   4580, Loss function: 3.151, Average Loss: 3.567, avg. samples / sec: 7281.52
Iteration:   4580, Loss function: 4.290, Average Loss: 3.567, avg. samples / sec: 7281.80
Iteration:   4580, Loss function: 2.404, Average Loss: 3.593, avg. samples / sec: 7281.11
Iteration:   4580, Loss function: 2.982, Average Loss: 3.562, avg. samples / sec: 7276.03
Iteration:   4580, Loss function: 2.793, Average Loss: 3.545, avg. samples / sec: 7279.76
Iteration:   4580, Loss function: 3.990, Average Loss: 3.613, avg. samples / sec: 7280.29
Iteration:   4580, Loss function: 4.399, Average Loss: 3.564, avg. samples / sec: 7280.68
Iteration:   4580, Loss function: 4.189, Average Loss: 3.548, avg. samples / sec: 7279.59
Iteration:   4580, Loss function: 3.934, Average Loss: 3.580, avg. samples / sec: 7280.34
Iteration:   4580, Loss function: 4.090, Average Loss: 3.562, avg. samples / sec: 7280.32
Iteration:   4580, Loss function: 2.767, Average Loss: 3.563, avg. samples / sec: 7275.96
Iteration:   4580, Loss function: 2.771, Average Loss: 3.575, avg. samples / sec: 7275.26
Iteration:   4600, Loss function: 3.635, Average Loss: 3.572, avg. samples / sec: 52715.56
Iteration:   4600, Loss function: 2.865, Average Loss: 3.555, avg. samples / sec: 52922.47
Iteration:   4600, Loss function: 3.569, Average Loss: 3.565, avg. samples / sec: 52740.73
Iteration:   4600, Loss function: 2.199, Average Loss: 3.568, avg. samples / sec: 52736.88
Iteration:   4600, Loss function: 3.516, Average Loss: 3.586, avg. samples / sec: 52752.26
Iteration:   4600, Loss function: 3.686, Average Loss: 3.559, avg. samples / sec: 52757.12
Iteration:   4600, Loss function: 2.810, Average Loss: 3.573, avg. samples / sec: 52830.83
Iteration:   4600, Loss function: 3.280, Average Loss: 3.571, avg. samples / sec: 53047.37
Iteration:   4600, Loss function: 5.321, Average Loss: 3.558, avg. samples / sec: 52756.23
Iteration:   4600, Loss function: 4.256, Average Loss: 3.570, avg. samples / sec: 52690.98
Iteration:   4600, Loss function: 4.042, Average Loss: 3.555, avg. samples / sec: 52740.61
Iteration:   4600, Loss function: 3.548, Average Loss: 3.556, avg. samples / sec: 52680.72
Iteration:   4600, Loss function: 2.584, Average Loss: 3.574, avg. samples / sec: 52687.89
Iteration:   4600, Loss function: 3.235, Average Loss: 3.554, avg. samples / sec: 52680.54
Iteration:   4600, Loss function: 3.814, Average Loss: 3.543, avg. samples / sec: 52712.46
Iteration:   4600, Loss function: 3.585, Average Loss: 3.610, avg. samples / sec: 52770.10
Iteration:   4600, Loss function: 3.020, Average Loss: 3.591, avg. samples / sec: 52758.30
Iteration:   4600, Loss function: 3.630, Average Loss: 3.581, avg. samples / sec: 52692.20
Iteration:   4600, Loss function: 2.901, Average Loss: 3.563, avg. samples / sec: 52716.13
Iteration:   4600, Loss function: 4.880, Average Loss: 3.565, avg. samples / sec: 52710.57
Iteration:   4600, Loss function: 3.194, Average Loss: 3.577, avg. samples / sec: 52708.20
Iteration:   4600, Loss function: 3.661, Average Loss: 3.553, avg. samples / sec: 52771.44
Iteration:   4600, Loss function: 3.405, Average Loss: 3.557, avg. samples / sec: 52776.74
Iteration:   4600, Loss function: 3.614, Average Loss: 3.559, avg. samples / sec: 52756.59
Iteration:   4600, Loss function: 3.365, Average Loss: 3.544, avg. samples / sec: 52737.16
Iteration:   4600, Loss function: 3.511, Average Loss: 3.580, avg. samples / sec: 52683.87
Iteration:   4600, Loss function: 3.323, Average Loss: 3.562, avg. samples / sec: 52686.98
Iteration:   4600, Loss function: 4.725, Average Loss: 3.562, avg. samples / sec: 52719.60
Iteration:   4600, Loss function: 5.564, Average Loss: 3.580, avg. samples / sec: 52730.17
Iteration:   4600, Loss function: 2.731, Average Loss: 3.557, avg. samples / sec: 52733.05
:::MLL 1558640733.455 epoch_stop: {"value": null, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 819}}
:::MLL 1558640733.456 epoch_start: {"value": null, "metadata": {"epoch_num": 67, "file": "train.py", "lineno": 673}}
Iteration:   4620, Loss function: 4.542, Average Loss: 3.570, avg. samples / sec: 52656.63
Iteration:   4620, Loss function: 3.584, Average Loss: 3.553, avg. samples / sec: 52663.04
Iteration:   4620, Loss function: 3.458, Average Loss: 3.560, avg. samples / sec: 52672.47
Iteration:   4620, Loss function: 4.373, Average Loss: 3.557, avg. samples / sec: 52683.24
Iteration:   4620, Loss function: 4.365, Average Loss: 3.570, avg. samples / sec: 52656.27
Iteration:   4620, Loss function: 2.909, Average Loss: 3.563, avg. samples / sec: 52621.51
Iteration:   4620, Loss function: 3.160, Average Loss: 3.579, avg. samples / sec: 52631.51
Iteration:   4620, Loss function: 3.110, Average Loss: 3.567, avg. samples / sec: 52639.16
Iteration:   4620, Loss function: 2.706, Average Loss: 3.546, avg. samples / sec: 52724.20
Iteration:   4620, Loss function: 3.452, Average Loss: 3.555, avg. samples / sec: 52668.18
Iteration:   4620, Loss function: 3.218, Average Loss: 3.554, avg. samples / sec: 52605.44
Iteration:   4620, Loss function: 2.552, Average Loss: 3.570, avg. samples / sec: 52690.53
Iteration:   4620, Loss function: 3.191, Average Loss: 3.547, avg. samples / sec: 52621.08
Iteration:   4620, Loss function: 2.802, Average Loss: 3.567, avg. samples / sec: 52602.42
Iteration:   4620, Loss function: 3.234, Average Loss: 3.576, avg. samples / sec: 52667.02
Iteration:   4620, Loss function: 4.428, Average Loss: 3.537, avg. samples / sec: 52650.90
Iteration:   4620, Loss function: 2.768, Average Loss: 3.606, avg. samples / sec: 52655.21
Iteration:   4620, Loss function: 1.926, Average Loss: 3.552, avg. samples / sec: 52677.78
Iteration:   4620, Loss function: 2.731, Average Loss: 3.557, avg. samples / sec: 52649.76
Iteration:   4620, Loss function: 3.382, Average Loss: 3.561, avg. samples / sec: 52655.94
Iteration:   4620, Loss function: 3.191, Average Loss: 3.577, avg. samples / sec: 52655.03
Iteration:   4620, Loss function: 2.949, Average Loss: 3.548, avg. samples / sec: 52654.30
Iteration:   4620, Loss function: 3.034, Average Loss: 3.532, avg. samples / sec: 52655.60
Iteration:   4620, Loss function: 3.993, Average Loss: 3.587, avg. samples / sec: 52617.09
Iteration:   4620, Loss function: 4.133, Average Loss: 3.550, avg. samples / sec: 52638.14
Iteration:   4620, Loss function: 4.383, Average Loss: 3.556, avg. samples / sec: 52655.17
Iteration:   4620, Loss function: 3.408, Average Loss: 3.577, avg. samples / sec: 52670.50
Iteration:   4620, Loss function: 2.759, Average Loss: 3.584, avg. samples / sec: 52639.85
Iteration:   4620, Loss function: 3.523, Average Loss: 3.559, avg. samples / sec: 52635.21
Iteration:   4620, Loss function: 2.658, Average Loss: 3.556, avg. samples / sec: 52665.93
Iteration:   4640, Loss function: 4.238, Average Loss: 3.552, avg. samples / sec: 53258.19
Iteration:   4640, Loss function: 2.728, Average Loss: 3.557, avg. samples / sec: 53261.26
Iteration:   4640, Loss function: 4.460, Average Loss: 3.560, avg. samples / sec: 53263.58
Iteration:   4640, Loss function: 2.764, Average Loss: 3.550, avg. samples / sec: 53198.01
Iteration:   4640, Loss function: 4.786, Average Loss: 3.567, avg. samples / sec: 53227.25
Iteration:   4640, Loss function: 2.274, Average Loss: 3.558, avg. samples / sec: 53291.09
Iteration:   4640, Loss function: 3.619, Average Loss: 3.543, avg. samples / sec: 53237.28
Iteration:   4640, Loss function: 3.108, Average Loss: 3.561, avg. samples / sec: 53227.21
Iteration:   4640, Loss function: 3.786, Average Loss: 3.579, avg. samples / sec: 53217.84
Iteration:   4640, Loss function: 3.039, Average Loss: 3.551, avg. samples / sec: 53243.96
Iteration:   4640, Loss function: 3.657, Average Loss: 3.568, avg. samples / sec: 53242.63
Iteration:   4640, Loss function: 2.965, Average Loss: 3.542, avg. samples / sec: 53233.84
Iteration:   4640, Loss function: 2.995, Average Loss: 3.564, avg. samples / sec: 52961.55
Iteration:   4640, Loss function: 3.276, Average Loss: 3.528, avg. samples / sec: 53276.16
Iteration:   4640, Loss function: 2.724, Average Loss: 3.542, avg. samples / sec: 53266.06
Iteration:   4640, Loss function: 2.563, Average Loss: 3.549, avg. samples / sec: 53232.66
Iteration:   4640, Loss function: 2.527, Average Loss: 3.603, avg. samples / sec: 53209.38
Iteration:   4640, Loss function: 3.302, Average Loss: 3.570, avg. samples / sec: 53185.95
Iteration:   4640, Loss function: 4.564, Average Loss: 3.584, avg. samples / sec: 53233.80
Iteration:   4640, Loss function: 2.146, Average Loss: 3.557, avg. samples / sec: 53202.53
Iteration:   4640, Loss function: 3.332, Average Loss: 3.539, avg. samples / sec: 53185.97
Iteration:   4640, Loss function: 3.556, Average Loss: 3.576, avg. samples / sec: 53202.25
Iteration:   4640, Loss function: 2.635, Average Loss: 3.581, avg. samples / sec: 53246.29
Iteration:   4640, Loss function: 3.518, Average Loss: 3.558, avg. samples / sec: 53196.63
Iteration:   4640, Loss function: 3.984, Average Loss: 3.546, avg. samples / sec: 53226.12
Iteration:   4640, Loss function: 2.396, Average Loss: 3.554, avg. samples / sec: 53237.91
Iteration:   4640, Loss function: 2.558, Average Loss: 3.549, avg. samples / sec: 53226.79
Iteration:   4640, Loss function: 3.623, Average Loss: 3.575, avg. samples / sec: 53224.59
Iteration:   4640, Loss function: 4.062, Average Loss: 3.558, avg. samples / sec: 53220.62
Iteration:   4640, Loss function: 3.213, Average Loss: 3.549, avg. samples / sec: 52939.01
Iteration:   4660, Loss function: 3.152, Average Loss: 3.543, avg. samples / sec: 53382.72
Iteration:   4660, Loss function: 3.697, Average Loss: 3.556, avg. samples / sec: 53655.92
Iteration:   4660, Loss function: 3.392, Average Loss: 3.578, avg. samples / sec: 53512.26
Iteration:   4660, Loss function: 2.523, Average Loss: 3.542, avg. samples / sec: 53484.42
Iteration:   4660, Loss function: 3.695, Average Loss: 3.546, avg. samples / sec: 53457.80
Iteration:   4660, Loss function: 2.769, Average Loss: 3.564, avg. samples / sec: 53456.95
Iteration:   4660, Loss function: 3.093, Average Loss: 3.557, avg. samples / sec: 53473.64
Iteration:   4660, Loss function: 3.032, Average Loss: 3.561, avg. samples / sec: 53413.69
Iteration:   4660, Loss function: 2.824, Average Loss: 3.556, avg. samples / sec: 53459.20
Iteration:   4660, Loss function: 4.924, Average Loss: 3.540, avg. samples / sec: 53503.93
Iteration:   4660, Loss function: 3.652, Average Loss: 3.564, avg. samples / sec: 53465.69
Iteration:   4660, Loss function: 3.223, Average Loss: 3.543, avg. samples / sec: 53752.62
Iteration:   4660, Loss function: 3.284, Average Loss: 3.547, avg. samples / sec: 53406.27
Iteration:   4660, Loss function: 3.855, Average Loss: 3.539, avg. samples / sec: 53488.46
Iteration:   4660, Loss function: 3.593, Average Loss: 3.537, avg. samples / sec: 53504.32
Iteration:   4660, Loss function: 2.722, Average Loss: 3.529, avg. samples / sec: 53445.58
Iteration:   4660, Loss function: 2.626, Average Loss: 3.579, avg. samples / sec: 53497.82
Iteration:   4660, Loss function: 3.640, Average Loss: 3.564, avg. samples / sec: 53490.15
Iteration:   4660, Loss function: 3.319, Average Loss: 3.548, avg. samples / sec: 53501.13
Iteration:   4660, Loss function: 4.071, Average Loss: 3.598, avg. samples / sec: 53469.65
Iteration:   4660, Loss function: 3.118, Average Loss: 3.553, avg. samples / sec: 53513.63
Iteration:   4660, Loss function: 3.276, Average Loss: 3.565, avg. samples / sec: 53473.44
Iteration:   4660, Loss function: 2.733, Average Loss: 3.554, avg. samples / sec: 53472.24
Iteration:   4660, Loss function: 3.941, Average Loss: 3.572, avg. samples / sec: 53473.02
Iteration:   4660, Loss function: 2.884, Average Loss: 3.545, avg. samples / sec: 53422.62
Iteration:   4660, Loss function: 3.417, Average Loss: 3.552, avg. samples / sec: 53460.91
Iteration:   4660, Loss function: 3.358, Average Loss: 3.551, avg. samples / sec: 53466.42
Iteration:   4660, Loss function: 2.826, Average Loss: 3.554, avg. samples / sec: 53121.55
Iteration:   4660, Loss function: 3.287, Average Loss: 3.575, avg. samples / sec: 53467.27
Iteration:   4660, Loss function: 3.917, Average Loss: 3.540, avg. samples / sec: 53441.22
:::MLL 1558640735.667 epoch_stop: {"value": null, "metadata": {"epoch_num": 67, "file": "train.py", "lineno": 819}}
:::MLL 1558640735.667 epoch_start: {"value": null, "metadata": {"epoch_num": 68, "file": "train.py", "lineno": 673}}
Iteration:   4680, Loss function: 3.339, Average Loss: 3.540, avg. samples / sec: 53045.71
Iteration:   4680, Loss function: 3.357, Average Loss: 3.553, avg. samples / sec: 52975.23
Iteration:   4680, Loss function: 3.852, Average Loss: 3.543, avg. samples / sec: 52964.43
Iteration:   4680, Loss function: 2.872, Average Loss: 3.549, avg. samples / sec: 52976.20
Iteration:   4680, Loss function: 3.364, Average Loss: 3.581, avg. samples / sec: 52923.40
Iteration:   4680, Loss function: 3.324, Average Loss: 3.559, avg. samples / sec: 52931.35
Iteration:   4680, Loss function: 3.835, Average Loss: 3.563, avg. samples / sec: 52941.85
Iteration:   4680, Loss function: 3.173, Average Loss: 3.540, avg. samples / sec: 52914.88
Iteration:   4680, Loss function: 3.416, Average Loss: 3.552, avg. samples / sec: 52933.74
Iteration:   4680, Loss function: 2.723, Average Loss: 3.559, avg. samples / sec: 52934.77
Iteration:   4680, Loss function: 2.532, Average Loss: 3.543, avg. samples / sec: 52973.83
Iteration:   4680, Loss function: 4.346, Average Loss: 3.545, avg. samples / sec: 52907.05
Iteration:   4680, Loss function: 4.055, Average Loss: 3.539, avg. samples / sec: 53018.03
Iteration:   4680, Loss function: 3.539, Average Loss: 3.533, avg. samples / sec: 53040.32
Iteration:   4680, Loss function: 3.509, Average Loss: 3.562, avg. samples / sec: 53046.53
Iteration:   4680, Loss function: 3.944, Average Loss: 3.551, avg. samples / sec: 53058.10
Iteration:   4680, Loss function: 2.491, Average Loss: 3.537, avg. samples / sec: 53095.68
Iteration:   4680, Loss function: 3.534, Average Loss: 3.567, avg. samples / sec: 53060.59
Iteration:   4680, Loss function: 2.911, Average Loss: 3.553, avg. samples / sec: 53045.69
Iteration:   4680, Loss function: 4.267, Average Loss: 3.576, avg. samples / sec: 53056.10
Iteration:   4680, Loss function: 3.311, Average Loss: 3.544, avg. samples / sec: 53014.94
Iteration:   4680, Loss function: 3.181, Average Loss: 3.559, avg. samples / sec: 53032.82
Iteration:   4680, Loss function: 2.858, Average Loss: 3.590, avg. samples / sec: 52980.78
Iteration:   4680, Loss function: 3.534, Average Loss: 3.539, avg. samples / sec: 52975.58
Iteration:   4680, Loss function: 3.938, Average Loss: 3.536, avg. samples / sec: 52720.84
Iteration:   4680, Loss function: 2.285, Average Loss: 3.528, avg. samples / sec: 52922.81
Iteration:   4680, Loss function: 2.362, Average Loss: 3.573, avg. samples / sec: 52917.88
Iteration:   4680, Loss function: 4.016, Average Loss: 3.549, avg. samples / sec: 52942.87
Iteration:   4680, Loss function: 3.141, Average Loss: 3.549, avg. samples / sec: 52924.04
Iteration:   4680, Loss function: 3.292, Average Loss: 3.548, avg. samples / sec: 52917.78
Iteration:   4700, Loss function: 3.176, Average Loss: 3.551, avg. samples / sec: 53127.16
Iteration:   4700, Loss function: 3.805, Average Loss: 3.538, avg. samples / sec: 53033.62
Iteration:   4700, Loss function: 3.181, Average Loss: 3.538, avg. samples / sec: 53097.92
Iteration:   4700, Loss function: 3.956, Average Loss: 3.544, avg. samples / sec: 53147.96
Iteration:   4700, Loss function: 2.292, Average Loss: 3.581, avg. samples / sec: 53100.08
Iteration:   4700, Loss function: 3.318, Average Loss: 3.552, avg. samples / sec: 53111.60
Iteration:   4700, Loss function: 2.554, Average Loss: 3.540, avg. samples / sec: 53108.14
Iteration:   4700, Loss function: 4.126, Average Loss: 3.559, avg. samples / sec: 53107.72
Iteration:   4700, Loss function: 4.077, Average Loss: 3.538, avg. samples / sec: 53107.76
Iteration:   4700, Loss function: 4.157, Average Loss: 3.545, avg. samples / sec: 53026.69
Iteration:   4700, Loss function: 2.608, Average Loss: 3.555, avg. samples / sec: 53076.64
Iteration:   4700, Loss function: 3.420, Average Loss: 3.541, avg. samples / sec: 53106.38
Iteration:   4700, Loss function: 2.862, Average Loss: 3.531, avg. samples / sec: 53155.56
Iteration:   4700, Loss function: 3.267, Average Loss: 3.539, avg. samples / sec: 53009.96
Iteration:   4700, Loss function: 3.278, Average Loss: 3.533, avg. samples / sec: 53009.94
Iteration:   4700, Loss function: 2.891, Average Loss: 3.549, avg. samples / sec: 53172.66
Iteration:   4700, Loss function: 2.738, Average Loss: 3.554, avg. samples / sec: 53041.96
Iteration:   4700, Loss function: 2.869, Average Loss: 3.543, avg. samples / sec: 53131.43
Iteration:   4700, Loss function: 3.444, Average Loss: 3.563, avg. samples / sec: 53009.94
Iteration:   4700, Loss function: 3.631, Average Loss: 3.547, avg. samples / sec: 53020.39
Iteration:   4700, Loss function: 2.750, Average Loss: 3.532, avg. samples / sec: 53003.64
Iteration:   4700, Loss function: 3.603, Average Loss: 3.568, avg. samples / sec: 53113.85
Iteration:   4700, Loss function: 3.403, Average Loss: 3.558, avg. samples / sec: 52987.30
Iteration:   4700, Loss function: 2.708, Average Loss: 3.584, avg. samples / sec: 53062.81
Iteration:   4700, Loss function: 3.423, Average Loss: 3.535, avg. samples / sec: 53077.32
Iteration:   4700, Loss function: 3.401, Average Loss: 3.571, avg. samples / sec: 53009.34
Iteration:   4700, Loss function: 3.716, Average Loss: 3.531, avg. samples / sec: 53074.76
Iteration:   4700, Loss function: 2.808, Average Loss: 3.542, avg. samples / sec: 53118.13
Iteration:   4700, Loss function: 3.566, Average Loss: 3.543, avg. samples / sec: 52988.19
Iteration:   4700, Loss function: 3.013, Average Loss: 3.546, avg. samples / sec: 52938.55
Iteration:   4720, Loss function: 2.835, Average Loss: 3.548, avg. samples / sec: 53060.73
Iteration:   4720, Loss function: 2.954, Average Loss: 3.541, avg. samples / sec: 53064.85
Iteration:   4720, Loss function: 2.467, Average Loss: 3.535, avg. samples / sec: 53113.87
Iteration:   4720, Loss function: 2.105, Average Loss: 3.538, avg. samples / sec: 53024.04
Iteration:   4720, Loss function: 3.816, Average Loss: 3.534, avg. samples / sec: 53052.06
Iteration:   4720, Loss function: 3.773, Average Loss: 3.559, avg. samples / sec: 53038.23
Iteration:   4720, Loss function: 3.656, Average Loss: 3.538, avg. samples / sec: 53102.34
Iteration:   4720, Loss function: 2.529, Average Loss: 3.533, avg. samples / sec: 53062.79
Iteration:   4720, Loss function: 4.164, Average Loss: 3.538, avg. samples / sec: 52871.30
Iteration:   4720, Loss function: 2.910, Average Loss: 3.553, avg. samples / sec: 53079.76
Iteration:   4720, Loss function: 2.984, Average Loss: 3.551, avg. samples / sec: 52996.44
Iteration:   4720, Loss function: 3.503, Average Loss: 3.536, avg. samples / sec: 53069.74
Iteration:   4720, Loss function: 2.871, Average Loss: 3.550, avg. samples / sec: 53067.69
Iteration:   4720, Loss function: 3.090, Average Loss: 3.576, avg. samples / sec: 52823.36
Iteration:   4720, Loss function: 4.470, Average Loss: 3.551, avg. samples / sec: 53071.12
Iteration:   4720, Loss function: 3.439, Average Loss: 3.541, avg. samples / sec: 53116.75
Iteration:   4720, Loss function: 3.069, Average Loss: 3.538, avg. samples / sec: 53057.80
Iteration:   4720, Loss function: 4.557, Average Loss: 3.528, avg. samples / sec: 52999.75
Iteration:   4720, Loss function: 3.117, Average Loss: 3.564, avg. samples / sec: 53042.76
Iteration:   4720, Loss function: 3.812, Average Loss: 3.533, avg. samples / sec: 53002.94
Iteration:   4720, Loss function: 3.028, Average Loss: 3.528, avg. samples / sec: 53043.42
Iteration:   4720, Loss function: 2.272, Average Loss: 3.551, avg. samples / sec: 53031.34
Iteration:   4720, Loss function: 3.388, Average Loss: 3.532, avg. samples / sec: 53035.69
Iteration:   4720, Loss function: 3.183, Average Loss: 3.579, avg. samples / sec: 53027.51
Iteration:   4720, Loss function: 3.435, Average Loss: 3.538, avg. samples / sec: 53066.19
Iteration:   4720, Loss function: 2.458, Average Loss: 3.529, avg. samples / sec: 53021.84
Iteration:   4720, Loss function: 3.642, Average Loss: 3.547, avg. samples / sec: 52976.80
Iteration:   4720, Loss function: 2.609, Average Loss: 3.562, avg. samples / sec: 52975.62
Iteration:   4720, Loss function: 3.115, Average Loss: 3.561, avg. samples / sec: 52989.43
Iteration:   4720, Loss function: 2.478, Average Loss: 3.538, avg. samples / sec: 53010.69
Iteration:   4740, Loss function: 3.270, Average Loss: 3.545, avg. samples / sec: 53224.88
Iteration:   4740, Loss function: 2.677, Average Loss: 3.533, avg. samples / sec: 53381.34
Iteration:   4740, Loss function: 2.993, Average Loss: 3.533, avg. samples / sec: 53186.55
Iteration:   4740, Loss function: 3.484, Average Loss: 3.529, avg. samples / sec: 53235.73
Iteration:   4740, Loss function: 3.051, Average Loss: 3.538, avg. samples / sec: 53203.94
Iteration:   4740, Loss function: 3.056, Average Loss: 3.541, avg. samples / sec: 53258.02
Iteration:   4740, Loss function: 2.924, Average Loss: 3.535, avg. samples / sec: 53205.36
Iteration:   4740, Loss function: 3.905, Average Loss: 3.549, avg. samples / sec: 53224.94
Iteration:   4740, Loss function: 2.987, Average Loss: 3.554, avg. samples / sec: 53211.15
Iteration:   4740, Loss function: 3.581, Average Loss: 3.537, avg. samples / sec: 53181.85
Iteration:   4740, Loss function: 2.907, Average Loss: 3.537, avg. samples / sec: 53174.51
Iteration:   4740, Loss function: 3.238, Average Loss: 3.528, avg. samples / sec: 53277.17
Iteration:   4740, Loss function: 2.889, Average Loss: 3.544, avg. samples / sec: 53289.84
Iteration:   4740, Loss function: 3.765, Average Loss: 3.534, avg. samples / sec: 53213.04
Iteration:   4740, Loss function: 3.310, Average Loss: 3.565, avg. samples / sec: 53229.94
Iteration:   4740, Loss function: 3.842, Average Loss: 3.579, avg. samples / sec: 53268.83
Iteration:   4740, Loss function: 2.957, Average Loss: 3.527, avg. samples / sec: 53255.09
Iteration:   4740, Loss function: 2.227, Average Loss: 3.523, avg. samples / sec: 53284.67
Iteration:   4740, Loss function: 3.349, Average Loss: 3.527, avg. samples / sec: 53224.84
Iteration:   4740, Loss function: 3.709, Average Loss: 3.523, avg. samples / sec: 53227.05
Iteration:   4740, Loss function: 2.995, Average Loss: 3.547, avg. samples / sec: 53186.49
Iteration:   4740, Loss function: 3.064, Average Loss: 3.537, avg. samples / sec: 53199.56
Iteration:   4740, Loss function: 2.801, Average Loss: 3.551, avg. samples / sec: 53190.48
Iteration:   4740, Loss function: 3.754, Average Loss: 3.538, avg. samples / sec: 53198.56
Iteration:   4740, Loss function: 2.433, Average Loss: 3.556, avg. samples / sec: 53285.51
Iteration:   4740, Loss function: 3.729, Average Loss: 3.544, avg. samples / sec: 53257.90
Iteration:   4740, Loss function: 3.008, Average Loss: 3.537, avg. samples / sec: 53219.95
Iteration:   4740, Loss function: 2.602, Average Loss: 3.558, avg. samples / sec: 53263.24
Iteration:   4740, Loss function: 1.726, Average Loss: 3.557, avg. samples / sec: 53183.82
Iteration:   4740, Loss function: 3.034, Average Loss: 3.538, avg. samples / sec: 53214.53
:::MLL 1558640737.883 epoch_stop: {"value": null, "metadata": {"epoch_num": 68, "file": "train.py", "lineno": 819}}
:::MLL 1558640737.884 epoch_start: {"value": null, "metadata": {"epoch_num": 69, "file": "train.py", "lineno": 673}}
Iteration:   4760, Loss function: 2.305, Average Loss: 3.541, avg. samples / sec: 53151.25
Iteration:   4760, Loss function: 3.263, Average Loss: 3.527, avg. samples / sec: 53193.09
Iteration:   4760, Loss function: 2.106, Average Loss: 3.533, avg. samples / sec: 53155.80
Iteration:   4760, Loss function: 3.745, Average Loss: 3.528, avg. samples / sec: 53139.12
Iteration:   4760, Loss function: 3.257, Average Loss: 3.533, avg. samples / sec: 53179.85
Iteration:   4760, Loss function: 2.318, Average Loss: 3.530, avg. samples / sec: 53132.13
Iteration:   4760, Loss function: 3.238, Average Loss: 3.536, avg. samples / sec: 53119.67
Iteration:   4760, Loss function: 2.708, Average Loss: 3.544, avg. samples / sec: 53133.15
Iteration:   4760, Loss function: 3.471, Average Loss: 3.534, avg. samples / sec: 53108.86
Iteration:   4760, Loss function: 2.677, Average Loss: 3.551, avg. samples / sec: 53128.46
Iteration:   4760, Loss function: 3.919, Average Loss: 3.536, avg. samples / sec: 53145.87
Iteration:   4760, Loss function: 2.757, Average Loss: 3.518, avg. samples / sec: 53162.25
Iteration:   4760, Loss function: 2.724, Average Loss: 3.520, avg. samples / sec: 53155.44
Iteration:   4760, Loss function: 3.954, Average Loss: 3.526, avg. samples / sec: 53147.00
Iteration:   4760, Loss function: 3.747, Average Loss: 3.536, avg. samples / sec: 53101.84
Iteration:   4760, Loss function: 2.402, Average Loss: 3.547, avg. samples / sec: 53155.22
Iteration:   4760, Loss function: 2.687, Average Loss: 3.537, avg. samples / sec: 53162.19
Iteration:   4760, Loss function: 3.311, Average Loss: 3.534, avg. samples / sec: 53147.14
Iteration:   4760, Loss function: 2.674, Average Loss: 3.523, avg. samples / sec: 53129.18
Iteration:   4760, Loss function: 3.427, Average Loss: 3.544, avg. samples / sec: 53093.44
Iteration:   4760, Loss function: 3.779, Average Loss: 3.560, avg. samples / sec: 53095.98
Iteration:   4760, Loss function: 2.094, Average Loss: 3.555, avg. samples / sec: 53167.73
Iteration:   4760, Loss function: 4.378, Average Loss: 3.538, avg. samples / sec: 53151.85
Iteration:   4760, Loss function: 2.835, Average Loss: 3.573, avg. samples / sec: 53103.80
Iteration:   4760, Loss function: 2.770, Average Loss: 3.556, avg. samples / sec: 53121.87
Iteration:   4760, Loss function: 3.121, Average Loss: 3.527, avg. samples / sec: 53058.33
Iteration:   4760, Loss function: 3.425, Average Loss: 3.531, avg. samples / sec: 53118.67
Iteration:   4760, Loss function: 2.584, Average Loss: 3.537, avg. samples / sec: 53115.17
Iteration:   4760, Loss function: 4.054, Average Loss: 3.552, avg. samples / sec: 53136.36
Iteration:   4760, Loss function: 2.759, Average Loss: 3.532, avg. samples / sec: 53177.30
Iteration:   4780, Loss function: 3.113, Average Loss: 3.529, avg. samples / sec: 53359.84
Iteration:   4780, Loss function: 3.503, Average Loss: 3.529, avg. samples / sec: 53269.76
Iteration:   4780, Loss function: 3.647, Average Loss: 3.547, avg. samples / sec: 53341.78
Iteration:   4780, Loss function: 4.167, Average Loss: 3.538, avg. samples / sec: 53331.77
Iteration:   4780, Loss function: 3.085, Average Loss: 3.525, avg. samples / sec: 53104.34
Iteration:   4780, Loss function: 3.844, Average Loss: 3.525, avg. samples / sec: 53303.65
Iteration:   4780, Loss function: 2.748, Average Loss: 3.538, avg. samples / sec: 53082.64
Iteration:   4780, Loss function: 3.693, Average Loss: 3.529, avg. samples / sec: 53259.07
Iteration:   4780, Loss function: 2.752, Average Loss: 3.534, avg. samples / sec: 53290.77
Iteration:   4780, Loss function: 4.299, Average Loss: 3.538, avg. samples / sec: 53309.60
Iteration:   4780, Loss function: 3.105, Average Loss: 3.569, avg. samples / sec: 53369.09
Iteration:   4780, Loss function: 3.787, Average Loss: 3.556, avg. samples / sec: 53351.94
Iteration:   4780, Loss function: 4.796, Average Loss: 3.512, avg. samples / sec: 53310.71
Iteration:   4780, Loss function: 2.774, Average Loss: 3.520, avg. samples / sec: 53362.67
Iteration:   4780, Loss function: 3.245, Average Loss: 3.535, avg. samples / sec: 53322.99
Iteration:   4780, Loss function: 3.352, Average Loss: 3.521, avg. samples / sec: 53319.42
Iteration:   4780, Loss function: 3.720, Average Loss: 3.542, avg. samples / sec: 53324.42
Iteration:   4780, Loss function: 4.236, Average Loss: 3.535, avg. samples / sec: 53334.31
Iteration:   4780, Loss function: 3.333, Average Loss: 3.519, avg. samples / sec: 53302.34
Iteration:   4780, Loss function: 3.776, Average Loss: 3.553, avg. samples / sec: 53335.32
Iteration:   4780, Loss function: 3.247, Average Loss: 3.520, avg. samples / sec: 53300.28
Iteration:   4780, Loss function: 3.370, Average Loss: 3.531, avg. samples / sec: 53333.91
Iteration:   4780, Loss function: 2.316, Average Loss: 3.544, avg. samples / sec: 53333.28
Iteration:   4780, Loss function: 3.146, Average Loss: 3.535, avg. samples / sec: 53048.71
Iteration:   4780, Loss function: 3.533, Average Loss: 3.545, avg. samples / sec: 53274.57
Iteration:   4780, Loss function: 3.219, Average Loss: 3.528, avg. samples / sec: 53313.71
Iteration:   4780, Loss function: 2.854, Average Loss: 3.546, avg. samples / sec: 53285.53
Iteration:   4780, Loss function: 2.546, Average Loss: 3.528, avg. samples / sec: 53272.02
Iteration:   4780, Loss function: 3.470, Average Loss: 3.532, avg. samples / sec: 53316.74
Iteration:   4780, Loss function: 3.411, Average Loss: 3.528, avg. samples / sec: 53157.78
Iteration:   4800, Loss function: 4.165, Average Loss: 3.537, avg. samples / sec: 53473.34
Iteration:   4800, Loss function: 2.831, Average Loss: 3.521, avg. samples / sec: 53421.33
Iteration:   4800, Loss function: 2.980, Average Loss: 3.529, avg. samples / sec: 53279.65
Iteration:   4800, Loss function: 3.426, Average Loss: 3.527, avg. samples / sec: 53257.50
Iteration:   4800, Loss function: 3.693, Average Loss: 3.545, avg. samples / sec: 53268.65
Iteration:   4800, Loss function: 3.654, Average Loss: 3.536, avg. samples / sec: 53308.79
Iteration:   4800, Loss function: 2.974, Average Loss: 3.517, avg. samples / sec: 53276.41
Iteration:   4800, Loss function: 2.467, Average Loss: 3.523, avg. samples / sec: 53275.10
Iteration:   4800, Loss function: 2.859, Average Loss: 3.530, avg. samples / sec: 53504.67
Iteration:   4800, Loss function: 2.674, Average Loss: 3.532, avg. samples / sec: 53263.50
Iteration:   4800, Loss function: 2.187, Average Loss: 3.532, avg. samples / sec: 53175.79
Iteration:   4800, Loss function: 3.161, Average Loss: 3.520, avg. samples / sec: 53280.09
Iteration:   4800, Loss function: 3.211, Average Loss: 3.515, avg. samples / sec: 53302.84
Iteration:   4800, Loss function: 2.690, Average Loss: 3.521, avg. samples / sec: 53271.69
Iteration:   4800, Loss function: 3.643, Average Loss: 3.519, avg. samples / sec: 53264.59
Iteration:   4800, Loss function: 3.190, Average Loss: 3.523, avg. samples / sec: 53307.56
Iteration:   4800, Loss function: 2.635, Average Loss: 3.531, avg. samples / sec: 53246.19
Iteration:   4800, Loss function: 3.326, Average Loss: 3.507, avg. samples / sec: 53234.29
Iteration:   4800, Loss function: 3.545, Average Loss: 3.526, avg. samples / sec: 53275.36
Iteration:   4800, Loss function: 2.310, Average Loss: 3.522, avg. samples / sec: 53290.95
Iteration:   4800, Loss function: 4.438, Average Loss: 3.532, avg. samples / sec: 53244.62
Iteration:   4800, Loss function: 3.356, Average Loss: 3.554, avg. samples / sec: 53209.30
Iteration:   4800, Loss function: 2.457, Average Loss: 3.539, avg. samples / sec: 53284.18
Iteration:   4800, Loss function: 2.975, Average Loss: 3.537, avg. samples / sec: 53271.49
Iteration:   4800, Loss function: 3.540, Average Loss: 3.562, avg. samples / sec: 53199.68
Iteration:   4800, Loss function: 3.280, Average Loss: 3.538, avg. samples / sec: 53224.88
Iteration:   4800, Loss function: 3.576, Average Loss: 3.544, avg. samples / sec: 53246.21
Iteration:   4800, Loss function: 4.243, Average Loss: 3.539, avg. samples / sec: 53252.55
Iteration:   4800, Loss function: 2.463, Average Loss: 3.522, avg. samples / sec: 53381.04
Iteration:   4800, Loss function: 3.430, Average Loss: 3.531, avg. samples / sec: 53240.50
:::MLL 1558640740.091 epoch_stop: {"value": null, "metadata": {"epoch_num": 69, "file": "train.py", "lineno": 819}}
:::MLL 1558640740.092 epoch_start: {"value": null, "metadata": {"epoch_num": 70, "file": "train.py", "lineno": 673}}
Iteration:   4820, Loss function: 4.037, Average Loss: 3.532, avg. samples / sec: 53057.66
Iteration:   4820, Loss function: 3.332, Average Loss: 3.517, avg. samples / sec: 53102.06
Iteration:   4820, Loss function: 3.672, Average Loss: 3.525, avg. samples / sec: 53075.28
Iteration:   4820, Loss function: 3.381, Average Loss: 3.515, avg. samples / sec: 53076.66
Iteration:   4820, Loss function: 2.497, Average Loss: 3.532, avg. samples / sec: 53058.63
Iteration:   4820, Loss function: 3.279, Average Loss: 3.522, avg. samples / sec: 53042.22
Iteration:   4820, Loss function: 4.413, Average Loss: 3.540, avg. samples / sec: 53033.64
Iteration:   4820, Loss function: 4.441, Average Loss: 3.524, avg. samples / sec: 53051.90
Iteration:   4820, Loss function: 3.544, Average Loss: 3.524, avg. samples / sec: 53040.84
Iteration:   4820, Loss function: 3.421, Average Loss: 3.530, avg. samples / sec: 53070.18
Iteration:   4820, Loss function: 3.359, Average Loss: 3.528, avg. samples / sec: 53092.92
Iteration:   4820, Loss function: 3.832, Average Loss: 3.533, avg. samples / sec: 53233.08
Iteration:   4820, Loss function: 4.200, Average Loss: 3.527, avg. samples / sec: 53200.77
Iteration:   4820, Loss function: 4.036, Average Loss: 3.523, avg. samples / sec: 53144.53
Iteration:   4820, Loss function: 3.992, Average Loss: 3.531, avg. samples / sec: 53198.05
Iteration:   4820, Loss function: 2.686, Average Loss: 3.518, avg. samples / sec: 53157.40
Iteration:   4820, Loss function: 2.060, Average Loss: 3.527, avg. samples / sec: 53165.92
Iteration:   4820, Loss function: 3.750, Average Loss: 3.522, avg. samples / sec: 53148.20
Iteration:   4820, Loss function: 2.699, Average Loss: 3.532, avg. samples / sec: 53165.56
Iteration:   4820, Loss function: 2.825, Average Loss: 3.520, avg. samples / sec: 53118.03
Iteration:   4820, Loss function: 2.581, Average Loss: 3.552, avg. samples / sec: 53103.82
Iteration:   4820, Loss function: 3.331, Average Loss: 3.504, avg. samples / sec: 53066.87
Iteration:   4820, Loss function: 3.302, Average Loss: 3.557, avg. samples / sec: 53097.22
Iteration:   4820, Loss function: 2.903, Average Loss: 3.515, avg. samples / sec: 53032.42
Iteration:   4820, Loss function: 3.424, Average Loss: 3.514, avg. samples / sec: 53047.89
Iteration:   4820, Loss function: 2.530, Average Loss: 3.515, avg. samples / sec: 53041.58
Iteration:   4820, Loss function: 3.548, Average Loss: 3.515, avg. samples / sec: 52989.71
Iteration:   4820, Loss function: 2.984, Average Loss: 3.514, avg. samples / sec: 53054.42
Iteration:   4820, Loss function: 2.951, Average Loss: 3.538, avg. samples / sec: 53027.57
Iteration:   4820, Loss function: 4.113, Average Loss: 3.528, avg. samples / sec: 53050.49
Iteration:   4840, Loss function: 3.069, Average Loss: 3.511, avg. samples / sec: 53390.67
Iteration:   4840, Loss function: 3.687, Average Loss: 3.521, avg. samples / sec: 53404.16
Iteration:   4840, Loss function: 2.377, Average Loss: 3.518, avg. samples / sec: 53446.29
Iteration:   4840, Loss function: 3.497, Average Loss: 3.529, avg. samples / sec: 53391.41
Iteration:   4840, Loss function: 3.994, Average Loss: 3.539, avg. samples / sec: 53400.58
Iteration:   4840, Loss function: 2.811, Average Loss: 3.526, avg. samples / sec: 53401.17
Iteration:   4840, Loss function: 2.750, Average Loss: 3.514, avg. samples / sec: 53346.79
Iteration:   4840, Loss function: 2.959, Average Loss: 3.523, avg. samples / sec: 53399.57
Iteration:   4840, Loss function: 2.341, Average Loss: 3.516, avg. samples / sec: 53337.20
Iteration:   4840, Loss function: 3.250, Average Loss: 3.528, avg. samples / sec: 53100.28
Iteration:   4840, Loss function: 2.141, Average Loss: 3.514, avg. samples / sec: 53426.15
Iteration:   4840, Loss function: 2.117, Average Loss: 3.522, avg. samples / sec: 53281.99
Iteration:   4840, Loss function: 3.402, Average Loss: 3.510, avg. samples / sec: 53419.65
Iteration:   4840, Loss function: 3.818, Average Loss: 3.499, avg. samples / sec: 53398.03
Iteration:   4840, Loss function: 2.744, Average Loss: 3.517, avg. samples / sec: 53333.00
Iteration:   4840, Loss function: 2.758, Average Loss: 3.522, avg. samples / sec: 53318.05
Iteration:   4840, Loss function: 3.704, Average Loss: 3.547, avg. samples / sec: 53375.48
Iteration:   4840, Loss function: 3.347, Average Loss: 3.513, avg. samples / sec: 53441.91
Iteration:   4840, Loss function: 4.258, Average Loss: 3.528, avg. samples / sec: 53277.33
Iteration:   4840, Loss function: 3.444, Average Loss: 3.514, avg. samples / sec: 53336.49
Iteration:   4840, Loss function: 2.746, Average Loss: 3.513, avg. samples / sec: 53407.24
Iteration:   4840, Loss function: 3.335, Average Loss: 3.532, avg. samples / sec: 53446.39
Iteration:   4840, Loss function: 2.954, Average Loss: 3.529, avg. samples / sec: 53225.88
Iteration:   4840, Loss function: 3.885, Average Loss: 3.551, avg. samples / sec: 53373.20
Iteration:   4840, Loss function: 2.983, Average Loss: 3.516, avg. samples / sec: 53160.63
Iteration:   4840, Loss function: 2.511, Average Loss: 3.515, avg. samples / sec: 53412.48
Iteration:   4840, Loss function: 3.315, Average Loss: 3.517, avg. samples / sec: 53261.83
Iteration:   4840, Loss function: 3.817, Average Loss: 3.530, avg. samples / sec: 53274.41
Iteration:   4840, Loss function: 3.200, Average Loss: 3.526, avg. samples / sec: 53418.17
Iteration:   4840, Loss function: 4.623, Average Loss: 3.522, avg. samples / sec: 53215.13
Iteration:   4860, Loss function: 3.119, Average Loss: 3.505, avg. samples / sec: 53431.05
Iteration:   4860, Loss function: 3.514, Average Loss: 3.525, avg. samples / sec: 53729.85
Iteration:   4860, Loss function: 3.440, Average Loss: 3.517, avg. samples / sec: 53442.56
Iteration:   4860, Loss function: 4.046, Average Loss: 3.518, avg. samples / sec: 53437.67
Iteration:   4860, Loss function: 3.983, Average Loss: 3.535, avg. samples / sec: 53459.97
Iteration:   4860, Loss function: 3.563, Average Loss: 3.525, avg. samples / sec: 53427.50
Iteration:   4860, Loss function: 3.495, Average Loss: 3.512, avg. samples / sec: 53691.53
Iteration:   4860, Loss function: 3.247, Average Loss: 3.513, avg. samples / sec: 53481.76
Iteration:   4860, Loss function: 3.881, Average Loss: 3.513, avg. samples / sec: 53446.83
Iteration:   4860, Loss function: 3.037, Average Loss: 3.526, avg. samples / sec: 53438.63
Iteration:   4860, Loss function: 4.076, Average Loss: 3.524, avg. samples / sec: 53442.15
Iteration:   4860, Loss function: 2.313, Average Loss: 3.524, avg. samples / sec: 53488.44
Iteration:   4860, Loss function: 3.501, Average Loss: 3.511, avg. samples / sec: 53446.27
Iteration:   4860, Loss function: 3.743, Average Loss: 3.520, avg. samples / sec: 53521.10
Iteration:   4860, Loss function: 2.950, Average Loss: 3.518, avg. samples / sec: 53434.01
Iteration:   4860, Loss function: 4.780, Average Loss: 3.516, avg. samples / sec: 53449.84
Iteration:   4860, Loss function: 3.797, Average Loss: 3.511, avg. samples / sec: 53453.63
Iteration:   4860, Loss function: 2.391, Average Loss: 3.494, avg. samples / sec: 53443.21
Iteration:   4860, Loss function: 3.436, Average Loss: 3.507, avg. samples / sec: 53455.53
Iteration:   4860, Loss function: 3.836, Average Loss: 3.509, avg. samples / sec: 53429.31
Iteration:   4860, Loss function: 2.516, Average Loss: 3.541, avg. samples / sec: 53427.48
Iteration:   4860, Loss function: 3.777, Average Loss: 3.547, avg. samples / sec: 53447.81
Iteration:   4860, Loss function: 3.935, Average Loss: 3.531, avg. samples / sec: 53451.34
Iteration:   4860, Loss function: 3.764, Average Loss: 3.514, avg. samples / sec: 53468.11
Iteration:   4860, Loss function: 3.087, Average Loss: 3.510, avg. samples / sec: 53426.98
Iteration:   4860, Loss function: 3.392, Average Loss: 3.520, avg. samples / sec: 53466.28
Iteration:   4860, Loss function: 3.955, Average Loss: 3.514, avg. samples / sec: 53400.11
Iteration:   4860, Loss function: 2.442, Average Loss: 3.522, avg. samples / sec: 53464.29
Iteration:   4860, Loss function: 3.047, Average Loss: 3.527, avg. samples / sec: 53418.29
Iteration:   4860, Loss function: 3.388, Average Loss: 3.513, avg. samples / sec: 53431.50
Iteration:   4880, Loss function: 3.277, Average Loss: 3.520, avg. samples / sec: 53320.31
Iteration:   4880, Loss function: 4.016, Average Loss: 3.501, avg. samples / sec: 53320.41
Iteration:   4880, Loss function: 3.218, Average Loss: 3.517, avg. samples / sec: 53311.94
Iteration:   4880, Loss function: 3.293, Average Loss: 3.515, avg. samples / sec: 53337.48
Iteration:   4880, Loss function: 3.586, Average Loss: 3.519, avg. samples / sec: 53364.67
Iteration:   4880, Loss function: 3.190, Average Loss: 3.517, avg. samples / sec: 53335.42
Iteration:   4880, Loss function: 3.758, Average Loss: 3.513, avg. samples / sec: 53335.85
Iteration:   4880, Loss function: 2.567, Average Loss: 3.513, avg. samples / sec: 53311.31
Iteration:   4880, Loss function: 3.135, Average Loss: 3.524, avg. samples / sec: 53303.55
Iteration:   4880, Loss function: 3.764, Average Loss: 3.530, avg. samples / sec: 53244.10
Iteration:   4880, Loss function: 3.938, Average Loss: 3.526, avg. samples / sec: 53274.15
Iteration:   4880, Loss function: 4.624, Average Loss: 3.522, avg. samples / sec: 53357.98
Iteration:   4880, Loss function: 2.401, Average Loss: 3.507, avg. samples / sec: 53342.59
Iteration:   4880, Loss function: 2.548, Average Loss: 3.533, avg. samples / sec: 53370.57
Iteration:   4880, Loss function: 2.999, Average Loss: 3.498, avg. samples / sec: 53344.00
Iteration:   4880, Loss function: 3.112, Average Loss: 3.502, avg. samples / sec: 53328.90
Iteration:   4880, Loss function: 3.268, Average Loss: 3.504, avg. samples / sec: 53319.30
Iteration:   4880, Loss function: 3.454, Average Loss: 3.517, avg. samples / sec: 53305.04
Iteration:   4880, Loss function: 3.157, Average Loss: 3.527, avg. samples / sec: 53334.55
Iteration:   4880, Loss function: 3.527, Average Loss: 3.513, avg. samples / sec: 53307.06
Iteration:   4880, Loss function: 3.359, Average Loss: 3.508, avg. samples / sec: 53360.81
Iteration:   4880, Loss function: 4.153, Average Loss: 3.522, avg. samples / sec: 53270.49
Iteration:   4880, Loss function: 3.637, Average Loss: 3.511, avg. samples / sec: 53330.58
Iteration:   4880, Loss function: 2.375, Average Loss: 3.507, avg. samples / sec: 53331.69
Iteration:   4880, Loss function: 3.172, Average Loss: 3.511, avg. samples / sec: 53307.78
Iteration:   4880, Loss function: 3.204, Average Loss: 3.513, avg. samples / sec: 53322.85
Iteration:   4880, Loss function: 2.329, Average Loss: 3.516, avg. samples / sec: 53319.34
Iteration:   4880, Loss function: 3.944, Average Loss: 3.544, avg. samples / sec: 53296.09
Iteration:   4880, Loss function: 3.038, Average Loss: 3.525, avg. samples / sec: 53310.87
Iteration:   4880, Loss function: 2.254, Average Loss: 3.499, avg. samples / sec: 53277.01
:::MLL 1558640742.297 epoch_stop: {"value": null, "metadata": {"epoch_num": 70, "file": "train.py", "lineno": 819}}
:::MLL 1558640742.298 epoch_start: {"value": null, "metadata": {"epoch_num": 71, "file": "train.py", "lineno": 673}}
Iteration:   4900, Loss function: 3.814, Average Loss: 3.522, avg. samples / sec: 53646.30
Iteration:   4900, Loss function: 3.623, Average Loss: 3.516, avg. samples / sec: 53265.75
Iteration:   4900, Loss function: 3.430, Average Loss: 3.500, avg. samples / sec: 53209.24
Iteration:   4900, Loss function: 2.569, Average Loss: 3.510, avg. samples / sec: 53265.41
Iteration:   4900, Loss function: 3.893, Average Loss: 3.514, avg. samples / sec: 53251.81
Iteration:   4900, Loss function: 2.561, Average Loss: 3.515, avg. samples / sec: 53254.20
Iteration:   4900, Loss function: 4.307, Average Loss: 3.513, avg. samples / sec: 53264.06
Iteration:   4900, Loss function: 2.903, Average Loss: 3.506, avg. samples / sec: 53263.66
Iteration:   4900, Loss function: 2.593, Average Loss: 3.523, avg. samples / sec: 53321.05
Iteration:   4900, Loss function: 3.129, Average Loss: 3.504, avg. samples / sec: 53484.32
Iteration:   4900, Loss function: 3.286, Average Loss: 3.524, avg. samples / sec: 53249.43
Iteration:   4900, Loss function: 4.907, Average Loss: 3.513, avg. samples / sec: 53206.25
Iteration:   4900, Loss function: 3.702, Average Loss: 3.518, avg. samples / sec: 53266.22
Iteration:   4900, Loss function: 3.243, Average Loss: 3.493, avg. samples / sec: 53252.41
Iteration:   4900, Loss function: 4.590, Average Loss: 3.514, avg. samples / sec: 53267.93
Iteration:   4900, Loss function: 3.709, Average Loss: 3.495, avg. samples / sec: 53240.18
Iteration:   4900, Loss function: 3.058, Average Loss: 3.531, avg. samples / sec: 53226.48
Iteration:   4900, Loss function: 3.315, Average Loss: 3.513, avg. samples / sec: 53268.55
Iteration:   4900, Loss function: 2.774, Average Loss: 3.506, avg. samples / sec: 53206.15
Iteration:   4900, Loss function: 4.642, Average Loss: 3.541, avg. samples / sec: 53296.74
Iteration:   4900, Loss function: 3.137, Average Loss: 3.523, avg. samples / sec: 53264.93
Iteration:   4900, Loss function: 3.335, Average Loss: 3.500, avg. samples / sec: 53246.53
Iteration:   4900, Loss function: 3.373, Average Loss: 3.506, avg. samples / sec: 53259.27
Iteration:   4900, Loss function: 5.043, Average Loss: 3.524, avg. samples / sec: 53243.84
Iteration:   4900, Loss function: 3.588, Average Loss: 3.503, avg. samples / sec: 53262.92
Iteration:   4900, Loss function: 3.088, Average Loss: 3.496, avg. samples / sec: 53285.67
Iteration:   4900, Loss function: 3.221, Average Loss: 3.527, avg. samples / sec: 53281.60
Iteration:   4900, Loss function: 3.673, Average Loss: 3.506, avg. samples / sec: 53266.14
Iteration:   4900, Loss function: 3.248, Average Loss: 3.514, avg. samples / sec: 53257.84
Iteration:   4900, Loss function: 3.717, Average Loss: 3.508, avg. samples / sec: 53245.39
Iteration:   4920, Loss function: 3.589, Average Loss: 3.508, avg. samples / sec: 53664.91
Iteration:   4920, Loss function: 2.633, Average Loss: 3.508, avg. samples / sec: 53636.32
Iteration:   4920, Loss function: 3.307, Average Loss: 3.515, avg. samples / sec: 53450.52
Iteration:   4920, Loss function: 3.489, Average Loss: 3.517, avg. samples / sec: 53659.54
Iteration:   4920, Loss function: 4.274, Average Loss: 3.507, avg. samples / sec: 53639.83
Iteration:   4920, Loss function: 4.226, Average Loss: 3.502, avg. samples / sec: 53508.81
Iteration:   4920, Loss function: 2.876, Average Loss: 3.524, avg. samples / sec: 53695.48
Iteration:   4920, Loss function: 4.637, Average Loss: 3.501, avg. samples / sec: 53624.99
Iteration:   4920, Loss function: 3.385, Average Loss: 3.510, avg. samples / sec: 53695.27
Iteration:   4920, Loss function: 4.145, Average Loss: 3.512, avg. samples / sec: 53601.88
Iteration:   4920, Loss function: 2.895, Average Loss: 3.517, avg. samples / sec: 53673.19
Iteration:   4920, Loss function: 3.284, Average Loss: 3.520, avg. samples / sec: 53696.58
Iteration:   4920, Loss function: 3.271, Average Loss: 3.507, avg. samples / sec: 53668.08
Iteration:   4920, Loss function: 3.694, Average Loss: 3.525, avg. samples / sec: 53664.99
Iteration:   4920, Loss function: 3.037, Average Loss: 3.502, avg. samples / sec: 53667.24
Iteration:   4920, Loss function: 3.395, Average Loss: 3.506, avg. samples / sec: 53679.79
Iteration:   4920, Loss function: 3.534, Average Loss: 3.504, avg. samples / sec: 53709.52
Iteration:   4920, Loss function: 2.549, Average Loss: 3.512, avg. samples / sec: 53676.97
Iteration:   4920, Loss function: 3.679, Average Loss: 3.495, avg. samples / sec: 53671.76
Iteration:   4920, Loss function: 3.287, Average Loss: 3.497, avg. samples / sec: 53647.77
Iteration:   4920, Loss function: 2.882, Average Loss: 3.537, avg. samples / sec: 53660.19
Iteration:   4920, Loss function: 4.024, Average Loss: 3.522, avg. samples / sec: 53677.32
Iteration:   4920, Loss function: 2.631, Average Loss: 3.510, avg. samples / sec: 53647.18
Iteration:   4920, Loss function: 3.711, Average Loss: 3.510, avg. samples / sec: 53384.15
Iteration:   4920, Loss function: 3.371, Average Loss: 3.498, avg. samples / sec: 53660.97
Iteration:   4920, Loss function: 3.072, Average Loss: 3.503, avg. samples / sec: 53423.66
Iteration:   4920, Loss function: 2.882, Average Loss: 3.488, avg. samples / sec: 53614.03
Iteration:   4920, Loss function: 3.646, Average Loss: 3.494, avg. samples / sec: 53657.47
Iteration:   4920, Loss function: 4.042, Average Loss: 3.513, avg. samples / sec: 53664.73
Iteration:   4920, Loss function: 3.976, Average Loss: 3.503, avg. samples / sec: 53631.03
Iteration:   4940, Loss function: 2.434, Average Loss: 3.503, avg. samples / sec: 53378.51
Iteration:   4940, Loss function: 3.425, Average Loss: 3.515, avg. samples / sec: 53562.24
Iteration:   4940, Loss function: 3.889, Average Loss: 3.497, avg. samples / sec: 53570.38
Iteration:   4940, Loss function: 3.251, Average Loss: 3.507, avg. samples / sec: 53450.97
Iteration:   4940, Loss function: 3.275, Average Loss: 3.502, avg. samples / sec: 53409.06
Iteration:   4940, Loss function: 3.432, Average Loss: 3.499, avg. samples / sec: 53433.06
Iteration:   4940, Loss function: 4.782, Average Loss: 3.511, avg. samples / sec: 53375.58
Iteration:   4940, Loss function: 2.463, Average Loss: 3.506, avg. samples / sec: 53647.10
Iteration:   4940, Loss function: 2.739, Average Loss: 3.511, avg. samples / sec: 53424.08
Iteration:   4940, Loss function: 3.634, Average Loss: 3.519, avg. samples / sec: 53398.58
Iteration:   4940, Loss function: 3.605, Average Loss: 3.491, avg. samples / sec: 53601.80
Iteration:   4940, Loss function: 2.737, Average Loss: 3.513, avg. samples / sec: 53438.24
Iteration:   4940, Loss function: 2.221, Average Loss: 3.515, avg. samples / sec: 53343.46
Iteration:   4940, Loss function: 2.947, Average Loss: 3.518, avg. samples / sec: 53404.57
Iteration:   4940, Loss function: 2.728, Average Loss: 3.504, avg. samples / sec: 53411.29
Iteration:   4940, Loss function: 3.299, Average Loss: 3.500, avg. samples / sec: 53420.09
Iteration:   4940, Loss function: 3.443, Average Loss: 3.521, avg. samples / sec: 53405.44
Iteration:   4940, Loss function: 3.186, Average Loss: 3.506, avg. samples / sec: 53425.82
Iteration:   4940, Loss function: 2.676, Average Loss: 3.487, avg. samples / sec: 53445.76
Iteration:   4940, Loss function: 4.530, Average Loss: 3.507, avg. samples / sec: 53435.22
Iteration:   4940, Loss function: 2.641, Average Loss: 3.502, avg. samples / sec: 53393.94
Iteration:   4940, Loss function: 3.324, Average Loss: 3.498, avg. samples / sec: 53403.41
Iteration:   4940, Loss function: 4.502, Average Loss: 3.510, avg. samples / sec: 53402.48
Iteration:   4940, Loss function: 3.238, Average Loss: 3.535, avg. samples / sec: 53397.22
Iteration:   4940, Loss function: 3.650, Average Loss: 3.519, avg. samples / sec: 53389.23
Iteration:   4940, Loss function: 3.477, Average Loss: 3.494, avg. samples / sec: 53390.08
Iteration:   4940, Loss function: 3.020, Average Loss: 3.492, avg. samples / sec: 53386.42
Iteration:   4940, Loss function: 3.628, Average Loss: 3.509, avg. samples / sec: 53393.15
Iteration:   4940, Loss function: 3.159, Average Loss: 3.500, avg. samples / sec: 53398.09
Iteration:   4940, Loss function: 2.679, Average Loss: 3.503, avg. samples / sec: 53342.65
:::MLL 1558640744.308 eval_start: {"value": null, "metadata": {"epoch_num": 71, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.70 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.60s)
DONE (t=0.65s)
DONE (t=2.52s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23026
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39194
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23489
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05760
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24189
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22118
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33987
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53425
Current AP: 0.23026 AP goal: 0.23000
:::MLL 1558640748.139 eval_accuracy: {"value": 0.23026008340935386, "metadata": {"epoch_num": 71, "file": "train.py", "lineno": 389}}
:::MLL 1558640748.225 eval_stop: {"value": null, "metadata": {"epoch_num": 71, "file": "train.py", "lineno": 392}}
:::MLL 1558640748.231 block_stop: {"value": null, "metadata": {"first_epoch_num": 66, "file": "train.py", "lineno": 804}}
:::MLL 1558640748.775 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 07:45:47 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:04 PM
ENDING TIMING RUN AT 2019-05-23 07:45:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:06 PM
ENDING TIMING RUN AT 2019-05-23 07:45:46 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:02 PM
ENDING TIMING RUN AT 2019-05-23 07:45:47 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:04 PM
ENDING TIMING RUN AT 2019-05-23 07:45:54 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:10 PM
ENDING TIMING RUN AT 2019-05-23 07:45:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:02 PM
ENDING TIMING RUN AT 2019-05-23 07:45:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:01 PM
ENDING TIMING RUN AT 2019-05-23 07:45:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:02 PM
ENDING TIMING RUN AT 2019-05-23 07:45:44 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:00 PM
ENDING TIMING RUN AT 2019-05-23 07:45:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:02 PM
ENDING TIMING RUN AT 2019-05-23 07:45:46 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:03 PM
ENDING TIMING RUN AT 2019-05-23 07:45:46 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:02 PM
ENDING TIMING RUN AT 2019-05-23 07:45:46 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:02 PM
ENDING TIMING RUN AT 2019-05-23 07:45:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:02 PM
ENDING TIMING RUN AT 2019-05-23 07:45:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:00 PM
ENDING TIMING RUN AT 2019-05-23 07:45:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:05 PM
ENDING TIMING RUN AT 2019-05-23 07:45:47 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:04 PM
ENDING TIMING RUN AT 2019-05-23 07:45:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:07 PM
ENDING TIMING RUN AT 2019-05-23 07:45:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:01 PM
ENDING TIMING RUN AT 2019-05-23 07:45:48 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:04 PM
ENDING TIMING RUN AT 2019-05-23 07:45:58 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:14 PM
ENDING TIMING RUN AT 2019-05-23 07:45:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:07 PM
ENDING TIMING RUN AT 2019-05-23 07:45:47 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:04 PM
ENDING TIMING RUN AT 2019-05-23 07:45:53 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:10 PM
ENDING TIMING RUN AT 2019-05-23 07:45:46 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:03 PM
ENDING TIMING RUN AT 2019-05-23 07:45:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:05 PM
ENDING TIMING RUN AT 2019-05-23 07:45:47 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:04 PM
ENDING TIMING RUN AT 2019-05-23 07:45:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:06 PM
ENDING TIMING RUN AT 2019-05-23 07:45:48 PM
RESULT,SINGLE_STAGE_DETECTOR,,224,nvidia,2019-05-23 07:42:04 PM
ENDING TIMING RUN AT 2019-05-23 07:45:43 PM
RESULT,SINGLE_STAGE_DETECTOR,,223,nvidia,2019-05-23 07:42:00 PM
