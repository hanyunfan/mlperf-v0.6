Beginning trial 4 of 5
Gathering sys log on sc-sdgx-407
:::MLL 1558640754.808 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558640754.808 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558640754.809 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558640754.810 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558640754.811 submission_platform: {"value": "30xDGX-1 with V100", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558640754.811 submission_entry: {"value": "{'hardware': 'DGX-1 with V100', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.2 LTS / NVIDIA DGX Server 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz', 'num_cores': '40', 'num_vcpus': '80', 'accelerator': 'Tesla V100-SXM2-16GB', 'num_accelerators': '8', 'sys_mem_size': '503 GB', 'sys_storage_type': 'SATA SSD', 'sys_storage_size': '1x 7T + 1x 446.6G', 'cpu_accel_interconnect': 'QPI', 'network_card': 'Mellanox Technologies MT27700 Family [ConnectX-4]', 'num_network_cards': '4', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558640754.812 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558640754.812 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558640799.692 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640798.573 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640799.938 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640798.524 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640808.924 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640796.519 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640797.170 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640804.469 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640797.049 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640801.505 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640797.828 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640797.703 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640795.442 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640795.184 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640797.327 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640797.068 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640796.514 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640795.123 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640808.366 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640805.212 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640802.346 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640802.915 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640802.764 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640803.084 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640802.471 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640800.777 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640805.786 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640805.351 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640805.762 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558640805.503 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node sc-sdgx-407
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-408
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-414
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-407
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-415
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-408
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-416
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-407 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-408 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-414
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-417
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-415
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-414 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-416
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-418
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-415 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-416 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-423
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-417
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-424
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-418
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-417 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-423
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-425
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-418 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-423 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-424
+ set +x
Launching on node sc-sdgx-426
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-427
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-425
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-424 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-426
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-433
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-425 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-426 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-427
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-434
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-427 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-435
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-433
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-436
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-434
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-433 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-435
+ set +x
Launching on node sc-sdgx-441
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-434 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-442
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-436
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-435 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-441
Launching on node sc-sdgx-443
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-436 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-442
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-444
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-441 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-442 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-443
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-628
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-444
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-443 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-629
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-444 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-628
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-630
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-628 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-629
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-631
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-629 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
Launching on node sc-sdgx-632
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-630
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-630 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
Launching on node sc-sdgx-638
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-631
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-632
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-639
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-631 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-632 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-638
+ set +x
Launching on node sc-sdgx-640
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-638 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-641
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-639
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-640
+ set +x
Launching on node sc-sdgx-646
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-639 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-641
+ set +x
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-640 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-641 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-646
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-646 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:46:51 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:46:54 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:46:45 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:48 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:46:46 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:47 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:46 PM
STARTING TIMING RUN AT 2019-05-23 07:46:49 PM
running benchmark
running benchmark
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:48 PM
STARTING TIMING RUN AT 2019-05-23 07:46:54 PM
STARTING TIMING RUN AT 2019-05-23 07:46:48 PM
running benchmark
running benchmark
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:46:44 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ export TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:46:48 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:51 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:46:49 PM
STARTING TIMING RUN AT 2019-05-23 07:46:46 PM
running benchmark
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:46:45 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ NUMEPOCHS=80
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:46 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:46 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:46:48 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:46:50 PM
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 07:46:58 PM
+ echo 'running benchmark'
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:51 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:46 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:46:46 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:46:48 PM
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:44 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:46:47 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:46:48 PM
STARTING TIMING RUN AT 2019-05-23 07:46:44 PM
running benchmark
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558640811.743 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.743 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.743 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.743 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.744 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.744 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.744 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.744 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640811.101 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.101 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.101 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.101 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.101 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.101 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.101 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.102 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640814.973 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.973 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.973 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.974 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.974 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640814.976 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.976 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.976 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640812.659 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.659 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.659 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.660 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.661 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.661 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640812.662 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640808.166 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.166 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.166 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.166 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.166 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.166 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.166 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.167 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.664 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640812.275 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.275 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.276 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.277 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.277 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.277 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.277 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.277 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640810.533 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.533 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.533 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.533 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640810.535 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.535 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.535 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640810.536 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640808.848 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.848 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.848 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.848 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.850 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.850 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.850 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.850 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640814.693 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.693 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640814.695 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640814.695 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.696 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.696 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.696 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640814.696 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.551 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.551 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.551 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640812.553 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.553 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.553 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.553 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.553 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640809.894 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.894 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.894 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.894 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.896 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.896 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.896 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.896 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640811.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640810.800 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.801 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.801 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.801 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.482 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.482 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.802 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.802 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.802 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.803 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640810.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640810.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.217 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.217 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.217 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.217 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640812.218 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.218 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.218 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.484 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640810.484 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640812.219 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640812.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.917 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.918 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.918 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.918 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.918 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.919 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640815.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.196 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640815.196 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.345 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640810.346 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.346 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.346 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.347 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640813.820 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.821 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.821 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.821 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.821 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.821 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.822 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640813.823 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640809.805 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.806 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.806 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.808 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.808 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640809.808 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640809.809 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640809.810 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640822.804 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640822.804 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640822.804 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640822.805 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640822.805 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640822.805 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640822.805 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640822.805 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640818.890 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.890 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.890 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.890 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.891 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.892 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.892 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.892 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640818.395 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.395 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.395 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.395 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.396 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.397 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640818.397 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640818.398 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640810.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640810.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640810.484 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558640813.782 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.782 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.782 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.782 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.783 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.783 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.783 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640813.784 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640812.658 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.658 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.658 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.658 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.660 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.660 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.660 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640812.660 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640811.013 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.013 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.013 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.015 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.015 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640811.016 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.016 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.016 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640808.752 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.752 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.752 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.754 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.754 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558640808.755 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.755 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640808.755 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640811.243 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.243 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.243 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.243 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.245 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.245 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640811.245 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640811.246 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558640815.705 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.705 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.705 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.705 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.705 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.706 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.706 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558640815.706 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
1 Using seed = 1294090860
5 Using seed = 1294090864
0 Using seed = 1294090859
:::MLL 1558640828.286 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
3 Using seed = 1294090862
7 Using seed = 1294090866
6 Using seed = 1294090865
4 Using seed = 1294090863
15 Using seed = 1294090874
12 Using seed = 1294090871
14 Using seed = 1294090873
13 Using seed = 1294090872
10 Using seed = 1294090869
11 Using seed = 1294090870
9 Using seed = 1294090868
8 Using seed = 1294090867
23 Using seed = 1294090882
22 Using seed = 1294090881
20 Using seed = 1294090879
21 Using seed = 1294090880
18 Using seed = 1294090877
17 Using seed = 1294090876
19 Using seed = 1294090878
16 Using seed = 1294090875
29 Using seed = 1294090888
31 Using seed = 1294090890
30 Using seed = 1294090889
28 Using seed = 1294090887
25 Using seed = 1294090884
24 Using seed = 1294090883
26 Using seed = 1294090885
27 Using seed = 1294090886
37 Using seed = 1294090896
38 Using seed = 1294090897
36 Using seed = 1294090895
39 Using seed = 1294090898
34 Using seed = 1294090893
33 Using seed = 1294090892
35 Using seed = 1294090894
32 Using seed = 1294090891
45 Using seed = 1294090904
46 Using seed = 1294090905
47 Using seed = 1294090906
44 Using seed = 1294090903
41 Using seed = 1294090900
43 Using seed = 1294090902
40 Using seed = 1294090899
42 Using seed = 1294090901
51 Using seed = 1294090910
48 Using seed = 1294090907
50 Using seed = 1294090909
49 Using seed = 1294090908
55 Using seed = 1294090914
54 Using seed = 1294090913
53 Using seed = 1294090912
52 Using seed = 1294090911
61 Using seed = 1294090920
63 Using seed = 1294090922
60 Using seed = 1294090919
62 Using seed = 1294090921
58 Using seed = 1294090917
57 Using seed = 1294090916
59 Using seed = 1294090918
56 Using seed = 1294090915
70 Using seed = 1294090929
68 Using seed = 1294090927
69 Using seed = 1294090928
71 Using seed = 1294090930
65 Using seed = 1294090924
67 Using seed = 1294090926
64 Using seed = 1294090923
66 Using seed = 1294090925
79 Using seed = 1294090938
77 Using seed = 1294090936
78 Using seed = 1294090937
76 Using seed = 1294090935
72 Using seed = 1294090931
73 Using seed = 1294090932
75 Using seed = 1294090934
74 Using seed = 1294090933
85 Using seed = 1294090944
87 Using seed = 1294090946
84 Using seed = 1294090943
86 Using seed = 1294090945
82 Using seed = 1294090941
81 Using seed = 1294090940
80 Using seed = 1294090939
83 Using seed = 1294090942
88 Using seed = 1294090947
91 Using seed = 1294090950
90 Using seed = 1294090949
89 Using seed = 1294090948
95 Using seed = 1294090954
94 Using seed = 1294090953
93 Using seed = 1294090952
92 Using seed = 1294090951
96 Using seed = 1294090955
97 Using seed = 1294090956
98 Using seed = 1294090957
99 Using seed = 1294090958
101 Using seed = 1294090960
103 Using seed = 1294090962
100 Using seed = 1294090959
102 Using seed = 1294090961
109 Using seed = 1294090968
108 Using seed = 1294090967
111 Using seed = 1294090970
110 Using seed = 1294090969
104 Using seed = 1294090963
107 Using seed = 1294090966
105 Using seed = 1294090964
106 Using seed = 1294090965
117 Using seed = 1294090976
116 Using seed = 1294090975
119 Using seed = 1294090978
118 Using seed = 1294090977
113 Using seed = 1294090972
115 Using seed = 1294090974
112 Using seed = 1294090971
114 Using seed = 1294090973
124 Using seed = 1294090983
127 Using seed = 1294090986
126 Using seed = 1294090985
125 Using seed = 1294090984
122 Using seed = 1294090981
120 Using seed = 1294090979
121 Using seed = 1294090980
123 Using seed = 1294090982
132 Using seed = 1294090991
134 Using seed = 1294090993
135 Using seed = 1294090994
133 Using seed = 1294090992
129 Using seed = 1294090988
131 Using seed = 1294090990
128 Using seed = 1294090987
130 Using seed = 1294090989
143 Using seed = 1294091002
140 Using seed = 1294090999
142 Using seed = 1294091001
141 Using seed = 1294091000
139 Using seed = 1294090998
136 Using seed = 1294090995
138 Using seed = 1294090997
137 Using seed = 1294090996
144 Using seed = 1294091003
147 Using seed = 1294091006
145 Using seed = 1294091004
146 Using seed = 1294091005
150 Using seed = 1294091009
149 Using seed = 1294091008
148 Using seed = 1294091007
151 Using seed = 1294091010
155 Using seed = 1294091014
152 Using seed = 1294091011
154 Using seed = 1294091013
153 Using seed = 1294091012
158 Using seed = 1294091017
157 Using seed = 1294091016
159 Using seed = 1294091018
156 Using seed = 1294091015
165 Using seed = 1294091024
166 Using seed = 1294091025
167 Using seed = 1294091026
164 Using seed = 1294091023
161 Using seed = 1294091020
163 Using seed = 1294091022
162 Using seed = 1294091021
160 Using seed = 1294091019
172 Using seed = 1294091031
175 Using seed = 1294091034
174 Using seed = 1294091033
173 Using seed = 1294091032
168 Using seed = 1294091027
169 Using seed = 1294091028
171 Using seed = 1294091030
170 Using seed = 1294091029
176 Using seed = 1294091035
179 Using seed = 1294091038
177 Using seed = 1294091036
178 Using seed = 1294091037
181 Using seed = 1294091040
183 Using seed = 1294091042
182 Using seed = 1294091041
180 Using seed = 1294091039
185 Using seed = 1294091044
186 Using seed = 1294091045
184 Using seed = 1294091043
189 Using seed = 1294091048
191 Using seed = 1294091050
190 Using seed = 1294091049
187 Using seed = 1294091046
188 Using seed = 1294091047
197 Using seed = 1294091056
196 Using seed = 1294091055
198 Using seed = 1294091057
199 Using seed = 1294091058
194 Using seed = 1294091053
195 Using seed = 1294091054
193 Using seed = 1294091052
192 Using seed = 1294091051
206 Using seed = 1294091065
205 Using seed = 1294091064
204 Using seed = 1294091063
207 Using seed = 1294091066
200 Using seed = 1294091059
201 Using seed = 1294091060
202 Using seed = 1294091061
203 Using seed = 1294091062
212 Using seed = 1294091071
214 Using seed = 1294091073
215 Using seed = 1294091074
213 Using seed = 1294091072
210 Using seed = 1294091069
209 Using seed = 1294091068
211 Using seed = 1294091070
208 Using seed = 1294091067
217 Using seed = 1294091076
219 Using seed = 1294091078
216 Using seed = 1294091075
218 Using seed = 1294091077
223 Using seed = 1294091082
220 Using seed = 1294091079
222 Using seed = 1294091081
221 Using seed = 1294091080
230 Using seed = 1294091089
231 Using seed = 1294091090
229 Using seed = 1294091088
228 Using seed = 1294091087
225 Using seed = 1294091084
226 Using seed = 1294091085
227 Using seed = 1294091086
224 Using seed = 1294091083
233 Using seed = 1294091092
235 Using seed = 1294091094
234 Using seed = 1294091093
232 Using seed = 1294091091
238 Using seed = 1294091097
239 Using seed = 1294091098
236 Using seed = 1294091095
237 Using seed = 1294091096
2 Using seed = 1294090861
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1558640832.951 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558640832.952 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558640832.959 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1558640832.959 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1558640832.960 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558640832.960 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558640841.965 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558640841.965 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.48s)
Done (t=0.48s)
creating index...
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.55s)
creating index...
Done (t=0.57s)
creating index...
time_check a: 1558640835.861711502
time_check a: 1558640834.443767071
time_check a: 1558640836.027227402
time_check a: 1558640838.143007278
time_check a: 1558640838.301310539
time_check a: 1558640837.766436815
time_check a: 1558640840.946509838
time_check a: 1558640836.511556864
time_check a: 1558640843.805129528
time_check a: 1558640836.754945755
time_check a: 1558640838.464440584
time_check a: 1558640835.878174543
time_check a: 1558640835.314066887
time_check a: 1558640836.362283945
time_check a: 1558640839.163333893
time_check a: 1558640836.379440546
time_check a: 1558640833.820815563
time_check a: 1558640834.051667452
time_check a: 1558640840.309029579
time_check a: 1558640844.387287617
time_check a: 1558640840.647729635
time_check a: 1558640836.913520098
time_check a: 1558640839.365393162
time_check a: 1558640838.042373419
time_check a: 1558640835.493875027
time_check a: 1558640848.330226183
time_check a: 1558640836.189746380
time_check a: 1558640840.758290529
time_check a: 1558640837.965170145
time_check a: 1558640837.853255749
time_check b: 1558640851.959962368
time_check b: 1558640839.541879177
time_check b: 1558640844.300150871
time_check b: 1558640840.057206154
time_check b: 1558640840.203828335
time_check b: 1558640847.512626171
time_check b: 1558640841.732769728
time_check b: 1558640842.874790192
time_check b: 1558640841.492786646
time_check b: 1558640840.077460527
time_check b: 1558640844.674656868
time_check b: 1558640841.876689434
time_check b: 1558640837.774486065
time_check b: 1558640848.106411695
time_check b: 1558640841.506264687
time_check b: 1558640841.649376631
time_check b: 1558640842.209177494
time_check b: 1558640843.104559183
time_check b: 1558640840.659695864
time_check b: 1558640837.577293634
time_check b: 1558640839.235909462
time_check b: 1558640839.078371525
time_check b: 1558640840.524888992
time_check b: 1558640842.080458641
time_check b: 1558640839.654229403
time_check b: 1558640844.074549675
time_check b: 1558640844.518496037
time_check b: 1558640839.837612867
time_check b: 1558640838.254829884
time_check b: 1558640840.008256674
:::MLL 1558640848.667 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558640848.669 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 21.910, Average Loss: 0.022, avg. samples / sec: 135.63
Iteration:      0, Loss function: 22.304, Average Loss: 0.022, avg. samples / sec: 154.84
Iteration:      0, Loss function: 22.104, Average Loss: 0.022, avg. samples / sec: 132.34
Iteration:      0, Loss function: 22.746, Average Loss: 0.023, avg. samples / sec: 132.39
Iteration:      0, Loss function: 22.276, Average Loss: 0.022, avg. samples / sec: 132.36
Iteration:      0, Loss function: 23.767, Average Loss: 0.024, avg. samples / sec: 133.73
Iteration:      0, Loss function: 22.152, Average Loss: 0.022, avg. samples / sec: 131.15
Iteration:      0, Loss function: 22.069, Average Loss: 0.022, avg. samples / sec: 134.77
Iteration:      0, Loss function: 22.365, Average Loss: 0.022, avg. samples / sec: 132.41
Iteration:      0, Loss function: 22.318, Average Loss: 0.022, avg. samples / sec: 131.52
Iteration:      0, Loss function: 22.051, Average Loss: 0.022, avg. samples / sec: 132.60
Iteration:      0, Loss function: 22.513, Average Loss: 0.023, avg. samples / sec: 131.96
Iteration:      0, Loss function: 22.515, Average Loss: 0.023, avg. samples / sec: 132.40
Iteration:      0, Loss function: 22.042, Average Loss: 0.022, avg. samples / sec: 134.59
Iteration:      0, Loss function: 22.079, Average Loss: 0.022, avg. samples / sec: 134.33
Iteration:      0, Loss function: 21.724, Average Loss: 0.022, avg. samples / sec: 148.99
Iteration:      0, Loss function: 23.074, Average Loss: 0.023, avg. samples / sec: 132.55
Iteration:      0, Loss function: 22.542, Average Loss: 0.023, avg. samples / sec: 135.33
Iteration:      0, Loss function: 23.317, Average Loss: 0.023, avg. samples / sec: 131.09
Iteration:      0, Loss function: 22.254, Average Loss: 0.022, avg. samples / sec: 133.60
Iteration:      0, Loss function: 22.131, Average Loss: 0.022, avg. samples / sec: 132.16
Iteration:      0, Loss function: 23.247, Average Loss: 0.023, avg. samples / sec: 136.25
Iteration:      0, Loss function: 22.999, Average Loss: 0.023, avg. samples / sec: 134.18
Iteration:      0, Loss function: 22.323, Average Loss: 0.022, avg. samples / sec: 131.17
Iteration:      0, Loss function: 22.197, Average Loss: 0.022, avg. samples / sec: 130.86
Iteration:      0, Loss function: 22.146, Average Loss: 0.022, avg. samples / sec: 132.22
Iteration:      0, Loss function: 22.502, Average Loss: 0.023, avg. samples / sec: 131.85
Iteration:      0, Loss function: 22.091, Average Loss: 0.022, avg. samples / sec: 135.04
Iteration:      0, Loss function: 22.720, Average Loss: 0.023, avg. samples / sec: 164.26
Iteration:      0, Loss function: 22.438, Average Loss: 0.022, avg. samples / sec: 130.86
Iteration:     20, Loss function: 21.232, Average Loss: 0.447, avg. samples / sec: 33220.18
Iteration:     20, Loss function: 20.332, Average Loss: 0.440, avg. samples / sec: 30970.54
Iteration:     20, Loss function: 20.000, Average Loss: 0.442, avg. samples / sec: 33135.19
Iteration:     20, Loss function: 21.019, Average Loss: 0.443, avg. samples / sec: 33259.55
Iteration:     20, Loss function: 20.342, Average Loss: 0.440, avg. samples / sec: 32300.44
Iteration:     20, Loss function: 20.977, Average Loss: 0.440, avg. samples / sec: 32469.76
Iteration:     20, Loss function: 20.480, Average Loss: 0.444, avg. samples / sec: 32666.99
Iteration:     20, Loss function: 20.422, Average Loss: 0.442, avg. samples / sec: 32493.86
Iteration:     20, Loss function: 20.475, Average Loss: 0.441, avg. samples / sec: 34163.35
Iteration:     20, Loss function: 20.389, Average Loss: 0.441, avg. samples / sec: 32527.06
Iteration:     20, Loss function: 20.115, Average Loss: 0.441, avg. samples / sec: 31576.94
Iteration:     20, Loss function: 21.333, Average Loss: 0.444, avg. samples / sec: 31681.77
Iteration:     20, Loss function: 20.712, Average Loss: 0.445, avg. samples / sec: 32397.32
Iteration:     20, Loss function: 20.426, Average Loss: 0.444, avg. samples / sec: 31471.85
Iteration:     20, Loss function: 20.439, Average Loss: 0.444, avg. samples / sec: 32874.05
Iteration:     20, Loss function: 20.943, Average Loss: 0.442, avg. samples / sec: 33209.68
Iteration:     20, Loss function: 20.744, Average Loss: 0.442, avg. samples / sec: 32014.51
Iteration:     20, Loss function: 20.288, Average Loss: 0.442, avg. samples / sec: 33179.40
Iteration:     20, Loss function: 21.101, Average Loss: 0.440, avg. samples / sec: 31924.24
Iteration:     20, Loss function: 20.514, Average Loss: 0.446, avg. samples / sec: 32643.61
Iteration:     20, Loss function: 22.508, Average Loss: 0.445, avg. samples / sec: 31153.96
Iteration:     20, Loss function: 20.757, Average Loss: 0.441, avg. samples / sec: 35808.88
Iteration:     20, Loss function: 20.227, Average Loss: 0.442, avg. samples / sec: 33916.96
Iteration:     20, Loss function: 20.914, Average Loss: 0.442, avg. samples / sec: 31319.06
Iteration:     20, Loss function: 20.577, Average Loss: 0.440, avg. samples / sec: 33093.78
Iteration:     20, Loss function: 20.544, Average Loss: 0.442, avg. samples / sec: 31348.01
Iteration:     20, Loss function: 20.991, Average Loss: 0.450, avg. samples / sec: 31250.73
Iteration:     20, Loss function: 20.840, Average Loss: 0.442, avg. samples / sec: 31038.71
Iteration:     20, Loss function: 20.516, Average Loss: 0.443, avg. samples / sec: 31304.77
Iteration:     20, Loss function: 20.650, Average Loss: 0.444, avg. samples / sec: 33711.77
Iteration:     40, Loss function: 18.807, Average Loss: 0.833, avg. samples / sec: 48143.10
Iteration:     40, Loss function: 19.406, Average Loss: 0.837, avg. samples / sec: 48276.65
Iteration:     40, Loss function: 17.258, Average Loss: 0.826, avg. samples / sec: 48161.11
Iteration:     40, Loss function: 17.272, Average Loss: 0.826, avg. samples / sec: 48494.37
Iteration:     40, Loss function: 17.643, Average Loss: 0.832, avg. samples / sec: 48284.90
Iteration:     40, Loss function: 17.202, Average Loss: 0.831, avg. samples / sec: 48308.80
Iteration:     40, Loss function: 17.485, Average Loss: 0.828, avg. samples / sec: 48215.19
Iteration:     40, Loss function: 17.297, Average Loss: 0.821, avg. samples / sec: 48031.47
Iteration:     40, Loss function: 17.390, Average Loss: 0.827, avg. samples / sec: 48016.65
Iteration:     40, Loss function: 18.056, Average Loss: 0.823, avg. samples / sec: 48398.84
Iteration:     40, Loss function: 17.820, Average Loss: 0.826, avg. samples / sec: 48306.35
Iteration:     40, Loss function: 17.415, Average Loss: 0.827, avg. samples / sec: 48362.22
Iteration:     40, Loss function: 18.257, Average Loss: 0.830, avg. samples / sec: 48307.73
Iteration:     40, Loss function: 18.076, Average Loss: 0.831, avg. samples / sec: 48317.05
Iteration:     40, Loss function: 18.460, Average Loss: 0.827, avg. samples / sec: 47962.77
Iteration:     40, Loss function: 18.718, Average Loss: 0.834, avg. samples / sec: 48281.88
Iteration:     40, Loss function: 17.889, Average Loss: 0.828, avg. samples / sec: 48549.25
Iteration:     40, Loss function: 17.827, Average Loss: 0.827, avg. samples / sec: 48371.58
Iteration:     40, Loss function: 18.202, Average Loss: 0.828, avg. samples / sec: 48468.77
Iteration:     40, Loss function: 17.888, Average Loss: 0.825, avg. samples / sec: 47818.93
Iteration:     40, Loss function: 17.582, Average Loss: 0.826, avg. samples / sec: 47821.66
Iteration:     40, Loss function: 18.221, Average Loss: 0.827, avg. samples / sec: 48155.75
Iteration:     40, Loss function: 18.299, Average Loss: 0.831, avg. samples / sec: 48208.35
Iteration:     40, Loss function: 18.006, Average Loss: 0.829, avg. samples / sec: 47765.40
Iteration:     40, Loss function: 17.755, Average Loss: 0.836, avg. samples / sec: 48252.15
Iteration:     40, Loss function: 17.489, Average Loss: 0.828, avg. samples / sec: 47762.78
Iteration:     40, Loss function: 17.682, Average Loss: 0.829, avg. samples / sec: 47553.66
Iteration:     40, Loss function: 17.543, Average Loss: 0.824, avg. samples / sec: 47500.96
Iteration:     40, Loss function: 18.734, Average Loss: 0.828, avg. samples / sec: 47211.41
Iteration:     40, Loss function: 18.128, Average Loss: 0.830, avg. samples / sec: 47813.92
Iteration:     60, Loss function: 11.766, Average Loss: 1.089, avg. samples / sec: 49523.03
Iteration:     60, Loss function: 11.993, Average Loss: 1.090, avg. samples / sec: 49197.50
Iteration:     60, Loss function: 13.643, Average Loss: 1.099, avg. samples / sec: 49708.67
Iteration:     60, Loss function: 13.039, Average Loss: 1.093, avg. samples / sec: 49280.20
Iteration:     60, Loss function: 11.362, Average Loss: 1.080, avg. samples / sec: 49361.55
Iteration:     60, Loss function: 11.607, Average Loss: 1.092, avg. samples / sec: 49292.08
Iteration:     60, Loss function: 12.739, Average Loss: 1.084, avg. samples / sec: 49373.76
Iteration:     60, Loss function: 12.465, Average Loss: 1.081, avg. samples / sec: 49386.29
Iteration:     60, Loss function: 13.271, Average Loss: 1.086, avg. samples / sec: 49166.22
Iteration:     60, Loss function: 13.060, Average Loss: 1.078, avg. samples / sec: 49219.96
Iteration:     60, Loss function: 12.395, Average Loss: 1.084, avg. samples / sec: 49392.55
Iteration:     60, Loss function: 11.227, Average Loss: 1.080, avg. samples / sec: 49866.34
Iteration:     60, Loss function: 12.037, Average Loss: 1.088, avg. samples / sec: 50127.82
Iteration:     60, Loss function: 11.928, Average Loss: 1.083, avg. samples / sec: 49220.62
Iteration:     60, Loss function: 13.353, Average Loss: 1.086, avg. samples / sec: 49217.90
Iteration:     60, Loss function: 11.947, Average Loss: 1.086, avg. samples / sec: 49244.52
Iteration:     60, Loss function: 11.997, Average Loss: 1.082, avg. samples / sec: 49356.50
Iteration:     60, Loss function: 11.827, Average Loss: 1.090, avg. samples / sec: 49217.19
Iteration:     60, Loss function: 12.255, Average Loss: 1.090, avg. samples / sec: 49099.80
Iteration:     60, Loss function: 12.628, Average Loss: 1.086, avg. samples / sec: 50006.52
Iteration:     60, Loss function: 13.013, Average Loss: 1.086, avg. samples / sec: 49119.06
Iteration:     60, Loss function: 12.312, Average Loss: 1.084, avg. samples / sec: 49432.51
Iteration:     60, Loss function: 12.318, Average Loss: 1.091, avg. samples / sec: 48845.88
Iteration:     60, Loss function: 12.789, Average Loss: 1.080, avg. samples / sec: 49206.47
Iteration:     60, Loss function: 11.367, Average Loss: 1.078, avg. samples / sec: 48835.38
Iteration:     60, Loss function: 12.797, Average Loss: 1.080, avg. samples / sec: 49127.62
Iteration:     60, Loss function: 12.556, Average Loss: 1.082, avg. samples / sec: 49170.68
Iteration:     60, Loss function: 11.234, Average Loss: 1.081, avg. samples / sec: 49089.18
Iteration:     60, Loss function: 13.294, Average Loss: 1.081, avg. samples / sec: 49265.85
Iteration:     60, Loss function: 11.872, Average Loss: 1.084, avg. samples / sec: 48684.78
:::MLL 1558640852.294 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558640852.295 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 9.757, Average Loss: 1.284, avg. samples / sec: 52422.17
Iteration:     80, Loss function: 9.308, Average Loss: 1.274, avg. samples / sec: 52527.48
Iteration:     80, Loss function: 10.162, Average Loss: 1.281, avg. samples / sec: 52233.31
Iteration:     80, Loss function: 10.703, Average Loss: 1.278, avg. samples / sec: 52592.13
Iteration:     80, Loss function: 9.723, Average Loss: 1.274, avg. samples / sec: 52553.99
Iteration:     80, Loss function: 10.045, Average Loss: 1.273, avg. samples / sec: 52604.11
Iteration:     80, Loss function: 10.720, Average Loss: 1.291, avg. samples / sec: 52246.69
Iteration:     80, Loss function: 11.374, Average Loss: 1.276, avg. samples / sec: 52676.17
Iteration:     80, Loss function: 10.393, Average Loss: 1.276, avg. samples / sec: 53083.96
Iteration:     80, Loss function: 10.365, Average Loss: 1.280, avg. samples / sec: 52166.26
Iteration:     80, Loss function: 10.768, Average Loss: 1.262, avg. samples / sec: 52580.24
Iteration:     80, Loss function: 10.416, Average Loss: 1.272, avg. samples / sec: 52979.31
Iteration:     80, Loss function: 10.662, Average Loss: 1.272, avg. samples / sec: 52163.46
Iteration:     80, Loss function: 9.834, Average Loss: 1.289, avg. samples / sec: 52386.33
Iteration:     80, Loss function: 9.838, Average Loss: 1.278, avg. samples / sec: 52367.84
Iteration:     80, Loss function: 9.424, Average Loss: 1.266, avg. samples / sec: 52240.83
Iteration:     80, Loss function: 10.854, Average Loss: 1.281, avg. samples / sec: 52235.95
Iteration:     80, Loss function: 10.509, Average Loss: 1.278, avg. samples / sec: 52053.79
Iteration:     80, Loss function: 9.829, Average Loss: 1.273, avg. samples / sec: 52506.92
Iteration:     80, Loss function: 10.276, Average Loss: 1.282, avg. samples / sec: 52377.10
Iteration:     80, Loss function: 9.907, Average Loss: 1.276, avg. samples / sec: 52160.76
Iteration:     80, Loss function: 9.193, Average Loss: 1.274, avg. samples / sec: 52442.20
Iteration:     80, Loss function: 10.448, Average Loss: 1.272, avg. samples / sec: 52231.96
Iteration:     80, Loss function: 10.249, Average Loss: 1.276, avg. samples / sec: 52023.66
Iteration:     80, Loss function: 10.480, Average Loss: 1.284, avg. samples / sec: 52074.28
Iteration:     80, Loss function: 11.832, Average Loss: 1.289, avg. samples / sec: 51831.66
Iteration:     80, Loss function: 9.993, Average Loss: 1.268, avg. samples / sec: 52184.01
Iteration:     80, Loss function: 9.471, Average Loss: 1.278, avg. samples / sec: 51856.70
Iteration:     80, Loss function: 9.762, Average Loss: 1.274, avg. samples / sec: 51450.55
Iteration:     80, Loss function: 9.864, Average Loss: 1.277, avg. samples / sec: 51328.99
Iteration:    100, Loss function: 8.445, Average Loss: 1.459, avg. samples / sec: 51497.72
Iteration:    100, Loss function: 9.918, Average Loss: 1.445, avg. samples / sec: 51350.40
Iteration:    100, Loss function: 9.182, Average Loss: 1.447, avg. samples / sec: 51615.06
Iteration:    100, Loss function: 9.794, Average Loss: 1.447, avg. samples / sec: 51197.45
Iteration:    100, Loss function: 9.681, Average Loss: 1.447, avg. samples / sec: 51299.49
Iteration:    100, Loss function: 10.335, Average Loss: 1.464, avg. samples / sec: 51717.07
Iteration:    100, Loss function: 9.927, Average Loss: 1.453, avg. samples / sec: 51275.84
Iteration:    100, Loss function: 9.657, Average Loss: 1.446, avg. samples / sec: 52145.67
Iteration:    100, Loss function: 9.955, Average Loss: 1.445, avg. samples / sec: 51372.27
Iteration:    100, Loss function: 9.896, Average Loss: 1.456, avg. samples / sec: 51069.53
Iteration:    100, Loss function: 9.835, Average Loss: 1.451, avg. samples / sec: 51616.32
Iteration:    100, Loss function: 9.585, Average Loss: 1.434, avg. samples / sec: 51137.95
Iteration:    100, Loss function: 9.867, Average Loss: 1.459, avg. samples / sec: 50906.86
Iteration:    100, Loss function: 9.654, Average Loss: 1.447, avg. samples / sec: 51351.92
Iteration:    100, Loss function: 9.049, Average Loss: 1.437, avg. samples / sec: 51471.24
Iteration:    100, Loss function: 9.881, Average Loss: 1.444, avg. samples / sec: 51078.75
Iteration:    100, Loss function: 10.107, Average Loss: 1.450, avg. samples / sec: 50945.19
Iteration:    100, Loss function: 9.958, Average Loss: 1.450, avg. samples / sec: 50823.31
Iteration:    100, Loss function: 9.858, Average Loss: 1.448, avg. samples / sec: 51064.48
Iteration:    100, Loss function: 9.438, Average Loss: 1.451, avg. samples / sec: 50953.79
Iteration:    100, Loss function: 10.023, Average Loss: 1.448, avg. samples / sec: 50722.34
Iteration:    100, Loss function: 9.612, Average Loss: 1.460, avg. samples / sec: 51038.72
Iteration:    100, Loss function: 8.783, Average Loss: 1.454, avg. samples / sec: 50668.05
Iteration:    100, Loss function: 9.016, Average Loss: 1.437, avg. samples / sec: 50589.26
Iteration:    100, Loss function: 9.905, Average Loss: 1.462, avg. samples / sec: 50368.96
Iteration:    100, Loss function: 9.511, Average Loss: 1.449, avg. samples / sec: 50426.83
Iteration:    100, Loss function: 9.938, Average Loss: 1.451, avg. samples / sec: 50231.22
Iteration:    100, Loss function: 9.909, Average Loss: 1.451, avg. samples / sec: 51158.50
Iteration:    100, Loss function: 9.818, Average Loss: 1.451, avg. samples / sec: 50009.91
Iteration:    100, Loss function: 9.873, Average Loss: 1.451, avg. samples / sec: 49567.84
Iteration:    120, Loss function: 8.501, Average Loss: 1.612, avg. samples / sec: 50186.93
Iteration:    120, Loss function: 9.334, Average Loss: 1.605, avg. samples / sec: 51088.17
Iteration:    120, Loss function: 9.135, Average Loss: 1.589, avg. samples / sec: 50809.53
Iteration:    120, Loss function: 10.320, Average Loss: 1.599, avg. samples / sec: 49959.41
Iteration:    120, Loss function: 9.169, Average Loss: 1.614, avg. samples / sec: 49926.78
Iteration:    120, Loss function: 10.162, Average Loss: 1.602, avg. samples / sec: 50229.77
Iteration:    120, Loss function: 9.351, Average Loss: 1.600, avg. samples / sec: 50015.96
Iteration:    120, Loss function: 9.236, Average Loss: 1.601, avg. samples / sec: 51045.89
Iteration:    120, Loss function: 8.764, Average Loss: 1.597, avg. samples / sec: 49729.74
Iteration:    120, Loss function: 9.258, Average Loss: 1.602, avg. samples / sec: 51018.74
Iteration:    120, Loss function: 8.420, Average Loss: 1.596, avg. samples / sec: 49707.66
Iteration:    120, Loss function: 8.414, Average Loss: 1.597, avg. samples / sec: 50318.83
Iteration:    120, Loss function: 9.300, Average Loss: 1.600, avg. samples / sec: 50369.07
Iteration:    120, Loss function: 9.675, Average Loss: 1.597, avg. samples / sec: 49994.84
Iteration:    120, Loss function: 9.652, Average Loss: 1.602, avg. samples / sec: 50393.74
Iteration:    120, Loss function: 8.313, Average Loss: 1.596, avg. samples / sec: 49871.07
Iteration:    120, Loss function: 9.275, Average Loss: 1.594, avg. samples / sec: 49992.02
Iteration:    120, Loss function: 8.253, Average Loss: 1.583, avg. samples / sec: 49925.95
Iteration:    120, Loss function: 8.662, Average Loss: 1.605, avg. samples / sec: 50836.34
Iteration:    120, Loss function: 8.884, Average Loss: 1.597, avg. samples / sec: 49653.35
Iteration:    120, Loss function: 8.728, Average Loss: 1.602, avg. samples / sec: 49645.74
Iteration:    120, Loss function: 10.086, Average Loss: 1.610, avg. samples / sec: 49766.65
Iteration:    120, Loss function: 10.268, Average Loss: 1.602, avg. samples / sec: 49861.68
Iteration:    120, Loss function: 9.335, Average Loss: 1.597, avg. samples / sec: 49758.73
Iteration:    120, Loss function: 8.612, Average Loss: 1.613, avg. samples / sec: 50280.56
Iteration:    120, Loss function: 9.251, Average Loss: 1.608, avg. samples / sec: 50033.08
Iteration:    120, Loss function: 8.473, Average Loss: 1.596, avg. samples / sec: 49370.18
Iteration:    120, Loss function: 9.306, Average Loss: 1.614, avg. samples / sec: 49774.37
Iteration:    120, Loss function: 8.429, Average Loss: 1.610, avg. samples / sec: 48890.72
Iteration:    120, Loss function: 8.697, Average Loss: 1.602, avg. samples / sec: 50437.19
:::MLL 1558640854.602 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558640854.603 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 8.532, Average Loss: 1.746, avg. samples / sec: 51464.68
Iteration:    140, Loss function: 8.837, Average Loss: 1.753, avg. samples / sec: 50762.02
Iteration:    140, Loss function: 9.028, Average Loss: 1.742, avg. samples / sec: 50913.70
Iteration:    140, Loss function: 8.708, Average Loss: 1.744, avg. samples / sec: 50708.90
Iteration:    140, Loss function: 7.982, Average Loss: 1.761, avg. samples / sec: 51426.57
Iteration:    140, Loss function: 8.733, Average Loss: 1.745, avg. samples / sec: 51105.48
Iteration:    140, Loss function: 8.533, Average Loss: 1.741, avg. samples / sec: 50664.40
Iteration:    140, Loss function: 8.450, Average Loss: 1.743, avg. samples / sec: 51193.49
Iteration:    140, Loss function: 9.367, Average Loss: 1.744, avg. samples / sec: 50762.64
Iteration:    140, Loss function: 8.717, Average Loss: 1.755, avg. samples / sec: 51500.30
Iteration:    140, Loss function: 9.186, Average Loss: 1.740, avg. samples / sec: 51119.08
Iteration:    140, Loss function: 8.737, Average Loss: 1.752, avg. samples / sec: 50501.24
Iteration:    140, Loss function: 8.004, Average Loss: 1.738, avg. samples / sec: 50719.47
Iteration:    140, Loss function: 8.584, Average Loss: 1.737, avg. samples / sec: 50703.63
Iteration:    140, Loss function: 9.032, Average Loss: 1.739, avg. samples / sec: 50815.39
Iteration:    140, Loss function: 8.669, Average Loss: 1.742, avg. samples / sec: 50619.56
Iteration:    140, Loss function: 9.689, Average Loss: 1.742, avg. samples / sec: 50697.67
Iteration:    140, Loss function: 9.144, Average Loss: 1.743, avg. samples / sec: 50567.78
Iteration:    140, Loss function: 10.213, Average Loss: 1.726, avg. samples / sec: 50736.03
Iteration:    140, Loss function: 8.593, Average Loss: 1.738, avg. samples / sec: 51239.84
Iteration:    140, Loss function: 8.888, Average Loss: 1.740, avg. samples / sec: 50594.23
Iteration:    140, Loss function: 8.566, Average Loss: 1.736, avg. samples / sec: 50664.75
Iteration:    140, Loss function: 7.720, Average Loss: 1.741, avg. samples / sec: 50612.40
Iteration:    140, Loss function: 8.807, Average Loss: 1.729, avg. samples / sec: 50229.72
Iteration:    140, Loss function: 8.538, Average Loss: 1.754, avg. samples / sec: 50936.63
Iteration:    140, Loss function: 9.000, Average Loss: 1.745, avg. samples / sec: 50055.22
Iteration:    140, Loss function: 8.764, Average Loss: 1.751, avg. samples / sec: 50264.96
Iteration:    140, Loss function: 8.781, Average Loss: 1.744, avg. samples / sec: 50050.90
Iteration:    140, Loss function: 8.231, Average Loss: 1.732, avg. samples / sec: 49915.12
Iteration:    140, Loss function: 8.447, Average Loss: 1.741, avg. samples / sec: 50683.48
Iteration:    160, Loss function: 8.175, Average Loss: 1.895, avg. samples / sec: 52572.57
Iteration:    160, Loss function: 8.053, Average Loss: 1.890, avg. samples / sec: 53228.66
Iteration:    160, Loss function: 9.165, Average Loss: 1.882, avg. samples / sec: 52527.78
Iteration:    160, Loss function: 8.823, Average Loss: 1.889, avg. samples / sec: 52433.31
Iteration:    160, Loss function: 8.501, Average Loss: 1.879, avg. samples / sec: 52665.58
Iteration:    160, Loss function: 8.542, Average Loss: 1.895, avg. samples / sec: 52558.51
Iteration:    160, Loss function: 7.621, Average Loss: 1.880, avg. samples / sec: 52402.40
Iteration:    160, Loss function: 8.809, Average Loss: 1.875, avg. samples / sec: 52540.62
Iteration:    160, Loss function: 8.439, Average Loss: 1.870, avg. samples / sec: 52568.91
Iteration:    160, Loss function: 8.690, Average Loss: 1.884, avg. samples / sec: 53218.65
Iteration:    160, Loss function: 7.652, Average Loss: 1.888, avg. samples / sec: 52331.44
Iteration:    160, Loss function: 8.060, Average Loss: 1.874, avg. samples / sec: 52538.33
Iteration:    160, Loss function: 8.514, Average Loss: 1.881, avg. samples / sec: 52280.11
Iteration:    160, Loss function: 8.985, Average Loss: 1.868, avg. samples / sec: 52518.97
Iteration:    160, Loss function: 9.005, Average Loss: 1.867, avg. samples / sec: 52766.94
Iteration:    160, Loss function: 8.415, Average Loss: 1.878, avg. samples / sec: 53848.80
Iteration:    160, Loss function: 8.572, Average Loss: 1.877, avg. samples / sec: 53102.76
Iteration:    160, Loss function: 8.564, Average Loss: 1.880, avg. samples / sec: 52051.54
Iteration:    160, Loss function: 8.763, Average Loss: 1.880, avg. samples / sec: 52274.25
Iteration:    160, Loss function: 8.022, Average Loss: 1.873, avg. samples / sec: 53119.43
Iteration:    160, Loss function: 7.772, Average Loss: 1.870, avg. samples / sec: 52280.38
Iteration:    160, Loss function: 7.999, Average Loss: 1.891, avg. samples / sec: 52920.74
Iteration:    160, Loss function: 7.981, Average Loss: 1.881, avg. samples / sec: 52146.78
Iteration:    160, Loss function: 8.065, Average Loss: 1.897, avg. samples / sec: 51850.38
Iteration:    160, Loss function: 8.934, Average Loss: 1.881, avg. samples / sec: 52014.43
Iteration:    160, Loss function: 8.645, Average Loss: 1.880, avg. samples / sec: 51690.71
Iteration:    160, Loss function: 8.553, Average Loss: 1.877, avg. samples / sec: 51804.83
Iteration:    160, Loss function: 9.462, Average Loss: 1.885, avg. samples / sec: 51595.88
Iteration:    160, Loss function: 7.543, Average Loss: 1.881, avg. samples / sec: 51538.61
Iteration:    160, Loss function: 8.205, Average Loss: 1.877, avg. samples / sec: 51205.86
Iteration:    180, Loss function: 8.313, Average Loss: 2.012, avg. samples / sec: 51918.67
Iteration:    180, Loss function: 9.636, Average Loss: 2.021, avg. samples / sec: 51848.49
Iteration:    180, Loss function: 7.523, Average Loss: 2.010, avg. samples / sec: 51930.07
Iteration:    180, Loss function: 8.292, Average Loss: 1.995, avg. samples / sec: 51909.05
Iteration:    180, Loss function: 7.867, Average Loss: 2.009, avg. samples / sec: 52572.12
Iteration:    180, Loss function: 7.518, Average Loss: 2.004, avg. samples / sec: 52185.56
Iteration:    180, Loss function: 9.221, Average Loss: 2.024, avg. samples / sec: 51732.87
Iteration:    180, Loss function: 8.363, Average Loss: 2.018, avg. samples / sec: 52234.17
Iteration:    180, Loss function: 8.107, Average Loss: 2.007, avg. samples / sec: 52540.45
Iteration:    180, Loss function: 8.500, Average Loss: 2.018, avg. samples / sec: 51770.76
Iteration:    180, Loss function: 7.908, Average Loss: 2.003, avg. samples / sec: 51814.05
Iteration:    180, Loss function: 8.008, Average Loss: 2.016, avg. samples / sec: 52665.23
Iteration:    180, Loss function: 9.408, Average Loss: 2.026, avg. samples / sec: 51755.59
Iteration:    180, Loss function: 8.181, Average Loss: 2.017, avg. samples / sec: 51818.66
Iteration:    180, Loss function: 8.489, Average Loss: 2.001, avg. samples / sec: 51834.82
Iteration:    180, Loss function: 7.569, Average Loss: 2.002, avg. samples / sec: 51734.37
Iteration:    180, Loss function: 8.719, Average Loss: 2.010, avg. samples / sec: 52299.61
Iteration:    180, Loss function: 7.700, Average Loss: 1.995, avg. samples / sec: 51774.95
Iteration:    180, Loss function: 9.081, Average Loss: 2.009, avg. samples / sec: 51841.13
Iteration:    180, Loss function: 8.894, Average Loss: 1.993, avg. samples / sec: 51725.83
Iteration:    180, Loss function: 8.054, Average Loss: 2.026, avg. samples / sec: 52143.29
Iteration:    180, Loss function: 8.347, Average Loss: 2.007, avg. samples / sec: 52758.88
Iteration:    180, Loss function: 8.206, Average Loss: 2.003, avg. samples / sec: 53031.48
Iteration:    180, Loss function: 8.268, Average Loss: 2.010, avg. samples / sec: 52034.03
Iteration:    180, Loss function: 7.766, Average Loss: 2.001, avg. samples / sec: 51939.51
Iteration:    180, Loss function: 8.383, Average Loss: 2.008, avg. samples / sec: 51614.39
Iteration:    180, Loss function: 8.330, Average Loss: 1.998, avg. samples / sec: 51868.19
Iteration:    180, Loss function: 7.973, Average Loss: 2.011, avg. samples / sec: 51505.83
Iteration:    180, Loss function: 8.272, Average Loss: 2.008, avg. samples / sec: 51549.00
Iteration:    180, Loss function: 7.294, Average Loss: 2.010, avg. samples / sec: 51225.05
Iteration:    200, Loss function: 8.491, Average Loss: 2.141, avg. samples / sec: 53129.30
Iteration:    200, Loss function: 8.598, Average Loss: 2.134, avg. samples / sec: 53637.46
Iteration:    200, Loss function: 9.165, Average Loss: 2.143, avg. samples / sec: 53047.79
Iteration:    200, Loss function: 8.796, Average Loss: 2.127, avg. samples / sec: 53260.20
Iteration:    200, Loss function: 9.134, Average Loss: 2.135, avg. samples / sec: 53115.67
Iteration:    200, Loss function: 8.227, Average Loss: 2.125, avg. samples / sec: 53004.43
Iteration:    200, Loss function: 8.401, Average Loss: 2.146, avg. samples / sec: 52758.84
Iteration:    200, Loss function: 7.262, Average Loss: 2.131, avg. samples / sec: 52818.67
Iteration:    200, Loss function: 7.986, Average Loss: 2.136, avg. samples / sec: 52746.22
Iteration:    200, Loss function: 8.904, Average Loss: 2.128, avg. samples / sec: 52872.75
Iteration:    200, Loss function: 7.527, Average Loss: 2.125, avg. samples / sec: 52898.89
Iteration:    200, Loss function: 9.143, Average Loss: 2.144, avg. samples / sec: 52847.95
Iteration:    200, Loss function: 7.908, Average Loss: 2.135, avg. samples / sec: 53194.72
Iteration:    200, Loss function: 7.364, Average Loss: 2.155, avg. samples / sec: 53022.40
Iteration:    200, Loss function: 8.707, Average Loss: 2.130, avg. samples / sec: 52771.09
Iteration:    200, Loss function: 8.178, Average Loss: 2.132, avg. samples / sec: 53061.95
Iteration:    200, Loss function: 8.564, Average Loss: 2.150, avg. samples / sec: 52734.10
Iteration:    200, Loss function: 8.015, Average Loss: 2.133, avg. samples / sec: 53664.32
Iteration:    200, Loss function: 7.426, Average Loss: 2.135, avg. samples / sec: 52853.87
Iteration:    200, Loss function: 8.404, Average Loss: 2.122, avg. samples / sec: 52852.11
Iteration:    200, Loss function: 8.517, Average Loss: 2.126, avg. samples / sec: 52860.49
Iteration:    200, Loss function: 8.655, Average Loss: 2.119, avg. samples / sec: 52535.88
Iteration:    200, Loss function: 8.288, Average Loss: 2.133, avg. samples / sec: 52836.83
Iteration:    200, Loss function: 8.016, Average Loss: 2.132, avg. samples / sec: 52850.90
Iteration:    200, Loss function: 7.475, Average Loss: 2.120, avg. samples / sec: 52934.33
Iteration:    200, Loss function: 7.647, Average Loss: 2.126, avg. samples / sec: 52523.31
Iteration:    200, Loss function: 8.647, Average Loss: 2.118, avg. samples / sec: 52503.90
Iteration:    200, Loss function: 7.508, Average Loss: 2.153, avg. samples / sec: 52270.65
Iteration:    200, Loss function: 7.798, Average Loss: 2.133, avg. samples / sec: 52075.33
Iteration:    200, Loss function: 9.323, Average Loss: 2.145, avg. samples / sec: 51833.52
:::MLL 1558640856.847 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558640856.847 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 7.911, Average Loss: 2.233, avg. samples / sec: 53500.48
Iteration:    220, Loss function: 8.088, Average Loss: 2.242, avg. samples / sec: 53063.67
Iteration:    220, Loss function: 8.272, Average Loss: 2.259, avg. samples / sec: 53093.56
Iteration:    220, Loss function: 8.882, Average Loss: 2.247, avg. samples / sec: 53044.63
Iteration:    220, Loss function: 7.942, Average Loss: 2.250, avg. samples / sec: 52905.22
Iteration:    220, Loss function: 8.611, Average Loss: 2.248, avg. samples / sec: 53035.03
Iteration:    220, Loss function: 8.770, Average Loss: 2.268, avg. samples / sec: 53169.53
Iteration:    220, Loss function: 7.217, Average Loss: 2.257, avg. samples / sec: 52842.34
Iteration:    220, Loss function: 7.125, Average Loss: 2.268, avg. samples / sec: 53012.17
Iteration:    220, Loss function: 8.017, Average Loss: 2.243, avg. samples / sec: 52943.84
Iteration:    220, Loss function: 7.776, Average Loss: 2.262, avg. samples / sec: 52972.14
Iteration:    220, Loss function: 7.543, Average Loss: 2.271, avg. samples / sec: 53522.30
Iteration:    220, Loss function: 8.038, Average Loss: 2.248, avg. samples / sec: 53005.37
Iteration:    220, Loss function: 8.183, Average Loss: 2.260, avg. samples / sec: 52665.86
Iteration:    220, Loss function: 8.273, Average Loss: 2.250, avg. samples / sec: 53477.44
Iteration:    220, Loss function: 8.023, Average Loss: 2.237, avg. samples / sec: 53073.08
Iteration:    220, Loss function: 7.394, Average Loss: 2.239, avg. samples / sec: 52844.48
Iteration:    220, Loss function: 8.078, Average Loss: 2.246, avg. samples / sec: 52895.65
Iteration:    220, Loss function: 7.361, Average Loss: 2.247, avg. samples / sec: 52643.07
Iteration:    220, Loss function: 8.298, Average Loss: 2.250, avg. samples / sec: 52801.71
Iteration:    220, Loss function: 7.494, Average Loss: 2.244, avg. samples / sec: 52992.50
Iteration:    220, Loss function: 7.982, Average Loss: 2.234, avg. samples / sec: 53267.85
Iteration:    220, Loss function: 7.645, Average Loss: 2.248, avg. samples / sec: 52991.30
Iteration:    220, Loss function: 7.547, Average Loss: 2.251, avg. samples / sec: 52927.85
Iteration:    220, Loss function: 7.614, Average Loss: 2.244, avg. samples / sec: 52900.12
Iteration:    220, Loss function: 7.920, Average Loss: 2.234, avg. samples / sec: 52912.97
Iteration:    220, Loss function: 7.177, Average Loss: 2.240, avg. samples / sec: 52484.31
Iteration:    220, Loss function: 6.866, Average Loss: 2.246, avg. samples / sec: 52784.03
Iteration:    220, Loss function: 7.324, Average Loss: 2.257, avg. samples / sec: 53126.44
Iteration:    220, Loss function: 8.327, Average Loss: 2.241, avg. samples / sec: 51999.32
Iteration:    240, Loss function: 7.994, Average Loss: 2.356, avg. samples / sec: 52690.09
Iteration:    240, Loss function: 7.686, Average Loss: 2.358, avg. samples / sec: 52700.12
Iteration:    240, Loss function: 8.889, Average Loss: 2.358, avg. samples / sec: 53034.29
Iteration:    240, Loss function: 8.518, Average Loss: 2.366, avg. samples / sec: 52715.64
Iteration:    240, Loss function: 7.712, Average Loss: 2.367, avg. samples / sec: 52719.23
Iteration:    240, Loss function: 8.921, Average Loss: 2.375, avg. samples / sec: 52579.79
Iteration:    240, Loss function: 7.814, Average Loss: 2.355, avg. samples / sec: 52620.71
Iteration:    240, Loss function: 8.491, Average Loss: 2.343, avg. samples / sec: 52397.53
Iteration:    240, Loss function: 8.901, Average Loss: 2.366, avg. samples / sec: 52705.62
Iteration:    240, Loss function: 8.581, Average Loss: 2.351, avg. samples / sec: 52744.90
Iteration:    240, Loss function: 8.554, Average Loss: 2.371, avg. samples / sec: 52680.64
Iteration:    240, Loss function: 8.257, Average Loss: 2.357, avg. samples / sec: 52654.13
Iteration:    240, Loss function: 7.840, Average Loss: 2.379, avg. samples / sec: 52644.55
Iteration:    240, Loss function: 8.330, Average Loss: 2.355, avg. samples / sec: 52820.75
Iteration:    240, Loss function: 8.132, Average Loss: 2.377, avg. samples / sec: 52612.32
Iteration:    240, Loss function: 9.052, Average Loss: 2.345, avg. samples / sec: 52797.82
Iteration:    240, Loss function: 9.191, Average Loss: 2.360, avg. samples / sec: 52745.21
Iteration:    240, Loss function: 8.539, Average Loss: 2.352, avg. samples / sec: 52704.03
Iteration:    240, Loss function: 7.866, Average Loss: 2.382, avg. samples / sec: 52558.57
Iteration:    240, Loss function: 8.378, Average Loss: 2.350, avg. samples / sec: 53736.86
Iteration:    240, Loss function: 7.556, Average Loss: 2.361, avg. samples / sec: 52688.44
Iteration:    240, Loss function: 7.416, Average Loss: 2.355, avg. samples / sec: 52616.87
Iteration:    240, Loss function: 8.716, Average Loss: 2.350, avg. samples / sec: 52764.72
Iteration:    240, Loss function: 8.027, Average Loss: 2.360, avg. samples / sec: 52661.70
Iteration:    240, Loss function: 7.775, Average Loss: 2.377, avg. samples / sec: 52357.28
Iteration:    240, Loss function: 7.808, Average Loss: 2.372, avg. samples / sec: 53235.85
Iteration:    240, Loss function: 7.302, Average Loss: 2.362, avg. samples / sec: 52348.70
Iteration:    240, Loss function: 7.267, Average Loss: 2.359, avg. samples / sec: 52667.17
Iteration:    240, Loss function: 7.692, Average Loss: 2.355, avg. samples / sec: 52145.76
Iteration:    240, Loss function: 8.770, Average Loss: 2.363, avg. samples / sec: 51985.45
Iteration:    260, Loss function: 7.791, Average Loss: 2.482, avg. samples / sec: 52127.09
Iteration:    260, Loss function: 7.696, Average Loss: 2.465, avg. samples / sec: 51877.14
Iteration:    260, Loss function: 8.128, Average Loss: 2.482, avg. samples / sec: 51572.18
Iteration:    260, Loss function: 7.578, Average Loss: 2.470, avg. samples / sec: 51438.01
Iteration:    260, Loss function: 7.523, Average Loss: 2.476, avg. samples / sec: 51487.71
Iteration:    260, Loss function: 7.861, Average Loss: 2.491, avg. samples / sec: 51529.47
Iteration:    260, Loss function: 7.550, Average Loss: 2.463, avg. samples / sec: 51573.31
Iteration:    260, Loss function: 7.741, Average Loss: 2.486, avg. samples / sec: 51579.82
Iteration:    260, Loss function: 7.384, Average Loss: 2.488, avg. samples / sec: 51628.86
Iteration:    260, Loss function: 7.798, Average Loss: 2.497, avg. samples / sec: 51613.03
Iteration:    260, Loss function: 8.804, Average Loss: 2.482, avg. samples / sec: 52369.34
Iteration:    260, Loss function: 8.493, Average Loss: 2.469, avg. samples / sec: 51580.50
Iteration:    260, Loss function: 7.917, Average Loss: 2.475, avg. samples / sec: 51554.54
Iteration:    260, Loss function: 8.568, Average Loss: 2.499, avg. samples / sec: 51513.78
Iteration:    260, Loss function: 7.389, Average Loss: 2.470, avg. samples / sec: 51394.45
Iteration:    260, Loss function: 7.531, Average Loss: 2.472, avg. samples / sec: 52269.99
Iteration:    260, Loss function: 6.799, Average Loss: 2.459, avg. samples / sec: 51485.47
Iteration:    260, Loss function: 7.061, Average Loss: 2.485, avg. samples / sec: 51397.17
Iteration:    260, Loss function: 7.561, Average Loss: 2.473, avg. samples / sec: 51448.50
Iteration:    260, Loss function: 7.670, Average Loss: 2.493, avg. samples / sec: 51638.51
Iteration:    260, Loss function: 7.622, Average Loss: 2.474, avg. samples / sec: 51410.40
Iteration:    260, Loss function: 8.494, Average Loss: 2.476, avg. samples / sec: 51525.66
Iteration:    260, Loss function: 7.482, Average Loss: 2.462, avg. samples / sec: 51308.04
Iteration:    260, Loss function: 7.191, Average Loss: 2.476, avg. samples / sec: 51720.59
Iteration:    260, Loss function: 8.327, Average Loss: 2.485, avg. samples / sec: 51144.78
Iteration:    260, Loss function: 8.093, Average Loss: 2.493, avg. samples / sec: 51250.98
Iteration:    260, Loss function: 7.023, Average Loss: 2.473, avg. samples / sec: 50781.15
Iteration:    260, Loss function: 8.155, Average Loss: 2.467, avg. samples / sec: 50984.98
Iteration:    260, Loss function: 7.652, Average Loss: 2.475, avg. samples / sec: 50952.47
Iteration:    260, Loss function: 7.610, Average Loss: 2.478, avg. samples / sec: 50589.07
:::MLL 1558640859.096 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558640859.096 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 7.806, Average Loss: 2.581, avg. samples / sec: 52240.26
Iteration:    280, Loss function: 8.031, Average Loss: 2.603, avg. samples / sec: 52289.07
Iteration:    280, Loss function: 7.357, Average Loss: 2.571, avg. samples / sec: 52326.74
Iteration:    280, Loss function: 7.149, Average Loss: 2.578, avg. samples / sec: 52036.01
Iteration:    280, Loss function: 7.440, Average Loss: 2.581, avg. samples / sec: 52252.54
Iteration:    280, Loss function: 9.147, Average Loss: 2.567, avg. samples / sec: 51890.36
Iteration:    280, Loss function: 7.741, Average Loss: 2.586, avg. samples / sec: 52238.46
Iteration:    280, Loss function: 7.509, Average Loss: 2.573, avg. samples / sec: 52644.31
Iteration:    280, Loss function: 7.256, Average Loss: 2.562, avg. samples / sec: 51795.04
Iteration:    280, Loss function: 7.687, Average Loss: 2.587, avg. samples / sec: 51520.75
Iteration:    280, Loss function: 7.497, Average Loss: 2.579, avg. samples / sec: 51893.91
Iteration:    280, Loss function: 7.930, Average Loss: 2.595, avg. samples / sec: 52246.81
Iteration:    280, Loss function: 8.276, Average Loss: 2.574, avg. samples / sec: 51715.27
Iteration:    280, Loss function: 7.537, Average Loss: 2.581, avg. samples / sec: 52768.04
Iteration:    280, Loss function: 7.660, Average Loss: 2.596, avg. samples / sec: 51586.19
Iteration:    280, Loss function: 6.384, Average Loss: 2.567, avg. samples / sec: 52187.51
Iteration:    280, Loss function: 7.948, Average Loss: 2.583, avg. samples / sec: 51346.03
Iteration:    280, Loss function: 7.881, Average Loss: 2.565, avg. samples / sec: 51395.07
Iteration:    280, Loss function: 8.654, Average Loss: 2.576, avg. samples / sec: 51476.30
Iteration:    280, Loss function: 7.672, Average Loss: 2.581, avg. samples / sec: 51155.62
Iteration:    280, Loss function: 7.414, Average Loss: 2.570, avg. samples / sec: 51301.43
Iteration:    280, Loss function: 8.504, Average Loss: 2.589, avg. samples / sec: 51139.17
Iteration:    280, Loss function: 7.541, Average Loss: 2.562, avg. samples / sec: 51366.72
Iteration:    280, Loss function: 6.891, Average Loss: 2.594, avg. samples / sec: 51147.93
Iteration:    280, Loss function: 6.888, Average Loss: 2.569, avg. samples / sec: 51711.12
Iteration:    280, Loss function: 7.133, Average Loss: 2.585, avg. samples / sec: 51154.69
Iteration:    280, Loss function: 8.270, Average Loss: 2.574, avg. samples / sec: 51151.87
Iteration:    280, Loss function: 7.627, Average Loss: 2.584, avg. samples / sec: 50856.16
Iteration:    280, Loss function: 7.111, Average Loss: 2.568, avg. samples / sec: 50730.37
Iteration:    280, Loss function: 7.528, Average Loss: 2.564, avg. samples / sec: 50841.35
Iteration:    300, Loss function: 7.292, Average Loss: 2.672, avg. samples / sec: 53969.75
Iteration:    300, Loss function: 7.503, Average Loss: 2.659, avg. samples / sec: 54196.27
Iteration:    300, Loss function: 7.108, Average Loss: 2.668, avg. samples / sec: 53659.64
Iteration:    300, Loss function: 6.730, Average Loss: 2.681, avg. samples / sec: 53704.67
Iteration:    300, Loss function: 7.660, Average Loss: 2.680, avg. samples / sec: 53115.19
Iteration:    300, Loss function: 6.962, Average Loss: 2.670, avg. samples / sec: 52691.06
Iteration:    300, Loss function: 7.738, Average Loss: 2.680, avg. samples / sec: 52851.24
Iteration:    300, Loss function: 7.310, Average Loss: 2.676, avg. samples / sec: 53454.80
Iteration:    300, Loss function: 7.433, Average Loss: 2.672, avg. samples / sec: 53162.17
Iteration:    300, Loss function: 7.159, Average Loss: 2.654, avg. samples / sec: 54125.31
Iteration:    300, Loss function: 7.303, Average Loss: 2.661, avg. samples / sec: 52521.44
Iteration:    300, Loss function: 7.012, Average Loss: 2.693, avg. samples / sec: 53316.64
Iteration:    300, Loss function: 7.571, Average Loss: 2.702, avg. samples / sec: 52496.49
Iteration:    300, Loss function: 7.633, Average Loss: 2.674, avg. samples / sec: 52490.68
Iteration:    300, Loss function: 6.483, Average Loss: 2.670, avg. samples / sec: 52611.85
Iteration:    300, Loss function: 6.609, Average Loss: 2.662, avg. samples / sec: 53496.93
Iteration:    300, Loss function: 8.274, Average Loss: 2.680, avg. samples / sec: 53879.31
Iteration:    300, Loss function: 8.435, Average Loss: 2.660, avg. samples / sec: 52642.15
Iteration:    300, Loss function: 6.906, Average Loss: 2.656, avg. samples / sec: 52848.56
Iteration:    300, Loss function: 7.451, Average Loss: 2.656, avg. samples / sec: 53311.82
Iteration:    300, Loss function: 7.273, Average Loss: 2.656, avg. samples / sec: 53453.44
Iteration:    300, Loss function: 7.961, Average Loss: 2.684, avg. samples / sec: 53448.78
Iteration:    300, Loss function: 5.828, Average Loss: 2.670, avg. samples / sec: 52971.32
Iteration:    300, Loss function: 7.865, Average Loss: 2.664, avg. samples / sec: 53105.44
Iteration:    300, Loss function: 6.903, Average Loss: 2.664, avg. samples / sec: 53426.49
Iteration:    300, Loss function: 6.789, Average Loss: 2.688, avg. samples / sec: 52792.99
Iteration:    300, Loss function: 7.708, Average Loss: 2.665, avg. samples / sec: 53564.07
Iteration:    300, Loss function: 8.304, Average Loss: 2.671, avg. samples / sec: 53088.58
Iteration:    300, Loss function: 7.503, Average Loss: 2.671, avg. samples / sec: 52718.28
Iteration:    300, Loss function: 6.421, Average Loss: 2.667, avg. samples / sec: 52466.61
Iteration:    320, Loss function: 7.348, Average Loss: 2.765, avg. samples / sec: 52898.53
Iteration:    320, Loss function: 6.491, Average Loss: 2.763, avg. samples / sec: 52821.66
Iteration:    320, Loss function: 7.300, Average Loss: 2.765, avg. samples / sec: 52852.54
Iteration:    320, Loss function: 9.775, Average Loss: 2.775, avg. samples / sec: 52841.53
Iteration:    320, Loss function: 7.075, Average Loss: 2.773, avg. samples / sec: 52931.45
Iteration:    320, Loss function: 7.661, Average Loss: 2.791, avg. samples / sec: 52866.17
Iteration:    320, Loss function: 7.591, Average Loss: 2.759, avg. samples / sec: 53089.44
Iteration:    320, Loss function: 7.493, Average Loss: 2.755, avg. samples / sec: 52787.63
Iteration:    320, Loss function: 6.889, Average Loss: 2.752, avg. samples / sec: 52821.15
Iteration:    320, Loss function: 8.049, Average Loss: 2.751, avg. samples / sec: 52854.94
Iteration:    320, Loss function: 6.858, Average Loss: 2.767, avg. samples / sec: 52578.12
Iteration:    320, Loss function: 6.545, Average Loss: 2.764, avg. samples / sec: 52766.15
Iteration:    320, Loss function: 7.571, Average Loss: 2.746, avg. samples / sec: 52817.40
Iteration:    320, Loss function: 7.278, Average Loss: 2.778, avg. samples / sec: 52900.97
Iteration:    320, Loss function: 8.663, Average Loss: 2.760, avg. samples / sec: 53035.41
Iteration:    320, Loss function: 7.630, Average Loss: 2.786, avg. samples / sec: 52662.17
Iteration:    320, Loss function: 7.663, Average Loss: 2.745, avg. samples / sec: 52609.41
Iteration:    320, Loss function: 6.873, Average Loss: 2.761, avg. samples / sec: 53066.39
Iteration:    320, Loss function: 7.721, Average Loss: 2.763, avg. samples / sec: 52941.53
Iteration:    320, Loss function: 6.850, Average Loss: 2.758, avg. samples / sec: 52825.82
Iteration:    320, Loss function: 7.773, Average Loss: 2.747, avg. samples / sec: 52746.77
Iteration:    320, Loss function: 6.963, Average Loss: 2.764, avg. samples / sec: 52542.02
Iteration:    320, Loss function: 8.746, Average Loss: 2.781, avg. samples / sec: 52842.12
Iteration:    320, Loss function: 7.032, Average Loss: 2.755, avg. samples / sec: 52831.62
Iteration:    320, Loss function: 8.126, Average Loss: 2.762, avg. samples / sec: 52481.97
Iteration:    320, Loss function: 6.165, Average Loss: 2.756, avg. samples / sec: 52857.50
Iteration:    320, Loss function: 7.609, Average Loss: 2.748, avg. samples / sec: 52178.24
Iteration:    320, Loss function: 7.066, Average Loss: 2.771, avg. samples / sec: 52187.30
Iteration:    320, Loss function: 7.497, Average Loss: 2.758, avg. samples / sec: 52265.82
Iteration:    320, Loss function: 7.833, Average Loss: 2.748, avg. samples / sec: 52086.75
Iteration:    340, Loss function: 6.941, Average Loss: 2.835, avg. samples / sec: 53931.75
Iteration:    340, Loss function: 6.507, Average Loss: 2.861, avg. samples / sec: 53300.91
Iteration:    340, Loss function: 6.759, Average Loss: 2.848, avg. samples / sec: 53692.49
Iteration:    340, Loss function: 8.499, Average Loss: 2.852, avg. samples / sec: 53899.07
Iteration:    340, Loss function: 7.041, Average Loss: 2.847, avg. samples / sec: 53961.38
Iteration:    340, Loss function: 7.168, Average Loss: 2.843, avg. samples / sec: 53343.80
Iteration:    340, Loss function: 7.107, Average Loss: 2.851, avg. samples / sec: 53136.58
Iteration:    340, Loss function: 6.365, Average Loss: 2.850, avg. samples / sec: 53135.19
Iteration:    340, Loss function: 7.156, Average Loss: 2.859, avg. samples / sec: 53189.42
Iteration:    340, Loss function: 7.788, Average Loss: 2.847, avg. samples / sec: 53509.38
Iteration:    340, Loss function: 7.352, Average Loss: 2.872, avg. samples / sec: 53393.28
Iteration:    340, Loss function: 6.974, Average Loss: 2.850, avg. samples / sec: 53275.90
Iteration:    340, Loss function: 6.338, Average Loss: 2.837, avg. samples / sec: 53219.13
Iteration:    340, Loss function: 7.460, Average Loss: 2.874, avg. samples / sec: 53152.35
Iteration:    340, Loss function: 7.467, Average Loss: 2.852, avg. samples / sec: 53107.92
Iteration:    340, Loss function: 6.511, Average Loss: 2.843, avg. samples / sec: 53009.82
Iteration:    340, Loss function: 7.565, Average Loss: 2.835, avg. samples / sec: 53868.21
Iteration:    340, Loss function: 6.528, Average Loss: 2.830, avg. samples / sec: 53291.01
Iteration:    340, Loss function: 6.422, Average Loss: 2.848, avg. samples / sec: 53239.82
Iteration:    340, Loss function: 6.655, Average Loss: 2.840, avg. samples / sec: 53254.08
Iteration:    340, Loss function: 7.249, Average Loss: 2.848, avg. samples / sec: 53229.26
Iteration:    340, Loss function: 8.609, Average Loss: 2.845, avg. samples / sec: 53255.27
Iteration:    340, Loss function: 8.477, Average Loss: 2.834, avg. samples / sec: 53184.00
Iteration:    340, Loss function: 7.066, Average Loss: 2.863, avg. samples / sec: 53235.59
Iteration:    340, Loss function: 6.979, Average Loss: 2.852, avg. samples / sec: 52799.54
Iteration:    340, Loss function: 7.353, Average Loss: 2.833, avg. samples / sec: 52862.97
Iteration:    340, Loss function: 7.509, Average Loss: 2.835, avg. samples / sec: 52780.00
Iteration:    340, Loss function: 7.204, Average Loss: 2.842, avg. samples / sec: 52700.04
Iteration:    340, Loss function: 6.438, Average Loss: 2.843, avg. samples / sec: 52810.48
Iteration:    340, Loss function: 7.169, Average Loss: 2.866, avg. samples / sec: 52609.76
:::MLL 1558640861.322 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558640861.322 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 8.585, Average Loss: 2.953, avg. samples / sec: 53555.58
Iteration:    360, Loss function: 6.089, Average Loss: 2.939, avg. samples / sec: 53203.36
Iteration:    360, Loss function: 6.039, Average Loss: 2.922, avg. samples / sec: 53024.26
Iteration:    360, Loss function: 6.879, Average Loss: 2.935, avg. samples / sec: 53182.94
Iteration:    360, Loss function: 6.620, Average Loss: 2.942, avg. samples / sec: 53008.34
Iteration:    360, Loss function: 7.321, Average Loss: 2.940, avg. samples / sec: 52938.39
Iteration:    360, Loss function: 7.743, Average Loss: 2.926, avg. samples / sec: 52937.77
Iteration:    360, Loss function: 8.230, Average Loss: 2.943, avg. samples / sec: 53194.40
Iteration:    360, Loss function: 6.799, Average Loss: 2.922, avg. samples / sec: 53056.82
Iteration:    360, Loss function: 7.385, Average Loss: 2.934, avg. samples / sec: 52834.93
Iteration:    360, Loss function: 6.908, Average Loss: 2.931, avg. samples / sec: 52872.17
Iteration:    360, Loss function: 6.065, Average Loss: 2.931, avg. samples / sec: 53018.17
Iteration:    360, Loss function: 7.149, Average Loss: 2.952, avg. samples / sec: 53748.68
Iteration:    360, Loss function: 8.187, Average Loss: 2.927, avg. samples / sec: 53640.75
Iteration:    360, Loss function: 7.451, Average Loss: 2.944, avg. samples / sec: 52937.89
Iteration:    360, Loss function: 6.980, Average Loss: 2.960, avg. samples / sec: 53000.75
Iteration:    360, Loss function: 7.872, Average Loss: 2.921, avg. samples / sec: 53111.62
Iteration:    360, Loss function: 6.871, Average Loss: 2.918, avg. samples / sec: 53399.91
Iteration:    360, Loss function: 7.377, Average Loss: 2.963, avg. samples / sec: 52915.59
Iteration:    360, Loss function: 6.677, Average Loss: 2.922, avg. samples / sec: 53148.76
Iteration:    360, Loss function: 7.431, Average Loss: 2.929, avg. samples / sec: 53056.50
Iteration:    360, Loss function: 7.276, Average Loss: 2.922, avg. samples / sec: 53334.47
Iteration:    360, Loss function: 8.230, Average Loss: 2.932, avg. samples / sec: 52806.58
Iteration:    360, Loss function: 6.965, Average Loss: 2.931, avg. samples / sec: 53027.19
Iteration:    360, Loss function: 8.134, Average Loss: 2.922, avg. samples / sec: 52979.47
Iteration:    360, Loss function: 7.504, Average Loss: 2.917, avg. samples / sec: 52992.62
Iteration:    360, Loss function: 8.587, Average Loss: 2.938, avg. samples / sec: 53028.47
Iteration:    360, Loss function: 7.003, Average Loss: 2.934, avg. samples / sec: 52952.39
Iteration:    360, Loss function: 8.387, Average Loss: 2.930, avg. samples / sec: 53465.12
Iteration:    360, Loss function: 6.990, Average Loss: 2.928, avg. samples / sec: 52960.59
Iteration:    380, Loss function: 7.301, Average Loss: 3.000, avg. samples / sec: 52892.04
Iteration:    380, Loss function: 6.925, Average Loss: 3.014, avg. samples / sec: 52936.22
Iteration:    380, Loss function: 6.182, Average Loss: 3.020, avg. samples / sec: 52388.01
Iteration:    380, Loss function: 6.716, Average Loss: 3.008, avg. samples / sec: 52592.82
Iteration:    380, Loss function: 5.897, Average Loss: 3.019, avg. samples / sec: 52414.10
Iteration:    380, Loss function: 6.440, Average Loss: 3.020, avg. samples / sec: 52304.48
Iteration:    380, Loss function: 6.712, Average Loss: 3.005, avg. samples / sec: 52260.57
Iteration:    380, Loss function: 6.127, Average Loss: 3.021, avg. samples / sec: 52429.83
Iteration:    380, Loss function: 6.341, Average Loss: 3.042, avg. samples / sec: 52577.46
Iteration:    380, Loss function: 5.394, Average Loss: 3.012, avg. samples / sec: 52691.89
Iteration:    380, Loss function: 6.523, Average Loss: 3.016, avg. samples / sec: 52453.47
Iteration:    380, Loss function: 7.111, Average Loss: 2.991, avg. samples / sec: 52531.93
Iteration:    380, Loss function: 7.092, Average Loss: 3.014, avg. samples / sec: 52422.13
Iteration:    380, Loss function: 6.066, Average Loss: 3.023, avg. samples / sec: 52441.17
Iteration:    380, Loss function: 7.176, Average Loss: 3.006, avg. samples / sec: 52536.45
Iteration:    380, Loss function: 6.608, Average Loss: 3.036, avg. samples / sec: 52391.01
Iteration:    380, Loss function: 6.425, Average Loss: 3.013, avg. samples / sec: 52383.24
Iteration:    380, Loss function: 6.644, Average Loss: 3.006, avg. samples / sec: 52345.10
Iteration:    380, Loss function: 6.524, Average Loss: 3.041, avg. samples / sec: 52381.70
Iteration:    380, Loss function: 7.228, Average Loss: 3.005, avg. samples / sec: 52521.87
Iteration:    380, Loss function: 7.690, Average Loss: 3.007, avg. samples / sec: 52352.53
Iteration:    380, Loss function: 6.535, Average Loss: 3.005, avg. samples / sec: 52395.08
Iteration:    380, Loss function: 7.073, Average Loss: 3.019, avg. samples / sec: 52501.03
Iteration:    380, Loss function: 7.719, Average Loss: 3.013, avg. samples / sec: 52260.51
Iteration:    380, Loss function: 6.456, Average Loss: 3.013, avg. samples / sec: 52404.90
Iteration:    380, Loss function: 6.512, Average Loss: 3.002, avg. samples / sec: 52313.49
Iteration:    380, Loss function: 5.993, Average Loss: 3.030, avg. samples / sec: 51909.82
Iteration:    380, Loss function: 6.773, Average Loss: 3.012, avg. samples / sec: 52391.30
Iteration:    380, Loss function: 8.081, Average Loss: 3.018, avg. samples / sec: 52319.88
Iteration:    380, Loss function: 6.765, Average Loss: 3.024, avg. samples / sec: 51790.80
Iteration:    400, Loss function: 5.839, Average Loss: 3.097, avg. samples / sec: 53573.47
Iteration:    400, Loss function: 7.568, Average Loss: 3.094, avg. samples / sec: 53656.82
Iteration:    400, Loss function: 7.363, Average Loss: 3.092, avg. samples / sec: 53459.95
Iteration:    400, Loss function: 7.640, Average Loss: 3.079, avg. samples / sec: 53582.93
Iteration:    400, Loss function: 7.285, Average Loss: 3.092, avg. samples / sec: 53548.92
Iteration:    400, Loss function: 5.536, Average Loss: 3.071, avg. samples / sec: 53390.12
Iteration:    400, Loss function: 5.857, Average Loss: 3.095, avg. samples / sec: 53509.68
Iteration:    400, Loss function: 6.542, Average Loss: 3.086, avg. samples / sec: 53314.56
Iteration:    400, Loss function: 6.753, Average Loss: 3.111, avg. samples / sec: 53547.20
Iteration:    400, Loss function: 6.617, Average Loss: 3.120, avg. samples / sec: 53421.21
Iteration:    400, Loss function: 7.208, Average Loss: 3.084, avg. samples / sec: 53448.31
Iteration:    400, Loss function: 6.128, Average Loss: 3.061, avg. samples / sec: 53412.24
Iteration:    400, Loss function: 7.242, Average Loss: 3.113, avg. samples / sec: 53528.28
Iteration:    400, Loss function: 7.091, Average Loss: 3.085, avg. samples / sec: 53468.21
Iteration:    400, Loss function: 5.681, Average Loss: 3.093, avg. samples / sec: 53429.35
Iteration:    400, Loss function: 6.717, Average Loss: 3.080, avg. samples / sec: 53431.64
Iteration:    400, Loss function: 6.477, Average Loss: 3.103, avg. samples / sec: 54024.66
Iteration:    400, Loss function: 6.669, Average Loss: 3.088, avg. samples / sec: 53543.55
Iteration:    400, Loss function: 6.609, Average Loss: 3.075, avg. samples / sec: 53326.40
Iteration:    400, Loss function: 7.651, Average Loss: 3.089, avg. samples / sec: 53450.99
Iteration:    400, Loss function: 7.056, Average Loss: 3.089, avg. samples / sec: 53203.36
Iteration:    400, Loss function: 6.595, Average Loss: 3.077, avg. samples / sec: 53432.10
Iteration:    400, Loss function: 6.717, Average Loss: 3.078, avg. samples / sec: 53368.73
Iteration:    400, Loss function: 5.750, Average Loss: 3.080, avg. samples / sec: 53390.65
Iteration:    400, Loss function: 7.939, Average Loss: 3.088, avg. samples / sec: 53580.77
Iteration:    400, Loss function: 8.162, Average Loss: 3.102, avg. samples / sec: 53469.79
Iteration:    400, Loss function: 6.078, Average Loss: 3.084, avg. samples / sec: 52975.05
Iteration:    400, Loss function: 5.807, Average Loss: 3.084, avg. samples / sec: 53477.30
Iteration:    400, Loss function: 7.178, Average Loss: 3.078, avg. samples / sec: 53391.58
Iteration:    400, Loss function: 6.957, Average Loss: 3.086, avg. samples / sec: 53362.10
:::MLL 1558640863.544 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558640863.544 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 7.149, Average Loss: 3.153, avg. samples / sec: 53087.92
Iteration:    420, Loss function: 6.128, Average Loss: 3.173, avg. samples / sec: 52719.17
Iteration:    420, Loss function: 7.145, Average Loss: 3.150, avg. samples / sec: 52634.09
Iteration:    420, Loss function: 6.465, Average Loss: 3.168, avg. samples / sec: 52849.61
Iteration:    420, Loss function: 5.840, Average Loss: 3.165, avg. samples / sec: 52515.00
Iteration:    420, Loss function: 6.169, Average Loss: 3.166, avg. samples / sec: 52514.70
Iteration:    420, Loss function: 5.836, Average Loss: 3.184, avg. samples / sec: 52733.00
Iteration:    420, Loss function: 7.250, Average Loss: 3.168, avg. samples / sec: 52524.92
Iteration:    420, Loss function: 6.094, Average Loss: 3.170, avg. samples / sec: 52384.58
Iteration:    420, Loss function: 7.563, Average Loss: 3.157, avg. samples / sec: 52611.06
Iteration:    420, Loss function: 6.289, Average Loss: 3.172, avg. samples / sec: 52750.35
Iteration:    420, Loss function: 6.578, Average Loss: 3.159, avg. samples / sec: 52862.34
Iteration:    420, Loss function: 7.574, Average Loss: 3.145, avg. samples / sec: 52453.56
Iteration:    420, Loss function: 6.837, Average Loss: 3.156, avg. samples / sec: 52646.79
Iteration:    420, Loss function: 6.839, Average Loss: 3.134, avg. samples / sec: 52620.31
Iteration:    420, Loss function: 5.817, Average Loss: 3.197, avg. samples / sec: 52567.55
Iteration:    420, Loss function: 6.716, Average Loss: 3.175, avg. samples / sec: 52814.24
Iteration:    420, Loss function: 6.710, Average Loss: 3.154, avg. samples / sec: 52634.38
Iteration:    420, Loss function: 7.119, Average Loss: 3.152, avg. samples / sec: 52553.46
Iteration:    420, Loss function: 7.770, Average Loss: 3.147, avg. samples / sec: 52674.06
Iteration:    420, Loss function: 7.005, Average Loss: 3.151, avg. samples / sec: 52709.76
Iteration:    420, Loss function: 7.026, Average Loss: 3.186, avg. samples / sec: 52471.55
Iteration:    420, Loss function: 6.961, Average Loss: 3.158, avg. samples / sec: 52806.58
Iteration:    420, Loss function: 6.242, Average Loss: 3.150, avg. samples / sec: 52709.80
Iteration:    420, Loss function: 7.029, Average Loss: 3.157, avg. samples / sec: 52737.22
Iteration:    420, Loss function: 5.948, Average Loss: 3.161, avg. samples / sec: 52629.35
Iteration:    420, Loss function: 6.073, Average Loss: 3.151, avg. samples / sec: 52710.08
Iteration:    420, Loss function: 5.630, Average Loss: 3.157, avg. samples / sec: 52669.95
Iteration:    420, Loss function: 5.598, Average Loss: 3.159, avg. samples / sec: 52400.88
Iteration:    420, Loss function: 5.967, Average Loss: 3.163, avg. samples / sec: 51861.66
Iteration:    440, Loss function: 6.508, Average Loss: 3.241, avg. samples / sec: 53571.23
Iteration:    440, Loss function: 6.170, Average Loss: 3.222, avg. samples / sec: 53378.65
Iteration:    440, Loss function: 5.902, Average Loss: 3.223, avg. samples / sec: 53507.39
Iteration:    440, Loss function: 6.105, Average Loss: 3.237, avg. samples / sec: 53445.94
Iteration:    440, Loss function: 6.426, Average Loss: 3.232, avg. samples / sec: 53389.31
Iteration:    440, Loss function: 6.334, Average Loss: 3.249, avg. samples / sec: 53252.37
Iteration:    440, Loss function: 7.060, Average Loss: 3.223, avg. samples / sec: 53200.58
Iteration:    440, Loss function: 5.596, Average Loss: 3.219, avg. samples / sec: 53543.98
Iteration:    440, Loss function: 7.199, Average Loss: 3.231, avg. samples / sec: 53738.64
Iteration:    440, Loss function: 6.645, Average Loss: 3.212, avg. samples / sec: 53375.26
Iteration:    440, Loss function: 7.694, Average Loss: 3.254, avg. samples / sec: 53272.56
Iteration:    440, Loss function: 5.822, Average Loss: 3.233, avg. samples / sec: 53239.25
Iteration:    440, Loss function: 6.926, Average Loss: 3.199, avg. samples / sec: 53375.28
Iteration:    440, Loss function: 7.616, Average Loss: 3.230, avg. samples / sec: 53370.69
Iteration:    440, Loss function: 6.662, Average Loss: 3.255, avg. samples / sec: 53458.25
Iteration:    440, Loss function: 6.103, Average Loss: 3.269, avg. samples / sec: 53374.77
Iteration:    440, Loss function: 4.951, Average Loss: 3.211, avg. samples / sec: 53445.03
Iteration:    440, Loss function: 6.104, Average Loss: 3.225, avg. samples / sec: 53399.73
Iteration:    440, Loss function: 5.880, Average Loss: 3.240, avg. samples / sec: 53273.37
Iteration:    440, Loss function: 5.900, Average Loss: 3.223, avg. samples / sec: 53367.09
Iteration:    440, Loss function: 5.663, Average Loss: 3.222, avg. samples / sec: 53368.51
Iteration:    440, Loss function: 6.232, Average Loss: 3.231, avg. samples / sec: 54173.18
Iteration:    440, Loss function: 6.073, Average Loss: 3.233, avg. samples / sec: 52976.22
Iteration:    440, Loss function: 5.579, Average Loss: 3.220, avg. samples / sec: 53327.39
Iteration:    440, Loss function: 5.346, Average Loss: 3.225, avg. samples / sec: 53233.46
Iteration:    440, Loss function: 6.157, Average Loss: 3.228, avg. samples / sec: 53320.81
Iteration:    440, Loss function: 5.799, Average Loss: 3.244, avg. samples / sec: 53148.10
Iteration:    440, Loss function: 7.131, Average Loss: 3.232, avg. samples / sec: 53256.74
Iteration:    440, Loss function: 6.675, Average Loss: 3.232, avg. samples / sec: 53075.46
Iteration:    440, Loss function: 8.557, Average Loss: 3.224, avg. samples / sec: 52266.81
Iteration:    460, Loss function: 5.735, Average Loss: 3.292, avg. samples / sec: 53438.08
Iteration:    460, Loss function: 6.721, Average Loss: 3.289, avg. samples / sec: 52947.46
Iteration:    460, Loss function: 5.846, Average Loss: 3.306, avg. samples / sec: 52707.16
Iteration:    460, Loss function: 5.487, Average Loss: 3.322, avg. samples / sec: 52967.20
Iteration:    460, Loss function: 7.964, Average Loss: 3.286, avg. samples / sec: 52952.41
Iteration:    460, Loss function: 7.254, Average Loss: 3.292, avg. samples / sec: 52741.13
Iteration:    460, Loss function: 7.753, Average Loss: 3.303, avg. samples / sec: 52823.32
Iteration:    460, Loss function: 6.551, Average Loss: 3.276, avg. samples / sec: 52726.13
Iteration:    460, Loss function: 5.799, Average Loss: 3.294, avg. samples / sec: 52962.13
Iteration:    460, Loss function: 7.324, Average Loss: 3.286, avg. samples / sec: 52621.47
Iteration:    460, Loss function: 7.358, Average Loss: 3.292, avg. samples / sec: 52689.56
Iteration:    460, Loss function: 7.008, Average Loss: 3.290, avg. samples / sec: 52422.13
Iteration:    460, Loss function: 6.164, Average Loss: 3.306, avg. samples / sec: 52857.86
Iteration:    460, Loss function: 6.635, Average Loss: 3.289, avg. samples / sec: 52736.92
Iteration:    460, Loss function: 7.217, Average Loss: 3.300, avg. samples / sec: 52419.40
Iteration:    460, Loss function: 6.538, Average Loss: 3.300, avg. samples / sec: 52708.99
Iteration:    460, Loss function: 7.046, Average Loss: 3.307, avg. samples / sec: 52530.38
Iteration:    460, Loss function: 5.977, Average Loss: 3.297, avg. samples / sec: 52687.28
Iteration:    460, Loss function: 6.042, Average Loss: 3.293, avg. samples / sec: 52369.67
Iteration:    460, Loss function: 6.344, Average Loss: 3.293, avg. samples / sec: 53494.47
Iteration:    460, Loss function: 6.496, Average Loss: 3.262, avg. samples / sec: 52260.16
Iteration:    460, Loss function: 6.325, Average Loss: 3.316, avg. samples / sec: 52216.61
Iteration:    460, Loss function: 6.919, Average Loss: 3.285, avg. samples / sec: 52431.59
Iteration:    460, Loss function: 7.035, Average Loss: 3.319, avg. samples / sec: 52097.47
Iteration:    460, Loss function: 7.168, Average Loss: 3.301, avg. samples / sec: 52423.28
Iteration:    460, Loss function: 6.729, Average Loss: 3.297, avg. samples / sec: 52128.94
Iteration:    460, Loss function: 6.865, Average Loss: 3.338, avg. samples / sec: 52071.02
Iteration:    460, Loss function: 5.062, Average Loss: 3.289, avg. samples / sec: 52099.48
Iteration:    460, Loss function: 6.484, Average Loss: 3.299, avg. samples / sec: 51815.36
Iteration:    460, Loss function: 6.506, Average Loss: 3.292, avg. samples / sec: 52122.02
Iteration:    480, Loss function: 6.647, Average Loss: 3.364, avg. samples / sec: 53337.50
Iteration:    480, Loss function: 6.257, Average Loss: 3.369, avg. samples / sec: 52887.61
Iteration:    480, Loss function: 6.742, Average Loss: 3.379, avg. samples / sec: 53600.47
Iteration:    480, Loss function: 7.596, Average Loss: 3.352, avg. samples / sec: 52581.05
Iteration:    480, Loss function: 6.171, Average Loss: 3.357, avg. samples / sec: 53096.00
Iteration:    480, Loss function: 5.667, Average Loss: 3.341, avg. samples / sec: 53549.47
Iteration:    480, Loss function: 6.155, Average Loss: 3.396, avg. samples / sec: 53683.29
Iteration:    480, Loss function: 6.421, Average Loss: 3.321, avg. samples / sec: 53459.45
Iteration:    480, Loss function: 6.837, Average Loss: 3.364, avg. samples / sec: 53189.60
Iteration:    480, Loss function: 6.776, Average Loss: 3.356, avg. samples / sec: 53388.16
Iteration:    480, Loss function: 6.627, Average Loss: 3.364, avg. samples / sec: 52863.59
Iteration:    480, Loss function: 5.664, Average Loss: 3.358, avg. samples / sec: 53574.70
Iteration:    480, Loss function: 7.768, Average Loss: 3.378, avg. samples / sec: 53469.61
Iteration:    480, Loss function: 5.892, Average Loss: 3.381, avg. samples / sec: 52705.86
Iteration:    480, Loss function: 6.698, Average Loss: 3.372, avg. samples / sec: 53183.48
Iteration:    480, Loss function: 6.342, Average Loss: 3.343, avg. samples / sec: 52722.01
Iteration:    480, Loss function: 6.130, Average Loss: 3.357, avg. samples / sec: 53040.20
Iteration:    480, Loss function: 7.059, Average Loss: 3.340, avg. samples / sec: 52905.86
Iteration:    480, Loss function: 6.824, Average Loss: 3.350, avg. samples / sec: 53210.37
Iteration:    480, Loss function: 6.272, Average Loss: 3.352, avg. samples / sec: 53583.97
Iteration:    480, Loss function: 6.496, Average Loss: 3.358, avg. samples / sec: 52721.14
Iteration:    480, Loss function: 7.517, Average Loss: 3.348, avg. samples / sec: 52925.89
Iteration:    480, Loss function: 6.072, Average Loss: 3.344, avg. samples / sec: 52793.52
Iteration:    480, Loss function: 6.006, Average Loss: 3.359, avg. samples / sec: 53499.08
Iteration:    480, Loss function: 5.555, Average Loss: 3.355, avg. samples / sec: 52263.44
Iteration:    480, Loss function: 6.766, Average Loss: 3.358, avg. samples / sec: 52712.11
Iteration:    480, Loss function: 7.076, Average Loss: 3.360, avg. samples / sec: 52974.55
Iteration:    480, Loss function: 6.506, Average Loss: 3.370, avg. samples / sec: 52767.67
Iteration:    480, Loss function: 5.837, Average Loss: 3.365, avg. samples / sec: 52566.34
Iteration:    480, Loss function: 5.684, Average Loss: 3.352, avg. samples / sec: 52436.04
:::MLL 1558640865.764 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558640865.765 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 7.332, Average Loss: 3.428, avg. samples / sec: 53746.30
Iteration:    500, Loss function: 5.944, Average Loss: 3.429, avg. samples / sec: 53212.30
Iteration:    500, Loss function: 6.256, Average Loss: 3.428, avg. samples / sec: 53156.26
Iteration:    500, Loss function: 5.456, Average Loss: 3.410, avg. samples / sec: 53284.42
Iteration:    500, Loss function: 6.369, Average Loss: 3.422, avg. samples / sec: 53331.71
Iteration:    500, Loss function: 6.435, Average Loss: 3.443, avg. samples / sec: 53190.30
Iteration:    500, Loss function: 7.066, Average Loss: 3.418, avg. samples / sec: 53269.28
Iteration:    500, Loss function: 6.464, Average Loss: 3.437, avg. samples / sec: 53255.17
Iteration:    500, Loss function: 5.951, Average Loss: 3.416, avg. samples / sec: 53206.37
Iteration:    500, Loss function: 6.307, Average Loss: 3.442, avg. samples / sec: 53245.01
Iteration:    500, Loss function: 6.230, Average Loss: 3.419, avg. samples / sec: 53241.45
Iteration:    500, Loss function: 6.230, Average Loss: 3.381, avg. samples / sec: 53186.51
Iteration:    500, Loss function: 6.425, Average Loss: 3.431, avg. samples / sec: 53192.01
Iteration:    500, Loss function: 5.831, Average Loss: 3.458, avg. samples / sec: 53164.82
Iteration:    500, Loss function: 5.455, Average Loss: 3.415, avg. samples / sec: 53112.73
Iteration:    500, Loss function: 6.862, Average Loss: 3.402, avg. samples / sec: 53201.43
Iteration:    500, Loss function: 6.307, Average Loss: 3.433, avg. samples / sec: 53126.18
Iteration:    500, Loss function: 6.443, Average Loss: 3.408, avg. samples / sec: 54393.23
Iteration:    500, Loss function: 6.137, Average Loss: 3.396, avg. samples / sec: 53038.75
Iteration:    500, Loss function: 6.274, Average Loss: 3.406, avg. samples / sec: 53197.11
Iteration:    500, Loss function: 6.203, Average Loss: 3.413, avg. samples / sec: 53068.42
Iteration:    500, Loss function: 6.218, Average Loss: 3.417, avg. samples / sec: 53240.32
Iteration:    500, Loss function: 6.323, Average Loss: 3.401, avg. samples / sec: 53195.60
Iteration:    500, Loss function: 6.482, Average Loss: 3.412, avg. samples / sec: 53105.12
Iteration:    500, Loss function: 5.929, Average Loss: 3.412, avg. samples / sec: 53202.67
Iteration:    500, Loss function: 8.074, Average Loss: 3.404, avg. samples / sec: 52892.85
Iteration:    500, Loss function: 7.120, Average Loss: 3.419, avg. samples / sec: 53070.12
Iteration:    500, Loss function: 7.104, Average Loss: 3.418, avg. samples / sec: 53130.33
Iteration:    500, Loss function: 6.882, Average Loss: 3.424, avg. samples / sec: 53818.10
Iteration:    500, Loss function: 6.667, Average Loss: 3.422, avg. samples / sec: 52595.23
Iteration:    520, Loss function: 5.662, Average Loss: 3.495, avg. samples / sec: 53846.48
Iteration:    520, Loss function: 5.724, Average Loss: 3.487, avg. samples / sec: 53771.77
Iteration:    520, Loss function: 6.779, Average Loss: 3.465, avg. samples / sec: 53713.98
Iteration:    520, Loss function: 5.032, Average Loss: 3.475, avg. samples / sec: 54095.35
Iteration:    520, Loss function: 5.923, Average Loss: 3.467, avg. samples / sec: 54045.50
Iteration:    520, Loss function: 6.723, Average Loss: 3.508, avg. samples / sec: 53817.63
Iteration:    520, Loss function: 6.637, Average Loss: 3.491, avg. samples / sec: 53796.75
Iteration:    520, Loss function: 5.896, Average Loss: 3.474, avg. samples / sec: 53691.08
Iteration:    520, Loss function: 5.494, Average Loss: 3.482, avg. samples / sec: 53562.93
Iteration:    520, Loss function: 6.494, Average Loss: 3.475, avg. samples / sec: 53582.23
Iteration:    520, Loss function: 5.499, Average Loss: 3.471, avg. samples / sec: 53657.27
Iteration:    520, Loss function: 7.013, Average Loss: 3.434, avg. samples / sec: 53633.91
Iteration:    520, Loss function: 5.825, Average Loss: 3.494, avg. samples / sec: 53608.20
Iteration:    520, Loss function: 6.225, Average Loss: 3.489, avg. samples / sec: 53723.28
Iteration:    520, Loss function: 7.004, Average Loss: 3.465, avg. samples / sec: 53636.87
Iteration:    520, Loss function: 5.743, Average Loss: 3.462, avg. samples / sec: 53831.89
Iteration:    520, Loss function: 6.255, Average Loss: 3.481, avg. samples / sec: 53338.65
Iteration:    520, Loss function: 5.649, Average Loss: 3.469, avg. samples / sec: 53762.65
Iteration:    520, Loss function: 5.480, Average Loss: 3.462, avg. samples / sec: 53740.57
Iteration:    520, Loss function: 6.238, Average Loss: 3.455, avg. samples / sec: 53766.11
Iteration:    520, Loss function: 6.307, Average Loss: 3.475, avg. samples / sec: 53569.93
Iteration:    520, Loss function: 5.699, Average Loss: 3.467, avg. samples / sec: 53750.04
Iteration:    520, Loss function: 6.541, Average Loss: 3.480, avg. samples / sec: 53913.38
Iteration:    520, Loss function: 6.256, Average Loss: 3.472, avg. samples / sec: 53833.09
Iteration:    520, Loss function: 6.083, Average Loss: 3.450, avg. samples / sec: 53719.88
Iteration:    520, Loss function: 5.615, Average Loss: 3.473, avg. samples / sec: 53726.67
Iteration:    520, Loss function: 6.072, Average Loss: 3.470, avg. samples / sec: 53733.41
Iteration:    520, Loss function: 6.534, Average Loss: 3.480, avg. samples / sec: 54422.36
Iteration:    520, Loss function: 5.845, Average Loss: 3.495, avg. samples / sec: 53247.92
Iteration:    520, Loss function: 5.949, Average Loss: 3.474, avg. samples / sec: 53227.53
Iteration:    540, Loss function: 5.527, Average Loss: 3.523, avg. samples / sec: 54528.74
Iteration:    540, Loss function: 5.416, Average Loss: 3.532, avg. samples / sec: 54223.56
Iteration:    540, Loss function: 5.607, Average Loss: 3.521, avg. samples / sec: 54041.50
Iteration:    540, Loss function: 7.197, Average Loss: 3.542, avg. samples / sec: 53899.30
Iteration:    540, Loss function: 6.299, Average Loss: 3.551, avg. samples / sec: 53891.80
Iteration:    540, Loss function: 5.810, Average Loss: 3.536, avg. samples / sec: 54076.55
Iteration:    540, Loss function: 7.116, Average Loss: 3.557, avg. samples / sec: 53949.46
Iteration:    540, Loss function: 7.164, Average Loss: 3.527, avg. samples / sec: 54265.53
Iteration:    540, Loss function: 5.342, Average Loss: 3.546, avg. samples / sec: 54099.73
Iteration:    540, Loss function: 5.618, Average Loss: 3.529, avg. samples / sec: 54480.89
Iteration:    540, Loss function: 7.711, Average Loss: 3.546, avg. samples / sec: 53905.13
Iteration:    540, Loss function: 7.524, Average Loss: 3.527, avg. samples / sec: 53932.24
Iteration:    540, Loss function: 6.988, Average Loss: 3.484, avg. samples / sec: 54044.46
Iteration:    540, Loss function: 6.871, Average Loss: 3.521, avg. samples / sec: 53859.44
Iteration:    540, Loss function: 6.971, Average Loss: 3.531, avg. samples / sec: 54151.02
Iteration:    540, Loss function: 6.891, Average Loss: 3.524, avg. samples / sec: 53953.22
Iteration:    540, Loss function: 5.466, Average Loss: 3.516, avg. samples / sec: 53997.48
Iteration:    540, Loss function: 7.582, Average Loss: 3.545, avg. samples / sec: 53943.72
Iteration:    540, Loss function: 5.910, Average Loss: 3.523, avg. samples / sec: 54005.01
Iteration:    540, Loss function: 7.022, Average Loss: 3.513, avg. samples / sec: 53978.33
Iteration:    540, Loss function: 6.850, Average Loss: 3.507, avg. samples / sec: 53998.10
Iteration:    540, Loss function: 6.947, Average Loss: 3.517, avg. samples / sec: 53929.56
Iteration:    540, Loss function: 6.706, Average Loss: 3.521, avg. samples / sec: 53699.75
Iteration:    540, Loss function: 4.452, Average Loss: 3.515, avg. samples / sec: 53953.24
Iteration:    540, Loss function: 6.466, Average Loss: 3.530, avg. samples / sec: 53942.93
Iteration:    540, Loss function: 6.584, Average Loss: 3.521, avg. samples / sec: 53982.42
Iteration:    540, Loss function: 5.695, Average Loss: 3.507, avg. samples / sec: 53944.24
Iteration:    540, Loss function: 6.089, Average Loss: 3.534, avg. samples / sec: 53960.39
Iteration:    540, Loss function: 6.461, Average Loss: 3.553, avg. samples / sec: 53917.08
Iteration:    540, Loss function: 4.726, Average Loss: 3.534, avg. samples / sec: 53050.41
:::MLL 1558640867.960 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558640867.960 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 6.179, Average Loss: 3.604, avg. samples / sec: 53023.12
Iteration:    560, Loss function: 5.023, Average Loss: 3.595, avg. samples / sec: 52984.47
Iteration:    560, Loss function: 6.136, Average Loss: 3.592, avg. samples / sec: 52988.03
Iteration:    560, Loss function: 5.958, Average Loss: 3.574, avg. samples / sec: 52898.27
Iteration:    560, Loss function: 5.997, Average Loss: 3.587, avg. samples / sec: 53100.64
Iteration:    560, Loss function: 6.611, Average Loss: 3.600, avg. samples / sec: 53081.80
Iteration:    560, Loss function: 4.771, Average Loss: 3.599, avg. samples / sec: 53029.31
Iteration:    560, Loss function: 6.210, Average Loss: 3.568, avg. samples / sec: 53093.72
Iteration:    560, Loss function: 5.793, Average Loss: 3.590, avg. samples / sec: 52765.61
Iteration:    560, Loss function: 6.264, Average Loss: 3.583, avg. samples / sec: 53008.82
Iteration:    560, Loss function: 5.381, Average Loss: 3.587, avg. samples / sec: 52938.43
Iteration:    560, Loss function: 5.365, Average Loss: 3.581, avg. samples / sec: 54102.83
Iteration:    560, Loss function: 7.190, Average Loss: 3.589, avg. samples / sec: 52917.32
Iteration:    560, Loss function: 4.693, Average Loss: 3.588, avg. samples / sec: 53079.62
Iteration:    560, Loss function: 6.867, Average Loss: 3.582, avg. samples / sec: 53090.54
Iteration:    560, Loss function: 5.567, Average Loss: 3.572, avg. samples / sec: 53046.85
Iteration:    560, Loss function: 5.970, Average Loss: 3.567, avg. samples / sec: 53035.11
Iteration:    560, Loss function: 5.380, Average Loss: 3.577, avg. samples / sec: 52872.65
Iteration:    560, Loss function: 6.199, Average Loss: 3.559, avg. samples / sec: 53049.17
Iteration:    560, Loss function: 6.940, Average Loss: 3.570, avg. samples / sec: 53024.64
Iteration:    560, Loss function: 5.960, Average Loss: 3.574, avg. samples / sec: 53019.25
Iteration:    560, Loss function: 5.326, Average Loss: 3.607, avg. samples / sec: 53302.92
Iteration:    560, Loss function: 5.869, Average Loss: 3.590, avg. samples / sec: 53030.42
Iteration:    560, Loss function: 5.947, Average Loss: 3.578, avg. samples / sec: 52951.68
Iteration:    560, Loss function: 5.525, Average Loss: 3.576, avg. samples / sec: 52389.84
Iteration:    560, Loss function: 6.508, Average Loss: 3.578, avg. samples / sec: 52865.63
Iteration:    560, Loss function: 6.474, Average Loss: 3.585, avg. samples / sec: 52618.45
Iteration:    560, Loss function: 5.543, Average Loss: 3.613, avg. samples / sec: 52579.10
Iteration:    560, Loss function: 5.100, Average Loss: 3.599, avg. samples / sec: 52592.00
Iteration:    560, Loss function: 7.215, Average Loss: 3.543, avg. samples / sec: 52383.28
Iteration:    580, Loss function: 5.707, Average Loss: 3.623, avg. samples / sec: 53689.87
Iteration:    580, Loss function: 5.804, Average Loss: 3.621, avg. samples / sec: 53811.93
Iteration:    580, Loss function: 5.827, Average Loss: 3.642, avg. samples / sec: 53511.67
Iteration:    580, Loss function: 5.629, Average Loss: 3.643, avg. samples / sec: 53367.40
Iteration:    580, Loss function: 5.719, Average Loss: 3.633, avg. samples / sec: 53359.03
Iteration:    580, Loss function: 5.681, Average Loss: 3.622, avg. samples / sec: 53319.95
Iteration:    580, Loss function: 5.159, Average Loss: 3.652, avg. samples / sec: 53256.70
Iteration:    580, Loss function: 5.294, Average Loss: 3.633, avg. samples / sec: 53409.32
Iteration:    580, Loss function: 5.219, Average Loss: 3.637, avg. samples / sec: 53185.99
Iteration:    580, Loss function: 5.484, Average Loss: 3.647, avg. samples / sec: 53194.70
Iteration:    580, Loss function: 5.793, Average Loss: 3.625, avg. samples / sec: 53467.50
Iteration:    580, Loss function: 6.109, Average Loss: 3.590, avg. samples / sec: 53888.25
Iteration:    580, Loss function: 5.985, Average Loss: 3.609, avg. samples / sec: 53365.17
Iteration:    580, Loss function: 5.719, Average Loss: 3.649, avg. samples / sec: 53142.77
Iteration:    580, Loss function: 5.559, Average Loss: 3.634, avg. samples / sec: 53286.66
Iteration:    580, Loss function: 7.144, Average Loss: 3.654, avg. samples / sec: 53320.91
Iteration:    580, Loss function: 6.561, Average Loss: 3.637, avg. samples / sec: 53247.24
Iteration:    580, Loss function: 6.260, Average Loss: 3.622, avg. samples / sec: 53299.36
Iteration:    580, Loss function: 6.133, Average Loss: 3.645, avg. samples / sec: 53687.50
Iteration:    580, Loss function: 5.215, Average Loss: 3.616, avg. samples / sec: 53237.06
Iteration:    580, Loss function: 6.242, Average Loss: 3.623, avg. samples / sec: 53223.63
Iteration:    580, Loss function: 6.234, Average Loss: 3.631, avg. samples / sec: 53393.52
Iteration:    580, Loss function: 4.848, Average Loss: 3.619, avg. samples / sec: 53223.43
Iteration:    580, Loss function: 6.088, Average Loss: 3.639, avg. samples / sec: 53242.05
Iteration:    580, Loss function: 6.662, Average Loss: 3.621, avg. samples / sec: 53044.99
Iteration:    580, Loss function: 5.846, Average Loss: 3.660, avg. samples / sec: 53391.43
Iteration:    580, Loss function: 6.725, Average Loss: 3.630, avg. samples / sec: 53092.44
Iteration:    580, Loss function: 6.430, Average Loss: 3.629, avg. samples / sec: 53337.04
Iteration:    580, Loss function: 5.328, Average Loss: 3.618, avg. samples / sec: 53068.96
Iteration:    580, Loss function: 4.982, Average Loss: 3.633, avg. samples / sec: 52756.55
Iteration:    600, Loss function: 6.607, Average Loss: 3.680, avg. samples / sec: 54122.28
Iteration:    600, Loss function: 6.373, Average Loss: 3.674, avg. samples / sec: 53634.48
Iteration:    600, Loss function: 6.635, Average Loss: 3.695, avg. samples / sec: 53550.08
Iteration:    600, Loss function: 5.742, Average Loss: 3.689, avg. samples / sec: 53511.25
Iteration:    600, Loss function: 6.801, Average Loss: 3.702, avg. samples / sec: 53577.63
Iteration:    600, Loss function: 6.245, Average Loss: 3.684, avg. samples / sec: 53532.39
Iteration:    600, Loss function: 6.727, Average Loss: 3.690, avg. samples / sec: 53639.50
Iteration:    600, Loss function: 7.477, Average Loss: 3.700, avg. samples / sec: 53703.93
Iteration:    600, Loss function: 5.612, Average Loss: 3.665, avg. samples / sec: 53960.16
Iteration:    600, Loss function: 6.387, Average Loss: 3.685, avg. samples / sec: 53541.38
Iteration:    600, Loss function: 7.582, Average Loss: 3.676, avg. samples / sec: 53834.48
Iteration:    600, Loss function: 6.501, Average Loss: 3.704, avg. samples / sec: 53583.03
Iteration:    600, Loss function: 6.560, Average Loss: 3.690, avg. samples / sec: 54172.23
Iteration:    600, Loss function: 6.514, Average Loss: 3.668, avg. samples / sec: 53746.37
Iteration:    600, Loss function: 5.347, Average Loss: 3.679, avg. samples / sec: 53651.65
Iteration:    600, Loss function: 5.526, Average Loss: 3.681, avg. samples / sec: 53716.82
Iteration:    600, Loss function: 5.856, Average Loss: 3.673, avg. samples / sec: 53674.86
Iteration:    600, Loss function: 5.875, Average Loss: 3.677, avg. samples / sec: 53195.83
Iteration:    600, Loss function: 6.687, Average Loss: 3.707, avg. samples / sec: 53573.13
Iteration:    600, Loss function: 5.900, Average Loss: 3.677, avg. samples / sec: 53439.90
Iteration:    600, Loss function: 6.507, Average Loss: 3.672, avg. samples / sec: 53645.61
Iteration:    600, Loss function: 6.483, Average Loss: 3.693, avg. samples / sec: 53575.59
Iteration:    600, Loss function: 7.445, Average Loss: 3.679, avg. samples / sec: 53571.07
Iteration:    600, Loss function: 5.622, Average Loss: 3.660, avg. samples / sec: 53486.59
Iteration:    600, Loss function: 5.830, Average Loss: 3.687, avg. samples / sec: 53671.47
Iteration:    600, Loss function: 6.244, Average Loss: 3.688, avg. samples / sec: 53513.30
Iteration:    600, Loss function: 5.766, Average Loss: 3.690, avg. samples / sec: 53594.60
Iteration:    600, Loss function: 6.669, Average Loss: 3.714, avg. samples / sec: 53613.93
Iteration:    600, Loss function: 7.328, Average Loss: 3.680, avg. samples / sec: 52965.27
Iteration:    600, Loss function: 6.929, Average Loss: 3.645, avg. samples / sec: 52965.91
Iteration:    620, Loss function: 6.295, Average Loss: 3.734, avg. samples / sec: 52000.72
Iteration:    620, Loss function: 6.327, Average Loss: 3.748, avg. samples / sec: 52002.95
Iteration:    620, Loss function: 4.598, Average Loss: 3.720, avg. samples / sec: 52286.67
Iteration:    620, Loss function: 5.951, Average Loss: 3.715, avg. samples / sec: 51939.89
Iteration:    620, Loss function: 5.581, Average Loss: 3.730, avg. samples / sec: 51930.65
Iteration:    620, Loss function: 6.819, Average Loss: 3.689, avg. samples / sec: 52629.06
Iteration:    620, Loss function: 6.851, Average Loss: 3.743, avg. samples / sec: 51821.27
Iteration:    620, Loss function: 4.676, Average Loss: 3.725, avg. samples / sec: 52011.37
Iteration:    620, Loss function: 5.459, Average Loss: 3.710, avg. samples / sec: 51926.29
Iteration:    620, Loss function: 5.441, Average Loss: 3.740, avg. samples / sec: 51865.93
Iteration:    620, Loss function: 5.872, Average Loss: 3.724, avg. samples / sec: 51912.97
Iteration:    620, Loss function: 6.933, Average Loss: 3.732, avg. samples / sec: 51902.97
Iteration:    620, Loss function: 5.740, Average Loss: 3.751, avg. samples / sec: 51909.78
Iteration:    620, Loss function: 5.573, Average Loss: 3.739, avg. samples / sec: 51869.96
Iteration:    620, Loss function: 6.123, Average Loss: 3.735, avg. samples / sec: 52099.25
Iteration:    620, Loss function: 5.838, Average Loss: 3.740, avg. samples / sec: 52046.58
Iteration:    620, Loss function: 6.602, Average Loss: 3.739, avg. samples / sec: 51857.71
Iteration:    620, Loss function: 5.534, Average Loss: 3.728, avg. samples / sec: 51861.34
Iteration:    620, Loss function: 6.209, Average Loss: 3.717, avg. samples / sec: 51888.37
Iteration:    620, Loss function: 5.681, Average Loss: 3.737, avg. samples / sec: 51955.27
Iteration:    620, Loss function: 6.114, Average Loss: 3.721, avg. samples / sec: 51901.37
Iteration:    620, Loss function: 5.523, Average Loss: 3.714, avg. samples / sec: 51767.80
Iteration:    620, Loss function: 6.112, Average Loss: 3.735, avg. samples / sec: 51941.44
Iteration:    620, Loss function: 5.219, Average Loss: 3.749, avg. samples / sec: 51884.11
Iteration:    620, Loss function: 6.238, Average Loss: 3.707, avg. samples / sec: 51884.88
Iteration:    620, Loss function: 6.275, Average Loss: 3.724, avg. samples / sec: 51869.43
Iteration:    620, Loss function: 5.620, Average Loss: 3.724, avg. samples / sec: 51462.76
Iteration:    620, Loss function: 6.641, Average Loss: 3.727, avg. samples / sec: 51859.10
Iteration:    620, Loss function: 6.035, Average Loss: 3.722, avg. samples / sec: 52005.60
Iteration:    620, Loss function: 7.345, Average Loss: 3.763, avg. samples / sec: 51902.88
:::MLL 1558640870.182 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558640870.183 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 5.697, Average Loss: 3.751, avg. samples / sec: 52849.97
Iteration:    640, Loss function: 4.979, Average Loss: 3.785, avg. samples / sec: 52823.54
Iteration:    640, Loss function: 6.362, Average Loss: 3.769, avg. samples / sec: 52855.76
Iteration:    640, Loss function: 4.788, Average Loss: 3.758, avg. samples / sec: 53117.69
Iteration:    640, Loss function: 5.491, Average Loss: 3.792, avg. samples / sec: 53134.47
Iteration:    640, Loss function: 5.074, Average Loss: 3.779, avg. samples / sec: 52706.08
Iteration:    640, Loss function: 5.887, Average Loss: 3.772, avg. samples / sec: 52899.78
Iteration:    640, Loss function: 5.407, Average Loss: 3.768, avg. samples / sec: 52834.71
Iteration:    640, Loss function: 5.114, Average Loss: 3.759, avg. samples / sec: 53102.12
Iteration:    640, Loss function: 4.849, Average Loss: 3.778, avg. samples / sec: 52969.79
Iteration:    640, Loss function: 5.312, Average Loss: 3.755, avg. samples / sec: 52856.07
Iteration:    640, Loss function: 5.442, Average Loss: 3.732, avg. samples / sec: 52807.09
Iteration:    640, Loss function: 5.403, Average Loss: 3.769, avg. samples / sec: 52883.86
Iteration:    640, Loss function: 4.891, Average Loss: 3.763, avg. samples / sec: 52870.57
Iteration:    640, Loss function: 5.843, Average Loss: 3.793, avg. samples / sec: 52863.03
Iteration:    640, Loss function: 6.015, Average Loss: 3.781, avg. samples / sec: 52862.89
Iteration:    640, Loss function: 5.708, Average Loss: 3.756, avg. samples / sec: 52862.08
Iteration:    640, Loss function: 5.020, Average Loss: 3.767, avg. samples / sec: 52929.42
Iteration:    640, Loss function: 5.573, Average Loss: 3.747, avg. samples / sec: 52899.88
Iteration:    640, Loss function: 5.802, Average Loss: 3.753, avg. samples / sec: 52872.75
Iteration:    640, Loss function: 4.541, Average Loss: 3.780, avg. samples / sec: 52614.63
Iteration:    640, Loss function: 5.386, Average Loss: 3.755, avg. samples / sec: 52465.73
Iteration:    640, Loss function: 5.409, Average Loss: 3.763, avg. samples / sec: 52883.90
Iteration:    640, Loss function: 5.936, Average Loss: 3.777, avg. samples / sec: 52822.49
Iteration:    640, Loss function: 6.363, Average Loss: 3.762, avg. samples / sec: 52905.30
Iteration:    640, Loss function: 5.532, Average Loss: 3.775, avg. samples / sec: 52845.87
Iteration:    640, Loss function: 6.411, Average Loss: 3.773, avg. samples / sec: 52683.44
Iteration:    640, Loss function: 6.270, Average Loss: 3.779, avg. samples / sec: 52657.79
Iteration:    640, Loss function: 5.314, Average Loss: 3.801, avg. samples / sec: 52839.35
Iteration:    640, Loss function: 5.605, Average Loss: 3.770, avg. samples / sec: 52622.30
Iteration:    660, Loss function: 6.217, Average Loss: 3.824, avg. samples / sec: 53322.91
Iteration:    660, Loss function: 5.292, Average Loss: 3.788, avg. samples / sec: 53233.54
Iteration:    660, Loss function: 5.156, Average Loss: 3.796, avg. samples / sec: 53499.47
Iteration:    660, Loss function: 5.557, Average Loss: 3.806, avg. samples / sec: 53470.58
Iteration:    660, Loss function: 7.177, Average Loss: 3.812, avg. samples / sec: 53687.68
Iteration:    660, Loss function: 5.813, Average Loss: 3.792, avg. samples / sec: 53252.29
Iteration:    660, Loss function: 5.468, Average Loss: 3.805, avg. samples / sec: 53125.18
Iteration:    660, Loss function: 5.572, Average Loss: 3.811, avg. samples / sec: 53236.88
Iteration:    660, Loss function: 5.879, Average Loss: 3.801, avg. samples / sec: 53238.79
Iteration:    660, Loss function: 5.413, Average Loss: 3.827, avg. samples / sec: 53157.46
Iteration:    660, Loss function: 5.527, Average Loss: 3.836, avg. samples / sec: 53222.58
Iteration:    660, Loss function: 6.532, Average Loss: 3.809, avg. samples / sec: 53157.14
Iteration:    660, Loss function: 5.707, Average Loss: 3.766, avg. samples / sec: 53175.75
Iteration:    660, Loss function: 5.074, Average Loss: 3.818, avg. samples / sec: 53305.73
Iteration:    660, Loss function: 6.666, Average Loss: 3.821, avg. samples / sec: 53091.64
Iteration:    660, Loss function: 6.329, Average Loss: 3.787, avg. samples / sec: 53238.17
Iteration:    660, Loss function: 6.150, Average Loss: 3.797, avg. samples / sec: 52993.25
Iteration:    660, Loss function: 5.014, Average Loss: 3.822, avg. samples / sec: 53052.04
Iteration:    660, Loss function: 5.990, Average Loss: 3.805, avg. samples / sec: 53000.69
Iteration:    660, Loss function: 5.787, Average Loss: 3.803, avg. samples / sec: 53215.75
Iteration:    660, Loss function: 5.883, Average Loss: 3.797, avg. samples / sec: 53203.07
Iteration:    660, Loss function: 6.405, Average Loss: 3.795, avg. samples / sec: 53205.57
Iteration:    660, Loss function: 6.674, Average Loss: 3.822, avg. samples / sec: 53212.70
Iteration:    660, Loss function: 4.969, Average Loss: 3.814, avg. samples / sec: 53224.19
Iteration:    660, Loss function: 6.165, Average Loss: 3.817, avg. samples / sec: 53244.66
Iteration:    660, Loss function: 7.569, Average Loss: 3.805, avg. samples / sec: 53198.36
Iteration:    660, Loss function: 5.692, Average Loss: 3.805, avg. samples / sec: 53206.59
Iteration:    660, Loss function: 5.478, Average Loss: 3.800, avg. samples / sec: 52961.23
Iteration:    660, Loss function: 6.617, Average Loss: 3.825, avg. samples / sec: 52899.60
Iteration:    660, Loss function: 4.470, Average Loss: 3.831, avg. samples / sec: 53214.00
Iteration:    680, Loss function: 5.344, Average Loss: 3.826, avg. samples / sec: 52906.02
Iteration:    680, Loss function: 5.312, Average Loss: 3.862, avg. samples / sec: 53367.25
Iteration:    680, Loss function: 7.278, Average Loss: 3.860, avg. samples / sec: 52790.54
Iteration:    680, Loss function: 6.722, Average Loss: 3.837, avg. samples / sec: 52992.97
Iteration:    680, Loss function: 4.926, Average Loss: 3.840, avg. samples / sec: 52957.03
Iteration:    680, Loss function: 5.509, Average Loss: 3.837, avg. samples / sec: 52863.83
Iteration:    680, Loss function: 5.174, Average Loss: 3.859, avg. samples / sec: 52967.08
Iteration:    680, Loss function: 4.738, Average Loss: 3.844, avg. samples / sec: 53164.40
Iteration:    680, Loss function: 4.711, Average Loss: 3.869, avg. samples / sec: 53250.60
Iteration:    680, Loss function: 4.324, Average Loss: 3.870, avg. samples / sec: 52973.61
Iteration:    680, Loss function: 6.368, Average Loss: 3.844, avg. samples / sec: 52967.66
Iteration:    680, Loss function: 6.085, Average Loss: 3.858, avg. samples / sec: 53053.18
Iteration:    680, Loss function: 5.633, Average Loss: 3.833, avg. samples / sec: 52896.23
Iteration:    680, Loss function: 6.312, Average Loss: 3.858, avg. samples / sec: 53112.40
Iteration:    680, Loss function: 5.423, Average Loss: 3.838, avg. samples / sec: 53105.48
Iteration:    680, Loss function: 5.314, Average Loss: 3.843, avg. samples / sec: 53134.07
Iteration:    680, Loss function: 6.620, Average Loss: 3.851, avg. samples / sec: 52861.07
Iteration:    680, Loss function: 5.197, Average Loss: 3.850, avg. samples / sec: 53040.58
Iteration:    680, Loss function: 5.879, Average Loss: 3.832, avg. samples / sec: 52991.92
Iteration:    680, Loss function: 4.919, Average Loss: 3.826, avg. samples / sec: 52919.35
Iteration:    680, Loss function: 6.510, Average Loss: 3.832, avg. samples / sec: 52919.86
Iteration:    680, Loss function: 7.319, Average Loss: 3.857, avg. samples / sec: 52847.75
Iteration:    680, Loss function: 5.221, Average Loss: 3.854, avg. samples / sec: 52953.07
Iteration:    680, Loss function: 4.944, Average Loss: 3.838, avg. samples / sec: 52656.00
Iteration:    680, Loss function: 7.540, Average Loss: 3.846, avg. samples / sec: 52940.76
Iteration:    680, Loss function: 5.260, Average Loss: 3.831, avg. samples / sec: 52921.29
Iteration:    680, Loss function: 5.534, Average Loss: 3.862, avg. samples / sec: 52912.43
Iteration:    680, Loss function: 6.453, Average Loss: 3.837, avg. samples / sec: 52921.87
Iteration:    680, Loss function: 3.877, Average Loss: 3.807, avg. samples / sec: 52627.78
Iteration:    680, Loss function: 4.997, Average Loss: 3.842, avg. samples / sec: 52202.20
:::MLL 1558640872.397 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558640872.398 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 6.435, Average Loss: 3.896, avg. samples / sec: 53337.76
Iteration:    700, Loss function: 5.821, Average Loss: 3.870, avg. samples / sec: 53659.72
Iteration:    700, Loss function: 6.653, Average Loss: 3.884, avg. samples / sec: 53371.92
Iteration:    700, Loss function: 7.298, Average Loss: 3.894, avg. samples / sec: 53346.41
Iteration:    700, Loss function: 6.037, Average Loss: 3.864, avg. samples / sec: 53205.12
Iteration:    700, Loss function: 5.184, Average Loss: 3.897, avg. samples / sec: 53207.45
Iteration:    700, Loss function: 7.006, Average Loss: 3.871, avg. samples / sec: 53341.20
Iteration:    700, Loss function: 7.412, Average Loss: 3.872, avg. samples / sec: 53377.58
Iteration:    700, Loss function: 6.816, Average Loss: 3.872, avg. samples / sec: 53233.10
Iteration:    700, Loss function: 5.551, Average Loss: 3.904, avg. samples / sec: 53274.96
Iteration:    700, Loss function: 4.696, Average Loss: 3.872, avg. samples / sec: 53256.09
Iteration:    700, Loss function: 6.403, Average Loss: 3.872, avg. samples / sec: 53224.47
Iteration:    700, Loss function: 5.940, Average Loss: 3.888, avg. samples / sec: 53188.16
Iteration:    700, Loss function: 6.179, Average Loss: 3.868, avg. samples / sec: 53368.95
Iteration:    700, Loss function: 6.568, Average Loss: 3.894, avg. samples / sec: 53187.87
Iteration:    700, Loss function: 6.067, Average Loss: 3.838, avg. samples / sec: 53469.95
Iteration:    700, Loss function: 7.074, Average Loss: 3.892, avg. samples / sec: 53312.89
Iteration:    700, Loss function: 6.251, Average Loss: 3.869, avg. samples / sec: 53276.33
Iteration:    700, Loss function: 6.069, Average Loss: 3.877, avg. samples / sec: 53065.83
Iteration:    700, Loss function: 5.488, Average Loss: 3.862, avg. samples / sec: 53250.44
Iteration:    700, Loss function: 6.444, Average Loss: 3.878, avg. samples / sec: 53134.15
Iteration:    700, Loss function: 5.682, Average Loss: 3.884, avg. samples / sec: 53211.79
Iteration:    700, Loss function: 7.424, Average Loss: 3.879, avg. samples / sec: 53299.50
Iteration:    700, Loss function: 5.454, Average Loss: 3.901, avg. samples / sec: 53322.51
Iteration:    700, Loss function: 6.139, Average Loss: 3.891, avg. samples / sec: 53286.72
Iteration:    700, Loss function: 7.280, Average Loss: 3.881, avg. samples / sec: 53299.90
Iteration:    700, Loss function: 6.235, Average Loss: 3.879, avg. samples / sec: 53664.13
Iteration:    700, Loss function: 5.536, Average Loss: 3.866, avg. samples / sec: 53194.34
Iteration:    700, Loss function: 5.499, Average Loss: 3.909, avg. samples / sec: 52787.63
Iteration:    700, Loss function: 5.071, Average Loss: 3.887, avg. samples / sec: 52312.19
Iteration:    720, Loss function: 5.924, Average Loss: 3.906, avg. samples / sec: 53457.21
Iteration:    720, Loss function: 6.122, Average Loss: 3.912, avg. samples / sec: 53479.20
Iteration:    720, Loss function: 5.548, Average Loss: 3.936, avg. samples / sec: 53296.01
Iteration:    720, Loss function: 6.416, Average Loss: 3.901, avg. samples / sec: 53662.93
Iteration:    720, Loss function: 5.101, Average Loss: 3.910, avg. samples / sec: 53438.61
Iteration:    720, Loss function: 5.797, Average Loss: 3.920, avg. samples / sec: 53525.62
Iteration:    720, Loss function: 4.785, Average Loss: 3.916, avg. samples / sec: 53318.29
Iteration:    720, Loss function: 4.954, Average Loss: 3.908, avg. samples / sec: 53424.49
Iteration:    720, Loss function: 4.963, Average Loss: 3.923, avg. samples / sec: 54471.52
Iteration:    720, Loss function: 6.791, Average Loss: 3.941, avg. samples / sec: 53308.25
Iteration:    720, Loss function: 5.190, Average Loss: 3.906, avg. samples / sec: 53334.45
Iteration:    720, Loss function: 5.373, Average Loss: 3.916, avg. samples / sec: 53696.09
Iteration:    720, Loss function: 4.284, Average Loss: 3.906, avg. samples / sec: 53338.07
Iteration:    720, Loss function: 4.903, Average Loss: 3.906, avg. samples / sec: 53548.19
Iteration:    720, Loss function: 5.782, Average Loss: 3.916, avg. samples / sec: 53553.06
Iteration:    720, Loss function: 6.163, Average Loss: 3.947, avg. samples / sec: 53335.87
Iteration:    720, Loss function: 5.440, Average Loss: 3.910, avg. samples / sec: 53538.71
Iteration:    720, Loss function: 5.850, Average Loss: 3.949, avg. samples / sec: 53822.05
Iteration:    720, Loss function: 5.919, Average Loss: 3.934, avg. samples / sec: 53168.53
Iteration:    720, Loss function: 4.445, Average Loss: 3.936, avg. samples / sec: 53388.60
Iteration:    720, Loss function: 6.007, Average Loss: 3.929, avg. samples / sec: 53361.70
Iteration:    720, Loss function: 5.602, Average Loss: 3.905, avg. samples / sec: 53496.44
Iteration:    720, Loss function: 5.407, Average Loss: 3.925, avg. samples / sec: 53364.89
Iteration:    720, Loss function: 4.450, Average Loss: 3.932, avg. samples / sec: 53375.52
Iteration:    720, Loss function: 5.754, Average Loss: 3.918, avg. samples / sec: 53360.59
Iteration:    720, Loss function: 6.037, Average Loss: 3.921, avg. samples / sec: 53366.26
Iteration:    720, Loss function: 4.750, Average Loss: 3.911, avg. samples / sec: 53022.78
Iteration:    720, Loss function: 4.676, Average Loss: 3.929, avg. samples / sec: 53195.56
Iteration:    720, Loss function: 5.240, Average Loss: 3.906, avg. samples / sec: 53141.65
Iteration:    720, Loss function: 5.012, Average Loss: 3.874, avg. samples / sec: 52782.27
Iteration:    740, Loss function: 5.737, Average Loss: 3.950, avg. samples / sec: 53473.67
Iteration:    740, Loss function: 6.037, Average Loss: 3.960, avg. samples / sec: 53601.53
Iteration:    740, Loss function: 5.649, Average Loss: 3.951, avg. samples / sec: 53272.44
Iteration:    740, Loss function: 5.596, Average Loss: 3.936, avg. samples / sec: 53488.62
Iteration:    740, Loss function: 6.070, Average Loss: 3.985, avg. samples / sec: 53292.52
Iteration:    740, Loss function: 5.549, Average Loss: 3.941, avg. samples / sec: 53133.37
Iteration:    740, Loss function: 5.484, Average Loss: 3.941, avg. samples / sec: 53058.39
Iteration:    740, Loss function: 5.767, Average Loss: 3.938, avg. samples / sec: 53079.14
Iteration:    740, Loss function: 6.322, Average Loss: 3.975, avg. samples / sec: 53036.13
Iteration:    740, Loss function: 5.319, Average Loss: 3.968, avg. samples / sec: 52954.94
Iteration:    740, Loss function: 4.544, Average Loss: 3.931, avg. samples / sec: 52953.99
Iteration:    740, Loss function: 5.645, Average Loss: 3.936, avg. samples / sec: 53372.16
Iteration:    740, Loss function: 5.548, Average Loss: 3.944, avg. samples / sec: 53270.67
Iteration:    740, Loss function: 5.453, Average Loss: 3.980, avg. samples / sec: 52976.88
Iteration:    740, Loss function: 4.635, Average Loss: 3.964, avg. samples / sec: 53128.24
Iteration:    740, Loss function: 5.554, Average Loss: 3.939, avg. samples / sec: 52912.99
Iteration:    740, Loss function: 4.987, Average Loss: 3.955, avg. samples / sec: 53054.20
Iteration:    740, Loss function: 5.972, Average Loss: 3.938, avg. samples / sec: 52664.50
Iteration:    740, Loss function: 6.974, Average Loss: 3.955, avg. samples / sec: 52731.71
Iteration:    740, Loss function: 6.468, Average Loss: 3.940, avg. samples / sec: 52564.24
Iteration:    740, Loss function: 6.688, Average Loss: 3.937, avg. samples / sec: 52740.34
Iteration:    740, Loss function: 4.682, Average Loss: 3.937, avg. samples / sec: 52639.97
Iteration:    740, Loss function: 6.190, Average Loss: 3.948, avg. samples / sec: 52796.27
Iteration:    740, Loss function: 5.307, Average Loss: 3.970, avg. samples / sec: 52685.39
Iteration:    740, Loss function: 5.738, Average Loss: 3.960, avg. samples / sec: 52857.86
Iteration:    740, Loss function: 4.811, Average Loss: 3.933, avg. samples / sec: 52533.20
Iteration:    740, Loss function: 5.079, Average Loss: 3.950, avg. samples / sec: 52766.58
Iteration:    740, Loss function: 6.201, Average Loss: 3.904, avg. samples / sec: 53296.76
Iteration:    740, Loss function: 4.325, Average Loss: 3.953, avg. samples / sec: 52694.94
Iteration:    740, Loss function: 6.093, Average Loss: 3.950, avg. samples / sec: 52238.15
Iteration:    760, Loss function: 4.881, Average Loss: 3.964, avg. samples / sec: 54384.14
Iteration:    760, Loss function: 4.832, Average Loss: 3.969, avg. samples / sec: 54210.57
Iteration:    760, Loss function: 5.589, Average Loss: 3.994, avg. samples / sec: 53941.80
Iteration:    760, Loss function: 5.618, Average Loss: 4.003, avg. samples / sec: 53882.86
Iteration:    760, Loss function: 5.463, Average Loss: 3.970, avg. samples / sec: 53811.34
Iteration:    760, Loss function: 5.118, Average Loss: 3.988, avg. samples / sec: 53542.74
Iteration:    760, Loss function: 5.671, Average Loss: 3.971, avg. samples / sec: 54254.63
Iteration:    760, Loss function: 4.923, Average Loss: 4.013, avg. samples / sec: 53642.05
Iteration:    760, Loss function: 6.099, Average Loss: 3.972, avg. samples / sec: 53846.72
Iteration:    760, Loss function: 5.267, Average Loss: 3.964, avg. samples / sec: 54384.01
Iteration:    760, Loss function: 7.543, Average Loss: 3.970, avg. samples / sec: 54020.70
Iteration:    760, Loss function: 5.349, Average Loss: 3.983, avg. samples / sec: 54148.96
Iteration:    760, Loss function: 5.379, Average Loss: 3.982, avg. samples / sec: 53543.86
Iteration:    760, Loss function: 5.206, Average Loss: 3.998, avg. samples / sec: 54328.04
Iteration:    760, Loss function: 5.205, Average Loss: 3.992, avg. samples / sec: 54331.18
Iteration:    760, Loss function: 5.907, Average Loss: 3.938, avg. samples / sec: 54216.35
Iteration:    760, Loss function: 3.480, Average Loss: 3.980, avg. samples / sec: 54182.77
Iteration:    760, Loss function: 5.566, Average Loss: 3.964, avg. samples / sec: 53410.50
Iteration:    760, Loss function: 6.371, Average Loss: 3.986, avg. samples / sec: 53830.91
Iteration:    760, Loss function: 6.753, Average Loss: 3.966, avg. samples / sec: 53986.56
Iteration:    760, Loss function: 6.178, Average Loss: 3.968, avg. samples / sec: 53649.77
Iteration:    760, Loss function: 4.489, Average Loss: 3.981, avg. samples / sec: 54106.21
Iteration:    760, Loss function: 4.681, Average Loss: 3.977, avg. samples / sec: 54495.13
Iteration:    760, Loss function: 5.747, Average Loss: 3.982, avg. samples / sec: 53185.73
Iteration:    760, Loss function: 5.236, Average Loss: 3.988, avg. samples / sec: 54198.94
Iteration:    760, Loss function: 5.431, Average Loss: 3.993, avg. samples / sec: 53720.10
Iteration:    760, Loss function: 5.158, Average Loss: 3.958, avg. samples / sec: 53606.37
Iteration:    760, Loss function: 4.392, Average Loss: 3.967, avg. samples / sec: 53455.07
Iteration:    760, Loss function: 5.482, Average Loss: 3.974, avg. samples / sec: 53606.10
Iteration:    760, Loss function: 4.808, Average Loss: 4.010, avg. samples / sec: 53684.53
:::MLL 1558640874.601 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558640874.602 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 6.285, Average Loss: 3.967, avg. samples / sec: 53672.02
Iteration:    780, Loss function: 5.405, Average Loss: 4.019, avg. samples / sec: 53360.12
Iteration:    780, Loss function: 5.143, Average Loss: 3.987, avg. samples / sec: 53223.39
Iteration:    780, Loss function: 4.364, Average Loss: 3.996, avg. samples / sec: 53245.41
Iteration:    780, Loss function: 5.699, Average Loss: 4.031, avg. samples / sec: 53299.84
Iteration:    780, Loss function: 4.818, Average Loss: 4.009, avg. samples / sec: 53363.41
Iteration:    780, Loss function: 5.344, Average Loss: 3.995, avg. samples / sec: 53318.31
Iteration:    780, Loss function: 4.751, Average Loss: 3.995, avg. samples / sec: 53291.39
Iteration:    780, Loss function: 5.911, Average Loss: 4.025, avg. samples / sec: 53358.26
Iteration:    780, Loss function: 4.947, Average Loss: 4.014, avg. samples / sec: 53283.01
Iteration:    780, Loss function: 5.749, Average Loss: 3.999, avg. samples / sec: 53279.45
Iteration:    780, Loss function: 4.603, Average Loss: 3.995, avg. samples / sec: 53535.30
Iteration:    780, Loss function: 5.674, Average Loss: 3.990, avg. samples / sec: 53253.54
Iteration:    780, Loss function: 5.886, Average Loss: 4.032, avg. samples / sec: 53287.04
Iteration:    780, Loss function: 5.775, Average Loss: 4.039, avg. samples / sec: 53236.58
Iteration:    780, Loss function: 5.887, Average Loss: 3.998, avg. samples / sec: 53200.87
Iteration:    780, Loss function: 5.334, Average Loss: 4.018, avg. samples / sec: 53320.95
Iteration:    780, Loss function: 5.946, Average Loss: 3.994, avg. samples / sec: 53299.68
Iteration:    780, Loss function: 5.984, Average Loss: 4.003, avg. samples / sec: 53312.60
Iteration:    780, Loss function: 5.732, Average Loss: 4.012, avg. samples / sec: 53295.14
Iteration:    780, Loss function: 6.360, Average Loss: 4.016, avg. samples / sec: 53296.72
Iteration:    780, Loss function: 5.096, Average Loss: 3.986, avg. samples / sec: 53310.47
Iteration:    780, Loss function: 5.757, Average Loss: 4.026, avg. samples / sec: 53296.07
Iteration:    780, Loss function: 4.566, Average Loss: 4.001, avg. samples / sec: 53256.45
Iteration:    780, Loss function: 4.789, Average Loss: 3.994, avg. samples / sec: 53231.01
Iteration:    780, Loss function: 4.765, Average Loss: 4.043, avg. samples / sec: 53299.32
Iteration:    780, Loss function: 5.390, Average Loss: 4.012, avg. samples / sec: 52998.00
Iteration:    780, Loss function: 5.574, Average Loss: 4.007, avg. samples / sec: 53207.49
Iteration:    780, Loss function: 6.149, Average Loss: 4.005, avg. samples / sec: 53269.42
Iteration:    780, Loss function: 4.977, Average Loss: 4.004, avg. samples / sec: 52964.22
Iteration:    800, Loss function: 6.531, Average Loss: 4.018, avg. samples / sec: 53672.90
Iteration:    800, Loss function: 4.942, Average Loss: 4.050, avg. samples / sec: 53884.03
Iteration:    800, Loss function: 5.650, Average Loss: 4.048, avg. samples / sec: 53525.52
Iteration:    800, Loss function: 5.965, Average Loss: 4.037, avg. samples / sec: 53973.14
Iteration:    800, Loss function: 4.419, Average Loss: 4.027, avg. samples / sec: 53581.07
Iteration:    800, Loss function: 5.689, Average Loss: 4.057, avg. samples / sec: 53573.35
Iteration:    800, Loss function: 5.434, Average Loss: 4.022, avg. samples / sec: 53523.83
Iteration:    800, Loss function: 5.011, Average Loss: 4.020, avg. samples / sec: 53535.72
Iteration:    800, Loss function: 4.400, Average Loss: 4.021, avg. samples / sec: 53578.93
Iteration:    800, Loss function: 5.045, Average Loss: 4.022, avg. samples / sec: 53565.35
Iteration:    800, Loss function: 5.765, Average Loss: 4.071, avg. samples / sec: 53565.11
Iteration:    800, Loss function: 3.785, Average Loss: 4.020, avg. samples / sec: 53779.30
Iteration:    800, Loss function: 4.936, Average Loss: 4.042, avg. samples / sec: 53462.71
Iteration:    800, Loss function: 4.572, Average Loss: 4.025, avg. samples / sec: 53554.50
Iteration:    800, Loss function: 5.220, Average Loss: 4.044, avg. samples / sec: 53468.00
Iteration:    800, Loss function: 5.247, Average Loss: 4.058, avg. samples / sec: 53488.99
Iteration:    800, Loss function: 6.001, Average Loss: 4.023, avg. samples / sec: 53573.90
Iteration:    800, Loss function: 4.765, Average Loss: 4.055, avg. samples / sec: 53602.23
Iteration:    800, Loss function: 5.596, Average Loss: 4.013, avg. samples / sec: 53594.93
Iteration:    800, Loss function: 4.218, Average Loss: 4.034, avg. samples / sec: 53586.02
Iteration:    800, Loss function: 4.605, Average Loss: 4.028, avg. samples / sec: 53631.42
Iteration:    800, Loss function: 5.845, Average Loss: 4.044, avg. samples / sec: 53574.02
Iteration:    800, Loss function: 4.674, Average Loss: 4.054, avg. samples / sec: 53298.85
Iteration:    800, Loss function: 5.627, Average Loss: 4.033, avg. samples / sec: 53579.10
Iteration:    800, Loss function: 4.780, Average Loss: 4.031, avg. samples / sec: 53341.18
Iteration:    800, Loss function: 5.809, Average Loss: 4.030, avg. samples / sec: 53544.61
Iteration:    800, Loss function: 6.571, Average Loss: 4.031, avg. samples / sec: 53894.81
Iteration:    800, Loss function: 5.145, Average Loss: 4.043, avg. samples / sec: 53589.55
Iteration:    800, Loss function: 5.300, Average Loss: 3.998, avg. samples / sec: 53095.12
Iteration:    800, Loss function: 5.520, Average Loss: 4.073, avg. samples / sec: 53570.26
Iteration:    820, Loss function: 4.810, Average Loss: 4.050, avg. samples / sec: 53688.69
Iteration:    820, Loss function: 5.517, Average Loss: 4.075, avg. samples / sec: 53722.95
Iteration:    820, Loss function: 5.057, Average Loss: 4.050, avg. samples / sec: 53716.80
Iteration:    820, Loss function: 7.146, Average Loss: 4.083, avg. samples / sec: 53918.35
Iteration:    820, Loss function: 5.878, Average Loss: 4.059, avg. samples / sec: 53928.09
Iteration:    820, Loss function: 6.382, Average Loss: 4.054, avg. samples / sec: 53654.63
Iteration:    820, Loss function: 5.482, Average Loss: 4.051, avg. samples / sec: 53603.12
Iteration:    820, Loss function: 4.682, Average Loss: 4.048, avg. samples / sec: 53749.48
Iteration:    820, Loss function: 5.440, Average Loss: 4.082, avg. samples / sec: 53588.16
Iteration:    820, Loss function: 6.049, Average Loss: 4.070, avg. samples / sec: 53698.47
Iteration:    820, Loss function: 6.201, Average Loss: 4.048, avg. samples / sec: 53642.07
Iteration:    820, Loss function: 5.363, Average Loss: 4.076, avg. samples / sec: 53711.09
Iteration:    820, Loss function: 5.201, Average Loss: 4.088, avg. samples / sec: 53707.53
Iteration:    820, Loss function: 4.958, Average Loss: 4.044, avg. samples / sec: 53596.58
Iteration:    820, Loss function: 5.740, Average Loss: 4.069, avg. samples / sec: 53811.93
Iteration:    820, Loss function: 4.541, Average Loss: 4.061, avg. samples / sec: 53752.99
Iteration:    820, Loss function: 4.728, Average Loss: 4.064, avg. samples / sec: 53720.92
Iteration:    820, Loss function: 5.524, Average Loss: 4.058, avg. samples / sec: 53714.70
Iteration:    820, Loss function: 5.469, Average Loss: 4.059, avg. samples / sec: 53704.36
Iteration:    820, Loss function: 5.879, Average Loss: 4.048, avg. samples / sec: 53632.62
Iteration:    820, Loss function: 5.002, Average Loss: 4.096, avg. samples / sec: 53477.76
Iteration:    820, Loss function: 4.854, Average Loss: 4.050, avg. samples / sec: 53637.13
Iteration:    820, Loss function: 5.012, Average Loss: 4.044, avg. samples / sec: 53473.62
Iteration:    820, Loss function: 5.723, Average Loss: 4.063, avg. samples / sec: 53625.62
Iteration:    820, Loss function: 5.502, Average Loss: 4.075, avg. samples / sec: 53281.40
Iteration:    820, Loss function: 5.244, Average Loss: 4.023, avg. samples / sec: 53668.04
Iteration:    820, Loss function: 5.776, Average Loss: 4.080, avg. samples / sec: 53605.20
Iteration:    820, Loss function: 5.901, Average Loss: 4.100, avg. samples / sec: 53628.01
Iteration:    820, Loss function: 5.331, Average Loss: 4.062, avg. samples / sec: 53243.03
Iteration:    820, Loss function: 5.540, Average Loss: 4.053, avg. samples / sec: 53548.95
:::MLL 1558640876.801 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558640876.802 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 4.766, Average Loss: 4.103, avg. samples / sec: 53525.21
Iteration:    840, Loss function: 4.006, Average Loss: 4.097, avg. samples / sec: 53025.67
Iteration:    840, Loss function: 5.452, Average Loss: 4.081, avg. samples / sec: 53190.20
Iteration:    840, Loss function: 4.291, Average Loss: 4.076, avg. samples / sec: 53193.17
Iteration:    840, Loss function: 5.445, Average Loss: 4.116, avg. samples / sec: 53377.30
Iteration:    840, Loss function: 4.635, Average Loss: 4.067, avg. samples / sec: 53216.01
Iteration:    840, Loss function: 4.648, Average Loss: 4.106, avg. samples / sec: 53151.27
Iteration:    840, Loss function: 6.294, Average Loss: 4.074, avg. samples / sec: 53016.54
Iteration:    840, Loss function: 5.340, Average Loss: 4.114, avg. samples / sec: 53080.14
Iteration:    840, Loss function: 5.424, Average Loss: 4.084, avg. samples / sec: 53046.03
Iteration:    840, Loss function: 4.769, Average Loss: 4.100, avg. samples / sec: 53107.98
Iteration:    840, Loss function: 4.947, Average Loss: 4.082, avg. samples / sec: 53036.25
Iteration:    840, Loss function: 5.788, Average Loss: 4.071, avg. samples / sec: 53249.95
Iteration:    840, Loss function: 4.190, Average Loss: 4.095, avg. samples / sec: 53037.51
Iteration:    840, Loss function: 5.937, Average Loss: 4.075, avg. samples / sec: 53001.62
Iteration:    840, Loss function: 5.094, Average Loss: 4.108, avg. samples / sec: 53067.59
Iteration:    840, Loss function: 5.066, Average Loss: 4.048, avg. samples / sec: 53215.41
Iteration:    840, Loss function: 4.655, Average Loss: 4.107, avg. samples / sec: 53221.86
Iteration:    840, Loss function: 4.121, Average Loss: 4.086, avg. samples / sec: 53058.10
Iteration:    840, Loss function: 5.383, Average Loss: 4.091, avg. samples / sec: 53014.01
Iteration:    840, Loss function: 5.693, Average Loss: 4.082, avg. samples / sec: 53094.22
Iteration:    840, Loss function: 5.402, Average Loss: 4.075, avg. samples / sec: 53166.00
Iteration:    840, Loss function: 5.820, Average Loss: 4.086, avg. samples / sec: 53088.32
Iteration:    840, Loss function: 6.029, Average Loss: 4.065, avg. samples / sec: 53045.09
Iteration:    840, Loss function: 5.292, Average Loss: 4.090, avg. samples / sec: 52948.93
Iteration:    840, Loss function: 5.022, Average Loss: 4.088, avg. samples / sec: 52958.92
Iteration:    840, Loss function: 4.364, Average Loss: 4.061, avg. samples / sec: 52998.89
Iteration:    840, Loss function: 5.462, Average Loss: 4.089, avg. samples / sec: 53059.09
Iteration:    840, Loss function: 6.505, Average Loss: 4.127, avg. samples / sec: 53002.22
Iteration:    840, Loss function: 5.058, Average Loss: 4.081, avg. samples / sec: 52233.82
Iteration:    860, Loss function: 4.579, Average Loss: 4.119, avg. samples / sec: 53576.55
Iteration:    860, Loss function: 3.691, Average Loss: 4.138, avg. samples / sec: 53589.75
Iteration:    860, Loss function: 5.783, Average Loss: 4.107, avg. samples / sec: 54208.90
Iteration:    860, Loss function: 4.152, Average Loss: 4.118, avg. samples / sec: 53737.68
Iteration:    860, Loss function: 5.962, Average Loss: 4.113, avg. samples / sec: 53620.42
Iteration:    860, Loss function: 4.667, Average Loss: 4.104, avg. samples / sec: 53413.03
Iteration:    860, Loss function: 5.444, Average Loss: 4.097, avg. samples / sec: 53498.33
Iteration:    860, Loss function: 5.965, Average Loss: 4.133, avg. samples / sec: 53441.18
Iteration:    860, Loss function: 4.912, Average Loss: 4.089, avg. samples / sec: 53438.00
Iteration:    860, Loss function: 5.093, Average Loss: 4.108, avg. samples / sec: 53512.12
Iteration:    860, Loss function: 4.455, Average Loss: 4.126, avg. samples / sec: 53614.93
Iteration:    860, Loss function: 5.426, Average Loss: 4.105, avg. samples / sec: 53513.99
Iteration:    860, Loss function: 5.146, Average Loss: 4.131, avg. samples / sec: 53566.88
Iteration:    860, Loss function: 5.906, Average Loss: 4.101, avg. samples / sec: 53390.32
Iteration:    860, Loss function: 5.034, Average Loss: 4.143, avg. samples / sec: 53385.57
Iteration:    860, Loss function: 5.663, Average Loss: 4.098, avg. samples / sec: 53518.28
Iteration:    860, Loss function: 6.467, Average Loss: 4.127, avg. samples / sec: 53442.94
Iteration:    860, Loss function: 5.982, Average Loss: 4.086, avg. samples / sec: 53570.26
Iteration:    860, Loss function: 4.886, Average Loss: 4.102, avg. samples / sec: 53468.43
Iteration:    860, Loss function: 4.223, Average Loss: 4.078, avg. samples / sec: 53609.18
Iteration:    860, Loss function: 5.338, Average Loss: 4.128, avg. samples / sec: 53086.94
Iteration:    860, Loss function: 4.140, Average Loss: 4.095, avg. samples / sec: 53329.37
Iteration:    860, Loss function: 4.551, Average Loss: 4.150, avg. samples / sec: 53652.96
Iteration:    860, Loss function: 5.916, Average Loss: 4.111, avg. samples / sec: 53586.29
Iteration:    860, Loss function: 4.799, Average Loss: 4.110, avg. samples / sec: 53430.16
Iteration:    860, Loss function: 4.892, Average Loss: 4.109, avg. samples / sec: 53575.78
Iteration:    860, Loss function: 5.853, Average Loss: 4.119, avg. samples / sec: 53588.45
Iteration:    860, Loss function: 5.760, Average Loss: 4.108, avg. samples / sec: 53494.53
Iteration:    860, Loss function: 4.537, Average Loss: 4.091, avg. samples / sec: 53495.16
Iteration:    860, Loss function: 5.930, Average Loss: 4.073, avg. samples / sec: 53368.99
Iteration:    880, Loss function: 5.336, Average Loss: 4.135, avg. samples / sec: 53972.85
Iteration:    880, Loss function: 4.758, Average Loss: 4.106, avg. samples / sec: 54276.40
Iteration:    880, Loss function: 6.084, Average Loss: 4.145, avg. samples / sec: 53814.22
Iteration:    880, Loss function: 5.392, Average Loss: 4.169, avg. samples / sec: 54061.46
Iteration:    880, Loss function: 5.614, Average Loss: 4.163, avg. samples / sec: 53863.95
Iteration:    880, Loss function: 5.026, Average Loss: 4.131, avg. samples / sec: 53884.79
Iteration:    880, Loss function: 5.327, Average Loss: 4.124, avg. samples / sec: 53899.42
Iteration:    880, Loss function: 5.562, Average Loss: 4.111, avg. samples / sec: 53874.49
Iteration:    880, Loss function: 5.546, Average Loss: 4.138, avg. samples / sec: 53814.71
Iteration:    880, Loss function: 4.356, Average Loss: 4.152, avg. samples / sec: 53882.48
Iteration:    880, Loss function: 5.062, Average Loss: 4.134, avg. samples / sec: 53822.91
Iteration:    880, Loss function: 5.888, Average Loss: 4.124, avg. samples / sec: 53830.56
Iteration:    880, Loss function: 5.035, Average Loss: 4.145, avg. samples / sec: 53936.31
Iteration:    880, Loss function: 5.256, Average Loss: 4.124, avg. samples / sec: 53876.86
Iteration:    880, Loss function: 5.774, Average Loss: 4.160, avg. samples / sec: 53834.96
Iteration:    880, Loss function: 4.639, Average Loss: 4.146, avg. samples / sec: 53838.45
Iteration:    880, Loss function: 5.135, Average Loss: 4.140, avg. samples / sec: 54016.89
Iteration:    880, Loss function: 5.501, Average Loss: 4.137, avg. samples / sec: 53914.54
Iteration:    880, Loss function: 6.410, Average Loss: 4.110, avg. samples / sec: 53889.68
Iteration:    880, Loss function: 4.555, Average Loss: 4.137, avg. samples / sec: 53928.65
Iteration:    880, Loss function: 4.474, Average Loss: 4.118, avg. samples / sec: 53901.55
Iteration:    880, Loss function: 4.818, Average Loss: 4.123, avg. samples / sec: 53727.21
Iteration:    880, Loss function: 5.874, Average Loss: 4.121, avg. samples / sec: 53888.69
Iteration:    880, Loss function: 5.438, Average Loss: 4.136, avg. samples / sec: 53874.31
Iteration:    880, Loss function: 4.355, Average Loss: 4.155, avg. samples / sec: 53848.39
Iteration:    880, Loss function: 5.610, Average Loss: 4.134, avg. samples / sec: 53866.93
Iteration:    880, Loss function: 4.828, Average Loss: 4.140, avg. samples / sec: 53543.86
Iteration:    880, Loss function: 6.571, Average Loss: 4.131, avg. samples / sec: 53817.77
Iteration:    880, Loss function: 5.790, Average Loss: 4.099, avg. samples / sec: 53847.03
Iteration:    880, Loss function: 5.669, Average Loss: 4.172, avg. samples / sec: 53810.35
Iteration:    900, Loss function: 5.277, Average Loss: 4.153, avg. samples / sec: 53731.10
Iteration:    900, Loss function: 5.123, Average Loss: 4.165, avg. samples / sec: 53668.04
Iteration:    900, Loss function: 5.303, Average Loss: 4.150, avg. samples / sec: 53780.86
Iteration:    900, Loss function: 5.269, Average Loss: 4.158, avg. samples / sec: 53759.22
Iteration:    900, Loss function: 5.306, Average Loss: 4.157, avg. samples / sec: 54002.73
Iteration:    900, Loss function: 3.964, Average Loss: 4.182, avg. samples / sec: 53658.49
Iteration:    900, Loss function: 5.255, Average Loss: 4.166, avg. samples / sec: 53783.88
Iteration:    900, Loss function: 5.979, Average Loss: 4.185, avg. samples / sec: 53778.30
Iteration:    900, Loss function: 4.041, Average Loss: 4.165, avg. samples / sec: 53766.56
Iteration:    900, Loss function: 4.970, Average Loss: 4.160, avg. samples / sec: 53925.95
Iteration:    900, Loss function: 4.813, Average Loss: 4.163, avg. samples / sec: 53706.26
Iteration:    900, Loss function: 3.462, Average Loss: 4.156, avg. samples / sec: 53719.16
Iteration:    900, Loss function: 5.009, Average Loss: 4.144, avg. samples / sec: 53725.75
Iteration:    900, Loss function: 4.957, Average Loss: 4.177, avg. samples / sec: 53944.30
Iteration:    900, Loss function: 4.628, Average Loss: 4.139, avg. samples / sec: 53710.68
Iteration:    900, Loss function: 3.653, Average Loss: 4.129, avg. samples / sec: 53680.87
Iteration:    900, Loss function: 4.119, Average Loss: 4.187, avg. samples / sec: 53531.05
Iteration:    900, Loss function: 5.716, Average Loss: 4.144, avg. samples / sec: 53852.63
Iteration:    900, Loss function: 5.212, Average Loss: 4.173, avg. samples / sec: 53609.20
Iteration:    900, Loss function: 4.122, Average Loss: 4.134, avg. samples / sec: 53710.91
Iteration:    900, Loss function: 5.643, Average Loss: 4.123, avg. samples / sec: 53310.00
Iteration:    900, Loss function: 6.044, Average Loss: 4.158, avg. samples / sec: 53684.62
Iteration:    900, Loss function: 4.845, Average Loss: 4.141, avg. samples / sec: 53687.42
Iteration:    900, Loss function: 3.340, Average Loss: 4.155, avg. samples / sec: 53589.75
Iteration:    900, Loss function: 5.672, Average Loss: 4.150, avg. samples / sec: 53739.19
Iteration:    900, Loss function: 5.194, Average Loss: 4.153, avg. samples / sec: 53713.32
Iteration:    900, Loss function: 4.841, Average Loss: 4.138, avg. samples / sec: 53696.99
Iteration:    900, Loss function: 6.787, Average Loss: 4.190, avg. samples / sec: 53755.16
Iteration:    900, Loss function: 4.809, Average Loss: 4.121, avg. samples / sec: 53733.87
Iteration:    900, Loss function: 5.331, Average Loss: 4.162, avg. samples / sec: 53679.81
:::MLL 1558640878.993 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558640878.994 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 6.131, Average Loss: 4.177, avg. samples / sec: 53529.72
Iteration:    920, Loss function: 4.576, Average Loss: 4.175, avg. samples / sec: 53932.01
Iteration:    920, Loss function: 5.936, Average Loss: 4.170, avg. samples / sec: 53561.64
Iteration:    920, Loss function: 6.058, Average Loss: 4.179, avg. samples / sec: 53625.31
Iteration:    920, Loss function: 5.030, Average Loss: 4.164, avg. samples / sec: 53480.10
Iteration:    920, Loss function: 4.599, Average Loss: 4.199, avg. samples / sec: 53407.72
Iteration:    920, Loss function: 4.886, Average Loss: 4.192, avg. samples / sec: 53553.16
Iteration:    920, Loss function: 5.333, Average Loss: 4.203, avg. samples / sec: 53396.69
Iteration:    920, Loss function: 5.238, Average Loss: 4.150, avg. samples / sec: 53428.19
Iteration:    920, Loss function: 6.166, Average Loss: 4.178, avg. samples / sec: 53359.92
Iteration:    920, Loss function: 5.333, Average Loss: 4.164, avg. samples / sec: 53456.69
Iteration:    920, Loss function: 6.408, Average Loss: 4.147, avg. samples / sec: 53612.89
Iteration:    920, Loss function: 4.574, Average Loss: 4.208, avg. samples / sec: 53596.64
Iteration:    920, Loss function: 4.073, Average Loss: 4.183, avg. samples / sec: 53314.01
Iteration:    920, Loss function: 4.615, Average Loss: 4.199, avg. samples / sec: 53316.90
Iteration:    920, Loss function: 5.167, Average Loss: 4.185, avg. samples / sec: 53236.50
Iteration:    920, Loss function: 5.175, Average Loss: 4.174, avg. samples / sec: 53209.56
Iteration:    920, Loss function: 5.003, Average Loss: 4.145, avg. samples / sec: 53457.24
Iteration:    920, Loss function: 6.282, Average Loss: 4.159, avg. samples / sec: 53386.40
Iteration:    920, Loss function: 5.165, Average Loss: 4.157, avg. samples / sec: 53409.06
Iteration:    920, Loss function: 6.130, Average Loss: 4.166, avg. samples / sec: 53395.34
Iteration:    920, Loss function: 4.074, Average Loss: 4.161, avg. samples / sec: 53141.02
Iteration:    920, Loss function: 4.327, Average Loss: 4.188, avg. samples / sec: 52981.96
Iteration:    920, Loss function: 4.641, Average Loss: 4.205, avg. samples / sec: 53048.97
Iteration:    920, Loss function: 5.201, Average Loss: 4.183, avg. samples / sec: 52957.07
Iteration:    920, Loss function: 4.138, Average Loss: 4.179, avg. samples / sec: 52924.97
Iteration:    920, Loss function: 5.186, Average Loss: 4.180, avg. samples / sec: 53039.74
Iteration:    920, Loss function: 5.187, Average Loss: 4.175, avg. samples / sec: 53036.39
Iteration:    920, Loss function: 4.953, Average Loss: 4.181, avg. samples / sec: 53063.31
Iteration:    920, Loss function: 4.233, Average Loss: 4.154, avg. samples / sec: 52799.44
Iteration:    940, Loss function: 4.551, Average Loss: 4.196, avg. samples / sec: 53394.39
Iteration:    940, Loss function: 6.100, Average Loss: 4.205, avg. samples / sec: 53977.93
Iteration:    940, Loss function: 6.038, Average Loss: 4.192, avg. samples / sec: 53315.35
Iteration:    940, Loss function: 4.417, Average Loss: 4.192, avg. samples / sec: 53551.20
Iteration:    940, Loss function: 5.249, Average Loss: 4.199, avg. samples / sec: 53325.13
Iteration:    940, Loss function: 4.619, Average Loss: 4.219, avg. samples / sec: 53514.11
Iteration:    940, Loss function: 4.625, Average Loss: 4.197, avg. samples / sec: 54033.32
Iteration:    940, Loss function: 5.243, Average Loss: 4.220, avg. samples / sec: 53922.58
Iteration:    940, Loss function: 5.938, Average Loss: 4.172, avg. samples / sec: 53516.73
Iteration:    940, Loss function: 3.922, Average Loss: 4.199, avg. samples / sec: 53915.69
Iteration:    940, Loss function: 3.942, Average Loss: 4.184, avg. samples / sec: 53428.70
Iteration:    940, Loss function: 4.707, Average Loss: 4.176, avg. samples / sec: 53765.70
Iteration:    940, Loss function: 4.143, Average Loss: 4.180, avg. samples / sec: 53446.92
Iteration:    940, Loss function: 4.233, Average Loss: 4.213, avg. samples / sec: 53308.91
Iteration:    940, Loss function: 4.644, Average Loss: 4.216, avg. samples / sec: 53414.83
Iteration:    940, Loss function: 4.528, Average Loss: 4.172, avg. samples / sec: 54118.66
Iteration:    940, Loss function: 5.203, Average Loss: 4.178, avg. samples / sec: 53542.03
Iteration:    940, Loss function: 6.272, Average Loss: 4.160, avg. samples / sec: 53469.22
Iteration:    940, Loss function: 4.868, Average Loss: 4.184, avg. samples / sec: 53553.97
Iteration:    940, Loss function: 3.546, Average Loss: 4.177, avg. samples / sec: 53542.27
Iteration:    940, Loss function: 6.667, Average Loss: 4.203, avg. samples / sec: 53353.31
Iteration:    940, Loss function: 4.828, Average Loss: 4.199, avg. samples / sec: 53879.87
Iteration:    940, Loss function: 5.146, Average Loss: 4.194, avg. samples / sec: 53884.19
Iteration:    940, Loss function: 5.989, Average Loss: 4.192, avg. samples / sec: 53410.29
Iteration:    940, Loss function: 4.499, Average Loss: 4.196, avg. samples / sec: 52987.77
Iteration:    940, Loss function: 5.949, Average Loss: 4.221, avg. samples / sec: 53217.02
Iteration:    940, Loss function: 4.397, Average Loss: 4.204, avg. samples / sec: 53390.61
Iteration:    940, Loss function: 4.873, Average Loss: 4.197, avg. samples / sec: 53879.93
Iteration:    940, Loss function: 6.169, Average Loss: 4.226, avg. samples / sec: 53268.51
Iteration:    940, Loss function: 4.894, Average Loss: 4.165, avg. samples / sec: 53249.39
Iteration:    960, Loss function: 7.032, Average Loss: 4.217, avg. samples / sec: 52849.93
Iteration:    960, Loss function: 3.872, Average Loss: 4.225, avg. samples / sec: 52869.20
Iteration:    960, Loss function: 5.394, Average Loss: 4.212, avg. samples / sec: 52928.09
Iteration:    960, Loss function: 5.117, Average Loss: 4.214, avg. samples / sec: 52941.87
Iteration:    960, Loss function: 5.834, Average Loss: 4.242, avg. samples / sec: 52931.91
Iteration:    960, Loss function: 4.727, Average Loss: 4.207, avg. samples / sec: 52976.96
Iteration:    960, Loss function: 4.301, Average Loss: 4.243, avg. samples / sec: 53246.37
Iteration:    960, Loss function: 4.516, Average Loss: 4.228, avg. samples / sec: 53109.30
Iteration:    960, Loss function: 4.820, Average Loss: 4.216, avg. samples / sec: 53155.84
Iteration:    960, Loss function: 5.526, Average Loss: 4.222, avg. samples / sec: 52927.71
Iteration:    960, Loss function: 5.504, Average Loss: 4.225, avg. samples / sec: 53149.20
Iteration:    960, Loss function: 5.490, Average Loss: 4.190, avg. samples / sec: 52892.14
Iteration:    960, Loss function: 4.818, Average Loss: 4.239, avg. samples / sec: 52880.01
Iteration:    960, Loss function: 5.359, Average Loss: 4.218, avg. samples / sec: 52870.79
Iteration:    960, Loss function: 4.674, Average Loss: 4.237, avg. samples / sec: 53135.93
Iteration:    960, Loss function: 6.112, Average Loss: 4.199, avg. samples / sec: 52962.94
Iteration:    960, Loss function: 5.266, Average Loss: 4.215, avg. samples / sec: 53119.37
Iteration:    960, Loss function: 4.787, Average Loss: 4.194, avg. samples / sec: 52881.40
Iteration:    960, Loss function: 6.147, Average Loss: 4.207, avg. samples / sec: 52997.62
Iteration:    960, Loss function: 4.394, Average Loss: 4.194, avg. samples / sec: 52939.80
Iteration:    960, Loss function: 5.833, Average Loss: 4.180, avg. samples / sec: 52920.28
Iteration:    960, Loss function: 5.026, Average Loss: 4.194, avg. samples / sec: 52916.80
Iteration:    960, Loss function: 4.312, Average Loss: 4.232, avg. samples / sec: 52901.63
Iteration:    960, Loss function: 5.568, Average Loss: 4.223, avg. samples / sec: 52921.47
Iteration:    960, Loss function: 7.079, Average Loss: 4.215, avg. samples / sec: 52942.35
Iteration:    960, Loss function: 5.185, Average Loss: 4.224, avg. samples / sec: 52907.67
Iteration:    960, Loss function: 5.726, Average Loss: 4.212, avg. samples / sec: 52651.16
Iteration:    960, Loss function: 5.717, Average Loss: 4.199, avg. samples / sec: 52866.86
Iteration:    960, Loss function: 4.999, Average Loss: 4.215, avg. samples / sec: 52905.86
Iteration:    960, Loss function: 5.319, Average Loss: 4.184, avg. samples / sec: 52924.18
:::MLL 1558640881.200 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558640881.201 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 5.083, Average Loss: 4.234, avg. samples / sec: 53401.31
Iteration:    980, Loss function: 5.478, Average Loss: 4.203, avg. samples / sec: 53547.24
Iteration:    980, Loss function: 6.837, Average Loss: 4.260, avg. samples / sec: 53440.17
Iteration:    980, Loss function: 4.232, Average Loss: 4.214, avg. samples / sec: 53560.91
Iteration:    980, Loss function: 5.478, Average Loss: 4.241, avg. samples / sec: 53370.65
Iteration:    980, Loss function: 4.797, Average Loss: 4.235, avg. samples / sec: 53409.30
Iteration:    980, Loss function: 4.603, Average Loss: 4.235, avg. samples / sec: 53455.00
Iteration:    980, Loss function: 4.628, Average Loss: 4.233, avg. samples / sec: 53469.71
Iteration:    980, Loss function: 6.397, Average Loss: 4.257, avg. samples / sec: 53459.32
Iteration:    980, Loss function: 3.659, Average Loss: 4.254, avg. samples / sec: 53414.46
Iteration:    980, Loss function: 4.985, Average Loss: 4.224, avg. samples / sec: 53403.03
Iteration:    980, Loss function: 5.955, Average Loss: 4.225, avg. samples / sec: 53313.23
Iteration:    980, Loss function: 3.654, Average Loss: 4.216, avg. samples / sec: 53603.45
Iteration:    980, Loss function: 5.585, Average Loss: 4.228, avg. samples / sec: 53274.69
Iteration:    980, Loss function: 4.793, Average Loss: 4.237, avg. samples / sec: 53341.01
Iteration:    980, Loss function: 5.153, Average Loss: 4.232, avg. samples / sec: 53334.92
Iteration:    980, Loss function: 4.795, Average Loss: 4.249, avg. samples / sec: 53259.57
Iteration:    980, Loss function: 4.406, Average Loss: 4.240, avg. samples / sec: 53521.67
Iteration:    980, Loss function: 4.769, Average Loss: 4.246, avg. samples / sec: 53479.69
Iteration:    980, Loss function: 4.301, Average Loss: 4.231, avg. samples / sec: 53536.01
Iteration:    980, Loss function: 4.704, Average Loss: 4.222, avg. samples / sec: 53372.87
Iteration:    980, Loss function: 4.704, Average Loss: 4.239, avg. samples / sec: 53462.33
Iteration:    980, Loss function: 5.526, Average Loss: 4.225, avg. samples / sec: 53468.31
Iteration:    980, Loss function: 4.721, Average Loss: 4.212, avg. samples / sec: 53403.70
Iteration:    980, Loss function: 6.098, Average Loss: 4.217, avg. samples / sec: 53417.56
Iteration:    980, Loss function: 5.274, Average Loss: 4.203, avg. samples / sec: 53504.30
Iteration:    980, Loss function: 5.284, Average Loss: 4.196, avg. samples / sec: 53323.76
Iteration:    980, Loss function: 5.817, Average Loss: 4.228, avg. samples / sec: 53284.99
Iteration:    980, Loss function: 5.647, Average Loss: 4.235, avg. samples / sec: 53038.05
Iteration:    980, Loss function: 5.798, Average Loss: 4.258, avg. samples / sec: 52996.24
Iteration:   1000, Loss function: 6.137, Average Loss: 4.213, avg. samples / sec: 53124.62
Iteration:   1000, Loss function: 5.005, Average Loss: 4.255, avg. samples / sec: 52738.96
Iteration:   1000, Loss function: 5.461, Average Loss: 4.261, avg. samples / sec: 52716.27
Iteration:   1000, Loss function: 5.286, Average Loss: 4.270, avg. samples / sec: 52709.90
Iteration:   1000, Loss function: 5.387, Average Loss: 4.244, avg. samples / sec: 52789.47
Iteration:   1000, Loss function: 5.266, Average Loss: 4.278, avg. samples / sec: 52633.01
Iteration:   1000, Loss function: 4.555, Average Loss: 4.255, avg. samples / sec: 52775.99
Iteration:   1000, Loss function: 5.431, Average Loss: 4.252, avg. samples / sec: 52623.91
Iteration:   1000, Loss function: 5.351, Average Loss: 4.255, avg. samples / sec: 52627.09
Iteration:   1000, Loss function: 5.614, Average Loss: 4.249, avg. samples / sec: 52739.17
Iteration:   1000, Loss function: 4.314, Average Loss: 4.222, avg. samples / sec: 52525.90
Iteration:   1000, Loss function: 3.888, Average Loss: 4.275, avg. samples / sec: 52643.84
Iteration:   1000, Loss function: 4.446, Average Loss: 4.243, avg. samples / sec: 52685.66
Iteration:   1000, Loss function: 5.892, Average Loss: 4.264, avg. samples / sec: 52738.24
Iteration:   1000, Loss function: 5.685, Average Loss: 4.232, avg. samples / sec: 52540.00
Iteration:   1000, Loss function: 5.303, Average Loss: 4.246, avg. samples / sec: 52935.53
Iteration:   1000, Loss function: 3.628, Average Loss: 4.229, avg. samples / sec: 52626.40
Iteration:   1000, Loss function: 5.888, Average Loss: 4.234, avg. samples / sec: 52696.93
Iteration:   1000, Loss function: 5.558, Average Loss: 4.263, avg. samples / sec: 52587.91
Iteration:   1000, Loss function: 4.603, Average Loss: 4.235, avg. samples / sec: 52630.41
Iteration:   1000, Loss function: 3.492, Average Loss: 4.236, avg. samples / sec: 52599.16
Iteration:   1000, Loss function: 5.113, Average Loss: 4.248, avg. samples / sec: 52767.94
Iteration:   1000, Loss function: 4.797, Average Loss: 4.248, avg. samples / sec: 52526.21
Iteration:   1000, Loss function: 5.611, Average Loss: 4.236, avg. samples / sec: 52436.15
Iteration:   1000, Loss function: 3.703, Average Loss: 4.247, avg. samples / sec: 52539.14
Iteration:   1000, Loss function: 4.568, Average Loss: 4.258, avg. samples / sec: 52553.28
Iteration:   1000, Loss function: 5.183, Average Loss: 4.276, avg. samples / sec: 52759.77
Iteration:   1000, Loss function: 5.992, Average Loss: 4.254, avg. samples / sec: 52251.15
Iteration:   1000, Loss function: 4.407, Average Loss: 4.219, avg. samples / sec: 52572.28
Iteration:   1000, Loss function: 4.042, Average Loss: 4.239, avg. samples / sec: 52543.43
Iteration:   1020, Loss function: 4.537, Average Loss: 4.271, avg. samples / sec: 53396.53
Iteration:   1020, Loss function: 5.418, Average Loss: 4.286, avg. samples / sec: 52996.88
Iteration:   1020, Loss function: 4.386, Average Loss: 4.263, avg. samples / sec: 53075.12
Iteration:   1020, Loss function: 5.654, Average Loss: 4.256, avg. samples / sec: 53048.17
Iteration:   1020, Loss function: 4.559, Average Loss: 4.266, avg. samples / sec: 52872.08
Iteration:   1020, Loss function: 4.354, Average Loss: 4.272, avg. samples / sec: 52959.40
Iteration:   1020, Loss function: 4.605, Average Loss: 4.257, avg. samples / sec: 52908.80
Iteration:   1020, Loss function: 3.757, Average Loss: 4.273, avg. samples / sec: 53002.62
Iteration:   1020, Loss function: 4.501, Average Loss: 4.290, avg. samples / sec: 52983.13
Iteration:   1020, Loss function: 4.393, Average Loss: 4.264, avg. samples / sec: 52950.19
Iteration:   1020, Loss function: 3.679, Average Loss: 4.241, avg. samples / sec: 53000.39
Iteration:   1020, Loss function: 5.493, Average Loss: 4.267, avg. samples / sec: 52941.31
Iteration:   1020, Loss function: 6.350, Average Loss: 4.293, avg. samples / sec: 52863.07
Iteration:   1020, Loss function: 5.519, Average Loss: 4.238, avg. samples / sec: 52892.02
Iteration:   1020, Loss function: 3.978, Average Loss: 4.246, avg. samples / sec: 52997.26
Iteration:   1020, Loss function: 5.442, Average Loss: 4.264, avg. samples / sec: 53037.89
Iteration:   1020, Loss function: 4.438, Average Loss: 4.254, avg. samples / sec: 52932.88
Iteration:   1020, Loss function: 5.377, Average Loss: 4.255, avg. samples / sec: 52994.97
Iteration:   1020, Loss function: 5.453, Average Loss: 4.244, avg. samples / sec: 52853.71
Iteration:   1020, Loss function: 5.252, Average Loss: 4.245, avg. samples / sec: 53002.62
Iteration:   1020, Loss function: 4.573, Average Loss: 4.277, avg. samples / sec: 52947.12
Iteration:   1020, Loss function: 4.638, Average Loss: 4.296, avg. samples / sec: 53009.18
Iteration:   1020, Loss function: 6.439, Average Loss: 4.265, avg. samples / sec: 52999.19
Iteration:   1020, Loss function: 4.751, Average Loss: 4.224, avg. samples / sec: 52554.38
Iteration:   1020, Loss function: 4.193, Average Loss: 4.259, avg. samples / sec: 52973.49
Iteration:   1020, Loss function: 5.981, Average Loss: 4.258, avg. samples / sec: 52788.62
Iteration:   1020, Loss function: 4.561, Average Loss: 4.233, avg. samples / sec: 53001.82
Iteration:   1020, Loss function: 4.540, Average Loss: 4.252, avg. samples / sec: 53000.65
Iteration:   1020, Loss function: 4.658, Average Loss: 4.278, avg. samples / sec: 52506.02
Iteration:   1020, Loss function: 4.637, Average Loss: 4.271, avg. samples / sec: 52866.78
Iteration:   1040, Loss function: 5.467, Average Loss: 4.279, avg. samples / sec: 53024.86
Iteration:   1040, Loss function: 5.512, Average Loss: 4.291, avg. samples / sec: 53507.29
Iteration:   1040, Loss function: 4.129, Average Loss: 4.271, avg. samples / sec: 53046.21
Iteration:   1040, Loss function: 5.031, Average Loss: 4.305, avg. samples / sec: 53089.54
Iteration:   1040, Loss function: 6.491, Average Loss: 4.284, avg. samples / sec: 53031.78
Iteration:   1040, Loss function: 5.656, Average Loss: 4.302, avg. samples / sec: 52966.13
Iteration:   1040, Loss function: 5.424, Average Loss: 4.289, avg. samples / sec: 53004.49
Iteration:   1040, Loss function: 4.943, Average Loss: 4.298, avg. samples / sec: 53090.74
Iteration:   1040, Loss function: 6.425, Average Loss: 4.287, avg. samples / sec: 53032.30
Iteration:   1040, Loss function: 5.109, Average Loss: 4.282, avg. samples / sec: 52905.70
Iteration:   1040, Loss function: 4.332, Average Loss: 4.284, avg. samples / sec: 52997.20
Iteration:   1040, Loss function: 6.243, Average Loss: 4.274, avg. samples / sec: 52978.35
Iteration:   1040, Loss function: 4.839, Average Loss: 4.251, avg. samples / sec: 53036.27
Iteration:   1040, Loss function: 5.337, Average Loss: 4.279, avg. samples / sec: 52950.07
Iteration:   1040, Loss function: 4.402, Average Loss: 4.286, avg. samples / sec: 53163.34
Iteration:   1040, Loss function: 5.378, Average Loss: 4.274, avg. samples / sec: 53122.82
Iteration:   1040, Loss function: 5.231, Average Loss: 4.239, avg. samples / sec: 53052.28
Iteration:   1040, Loss function: 6.551, Average Loss: 4.260, avg. samples / sec: 53002.26
Iteration:   1040, Loss function: 4.855, Average Loss: 4.270, avg. samples / sec: 53004.69
Iteration:   1040, Loss function: 5.042, Average Loss: 4.286, avg. samples / sec: 53166.81
Iteration:   1040, Loss function: 5.007, Average Loss: 4.256, avg. samples / sec: 52809.19
Iteration:   1040, Loss function: 3.709, Average Loss: 4.262, avg. samples / sec: 52985.32
Iteration:   1040, Loss function: 4.234, Average Loss: 4.253, avg. samples / sec: 53022.58
Iteration:   1040, Loss function: 6.069, Average Loss: 4.283, avg. samples / sec: 52939.09
Iteration:   1040, Loss function: 6.342, Average Loss: 4.280, avg. samples / sec: 52986.00
Iteration:   1040, Loss function: 4.380, Average Loss: 4.268, avg. samples / sec: 52999.55
Iteration:   1040, Loss function: 4.404, Average Loss: 4.258, avg. samples / sec: 52966.66
Iteration:   1040, Loss function: 5.401, Average Loss: 4.273, avg. samples / sec: 52980.60
Iteration:   1040, Loss function: 6.223, Average Loss: 4.271, avg. samples / sec: 52996.94
Iteration:   1040, Loss function: 5.270, Average Loss: 4.315, avg. samples / sec: 52958.70
:::MLL 1558640883.427 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558640883.428 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 4.841, Average Loss: 4.300, avg. samples / sec: 52686.98
Iteration:   1060, Loss function: 4.294, Average Loss: 4.323, avg. samples / sec: 52757.32
Iteration:   1060, Loss function: 4.775, Average Loss: 4.295, avg. samples / sec: 52637.02
Iteration:   1060, Loss function: 5.705, Average Loss: 4.288, avg. samples / sec: 52735.70
Iteration:   1060, Loss function: 5.327, Average Loss: 4.296, avg. samples / sec: 52676.39
Iteration:   1060, Loss function: 4.729, Average Loss: 4.307, avg. samples / sec: 52663.51
Iteration:   1060, Loss function: 6.163, Average Loss: 4.305, avg. samples / sec: 52615.46
Iteration:   1060, Loss function: 5.562, Average Loss: 4.270, avg. samples / sec: 52704.89
Iteration:   1060, Loss function: 4.673, Average Loss: 4.286, avg. samples / sec: 52550.28
Iteration:   1060, Loss function: 5.310, Average Loss: 4.293, avg. samples / sec: 52713.80
Iteration:   1060, Loss function: 4.873, Average Loss: 4.299, avg. samples / sec: 52584.15
Iteration:   1060, Loss function: 5.153, Average Loss: 4.298, avg. samples / sec: 52652.79
Iteration:   1060, Loss function: 4.687, Average Loss: 4.323, avg. samples / sec: 52562.57
Iteration:   1060, Loss function: 5.855, Average Loss: 4.317, avg. samples / sec: 52573.95
Iteration:   1060, Loss function: 5.575, Average Loss: 4.293, avg. samples / sec: 52697.23
Iteration:   1060, Loss function: 3.893, Average Loss: 4.269, avg. samples / sec: 52703.55
Iteration:   1060, Loss function: 4.285, Average Loss: 4.300, avg. samples / sec: 52559.69
Iteration:   1060, Loss function: 4.197, Average Loss: 4.252, avg. samples / sec: 52663.99
Iteration:   1060, Loss function: 4.724, Average Loss: 4.301, avg. samples / sec: 52714.71
Iteration:   1060, Loss function: 5.566, Average Loss: 4.273, avg. samples / sec: 52649.29
Iteration:   1060, Loss function: 5.567, Average Loss: 4.299, avg. samples / sec: 52659.38
Iteration:   1060, Loss function: 4.983, Average Loss: 4.298, avg. samples / sec: 52694.37
Iteration:   1060, Loss function: 5.955, Average Loss: 4.289, avg. samples / sec: 52700.18
Iteration:   1060, Loss function: 4.475, Average Loss: 4.281, avg. samples / sec: 52696.22
Iteration:   1060, Loss function: 5.033, Average Loss: 4.284, avg. samples / sec: 52503.45
Iteration:   1060, Loss function: 5.193, Average Loss: 4.286, avg. samples / sec: 52654.03
Iteration:   1060, Loss function: 5.141, Average Loss: 4.273, avg. samples / sec: 52648.23
Iteration:   1060, Loss function: 3.985, Average Loss: 4.332, avg. samples / sec: 52647.24
Iteration:   1060, Loss function: 5.250, Average Loss: 4.271, avg. samples / sec: 52492.21
Iteration:   1060, Loss function: 4.939, Average Loss: 4.272, avg. samples / sec: 52415.01
Iteration:   1080, Loss function: 5.456, Average Loss: 4.309, avg. samples / sec: 52925.71
Iteration:   1080, Loss function: 4.776, Average Loss: 4.315, avg. samples / sec: 53092.38
Iteration:   1080, Loss function: 5.281, Average Loss: 4.306, avg. samples / sec: 52925.41
Iteration:   1080, Loss function: 4.919, Average Loss: 4.299, avg. samples / sec: 52920.22
Iteration:   1080, Loss function: 5.118, Average Loss: 4.330, avg. samples / sec: 53005.51
Iteration:   1080, Loss function: 4.450, Average Loss: 4.300, avg. samples / sec: 52930.14
Iteration:   1080, Loss function: 5.582, Average Loss: 4.288, avg. samples / sec: 52929.15
Iteration:   1080, Loss function: 4.553, Average Loss: 4.308, avg. samples / sec: 52882.11
Iteration:   1080, Loss function: 4.776, Average Loss: 4.305, avg. samples / sec: 52881.20
Iteration:   1080, Loss function: 5.137, Average Loss: 4.331, avg. samples / sec: 52892.40
Iteration:   1080, Loss function: 5.246, Average Loss: 4.335, avg. samples / sec: 52649.84
Iteration:   1080, Loss function: 4.702, Average Loss: 4.316, avg. samples / sec: 52916.45
Iteration:   1080, Loss function: 4.356, Average Loss: 4.317, avg. samples / sec: 52712.72
Iteration:   1080, Loss function: 3.844, Average Loss: 4.314, avg. samples / sec: 52869.16
Iteration:   1080, Loss function: 5.082, Average Loss: 4.285, avg. samples / sec: 52850.15
Iteration:   1080, Loss function: 4.765, Average Loss: 4.316, avg. samples / sec: 52696.12
Iteration:   1080, Loss function: 5.473, Average Loss: 4.313, avg. samples / sec: 52889.52
Iteration:   1080, Loss function: 5.334, Average Loss: 4.265, avg. samples / sec: 52851.36
Iteration:   1080, Loss function: 4.585, Average Loss: 4.346, avg. samples / sec: 52949.65
Iteration:   1080, Loss function: 5.560, Average Loss: 4.285, avg. samples / sec: 52932.49
Iteration:   1080, Loss function: 5.223, Average Loss: 4.315, avg. samples / sec: 52652.81
Iteration:   1080, Loss function: 4.494, Average Loss: 4.289, avg. samples / sec: 53062.83
Iteration:   1080, Loss function: 5.234, Average Loss: 4.307, avg. samples / sec: 52813.45
Iteration:   1080, Loss function: 4.065, Average Loss: 4.288, avg. samples / sec: 53140.56
Iteration:   1080, Loss function: 4.461, Average Loss: 4.316, avg. samples / sec: 52848.88
Iteration:   1080, Loss function: 4.668, Average Loss: 4.296, avg. samples / sec: 52869.10
Iteration:   1080, Loss function: 4.362, Average Loss: 4.301, avg. samples / sec: 52854.53
Iteration:   1080, Loss function: 4.768, Average Loss: 4.300, avg. samples / sec: 52882.67
Iteration:   1080, Loss function: 4.323, Average Loss: 4.297, avg. samples / sec: 52850.07
Iteration:   1080, Loss function: 4.006, Average Loss: 4.286, avg. samples / sec: 52771.13
Iteration:   1100, Loss function: 6.302, Average Loss: 4.320, avg. samples / sec: 52993.49
Iteration:   1100, Loss function: 4.634, Average Loss: 4.342, avg. samples / sec: 53204.02
Iteration:   1100, Loss function: 5.776, Average Loss: 4.342, avg. samples / sec: 52990.05
Iteration:   1100, Loss function: 5.161, Average Loss: 4.320, avg. samples / sec: 52997.88
Iteration:   1100, Loss function: 4.389, Average Loss: 4.309, avg. samples / sec: 52964.99
Iteration:   1100, Loss function: 5.410, Average Loss: 4.305, avg. samples / sec: 52954.66
Iteration:   1100, Loss function: 5.394, Average Loss: 4.330, avg. samples / sec: 53176.96
Iteration:   1100, Loss function: 5.103, Average Loss: 4.313, avg. samples / sec: 52883.23
Iteration:   1100, Loss function: 5.157, Average Loss: 4.324, avg. samples / sec: 53199.40
Iteration:   1100, Loss function: 5.746, Average Loss: 4.321, avg. samples / sec: 52971.34
Iteration:   1100, Loss function: 5.054, Average Loss: 4.327, avg. samples / sec: 52756.55
Iteration:   1100, Loss function: 6.489, Average Loss: 4.347, avg. samples / sec: 52964.31
Iteration:   1100, Loss function: 5.953, Average Loss: 4.336, avg. samples / sec: 53156.72
Iteration:   1100, Loss function: 3.854, Average Loss: 4.314, avg. samples / sec: 53047.39
Iteration:   1100, Loss function: 4.695, Average Loss: 4.275, avg. samples / sec: 53013.45
Iteration:   1100, Loss function: 4.433, Average Loss: 4.323, avg. samples / sec: 52988.21
Iteration:   1100, Loss function: 4.813, Average Loss: 4.294, avg. samples / sec: 53093.86
Iteration:   1100, Loss function: 4.421, Average Loss: 4.311, avg. samples / sec: 53035.67
Iteration:   1100, Loss function: 5.498, Average Loss: 4.301, avg. samples / sec: 52994.17
Iteration:   1100, Loss function: 4.565, Average Loss: 4.311, avg. samples / sec: 53025.79
Iteration:   1100, Loss function: 5.162, Average Loss: 4.298, avg. samples / sec: 52958.46
Iteration:   1100, Loss function: 4.790, Average Loss: 4.331, avg. samples / sec: 53001.84
Iteration:   1100, Loss function: 5.785, Average Loss: 4.329, avg. samples / sec: 52938.65
Iteration:   1100, Loss function: 3.949, Average Loss: 4.313, avg. samples / sec: 52993.17
Iteration:   1100, Loss function: 4.931, Average Loss: 4.294, avg. samples / sec: 52940.58
Iteration:   1100, Loss function: 5.167, Average Loss: 4.298, avg. samples / sec: 52944.32
Iteration:   1100, Loss function: 5.289, Average Loss: 4.303, avg. samples / sec: 52976.70
Iteration:   1100, Loss function: 3.944, Average Loss: 4.321, avg. samples / sec: 52467.06
Iteration:   1100, Loss function: 4.072, Average Loss: 4.354, avg. samples / sec: 52895.91
Iteration:   1100, Loss function: 4.654, Average Loss: 4.329, avg. samples / sec: 52819.74
:::MLL 1558640885.653 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558640885.654 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 4.848, Average Loss: 4.331, avg. samples / sec: 52577.10
Iteration:   1120, Loss function: 5.699, Average Loss: 4.342, avg. samples / sec: 52782.39
Iteration:   1120, Loss function: 4.733, Average Loss: 4.321, avg. samples / sec: 52696.22
Iteration:   1120, Loss function: 4.973, Average Loss: 4.361, avg. samples / sec: 52737.97
Iteration:   1120, Loss function: 4.274, Average Loss: 4.309, avg. samples / sec: 52860.87
Iteration:   1120, Loss function: 5.040, Average Loss: 4.350, avg. samples / sec: 52503.55
Iteration:   1120, Loss function: 4.461, Average Loss: 4.360, avg. samples / sec: 52572.59
Iteration:   1120, Loss function: 3.880, Average Loss: 4.320, avg. samples / sec: 52628.92
Iteration:   1120, Loss function: 7.170, Average Loss: 4.336, avg. samples / sec: 52630.49
Iteration:   1120, Loss function: 4.749, Average Loss: 4.322, avg. samples / sec: 52603.70
Iteration:   1120, Loss function: 4.621, Average Loss: 4.334, avg. samples / sec: 52546.52
Iteration:   1120, Loss function: 5.118, Average Loss: 4.335, avg. samples / sec: 52581.36
Iteration:   1120, Loss function: 3.811, Average Loss: 4.332, avg. samples / sec: 52861.90
Iteration:   1120, Loss function: 6.208, Average Loss: 4.318, avg. samples / sec: 52835.01
Iteration:   1120, Loss function: 4.163, Average Loss: 4.348, avg. samples / sec: 52561.61
Iteration:   1120, Loss function: 4.666, Average Loss: 4.341, avg. samples / sec: 52499.05
Iteration:   1120, Loss function: 5.411, Average Loss: 4.347, avg. samples / sec: 52717.45
Iteration:   1120, Loss function: 5.089, Average Loss: 4.318, avg. samples / sec: 52685.94
Iteration:   1120, Loss function: 4.862, Average Loss: 4.313, avg. samples / sec: 52718.79
Iteration:   1120, Loss function: 6.329, Average Loss: 4.343, avg. samples / sec: 52688.38
Iteration:   1120, Loss function: 4.098, Average Loss: 4.304, avg. samples / sec: 52707.83
Iteration:   1120, Loss function: 4.494, Average Loss: 4.323, avg. samples / sec: 52620.80
Iteration:   1120, Loss function: 4.113, Average Loss: 4.344, avg. samples / sec: 52691.28
Iteration:   1120, Loss function: 4.805, Average Loss: 4.286, avg. samples / sec: 52548.58
Iteration:   1120, Loss function: 6.243, Average Loss: 4.323, avg. samples / sec: 52559.36
Iteration:   1120, Loss function: 3.564, Average Loss: 4.321, avg. samples / sec: 52581.26
Iteration:   1120, Loss function: 5.102, Average Loss: 4.338, avg. samples / sec: 52526.00
Iteration:   1120, Loss function: 5.874, Average Loss: 4.328, avg. samples / sec: 52480.68
Iteration:   1120, Loss function: 6.261, Average Loss: 4.310, avg. samples / sec: 52539.80
Iteration:   1120, Loss function: 4.435, Average Loss: 4.369, avg. samples / sec: 52607.52
Iteration:   1140, Loss function: 5.995, Average Loss: 4.366, avg. samples / sec: 53260.70
Iteration:   1140, Loss function: 4.275, Average Loss: 4.332, avg. samples / sec: 53430.34
Iteration:   1140, Loss function: 5.079, Average Loss: 4.348, avg. samples / sec: 53250.86
Iteration:   1140, Loss function: 5.301, Average Loss: 4.338, avg. samples / sec: 52997.50
Iteration:   1140, Loss function: 4.018, Average Loss: 4.370, avg. samples / sec: 53067.29
Iteration:   1140, Loss function: 4.932, Average Loss: 4.356, avg. samples / sec: 52909.41
Iteration:   1140, Loss function: 6.123, Average Loss: 4.356, avg. samples / sec: 53130.73
Iteration:   1140, Loss function: 5.175, Average Loss: 4.333, avg. samples / sec: 52995.62
Iteration:   1140, Loss function: 4.470, Average Loss: 4.345, avg. samples / sec: 53068.16
Iteration:   1140, Loss function: 5.339, Average Loss: 4.374, avg. samples / sec: 52932.05
Iteration:   1140, Loss function: 6.058, Average Loss: 4.337, avg. samples / sec: 53033.88
Iteration:   1140, Loss function: 5.427, Average Loss: 4.335, avg. samples / sec: 52902.76
Iteration:   1140, Loss function: 5.498, Average Loss: 4.347, avg. samples / sec: 53036.85
Iteration:   1140, Loss function: 4.546, Average Loss: 4.350, avg. samples / sec: 52946.63
Iteration:   1140, Loss function: 5.531, Average Loss: 4.323, avg. samples / sec: 52954.92
Iteration:   1140, Loss function: 5.323, Average Loss: 4.323, avg. samples / sec: 52813.23
Iteration:   1140, Loss function: 4.498, Average Loss: 4.352, avg. samples / sec: 53144.51
Iteration:   1140, Loss function: 4.700, Average Loss: 4.341, avg. samples / sec: 53155.62
Iteration:   1140, Loss function: 4.808, Average Loss: 4.323, avg. samples / sec: 53138.28
Iteration:   1140, Loss function: 4.500, Average Loss: 4.361, avg. samples / sec: 53083.18
Iteration:   1140, Loss function: 5.977, Average Loss: 4.335, avg. samples / sec: 53012.05
Iteration:   1140, Loss function: 5.072, Average Loss: 4.360, avg. samples / sec: 52941.79
Iteration:   1140, Loss function: 4.364, Average Loss: 4.351, avg. samples / sec: 52972.94
Iteration:   1140, Loss function: 4.316, Average Loss: 4.330, avg. samples / sec: 53093.90
Iteration:   1140, Loss function: 4.500, Average Loss: 4.326, avg. samples / sec: 52956.93
Iteration:   1140, Loss function: 5.292, Average Loss: 4.382, avg. samples / sec: 53109.40
Iteration:   1140, Loss function: 4.415, Average Loss: 4.313, avg. samples / sec: 52955.44
Iteration:   1140, Loss function: 6.140, Average Loss: 4.297, avg. samples / sec: 53041.26
Iteration:   1140, Loss function: 4.763, Average Loss: 4.335, avg. samples / sec: 53047.07
Iteration:   1140, Loss function: 4.549, Average Loss: 4.359, avg. samples / sec: 52822.00
Iteration:   1160, Loss function: 5.108, Average Loss: 4.345, avg. samples / sec: 53195.26
Iteration:   1160, Loss function: 4.365, Average Loss: 4.363, avg. samples / sec: 53291.58
Iteration:   1160, Loss function: 5.239, Average Loss: 4.345, avg. samples / sec: 53236.22
Iteration:   1160, Loss function: 3.828, Average Loss: 4.357, avg. samples / sec: 53012.37
Iteration:   1160, Loss function: 4.985, Average Loss: 4.384, avg. samples / sec: 53150.32
Iteration:   1160, Loss function: 5.634, Average Loss: 4.363, avg. samples / sec: 53096.52
Iteration:   1160, Loss function: 4.207, Average Loss: 4.343, avg. samples / sec: 53117.67
Iteration:   1160, Loss function: 5.018, Average Loss: 4.350, avg. samples / sec: 53119.45
Iteration:   1160, Loss function: 4.952, Average Loss: 4.357, avg. samples / sec: 53139.88
Iteration:   1160, Loss function: 5.227, Average Loss: 4.359, avg. samples / sec: 53190.30
Iteration:   1160, Loss function: 5.306, Average Loss: 4.364, avg. samples / sec: 53284.38
Iteration:   1160, Loss function: 4.197, Average Loss: 4.373, avg. samples / sec: 52836.83
Iteration:   1160, Loss function: 4.216, Average Loss: 4.343, avg. samples / sec: 53114.73
Iteration:   1160, Loss function: 5.704, Average Loss: 4.379, avg. samples / sec: 53010.08
Iteration:   1160, Loss function: 4.544, Average Loss: 4.365, avg. samples / sec: 53373.01
Iteration:   1160, Loss function: 5.027, Average Loss: 4.342, avg. samples / sec: 52790.04
Iteration:   1160, Loss function: 4.792, Average Loss: 4.353, avg. samples / sec: 53147.04
Iteration:   1160, Loss function: 4.546, Average Loss: 4.329, avg. samples / sec: 53142.13
Iteration:   1160, Loss function: 4.121, Average Loss: 4.308, avg. samples / sec: 53216.19
Iteration:   1160, Loss function: 4.218, Average Loss: 4.338, avg. samples / sec: 53236.34
Iteration:   1160, Loss function: 6.044, Average Loss: 4.363, avg. samples / sec: 53176.58
Iteration:   1160, Loss function: 5.061, Average Loss: 4.368, avg. samples / sec: 53116.83
Iteration:   1160, Loss function: 4.378, Average Loss: 4.333, avg. samples / sec: 53094.78
Iteration:   1160, Loss function: 4.608, Average Loss: 4.341, avg. samples / sec: 53121.53
Iteration:   1160, Loss function: 5.833, Average Loss: 4.344, avg. samples / sec: 53108.82
Iteration:   1160, Loss function: 4.544, Average Loss: 4.324, avg. samples / sec: 53116.05
Iteration:   1160, Loss function: 5.210, Average Loss: 4.335, avg. samples / sec: 53095.90
Iteration:   1160, Loss function: 4.742, Average Loss: 4.370, avg. samples / sec: 53081.88
Iteration:   1160, Loss function: 4.977, Average Loss: 4.390, avg. samples / sec: 53098.38
Iteration:   1160, Loss function: 4.380, Average Loss: 4.333, avg. samples / sec: 52979.57
Iteration:   1180, Loss function: 5.048, Average Loss: 4.369, avg. samples / sec: 53163.44
Iteration:   1180, Loss function: 4.525, Average Loss: 4.358, avg. samples / sec: 52935.67
Iteration:   1180, Loss function: 5.407, Average Loss: 4.375, avg. samples / sec: 52932.37
Iteration:   1180, Loss function: 5.084, Average Loss: 4.390, avg. samples / sec: 53109.48
Iteration:   1180, Loss function: 5.080, Average Loss: 4.372, avg. samples / sec: 53059.31
Iteration:   1180, Loss function: 5.405, Average Loss: 4.371, avg. samples / sec: 53072.66
Iteration:   1180, Loss function: 3.849, Average Loss: 4.360, avg. samples / sec: 53055.86
Iteration:   1180, Loss function: 4.743, Average Loss: 4.379, avg. samples / sec: 53068.82
Iteration:   1180, Loss function: 3.672, Average Loss: 4.356, avg. samples / sec: 52930.36
Iteration:   1180, Loss function: 5.775, Average Loss: 4.360, avg. samples / sec: 53037.01
Iteration:   1180, Loss function: 6.797, Average Loss: 4.352, avg. samples / sec: 53253.19
Iteration:   1180, Loss function: 4.520, Average Loss: 4.367, avg. samples / sec: 53014.20
Iteration:   1180, Loss function: 3.970, Average Loss: 4.349, avg. samples / sec: 53009.80
Iteration:   1180, Loss function: 5.062, Average Loss: 4.362, avg. samples / sec: 53038.01
Iteration:   1180, Loss function: 5.255, Average Loss: 4.394, avg. samples / sec: 52849.61
Iteration:   1180, Loss function: 4.999, Average Loss: 4.378, avg. samples / sec: 52905.04
Iteration:   1180, Loss function: 4.456, Average Loss: 4.341, avg. samples / sec: 52983.53
Iteration:   1180, Loss function: 6.540, Average Loss: 4.380, avg. samples / sec: 53029.27
Iteration:   1180, Loss function: 4.726, Average Loss: 4.346, avg. samples / sec: 53044.63
Iteration:   1180, Loss function: 4.054, Average Loss: 4.370, avg. samples / sec: 52991.66
Iteration:   1180, Loss function: 4.346, Average Loss: 4.379, avg. samples / sec: 53066.69
Iteration:   1180, Loss function: 6.116, Average Loss: 4.343, avg. samples / sec: 53056.20
Iteration:   1180, Loss function: 3.629, Average Loss: 4.362, avg. samples / sec: 53027.95
Iteration:   1180, Loss function: 4.539, Average Loss: 4.334, avg. samples / sec: 53035.51
Iteration:   1180, Loss function: 4.518, Average Loss: 4.350, avg. samples / sec: 52855.99
Iteration:   1180, Loss function: 5.794, Average Loss: 4.377, avg. samples / sec: 52795.26
Iteration:   1180, Loss function: 5.208, Average Loss: 4.342, avg. samples / sec: 53050.92
Iteration:   1180, Loss function: 5.065, Average Loss: 4.323, avg. samples / sec: 52929.60
Iteration:   1180, Loss function: 5.293, Average Loss: 4.402, avg. samples / sec: 53002.12
Iteration:   1180, Loss function: 4.575, Average Loss: 4.345, avg. samples / sec: 52880.73
:::MLL 1558640887.873 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558640887.873 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 5.101, Average Loss: 4.386, avg. samples / sec: 52816.18
Iteration:   1200, Loss function: 4.737, Average Loss: 4.392, avg. samples / sec: 52840.50
Iteration:   1200, Loss function: 4.681, Average Loss: 4.369, avg. samples / sec: 52667.71
Iteration:   1200, Loss function: 4.694, Average Loss: 4.405, avg. samples / sec: 52713.98
Iteration:   1200, Loss function: 5.015, Average Loss: 4.375, avg. samples / sec: 52722.76
Iteration:   1200, Loss function: 4.860, Average Loss: 4.370, avg. samples / sec: 52727.93
Iteration:   1200, Loss function: 5.628, Average Loss: 4.408, avg. samples / sec: 52790.95
Iteration:   1200, Loss function: 5.140, Average Loss: 4.375, avg. samples / sec: 52594.74
Iteration:   1200, Loss function: 5.316, Average Loss: 4.356, avg. samples / sec: 52808.58
Iteration:   1200, Loss function: 5.796, Average Loss: 4.371, avg. samples / sec: 52542.39
Iteration:   1200, Loss function: 4.603, Average Loss: 4.393, avg. samples / sec: 52694.61
Iteration:   1200, Loss function: 4.371, Average Loss: 4.388, avg. samples / sec: 52732.03
Iteration:   1200, Loss function: 4.878, Average Loss: 4.337, avg. samples / sec: 52766.30
Iteration:   1200, Loss function: 4.837, Average Loss: 4.393, avg. samples / sec: 52755.44
Iteration:   1200, Loss function: 5.312, Average Loss: 4.386, avg. samples / sec: 52297.96
Iteration:   1200, Loss function: 4.920, Average Loss: 4.383, avg. samples / sec: 52445.27
Iteration:   1200, Loss function: 3.852, Average Loss: 4.359, avg. samples / sec: 52515.49
Iteration:   1200, Loss function: 4.333, Average Loss: 4.375, avg. samples / sec: 52661.92
Iteration:   1200, Loss function: 4.608, Average Loss: 4.346, avg. samples / sec: 52667.35
Iteration:   1200, Loss function: 3.993, Average Loss: 4.357, avg. samples / sec: 52695.32
Iteration:   1200, Loss function: 3.540, Average Loss: 4.390, avg. samples / sec: 52594.57
Iteration:   1200, Loss function: 4.709, Average Loss: 4.414, avg. samples / sec: 52601.63
Iteration:   1200, Loss function: 5.087, Average Loss: 4.365, avg. samples / sec: 52542.04
Iteration:   1200, Loss function: 4.515, Average Loss: 4.379, avg. samples / sec: 52241.48
Iteration:   1200, Loss function: 6.027, Average Loss: 4.364, avg. samples / sec: 52448.12
Iteration:   1200, Loss function: 5.705, Average Loss: 4.378, avg. samples / sec: 52190.85
Iteration:   1200, Loss function: 5.155, Average Loss: 4.376, avg. samples / sec: 52289.23
Iteration:   1200, Loss function: 5.412, Average Loss: 4.358, avg. samples / sec: 52319.76
Iteration:   1200, Loss function: 4.536, Average Loss: 4.383, avg. samples / sec: 52287.11
Iteration:   1200, Loss function: 4.332, Average Loss: 4.353, avg. samples / sec: 52262.29
Iteration:   1220, Loss function: 5.659, Average Loss: 4.396, avg. samples / sec: 53196.31
Iteration:   1220, Loss function: 5.429, Average Loss: 4.377, avg. samples / sec: 52909.93
Iteration:   1220, Loss function: 5.299, Average Loss: 4.387, avg. samples / sec: 53357.80
Iteration:   1220, Loss function: 5.295, Average Loss: 4.381, avg. samples / sec: 52976.00
Iteration:   1220, Loss function: 5.259, Average Loss: 4.400, avg. samples / sec: 52621.02
Iteration:   1220, Loss function: 4.048, Average Loss: 4.381, avg. samples / sec: 53360.06
Iteration:   1220, Loss function: 4.952, Average Loss: 4.387, avg. samples / sec: 53023.94
Iteration:   1220, Loss function: 3.973, Average Loss: 4.406, avg. samples / sec: 52734.00
Iteration:   1220, Loss function: 4.658, Average Loss: 4.368, avg. samples / sec: 53027.57
Iteration:   1220, Loss function: 4.029, Average Loss: 4.375, avg. samples / sec: 52735.15
Iteration:   1220, Loss function: 4.326, Average Loss: 4.386, avg. samples / sec: 52869.06
Iteration:   1220, Loss function: 5.551, Average Loss: 4.417, avg. samples / sec: 52815.80
Iteration:   1220, Loss function: 5.298, Average Loss: 4.369, avg. samples / sec: 53247.58
Iteration:   1220, Loss function: 3.988, Average Loss: 4.400, avg. samples / sec: 52954.74
Iteration:   1220, Loss function: 5.058, Average Loss: 4.387, avg. samples / sec: 53192.11
Iteration:   1220, Loss function: 4.073, Average Loss: 4.366, avg. samples / sec: 53188.64
Iteration:   1220, Loss function: 5.260, Average Loss: 4.399, avg. samples / sec: 52430.26
Iteration:   1220, Loss function: 4.897, Average Loss: 4.367, avg. samples / sec: 53232.74
Iteration:   1220, Loss function: 4.052, Average Loss: 4.397, avg. samples / sec: 52764.27
Iteration:   1220, Loss function: 5.749, Average Loss: 4.401, avg. samples / sec: 53217.70
Iteration:   1220, Loss function: 6.222, Average Loss: 4.366, avg. samples / sec: 52723.70
Iteration:   1220, Loss function: 4.274, Average Loss: 4.381, avg. samples / sec: 52530.11
Iteration:   1220, Loss function: 4.900, Average Loss: 4.382, avg. samples / sec: 52844.46
Iteration:   1220, Loss function: 3.359, Average Loss: 4.401, avg. samples / sec: 52728.62
Iteration:   1220, Loss function: 5.229, Average Loss: 4.403, avg. samples / sec: 52748.11
Iteration:   1220, Loss function: 5.675, Average Loss: 4.351, avg. samples / sec: 52830.61
Iteration:   1220, Loss function: 4.568, Average Loss: 4.366, avg. samples / sec: 52859.70
Iteration:   1220, Loss function: 3.334, Average Loss: 4.347, avg. samples / sec: 52737.40
Iteration:   1220, Loss function: 5.509, Average Loss: 4.379, avg. samples / sec: 52937.58
Iteration:   1220, Loss function: 4.187, Average Loss: 4.424, avg. samples / sec: 52929.54
Iteration:   1240, Loss function: 5.769, Average Loss: 4.405, avg. samples / sec: 53524.84
Iteration:   1240, Loss function: 4.838, Average Loss: 4.374, avg. samples / sec: 53080.66
Iteration:   1240, Loss function: 4.117, Average Loss: 4.400, avg. samples / sec: 53033.02
Iteration:   1240, Loss function: 3.851, Average Loss: 4.386, avg. samples / sec: 53149.36
Iteration:   1240, Loss function: 5.543, Average Loss: 4.407, avg. samples / sec: 53054.86
Iteration:   1240, Loss function: 5.176, Average Loss: 4.391, avg. samples / sec: 52933.86
Iteration:   1240, Loss function: 5.352, Average Loss: 4.379, avg. samples / sec: 53071.54
Iteration:   1240, Loss function: 4.280, Average Loss: 4.393, avg. samples / sec: 53071.96
Iteration:   1240, Loss function: 4.006, Average Loss: 4.421, avg. samples / sec: 53082.40
Iteration:   1240, Loss function: 5.108, Average Loss: 4.393, avg. samples / sec: 53270.43
Iteration:   1240, Loss function: 4.751, Average Loss: 4.404, avg. samples / sec: 53281.40
Iteration:   1240, Loss function: 4.418, Average Loss: 4.410, avg. samples / sec: 53262.15
Iteration:   1240, Loss function: 3.424, Average Loss: 4.387, avg. samples / sec: 52986.82
Iteration:   1240, Loss function: 3.466, Average Loss: 4.375, avg. samples / sec: 53243.36
Iteration:   1240, Loss function: 5.412, Average Loss: 4.376, avg. samples / sec: 52985.76
Iteration:   1240, Loss function: 4.726, Average Loss: 4.389, avg. samples / sec: 52968.83
Iteration:   1240, Loss function: 4.595, Average Loss: 4.376, avg. samples / sec: 53095.96
Iteration:   1240, Loss function: 5.446, Average Loss: 4.395, avg. samples / sec: 53033.84
Iteration:   1240, Loss function: 5.316, Average Loss: 4.347, avg. samples / sec: 53086.38
Iteration:   1240, Loss function: 4.930, Average Loss: 4.403, avg. samples / sec: 53051.48
Iteration:   1240, Loss function: 3.761, Average Loss: 4.387, avg. samples / sec: 53056.82
Iteration:   1240, Loss function: 4.849, Average Loss: 4.407, avg. samples / sec: 53025.37
Iteration:   1240, Loss function: 5.549, Average Loss: 4.411, avg. samples / sec: 52988.09
Iteration:   1240, Loss function: 4.971, Average Loss: 4.376, avg. samples / sec: 52855.64
Iteration:   1240, Loss function: 3.738, Average Loss: 4.375, avg. samples / sec: 53020.65
Iteration:   1240, Loss function: 4.662, Average Loss: 4.360, avg. samples / sec: 53033.06
Iteration:   1240, Loss function: 4.756, Average Loss: 4.390, avg. samples / sec: 53028.63
Iteration:   1240, Loss function: 4.292, Average Loss: 4.433, avg. samples / sec: 52974.67
Iteration:   1240, Loss function: 4.909, Average Loss: 4.372, avg. samples / sec: 52851.04
Iteration:   1240, Loss function: 5.780, Average Loss: 4.416, avg. samples / sec: 52590.07
:::MLL 1558640890.096 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558640890.096 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 5.514, Average Loss: 4.404, avg. samples / sec: 52887.53
Iteration:   1260, Loss function: 4.595, Average Loss: 4.383, avg. samples / sec: 52826.41
Iteration:   1260, Loss function: 4.259, Average Loss: 4.416, avg. samples / sec: 53506.94
Iteration:   1260, Loss function: 5.033, Average Loss: 4.394, avg. samples / sec: 53032.34
Iteration:   1260, Loss function: 6.668, Average Loss: 4.432, avg. samples / sec: 53026.93
Iteration:   1260, Loss function: 4.995, Average Loss: 4.414, avg. samples / sec: 52735.03
Iteration:   1260, Loss function: 5.261, Average Loss: 4.398, avg. samples / sec: 52990.03
Iteration:   1260, Loss function: 4.026, Average Loss: 4.399, avg. samples / sec: 52960.59
Iteration:   1260, Loss function: 4.244, Average Loss: 4.407, avg. samples / sec: 52984.96
Iteration:   1260, Loss function: 3.432, Average Loss: 4.393, avg. samples / sec: 53010.87
Iteration:   1260, Loss function: 3.395, Average Loss: 4.379, avg. samples / sec: 52993.71
Iteration:   1260, Loss function: 6.786, Average Loss: 4.394, avg. samples / sec: 52945.55
Iteration:   1260, Loss function: 5.194, Average Loss: 4.384, avg. samples / sec: 52817.82
Iteration:   1260, Loss function: 4.828, Average Loss: 4.403, avg. samples / sec: 53092.90
Iteration:   1260, Loss function: 3.708, Average Loss: 4.391, avg. samples / sec: 52957.13
Iteration:   1260, Loss function: 4.107, Average Loss: 4.413, avg. samples / sec: 52857.34
Iteration:   1260, Loss function: 4.999, Average Loss: 4.381, avg. samples / sec: 52940.16
Iteration:   1260, Loss function: 4.819, Average Loss: 4.384, avg. samples / sec: 53078.44
Iteration:   1260, Loss function: 3.480, Average Loss: 4.405, avg. samples / sec: 53015.90
Iteration:   1260, Loss function: 4.637, Average Loss: 4.415, avg. samples / sec: 53019.07
Iteration:   1260, Loss function: 4.437, Average Loss: 4.367, avg. samples / sec: 53024.30
Iteration:   1260, Loss function: 3.396, Average Loss: 4.410, avg. samples / sec: 52978.99
Iteration:   1260, Loss function: 4.662, Average Loss: 4.383, avg. samples / sec: 52991.46
Iteration:   1260, Loss function: 5.419, Average Loss: 4.383, avg. samples / sec: 52898.83
Iteration:   1260, Loss function: 3.967, Average Loss: 4.380, avg. samples / sec: 53089.88
Iteration:   1260, Loss function: 4.108, Average Loss: 4.400, avg. samples / sec: 52952.59
Iteration:   1260, Loss function: 5.383, Average Loss: 4.348, avg. samples / sec: 52873.72
Iteration:   1260, Loss function: 4.716, Average Loss: 4.400, avg. samples / sec: 52879.42
Iteration:   1260, Loss function: 4.390, Average Loss: 4.421, avg. samples / sec: 52666.96
Iteration:   1260, Loss function: 4.123, Average Loss: 4.436, avg. samples / sec: 52941.31
Iteration:   1280, Loss function: 3.562, Average Loss: 4.407, avg. samples / sec: 52972.40
Iteration:   1280, Loss function: 5.141, Average Loss: 4.392, avg. samples / sec: 52958.54
Iteration:   1280, Loss function: 4.923, Average Loss: 4.427, avg. samples / sec: 52988.67
Iteration:   1280, Loss function: 4.536, Average Loss: 4.401, avg. samples / sec: 52953.45
Iteration:   1280, Loss function: 4.883, Average Loss: 4.418, avg. samples / sec: 53021.46
Iteration:   1280, Loss function: 6.147, Average Loss: 4.397, avg. samples / sec: 52954.78
Iteration:   1280, Loss function: 6.102, Average Loss: 4.398, avg. samples / sec: 52978.87
Iteration:   1280, Loss function: 5.034, Average Loss: 4.410, avg. samples / sec: 52885.31
Iteration:   1280, Loss function: 4.700, Average Loss: 4.410, avg. samples / sec: 53064.81
Iteration:   1280, Loss function: 5.178, Average Loss: 4.402, avg. samples / sec: 52903.45
Iteration:   1280, Loss function: 6.029, Average Loss: 4.429, avg. samples / sec: 52817.66
Iteration:   1280, Loss function: 4.668, Average Loss: 4.407, avg. samples / sec: 52863.94
Iteration:   1280, Loss function: 4.928, Average Loss: 4.440, avg. samples / sec: 52829.28
Iteration:   1280, Loss function: 5.623, Average Loss: 4.395, avg. samples / sec: 52905.24
Iteration:   1280, Loss function: 4.285, Average Loss: 4.409, avg. samples / sec: 52818.00
Iteration:   1280, Loss function: 6.373, Average Loss: 4.393, avg. samples / sec: 52953.19
Iteration:   1280, Loss function: 5.211, Average Loss: 4.417, avg. samples / sec: 52788.62
Iteration:   1280, Loss function: 4.849, Average Loss: 4.408, avg. samples / sec: 52826.59
Iteration:   1280, Loss function: 5.258, Average Loss: 4.390, avg. samples / sec: 52953.55
Iteration:   1280, Loss function: 5.096, Average Loss: 4.420, avg. samples / sec: 52927.44
Iteration:   1280, Loss function: 4.556, Average Loss: 4.387, avg. samples / sec: 52972.72
Iteration:   1280, Loss function: 4.632, Average Loss: 4.357, avg. samples / sec: 52976.50
Iteration:   1280, Loss function: 4.535, Average Loss: 4.426, avg. samples / sec: 52847.65
Iteration:   1280, Loss function: 4.564, Average Loss: 4.410, avg. samples / sec: 52971.28
Iteration:   1280, Loss function: 4.748, Average Loss: 4.377, avg. samples / sec: 52862.44
Iteration:   1280, Loss function: 4.430, Average Loss: 4.409, avg. samples / sec: 52940.90
Iteration:   1280, Loss function: 5.683, Average Loss: 4.447, avg. samples / sec: 53018.63
Iteration:   1280, Loss function: 4.568, Average Loss: 4.392, avg. samples / sec: 52878.66
Iteration:   1280, Loss function: 4.561, Average Loss: 4.429, avg. samples / sec: 52980.08
Iteration:   1280, Loss function: 5.834, Average Loss: 4.395, avg. samples / sec: 52775.00
Iteration:   1300, Loss function: 4.605, Average Loss: 4.415, avg. samples / sec: 53095.02
Iteration:   1300, Loss function: 4.447, Average Loss: 4.401, avg. samples / sec: 53096.22
Iteration:   1300, Loss function: 3.729, Average Loss: 4.421, avg. samples / sec: 53110.78
Iteration:   1300, Loss function: 6.217, Average Loss: 4.416, avg. samples / sec: 53135.11
Iteration:   1300, Loss function: 5.569, Average Loss: 4.413, avg. samples / sec: 53093.46
Iteration:   1300, Loss function: 4.500, Average Loss: 4.421, avg. samples / sec: 53114.13
Iteration:   1300, Loss function: 5.348, Average Loss: 4.452, avg. samples / sec: 53127.18
Iteration:   1300, Loss function: 4.277, Average Loss: 4.433, avg. samples / sec: 53113.15
Iteration:   1300, Loss function: 6.890, Average Loss: 4.405, avg. samples / sec: 53079.66
Iteration:   1300, Loss function: 3.577, Average Loss: 4.431, avg. samples / sec: 52979.81
Iteration:   1300, Loss function: 4.277, Average Loss: 4.419, avg. samples / sec: 53094.82
Iteration:   1300, Loss function: 4.559, Average Loss: 4.407, avg. samples / sec: 53085.54
Iteration:   1300, Loss function: 6.507, Average Loss: 4.423, avg. samples / sec: 53108.94
Iteration:   1300, Loss function: 4.181, Average Loss: 4.438, avg. samples / sec: 53340.05
Iteration:   1300, Loss function: 4.700, Average Loss: 4.425, avg. samples / sec: 53180.55
Iteration:   1300, Loss function: 5.685, Average Loss: 4.407, avg. samples / sec: 53102.32
Iteration:   1300, Loss function: 3.717, Average Loss: 4.404, avg. samples / sec: 53072.22
Iteration:   1300, Loss function: 5.559, Average Loss: 4.403, avg. samples / sec: 53129.46
Iteration:   1300, Loss function: 4.739, Average Loss: 4.415, avg. samples / sec: 52956.59
Iteration:   1300, Loss function: 4.917, Average Loss: 4.416, avg. samples / sec: 53074.16
Iteration:   1300, Loss function: 5.162, Average Loss: 4.433, avg. samples / sec: 53093.70
Iteration:   1300, Loss function: 5.648, Average Loss: 4.435, avg. samples / sec: 53127.48
Iteration:   1300, Loss function: 5.533, Average Loss: 4.399, avg. samples / sec: 53147.34
Iteration:   1300, Loss function: 4.085, Average Loss: 4.365, avg. samples / sec: 53120.65
Iteration:   1300, Loss function: 4.366, Average Loss: 4.417, avg. samples / sec: 53117.45
Iteration:   1300, Loss function: 4.262, Average Loss: 4.396, avg. samples / sec: 53088.90
Iteration:   1300, Loss function: 5.087, Average Loss: 4.419, avg. samples / sec: 53098.12
Iteration:   1300, Loss function: 4.715, Average Loss: 4.456, avg. samples / sec: 53096.94
Iteration:   1300, Loss function: 4.347, Average Loss: 4.382, avg. samples / sec: 53076.32
Iteration:   1300, Loss function: 3.767, Average Loss: 4.406, avg. samples / sec: 53086.58
Iteration:   1320, Loss function: 5.680, Average Loss: 4.420, avg. samples / sec: 53201.57
Iteration:   1320, Loss function: 3.858, Average Loss: 4.433, avg. samples / sec: 53327.57
Iteration:   1320, Loss function: 3.856, Average Loss: 4.410, avg. samples / sec: 53190.16
Iteration:   1320, Loss function: 4.460, Average Loss: 4.415, avg. samples / sec: 53269.72
Iteration:   1320, Loss function: 4.325, Average Loss: 4.421, avg. samples / sec: 53287.91
Iteration:   1320, Loss function: 5.371, Average Loss: 4.428, avg. samples / sec: 53245.47
Iteration:   1320, Loss function: 4.357, Average Loss: 4.424, avg. samples / sec: 53223.81
Iteration:   1320, Loss function: 3.940, Average Loss: 4.439, avg. samples / sec: 53233.42
Iteration:   1320, Loss function: 4.415, Average Loss: 4.428, avg. samples / sec: 53248.16
Iteration:   1320, Loss function: 3.549, Average Loss: 4.429, avg. samples / sec: 53179.04
Iteration:   1320, Loss function: 3.525, Average Loss: 4.411, avg. samples / sec: 53262.90
Iteration:   1320, Loss function: 4.930, Average Loss: 4.411, avg. samples / sec: 53224.07
Iteration:   1320, Loss function: 5.015, Average Loss: 4.422, avg. samples / sec: 53163.26
Iteration:   1320, Loss function: 4.989, Average Loss: 4.453, avg. samples / sec: 53182.05
Iteration:   1320, Loss function: 3.997, Average Loss: 4.407, avg. samples / sec: 53197.89
Iteration:   1320, Loss function: 5.151, Average Loss: 4.405, avg. samples / sec: 53409.83
Iteration:   1320, Loss function: 4.632, Average Loss: 4.420, avg. samples / sec: 53321.14
Iteration:   1320, Loss function: 4.212, Average Loss: 4.422, avg. samples / sec: 53238.49
Iteration:   1320, Loss function: 5.984, Average Loss: 4.437, avg. samples / sec: 53263.64
Iteration:   1320, Loss function: 5.757, Average Loss: 4.412, avg. samples / sec: 53203.07
Iteration:   1320, Loss function: 5.237, Average Loss: 4.408, avg. samples / sec: 53069.90
Iteration:   1320, Loss function: 4.260, Average Loss: 4.375, avg. samples / sec: 53215.45
Iteration:   1320, Loss function: 3.833, Average Loss: 4.383, avg. samples / sec: 53255.25
Iteration:   1320, Loss function: 4.240, Average Loss: 4.409, avg. samples / sec: 53270.93
Iteration:   1320, Loss function: 5.260, Average Loss: 4.405, avg. samples / sec: 53193.54
Iteration:   1320, Loss function: 4.229, Average Loss: 4.437, avg. samples / sec: 53181.83
Iteration:   1320, Loss function: 4.556, Average Loss: 4.423, avg. samples / sec: 53189.04
Iteration:   1320, Loss function: 5.259, Average Loss: 4.458, avg. samples / sec: 53219.33
Iteration:   1320, Loss function: 4.439, Average Loss: 4.417, avg. samples / sec: 53208.86
Iteration:   1320, Loss function: 4.422, Average Loss: 4.438, avg. samples / sec: 52979.55
:::MLL 1558640892.319 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558640892.319 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 5.825, Average Loss: 4.427, avg. samples / sec: 51992.43
Iteration:   1340, Loss function: 3.480, Average Loss: 4.411, avg. samples / sec: 51998.21
Iteration:   1340, Loss function: 4.356, Average Loss: 4.439, avg. samples / sec: 51974.37
Iteration:   1340, Loss function: 5.089, Average Loss: 4.417, avg. samples / sec: 52063.25
Iteration:   1340, Loss function: 4.564, Average Loss: 4.426, avg. samples / sec: 52026.10
Iteration:   1340, Loss function: 3.288, Average Loss: 4.419, avg. samples / sec: 51945.50
Iteration:   1340, Loss function: 4.221, Average Loss: 4.430, avg. samples / sec: 52042.05
Iteration:   1340, Loss function: 4.103, Average Loss: 4.409, avg. samples / sec: 52013.83
Iteration:   1340, Loss function: 5.118, Average Loss: 4.434, avg. samples / sec: 51977.09
Iteration:   1340, Loss function: 5.473, Average Loss: 4.442, avg. samples / sec: 51964.81
Iteration:   1340, Loss function: 5.156, Average Loss: 4.428, avg. samples / sec: 51990.77
Iteration:   1340, Loss function: 4.821, Average Loss: 4.415, avg. samples / sec: 52139.13
Iteration:   1340, Loss function: 3.731, Average Loss: 4.425, avg. samples / sec: 51913.83
Iteration:   1340, Loss function: 4.934, Average Loss: 4.459, avg. samples / sec: 51986.80
Iteration:   1340, Loss function: 4.028, Average Loss: 4.434, avg. samples / sec: 51957.64
Iteration:   1340, Loss function: 5.384, Average Loss: 4.432, avg. samples / sec: 51935.47
Iteration:   1340, Loss function: 4.469, Average Loss: 4.418, avg. samples / sec: 51911.12
Iteration:   1340, Loss function: 5.137, Average Loss: 4.429, avg. samples / sec: 51961.55
Iteration:   1340, Loss function: 4.375, Average Loss: 4.440, avg. samples / sec: 51936.93
Iteration:   1340, Loss function: 4.422, Average Loss: 4.417, avg. samples / sec: 51939.78
Iteration:   1340, Loss function: 5.143, Average Loss: 4.408, avg. samples / sec: 52002.05
Iteration:   1340, Loss function: 3.881, Average Loss: 4.440, avg. samples / sec: 52004.18
Iteration:   1340, Loss function: 5.391, Average Loss: 4.409, avg. samples / sec: 51805.25
Iteration:   1340, Loss function: 4.593, Average Loss: 4.440, avg. samples / sec: 51998.90
Iteration:   1340, Loss function: 4.463, Average Loss: 4.377, avg. samples / sec: 51959.00
Iteration:   1340, Loss function: 5.568, Average Loss: 4.389, avg. samples / sec: 51970.16
Iteration:   1340, Loss function: 3.976, Average Loss: 4.424, avg. samples / sec: 51969.24
Iteration:   1340, Loss function: 6.931, Average Loss: 4.423, avg. samples / sec: 51975.00
Iteration:   1340, Loss function: 3.941, Average Loss: 4.410, avg. samples / sec: 51934.46
Iteration:   1340, Loss function: 5.054, Average Loss: 4.458, avg. samples / sec: 51937.86
Iteration:   1360, Loss function: 5.287, Average Loss: 4.433, avg. samples / sec: 53308.41
Iteration:   1360, Loss function: 5.263, Average Loss: 4.414, avg. samples / sec: 53333.71
Iteration:   1360, Loss function: 3.591, Average Loss: 4.439, avg. samples / sec: 53348.85
Iteration:   1360, Loss function: 4.488, Average Loss: 4.424, avg. samples / sec: 53274.43
Iteration:   1360, Loss function: 6.036, Average Loss: 4.422, avg. samples / sec: 53201.89
Iteration:   1360, Loss function: 5.159, Average Loss: 4.432, avg. samples / sec: 53270.20
Iteration:   1360, Loss function: 4.328, Average Loss: 4.432, avg. samples / sec: 53193.48
Iteration:   1360, Loss function: 4.739, Average Loss: 4.440, avg. samples / sec: 53275.96
Iteration:   1360, Loss function: 4.575, Average Loss: 4.413, avg. samples / sec: 53242.79
Iteration:   1360, Loss function: 4.613, Average Loss: 4.443, avg. samples / sec: 53245.21
Iteration:   1360, Loss function: 4.874, Average Loss: 4.433, avg. samples / sec: 53238.23
Iteration:   1360, Loss function: 4.116, Average Loss: 4.425, avg. samples / sec: 53272.70
Iteration:   1360, Loss function: 4.046, Average Loss: 4.411, avg. samples / sec: 53485.74
Iteration:   1360, Loss function: 4.566, Average Loss: 4.419, avg. samples / sec: 53204.08
Iteration:   1360, Loss function: 4.145, Average Loss: 4.461, avg. samples / sec: 53195.24
Iteration:   1360, Loss function: 4.757, Average Loss: 4.427, avg. samples / sec: 53401.43
Iteration:   1360, Loss function: 4.350, Average Loss: 4.443, avg. samples / sec: 53084.46
Iteration:   1360, Loss function: 4.592, Average Loss: 4.420, avg. samples / sec: 53284.77
Iteration:   1360, Loss function: 3.771, Average Loss: 4.435, avg. samples / sec: 53216.33
Iteration:   1360, Loss function: 4.890, Average Loss: 4.384, avg. samples / sec: 53275.84
Iteration:   1360, Loss function: 4.462, Average Loss: 4.461, avg. samples / sec: 53336.03
Iteration:   1360, Loss function: 3.348, Average Loss: 4.410, avg. samples / sec: 53239.11
Iteration:   1360, Loss function: 4.336, Average Loss: 4.447, avg. samples / sec: 53256.66
Iteration:   1360, Loss function: 4.101, Average Loss: 4.445, avg. samples / sec: 52915.99
Iteration:   1360, Loss function: 4.338, Average Loss: 4.419, avg. samples / sec: 53233.26
Iteration:   1360, Loss function: 4.612, Average Loss: 4.445, avg. samples / sec: 53217.98
Iteration:   1360, Loss function: 4.639, Average Loss: 4.443, avg. samples / sec: 53233.46
Iteration:   1360, Loss function: 5.241, Average Loss: 4.430, avg. samples / sec: 53018.63
Iteration:   1360, Loss function: 4.323, Average Loss: 4.433, avg. samples / sec: 53274.67
Iteration:   1360, Loss function: 4.114, Average Loss: 4.394, avg. samples / sec: 53223.35
Iteration:   1380, Loss function: 4.516, Average Loss: 4.432, avg. samples / sec: 53100.90
Iteration:   1380, Loss function: 3.289, Average Loss: 4.446, avg. samples / sec: 53499.65
Iteration:   1380, Loss function: 6.067, Average Loss: 4.422, avg. samples / sec: 53034.37
Iteration:   1380, Loss function: 3.619, Average Loss: 4.429, avg. samples / sec: 53158.06
Iteration:   1380, Loss function: 3.896, Average Loss: 4.431, avg. samples / sec: 53454.56
Iteration:   1380, Loss function: 4.613, Average Loss: 4.438, avg. samples / sec: 53171.16
Iteration:   1380, Loss function: 5.361, Average Loss: 4.449, avg. samples / sec: 53210.35
Iteration:   1380, Loss function: 4.094, Average Loss: 4.427, avg. samples / sec: 53252.83
Iteration:   1380, Loss function: 3.953, Average Loss: 4.441, avg. samples / sec: 53197.01
Iteration:   1380, Loss function: 3.122, Average Loss: 4.462, avg. samples / sec: 53249.65
Iteration:   1380, Loss function: 4.747, Average Loss: 4.441, avg. samples / sec: 53097.74
Iteration:   1380, Loss function: 3.666, Average Loss: 4.424, avg. samples / sec: 53131.03
Iteration:   1380, Loss function: 4.555, Average Loss: 4.440, avg. samples / sec: 53129.89
Iteration:   1380, Loss function: 4.527, Average Loss: 4.424, avg. samples / sec: 53179.45
Iteration:   1380, Loss function: 5.461, Average Loss: 4.433, avg. samples / sec: 53111.06
Iteration:   1380, Loss function: 4.511, Average Loss: 4.413, avg. samples / sec: 53118.69
Iteration:   1380, Loss function: 4.280, Average Loss: 4.449, avg. samples / sec: 53283.19
Iteration:   1380, Loss function: 6.321, Average Loss: 4.449, avg. samples / sec: 53244.95
Iteration:   1380, Loss function: 3.830, Average Loss: 4.422, avg. samples / sec: 53253.90
Iteration:   1380, Loss function: 4.489, Average Loss: 4.390, avg. samples / sec: 53222.26
Iteration:   1380, Loss function: 4.429, Average Loss: 4.446, avg. samples / sec: 53162.39
Iteration:   1380, Loss function: 4.677, Average Loss: 4.447, avg. samples / sec: 53201.87
Iteration:   1380, Loss function: 4.026, Average Loss: 4.416, avg. samples / sec: 53189.56
Iteration:   1380, Loss function: 3.661, Average Loss: 4.435, avg. samples / sec: 53200.28
Iteration:   1380, Loss function: 3.460, Average Loss: 4.399, avg. samples / sec: 53219.19
Iteration:   1380, Loss function: 4.709, Average Loss: 4.434, avg. samples / sec: 53047.21
Iteration:   1380, Loss function: 5.288, Average Loss: 4.464, avg. samples / sec: 53121.65
Iteration:   1380, Loss function: 5.158, Average Loss: 4.425, avg. samples / sec: 52943.02
Iteration:   1380, Loss function: 3.920, Average Loss: 4.415, avg. samples / sec: 52704.08
Iteration:   1380, Loss function: 5.319, Average Loss: 4.441, avg. samples / sec: 52904.59
:::MLL 1558640894.539 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558640894.540 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 4.320, Average Loss: 4.435, avg. samples / sec: 53142.43
Iteration:   1400, Loss function: 4.581, Average Loss: 4.435, avg. samples / sec: 52909.95
Iteration:   1400, Loss function: 3.823, Average Loss: 4.423, avg. samples / sec: 52991.28
Iteration:   1400, Loss function: 4.816, Average Loss: 4.445, avg. samples / sec: 53055.08
Iteration:   1400, Loss function: 3.849, Average Loss: 4.466, avg. samples / sec: 53018.27
Iteration:   1400, Loss function: 5.582, Average Loss: 4.449, avg. samples / sec: 52930.66
Iteration:   1400, Loss function: 5.200, Average Loss: 4.441, avg. samples / sec: 52974.43
Iteration:   1400, Loss function: 3.733, Average Loss: 4.432, avg. samples / sec: 52897.80
Iteration:   1400, Loss function: 4.300, Average Loss: 4.443, avg. samples / sec: 52971.26
Iteration:   1400, Loss function: 4.572, Average Loss: 4.416, avg. samples / sec: 53419.97
Iteration:   1400, Loss function: 3.337, Average Loss: 4.431, avg. samples / sec: 52961.27
Iteration:   1400, Loss function: 4.407, Average Loss: 4.436, avg. samples / sec: 52881.18
Iteration:   1400, Loss function: 4.424, Average Loss: 4.453, avg. samples / sec: 52871.22
Iteration:   1400, Loss function: 5.232, Average Loss: 4.437, avg. samples / sec: 52854.03
Iteration:   1400, Loss function: 3.855, Average Loss: 4.441, avg. samples / sec: 52865.45
Iteration:   1400, Loss function: 4.319, Average Loss: 4.429, avg. samples / sec: 52893.67
Iteration:   1400, Loss function: 5.364, Average Loss: 4.450, avg. samples / sec: 53022.34
Iteration:   1400, Loss function: 4.318, Average Loss: 4.439, avg. samples / sec: 53033.12
Iteration:   1400, Loss function: 4.890, Average Loss: 4.408, avg. samples / sec: 52989.27
Iteration:   1400, Loss function: 3.106, Average Loss: 4.390, avg. samples / sec: 52919.86
Iteration:   1400, Loss function: 4.397, Average Loss: 4.421, avg. samples / sec: 52964.65
Iteration:   1400, Loss function: 4.923, Average Loss: 4.418, avg. samples / sec: 52829.74
Iteration:   1400, Loss function: 5.389, Average Loss: 4.446, avg. samples / sec: 53197.11
Iteration:   1400, Loss function: 5.285, Average Loss: 4.426, avg. samples / sec: 53105.10
Iteration:   1400, Loss function: 4.466, Average Loss: 4.448, avg. samples / sec: 52856.79
Iteration:   1400, Loss function: 5.392, Average Loss: 4.456, avg. samples / sec: 52831.82
Iteration:   1400, Loss function: 4.701, Average Loss: 4.457, avg. samples / sec: 52898.49
Iteration:   1400, Loss function: 4.508, Average Loss: 4.424, avg. samples / sec: 52825.48
Iteration:   1400, Loss function: 4.119, Average Loss: 4.468, avg. samples / sec: 52921.77
Iteration:   1400, Loss function: 3.641, Average Loss: 4.437, avg. samples / sec: 52866.68
Iteration:   1420, Loss function: 3.519, Average Loss: 4.429, avg. samples / sec: 53222.73
Iteration:   1420, Loss function: 4.432, Average Loss: 4.435, avg. samples / sec: 53155.34
Iteration:   1420, Loss function: 4.199, Average Loss: 4.450, avg. samples / sec: 53172.76
Iteration:   1420, Loss function: 5.064, Average Loss: 4.441, avg. samples / sec: 53294.08
Iteration:   1420, Loss function: 3.407, Average Loss: 4.436, avg. samples / sec: 53089.48
Iteration:   1420, Loss function: 4.819, Average Loss: 4.421, avg. samples / sec: 53195.52
Iteration:   1420, Loss function: 3.389, Average Loss: 4.443, avg. samples / sec: 53245.55
Iteration:   1420, Loss function: 5.905, Average Loss: 4.468, avg. samples / sec: 53107.16
Iteration:   1420, Loss function: 4.093, Average Loss: 4.449, avg. samples / sec: 53221.94
Iteration:   1420, Loss function: 4.257, Average Loss: 4.445, avg. samples / sec: 53108.20
Iteration:   1420, Loss function: 4.214, Average Loss: 4.445, avg. samples / sec: 53170.62
Iteration:   1420, Loss function: 5.037, Average Loss: 4.443, avg. samples / sec: 53205.30
Iteration:   1420, Loss function: 4.355, Average Loss: 4.433, avg. samples / sec: 53154.83
Iteration:   1420, Loss function: 4.575, Average Loss: 4.432, avg. samples / sec: 53178.36
Iteration:   1420, Loss function: 5.058, Average Loss: 4.427, avg. samples / sec: 53250.26
Iteration:   1420, Loss function: 5.409, Average Loss: 4.453, avg. samples / sec: 53102.84
Iteration:   1420, Loss function: 5.474, Average Loss: 4.423, avg. samples / sec: 53187.13
Iteration:   1420, Loss function: 4.727, Average Loss: 4.457, avg. samples / sec: 53237.58
Iteration:   1420, Loss function: 5.231, Average Loss: 4.432, avg. samples / sec: 53043.68
Iteration:   1420, Loss function: 4.589, Average Loss: 4.445, avg. samples / sec: 53211.37
Iteration:   1420, Loss function: 5.241, Average Loss: 4.458, avg. samples / sec: 53238.23
Iteration:   1420, Loss function: 4.250, Average Loss: 4.396, avg. samples / sec: 53166.77
Iteration:   1420, Loss function: 6.744, Average Loss: 4.454, avg. samples / sec: 53218.26
Iteration:   1420, Loss function: 4.047, Average Loss: 4.436, avg. samples / sec: 53234.37
Iteration:   1420, Loss function: 4.442, Average Loss: 4.414, avg. samples / sec: 53117.65
Iteration:   1420, Loss function: 4.460, Average Loss: 4.442, avg. samples / sec: 53088.64
Iteration:   1420, Loss function: 5.265, Average Loss: 4.467, avg. samples / sec: 53208.54
Iteration:   1420, Loss function: 4.112, Average Loss: 4.448, avg. samples / sec: 52794.99
Iteration:   1420, Loss function: 5.170, Average Loss: 4.427, avg. samples / sec: 53197.71
Iteration:   1420, Loss function: 3.629, Average Loss: 4.418, avg. samples / sec: 53129.93
Iteration:   1440, Loss function: 4.401, Average Loss: 4.436, avg. samples / sec: 53431.35
Iteration:   1440, Loss function: 5.293, Average Loss: 4.433, avg. samples / sec: 53349.35
Iteration:   1440, Loss function: 5.104, Average Loss: 4.456, avg. samples / sec: 53307.18
Iteration:   1440, Loss function: 4.797, Average Loss: 4.454, avg. samples / sec: 53358.79
Iteration:   1440, Loss function: 5.454, Average Loss: 4.459, avg. samples / sec: 53552.61
Iteration:   1440, Loss function: 4.008, Average Loss: 4.451, avg. samples / sec: 53358.83
Iteration:   1440, Loss function: 4.398, Average Loss: 4.450, avg. samples / sec: 53629.60
Iteration:   1440, Loss function: 6.102, Average Loss: 4.447, avg. samples / sec: 53359.21
Iteration:   1440, Loss function: 5.158, Average Loss: 4.426, avg. samples / sec: 53332.17
Iteration:   1440, Loss function: 3.923, Average Loss: 4.445, avg. samples / sec: 53276.53
Iteration:   1440, Loss function: 4.601, Average Loss: 4.441, avg. samples / sec: 53340.13
Iteration:   1440, Loss function: 4.517, Average Loss: 4.446, avg. samples / sec: 53325.57
Iteration:   1440, Loss function: 5.501, Average Loss: 4.445, avg. samples / sec: 53289.30
Iteration:   1440, Loss function: 4.640, Average Loss: 4.433, avg. samples / sec: 53351.82
Iteration:   1440, Loss function: 5.384, Average Loss: 4.474, avg. samples / sec: 53300.18
Iteration:   1440, Loss function: 4.603, Average Loss: 4.444, avg. samples / sec: 53274.80
Iteration:   1440, Loss function: 4.949, Average Loss: 4.451, avg. samples / sec: 53350.32
Iteration:   1440, Loss function: 5.808, Average Loss: 4.458, avg. samples / sec: 53345.66
Iteration:   1440, Loss function: 4.549, Average Loss: 4.431, avg. samples / sec: 53406.59
Iteration:   1440, Loss function: 4.398, Average Loss: 4.435, avg. samples / sec: 53313.37
Iteration:   1440, Loss function: 4.360, Average Loss: 4.433, avg. samples / sec: 53325.03
Iteration:   1440, Loss function: 4.865, Average Loss: 4.430, avg. samples / sec: 53306.47
Iteration:   1440, Loss function: 4.336, Average Loss: 4.447, avg. samples / sec: 53367.60
Iteration:   1440, Loss function: 5.502, Average Loss: 4.440, avg. samples / sec: 53348.61
Iteration:   1440, Loss function: 4.630, Average Loss: 4.459, avg. samples / sec: 53301.41
Iteration:   1440, Loss function: 4.105, Average Loss: 4.463, avg. samples / sec: 53305.97
Iteration:   1440, Loss function: 4.402, Average Loss: 4.417, avg. samples / sec: 53325.86
Iteration:   1440, Loss function: 3.432, Average Loss: 4.416, avg. samples / sec: 53348.81
Iteration:   1440, Loss function: 3.661, Average Loss: 4.468, avg. samples / sec: 53326.18
Iteration:   1440, Loss function: 4.296, Average Loss: 4.403, avg. samples / sec: 53229.92
Iteration:   1460, Loss function: 5.477, Average Loss: 4.455, avg. samples / sec: 53478.39
Iteration:   1460, Loss function: 4.347, Average Loss: 4.437, avg. samples / sec: 53329.95
Iteration:   1460, Loss function: 4.310, Average Loss: 4.440, avg. samples / sec: 53211.53
Iteration:   1460, Loss function: 4.985, Average Loss: 4.465, avg. samples / sec: 53327.05
Iteration:   1460, Loss function: 3.926, Average Loss: 4.449, avg. samples / sec: 53326.34
Iteration:   1460, Loss function: 4.617, Average Loss: 4.442, avg. samples / sec: 53344.87
Iteration:   1460, Loss function: 4.878, Average Loss: 4.450, avg. samples / sec: 53313.95
Iteration:   1460, Loss function: 3.109, Average Loss: 4.442, avg. samples / sec: 53341.34
Iteration:   1460, Loss function: 4.501, Average Loss: 4.431, avg. samples / sec: 53303.47
Iteration:   1460, Loss function: 3.675, Average Loss: 4.473, avg. samples / sec: 53322.20
Iteration:   1460, Loss function: 4.590, Average Loss: 4.451, avg. samples / sec: 53280.90
Iteration:   1460, Loss function: 6.017, Average Loss: 4.445, avg. samples / sec: 53340.87
Iteration:   1460, Loss function: 4.221, Average Loss: 4.444, avg. samples / sec: 53288.25
Iteration:   1460, Loss function: 3.753, Average Loss: 4.444, avg. samples / sec: 53267.81
Iteration:   1460, Loss function: 4.026, Average Loss: 4.431, avg. samples / sec: 53400.98
Iteration:   1460, Loss function: 5.020, Average Loss: 4.445, avg. samples / sec: 53215.99
Iteration:   1460, Loss function: 4.120, Average Loss: 4.408, avg. samples / sec: 53454.46
Iteration:   1460, Loss function: 4.481, Average Loss: 4.462, avg. samples / sec: 53278.94
Iteration:   1460, Loss function: 4.495, Average Loss: 4.455, avg. samples / sec: 53276.35
Iteration:   1460, Loss function: 4.303, Average Loss: 4.429, avg. samples / sec: 53304.64
Iteration:   1460, Loss function: 4.145, Average Loss: 4.442, avg. samples / sec: 53282.01
Iteration:   1460, Loss function: 4.527, Average Loss: 4.462, avg. samples / sec: 53313.33
Iteration:   1460, Loss function: 4.225, Average Loss: 4.445, avg. samples / sec: 53302.66
Iteration:   1460, Loss function: 4.218, Average Loss: 4.436, avg. samples / sec: 53271.59
Iteration:   1460, Loss function: 4.613, Average Loss: 4.465, avg. samples / sec: 53299.09
Iteration:   1460, Loss function: 4.480, Average Loss: 4.459, avg. samples / sec: 53016.02
Iteration:   1460, Loss function: 4.271, Average Loss: 4.416, avg. samples / sec: 53303.75
Iteration:   1460, Loss function: 4.672, Average Loss: 4.449, avg. samples / sec: 53263.84
Iteration:   1460, Loss function: 3.792, Average Loss: 4.471, avg. samples / sec: 53304.23
Iteration:   1460, Loss function: 3.680, Average Loss: 4.418, avg. samples / sec: 53284.52
:::MLL 1558640896.749 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558640896.750 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.916, Average Loss: 4.441, avg. samples / sec: 52801.04
Iteration:   1480, Loss function: 3.470, Average Loss: 4.442, avg. samples / sec: 52871.56
Iteration:   1480, Loss function: 3.587, Average Loss: 4.463, avg. samples / sec: 52844.08
Iteration:   1480, Loss function: 3.824, Average Loss: 4.443, avg. samples / sec: 52907.47
Iteration:   1480, Loss function: 3.855, Average Loss: 4.456, avg. samples / sec: 52645.71
Iteration:   1480, Loss function: 2.945, Average Loss: 4.449, avg. samples / sec: 52819.44
Iteration:   1480, Loss function: 4.793, Average Loss: 4.441, avg. samples / sec: 52801.75
Iteration:   1480, Loss function: 4.140, Average Loss: 4.451, avg. samples / sec: 52847.27
Iteration:   1480, Loss function: 4.897, Average Loss: 4.451, avg. samples / sec: 52834.77
Iteration:   1480, Loss function: 4.246, Average Loss: 4.444, avg. samples / sec: 52800.66
Iteration:   1480, Loss function: 5.120, Average Loss: 4.449, avg. samples / sec: 52921.97
Iteration:   1480, Loss function: 4.741, Average Loss: 4.453, avg. samples / sec: 52842.30
Iteration:   1480, Loss function: 4.402, Average Loss: 4.449, avg. samples / sec: 52759.31
Iteration:   1480, Loss function: 4.689, Average Loss: 4.433, avg. samples / sec: 52793.15
Iteration:   1480, Loss function: 3.881, Average Loss: 4.469, avg. samples / sec: 52759.15
Iteration:   1480, Loss function: 3.525, Average Loss: 4.442, avg. samples / sec: 52886.52
Iteration:   1480, Loss function: 4.717, Average Loss: 4.464, avg. samples / sec: 52905.88
Iteration:   1480, Loss function: 3.595, Average Loss: 4.466, avg. samples / sec: 52857.20
Iteration:   1480, Loss function: 5.345, Average Loss: 4.461, avg. samples / sec: 52859.88
Iteration:   1480, Loss function: 4.159, Average Loss: 4.404, avg. samples / sec: 52790.64
Iteration:   1480, Loss function: 3.436, Average Loss: 4.452, avg. samples / sec: 52835.62
Iteration:   1480, Loss function: 5.726, Average Loss: 4.435, avg. samples / sec: 52713.01
Iteration:   1480, Loss function: 5.166, Average Loss: 4.444, avg. samples / sec: 52840.79
Iteration:   1480, Loss function: 4.643, Average Loss: 4.430, avg. samples / sec: 52814.65
Iteration:   1480, Loss function: 5.285, Average Loss: 4.422, avg. samples / sec: 52872.27
Iteration:   1480, Loss function: 4.933, Average Loss: 4.470, avg. samples / sec: 52826.77
Iteration:   1480, Loss function: 4.337, Average Loss: 4.421, avg. samples / sec: 52837.27
Iteration:   1480, Loss function: 3.572, Average Loss: 4.434, avg. samples / sec: 52810.48
Iteration:   1480, Loss function: 3.235, Average Loss: 4.449, avg. samples / sec: 52816.79
Iteration:   1480, Loss function: 4.740, Average Loss: 4.473, avg. samples / sec: 52811.13
Iteration:   1500, Loss function: 4.233, Average Loss: 4.444, avg. samples / sec: 52901.53
Iteration:   1500, Loss function: 4.597, Average Loss: 4.440, avg. samples / sec: 52933.12
Iteration:   1500, Loss function: 4.222, Average Loss: 4.451, avg. samples / sec: 53004.08
Iteration:   1500, Loss function: 4.696, Average Loss: 4.465, avg. samples / sec: 52909.75
Iteration:   1500, Loss function: 4.629, Average Loss: 4.450, avg. samples / sec: 52911.18
Iteration:   1500, Loss function: 4.771, Average Loss: 4.437, avg. samples / sec: 52948.75
Iteration:   1500, Loss function: 4.615, Average Loss: 4.453, avg. samples / sec: 52901.25
Iteration:   1500, Loss function: 3.654, Average Loss: 4.453, avg. samples / sec: 52871.74
Iteration:   1500, Loss function: 4.589, Average Loss: 4.455, avg. samples / sec: 52894.32
Iteration:   1500, Loss function: 4.675, Average Loss: 4.446, avg. samples / sec: 52808.54
Iteration:   1500, Loss function: 5.269, Average Loss: 4.444, avg. samples / sec: 52825.32
Iteration:   1500, Loss function: 5.003, Average Loss: 4.460, avg. samples / sec: 52820.47
Iteration:   1500, Loss function: 3.728, Average Loss: 4.434, avg. samples / sec: 52998.99
Iteration:   1500, Loss function: 4.552, Average Loss: 4.452, avg. samples / sec: 52911.10
Iteration:   1500, Loss function: 5.310, Average Loss: 4.460, avg. samples / sec: 52875.45
Iteration:   1500, Loss function: 4.437, Average Loss: 4.466, avg. samples / sec: 52877.11
Iteration:   1500, Loss function: 4.935, Average Loss: 4.439, avg. samples / sec: 52907.61
Iteration:   1500, Loss function: 4.383, Average Loss: 4.443, avg. samples / sec: 52662.75
Iteration:   1500, Loss function: 3.857, Average Loss: 4.463, avg. samples / sec: 52868.49
Iteration:   1500, Loss function: 4.253, Average Loss: 4.471, avg. samples / sec: 52915.25
Iteration:   1500, Loss function: 4.290, Average Loss: 4.452, avg. samples / sec: 52828.75
Iteration:   1500, Loss function: 4.486, Average Loss: 4.471, avg. samples / sec: 52735.76
Iteration:   1500, Loss function: 3.895, Average Loss: 4.408, avg. samples / sec: 52846.30
Iteration:   1500, Loss function: 4.120, Average Loss: 4.439, avg. samples / sec: 52889.93
Iteration:   1500, Loss function: 4.887, Average Loss: 4.456, avg. samples / sec: 52543.29
Iteration:   1500, Loss function: 3.902, Average Loss: 4.477, avg. samples / sec: 52910.43
Iteration:   1500, Loss function: 4.525, Average Loss: 4.448, avg. samples / sec: 52839.96
Iteration:   1500, Loss function: 5.893, Average Loss: 4.453, avg. samples / sec: 52880.31
Iteration:   1500, Loss function: 5.478, Average Loss: 4.422, avg. samples / sec: 52847.99
Iteration:   1500, Loss function: 5.300, Average Loss: 4.426, avg. samples / sec: 52823.30
Iteration:   1520, Loss function: 4.161, Average Loss: 4.447, avg. samples / sec: 54252.58
Iteration:   1520, Loss function: 4.977, Average Loss: 4.445, avg. samples / sec: 54216.58
Iteration:   1520, Loss function: 5.226, Average Loss: 4.455, avg. samples / sec: 54252.75
Iteration:   1520, Loss function: 4.486, Average Loss: 4.452, avg. samples / sec: 54340.86
Iteration:   1520, Loss function: 5.530, Average Loss: 4.458, avg. samples / sec: 54142.24
Iteration:   1520, Loss function: 4.393, Average Loss: 4.456, avg. samples / sec: 54273.60
Iteration:   1520, Loss function: 3.591, Average Loss: 4.448, avg. samples / sec: 54538.22
Iteration:   1520, Loss function: 3.605, Average Loss: 4.437, avg. samples / sec: 54469.86
Iteration:   1520, Loss function: 4.328, Average Loss: 4.465, avg. samples / sec: 54194.50
Iteration:   1520, Loss function: 3.236, Average Loss: 4.436, avg. samples / sec: 54178.75
Iteration:   1520, Loss function: 5.615, Average Loss: 4.466, avg. samples / sec: 54267.95
Iteration:   1520, Loss function: 4.978, Average Loss: 4.447, avg. samples / sec: 54234.56
Iteration:   1520, Loss function: 4.608, Average Loss: 4.457, avg. samples / sec: 54188.97
Iteration:   1520, Loss function: 4.629, Average Loss: 4.454, avg. samples / sec: 54161.86
Iteration:   1520, Loss function: 4.535, Average Loss: 4.449, avg. samples / sec: 54327.26
Iteration:   1520, Loss function: 3.058, Average Loss: 4.449, avg. samples / sec: 54263.17
Iteration:   1520, Loss function: 4.598, Average Loss: 4.466, avg. samples / sec: 54260.98
Iteration:   1520, Loss function: 5.213, Average Loss: 4.454, avg. samples / sec: 54289.47
Iteration:   1520, Loss function: 5.038, Average Loss: 4.435, avg. samples / sec: 54163.38
Iteration:   1520, Loss function: 3.446, Average Loss: 4.471, avg. samples / sec: 54279.39
Iteration:   1520, Loss function: 4.894, Average Loss: 4.470, avg. samples / sec: 54259.60
Iteration:   1520, Loss function: 3.984, Average Loss: 4.440, avg. samples / sec: 54291.54
Iteration:   1520, Loss function: 4.214, Average Loss: 4.452, avg. samples / sec: 54295.24
Iteration:   1520, Loss function: 4.363, Average Loss: 4.465, avg. samples / sec: 54207.32
Iteration:   1520, Loss function: 5.477, Average Loss: 4.461, avg. samples / sec: 54235.85
Iteration:   1520, Loss function: 4.331, Average Loss: 4.406, avg. samples / sec: 54257.17
Iteration:   1520, Loss function: 5.140, Average Loss: 4.452, avg. samples / sec: 54280.25
Iteration:   1520, Loss function: 4.893, Average Loss: 4.422, avg. samples / sec: 54298.54
Iteration:   1520, Loss function: 4.388, Average Loss: 4.424, avg. samples / sec: 54259.35
Iteration:   1520, Loss function: 4.130, Average Loss: 4.477, avg. samples / sec: 54162.36
:::MLL 1558640898.948 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558640898.949 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.513, Average Loss: 4.446, avg. samples / sec: 53690.63
Iteration:   1540, Loss function: 4.922, Average Loss: 4.442, avg. samples / sec: 53619.42
Iteration:   1540, Loss function: 5.309, Average Loss: 4.461, avg. samples / sec: 53757.56
Iteration:   1540, Loss function: 4.167, Average Loss: 4.425, avg. samples / sec: 54010.64
Iteration:   1540, Loss function: 5.311, Average Loss: 4.455, avg. samples / sec: 53827.08
Iteration:   1540, Loss function: 4.212, Average Loss: 4.445, avg. samples / sec: 53720.20
Iteration:   1540, Loss function: 4.891, Average Loss: 4.467, avg. samples / sec: 53653.88
Iteration:   1540, Loss function: 4.198, Average Loss: 4.454, avg. samples / sec: 53575.21
Iteration:   1540, Loss function: 3.874, Average Loss: 4.436, avg. samples / sec: 53635.62
Iteration:   1540, Loss function: 4.261, Average Loss: 4.460, avg. samples / sec: 53581.32
Iteration:   1540, Loss function: 4.824, Average Loss: 4.452, avg. samples / sec: 53562.64
Iteration:   1540, Loss function: 3.996, Average Loss: 4.458, avg. samples / sec: 53649.98
Iteration:   1540, Loss function: 4.343, Average Loss: 4.427, avg. samples / sec: 53783.29
Iteration:   1540, Loss function: 4.370, Average Loss: 4.464, avg. samples / sec: 53814.36
Iteration:   1540, Loss function: 4.125, Average Loss: 4.465, avg. samples / sec: 53611.46
Iteration:   1540, Loss function: 4.330, Average Loss: 4.465, avg. samples / sec: 53775.08
Iteration:   1540, Loss function: 4.260, Average Loss: 4.466, avg. samples / sec: 53739.75
Iteration:   1540, Loss function: 4.265, Average Loss: 4.455, avg. samples / sec: 53587.94
Iteration:   1540, Loss function: 4.716, Average Loss: 4.441, avg. samples / sec: 53716.31
Iteration:   1540, Loss function: 4.832, Average Loss: 4.434, avg. samples / sec: 53493.13
Iteration:   1540, Loss function: 4.402, Average Loss: 4.423, avg. samples / sec: 53756.33
Iteration:   1540, Loss function: 4.999, Average Loss: 4.453, avg. samples / sec: 53710.83
Iteration:   1540, Loss function: 4.298, Average Loss: 4.446, avg. samples / sec: 53604.84
Iteration:   1540, Loss function: 4.226, Average Loss: 4.470, avg. samples / sec: 53601.41
Iteration:   1540, Loss function: 4.000, Average Loss: 4.471, avg. samples / sec: 53626.21
Iteration:   1540, Loss function: 4.148, Average Loss: 4.459, avg. samples / sec: 53639.64
Iteration:   1540, Loss function: 4.512, Average Loss: 4.407, avg. samples / sec: 53643.71
Iteration:   1540, Loss function: 5.279, Average Loss: 4.461, avg. samples / sec: 53586.70
Iteration:   1540, Loss function: 4.462, Average Loss: 4.448, avg. samples / sec: 53371.60
Iteration:   1540, Loss function: 4.517, Average Loss: 4.476, avg. samples / sec: 53696.56
Iteration:   1560, Loss function: 5.346, Average Loss: 4.451, avg. samples / sec: 53694.37
Iteration:   1560, Loss function: 4.058, Average Loss: 4.437, avg. samples / sec: 53692.82
Iteration:   1560, Loss function: 3.722, Average Loss: 4.441, avg. samples / sec: 53777.50
Iteration:   1560, Loss function: 5.191, Average Loss: 4.459, avg. samples / sec: 53732.84
Iteration:   1560, Loss function: 4.351, Average Loss: 4.458, avg. samples / sec: 53806.55
Iteration:   1560, Loss function: 5.068, Average Loss: 4.456, avg. samples / sec: 53766.99
Iteration:   1560, Loss function: 4.360, Average Loss: 4.463, avg. samples / sec: 53607.75
Iteration:   1560, Loss function: 4.367, Average Loss: 4.439, avg. samples / sec: 53766.40
Iteration:   1560, Loss function: 4.521, Average Loss: 4.454, avg. samples / sec: 53866.34
Iteration:   1560, Loss function: 4.458, Average Loss: 4.456, avg. samples / sec: 53762.85
Iteration:   1560, Loss function: 4.238, Average Loss: 4.469, avg. samples / sec: 53702.31
Iteration:   1560, Loss function: 3.928, Average Loss: 4.456, avg. samples / sec: 53878.47
Iteration:   1560, Loss function: 3.230, Average Loss: 4.459, avg. samples / sec: 53880.98
Iteration:   1560, Loss function: 5.949, Average Loss: 4.428, avg. samples / sec: 53540.08
Iteration:   1560, Loss function: 4.375, Average Loss: 4.443, avg. samples / sec: 53797.72
Iteration:   1560, Loss function: 4.444, Average Loss: 4.463, avg. samples / sec: 53679.16
Iteration:   1560, Loss function: 3.213, Average Loss: 4.460, avg. samples / sec: 53658.72
Iteration:   1560, Loss function: 4.870, Average Loss: 4.469, avg. samples / sec: 53582.80
Iteration:   1560, Loss function: 3.485, Average Loss: 4.426, avg. samples / sec: 53569.63
Iteration:   1560, Loss function: 5.155, Average Loss: 4.464, avg. samples / sec: 53583.66
Iteration:   1560, Loss function: 4.425, Average Loss: 4.441, avg. samples / sec: 53630.19
Iteration:   1560, Loss function: 4.593, Average Loss: 4.413, avg. samples / sec: 53724.89
Iteration:   1560, Loss function: 4.755, Average Loss: 4.458, avg. samples / sec: 53664.32
Iteration:   1560, Loss function: 5.298, Average Loss: 4.432, avg. samples / sec: 53615.83
Iteration:   1560, Loss function: 3.166, Average Loss: 4.419, avg. samples / sec: 53626.78
Iteration:   1560, Loss function: 4.665, Average Loss: 4.472, avg. samples / sec: 53689.18
Iteration:   1560, Loss function: 4.224, Average Loss: 4.447, avg. samples / sec: 53708.64
Iteration:   1560, Loss function: 3.882, Average Loss: 4.474, avg. samples / sec: 53732.84
Iteration:   1560, Loss function: 4.752, Average Loss: 4.454, avg. samples / sec: 53445.17
Iteration:   1560, Loss function: 3.566, Average Loss: 4.469, avg. samples / sec: 53578.04
Iteration:   1580, Loss function: 4.475, Average Loss: 4.436, avg. samples / sec: 54526.47
Iteration:   1580, Loss function: 4.845, Average Loss: 4.453, avg. samples / sec: 54361.46
Iteration:   1580, Loss function: 4.151, Average Loss: 4.427, avg. samples / sec: 54611.32
Iteration:   1580, Loss function: 5.208, Average Loss: 4.470, avg. samples / sec: 54505.65
Iteration:   1580, Loss function: 5.565, Average Loss: 4.461, avg. samples / sec: 54427.09
Iteration:   1580, Loss function: 4.450, Average Loss: 4.454, avg. samples / sec: 54828.04
Iteration:   1580, Loss function: 3.334, Average Loss: 4.457, avg. samples / sec: 54443.05
Iteration:   1580, Loss function: 4.139, Average Loss: 4.439, avg. samples / sec: 54451.44
Iteration:   1580, Loss function: 3.417, Average Loss: 4.440, avg. samples / sec: 54368.91
Iteration:   1580, Loss function: 5.217, Average Loss: 4.464, avg. samples / sec: 54429.17
Iteration:   1580, Loss function: 4.146, Average Loss: 4.462, avg. samples / sec: 54544.47
Iteration:   1580, Loss function: 5.024, Average Loss: 4.457, avg. samples / sec: 54447.49
Iteration:   1580, Loss function: 4.828, Average Loss: 4.454, avg. samples / sec: 54451.00
Iteration:   1580, Loss function: 3.655, Average Loss: 4.458, avg. samples / sec: 54386.32
Iteration:   1580, Loss function: 4.927, Average Loss: 4.423, avg. samples / sec: 54626.10
Iteration:   1580, Loss function: 4.820, Average Loss: 4.407, avg. samples / sec: 54626.82
Iteration:   1580, Loss function: 5.077, Average Loss: 4.456, avg. samples / sec: 54476.39
Iteration:   1580, Loss function: 4.073, Average Loss: 4.439, avg. samples / sec: 54443.49
Iteration:   1580, Loss function: 3.324, Average Loss: 4.459, avg. samples / sec: 54516.95
Iteration:   1580, Loss function: 3.227, Average Loss: 4.461, avg. samples / sec: 54414.19
Iteration:   1580, Loss function: 4.075, Average Loss: 4.473, avg. samples / sec: 54525.73
Iteration:   1580, Loss function: 5.557, Average Loss: 4.470, avg. samples / sec: 54628.87
Iteration:   1580, Loss function: 3.910, Average Loss: 4.440, avg. samples / sec: 54487.40
Iteration:   1580, Loss function: 5.430, Average Loss: 4.435, avg. samples / sec: 54499.18
Iteration:   1580, Loss function: 2.850, Average Loss: 4.457, avg. samples / sec: 54318.78
Iteration:   1580, Loss function: 4.540, Average Loss: 4.467, avg. samples / sec: 54448.98
Iteration:   1580, Loss function: 4.823, Average Loss: 4.423, avg. samples / sec: 54489.51
Iteration:   1580, Loss function: 2.729, Average Loss: 4.466, avg. samples / sec: 54509.00
Iteration:   1580, Loss function: 4.056, Average Loss: 4.443, avg. samples / sec: 54471.54
Iteration:   1580, Loss function: 5.201, Average Loss: 4.457, avg. samples / sec: 54428.63
Iteration:   1600, Loss function: 4.964, Average Loss: 4.433, avg. samples / sec: 54430.01
Iteration:   1600, Loss function: 4.378, Average Loss: 4.453, avg. samples / sec: 54533.87
Iteration:   1600, Loss function: 3.527, Average Loss: 4.426, avg. samples / sec: 54510.42
Iteration:   1600, Loss function: 4.074, Average Loss: 4.462, avg. samples / sec: 54525.07
Iteration:   1600, Loss function: 5.795, Average Loss: 4.470, avg. samples / sec: 54505.84
Iteration:   1600, Loss function: 3.239, Average Loss: 4.437, avg. samples / sec: 54516.05
Iteration:   1600, Loss function: 4.440, Average Loss: 4.455, avg. samples / sec: 54500.89
Iteration:   1600, Loss function: 4.072, Average Loss: 4.464, avg. samples / sec: 54517.65
Iteration:   1600, Loss function: 3.698, Average Loss: 4.450, avg. samples / sec: 54516.91
Iteration:   1600, Loss function: 4.429, Average Loss: 4.454, avg. samples / sec: 54471.75
Iteration:   1600, Loss function: 4.846, Average Loss: 4.438, avg. samples / sec: 54466.34
Iteration:   1600, Loss function: 5.814, Average Loss: 4.461, avg. samples / sec: 54464.13
Iteration:   1600, Loss function: 4.027, Average Loss: 4.462, avg. samples / sec: 54502.43
Iteration:   1600, Loss function: 3.703, Average Loss: 4.457, avg. samples / sec: 54461.14
Iteration:   1600, Loss function: 4.569, Average Loss: 4.443, avg. samples / sec: 54488.46
Iteration:   1600, Loss function: 3.866, Average Loss: 4.464, avg. samples / sec: 54507.70
Iteration:   1600, Loss function: 4.494, Average Loss: 4.462, avg. samples / sec: 54467.16
Iteration:   1600, Loss function: 3.980, Average Loss: 4.469, avg. samples / sec: 54525.33
Iteration:   1600, Loss function: 4.127, Average Loss: 4.420, avg. samples / sec: 54527.06
Iteration:   1600, Loss function: 4.571, Average Loss: 4.446, avg. samples / sec: 54554.24
Iteration:   1600, Loss function: 3.877, Average Loss: 4.471, avg. samples / sec: 54479.95
Iteration:   1600, Loss function: 4.369, Average Loss: 4.442, avg. samples / sec: 54483.84
Iteration:   1600, Loss function: 4.811, Average Loss: 4.437, avg. samples / sec: 54481.69
Iteration:   1600, Loss function: 3.361, Average Loss: 4.432, avg. samples / sec: 54316.42
Iteration:   1600, Loss function: 5.077, Average Loss: 4.408, avg. samples / sec: 54335.05
Iteration:   1600, Loss function: 5.718, Average Loss: 4.457, avg. samples / sec: 54410.05
Iteration:   1600, Loss function: 4.335, Average Loss: 4.465, avg. samples / sec: 54440.65
Iteration:   1600, Loss function: 4.521, Average Loss: 4.461, avg. samples / sec: 54444.84
Iteration:   1600, Loss function: 4.577, Average Loss: 4.457, avg. samples / sec: 54498.84
Iteration:   1600, Loss function: 4.567, Average Loss: 4.463, avg. samples / sec: 54456.66
:::MLL 1558640901.122 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558640901.122 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 4.277, Average Loss: 4.456, avg. samples / sec: 53890.03
Iteration:   1620, Loss function: 4.320, Average Loss: 4.431, avg. samples / sec: 53785.71
Iteration:   1620, Loss function: 3.856, Average Loss: 4.454, avg. samples / sec: 53946.14
Iteration:   1620, Loss function: 5.294, Average Loss: 4.424, avg. samples / sec: 53835.76
Iteration:   1620, Loss function: 3.883, Average Loss: 4.464, avg. samples / sec: 53845.82
Iteration:   1620, Loss function: 4.537, Average Loss: 4.435, avg. samples / sec: 53870.87
Iteration:   1620, Loss function: 4.613, Average Loss: 4.463, avg. samples / sec: 53876.00
Iteration:   1620, Loss function: 3.686, Average Loss: 4.444, avg. samples / sec: 53870.62
Iteration:   1620, Loss function: 5.991, Average Loss: 4.457, avg. samples / sec: 53843.78
Iteration:   1620, Loss function: 3.771, Average Loss: 4.461, avg. samples / sec: 53895.57
Iteration:   1620, Loss function: 4.553, Average Loss: 4.457, avg. samples / sec: 53845.96
Iteration:   1620, Loss function: 3.464, Average Loss: 4.437, avg. samples / sec: 53862.08
Iteration:   1620, Loss function: 5.001, Average Loss: 4.457, avg. samples / sec: 53779.00
Iteration:   1620, Loss function: 4.439, Average Loss: 4.457, avg. samples / sec: 53833.81
Iteration:   1620, Loss function: 4.567, Average Loss: 4.439, avg. samples / sec: 53869.67
Iteration:   1620, Loss function: 5.614, Average Loss: 4.459, avg. samples / sec: 53841.03
Iteration:   1620, Loss function: 4.076, Average Loss: 4.463, avg. samples / sec: 53825.25
Iteration:   1620, Loss function: 4.804, Average Loss: 4.464, avg. samples / sec: 53833.50
Iteration:   1620, Loss function: 4.605, Average Loss: 4.471, avg. samples / sec: 53864.55
Iteration:   1620, Loss function: 3.762, Average Loss: 4.443, avg. samples / sec: 53851.91
Iteration:   1620, Loss function: 3.764, Average Loss: 4.442, avg. samples / sec: 53835.25
Iteration:   1620, Loss function: 4.491, Average Loss: 4.413, avg. samples / sec: 53853.95
Iteration:   1620, Loss function: 4.459, Average Loss: 4.460, avg. samples / sec: 53880.28
Iteration:   1620, Loss function: 4.703, Average Loss: 4.455, avg. samples / sec: 53864.90
Iteration:   1620, Loss function: 4.033, Average Loss: 4.459, avg. samples / sec: 53876.00
Iteration:   1620, Loss function: 3.908, Average Loss: 4.431, avg. samples / sec: 53825.40
Iteration:   1620, Loss function: 3.991, Average Loss: 4.436, avg. samples / sec: 53833.58
Iteration:   1620, Loss function: 5.149, Average Loss: 4.418, avg. samples / sec: 53772.94
Iteration:   1620, Loss function: 3.849, Average Loss: 4.456, avg. samples / sec: 53847.73
Iteration:   1620, Loss function: 4.478, Average Loss: 4.462, avg. samples / sec: 53831.07
Iteration:   1640, Loss function: 4.867, Average Loss: 4.432, avg. samples / sec: 54485.76
Iteration:   1640, Loss function: 3.074, Average Loss: 4.457, avg. samples / sec: 54358.17
Iteration:   1640, Loss function: 3.905, Average Loss: 4.435, avg. samples / sec: 54440.13
Iteration:   1640, Loss function: 4.034, Average Loss: 4.441, avg. samples / sec: 54393.40
Iteration:   1640, Loss function: 4.205, Average Loss: 4.454, avg. samples / sec: 54402.87
Iteration:   1640, Loss function: 5.484, Average Loss: 4.464, avg. samples / sec: 54359.16
Iteration:   1640, Loss function: 6.371, Average Loss: 4.452, avg. samples / sec: 54340.82
Iteration:   1640, Loss function: 3.414, Average Loss: 4.459, avg. samples / sec: 54447.49
Iteration:   1640, Loss function: 3.361, Average Loss: 4.455, avg. samples / sec: 54393.96
Iteration:   1640, Loss function: 3.376, Average Loss: 4.458, avg. samples / sec: 54383.34
Iteration:   1640, Loss function: 4.859, Average Loss: 4.462, avg. samples / sec: 54321.02
Iteration:   1640, Loss function: 4.347, Average Loss: 4.437, avg. samples / sec: 54316.56
Iteration:   1640, Loss function: 4.246, Average Loss: 4.455, avg. samples / sec: 54410.49
Iteration:   1640, Loss function: 4.965, Average Loss: 4.466, avg. samples / sec: 54417.63
Iteration:   1640, Loss function: 3.920, Average Loss: 4.461, avg. samples / sec: 54403.25
Iteration:   1640, Loss function: 4.363, Average Loss: 4.451, avg. samples / sec: 54436.03
Iteration:   1640, Loss function: 4.113, Average Loss: 4.440, avg. samples / sec: 54322.59
Iteration:   1640, Loss function: 3.620, Average Loss: 4.465, avg. samples / sec: 54375.87
Iteration:   1640, Loss function: 3.929, Average Loss: 4.460, avg. samples / sec: 54383.07
Iteration:   1640, Loss function: 4.934, Average Loss: 4.437, avg. samples / sec: 54403.50
Iteration:   1640, Loss function: 6.215, Average Loss: 4.418, avg. samples / sec: 54381.87
Iteration:   1640, Loss function: 4.219, Average Loss: 4.428, avg. samples / sec: 54403.27
Iteration:   1640, Loss function: 4.641, Average Loss: 4.443, avg. samples / sec: 54371.36
Iteration:   1640, Loss function: 4.401, Average Loss: 4.460, avg. samples / sec: 54387.04
Iteration:   1640, Loss function: 3.730, Average Loss: 4.450, avg. samples / sec: 54404.42
Iteration:   1640, Loss function: 4.593, Average Loss: 4.460, avg. samples / sec: 54108.17
Iteration:   1640, Loss function: 3.861, Average Loss: 4.422, avg. samples / sec: 54057.13
Iteration:   1640, Loss function: 5.208, Average Loss: 4.445, avg. samples / sec: 54338.72
Iteration:   1640, Loss function: 4.762, Average Loss: 4.420, avg. samples / sec: 54364.82
Iteration:   1640, Loss function: 4.472, Average Loss: 4.458, avg. samples / sec: 54395.14
Iteration:   1660, Loss function: 4.394, Average Loss: 4.465, avg. samples / sec: 53979.71
Iteration:   1660, Loss function: 3.872, Average Loss: 4.432, avg. samples / sec: 53559.61
Iteration:   1660, Loss function: 3.338, Average Loss: 4.422, avg. samples / sec: 53946.53
Iteration:   1660, Loss function: 5.082, Average Loss: 4.465, avg. samples / sec: 53585.64
Iteration:   1660, Loss function: 3.695, Average Loss: 4.456, avg. samples / sec: 53586.49
Iteration:   1660, Loss function: 3.429, Average Loss: 4.451, avg. samples / sec: 53564.39
Iteration:   1660, Loss function: 6.896, Average Loss: 4.458, avg. samples / sec: 53456.75
Iteration:   1660, Loss function: 3.754, Average Loss: 4.441, avg. samples / sec: 53542.50
Iteration:   1660, Loss function: 4.434, Average Loss: 4.437, avg. samples / sec: 53598.64
Iteration:   1660, Loss function: 3.921, Average Loss: 4.465, avg. samples / sec: 53585.11
Iteration:   1660, Loss function: 5.580, Average Loss: 4.460, avg. samples / sec: 53552.28
Iteration:   1660, Loss function: 5.409, Average Loss: 4.438, avg. samples / sec: 53771.45
Iteration:   1660, Loss function: 5.065, Average Loss: 4.460, avg. samples / sec: 53562.32
Iteration:   1660, Loss function: 4.180, Average Loss: 4.438, avg. samples / sec: 53472.63
Iteration:   1660, Loss function: 5.344, Average Loss: 4.449, avg. samples / sec: 53506.03
Iteration:   1660, Loss function: 5.472, Average Loss: 4.459, avg. samples / sec: 53776.80
Iteration:   1660, Loss function: 3.211, Average Loss: 4.423, avg. samples / sec: 53610.30
Iteration:   1660, Loss function: 3.221, Average Loss: 4.455, avg. samples / sec: 53533.65
Iteration:   1660, Loss function: 4.270, Average Loss: 4.461, avg. samples / sec: 53546.54
Iteration:   1660, Loss function: 4.882, Average Loss: 4.444, avg. samples / sec: 53629.36
Iteration:   1660, Loss function: 4.590, Average Loss: 4.451, avg. samples / sec: 53549.94
Iteration:   1660, Loss function: 5.296, Average Loss: 4.466, avg. samples / sec: 53528.52
Iteration:   1660, Loss function: 3.488, Average Loss: 4.444, avg. samples / sec: 53592.01
Iteration:   1660, Loss function: 5.762, Average Loss: 4.456, avg. samples / sec: 53585.72
Iteration:   1660, Loss function: 5.004, Average Loss: 4.466, avg. samples / sec: 53566.86
Iteration:   1660, Loss function: 4.129, Average Loss: 4.414, avg. samples / sec: 53566.27
Iteration:   1660, Loss function: 4.967, Average Loss: 4.443, avg. samples / sec: 53583.86
Iteration:   1660, Loss function: 3.363, Average Loss: 4.437, avg. samples / sec: 53551.12
Iteration:   1660, Loss function: 4.249, Average Loss: 4.425, avg. samples / sec: 53610.99
Iteration:   1660, Loss function: 4.734, Average Loss: 4.456, avg. samples / sec: 53592.60
:::MLL 1558640903.301 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558640903.302 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 4.897, Average Loss: 4.435, avg. samples / sec: 53818.86
Iteration:   1680, Loss function: 4.158, Average Loss: 4.466, avg. samples / sec: 53968.63
Iteration:   1680, Loss function: 3.761, Average Loss: 4.467, avg. samples / sec: 53754.69
Iteration:   1680, Loss function: 3.830, Average Loss: 4.460, avg. samples / sec: 54013.95
Iteration:   1680, Loss function: 4.640, Average Loss: 4.462, avg. samples / sec: 53934.64
Iteration:   1680, Loss function: 4.184, Average Loss: 4.461, avg. samples / sec: 53973.26
Iteration:   1680, Loss function: 4.195, Average Loss: 4.421, avg. samples / sec: 53839.89
Iteration:   1680, Loss function: 4.335, Average Loss: 4.448, avg. samples / sec: 53932.20
Iteration:   1680, Loss function: 4.873, Average Loss: 4.437, avg. samples / sec: 53848.04
Iteration:   1680, Loss function: 3.745, Average Loss: 4.452, avg. samples / sec: 53826.51
Iteration:   1680, Loss function: 3.650, Average Loss: 4.465, avg. samples / sec: 53794.29
Iteration:   1680, Loss function: 4.535, Average Loss: 4.436, avg. samples / sec: 53875.98
Iteration:   1680, Loss function: 3.521, Average Loss: 4.444, avg. samples / sec: 53793.39
Iteration:   1680, Loss function: 4.656, Average Loss: 4.462, avg. samples / sec: 53802.75
Iteration:   1680, Loss function: 4.613, Average Loss: 4.455, avg. samples / sec: 54002.42
Iteration:   1680, Loss function: 4.248, Average Loss: 4.456, avg. samples / sec: 53737.96
Iteration:   1680, Loss function: 4.862, Average Loss: 4.454, avg. samples / sec: 53953.30
Iteration:   1680, Loss function: 5.546, Average Loss: 4.433, avg. samples / sec: 53969.11
Iteration:   1680, Loss function: 3.929, Average Loss: 4.441, avg. samples / sec: 53953.18
Iteration:   1680, Loss function: 4.388, Average Loss: 4.446, avg. samples / sec: 53910.62
Iteration:   1680, Loss function: 5.201, Average Loss: 4.411, avg. samples / sec: 53917.51
Iteration:   1680, Loss function: 5.124, Average Loss: 4.456, avg. samples / sec: 53877.75
Iteration:   1680, Loss function: 3.930, Average Loss: 4.437, avg. samples / sec: 53665.54
Iteration:   1680, Loss function: 3.801, Average Loss: 4.420, avg. samples / sec: 53866.63
Iteration:   1680, Loss function: 4.164, Average Loss: 4.447, avg. samples / sec: 53829.43
Iteration:   1680, Loss function: 2.533, Average Loss: 4.453, avg. samples / sec: 53841.89
Iteration:   1680, Loss function: 3.963, Average Loss: 4.461, avg. samples / sec: 53807.70
Iteration:   1680, Loss function: 4.863, Average Loss: 4.422, avg. samples / sec: 53783.86
Iteration:   1680, Loss function: 3.804, Average Loss: 4.467, avg. samples / sec: 53821.49
Iteration:   1680, Loss function: 4.922, Average Loss: 4.458, avg. samples / sec: 53819.42
Iteration:   1700, Loss function: 4.558, Average Loss: 4.467, avg. samples / sec: 54241.03
Iteration:   1700, Loss function: 4.509, Average Loss: 4.416, avg. samples / sec: 54232.12
Iteration:   1700, Loss function: 4.253, Average Loss: 4.429, avg. samples / sec: 54191.39
Iteration:   1700, Loss function: 3.837, Average Loss: 4.458, avg. samples / sec: 54144.36
Iteration:   1700, Loss function: 4.040, Average Loss: 4.450, avg. samples / sec: 54249.47
Iteration:   1700, Loss function: 3.956, Average Loss: 4.450, avg. samples / sec: 54207.30
Iteration:   1700, Loss function: 3.738, Average Loss: 4.455, avg. samples / sec: 54285.76
Iteration:   1700, Loss function: 3.721, Average Loss: 4.456, avg. samples / sec: 54093.23
Iteration:   1700, Loss function: 4.413, Average Loss: 4.461, avg. samples / sec: 54090.26
Iteration:   1700, Loss function: 4.065, Average Loss: 4.462, avg. samples / sec: 54074.35
Iteration:   1700, Loss function: 4.593, Average Loss: 4.461, avg. samples / sec: 54226.15
Iteration:   1700, Loss function: 4.732, Average Loss: 4.438, avg. samples / sec: 54162.36
Iteration:   1700, Loss function: 4.412, Average Loss: 4.433, avg. samples / sec: 54172.52
Iteration:   1700, Loss function: 5.285, Average Loss: 4.464, avg. samples / sec: 54164.23
Iteration:   1700, Loss function: 3.702, Average Loss: 4.453, avg. samples / sec: 54317.53
Iteration:   1700, Loss function: 3.791, Average Loss: 4.421, avg. samples / sec: 54345.11
Iteration:   1700, Loss function: 4.020, Average Loss: 4.437, avg. samples / sec: 54267.72
Iteration:   1700, Loss function: 4.226, Average Loss: 4.453, avg. samples / sec: 54124.71
Iteration:   1700, Loss function: 3.585, Average Loss: 4.442, avg. samples / sec: 54247.84
Iteration:   1700, Loss function: 4.411, Average Loss: 4.450, avg. samples / sec: 54057.67
Iteration:   1700, Loss function: 3.415, Average Loss: 4.407, avg. samples / sec: 54152.22
Iteration:   1700, Loss function: 3.965, Average Loss: 4.438, avg. samples / sec: 54015.59
Iteration:   1700, Loss function: 5.099, Average Loss: 4.441, avg. samples / sec: 54123.79
Iteration:   1700, Loss function: 4.733, Average Loss: 4.431, avg. samples / sec: 54092.20
Iteration:   1700, Loss function: 5.205, Average Loss: 4.450, avg. samples / sec: 54202.40
Iteration:   1700, Loss function: 3.681, Average Loss: 4.417, avg. samples / sec: 54195.50
Iteration:   1700, Loss function: 3.764, Average Loss: 4.461, avg. samples / sec: 54217.33
Iteration:   1700, Loss function: 4.991, Average Loss: 4.446, avg. samples / sec: 54094.50
Iteration:   1700, Loss function: 5.468, Average Loss: 4.467, avg. samples / sec: 54196.46
Iteration:   1700, Loss function: 4.740, Average Loss: 4.463, avg. samples / sec: 54225.92
Iteration:   1720, Loss function: 3.663, Average Loss: 4.414, avg. samples / sec: 53953.10
Iteration:   1720, Loss function: 4.909, Average Loss: 4.468, avg. samples / sec: 53918.89
Iteration:   1720, Loss function: 4.072, Average Loss: 4.444, avg. samples / sec: 54275.90
Iteration:   1720, Loss function: 5.090, Average Loss: 4.452, avg. samples / sec: 53860.82
Iteration:   1720, Loss function: 3.796, Average Loss: 4.430, avg. samples / sec: 53770.87
Iteration:   1720, Loss function: 3.871, Average Loss: 4.434, avg. samples / sec: 53944.65
Iteration:   1720, Loss function: 3.554, Average Loss: 4.461, avg. samples / sec: 53896.15
Iteration:   1720, Loss function: 4.677, Average Loss: 4.431, avg. samples / sec: 54125.37
Iteration:   1720, Loss function: 4.313, Average Loss: 4.456, avg. samples / sec: 53875.46
Iteration:   1720, Loss function: 4.246, Average Loss: 4.445, avg. samples / sec: 53819.29
Iteration:   1720, Loss function: 4.162, Average Loss: 4.439, avg. samples / sec: 53898.93
Iteration:   1720, Loss function: 3.969, Average Loss: 4.452, avg. samples / sec: 53812.18
Iteration:   1720, Loss function: 5.550, Average Loss: 4.451, avg. samples / sec: 53844.23
Iteration:   1720, Loss function: 5.144, Average Loss: 4.460, avg. samples / sec: 53867.49
Iteration:   1720, Loss function: 3.389, Average Loss: 4.450, avg. samples / sec: 53838.62
Iteration:   1720, Loss function: 3.388, Average Loss: 4.464, avg. samples / sec: 53876.98
Iteration:   1720, Loss function: 3.524, Average Loss: 4.452, avg. samples / sec: 53976.36
Iteration:   1720, Loss function: 4.921, Average Loss: 4.452, avg. samples / sec: 53790.86
Iteration:   1720, Loss function: 3.364, Average Loss: 4.456, avg. samples / sec: 53929.13
Iteration:   1720, Loss function: 4.323, Average Loss: 4.455, avg. samples / sec: 53868.69
Iteration:   1720, Loss function: 4.042, Average Loss: 4.442, avg. samples / sec: 53799.81
Iteration:   1720, Loss function: 5.016, Average Loss: 4.450, avg. samples / sec: 53875.69
Iteration:   1720, Loss function: 3.578, Average Loss: 4.437, avg. samples / sec: 53873.79
Iteration:   1720, Loss function: 3.653, Average Loss: 4.420, avg. samples / sec: 53769.62
Iteration:   1720, Loss function: 4.614, Average Loss: 4.445, avg. samples / sec: 53835.18
Iteration:   1720, Loss function: 3.781, Average Loss: 4.415, avg. samples / sec: 53877.07
Iteration:   1720, Loss function: 4.539, Average Loss: 4.443, avg. samples / sec: 53860.70
Iteration:   1720, Loss function: 4.432, Average Loss: 4.414, avg. samples / sec: 53846.89
Iteration:   1720, Loss function: 4.927, Average Loss: 4.465, avg. samples / sec: 53895.51
Iteration:   1720, Loss function: 4.695, Average Loss: 4.463, avg. samples / sec: 53763.84
Iteration:   1740, Loss function: 5.117, Average Loss: 4.427, avg. samples / sec: 55111.96
Iteration:   1740, Loss function: 4.854, Average Loss: 4.452, avg. samples / sec: 55227.36
Iteration:   1740, Loss function: 3.349, Average Loss: 4.462, avg. samples / sec: 54882.12
Iteration:   1740, Loss function: 3.667, Average Loss: 4.443, avg. samples / sec: 54875.75
Iteration:   1740, Loss function: 4.526, Average Loss: 4.416, avg. samples / sec: 54787.50
Iteration:   1740, Loss function: 4.150, Average Loss: 4.448, avg. samples / sec: 54928.24
Iteration:   1740, Loss function: 5.043, Average Loss: 4.462, avg. samples / sec: 54940.53
Iteration:   1740, Loss function: 3.807, Average Loss: 4.439, avg. samples / sec: 54959.86
Iteration:   1740, Loss function: 4.535, Average Loss: 4.441, avg. samples / sec: 54929.61
Iteration:   1740, Loss function: 4.695, Average Loss: 4.454, avg. samples / sec: 54919.63
Iteration:   1740, Loss function: 4.251, Average Loss: 4.454, avg. samples / sec: 54924.96
Iteration:   1740, Loss function: 3.882, Average Loss: 4.457, avg. samples / sec: 54946.98
Iteration:   1740, Loss function: 5.834, Average Loss: 4.446, avg. samples / sec: 54952.76
Iteration:   1740, Loss function: 4.123, Average Loss: 4.450, avg. samples / sec: 54942.99
Iteration:   1740, Loss function: 4.992, Average Loss: 4.464, avg. samples / sec: 54956.51
Iteration:   1740, Loss function: 5.316, Average Loss: 4.437, avg. samples / sec: 54879.62
Iteration:   1740, Loss function: 2.503, Average Loss: 4.458, avg. samples / sec: 55056.86
Iteration:   1740, Loss function: 4.927, Average Loss: 4.454, avg. samples / sec: 54913.09
Iteration:   1740, Loss function: 4.614, Average Loss: 4.449, avg. samples / sec: 54877.89
Iteration:   1740, Loss function: 3.545, Average Loss: 4.421, avg. samples / sec: 54947.88
Iteration:   1740, Loss function: 3.845, Average Loss: 4.442, avg. samples / sec: 54936.10
Iteration:   1740, Loss function: 5.380, Average Loss: 4.454, avg. samples / sec: 54911.44
Iteration:   1740, Loss function: 4.627, Average Loss: 4.435, avg. samples / sec: 54900.89
Iteration:   1740, Loss function: 3.483, Average Loss: 4.458, avg. samples / sec: 54925.26
Iteration:   1740, Loss function: 4.009, Average Loss: 4.443, avg. samples / sec: 54915.76
Iteration:   1740, Loss function: 4.937, Average Loss: 4.434, avg. samples / sec: 54649.38
Iteration:   1740, Loss function: 3.793, Average Loss: 4.411, avg. samples / sec: 54913.75
Iteration:   1740, Loss function: 5.881, Average Loss: 4.418, avg. samples / sec: 54898.05
Iteration:   1740, Loss function: 3.832, Average Loss: 4.464, avg. samples / sec: 55028.70
Iteration:   1740, Loss function: 4.263, Average Loss: 4.441, avg. samples / sec: 54449.55
:::MLL 1558640905.469 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558640905.470 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 4.118, Average Loss: 4.463, avg. samples / sec: 53995.74
Iteration:   1760, Loss function: 4.645, Average Loss: 4.445, avg. samples / sec: 53955.64
Iteration:   1760, Loss function: 4.794, Average Loss: 4.414, avg. samples / sec: 54009.83
Iteration:   1760, Loss function: 4.864, Average Loss: 4.429, avg. samples / sec: 53873.67
Iteration:   1760, Loss function: 5.882, Average Loss: 4.438, avg. samples / sec: 53960.12
Iteration:   1760, Loss function: 4.338, Average Loss: 4.459, avg. samples / sec: 53954.21
Iteration:   1760, Loss function: 4.929, Average Loss: 4.450, avg. samples / sec: 53946.88
Iteration:   1760, Loss function: 5.339, Average Loss: 4.439, avg. samples / sec: 53942.44
Iteration:   1760, Loss function: 5.138, Average Loss: 4.442, avg. samples / sec: 53967.14
Iteration:   1760, Loss function: 4.754, Average Loss: 4.458, avg. samples / sec: 53964.75
Iteration:   1760, Loss function: 5.338, Average Loss: 4.456, avg. samples / sec: 53970.95
Iteration:   1760, Loss function: 4.812, Average Loss: 4.453, avg. samples / sec: 53969.21
Iteration:   1760, Loss function: 3.026, Average Loss: 4.443, avg. samples / sec: 53948.57
Iteration:   1760, Loss function: 3.563, Average Loss: 4.457, avg. samples / sec: 53934.49
Iteration:   1760, Loss function: 3.971, Average Loss: 4.450, avg. samples / sec: 53935.46
Iteration:   1760, Loss function: 3.674, Average Loss: 4.432, avg. samples / sec: 53920.34
Iteration:   1760, Loss function: 4.164, Average Loss: 4.439, avg. samples / sec: 54454.68
Iteration:   1760, Loss function: 5.059, Average Loss: 4.448, avg. samples / sec: 53974.01
Iteration:   1760, Loss function: 4.774, Average Loss: 4.444, avg. samples / sec: 54021.99
Iteration:   1760, Loss function: 4.775, Average Loss: 4.457, avg. samples / sec: 53825.46
Iteration:   1760, Loss function: 4.229, Average Loss: 4.449, avg. samples / sec: 53961.54
Iteration:   1760, Loss function: 4.061, Average Loss: 4.438, avg. samples / sec: 53948.06
Iteration:   1760, Loss function: 4.656, Average Loss: 4.453, avg. samples / sec: 53921.86
Iteration:   1760, Loss function: 4.314, Average Loss: 4.416, avg. samples / sec: 53980.04
Iteration:   1760, Loss function: 4.553, Average Loss: 4.419, avg. samples / sec: 53905.46
Iteration:   1760, Loss function: 3.472, Average Loss: 4.453, avg. samples / sec: 53955.18
Iteration:   1760, Loss function: 4.804, Average Loss: 4.438, avg. samples / sec: 53942.21
Iteration:   1760, Loss function: 3.524, Average Loss: 4.434, avg. samples / sec: 53949.38
Iteration:   1760, Loss function: 5.743, Average Loss: 4.461, avg. samples / sec: 53977.54
Iteration:   1760, Loss function: 3.921, Average Loss: 4.413, avg. samples / sec: 53815.08
Iteration:   1780, Loss function: 4.001, Average Loss: 4.460, avg. samples / sec: 54435.84
Iteration:   1780, Loss function: 4.673, Average Loss: 4.438, avg. samples / sec: 54421.59
Iteration:   1780, Loss function: 4.920, Average Loss: 4.432, avg. samples / sec: 54356.77
Iteration:   1780, Loss function: 3.700, Average Loss: 4.456, avg. samples / sec: 54450.94
Iteration:   1780, Loss function: 3.730, Average Loss: 4.446, avg. samples / sec: 54511.79
Iteration:   1780, Loss function: 3.638, Average Loss: 4.425, avg. samples / sec: 54530.43
Iteration:   1780, Loss function: 4.508, Average Loss: 4.454, avg. samples / sec: 54469.73
Iteration:   1780, Loss function: 3.284, Average Loss: 4.436, avg. samples / sec: 54445.70
Iteration:   1780, Loss function: 5.379, Average Loss: 4.451, avg. samples / sec: 54480.96
Iteration:   1780, Loss function: 4.931, Average Loss: 4.457, avg. samples / sec: 54432.98
Iteration:   1780, Loss function: 4.552, Average Loss: 4.451, avg. samples / sec: 54439.37
Iteration:   1780, Loss function: 3.618, Average Loss: 4.432, avg. samples / sec: 54414.78
Iteration:   1780, Loss function: 3.736, Average Loss: 4.444, avg. samples / sec: 54396.46
Iteration:   1780, Loss function: 4.714, Average Loss: 4.436, avg. samples / sec: 54301.37
Iteration:   1780, Loss function: 3.549, Average Loss: 4.456, avg. samples / sec: 54607.39
Iteration:   1780, Loss function: 3.784, Average Loss: 4.422, avg. samples / sec: 54516.07
Iteration:   1780, Loss function: 3.913, Average Loss: 4.451, avg. samples / sec: 54489.66
Iteration:   1780, Loss function: 4.427, Average Loss: 4.444, avg. samples / sec: 54464.26
Iteration:   1780, Loss function: 4.289, Average Loss: 4.446, avg. samples / sec: 54422.85
Iteration:   1780, Loss function: 5.177, Average Loss: 4.437, avg. samples / sec: 54414.76
Iteration:   1780, Loss function: 4.177, Average Loss: 4.435, avg. samples / sec: 54477.42
Iteration:   1780, Loss function: 3.633, Average Loss: 4.441, avg. samples / sec: 54398.10
Iteration:   1780, Loss function: 4.199, Average Loss: 4.439, avg. samples / sec: 54434.32
Iteration:   1780, Loss function: 4.236, Average Loss: 4.432, avg. samples / sec: 54461.40
Iteration:   1780, Loss function: 5.166, Average Loss: 4.412, avg. samples / sec: 54050.41
Iteration:   1780, Loss function: 4.423, Average Loss: 4.450, avg. samples / sec: 54440.25
Iteration:   1780, Loss function: 3.709, Average Loss: 4.407, avg. samples / sec: 54422.30
Iteration:   1780, Loss function: 4.379, Average Loss: 4.443, avg. samples / sec: 54186.66
Iteration:   1780, Loss function: 4.975, Average Loss: 4.415, avg. samples / sec: 54560.77
Iteration:   1780, Loss function: 4.360, Average Loss: 4.459, avg. samples / sec: 54404.17
Iteration:   1800, Loss function: 4.287, Average Loss: 4.432, avg. samples / sec: 54706.42
Iteration:   1800, Loss function: 4.787, Average Loss: 4.432, avg. samples / sec: 54848.80
Iteration:   1800, Loss function: 3.627, Average Loss: 4.458, avg. samples / sec: 54577.80
Iteration:   1800, Loss function: 3.890, Average Loss: 4.441, avg. samples / sec: 54690.86
Iteration:   1800, Loss function: 4.568, Average Loss: 4.459, avg. samples / sec: 54625.61
Iteration:   1800, Loss function: 4.472, Average Loss: 4.431, avg. samples / sec: 54621.72
Iteration:   1800, Loss function: 4.488, Average Loss: 4.412, avg. samples / sec: 54918.74
Iteration:   1800, Loss function: 4.613, Average Loss: 4.444, avg. samples / sec: 54618.62
Iteration:   1800, Loss function: 4.159, Average Loss: 4.425, avg. samples / sec: 54608.17
Iteration:   1800, Loss function: 5.117, Average Loss: 4.457, avg. samples / sec: 54647.83
Iteration:   1800, Loss function: 3.688, Average Loss: 4.422, avg. samples / sec: 54821.38
Iteration:   1800, Loss function: 4.687, Average Loss: 4.444, avg. samples / sec: 54638.32
Iteration:   1800, Loss function: 5.300, Average Loss: 4.431, avg. samples / sec: 54642.17
Iteration:   1800, Loss function: 3.517, Average Loss: 4.436, avg. samples / sec: 54903.01
Iteration:   1800, Loss function: 4.026, Average Loss: 4.430, avg. samples / sec: 54599.96
Iteration:   1800, Loss function: 3.867, Average Loss: 4.451, avg. samples / sec: 54587.55
Iteration:   1800, Loss function: 3.807, Average Loss: 4.450, avg. samples / sec: 54593.36
Iteration:   1800, Loss function: 4.172, Average Loss: 4.443, avg. samples / sec: 54672.23
Iteration:   1800, Loss function: 4.459, Average Loss: 4.458, avg. samples / sec: 54486.35
Iteration:   1800, Loss function: 3.816, Average Loss: 4.454, avg. samples / sec: 54637.11
Iteration:   1800, Loss function: 5.054, Average Loss: 4.434, avg. samples / sec: 54638.93
Iteration:   1800, Loss function: 3.362, Average Loss: 4.438, avg. samples / sec: 54628.79
Iteration:   1800, Loss function: 4.311, Average Loss: 4.434, avg. samples / sec: 54652.45
Iteration:   1800, Loss function: 4.748, Average Loss: 4.443, avg. samples / sec: 54646.03
Iteration:   1800, Loss function: 5.185, Average Loss: 4.456, avg. samples / sec: 54670.09
Iteration:   1800, Loss function: 4.411, Average Loss: 4.408, avg. samples / sec: 54685.39
Iteration:   1800, Loss function: 3.449, Average Loss: 4.432, avg. samples / sec: 54630.48
Iteration:   1800, Loss function: 3.844, Average Loss: 4.468, avg. samples / sec: 54703.58
Iteration:   1800, Loss function: 4.843, Average Loss: 4.434, avg. samples / sec: 54603.83
Iteration:   1800, Loss function: 3.659, Average Loss: 4.405, avg. samples / sec: 54633.70
:::MLL 1558640907.631 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558640907.632 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 4.133, Average Loss: 4.428, avg. samples / sec: 54225.04
Iteration:   1820, Loss function: 4.414, Average Loss: 4.439, avg. samples / sec: 54357.79
Iteration:   1820, Loss function: 3.436, Average Loss: 4.452, avg. samples / sec: 54340.38
Iteration:   1820, Loss function: 4.339, Average Loss: 4.456, avg. samples / sec: 54247.13
Iteration:   1820, Loss function: 4.118, Average Loss: 4.430, avg. samples / sec: 54344.82
Iteration:   1820, Loss function: 3.368, Average Loss: 4.409, avg. samples / sec: 54328.62
Iteration:   1820, Loss function: 4.239, Average Loss: 4.429, avg. samples / sec: 54150.18
Iteration:   1820, Loss function: 3.854, Average Loss: 4.448, avg. samples / sec: 54343.54
Iteration:   1820, Loss function: 5.616, Average Loss: 4.427, avg. samples / sec: 54281.81
Iteration:   1820, Loss function: 4.888, Average Loss: 4.436, avg. samples / sec: 54282.59
Iteration:   1820, Loss function: 5.361, Average Loss: 4.432, avg. samples / sec: 54257.45
Iteration:   1820, Loss function: 3.966, Average Loss: 4.452, avg. samples / sec: 54245.29
Iteration:   1820, Loss function: 4.219, Average Loss: 4.427, avg. samples / sec: 54186.06
Iteration:   1820, Loss function: 3.314, Average Loss: 4.454, avg. samples / sec: 54182.37
Iteration:   1820, Loss function: 4.472, Average Loss: 4.444, avg. samples / sec: 54182.83
Iteration:   1820, Loss function: 4.468, Average Loss: 4.441, avg. samples / sec: 54131.26
Iteration:   1820, Loss function: 5.568, Average Loss: 4.441, avg. samples / sec: 54341.49
Iteration:   1820, Loss function: 5.076, Average Loss: 4.457, avg. samples / sec: 54299.82
Iteration:   1820, Loss function: 3.915, Average Loss: 4.447, avg. samples / sec: 54297.81
Iteration:   1820, Loss function: 5.579, Average Loss: 4.437, avg. samples / sec: 54297.94
Iteration:   1820, Loss function: 4.311, Average Loss: 4.443, avg. samples / sec: 54290.43
Iteration:   1820, Loss function: 4.852, Average Loss: 4.414, avg. samples / sec: 54257.57
Iteration:   1820, Loss function: 4.361, Average Loss: 4.453, avg. samples / sec: 54219.43
Iteration:   1820, Loss function: 5.038, Average Loss: 4.432, avg. samples / sec: 54221.25
Iteration:   1820, Loss function: 4.329, Average Loss: 4.443, avg. samples / sec: 54177.91
Iteration:   1820, Loss function: 4.446, Average Loss: 4.428, avg. samples / sec: 54251.66
Iteration:   1820, Loss function: 4.372, Average Loss: 4.403, avg. samples / sec: 54235.48
Iteration:   1820, Loss function: 4.930, Average Loss: 4.421, avg. samples / sec: 53962.54
Iteration:   1820, Loss function: 5.148, Average Loss: 4.435, avg. samples / sec: 54197.75
Iteration:   1820, Loss function: 4.142, Average Loss: 4.468, avg. samples / sec: 54178.16
Iteration:   1840, Loss function: 4.488, Average Loss: 4.430, avg. samples / sec: 54499.50
Iteration:   1840, Loss function: 4.010, Average Loss: 4.434, avg. samples / sec: 54450.27
Iteration:   1840, Loss function: 4.124, Average Loss: 4.427, avg. samples / sec: 54493.53
Iteration:   1840, Loss function: 5.420, Average Loss: 4.450, avg. samples / sec: 54494.17
Iteration:   1840, Loss function: 4.346, Average Loss: 4.428, avg. samples / sec: 54507.57
Iteration:   1840, Loss function: 4.268, Average Loss: 4.426, avg. samples / sec: 54562.76
Iteration:   1840, Loss function: 4.720, Average Loss: 4.453, avg. samples / sec: 54554.62
Iteration:   1840, Loss function: 5.044, Average Loss: 4.439, avg. samples / sec: 54589.11
Iteration:   1840, Loss function: 4.540, Average Loss: 4.459, avg. samples / sec: 54620.32
Iteration:   1840, Loss function: 4.876, Average Loss: 4.431, avg. samples / sec: 54354.67
Iteration:   1840, Loss function: 3.495, Average Loss: 4.458, avg. samples / sec: 54341.91
Iteration:   1840, Loss function: 4.421, Average Loss: 4.441, avg. samples / sec: 54713.43
Iteration:   1840, Loss function: 3.822, Average Loss: 4.451, avg. samples / sec: 54449.93
Iteration:   1840, Loss function: 3.090, Average Loss: 4.443, avg. samples / sec: 54483.00
Iteration:   1840, Loss function: 4.538, Average Loss: 4.430, avg. samples / sec: 54354.15
Iteration:   1840, Loss function: 4.602, Average Loss: 4.440, avg. samples / sec: 54454.47
Iteration:   1840, Loss function: 5.602, Average Loss: 4.453, avg. samples / sec: 54543.33
Iteration:   1840, Loss function: 3.712, Average Loss: 4.422, avg. samples / sec: 54609.71
Iteration:   1840, Loss function: 4.414, Average Loss: 4.453, avg. samples / sec: 54153.53
Iteration:   1840, Loss function: 4.017, Average Loss: 4.415, avg. samples / sec: 54167.48
Iteration:   1840, Loss function: 4.203, Average Loss: 4.439, avg. samples / sec: 54459.63
Iteration:   1840, Loss function: 5.099, Average Loss: 4.430, avg. samples / sec: 54451.23
Iteration:   1840, Loss function: 4.610, Average Loss: 4.426, avg. samples / sec: 54512.71
Iteration:   1840, Loss function: 4.769, Average Loss: 4.435, avg. samples / sec: 54572.52
Iteration:   1840, Loss function: 3.847, Average Loss: 4.412, avg. samples / sec: 54474.64
Iteration:   1840, Loss function: 3.879, Average Loss: 4.467, avg. samples / sec: 54544.07
Iteration:   1840, Loss function: 4.779, Average Loss: 4.433, avg. samples / sec: 54408.98
Iteration:   1840, Loss function: 4.849, Average Loss: 4.445, avg. samples / sec: 54264.72
Iteration:   1840, Loss function: 5.874, Average Loss: 4.436, avg. samples / sec: 54030.83
Iteration:   1840, Loss function: 5.536, Average Loss: 4.402, avg. samples / sec: 54250.18
Iteration:   1860, Loss function: 4.052, Average Loss: 4.430, avg. samples / sec: 54606.65
Iteration:   1860, Loss function: 4.892, Average Loss: 4.459, avg. samples / sec: 54770.27
Iteration:   1860, Loss function: 4.733, Average Loss: 4.424, avg. samples / sec: 54591.52
Iteration:   1860, Loss function: 3.366, Average Loss: 4.414, avg. samples / sec: 54874.11
Iteration:   1860, Loss function: 3.889, Average Loss: 4.426, avg. samples / sec: 54584.40
Iteration:   1860, Loss function: 4.086, Average Loss: 4.432, avg. samples / sec: 54604.55
Iteration:   1860, Loss function: 3.421, Average Loss: 4.429, avg. samples / sec: 54731.41
Iteration:   1860, Loss function: 4.885, Average Loss: 4.432, avg. samples / sec: 54595.20
Iteration:   1860, Loss function: 3.976, Average Loss: 4.429, avg. samples / sec: 54473.04
Iteration:   1860, Loss function: 4.554, Average Loss: 4.422, avg. samples / sec: 54558.64
Iteration:   1860, Loss function: 5.668, Average Loss: 4.428, avg. samples / sec: 55009.61
Iteration:   1860, Loss function: 3.694, Average Loss: 4.434, avg. samples / sec: 54638.40
Iteration:   1860, Loss function: 4.506, Average Loss: 4.446, avg. samples / sec: 54473.29
Iteration:   1860, Loss function: 3.981, Average Loss: 4.446, avg. samples / sec: 54599.07
Iteration:   1860, Loss function: 4.896, Average Loss: 4.454, avg. samples / sec: 54524.50
Iteration:   1860, Loss function: 4.484, Average Loss: 4.454, avg. samples / sec: 54716.98
Iteration:   1860, Loss function: 5.096, Average Loss: 4.434, avg. samples / sec: 54816.80
Iteration:   1860, Loss function: 6.016, Average Loss: 4.450, avg. samples / sec: 54567.57
Iteration:   1860, Loss function: 4.726, Average Loss: 4.453, avg. samples / sec: 54400.75
Iteration:   1860, Loss function: 5.255, Average Loss: 4.438, avg. samples / sec: 54528.39
Iteration:   1860, Loss function: 2.980, Average Loss: 4.438, avg. samples / sec: 54764.08
Iteration:   1860, Loss function: 5.137, Average Loss: 4.410, avg. samples / sec: 54595.62
Iteration:   1860, Loss function: 4.311, Average Loss: 4.436, avg. samples / sec: 54364.92
Iteration:   1860, Loss function: 3.940, Average Loss: 4.419, avg. samples / sec: 54520.10
Iteration:   1860, Loss function: 3.514, Average Loss: 4.423, avg. samples / sec: 54558.40
Iteration:   1860, Loss function: 3.988, Average Loss: 4.438, avg. samples / sec: 54549.70
Iteration:   1860, Loss function: 2.926, Average Loss: 4.433, avg. samples / sec: 54554.07
Iteration:   1860, Loss function: 4.453, Average Loss: 4.425, avg. samples / sec: 54547.19
Iteration:   1860, Loss function: 3.004, Average Loss: 4.402, avg. samples / sec: 54829.81
Iteration:   1860, Loss function: 4.391, Average Loss: 4.463, avg. samples / sec: 54559.67
Iteration:   1880, Loss function: 4.448, Average Loss: 4.412, avg. samples / sec: 54451.84
Iteration:   1880, Loss function: 4.973, Average Loss: 4.424, avg. samples / sec: 54357.69
Iteration:   1880, Loss function: 4.060, Average Loss: 4.451, avg. samples / sec: 54265.87
Iteration:   1880, Loss function: 4.737, Average Loss: 4.428, avg. samples / sec: 54378.16
Iteration:   1880, Loss function: 3.737, Average Loss: 4.449, avg. samples / sec: 54418.37
Iteration:   1880, Loss function: 5.399, Average Loss: 4.430, avg. samples / sec: 54363.83
Iteration:   1880, Loss function: 3.635, Average Loss: 4.441, avg. samples / sec: 54403.01
Iteration:   1880, Loss function: 3.819, Average Loss: 4.426, avg. samples / sec: 54354.67
Iteration:   1880, Loss function: 5.853, Average Loss: 4.413, avg. samples / sec: 54587.40
Iteration:   1880, Loss function: 4.549, Average Loss: 4.426, avg. samples / sec: 54295.93
Iteration:   1880, Loss function: 4.465, Average Loss: 4.439, avg. samples / sec: 54379.75
Iteration:   1880, Loss function: 4.086, Average Loss: 4.437, avg. samples / sec: 54361.46
Iteration:   1880, Loss function: 5.873, Average Loss: 4.445, avg. samples / sec: 54401.19
Iteration:   1880, Loss function: 3.727, Average Loss: 4.417, avg. samples / sec: 54314.99
Iteration:   1880, Loss function: 4.820, Average Loss: 4.424, avg. samples / sec: 54314.76
Iteration:   1880, Loss function: 3.628, Average Loss: 4.422, avg. samples / sec: 54251.37
Iteration:   1880, Loss function: 5.185, Average Loss: 4.432, avg. samples / sec: 54352.01
Iteration:   1880, Loss function: 4.608, Average Loss: 4.433, avg. samples / sec: 54375.66
Iteration:   1880, Loss function: 5.688, Average Loss: 4.431, avg. samples / sec: 54221.48
Iteration:   1880, Loss function: 3.851, Average Loss: 4.431, avg. samples / sec: 54382.80
Iteration:   1880, Loss function: 5.270, Average Loss: 4.428, avg. samples / sec: 54381.79
Iteration:   1880, Loss function: 4.274, Average Loss: 4.449, avg. samples / sec: 54308.50
Iteration:   1880, Loss function: 4.034, Average Loss: 4.445, avg. samples / sec: 54316.23
Iteration:   1880, Loss function: 4.025, Average Loss: 4.430, avg. samples / sec: 53895.96
Iteration:   1880, Loss function: 4.026, Average Loss: 4.433, avg. samples / sec: 54325.96
Iteration:   1880, Loss function: 4.104, Average Loss: 4.408, avg. samples / sec: 54336.71
Iteration:   1880, Loss function: 3.417, Average Loss: 4.417, avg. samples / sec: 54338.89
Iteration:   1880, Loss function: 3.608, Average Loss: 4.425, avg. samples / sec: 54353.41
Iteration:   1880, Loss function: 4.378, Average Loss: 4.397, avg. samples / sec: 54357.96
Iteration:   1880, Loss function: 4.840, Average Loss: 4.465, avg. samples / sec: 54372.77
:::MLL 1558640909.794 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558640909.795 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 3.635, Average Loss: 4.449, avg. samples / sec: 54242.74
Iteration:   1900, Loss function: 4.849, Average Loss: 4.419, avg. samples / sec: 54150.75
Iteration:   1900, Loss function: 3.552, Average Loss: 4.412, avg. samples / sec: 54033.38
Iteration:   1900, Loss function: 5.500, Average Loss: 4.429, avg. samples / sec: 54163.84
Iteration:   1900, Loss function: 4.386, Average Loss: 4.441, avg. samples / sec: 54150.12
Iteration:   1900, Loss function: 4.198, Average Loss: 4.414, avg. samples / sec: 54235.50
Iteration:   1900, Loss function: 4.406, Average Loss: 4.421, avg. samples / sec: 54119.43
Iteration:   1900, Loss function: 4.717, Average Loss: 4.427, avg. samples / sec: 54204.77
Iteration:   1900, Loss function: 4.292, Average Loss: 4.438, avg. samples / sec: 54159.65
Iteration:   1900, Loss function: 3.379, Average Loss: 4.420, avg. samples / sec: 54131.59
Iteration:   1900, Loss function: 4.394, Average Loss: 4.420, avg. samples / sec: 54136.95
Iteration:   1900, Loss function: 3.137, Average Loss: 4.441, avg. samples / sec: 54155.28
Iteration:   1900, Loss function: 3.899, Average Loss: 4.441, avg. samples / sec: 54112.86
Iteration:   1900, Loss function: 3.567, Average Loss: 4.435, avg. samples / sec: 54134.08
Iteration:   1900, Loss function: 4.376, Average Loss: 4.443, avg. samples / sec: 54338.20
Iteration:   1900, Loss function: 4.596, Average Loss: 4.415, avg. samples / sec: 54141.72
Iteration:   1900, Loss function: 3.911, Average Loss: 4.425, avg. samples / sec: 54283.07
Iteration:   1900, Loss function: 4.578, Average Loss: 4.424, avg. samples / sec: 54202.42
Iteration:   1900, Loss function: 4.902, Average Loss: 4.438, avg. samples / sec: 54182.39
Iteration:   1900, Loss function: 3.403, Average Loss: 4.429, avg. samples / sec: 54154.28
Iteration:   1900, Loss function: 4.483, Average Loss: 4.430, avg. samples / sec: 54172.93
Iteration:   1900, Loss function: 5.074, Average Loss: 4.429, avg. samples / sec: 54135.69
Iteration:   1900, Loss function: 3.450, Average Loss: 4.413, avg. samples / sec: 54167.42
Iteration:   1900, Loss function: 4.550, Average Loss: 4.427, avg. samples / sec: 54123.83
Iteration:   1900, Loss function: 3.346, Average Loss: 4.413, avg. samples / sec: 53907.55
Iteration:   1900, Loss function: 3.428, Average Loss: 4.421, avg. samples / sec: 54149.35
Iteration:   1900, Loss function: 3.848, Average Loss: 4.428, avg. samples / sec: 54132.40
Iteration:   1900, Loss function: 3.800, Average Loss: 4.395, avg. samples / sec: 54142.05
Iteration:   1900, Loss function: 3.528, Average Loss: 4.410, avg. samples / sec: 54123.23
Iteration:   1900, Loss function: 4.848, Average Loss: 4.460, avg. samples / sec: 54109.64
Iteration:   1920, Loss function: 4.802, Average Loss: 4.447, avg. samples / sec: 54390.37
Iteration:   1920, Loss function: 3.362, Average Loss: 4.416, avg. samples / sec: 54490.50
Iteration:   1920, Loss function: 4.186, Average Loss: 4.411, avg. samples / sec: 54503.38
Iteration:   1920, Loss function: 3.757, Average Loss: 4.415, avg. samples / sec: 54453.72
Iteration:   1920, Loss function: 3.386, Average Loss: 4.436, avg. samples / sec: 54455.08
Iteration:   1920, Loss function: 4.987, Average Loss: 4.431, avg. samples / sec: 54461.42
Iteration:   1920, Loss function: 4.233, Average Loss: 4.438, avg. samples / sec: 54436.72
Iteration:   1920, Loss function: 4.882, Average Loss: 4.415, avg. samples / sec: 54429.24
Iteration:   1920, Loss function: 5.340, Average Loss: 4.407, avg. samples / sec: 54400.77
Iteration:   1920, Loss function: 3.212, Average Loss: 4.427, avg. samples / sec: 54403.67
Iteration:   1920, Loss function: 5.646, Average Loss: 4.425, avg. samples / sec: 54368.22
Iteration:   1920, Loss function: 4.995, Average Loss: 4.435, avg. samples / sec: 54337.46
Iteration:   1920, Loss function: 6.046, Average Loss: 4.411, avg. samples / sec: 54301.58
Iteration:   1920, Loss function: 3.921, Average Loss: 4.417, avg. samples / sec: 54228.95
Iteration:   1920, Loss function: 5.416, Average Loss: 4.442, avg. samples / sec: 54317.57
Iteration:   1920, Loss function: 2.655, Average Loss: 4.420, avg. samples / sec: 54441.98
Iteration:   1920, Loss function: 3.947, Average Loss: 4.422, avg. samples / sec: 54384.50
Iteration:   1920, Loss function: 4.116, Average Loss: 4.421, avg. samples / sec: 54301.66
Iteration:   1920, Loss function: 4.085, Average Loss: 4.436, avg. samples / sec: 54410.81
Iteration:   1920, Loss function: 4.358, Average Loss: 4.422, avg. samples / sec: 54457.50
Iteration:   1920, Loss function: 4.372, Average Loss: 4.411, avg. samples / sec: 54428.33
Iteration:   1920, Loss function: 4.788, Average Loss: 4.424, avg. samples / sec: 54428.56
Iteration:   1920, Loss function: 5.005, Average Loss: 4.427, avg. samples / sec: 54385.69
Iteration:   1920, Loss function: 2.762, Average Loss: 4.411, avg. samples / sec: 54421.50
Iteration:   1920, Loss function: 4.033, Average Loss: 4.407, avg. samples / sec: 54433.92
Iteration:   1920, Loss function: 4.364, Average Loss: 4.420, avg. samples / sec: 54401.44
Iteration:   1920, Loss function: 4.003, Average Loss: 4.398, avg. samples / sec: 54418.77
Iteration:   1920, Loss function: 5.768, Average Loss: 4.430, avg. samples / sec: 54362.57
Iteration:   1920, Loss function: 4.098, Average Loss: 4.427, avg. samples / sec: 54120.09
Iteration:   1920, Loss function: 3.579, Average Loss: 4.454, avg. samples / sec: 54422.32
Iteration:   1940, Loss function: 4.297, Average Loss: 4.425, avg. samples / sec: 54704.77
Iteration:   1940, Loss function: 4.135, Average Loss: 4.444, avg. samples / sec: 54503.94
Iteration:   1940, Loss function: 4.067, Average Loss: 4.413, avg. samples / sec: 54702.81
Iteration:   1940, Loss function: 3.470, Average Loss: 4.430, avg. samples / sec: 54613.35
Iteration:   1940, Loss function: 4.763, Average Loss: 4.406, avg. samples / sec: 54557.01
Iteration:   1940, Loss function: 3.883, Average Loss: 4.416, avg. samples / sec: 54502.81
Iteration:   1940, Loss function: 4.404, Average Loss: 4.428, avg. samples / sec: 54556.65
Iteration:   1940, Loss function: 4.136, Average Loss: 4.430, avg. samples / sec: 54522.40
Iteration:   1940, Loss function: 4.651, Average Loss: 4.412, avg. samples / sec: 54471.99
Iteration:   1940, Loss function: 5.511, Average Loss: 4.424, avg. samples / sec: 54554.10
Iteration:   1940, Loss function: 3.423, Average Loss: 4.434, avg. samples / sec: 54534.17
Iteration:   1940, Loss function: 4.314, Average Loss: 4.408, avg. samples / sec: 54517.92
Iteration:   1940, Loss function: 4.884, Average Loss: 4.412, avg. samples / sec: 54570.26
Iteration:   1940, Loss function: 3.968, Average Loss: 4.409, avg. samples / sec: 54465.16
Iteration:   1940, Loss function: 5.033, Average Loss: 4.425, avg. samples / sec: 54782.34
Iteration:   1940, Loss function: 3.809, Average Loss: 4.415, avg. samples / sec: 54573.07
Iteration:   1940, Loss function: 3.581, Average Loss: 4.405, avg. samples / sec: 54582.87
Iteration:   1940, Loss function: 5.428, Average Loss: 4.420, avg. samples / sec: 54526.38
Iteration:   1940, Loss function: 3.740, Average Loss: 4.435, avg. samples / sec: 54473.19
Iteration:   1940, Loss function: 4.286, Average Loss: 4.411, avg. samples / sec: 54580.65
Iteration:   1940, Loss function: 4.547, Average Loss: 4.429, avg. samples / sec: 54522.46
Iteration:   1940, Loss function: 4.620, Average Loss: 4.432, avg. samples / sec: 54598.33
Iteration:   1940, Loss function: 4.244, Average Loss: 4.424, avg. samples / sec: 54501.75
Iteration:   1940, Loss function: 4.415, Average Loss: 4.416, avg. samples / sec: 54567.89
Iteration:   1940, Loss function: 3.900, Average Loss: 4.423, avg. samples / sec: 54561.32
Iteration:   1940, Loss function: 5.352, Average Loss: 4.403, avg. samples / sec: 54558.30
Iteration:   1940, Loss function: 4.519, Average Loss: 4.396, avg. samples / sec: 54577.97
Iteration:   1940, Loss function: 3.965, Average Loss: 4.414, avg. samples / sec: 54503.63
Iteration:   1940, Loss function: 3.821, Average Loss: 4.418, avg. samples / sec: 54508.37
Iteration:   1940, Loss function: 4.921, Average Loss: 4.455, avg. samples / sec: 54542.72
:::MLL 1558640911.960 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558640911.960 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 5.351, Average Loss: 4.442, avg. samples / sec: 53940.17
Iteration:   1960, Loss function: 3.993, Average Loss: 4.415, avg. samples / sec: 53927.83
Iteration:   1960, Loss function: 4.165, Average Loss: 4.424, avg. samples / sec: 54002.47
Iteration:   1960, Loss function: 3.982, Average Loss: 4.420, avg. samples / sec: 54010.97
Iteration:   1960, Loss function: 3.929, Average Loss: 4.421, avg. samples / sec: 53773.99
Iteration:   1960, Loss function: 4.322, Average Loss: 4.409, avg. samples / sec: 53938.15
Iteration:   1960, Loss function: 4.348, Average Loss: 4.409, avg. samples / sec: 53941.61
Iteration:   1960, Loss function: 4.970, Average Loss: 4.401, avg. samples / sec: 53894.66
Iteration:   1960, Loss function: 4.955, Average Loss: 4.406, avg. samples / sec: 53919.80
Iteration:   1960, Loss function: 4.975, Average Loss: 4.429, avg. samples / sec: 53868.19
Iteration:   1960, Loss function: 3.616, Average Loss: 4.417, avg. samples / sec: 53864.61
Iteration:   1960, Loss function: 3.782, Average Loss: 4.404, avg. samples / sec: 54043.57
Iteration:   1960, Loss function: 4.537, Average Loss: 4.407, avg. samples / sec: 53857.26
Iteration:   1960, Loss function: 3.121, Average Loss: 4.422, avg. samples / sec: 53823.49
Iteration:   1960, Loss function: 3.515, Average Loss: 4.409, avg. samples / sec: 53868.66
Iteration:   1960, Loss function: 4.774, Average Loss: 4.432, avg. samples / sec: 53838.64
Iteration:   1960, Loss function: 4.359, Average Loss: 4.437, avg. samples / sec: 54020.58
Iteration:   1960, Loss function: 5.055, Average Loss: 4.424, avg. samples / sec: 53968.72
Iteration:   1960, Loss function: 5.383, Average Loss: 4.411, avg. samples / sec: 54042.29
Iteration:   1960, Loss function: 3.950, Average Loss: 4.408, avg. samples / sec: 53962.45
Iteration:   1960, Loss function: 5.071, Average Loss: 4.419, avg. samples / sec: 53936.99
Iteration:   1960, Loss function: 3.191, Average Loss: 4.411, avg. samples / sec: 53896.74
Iteration:   1960, Loss function: 3.113, Average Loss: 4.398, avg. samples / sec: 53901.71
Iteration:   1960, Loss function: 5.384, Average Loss: 4.413, avg. samples / sec: 53816.64
Iteration:   1960, Loss function: 4.275, Average Loss: 4.426, avg. samples / sec: 53858.31
Iteration:   1960, Loss function: 3.722, Average Loss: 4.452, avg. samples / sec: 53903.82
Iteration:   1960, Loss function: 4.852, Average Loss: 4.412, avg. samples / sec: 53803.55
Iteration:   1960, Loss function: 4.597, Average Loss: 4.393, avg. samples / sec: 53831.87
Iteration:   1960, Loss function: 4.159, Average Loss: 4.418, avg. samples / sec: 53821.24
Iteration:   1960, Loss function: 4.481, Average Loss: 4.427, avg. samples / sec: 53753.60
Iteration:   1980, Loss function: 3.906, Average Loss: 4.417, avg. samples / sec: 54705.02
Iteration:   1980, Loss function: 3.438, Average Loss: 4.438, avg. samples / sec: 54551.20
Iteration:   1980, Loss function: 4.176, Average Loss: 4.408, avg. samples / sec: 54688.42
Iteration:   1980, Loss function: 3.968, Average Loss: 4.412, avg. samples / sec: 54560.43
Iteration:   1980, Loss function: 5.292, Average Loss: 4.404, avg. samples / sec: 54590.89
Iteration:   1980, Loss function: 3.984, Average Loss: 4.399, avg. samples / sec: 54642.45
Iteration:   1980, Loss function: 5.589, Average Loss: 4.401, avg. samples / sec: 54597.49
Iteration:   1980, Loss function: 3.907, Average Loss: 4.407, avg. samples / sec: 54633.34
Iteration:   1980, Loss function: 4.626, Average Loss: 4.416, avg. samples / sec: 54623.07
Iteration:   1980, Loss function: 3.736, Average Loss: 4.429, avg. samples / sec: 54632.37
Iteration:   1980, Loss function: 4.347, Average Loss: 4.418, avg. samples / sec: 54449.45
Iteration:   1980, Loss function: 4.639, Average Loss: 4.422, avg. samples / sec: 54594.46
Iteration:   1980, Loss function: 2.746, Average Loss: 4.397, avg. samples / sec: 54553.34
Iteration:   1980, Loss function: 3.680, Average Loss: 4.411, avg. samples / sec: 54574.97
Iteration:   1980, Loss function: 3.436, Average Loss: 4.402, avg. samples / sec: 54727.28
Iteration:   1980, Loss function: 3.443, Average Loss: 4.415, avg. samples / sec: 54469.42
Iteration:   1980, Loss function: 4.718, Average Loss: 4.436, avg. samples / sec: 54586.45
Iteration:   1980, Loss function: 3.543, Average Loss: 4.414, avg. samples / sec: 54626.92
Iteration:   1980, Loss function: 4.997, Average Loss: 4.426, avg. samples / sec: 54649.91
Iteration:   1980, Loss function: 4.466, Average Loss: 4.406, avg. samples / sec: 54632.35
Iteration:   1980, Loss function: 3.862, Average Loss: 4.421, avg. samples / sec: 54508.92
Iteration:   1980, Loss function: 3.412, Average Loss: 4.411, avg. samples / sec: 54686.02
Iteration:   1980, Loss function: 3.942, Average Loss: 4.409, avg. samples / sec: 54675.92
Iteration:   1980, Loss function: 4.872, Average Loss: 4.405, avg. samples / sec: 54475.14
Iteration:   1980, Loss function: 4.111, Average Loss: 4.396, avg. samples / sec: 54572.22
Iteration:   1980, Loss function: 3.900, Average Loss: 4.390, avg. samples / sec: 54636.71
Iteration:   1980, Loss function: 4.361, Average Loss: 4.406, avg. samples / sec: 54558.70
Iteration:   1980, Loss function: 2.999, Average Loss: 4.419, avg. samples / sec: 54691.96
Iteration:   1980, Loss function: 4.847, Average Loss: 4.400, avg. samples / sec: 54355.22
Iteration:   1980, Loss function: 3.228, Average Loss: 4.447, avg. samples / sec: 54611.60
Iteration:   2000, Loss function: 4.030, Average Loss: 4.412, avg. samples / sec: 54531.36
Iteration:   2000, Loss function: 4.669, Average Loss: 4.406, avg. samples / sec: 54566.50
Iteration:   2000, Loss function: 4.706, Average Loss: 4.436, avg. samples / sec: 54557.31
Iteration:   2000, Loss function: 4.423, Average Loss: 4.407, avg. samples / sec: 54574.19
Iteration:   2000, Loss function: 4.537, Average Loss: 4.421, avg. samples / sec: 54588.92
Iteration:   2000, Loss function: 4.665, Average Loss: 4.415, avg. samples / sec: 54570.89
Iteration:   2000, Loss function: 4.647, Average Loss: 4.409, avg. samples / sec: 54559.55
Iteration:   2000, Loss function: 5.062, Average Loss: 4.391, avg. samples / sec: 54532.42
Iteration:   2000, Loss function: 4.335, Average Loss: 4.427, avg. samples / sec: 54567.36
Iteration:   2000, Loss function: 3.887, Average Loss: 4.404, avg. samples / sec: 54494.31
Iteration:   2000, Loss function: 4.056, Average Loss: 4.404, avg. samples / sec: 54588.14
Iteration:   2000, Loss function: 5.199, Average Loss: 4.411, avg. samples / sec: 54586.28
Iteration:   2000, Loss function: 4.208, Average Loss: 4.390, avg. samples / sec: 54510.96
Iteration:   2000, Loss function: 2.765, Average Loss: 4.409, avg. samples / sec: 54506.45
Iteration:   2000, Loss function: 4.392, Average Loss: 4.394, avg. samples / sec: 54440.17
Iteration:   2000, Loss function: 4.003, Average Loss: 4.402, avg. samples / sec: 54595.75
Iteration:   2000, Loss function: 5.085, Average Loss: 4.413, avg. samples / sec: 54613.46
Iteration:   2000, Loss function: 3.401, Average Loss: 4.386, avg. samples / sec: 54585.90
Iteration:   2000, Loss function: 3.456, Average Loss: 4.406, avg. samples / sec: 54480.41
Iteration:   2000, Loss function: 5.057, Average Loss: 4.431, avg. samples / sec: 54419.44
Iteration:   2000, Loss function: 4.518, Average Loss: 4.413, avg. samples / sec: 54538.68
Iteration:   2000, Loss function: 3.260, Average Loss: 4.422, avg. samples / sec: 54531.95
Iteration:   2000, Loss function: 5.403, Average Loss: 4.404, avg. samples / sec: 54571.38
Iteration:   2000, Loss function: 3.848, Average Loss: 4.406, avg. samples / sec: 54529.04
Iteration:   2000, Loss function: 4.103, Average Loss: 4.395, avg. samples / sec: 54576.53
Iteration:   2000, Loss function: 5.081, Average Loss: 4.409, avg. samples / sec: 54520.79
Iteration:   2000, Loss function: 3.565, Average Loss: 4.388, avg. samples / sec: 54554.75
Iteration:   2000, Loss function: 4.139, Average Loss: 4.398, avg. samples / sec: 54560.22
Iteration:   2000, Loss function: 3.616, Average Loss: 4.394, avg. samples / sec: 54335.10
Iteration:   2000, Loss function: 4.455, Average Loss: 4.441, avg. samples / sec: 54541.87
Iteration:   2020, Loss function: 3.908, Average Loss: 4.411, avg. samples / sec: 54530.24
Iteration:   2020, Loss function: 4.264, Average Loss: 4.400, avg. samples / sec: 54540.90
Iteration:   2020, Loss function: 5.570, Average Loss: 4.436, avg. samples / sec: 54524.44
Iteration:   2020, Loss function: 5.090, Average Loss: 4.405, avg. samples / sec: 54499.24
Iteration:   2020, Loss function: 4.708, Average Loss: 4.413, avg. samples / sec: 54668.46
Iteration:   2020, Loss function: 3.807, Average Loss: 4.402, avg. samples / sec: 54610.69
Iteration:   2020, Loss function: 4.361, Average Loss: 4.404, avg. samples / sec: 54607.41
Iteration:   2020, Loss function: 4.671, Average Loss: 4.411, avg. samples / sec: 54592.75
Iteration:   2020, Loss function: 5.367, Average Loss: 4.430, avg. samples / sec: 54571.06
Iteration:   2020, Loss function: 4.310, Average Loss: 4.393, avg. samples / sec: 54700.07
Iteration:   2020, Loss function: 3.617, Average Loss: 4.424, avg. samples / sec: 54533.37
Iteration:   2020, Loss function: 4.604, Average Loss: 4.405, avg. samples / sec: 54540.33
Iteration:   2020, Loss function: 4.284, Average Loss: 4.405, avg. samples / sec: 54555.91
Iteration:   2020, Loss function: 6.005, Average Loss: 4.395, avg. samples / sec: 54516.03
Iteration:   2020, Loss function: 2.731, Average Loss: 4.387, avg. samples / sec: 54528.07
Iteration:   2020, Loss function: 5.189, Average Loss: 4.408, avg. samples / sec: 54625.21
Iteration:   2020, Loss function: 5.343, Average Loss: 4.394, avg. samples / sec: 54641.22
Iteration:   2020, Loss function: 5.024, Average Loss: 4.409, avg. samples / sec: 54601.10
Iteration:   2020, Loss function: 3.783, Average Loss: 4.407, avg. samples / sec: 54599.86
Iteration:   2020, Loss function: 5.225, Average Loss: 4.429, avg. samples / sec: 54597.27
Iteration:   2020, Loss function: 4.529, Average Loss: 4.417, avg. samples / sec: 54593.45
Iteration:   2020, Loss function: 5.973, Average Loss: 4.399, avg. samples / sec: 54578.94
Iteration:   2020, Loss function: 4.271, Average Loss: 4.390, avg. samples / sec: 54595.20
Iteration:   2020, Loss function: 4.082, Average Loss: 4.394, avg. samples / sec: 54505.19
Iteration:   2020, Loss function: 4.469, Average Loss: 4.409, avg. samples / sec: 54544.02
Iteration:   2020, Loss function: 2.938, Average Loss: 4.396, avg. samples / sec: 54603.26
Iteration:   2020, Loss function: 3.600, Average Loss: 4.411, avg. samples / sec: 54587.12
Iteration:   2020, Loss function: 5.347, Average Loss: 4.387, avg. samples / sec: 54546.03
Iteration:   2020, Loss function: 4.326, Average Loss: 4.382, avg. samples / sec: 54586.07
Iteration:   2020, Loss function: 3.464, Average Loss: 4.443, avg. samples / sec: 54599.79
:::MLL 1558640914.118 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558640914.119 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 4.505, Average Loss: 4.434, avg. samples / sec: 54360.60
Iteration:   2040, Loss function: 5.070, Average Loss: 4.401, avg. samples / sec: 54346.10
Iteration:   2040, Loss function: 3.809, Average Loss: 4.409, avg. samples / sec: 54236.38
Iteration:   2040, Loss function: 5.190, Average Loss: 4.389, avg. samples / sec: 54200.31
Iteration:   2040, Loss function: 4.561, Average Loss: 4.394, avg. samples / sec: 54521.07
Iteration:   2040, Loss function: 4.509, Average Loss: 4.389, avg. samples / sec: 54313.30
Iteration:   2040, Loss function: 3.593, Average Loss: 4.398, avg. samples / sec: 54225.42
Iteration:   2040, Loss function: 4.263, Average Loss: 4.423, avg. samples / sec: 54243.75
Iteration:   2040, Loss function: 5.212, Average Loss: 4.398, avg. samples / sec: 54201.52
Iteration:   2040, Loss function: 4.215, Average Loss: 4.417, avg. samples / sec: 54246.42
Iteration:   2040, Loss function: 4.324, Average Loss: 4.391, avg. samples / sec: 54229.66
Iteration:   2040, Loss function: 3.094, Average Loss: 4.408, avg. samples / sec: 54192.27
Iteration:   2040, Loss function: 4.335, Average Loss: 4.399, avg. samples / sec: 54244.50
Iteration:   2040, Loss function: 4.820, Average Loss: 4.382, avg. samples / sec: 54276.80
Iteration:   2040, Loss function: 4.789, Average Loss: 4.410, avg. samples / sec: 54142.92
Iteration:   2040, Loss function: 4.203, Average Loss: 4.401, avg. samples / sec: 54200.33
Iteration:   2040, Loss function: 3.746, Average Loss: 4.392, avg. samples / sec: 54300.11
Iteration:   2040, Loss function: 4.844, Average Loss: 4.426, avg. samples / sec: 54258.85
Iteration:   2040, Loss function: 5.005, Average Loss: 4.403, avg. samples / sec: 54236.40
Iteration:   2040, Loss function: 4.316, Average Loss: 4.403, avg. samples / sec: 54280.62
Iteration:   2040, Loss function: 3.767, Average Loss: 4.403, avg. samples / sec: 54235.23
Iteration:   2040, Loss function: 4.279, Average Loss: 4.385, avg. samples / sec: 54252.81
Iteration:   2040, Loss function: 4.407, Average Loss: 4.400, avg. samples / sec: 54204.65
Iteration:   2040, Loss function: 5.200, Average Loss: 4.408, avg. samples / sec: 54207.42
Iteration:   2040, Loss function: 3.848, Average Loss: 4.389, avg. samples / sec: 54241.32
Iteration:   2040, Loss function: 3.610, Average Loss: 4.385, avg. samples / sec: 54244.02
Iteration:   2040, Loss function: 3.582, Average Loss: 4.379, avg. samples / sec: 54226.11
Iteration:   2040, Loss function: 3.298, Average Loss: 4.389, avg. samples / sec: 54171.41
Iteration:   2040, Loss function: 2.312, Average Loss: 4.404, avg. samples / sec: 54188.49
Iteration:   2040, Loss function: 5.047, Average Loss: 4.436, avg. samples / sec: 54204.38
Iteration:   2060, Loss function: 2.863, Average Loss: 4.428, avg. samples / sec: 54268.21
Iteration:   2060, Loss function: 5.207, Average Loss: 4.402, avg. samples / sec: 54349.20
Iteration:   2060, Loss function: 3.136, Average Loss: 4.386, avg. samples / sec: 54347.77
Iteration:   2060, Loss function: 4.463, Average Loss: 4.391, avg. samples / sec: 54346.73
Iteration:   2060, Loss function: 5.654, Average Loss: 4.408, avg. samples / sec: 54395.41
Iteration:   2060, Loss function: 5.255, Average Loss: 4.413, avg. samples / sec: 54345.72
Iteration:   2060, Loss function: 3.691, Average Loss: 4.392, avg. samples / sec: 54348.26
Iteration:   2060, Loss function: 2.995, Average Loss: 4.380, avg. samples / sec: 54340.63
Iteration:   2060, Loss function: 5.463, Average Loss: 4.384, avg. samples / sec: 54325.63
Iteration:   2060, Loss function: 3.829, Average Loss: 4.389, avg. samples / sec: 54276.54
Iteration:   2060, Loss function: 5.378, Average Loss: 4.418, avg. samples / sec: 54276.11
Iteration:   2060, Loss function: 4.079, Average Loss: 4.405, avg. samples / sec: 54289.36
Iteration:   2060, Loss function: 3.184, Average Loss: 4.392, avg. samples / sec: 54050.23
Iteration:   2060, Loss function: 4.356, Average Loss: 4.382, avg. samples / sec: 54276.63
Iteration:   2060, Loss function: 3.820, Average Loss: 4.399, avg. samples / sec: 54295.91
Iteration:   2060, Loss function: 4.941, Average Loss: 4.399, avg. samples / sec: 54288.13
Iteration:   2060, Loss function: 4.094, Average Loss: 4.405, avg. samples / sec: 54310.14
Iteration:   2060, Loss function: 4.584, Average Loss: 4.420, avg. samples / sec: 54248.17
Iteration:   2060, Loss function: 4.023, Average Loss: 4.381, avg. samples / sec: 54277.99
Iteration:   2060, Loss function: 4.939, Average Loss: 4.398, avg. samples / sec: 54334.66
Iteration:   2060, Loss function: 3.345, Average Loss: 4.371, avg. samples / sec: 54305.72
Iteration:   2060, Loss function: 4.740, Average Loss: 4.387, avg. samples / sec: 54261.81
Iteration:   2060, Loss function: 4.651, Average Loss: 4.386, avg. samples / sec: 53981.66
Iteration:   2060, Loss function: 4.999, Average Loss: 4.390, avg. samples / sec: 53963.69
Iteration:   2060, Loss function: 4.835, Average Loss: 4.388, avg. samples / sec: 54286.14
Iteration:   2060, Loss function: 3.731, Average Loss: 4.393, avg. samples / sec: 54247.65
Iteration:   2060, Loss function: 5.048, Average Loss: 4.383, avg. samples / sec: 54266.37
Iteration:   2060, Loss function: 3.891, Average Loss: 4.396, avg. samples / sec: 54081.55
Iteration:   2060, Loss function: 3.504, Average Loss: 4.398, avg. samples / sec: 54208.82
Iteration:   2060, Loss function: 4.224, Average Loss: 4.433, avg. samples / sec: 54293.25
Iteration:   2080, Loss function: 4.711, Average Loss: 4.432, avg. samples / sec: 54626.56
Iteration:   2080, Loss function: 4.252, Average Loss: 4.399, avg. samples / sec: 54637.41
Iteration:   2080, Loss function: 4.540, Average Loss: 4.390, avg. samples / sec: 54879.71
Iteration:   2080, Loss function: 3.566, Average Loss: 4.386, avg. samples / sec: 55014.87
Iteration:   2080, Loss function: 4.114, Average Loss: 4.385, avg. samples / sec: 54590.17
Iteration:   2080, Loss function: 4.671, Average Loss: 4.411, avg. samples / sec: 54603.79
Iteration:   2080, Loss function: 4.453, Average Loss: 4.390, avg. samples / sec: 54587.97
Iteration:   2080, Loss function: 4.158, Average Loss: 4.388, avg. samples / sec: 54614.24
Iteration:   2080, Loss function: 3.249, Average Loss: 4.383, avg. samples / sec: 54587.53
Iteration:   2080, Loss function: 4.039, Average Loss: 4.381, avg. samples / sec: 54586.85
Iteration:   2080, Loss function: 5.884, Average Loss: 4.400, avg. samples / sec: 54888.66
Iteration:   2080, Loss function: 3.518, Average Loss: 4.404, avg. samples / sec: 54625.46
Iteration:   2080, Loss function: 3.973, Average Loss: 4.404, avg. samples / sec: 54556.38
Iteration:   2080, Loss function: 4.226, Average Loss: 4.384, avg. samples / sec: 54858.26
Iteration:   2080, Loss function: 4.268, Average Loss: 4.380, avg. samples / sec: 54576.68
Iteration:   2080, Loss function: 4.637, Average Loss: 4.416, avg. samples / sec: 54597.78
Iteration:   2080, Loss function: 5.952, Average Loss: 4.403, avg. samples / sec: 54779.49
Iteration:   2080, Loss function: 4.594, Average Loss: 4.413, avg. samples / sec: 54752.57
Iteration:   2080, Loss function: 2.828, Average Loss: 4.393, avg. samples / sec: 54729.28
Iteration:   2080, Loss function: 4.424, Average Loss: 4.401, avg. samples / sec: 54661.18
Iteration:   2080, Loss function: 4.780, Average Loss: 4.395, avg. samples / sec: 54725.27
Iteration:   2080, Loss function: 3.377, Average Loss: 4.376, avg. samples / sec: 54627.14
Iteration:   2080, Loss function: 5.202, Average Loss: 4.386, avg. samples / sec: 54694.45
Iteration:   2080, Loss function: 3.882, Average Loss: 4.391, avg. samples / sec: 54653.11
Iteration:   2080, Loss function: 3.446, Average Loss: 4.382, avg. samples / sec: 54685.75
Iteration:   2080, Loss function: 3.763, Average Loss: 4.381, avg. samples / sec: 54668.88
Iteration:   2080, Loss function: 5.725, Average Loss: 4.383, avg. samples / sec: 54620.83
Iteration:   2080, Loss function: 4.076, Average Loss: 4.428, avg. samples / sec: 54686.89
Iteration:   2080, Loss function: 3.113, Average Loss: 4.397, avg. samples / sec: 54581.56
Iteration:   2080, Loss function: 4.207, Average Loss: 4.367, avg. samples / sec: 54621.44
:::MLL 1558640916.278 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558640916.278 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 4.602, Average Loss: 4.385, avg. samples / sec: 54650.78
Iteration:   2100, Loss function: 2.854, Average Loss: 4.372, avg. samples / sec: 54635.23
Iteration:   2100, Loss function: 3.262, Average Loss: 4.390, avg. samples / sec: 54446.25
Iteration:   2100, Loss function: 3.753, Average Loss: 4.429, avg. samples / sec: 54409.53
Iteration:   2100, Loss function: 3.554, Average Loss: 4.393, avg. samples / sec: 54390.35
Iteration:   2100, Loss function: 3.450, Average Loss: 4.399, avg. samples / sec: 54583.00
Iteration:   2100, Loss function: 4.465, Average Loss: 4.383, avg. samples / sec: 54439.14
Iteration:   2100, Loss function: 3.613, Average Loss: 4.382, avg. samples / sec: 54550.72
Iteration:   2100, Loss function: 4.905, Average Loss: 4.376, avg. samples / sec: 54529.48
Iteration:   2100, Loss function: 4.676, Average Loss: 4.381, avg. samples / sec: 54435.56
Iteration:   2100, Loss function: 4.187, Average Loss: 4.395, avg. samples / sec: 54498.17
Iteration:   2100, Loss function: 5.298, Average Loss: 4.404, avg. samples / sec: 54427.95
Iteration:   2100, Loss function: 3.847, Average Loss: 4.376, avg. samples / sec: 54442.48
Iteration:   2100, Loss function: 4.447, Average Loss: 4.414, avg. samples / sec: 54416.06
Iteration:   2100, Loss function: 4.042, Average Loss: 4.396, avg. samples / sec: 54400.14
Iteration:   2100, Loss function: 4.760, Average Loss: 4.380, avg. samples / sec: 54590.38
Iteration:   2100, Loss function: 5.379, Average Loss: 4.400, avg. samples / sec: 54521.05
Iteration:   2100, Loss function: 3.961, Average Loss: 4.392, avg. samples / sec: 54591.48
Iteration:   2100, Loss function: 3.219, Average Loss: 4.409, avg. samples / sec: 54441.43
Iteration:   2100, Loss function: 4.261, Average Loss: 4.375, avg. samples / sec: 54352.74
Iteration:   2100, Loss function: 4.436, Average Loss: 4.379, avg. samples / sec: 54514.63
Iteration:   2100, Loss function: 4.110, Average Loss: 4.366, avg. samples / sec: 54442.67
Iteration:   2100, Loss function: 3.584, Average Loss: 4.386, avg. samples / sec: 54415.22
Iteration:   2100, Loss function: 4.245, Average Loss: 4.405, avg. samples / sec: 54293.21
Iteration:   2100, Loss function: 4.088, Average Loss: 4.375, avg. samples / sec: 54415.66
Iteration:   2100, Loss function: 4.635, Average Loss: 4.380, avg. samples / sec: 54426.21
Iteration:   2100, Loss function: 4.366, Average Loss: 4.364, avg. samples / sec: 54441.66
Iteration:   2100, Loss function: 4.291, Average Loss: 4.396, avg. samples / sec: 54365.28
Iteration:   2100, Loss function: 4.273, Average Loss: 4.387, avg. samples / sec: 54365.20
Iteration:   2100, Loss function: 3.689, Average Loss: 4.418, avg. samples / sec: 54390.54
Iteration:   2120, Loss function: 3.905, Average Loss: 4.420, avg. samples / sec: 54626.03
Iteration:   2120, Loss function: 3.255, Average Loss: 4.385, avg. samples / sec: 54535.73
Iteration:   2120, Loss function: 3.348, Average Loss: 4.388, avg. samples / sec: 54554.56
Iteration:   2120, Loss function: 3.795, Average Loss: 4.379, avg. samples / sec: 54531.80
Iteration:   2120, Loss function: 4.271, Average Loss: 4.411, avg. samples / sec: 54669.37
Iteration:   2120, Loss function: 5.073, Average Loss: 4.375, avg. samples / sec: 54486.58
Iteration:   2120, Loss function: 3.868, Average Loss: 4.377, avg. samples / sec: 54550.70
Iteration:   2120, Loss function: 4.436, Average Loss: 4.383, avg. samples / sec: 54358.49
Iteration:   2120, Loss function: 5.354, Average Loss: 4.392, avg. samples / sec: 54534.44
Iteration:   2120, Loss function: 3.887, Average Loss: 4.374, avg. samples / sec: 54566.07
Iteration:   2120, Loss function: 4.792, Average Loss: 4.369, avg. samples / sec: 54474.24
Iteration:   2120, Loss function: 5.521, Average Loss: 4.406, avg. samples / sec: 54531.28
Iteration:   2120, Loss function: 3.246, Average Loss: 4.370, avg. samples / sec: 54380.38
Iteration:   2120, Loss function: 3.861, Average Loss: 4.396, avg. samples / sec: 54608.34
Iteration:   2120, Loss function: 3.923, Average Loss: 4.398, avg. samples / sec: 54409.71
Iteration:   2120, Loss function: 4.523, Average Loss: 4.361, avg. samples / sec: 54566.60
Iteration:   2120, Loss function: 4.643, Average Loss: 4.384, avg. samples / sec: 54451.49
Iteration:   2120, Loss function: 4.916, Average Loss: 4.410, avg. samples / sec: 54462.89
Iteration:   2120, Loss function: 3.874, Average Loss: 4.381, avg. samples / sec: 54549.87
Iteration:   2120, Loss function: 4.358, Average Loss: 4.372, avg. samples / sec: 54598.82
Iteration:   2120, Loss function: 4.364, Average Loss: 4.381, avg. samples / sec: 54416.69
Iteration:   2120, Loss function: 4.995, Average Loss: 4.400, avg. samples / sec: 54430.94
Iteration:   2120, Loss function: 5.772, Average Loss: 4.408, avg. samples / sec: 54550.82
Iteration:   2120, Loss function: 4.284, Average Loss: 4.372, avg. samples / sec: 54450.37
Iteration:   2120, Loss function: 4.654, Average Loss: 4.375, avg. samples / sec: 54447.24
Iteration:   2120, Loss function: 5.275, Average Loss: 4.385, avg. samples / sec: 54607.01
Iteration:   2120, Loss function: 5.124, Average Loss: 4.369, avg. samples / sec: 54532.27
Iteration:   2120, Loss function: 4.793, Average Loss: 4.357, avg. samples / sec: 54546.77
Iteration:   2120, Loss function: 5.311, Average Loss: 4.419, avg. samples / sec: 54567.15
Iteration:   2120, Loss function: 3.765, Average Loss: 4.391, avg. samples / sec: 54509.26
Iteration:   2140, Loss function: 4.745, Average Loss: 4.418, avg. samples / sec: 54391.70
Iteration:   2140, Loss function: 4.918, Average Loss: 4.374, avg. samples / sec: 54518.56
Iteration:   2140, Loss function: 3.217, Average Loss: 4.376, avg. samples / sec: 54454.39
Iteration:   2140, Loss function: 5.984, Average Loss: 4.377, avg. samples / sec: 54496.93
Iteration:   2140, Loss function: 4.950, Average Loss: 4.391, avg. samples / sec: 54494.19
Iteration:   2140, Loss function: 4.719, Average Loss: 4.368, avg. samples / sec: 54480.75
Iteration:   2140, Loss function: 4.183, Average Loss: 4.372, avg. samples / sec: 54476.60
Iteration:   2140, Loss function: 5.607, Average Loss: 4.413, avg. samples / sec: 54457.46
Iteration:   2140, Loss function: 4.802, Average Loss: 4.399, avg. samples / sec: 54520.26
Iteration:   2140, Loss function: 3.822, Average Loss: 4.395, avg. samples / sec: 54505.63
Iteration:   2140, Loss function: 5.212, Average Loss: 4.372, avg. samples / sec: 54497.77
Iteration:   2140, Loss function: 4.493, Average Loss: 4.406, avg. samples / sec: 54496.53
Iteration:   2140, Loss function: 5.133, Average Loss: 4.384, avg. samples / sec: 54338.74
Iteration:   2140, Loss function: 4.803, Average Loss: 4.375, avg. samples / sec: 54494.12
Iteration:   2140, Loss function: 3.949, Average Loss: 4.373, avg. samples / sec: 54465.48
Iteration:   2140, Loss function: 5.187, Average Loss: 4.374, avg. samples / sec: 54620.49
Iteration:   2140, Loss function: 3.785, Average Loss: 4.362, avg. samples / sec: 54505.38
Iteration:   2140, Loss function: 4.047, Average Loss: 4.385, avg. samples / sec: 54512.21
Iteration:   2140, Loss function: 3.372, Average Loss: 4.411, avg. samples / sec: 54501.20
Iteration:   2140, Loss function: 4.593, Average Loss: 4.399, avg. samples / sec: 54514.80
Iteration:   2140, Loss function: 4.292, Average Loss: 4.406, avg. samples / sec: 54496.76
Iteration:   2140, Loss function: 4.875, Average Loss: 4.373, avg. samples / sec: 54510.67
Iteration:   2140, Loss function: 5.315, Average Loss: 4.372, avg. samples / sec: 54469.71
Iteration:   2140, Loss function: 4.457, Average Loss: 4.374, avg. samples / sec: 54517.19
Iteration:   2140, Loss function: 3.806, Average Loss: 4.356, avg. samples / sec: 54508.16
Iteration:   2140, Loss function: 3.843, Average Loss: 4.369, avg. samples / sec: 54475.33
Iteration:   2140, Loss function: 3.930, Average Loss: 4.393, avg. samples / sec: 54545.57
Iteration:   2140, Loss function: 3.436, Average Loss: 4.382, avg. samples / sec: 54481.61
Iteration:   2140, Loss function: 4.055, Average Loss: 4.414, avg. samples / sec: 54494.44
Iteration:   2140, Loss function: 3.554, Average Loss: 4.383, avg. samples / sec: 54397.01
Iteration:   2160, Loss function: 4.212, Average Loss: 4.416, avg. samples / sec: 54644.12
Iteration:   2160, Loss function: 4.534, Average Loss: 4.377, avg. samples / sec: 54608.53
Iteration:   2160, Loss function: 4.412, Average Loss: 4.372, avg. samples / sec: 54623.77
Iteration:   2160, Loss function: 4.416, Average Loss: 4.387, avg. samples / sec: 54626.97
Iteration:   2160, Loss function: 3.762, Average Loss: 4.373, avg. samples / sec: 54643.81
Iteration:   2160, Loss function: 3.932, Average Loss: 4.373, avg. samples / sec: 54603.90
Iteration:   2160, Loss function: 3.007, Average Loss: 4.361, avg. samples / sec: 54609.90
Iteration:   2160, Loss function: 3.361, Average Loss: 4.381, avg. samples / sec: 54642.60
Iteration:   2160, Loss function: 4.089, Average Loss: 4.366, avg. samples / sec: 54609.12
Iteration:   2160, Loss function: 3.993, Average Loss: 4.370, avg. samples / sec: 54615.03
Iteration:   2160, Loss function: 3.918, Average Loss: 4.374, avg. samples / sec: 54624.79
Iteration:   2160, Loss function: 3.730, Average Loss: 4.401, avg. samples / sec: 54607.43
Iteration:   2160, Loss function: 4.398, Average Loss: 4.399, avg. samples / sec: 54601.55
Iteration:   2160, Loss function: 5.000, Average Loss: 4.412, avg. samples / sec: 54561.09
Iteration:   2160, Loss function: 4.469, Average Loss: 4.402, avg. samples / sec: 54562.95
Iteration:   2160, Loss function: 4.276, Average Loss: 4.355, avg. samples / sec: 54612.89
Iteration:   2160, Loss function: 4.898, Average Loss: 4.405, avg. samples / sec: 54623.18
Iteration:   2160, Loss function: 4.474, Average Loss: 4.402, avg. samples / sec: 54644.63
Iteration:   2160, Loss function: 5.465, Average Loss: 4.398, avg. samples / sec: 54621.42
Iteration:   2160, Loss function: 4.227, Average Loss: 4.374, avg. samples / sec: 54651.71
Iteration:   2160, Loss function: 3.635, Average Loss: 4.381, avg. samples / sec: 54579.39
Iteration:   2160, Loss function: 4.029, Average Loss: 4.365, avg. samples / sec: 54612.99
Iteration:   2160, Loss function: 2.914, Average Loss: 4.376, avg. samples / sec: 54637.73
Iteration:   2160, Loss function: 4.263, Average Loss: 4.371, avg. samples / sec: 54596.89
Iteration:   2160, Loss function: 5.374, Average Loss: 4.388, avg. samples / sec: 54623.37
Iteration:   2160, Loss function: 3.474, Average Loss: 4.374, avg. samples / sec: 54438.07
Iteration:   2160, Loss function: 2.706, Average Loss: 4.347, avg. samples / sec: 54610.54
Iteration:   2160, Loss function: 3.747, Average Loss: 4.368, avg. samples / sec: 54599.77
Iteration:   2160, Loss function: 3.694, Average Loss: 4.411, avg. samples / sec: 54626.35
Iteration:   2160, Loss function: 3.882, Average Loss: 4.379, avg. samples / sec: 54649.97
:::MLL 1558640918.438 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558640918.439 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 3.591, Average Loss: 4.408, avg. samples / sec: 54201.17
Iteration:   2180, Loss function: 5.360, Average Loss: 4.369, avg. samples / sec: 54218.10
Iteration:   2180, Loss function: 4.097, Average Loss: 4.373, avg. samples / sec: 54151.93
Iteration:   2180, Loss function: 6.274, Average Loss: 4.369, avg. samples / sec: 54226.61
Iteration:   2180, Loss function: 4.247, Average Loss: 4.394, avg. samples / sec: 54252.37
Iteration:   2180, Loss function: 3.831, Average Loss: 4.410, avg. samples / sec: 54261.60
Iteration:   2180, Loss function: 3.710, Average Loss: 4.381, avg. samples / sec: 54167.67
Iteration:   2180, Loss function: 4.701, Average Loss: 4.381, avg. samples / sec: 54182.68
Iteration:   2180, Loss function: 3.411, Average Loss: 4.361, avg. samples / sec: 54191.00
Iteration:   2180, Loss function: 4.613, Average Loss: 4.368, avg. samples / sec: 54171.52
Iteration:   2180, Loss function: 5.052, Average Loss: 4.399, avg. samples / sec: 54234.04
Iteration:   2180, Loss function: 4.129, Average Loss: 4.396, avg. samples / sec: 54202.58
Iteration:   2180, Loss function: 3.358, Average Loss: 4.372, avg. samples / sec: 54182.02
Iteration:   2180, Loss function: 3.658, Average Loss: 4.372, avg. samples / sec: 54156.22
Iteration:   2180, Loss function: 4.510, Average Loss: 4.364, avg. samples / sec: 54370.71
Iteration:   2180, Loss function: 4.914, Average Loss: 4.405, avg. samples / sec: 54379.29
Iteration:   2180, Loss function: 4.133, Average Loss: 4.353, avg. samples / sec: 54074.93
Iteration:   2180, Loss function: 3.673, Average Loss: 4.370, avg. samples / sec: 54271.07
Iteration:   2180, Loss function: 5.318, Average Loss: 4.403, avg. samples / sec: 54218.97
Iteration:   2180, Loss function: 4.358, Average Loss: 4.352, avg. samples / sec: 54179.72
Iteration:   2180, Loss function: 3.825, Average Loss: 4.389, avg. samples / sec: 54187.58
Iteration:   2180, Loss function: 4.270, Average Loss: 4.407, avg. samples / sec: 54177.85
Iteration:   2180, Loss function: 4.485, Average Loss: 4.373, avg. samples / sec: 54254.79
Iteration:   2180, Loss function: 2.996, Average Loss: 4.380, avg. samples / sec: 54184.95
Iteration:   2180, Loss function: 3.338, Average Loss: 4.367, avg. samples / sec: 54206.11
Iteration:   2180, Loss function: 4.844, Average Loss: 4.369, avg. samples / sec: 54225.13
Iteration:   2180, Loss function: 3.768, Average Loss: 4.369, avg. samples / sec: 54212.34
Iteration:   2180, Loss function: 4.988, Average Loss: 4.342, avg. samples / sec: 54207.71
Iteration:   2180, Loss function: 4.370, Average Loss: 4.371, avg. samples / sec: 54163.15
Iteration:   2180, Loss function: 4.656, Average Loss: 4.382, avg. samples / sec: 54178.58
Iteration:   2200, Loss function: 3.616, Average Loss: 4.405, avg. samples / sec: 54416.69
Iteration:   2200, Loss function: 5.593, Average Loss: 4.371, avg. samples / sec: 54382.44
Iteration:   2200, Loss function: 5.241, Average Loss: 4.392, avg. samples / sec: 54416.21
Iteration:   2200, Loss function: 5.890, Average Loss: 4.355, avg. samples / sec: 54403.58
Iteration:   2200, Loss function: 4.283, Average Loss: 4.386, avg. samples / sec: 54350.65
Iteration:   2200, Loss function: 4.964, Average Loss: 4.368, avg. samples / sec: 54332.08
Iteration:   2200, Loss function: 3.297, Average Loss: 4.348, avg. samples / sec: 54479.90
Iteration:   2200, Loss function: 4.767, Average Loss: 4.410, avg. samples / sec: 54351.02
Iteration:   2200, Loss function: 5.015, Average Loss: 4.371, avg. samples / sec: 54388.67
Iteration:   2200, Loss function: 4.071, Average Loss: 4.372, avg. samples / sec: 54377.82
Iteration:   2200, Loss function: 3.568, Average Loss: 4.378, avg. samples / sec: 54314.30
Iteration:   2200, Loss function: 4.024, Average Loss: 4.365, avg. samples / sec: 54305.24
Iteration:   2200, Loss function: 3.286, Average Loss: 4.395, avg. samples / sec: 54392.41
Iteration:   2200, Loss function: 3.860, Average Loss: 4.403, avg. samples / sec: 54390.27
Iteration:   2200, Loss function: 4.029, Average Loss: 4.383, avg. samples / sec: 54370.29
Iteration:   2200, Loss function: 5.024, Average Loss: 4.360, avg. samples / sec: 54220.31
Iteration:   2200, Loss function: 3.976, Average Loss: 4.379, avg. samples / sec: 54384.37
Iteration:   2200, Loss function: 3.582, Average Loss: 4.371, avg. samples / sec: 54387.71
Iteration:   2200, Loss function: 4.055, Average Loss: 4.367, avg. samples / sec: 54397.55
Iteration:   2200, Loss function: 4.945, Average Loss: 4.348, avg. samples / sec: 54326.76
Iteration:   2200, Loss function: 3.566, Average Loss: 4.374, avg. samples / sec: 54111.91
Iteration:   2200, Loss function: 4.412, Average Loss: 4.359, avg. samples / sec: 54341.70
Iteration:   2200, Loss function: 5.422, Average Loss: 4.402, avg. samples / sec: 54180.62
Iteration:   2200, Loss function: 4.469, Average Loss: 4.344, avg. samples / sec: 54341.93
Iteration:   2200, Loss function: 3.726, Average Loss: 4.371, avg. samples / sec: 54341.26
Iteration:   2200, Loss function: 4.463, Average Loss: 4.365, avg. samples / sec: 54224.52
Iteration:   2200, Loss function: 3.813, Average Loss: 4.376, avg. samples / sec: 54350.00
Iteration:   2200, Loss function: 4.654, Average Loss: 4.368, avg. samples / sec: 54018.57
Iteration:   2200, Loss function: 4.646, Average Loss: 4.394, avg. samples / sec: 54081.90
Iteration:   2200, Loss function: 2.891, Average Loss: 4.370, avg. samples / sec: 54287.21
Iteration:   2220, Loss function: 4.820, Average Loss: 4.401, avg. samples / sec: 54630.95
Iteration:   2220, Loss function: 4.626, Average Loss: 4.363, avg. samples / sec: 55112.50
Iteration:   2220, Loss function: 4.931, Average Loss: 4.369, avg. samples / sec: 54614.22
Iteration:   2220, Loss function: 4.030, Average Loss: 4.342, avg. samples / sec: 54707.04
Iteration:   2220, Loss function: 4.307, Average Loss: 4.350, avg. samples / sec: 54655.57
Iteration:   2220, Loss function: 4.416, Average Loss: 4.381, avg. samples / sec: 54650.18
Iteration:   2220, Loss function: 3.670, Average Loss: 4.366, avg. samples / sec: 54925.03
Iteration:   2220, Loss function: 4.154, Average Loss: 4.388, avg. samples / sec: 54963.33
Iteration:   2220, Loss function: 5.303, Average Loss: 4.371, avg. samples / sec: 54656.22
Iteration:   2220, Loss function: 5.026, Average Loss: 4.369, avg. samples / sec: 54681.27
Iteration:   2220, Loss function: 4.041, Average Loss: 4.371, avg. samples / sec: 54692.60
Iteration:   2220, Loss function: 6.096, Average Loss: 4.390, avg. samples / sec: 54602.33
Iteration:   2220, Loss function: 5.523, Average Loss: 4.361, avg. samples / sec: 54708.48
Iteration:   2220, Loss function: 4.084, Average Loss: 4.397, avg. samples / sec: 54623.56
Iteration:   2220, Loss function: 4.184, Average Loss: 4.370, avg. samples / sec: 54623.03
Iteration:   2220, Loss function: 3.524, Average Loss: 4.364, avg. samples / sec: 54773.51
Iteration:   2220, Loss function: 4.532, Average Loss: 4.397, avg. samples / sec: 54652.98
Iteration:   2220, Loss function: 4.911, Average Loss: 4.393, avg. samples / sec: 54586.34
Iteration:   2220, Loss function: 3.901, Average Loss: 4.345, avg. samples / sec: 54680.12
Iteration:   2220, Loss function: 3.437, Average Loss: 4.364, avg. samples / sec: 54712.88
Iteration:   2220, Loss function: 4.112, Average Loss: 4.378, avg. samples / sec: 54656.08
Iteration:   2220, Loss function: 4.712, Average Loss: 4.380, avg. samples / sec: 54635.88
Iteration:   2220, Loss function: 4.379, Average Loss: 4.363, avg. samples / sec: 54634.17
Iteration:   2220, Loss function: 5.218, Average Loss: 4.362, avg. samples / sec: 54627.62
Iteration:   2220, Loss function: 4.694, Average Loss: 4.340, avg. samples / sec: 54685.92
Iteration:   2220, Loss function: 2.284, Average Loss: 4.360, avg. samples / sec: 54683.67
Iteration:   2220, Loss function: 2.807, Average Loss: 4.356, avg. samples / sec: 54658.15
Iteration:   2220, Loss function: 3.425, Average Loss: 4.368, avg. samples / sec: 54659.83
Iteration:   2220, Loss function: 4.206, Average Loss: 4.397, avg. samples / sec: 54639.91
Iteration:   2220, Loss function: 4.694, Average Loss: 4.367, avg. samples / sec: 54651.82
:::MLL 1558640920.599 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558640920.600 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 2.994, Average Loss: 4.389, avg. samples / sec: 54110.31
Iteration:   2240, Loss function: 3.451, Average Loss: 4.363, avg. samples / sec: 54254.69
Iteration:   2240, Loss function: 3.874, Average Loss: 4.381, avg. samples / sec: 54206.13
Iteration:   2240, Loss function: 4.384, Average Loss: 4.369, avg. samples / sec: 54108.08
Iteration:   2240, Loss function: 5.138, Average Loss: 4.361, avg. samples / sec: 54031.47
Iteration:   2240, Loss function: 4.686, Average Loss: 4.363, avg. samples / sec: 54230.37
Iteration:   2240, Loss function: 3.687, Average Loss: 4.360, avg. samples / sec: 54154.97
Iteration:   2240, Loss function: 4.148, Average Loss: 4.365, avg. samples / sec: 54165.61
Iteration:   2240, Loss function: 3.974, Average Loss: 4.346, avg. samples / sec: 54117.39
Iteration:   2240, Loss function: 3.624, Average Loss: 4.357, avg. samples / sec: 54151.41
Iteration:   2240, Loss function: 4.937, Average Loss: 4.364, avg. samples / sec: 54126.62
Iteration:   2240, Loss function: 4.109, Average Loss: 4.334, avg. samples / sec: 54069.33
Iteration:   2240, Loss function: 4.949, Average Loss: 4.378, avg. samples / sec: 54103.60
Iteration:   2240, Loss function: 4.053, Average Loss: 4.385, avg. samples / sec: 54126.91
Iteration:   2240, Loss function: 4.309, Average Loss: 4.389, avg. samples / sec: 54127.76
Iteration:   2240, Loss function: 4.142, Average Loss: 4.386, avg. samples / sec: 54271.44
Iteration:   2240, Loss function: 2.781, Average Loss: 4.359, avg. samples / sec: 54273.33
Iteration:   2240, Loss function: 3.317, Average Loss: 4.357, avg. samples / sec: 54344.09
Iteration:   2240, Loss function: 2.949, Average Loss: 4.372, avg. samples / sec: 54243.16
Iteration:   2240, Loss function: 4.016, Average Loss: 4.349, avg. samples / sec: 54265.66
Iteration:   2240, Loss function: 3.021, Average Loss: 4.371, avg. samples / sec: 54187.08
Iteration:   2240, Loss function: 4.351, Average Loss: 4.391, avg. samples / sec: 54151.99
Iteration:   2240, Loss function: 4.077, Average Loss: 4.359, avg. samples / sec: 54168.12
Iteration:   2240, Loss function: 3.843, Average Loss: 4.338, avg. samples / sec: 54124.79
Iteration:   2240, Loss function: 4.158, Average Loss: 4.359, avg. samples / sec: 54139.41
Iteration:   2240, Loss function: 4.218, Average Loss: 4.336, avg. samples / sec: 54130.55
Iteration:   2240, Loss function: 3.965, Average Loss: 4.359, avg. samples / sec: 54149.89
Iteration:   2240, Loss function: 4.765, Average Loss: 4.360, avg. samples / sec: 54075.86
Iteration:   2240, Loss function: 4.285, Average Loss: 4.383, avg. samples / sec: 54143.36
Iteration:   2240, Loss function: 3.842, Average Loss: 4.361, avg. samples / sec: 53969.81
Iteration:   2260, Loss function: 5.835, Average Loss: 4.357, avg. samples / sec: 54772.53
Iteration:   2260, Loss function: 3.692, Average Loss: 4.362, avg. samples / sec: 54767.12
Iteration:   2260, Loss function: 4.206, Average Loss: 4.390, avg. samples / sec: 54657.69
Iteration:   2260, Loss function: 3.450, Average Loss: 4.383, avg. samples / sec: 54730.41
Iteration:   2260, Loss function: 4.300, Average Loss: 4.361, avg. samples / sec: 54688.57
Iteration:   2260, Loss function: 4.450, Average Loss: 4.341, avg. samples / sec: 54652.18
Iteration:   2260, Loss function: 4.048, Average Loss: 4.351, avg. samples / sec: 54674.57
Iteration:   2260, Loss function: 3.740, Average Loss: 4.331, avg. samples / sec: 54662.58
Iteration:   2260, Loss function: 5.381, Average Loss: 4.360, avg. samples / sec: 54629.99
Iteration:   2260, Loss function: 5.075, Average Loss: 4.361, avg. samples / sec: 54507.91
Iteration:   2260, Loss function: 4.302, Average Loss: 4.361, avg. samples / sec: 54598.29
Iteration:   2260, Loss function: 4.616, Average Loss: 4.371, avg. samples / sec: 54641.50
Iteration:   2260, Loss function: 3.915, Average Loss: 4.374, avg. samples / sec: 54546.49
Iteration:   2260, Loss function: 5.000, Average Loss: 4.393, avg. samples / sec: 54781.96
Iteration:   2260, Loss function: 4.909, Average Loss: 4.334, avg. samples / sec: 54687.85
Iteration:   2260, Loss function: 4.182, Average Loss: 4.376, avg. samples / sec: 54532.33
Iteration:   2260, Loss function: 4.010, Average Loss: 4.368, avg. samples / sec: 54569.94
Iteration:   2260, Loss function: 5.048, Average Loss: 4.359, avg. samples / sec: 54670.66
Iteration:   2260, Loss function: 3.232, Average Loss: 4.378, avg. samples / sec: 54456.24
Iteration:   2260, Loss function: 4.089, Average Loss: 4.358, avg. samples / sec: 54400.41
Iteration:   2260, Loss function: 4.252, Average Loss: 4.357, avg. samples / sec: 54702.60
Iteration:   2260, Loss function: 4.145, Average Loss: 4.358, avg. samples / sec: 54712.56
Iteration:   2260, Loss function: 4.282, Average Loss: 4.365, avg. samples / sec: 54578.37
Iteration:   2260, Loss function: 4.755, Average Loss: 4.355, avg. samples / sec: 54522.10
Iteration:   2260, Loss function: 3.556, Average Loss: 4.359, avg. samples / sec: 54514.21
Iteration:   2260, Loss function: 3.280, Average Loss: 4.355, avg. samples / sec: 54623.03
Iteration:   2260, Loss function: 4.294, Average Loss: 4.337, avg. samples / sec: 54650.16
Iteration:   2260, Loss function: 5.079, Average Loss: 4.356, avg. samples / sec: 54657.09
Iteration:   2260, Loss function: 3.592, Average Loss: 4.380, avg. samples / sec: 54645.80
Iteration:   2260, Loss function: 3.901, Average Loss: 4.347, avg. samples / sec: 54491.34
Iteration:   2280, Loss function: 5.389, Average Loss: 4.381, avg. samples / sec: 54446.42
Iteration:   2280, Loss function: 3.367, Average Loss: 4.358, avg. samples / sec: 54425.24
Iteration:   2280, Loss function: 4.512, Average Loss: 4.353, avg. samples / sec: 54407.66
Iteration:   2280, Loss function: 3.647, Average Loss: 4.328, avg. samples / sec: 54484.83
Iteration:   2280, Loss function: 4.035, Average Loss: 4.355, avg. samples / sec: 54482.92
Iteration:   2280, Loss function: 3.259, Average Loss: 4.366, avg. samples / sec: 54478.70
Iteration:   2280, Loss function: 4.123, Average Loss: 4.334, avg. samples / sec: 54440.78
Iteration:   2280, Loss function: 3.692, Average Loss: 4.370, avg. samples / sec: 54671.96
Iteration:   2280, Loss function: 3.463, Average Loss: 4.358, avg. samples / sec: 54403.12
Iteration:   2280, Loss function: 3.144, Average Loss: 4.354, avg. samples / sec: 54434.68
Iteration:   2280, Loss function: 3.962, Average Loss: 4.376, avg. samples / sec: 54354.00
Iteration:   2280, Loss function: 5.197, Average Loss: 4.352, avg. samples / sec: 54353.71
Iteration:   2280, Loss function: 3.350, Average Loss: 4.374, avg. samples / sec: 54389.64
Iteration:   2280, Loss function: 4.611, Average Loss: 4.361, avg. samples / sec: 54295.13
Iteration:   2280, Loss function: 5.469, Average Loss: 4.361, avg. samples / sec: 54517.80
Iteration:   2280, Loss function: 4.646, Average Loss: 4.364, avg. samples / sec: 54465.25
Iteration:   2280, Loss function: 5.097, Average Loss: 4.377, avg. samples / sec: 54460.93
Iteration:   2280, Loss function: 3.634, Average Loss: 4.331, avg. samples / sec: 54444.82
Iteration:   2280, Loss function: 3.811, Average Loss: 4.388, avg. samples / sec: 54294.57
Iteration:   2280, Loss function: 4.296, Average Loss: 4.359, avg. samples / sec: 54467.04
Iteration:   2280, Loss function: 4.065, Average Loss: 4.358, avg. samples / sec: 54437.88
Iteration:   2280, Loss function: 4.341, Average Loss: 4.349, avg. samples / sec: 54440.63
Iteration:   2280, Loss function: 3.864, Average Loss: 4.349, avg. samples / sec: 54433.15
Iteration:   2280, Loss function: 4.354, Average Loss: 4.352, avg. samples / sec: 54447.49
Iteration:   2280, Loss function: 3.200, Average Loss: 4.352, avg. samples / sec: 54449.89
Iteration:   2280, Loss function: 4.125, Average Loss: 4.345, avg. samples / sec: 54445.39
Iteration:   2280, Loss function: 4.153, Average Loss: 4.344, avg. samples / sec: 54473.82
Iteration:   2280, Loss function: 4.237, Average Loss: 4.333, avg. samples / sec: 54437.27
Iteration:   2280, Loss function: 3.940, Average Loss: 4.359, avg. samples / sec: 54397.13
Iteration:   2280, Loss function: 4.205, Average Loss: 4.372, avg. samples / sec: 54442.17
:::MLL 1558640922.040 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.04 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.59s)
DONE (t=2.86s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.15499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.29179
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.15250
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.15871
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.25834
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.17220
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.25048
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06880
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.27427
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.41806
Current AP: 0.15499 AP goal: 0.23000
:::MLL 1558640926.513 eval_accuracy: {"value": 0.15498977937599376, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558640926.604 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558640926.610 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558640926.610 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 3.817, Average Loss: 4.370, avg. samples / sec: 6417.15
Iteration:   2300, Loss function: 4.402, Average Loss: 4.362, avg. samples / sec: 6413.77
Iteration:   2300, Loss function: 3.404, Average Loss: 4.377, avg. samples / sec: 6411.46
Iteration:   2300, Loss function: 4.936, Average Loss: 4.351, avg. samples / sec: 6416.90
Iteration:   2300, Loss function: 3.495, Average Loss: 4.355, avg. samples / sec: 6413.71
Iteration:   2300, Loss function: 3.875, Average Loss: 4.330, avg. samples / sec: 6413.25
Iteration:   2300, Loss function: 4.028, Average Loss: 4.344, avg. samples / sec: 6413.63
Iteration:   2300, Loss function: 5.207, Average Loss: 4.366, avg. samples / sec: 6413.28
Iteration:   2300, Loss function: 4.094, Average Loss: 4.361, avg. samples / sec: 6415.45
Iteration:   2300, Loss function: 3.175, Average Loss: 4.350, avg. samples / sec: 6414.08
Iteration:   2300, Loss function: 4.196, Average Loss: 4.354, avg. samples / sec: 6410.38
Iteration:   2300, Loss function: 4.899, Average Loss: 4.354, avg. samples / sec: 6416.08
Iteration:   2300, Loss function: 3.733, Average Loss: 4.347, avg. samples / sec: 6410.09
Iteration:   2300, Loss function: 5.315, Average Loss: 4.364, avg. samples / sec: 6413.52
Iteration:   2300, Loss function: 3.666, Average Loss: 4.321, avg. samples / sec: 6413.05
Iteration:   2300, Loss function: 3.193, Average Loss: 4.335, avg. samples / sec: 6413.31
Iteration:   2300, Loss function: 3.776, Average Loss: 4.354, avg. samples / sec: 6413.25
Iteration:   2300, Loss function: 4.586, Average Loss: 4.357, avg. samples / sec: 6412.92
Iteration:   2300, Loss function: 3.576, Average Loss: 4.366, avg. samples / sec: 6412.27
Iteration:   2300, Loss function: 3.585, Average Loss: 4.355, avg. samples / sec: 6411.98
Iteration:   2300, Loss function: 4.369, Average Loss: 4.341, avg. samples / sec: 6413.24
Iteration:   2300, Loss function: 4.431, Average Loss: 4.368, avg. samples / sec: 6410.36
Iteration:   2300, Loss function: 4.692, Average Loss: 4.383, avg. samples / sec: 6412.38
Iteration:   2300, Loss function: 3.914, Average Loss: 4.341, avg. samples / sec: 6412.61
Iteration:   2300, Loss function: 2.900, Average Loss: 4.328, avg. samples / sec: 6412.92
Iteration:   2300, Loss function: 2.957, Average Loss: 4.343, avg. samples / sec: 6412.78
Iteration:   2300, Loss function: 3.691, Average Loss: 4.352, avg. samples / sec: 6412.52
Iteration:   2300, Loss function: 5.036, Average Loss: 4.327, avg. samples / sec: 6408.65
Iteration:   2300, Loss function: 4.863, Average Loss: 4.351, avg. samples / sec: 6408.59
Iteration:   2300, Loss function: 4.518, Average Loss: 4.365, avg. samples / sec: 6412.91
:::MLL 1558640927.388 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558640927.389 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 4.326, Average Loss: 4.366, avg. samples / sec: 53280.09
Iteration:   2320, Loss function: 4.219, Average Loss: 4.324, avg. samples / sec: 53347.72
Iteration:   2320, Loss function: 4.154, Average Loss: 4.374, avg. samples / sec: 53311.03
Iteration:   2320, Loss function: 3.780, Average Loss: 4.353, avg. samples / sec: 53305.30
Iteration:   2320, Loss function: 3.839, Average Loss: 4.358, avg. samples / sec: 53311.94
Iteration:   2320, Loss function: 4.839, Average Loss: 4.345, avg. samples / sec: 53291.03
Iteration:   2320, Loss function: 3.651, Average Loss: 4.341, avg. samples / sec: 53303.69
Iteration:   2320, Loss function: 4.077, Average Loss: 4.350, avg. samples / sec: 53261.37
Iteration:   2320, Loss function: 4.056, Average Loss: 4.338, avg. samples / sec: 53351.29
Iteration:   2320, Loss function: 4.916, Average Loss: 4.356, avg. samples / sec: 53260.30
Iteration:   2320, Loss function: 4.781, Average Loss: 4.350, avg. samples / sec: 53556.21
Iteration:   2320, Loss function: 3.866, Average Loss: 4.340, avg. samples / sec: 53294.88
Iteration:   2320, Loss function: 3.691, Average Loss: 4.341, avg. samples / sec: 53262.43
Iteration:   2320, Loss function: 4.381, Average Loss: 4.313, avg. samples / sec: 53316.29
Iteration:   2320, Loss function: 3.326, Average Loss: 4.350, avg. samples / sec: 53329.53
Iteration:   2320, Loss function: 4.111, Average Loss: 4.330, avg. samples / sec: 53317.12
Iteration:   2320, Loss function: 4.690, Average Loss: 4.380, avg. samples / sec: 53355.64
Iteration:   2320, Loss function: 3.289, Average Loss: 4.358, avg. samples / sec: 53251.64
Iteration:   2320, Loss function: 3.970, Average Loss: 4.358, avg. samples / sec: 53328.36
Iteration:   2320, Loss function: 4.856, Average Loss: 4.339, avg. samples / sec: 53335.71
Iteration:   2320, Loss function: 3.475, Average Loss: 4.365, avg. samples / sec: 53321.46
Iteration:   2320, Loss function: 5.167, Average Loss: 4.336, avg. samples / sec: 53345.66
Iteration:   2320, Loss function: 3.812, Average Loss: 4.325, avg. samples / sec: 53348.36
Iteration:   2320, Loss function: 4.481, Average Loss: 4.362, avg. samples / sec: 53309.24
Iteration:   2320, Loss function: 4.207, Average Loss: 4.347, avg. samples / sec: 53288.63
Iteration:   2320, Loss function: 5.087, Average Loss: 4.351, avg. samples / sec: 53336.61
Iteration:   2320, Loss function: 3.823, Average Loss: 4.364, avg. samples / sec: 53353.33
Iteration:   2320, Loss function: 3.844, Average Loss: 4.349, avg. samples / sec: 53107.26
Iteration:   2320, Loss function: 3.086, Average Loss: 4.337, avg. samples / sec: 53304.13
Iteration:   2320, Loss function: 5.299, Average Loss: 4.323, avg. samples / sec: 53299.01
Iteration:   2340, Loss function: 5.632, Average Loss: 4.363, avg. samples / sec: 54019.27
Iteration:   2340, Loss function: 4.192, Average Loss: 4.322, avg. samples / sec: 54012.79
Iteration:   2340, Loss function: 4.645, Average Loss: 4.342, avg. samples / sec: 54061.26
Iteration:   2340, Loss function: 4.512, Average Loss: 4.351, avg. samples / sec: 54005.07
Iteration:   2340, Loss function: 4.407, Average Loss: 4.339, avg. samples / sec: 54080.26
Iteration:   2340, Loss function: 3.622, Average Loss: 4.341, avg. samples / sec: 54066.17
Iteration:   2340, Loss function: 3.405, Average Loss: 4.330, avg. samples / sec: 53997.89
Iteration:   2340, Loss function: 3.611, Average Loss: 4.348, avg. samples / sec: 53965.43
Iteration:   2340, Loss function: 3.673, Average Loss: 4.353, avg. samples / sec: 54040.32
Iteration:   2340, Loss function: 4.397, Average Loss: 4.340, avg. samples / sec: 53946.05
Iteration:   2340, Loss function: 5.058, Average Loss: 4.312, avg. samples / sec: 54019.67
Iteration:   2340, Loss function: 4.180, Average Loss: 4.332, avg. samples / sec: 53991.91
Iteration:   2340, Loss function: 3.326, Average Loss: 4.342, avg. samples / sec: 53981.35
Iteration:   2340, Loss function: 3.511, Average Loss: 4.358, avg. samples / sec: 53997.58
Iteration:   2340, Loss function: 2.866, Average Loss: 4.358, avg. samples / sec: 54032.90
Iteration:   2340, Loss function: 3.556, Average Loss: 4.363, avg. samples / sec: 54003.13
Iteration:   2340, Loss function: 5.057, Average Loss: 4.357, avg. samples / sec: 53981.59
Iteration:   2340, Loss function: 4.692, Average Loss: 4.344, avg. samples / sec: 54011.51
Iteration:   2340, Loss function: 3.728, Average Loss: 4.335, avg. samples / sec: 54032.30
Iteration:   2340, Loss function: 3.592, Average Loss: 4.333, avg. samples / sec: 53788.13
Iteration:   2340, Loss function: 4.854, Average Loss: 4.352, avg. samples / sec: 54001.39
Iteration:   2340, Loss function: 2.960, Average Loss: 4.323, avg. samples / sec: 53997.58
Iteration:   2340, Loss function: 4.959, Average Loss: 4.375, avg. samples / sec: 53954.75
Iteration:   2340, Loss function: 4.036, Average Loss: 4.349, avg. samples / sec: 53778.98
Iteration:   2340, Loss function: 4.294, Average Loss: 4.330, avg. samples / sec: 53962.45
Iteration:   2340, Loss function: 3.957, Average Loss: 4.329, avg. samples / sec: 53979.22
Iteration:   2340, Loss function: 5.529, Average Loss: 4.374, avg. samples / sec: 53672.80
Iteration:   2340, Loss function: 3.717, Average Loss: 4.314, avg. samples / sec: 54010.81
Iteration:   2340, Loss function: 4.783, Average Loss: 4.357, avg. samples / sec: 53949.73
Iteration:   2340, Loss function: 5.107, Average Loss: 4.342, avg. samples / sec: 53954.29
Iteration:   2360, Loss function: 4.389, Average Loss: 4.362, avg. samples / sec: 53995.16
Iteration:   2360, Loss function: 3.941, Average Loss: 4.367, avg. samples / sec: 54272.53
Iteration:   2360, Loss function: 5.436, Average Loss: 4.342, avg. samples / sec: 53969.11
Iteration:   2360, Loss function: 3.860, Average Loss: 4.327, avg. samples / sec: 53957.04
Iteration:   2360, Loss function: 4.698, Average Loss: 4.320, avg. samples / sec: 53893.43
Iteration:   2360, Loss function: 3.448, Average Loss: 4.333, avg. samples / sec: 53942.85
Iteration:   2360, Loss function: 4.329, Average Loss: 4.347, avg. samples / sec: 53929.46
Iteration:   2360, Loss function: 3.148, Average Loss: 4.331, avg. samples / sec: 54198.54
Iteration:   2360, Loss function: 4.428, Average Loss: 4.332, avg. samples / sec: 53918.09
Iteration:   2360, Loss function: 4.186, Average Loss: 4.332, avg. samples / sec: 53956.38
Iteration:   2360, Loss function: 3.402, Average Loss: 4.346, avg. samples / sec: 53908.04
Iteration:   2360, Loss function: 3.537, Average Loss: 4.340, avg. samples / sec: 53760.47
Iteration:   2360, Loss function: 4.685, Average Loss: 4.370, avg. samples / sec: 53993.51
Iteration:   2360, Loss function: 4.544, Average Loss: 4.353, avg. samples / sec: 53952.41
Iteration:   2360, Loss function: 4.914, Average Loss: 4.329, avg. samples / sec: 53948.80
Iteration:   2360, Loss function: 3.973, Average Loss: 4.309, avg. samples / sec: 53908.17
Iteration:   2360, Loss function: 4.057, Average Loss: 4.335, avg. samples / sec: 53948.51
Iteration:   2360, Loss function: 4.470, Average Loss: 4.351, avg. samples / sec: 53970.20
Iteration:   2360, Loss function: 3.908, Average Loss: 4.360, avg. samples / sec: 53950.20
Iteration:   2360, Loss function: 5.186, Average Loss: 4.357, avg. samples / sec: 53942.89
Iteration:   2360, Loss function: 3.449, Average Loss: 4.342, avg. samples / sec: 53950.39
Iteration:   2360, Loss function: 3.770, Average Loss: 4.322, avg. samples / sec: 53958.61
Iteration:   2360, Loss function: 4.366, Average Loss: 4.326, avg. samples / sec: 53940.85
Iteration:   2360, Loss function: 4.077, Average Loss: 4.324, avg. samples / sec: 53948.47
Iteration:   2360, Loss function: 4.430, Average Loss: 4.309, avg. samples / sec: 53950.60
Iteration:   2360, Loss function: 3.874, Average Loss: 4.340, avg. samples / sec: 53982.86
Iteration:   2360, Loss function: 3.698, Average Loss: 4.352, avg. samples / sec: 53924.28
Iteration:   2360, Loss function: 3.748, Average Loss: 4.329, avg. samples / sec: 53903.51
Iteration:   2360, Loss function: 2.841, Average Loss: 4.353, avg. samples / sec: 53956.77
Iteration:   2360, Loss function: 5.225, Average Loss: 4.349, avg. samples / sec: 53906.35
:::MLL 1558640929.574 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558640929.575 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 4.296, Average Loss: 4.348, avg. samples / sec: 53421.55
Iteration:   2380, Loss function: 4.133, Average Loss: 4.341, avg. samples / sec: 53588.06
Iteration:   2380, Loss function: 4.724, Average Loss: 4.339, avg. samples / sec: 53625.85
Iteration:   2380, Loss function: 4.929, Average Loss: 4.356, avg. samples / sec: 53537.80
Iteration:   2380, Loss function: 3.008, Average Loss: 4.337, avg. samples / sec: 53482.59
Iteration:   2380, Loss function: 3.707, Average Loss: 4.326, avg. samples / sec: 53523.54
Iteration:   2380, Loss function: 4.484, Average Loss: 4.316, avg. samples / sec: 53470.42
Iteration:   2380, Loss function: 4.211, Average Loss: 4.349, avg. samples / sec: 53690.02
Iteration:   2380, Loss function: 4.173, Average Loss: 4.331, avg. samples / sec: 53455.45
Iteration:   2380, Loss function: 4.553, Average Loss: 4.322, avg. samples / sec: 53446.61
Iteration:   2380, Loss function: 4.201, Average Loss: 4.330, avg. samples / sec: 53602.21
Iteration:   2380, Loss function: 4.679, Average Loss: 4.325, avg. samples / sec: 53444.71
Iteration:   2380, Loss function: 3.378, Average Loss: 4.325, avg. samples / sec: 53415.74
Iteration:   2380, Loss function: 4.275, Average Loss: 4.314, avg. samples / sec: 53618.70
Iteration:   2380, Loss function: 3.813, Average Loss: 4.341, avg. samples / sec: 53601.31
Iteration:   2380, Loss function: 5.205, Average Loss: 4.353, avg. samples / sec: 53588.28
Iteration:   2380, Loss function: 3.406, Average Loss: 4.322, avg. samples / sec: 53598.58
Iteration:   2380, Loss function: 3.208, Average Loss: 4.348, avg. samples / sec: 53635.68
Iteration:   2380, Loss function: 4.415, Average Loss: 4.302, avg. samples / sec: 53516.19
Iteration:   2380, Loss function: 3.922, Average Loss: 4.327, avg. samples / sec: 53490.15
Iteration:   2380, Loss function: 3.916, Average Loss: 4.321, avg. samples / sec: 53473.87
Iteration:   2380, Loss function: 3.718, Average Loss: 4.360, avg. samples / sec: 53468.45
Iteration:   2380, Loss function: 4.554, Average Loss: 4.346, avg. samples / sec: 53526.55
Iteration:   2380, Loss function: 3.450, Average Loss: 4.323, avg. samples / sec: 53534.79
Iteration:   2380, Loss function: 4.187, Average Loss: 4.350, avg. samples / sec: 53469.79
Iteration:   2380, Loss function: 3.380, Average Loss: 4.344, avg. samples / sec: 53436.95
Iteration:   2380, Loss function: 3.408, Average Loss: 4.322, avg. samples / sec: 53482.13
Iteration:   2380, Loss function: 3.396, Average Loss: 4.343, avg. samples / sec: 53515.07
Iteration:   2380, Loss function: 3.161, Average Loss: 4.302, avg. samples / sec: 53474.01
Iteration:   2380, Loss function: 4.734, Average Loss: 4.334, avg. samples / sec: 53436.40
Iteration:   2400, Loss function: 4.222, Average Loss: 4.347, avg. samples / sec: 54022.13
Iteration:   2400, Loss function: 3.602, Average Loss: 4.317, avg. samples / sec: 54133.54
Iteration:   2400, Loss function: 3.244, Average Loss: 4.352, avg. samples / sec: 53958.80
Iteration:   2400, Loss function: 4.000, Average Loss: 4.310, avg. samples / sec: 54035.82
Iteration:   2400, Loss function: 3.836, Average Loss: 4.335, avg. samples / sec: 53913.75
Iteration:   2400, Loss function: 5.724, Average Loss: 4.341, avg. samples / sec: 53887.39
Iteration:   2400, Loss function: 3.588, Average Loss: 4.314, avg. samples / sec: 54041.25
Iteration:   2400, Loss function: 4.369, Average Loss: 4.323, avg. samples / sec: 54025.86
Iteration:   2400, Loss function: 4.072, Average Loss: 4.314, avg. samples / sec: 54019.89
Iteration:   2400, Loss function: 4.242, Average Loss: 4.319, avg. samples / sec: 53981.43
Iteration:   2400, Loss function: 3.054, Average Loss: 4.321, avg. samples / sec: 54004.70
Iteration:   2400, Loss function: 4.015, Average Loss: 4.328, avg. samples / sec: 53935.69
Iteration:   2400, Loss function: 4.540, Average Loss: 4.326, avg. samples / sec: 54106.55
Iteration:   2400, Loss function: 2.668, Average Loss: 4.299, avg. samples / sec: 53992.82
Iteration:   2400, Loss function: 3.618, Average Loss: 4.335, avg. samples / sec: 54071.46
Iteration:   2400, Loss function: 3.311, Average Loss: 4.339, avg. samples / sec: 53810.09
Iteration:   2400, Loss function: 4.210, Average Loss: 4.356, avg. samples / sec: 54019.40
Iteration:   2400, Loss function: 4.798, Average Loss: 4.332, avg. samples / sec: 54087.50
Iteration:   2400, Loss function: 5.017, Average Loss: 4.346, avg. samples / sec: 54002.07
Iteration:   2400, Loss function: 6.018, Average Loss: 4.312, avg. samples / sec: 53876.08
Iteration:   2400, Loss function: 4.979, Average Loss: 4.296, avg. samples / sec: 54035.62
Iteration:   2400, Loss function: 3.848, Average Loss: 4.338, avg. samples / sec: 53864.88
Iteration:   2400, Loss function: 2.994, Average Loss: 4.351, avg. samples / sec: 53870.70
Iteration:   2400, Loss function: 4.369, Average Loss: 4.347, avg. samples / sec: 53975.76
Iteration:   2400, Loss function: 4.187, Average Loss: 4.319, avg. samples / sec: 53872.68
Iteration:   2400, Loss function: 4.318, Average Loss: 4.321, avg. samples / sec: 53946.45
Iteration:   2400, Loss function: 5.425, Average Loss: 4.339, avg. samples / sec: 53994.98
Iteration:   2400, Loss function: 4.245, Average Loss: 4.337, avg. samples / sec: 53871.42
Iteration:   2400, Loss function: 3.200, Average Loss: 4.318, avg. samples / sec: 53953.84
Iteration:   2400, Loss function: 3.915, Average Loss: 4.318, avg. samples / sec: 53982.07
Iteration:   2420, Loss function: 4.403, Average Loss: 4.325, avg. samples / sec: 54202.10
Iteration:   2420, Loss function: 3.749, Average Loss: 4.342, avg. samples / sec: 53863.11
Iteration:   2420, Loss function: 4.469, Average Loss: 4.323, avg. samples / sec: 54014.62
Iteration:   2420, Loss function: 3.666, Average Loss: 4.334, avg. samples / sec: 53963.78
Iteration:   2420, Loss function: 4.219, Average Loss: 4.350, avg. samples / sec: 53896.33
Iteration:   2420, Loss function: 4.495, Average Loss: 4.312, avg. samples / sec: 53934.88
Iteration:   2420, Loss function: 3.643, Average Loss: 4.320, avg. samples / sec: 53936.82
Iteration:   2420, Loss function: 4.316, Average Loss: 4.311, avg. samples / sec: 53897.73
Iteration:   2420, Loss function: 3.919, Average Loss: 4.320, avg. samples / sec: 53937.22
Iteration:   2420, Loss function: 5.438, Average Loss: 4.338, avg. samples / sec: 53895.94
Iteration:   2420, Loss function: 3.942, Average Loss: 4.314, avg. samples / sec: 53900.50
Iteration:   2420, Loss function: 4.371, Average Loss: 4.318, avg. samples / sec: 53901.69
Iteration:   2420, Loss function: 4.422, Average Loss: 4.352, avg. samples / sec: 54073.08
Iteration:   2420, Loss function: 4.076, Average Loss: 4.315, avg. samples / sec: 53775.28
Iteration:   2420, Loss function: 4.291, Average Loss: 4.298, avg. samples / sec: 53942.05
Iteration:   2420, Loss function: 4.193, Average Loss: 4.322, avg. samples / sec: 53989.74
Iteration:   2420, Loss function: 4.969, Average Loss: 4.337, avg. samples / sec: 53903.77
Iteration:   2420, Loss function: 4.468, Average Loss: 4.335, avg. samples / sec: 53901.67
Iteration:   2420, Loss function: 3.223, Average Loss: 4.342, avg. samples / sec: 53936.02
Iteration:   2420, Loss function: 4.396, Average Loss: 4.348, avg. samples / sec: 53952.50
Iteration:   2420, Loss function: 3.663, Average Loss: 4.314, avg. samples / sec: 53950.41
Iteration:   2420, Loss function: 6.024, Average Loss: 4.337, avg. samples / sec: 53943.66
Iteration:   2420, Loss function: 5.565, Average Loss: 4.311, avg. samples / sec: 53922.25
Iteration:   2420, Loss function: 4.046, Average Loss: 4.349, avg. samples / sec: 53939.42
Iteration:   2420, Loss function: 4.941, Average Loss: 4.332, avg. samples / sec: 53910.64
Iteration:   2420, Loss function: 4.982, Average Loss: 4.292, avg. samples / sec: 53918.87
Iteration:   2420, Loss function: 4.506, Average Loss: 4.321, avg. samples / sec: 53942.60
Iteration:   2420, Loss function: 3.293, Average Loss: 4.319, avg. samples / sec: 53929.62
Iteration:   2420, Loss function: 5.102, Average Loss: 4.339, avg. samples / sec: 53909.84
Iteration:   2420, Loss function: 3.576, Average Loss: 4.333, avg. samples / sec: 53885.51
Iteration:   2440, Loss function: 4.257, Average Loss: 4.335, avg. samples / sec: 54132.88
Iteration:   2440, Loss function: 4.576, Average Loss: 4.318, avg. samples / sec: 53978.68
Iteration:   2440, Loss function: 3.929, Average Loss: 4.345, avg. samples / sec: 54093.03
Iteration:   2440, Loss function: 4.372, Average Loss: 4.327, avg. samples / sec: 54016.71
Iteration:   2440, Loss function: 4.977, Average Loss: 4.316, avg. samples / sec: 54056.55
Iteration:   2440, Loss function: 3.734, Average Loss: 4.314, avg. samples / sec: 54037.83
Iteration:   2440, Loss function: 3.767, Average Loss: 4.315, avg. samples / sec: 53986.85
Iteration:   2440, Loss function: 3.177, Average Loss: 4.305, avg. samples / sec: 54024.86
Iteration:   2440, Loss function: 4.089, Average Loss: 4.314, avg. samples / sec: 54054.29
Iteration:   2440, Loss function: 4.744, Average Loss: 4.309, avg. samples / sec: 54034.52
Iteration:   2440, Loss function: 4.505, Average Loss: 4.307, avg. samples / sec: 53977.62
Iteration:   2440, Loss function: 5.115, Average Loss: 4.334, avg. samples / sec: 53995.35
Iteration:   2440, Loss function: 4.627, Average Loss: 4.311, avg. samples / sec: 54045.94
Iteration:   2440, Loss function: 4.123, Average Loss: 4.345, avg. samples / sec: 53941.08
Iteration:   2440, Loss function: 4.849, Average Loss: 4.296, avg. samples / sec: 54028.68
Iteration:   2440, Loss function: 3.907, Average Loss: 4.332, avg. samples / sec: 54065.90
Iteration:   2440, Loss function: 4.260, Average Loss: 4.312, avg. samples / sec: 54092.07
Iteration:   2440, Loss function: 2.959, Average Loss: 4.318, avg. samples / sec: 54044.46
Iteration:   2440, Loss function: 4.090, Average Loss: 4.303, avg. samples / sec: 54076.96
Iteration:   2440, Loss function: 3.462, Average Loss: 4.334, avg. samples / sec: 54054.73
Iteration:   2440, Loss function: 4.106, Average Loss: 4.349, avg. samples / sec: 54063.46
Iteration:   2440, Loss function: 4.948, Average Loss: 4.326, avg. samples / sec: 54032.47
Iteration:   2440, Loss function: 3.864, Average Loss: 4.334, avg. samples / sec: 54052.32
Iteration:   2440, Loss function: 4.033, Average Loss: 4.327, avg. samples / sec: 54059.20
Iteration:   2440, Loss function: 3.379, Average Loss: 4.291, avg. samples / sec: 54065.51
Iteration:   2440, Loss function: 3.994, Average Loss: 4.315, avg. samples / sec: 54070.90
Iteration:   2440, Loss function: 3.579, Average Loss: 4.340, avg. samples / sec: 54027.04
Iteration:   2440, Loss function: 3.796, Average Loss: 4.329, avg. samples / sec: 54085.05
Iteration:   2440, Loss function: 4.484, Average Loss: 4.329, avg. samples / sec: 54113.90
Iteration:   2440, Loss function: 3.879, Average Loss: 4.317, avg. samples / sec: 54038.56
:::MLL 1558640931.756 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558640931.756 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 2.784, Average Loss: 4.313, avg. samples / sec: 53777.38
Iteration:   2460, Loss function: 3.723, Average Loss: 4.331, avg. samples / sec: 53620.30
Iteration:   2460, Loss function: 3.819, Average Loss: 4.311, avg. samples / sec: 53731.65
Iteration:   2460, Loss function: 4.711, Average Loss: 4.301, avg. samples / sec: 53726.84
Iteration:   2460, Loss function: 5.039, Average Loss: 4.342, avg. samples / sec: 53635.89
Iteration:   2460, Loss function: 3.899, Average Loss: 4.307, avg. samples / sec: 53758.38
Iteration:   2460, Loss function: 4.805, Average Loss: 4.310, avg. samples / sec: 53677.01
Iteration:   2460, Loss function: 3.944, Average Loss: 4.330, avg. samples / sec: 53744.97
Iteration:   2460, Loss function: 3.689, Average Loss: 4.324, avg. samples / sec: 53668.22
Iteration:   2460, Loss function: 3.640, Average Loss: 4.307, avg. samples / sec: 53745.30
Iteration:   2460, Loss function: 5.163, Average Loss: 4.296, avg. samples / sec: 53697.61
Iteration:   2460, Loss function: 3.743, Average Loss: 4.305, avg. samples / sec: 53685.43
Iteration:   2460, Loss function: 3.275, Average Loss: 4.322, avg. samples / sec: 53853.49
Iteration:   2460, Loss function: 3.748, Average Loss: 4.331, avg. samples / sec: 53705.63
Iteration:   2460, Loss function: 5.830, Average Loss: 4.333, avg. samples / sec: 53716.19
Iteration:   2460, Loss function: 3.637, Average Loss: 4.346, avg. samples / sec: 53721.62
Iteration:   2460, Loss function: 3.904, Average Loss: 4.314, avg. samples / sec: 53701.15
Iteration:   2460, Loss function: 5.125, Average Loss: 4.292, avg. samples / sec: 53679.83
Iteration:   2460, Loss function: 3.719, Average Loss: 4.324, avg. samples / sec: 53712.57
Iteration:   2460, Loss function: 3.766, Average Loss: 4.297, avg. samples / sec: 53693.84
Iteration:   2460, Loss function: 3.525, Average Loss: 4.307, avg. samples / sec: 53470.46
Iteration:   2460, Loss function: 3.920, Average Loss: 4.334, avg. samples / sec: 53638.15
Iteration:   2460, Loss function: 3.941, Average Loss: 4.332, avg. samples / sec: 53702.15
Iteration:   2460, Loss function: 2.952, Average Loss: 4.323, avg. samples / sec: 53674.19
Iteration:   2460, Loss function: 5.306, Average Loss: 4.288, avg. samples / sec: 53675.64
Iteration:   2460, Loss function: 4.089, Average Loss: 4.305, avg. samples / sec: 53638.48
Iteration:   2460, Loss function: 5.370, Average Loss: 4.324, avg. samples / sec: 53681.65
Iteration:   2460, Loss function: 3.721, Average Loss: 4.307, avg. samples / sec: 53669.14
Iteration:   2460, Loss function: 3.823, Average Loss: 4.326, avg. samples / sec: 53647.52
Iteration:   2460, Loss function: 4.589, Average Loss: 4.308, avg. samples / sec: 53681.26
Iteration:   2480, Loss function: 4.825, Average Loss: 4.328, avg. samples / sec: 54079.91
Iteration:   2480, Loss function: 4.483, Average Loss: 4.313, avg. samples / sec: 53879.44
Iteration:   2480, Loss function: 4.225, Average Loss: 4.317, avg. samples / sec: 54066.98
Iteration:   2480, Loss function: 4.482, Average Loss: 4.311, avg. samples / sec: 54013.39
Iteration:   2480, Loss function: 4.115, Average Loss: 4.303, avg. samples / sec: 54094.52
Iteration:   2480, Loss function: 4.209, Average Loss: 4.299, avg. samples / sec: 54032.59
Iteration:   2480, Loss function: 3.810, Average Loss: 4.314, avg. samples / sec: 54017.00
Iteration:   2480, Loss function: 4.374, Average Loss: 4.326, avg. samples / sec: 54017.33
Iteration:   2480, Loss function: 5.096, Average Loss: 4.326, avg. samples / sec: 54187.33
Iteration:   2480, Loss function: 3.513, Average Loss: 4.285, avg. samples / sec: 54010.06
Iteration:   2480, Loss function: 5.070, Average Loss: 4.297, avg. samples / sec: 53944.48
Iteration:   2480, Loss function: 4.017, Average Loss: 4.322, avg. samples / sec: 54044.77
Iteration:   2480, Loss function: 4.831, Average Loss: 4.304, avg. samples / sec: 54006.46
Iteration:   2480, Loss function: 4.102, Average Loss: 4.328, avg. samples / sec: 53994.21
Iteration:   2480, Loss function: 5.507, Average Loss: 4.305, avg. samples / sec: 54004.25
Iteration:   2480, Loss function: 4.139, Average Loss: 4.289, avg. samples / sec: 53992.62
Iteration:   2480, Loss function: 3.178, Average Loss: 4.300, avg. samples / sec: 54038.06
Iteration:   2480, Loss function: 4.685, Average Loss: 4.303, avg. samples / sec: 53799.63
Iteration:   2480, Loss function: 3.410, Average Loss: 4.339, avg. samples / sec: 53978.47
Iteration:   2480, Loss function: 4.381, Average Loss: 4.291, avg. samples / sec: 53985.21
Iteration:   2480, Loss function: 2.882, Average Loss: 4.336, avg. samples / sec: 53743.39
Iteration:   2480, Loss function: 3.157, Average Loss: 4.326, avg. samples / sec: 54009.21
Iteration:   2480, Loss function: 3.626, Average Loss: 4.330, avg. samples / sec: 53991.44
Iteration:   2480, Loss function: 3.461, Average Loss: 4.314, avg. samples / sec: 54016.58
Iteration:   2480, Loss function: 3.853, Average Loss: 4.304, avg. samples / sec: 54028.12
Iteration:   2480, Loss function: 4.233, Average Loss: 4.322, avg. samples / sec: 53814.61
Iteration:   2480, Loss function: 2.926, Average Loss: 4.321, avg. samples / sec: 53994.19
Iteration:   2480, Loss function: 4.592, Average Loss: 4.304, avg. samples / sec: 54028.16
Iteration:   2480, Loss function: 4.053, Average Loss: 4.323, avg. samples / sec: 54015.48
Iteration:   2480, Loss function: 4.968, Average Loss: 4.281, avg. samples / sec: 53964.93
Iteration:   2500, Loss function: 4.663, Average Loss: 4.322, avg. samples / sec: 53804.19
Iteration:   2500, Loss function: 3.099, Average Loss: 4.332, avg. samples / sec: 54172.98
Iteration:   2500, Loss function: 4.187, Average Loss: 4.308, avg. samples / sec: 53868.81
Iteration:   2500, Loss function: 3.482, Average Loss: 4.294, avg. samples / sec: 53884.48
Iteration:   2500, Loss function: 3.394, Average Loss: 4.309, avg. samples / sec: 53856.05
Iteration:   2500, Loss function: 3.940, Average Loss: 4.302, avg. samples / sec: 53841.85
Iteration:   2500, Loss function: 4.185, Average Loss: 4.323, avg. samples / sec: 53870.93
Iteration:   2500, Loss function: 4.320, Average Loss: 4.295, avg. samples / sec: 53894.04
Iteration:   2500, Loss function: 3.814, Average Loss: 4.298, avg. samples / sec: 53810.02
Iteration:   2500, Loss function: 3.887, Average Loss: 4.280, avg. samples / sec: 53879.64
Iteration:   2500, Loss function: 3.245, Average Loss: 4.311, avg. samples / sec: 53824.20
Iteration:   2500, Loss function: 3.431, Average Loss: 4.296, avg. samples / sec: 54063.56
Iteration:   2500, Loss function: 3.445, Average Loss: 4.306, avg. samples / sec: 53903.88
Iteration:   2500, Loss function: 4.338, Average Loss: 4.322, avg. samples / sec: 53936.27
Iteration:   2500, Loss function: 3.800, Average Loss: 4.289, avg. samples / sec: 53906.33
Iteration:   2500, Loss function: 4.319, Average Loss: 4.325, avg. samples / sec: 53914.17
Iteration:   2500, Loss function: 3.916, Average Loss: 4.315, avg. samples / sec: 53851.83
Iteration:   2500, Loss function: 4.835, Average Loss: 4.325, avg. samples / sec: 53683.92
Iteration:   2500, Loss function: 2.533, Average Loss: 4.317, avg. samples / sec: 53877.05
Iteration:   2500, Loss function: 4.710, Average Loss: 4.300, avg. samples / sec: 53885.99
Iteration:   2500, Loss function: 3.176, Average Loss: 4.304, avg. samples / sec: 53894.66
Iteration:   2500, Loss function: 4.871, Average Loss: 4.331, avg. samples / sec: 53879.27
Iteration:   2500, Loss function: 3.136, Average Loss: 4.292, avg. samples / sec: 53869.90
Iteration:   2500, Loss function: 5.384, Average Loss: 4.285, avg. samples / sec: 53879.81
Iteration:   2500, Loss function: 3.508, Average Loss: 4.321, avg. samples / sec: 53898.39
Iteration:   2500, Loss function: 3.753, Average Loss: 4.296, avg. samples / sec: 53871.49
Iteration:   2500, Loss function: 5.888, Average Loss: 4.281, avg. samples / sec: 53918.79
Iteration:   2500, Loss function: 3.695, Average Loss: 4.315, avg. samples / sec: 53910.13
Iteration:   2500, Loss function: 4.521, Average Loss: 4.301, avg. samples / sec: 53881.48
Iteration:   2500, Loss function: 4.448, Average Loss: 4.316, avg. samples / sec: 53868.89
:::MLL 1558640933.939 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558640933.939 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 4.721, Average Loss: 4.316, avg. samples / sec: 53751.02
Iteration:   2520, Loss function: 4.162, Average Loss: 4.299, avg. samples / sec: 53800.37
Iteration:   2520, Loss function: 3.515, Average Loss: 4.304, avg. samples / sec: 53791.42
Iteration:   2520, Loss function: 3.275, Average Loss: 4.325, avg. samples / sec: 53691.14
Iteration:   2520, Loss function: 3.762, Average Loss: 4.292, avg. samples / sec: 53677.58
Iteration:   2520, Loss function: 4.435, Average Loss: 4.296, avg. samples / sec: 53693.33
Iteration:   2520, Loss function: 2.911, Average Loss: 4.276, avg. samples / sec: 53705.36
Iteration:   2520, Loss function: 4.354, Average Loss: 4.288, avg. samples / sec: 53686.15
Iteration:   2520, Loss function: 4.079, Average Loss: 4.302, avg. samples / sec: 53636.91
Iteration:   2520, Loss function: 5.480, Average Loss: 4.323, avg. samples / sec: 53874.04
Iteration:   2520, Loss function: 4.913, Average Loss: 4.316, avg. samples / sec: 53897.71
Iteration:   2520, Loss function: 3.017, Average Loss: 4.288, avg. samples / sec: 53693.33
Iteration:   2520, Loss function: 3.232, Average Loss: 4.293, avg. samples / sec: 53636.38
Iteration:   2520, Loss function: 3.572, Average Loss: 4.302, avg. samples / sec: 53808.46
Iteration:   2520, Loss function: 4.832, Average Loss: 4.326, avg. samples / sec: 53811.44
Iteration:   2520, Loss function: 4.594, Average Loss: 4.280, avg. samples / sec: 53817.44
Iteration:   2520, Loss function: 3.977, Average Loss: 4.312, avg. samples / sec: 53761.85
Iteration:   2520, Loss function: 4.678, Average Loss: 4.286, avg. samples / sec: 53780.41
Iteration:   2520, Loss function: 4.656, Average Loss: 4.297, avg. samples / sec: 53819.52
Iteration:   2520, Loss function: 5.725, Average Loss: 4.315, avg. samples / sec: 53773.17
Iteration:   2520, Loss function: 3.303, Average Loss: 4.286, avg. samples / sec: 53703.87
Iteration:   2520, Loss function: 4.644, Average Loss: 4.300, avg. samples / sec: 53687.36
Iteration:   2520, Loss function: 4.071, Average Loss: 4.318, avg. samples / sec: 53656.72
Iteration:   2520, Loss function: 3.583, Average Loss: 4.313, avg. samples / sec: 53688.46
Iteration:   2520, Loss function: 3.966, Average Loss: 4.318, avg. samples / sec: 53660.66
Iteration:   2520, Loss function: 5.228, Average Loss: 4.320, avg. samples / sec: 53449.86
Iteration:   2520, Loss function: 3.471, Average Loss: 4.308, avg. samples / sec: 53740.11
Iteration:   2520, Loss function: 4.204, Average Loss: 4.297, avg. samples / sec: 53654.78
Iteration:   2520, Loss function: 4.209, Average Loss: 4.279, avg. samples / sec: 53666.63
Iteration:   2520, Loss function: 3.661, Average Loss: 4.297, avg. samples / sec: 53656.08
Iteration:   2540, Loss function: 3.375, Average Loss: 4.311, avg. samples / sec: 53840.37
Iteration:   2540, Loss function: 4.334, Average Loss: 4.321, avg. samples / sec: 53836.29
Iteration:   2540, Loss function: 3.089, Average Loss: 4.282, avg. samples / sec: 53849.01
Iteration:   2540, Loss function: 4.466, Average Loss: 4.283, avg. samples / sec: 53904.19
Iteration:   2540, Loss function: 4.827, Average Loss: 4.305, avg. samples / sec: 53816.27
Iteration:   2540, Loss function: 3.750, Average Loss: 4.287, avg. samples / sec: 53844.65
Iteration:   2540, Loss function: 2.886, Average Loss: 4.289, avg. samples / sec: 53878.06
Iteration:   2540, Loss function: 3.309, Average Loss: 4.296, avg. samples / sec: 53670.00
Iteration:   2540, Loss function: 3.593, Average Loss: 4.293, avg. samples / sec: 53898.02
Iteration:   2540, Loss function: 3.151, Average Loss: 4.269, avg. samples / sec: 53822.83
Iteration:   2540, Loss function: 4.081, Average Loss: 4.286, avg. samples / sec: 53818.88
Iteration:   2540, Loss function: 4.554, Average Loss: 4.285, avg. samples / sec: 53862.55
Iteration:   2540, Loss function: 4.339, Average Loss: 4.294, avg. samples / sec: 53857.28
Iteration:   2540, Loss function: 3.918, Average Loss: 4.296, avg. samples / sec: 53916.04
Iteration:   2540, Loss function: 5.060, Average Loss: 4.316, avg. samples / sec: 53678.44
Iteration:   2540, Loss function: 3.655, Average Loss: 4.308, avg. samples / sec: 53868.13
Iteration:   2540, Loss function: 3.696, Average Loss: 4.280, avg. samples / sec: 53789.67
Iteration:   2540, Loss function: 3.435, Average Loss: 4.312, avg. samples / sec: 53854.56
Iteration:   2540, Loss function: 4.110, Average Loss: 4.316, avg. samples / sec: 53858.45
Iteration:   2540, Loss function: 4.386, Average Loss: 4.278, avg. samples / sec: 53738.05
Iteration:   2540, Loss function: 3.437, Average Loss: 4.320, avg. samples / sec: 53734.48
Iteration:   2540, Loss function: 4.417, Average Loss: 4.316, avg. samples / sec: 53856.25
Iteration:   2540, Loss function: 3.538, Average Loss: 4.306, avg. samples / sec: 53741.90
Iteration:   2540, Loss function: 3.095, Average Loss: 4.300, avg. samples / sec: 53714.20
Iteration:   2540, Loss function: 4.411, Average Loss: 4.294, avg. samples / sec: 53743.54
Iteration:   2540, Loss function: 3.667, Average Loss: 4.297, avg. samples / sec: 53880.84
Iteration:   2540, Loss function: 3.072, Average Loss: 4.273, avg. samples / sec: 53871.75
Iteration:   2540, Loss function: 3.040, Average Loss: 4.311, avg. samples / sec: 53760.82
Iteration:   2540, Loss function: 4.672, Average Loss: 4.312, avg. samples / sec: 53617.44
Iteration:   2540, Loss function: 3.573, Average Loss: 4.302, avg. samples / sec: 53799.12
Iteration:   2560, Loss function: 3.992, Average Loss: 4.298, avg. samples / sec: 53950.02
Iteration:   2560, Loss function: 3.059, Average Loss: 4.286, avg. samples / sec: 54071.19
Iteration:   2560, Loss function: 4.383, Average Loss: 4.289, avg. samples / sec: 54071.88
Iteration:   2560, Loss function: 3.442, Average Loss: 4.312, avg. samples / sec: 53991.79
Iteration:   2560, Loss function: 5.907, Average Loss: 4.307, avg. samples / sec: 54238.86
Iteration:   2560, Loss function: 3.268, Average Loss: 4.277, avg. samples / sec: 53983.87
Iteration:   2560, Loss function: 4.366, Average Loss: 4.274, avg. samples / sec: 53971.69
Iteration:   2560, Loss function: 5.017, Average Loss: 4.280, avg. samples / sec: 53988.71
Iteration:   2560, Loss function: 3.501, Average Loss: 4.263, avg. samples / sec: 54025.49
Iteration:   2560, Loss function: 5.100, Average Loss: 4.304, avg. samples / sec: 54260.75
Iteration:   2560, Loss function: 3.569, Average Loss: 4.282, avg. samples / sec: 53956.34
Iteration:   2560, Loss function: 4.053, Average Loss: 4.311, avg. samples / sec: 54193.75
Iteration:   2560, Loss function: 3.798, Average Loss: 4.295, avg. samples / sec: 54260.68
Iteration:   2560, Loss function: 3.856, Average Loss: 4.284, avg. samples / sec: 54022.28
Iteration:   2560, Loss function: 4.066, Average Loss: 4.287, avg. samples / sec: 53984.05
Iteration:   2560, Loss function: 3.609, Average Loss: 4.298, avg. samples / sec: 54028.14
Iteration:   2560, Loss function: 3.708, Average Loss: 4.310, avg. samples / sec: 53983.21
Iteration:   2560, Loss function: 4.931, Average Loss: 4.293, avg. samples / sec: 53962.23
Iteration:   2560, Loss function: 4.632, Average Loss: 4.306, avg. samples / sec: 53735.75
Iteration:   2560, Loss function: 4.370, Average Loss: 4.296, avg. samples / sec: 53999.63
Iteration:   2560, Loss function: 3.081, Average Loss: 4.305, avg. samples / sec: 53976.82
Iteration:   2560, Loss function: 3.824, Average Loss: 4.270, avg. samples / sec: 53963.96
Iteration:   2560, Loss function: 3.192, Average Loss: 4.287, avg. samples / sec: 53982.13
Iteration:   2560, Loss function: 5.191, Average Loss: 4.266, avg. samples / sec: 53974.25
Iteration:   2560, Loss function: 3.224, Average Loss: 4.274, avg. samples / sec: 53920.29
Iteration:   2560, Loss function: 4.165, Average Loss: 4.304, avg. samples / sec: 53907.49
Iteration:   2560, Loss function: 3.709, Average Loss: 4.309, avg. samples / sec: 53936.99
Iteration:   2560, Loss function: 3.885, Average Loss: 4.306, avg. samples / sec: 53959.60
Iteration:   2560, Loss function: 4.625, Average Loss: 4.289, avg. samples / sec: 53929.41
Iteration:   2560, Loss function: 4.110, Average Loss: 4.282, avg. samples / sec: 53802.46
Iteration:   2580, Loss function: 4.453, Average Loss: 4.294, avg. samples / sec: 53859.40
Iteration:   2580, Loss function: 3.644, Average Loss: 4.282, avg. samples / sec: 53843.02
Iteration:   2580, Loss function: 3.527, Average Loss: 4.275, avg. samples / sec: 53865.37
Iteration:   2580, Loss function: 2.562, Average Loss: 4.308, avg. samples / sec: 53833.35
Iteration:   2580, Loss function: 4.335, Average Loss: 4.277, avg. samples / sec: 53878.43
Iteration:   2580, Loss function: 3.990, Average Loss: 4.253, avg. samples / sec: 53843.64
Iteration:   2580, Loss function: 5.165, Average Loss: 4.270, avg. samples / sec: 53813.85
Iteration:   2580, Loss function: 4.146, Average Loss: 4.289, avg. samples / sec: 53827.14
Iteration:   2580, Loss function: 2.301, Average Loss: 4.271, avg. samples / sec: 53770.01
Iteration:   2580, Loss function: 3.891, Average Loss: 4.305, avg. samples / sec: 53766.58
Iteration:   2580, Loss function: 3.948, Average Loss: 4.280, avg. samples / sec: 53837.49
Iteration:   2580, Loss function: 4.875, Average Loss: 4.280, avg. samples / sec: 53733.48
Iteration:   2580, Loss function: 4.365, Average Loss: 4.311, avg. samples / sec: 53801.77
Iteration:   2580, Loss function: 4.043, Average Loss: 4.295, avg. samples / sec: 53871.84
Iteration:   2580, Loss function: 3.386, Average Loss: 4.279, avg. samples / sec: 53825.31
Iteration:   2580, Loss function: 4.458, Average Loss: 4.306, avg. samples / sec: 53831.83
Iteration:   2580, Loss function: 4.132, Average Loss: 4.278, avg. samples / sec: 53985.54
Iteration:   2580, Loss function: 4.533, Average Loss: 4.301, avg. samples / sec: 53865.04
Iteration:   2580, Loss function: 4.557, Average Loss: 4.306, avg. samples / sec: 53900.23
Iteration:   2580, Loss function: 3.597, Average Loss: 4.298, avg. samples / sec: 53620.09
Iteration:   2580, Loss function: 2.495, Average Loss: 4.300, avg. samples / sec: 53894.31
Iteration:   2580, Loss function: 4.059, Average Loss: 4.272, avg. samples / sec: 53879.23
Iteration:   2580, Loss function: 3.400, Average Loss: 4.288, avg. samples / sec: 53808.52
Iteration:   2580, Loss function: 2.764, Average Loss: 4.290, avg. samples / sec: 53830.62
Iteration:   2580, Loss function: 3.487, Average Loss: 4.262, avg. samples / sec: 53849.58
Iteration:   2580, Loss function: 4.842, Average Loss: 4.304, avg. samples / sec: 53818.12
Iteration:   2580, Loss function: 3.084, Average Loss: 4.281, avg. samples / sec: 53847.38
Iteration:   2580, Loss function: 3.643, Average Loss: 4.299, avg. samples / sec: 53861.09
Iteration:   2580, Loss function: 4.969, Average Loss: 4.281, avg. samples / sec: 53880.38
Iteration:   2580, Loss function: 4.676, Average Loss: 4.269, avg. samples / sec: 53840.68
:::MLL 1558640936.125 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558640936.126 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 2.779, Average Loss: 4.286, avg. samples / sec: 53416.14
Iteration:   2600, Loss function: 4.333, Average Loss: 4.281, avg. samples / sec: 53448.58
Iteration:   2600, Loss function: 4.503, Average Loss: 4.274, avg. samples / sec: 53480.99
Iteration:   2600, Loss function: 3.590, Average Loss: 4.273, avg. samples / sec: 53452.96
Iteration:   2600, Loss function: 3.828, Average Loss: 4.264, avg. samples / sec: 53483.00
Iteration:   2600, Loss function: 3.863, Average Loss: 4.301, avg. samples / sec: 53500.36
Iteration:   2600, Loss function: 3.698, Average Loss: 4.302, avg. samples / sec: 53421.85
Iteration:   2600, Loss function: 3.961, Average Loss: 4.251, avg. samples / sec: 53457.03
Iteration:   2600, Loss function: 3.304, Average Loss: 4.276, avg. samples / sec: 53480.06
Iteration:   2600, Loss function: 4.567, Average Loss: 4.280, avg. samples / sec: 53463.85
Iteration:   2600, Loss function: 5.033, Average Loss: 4.278, avg. samples / sec: 53470.16
Iteration:   2600, Loss function: 4.689, Average Loss: 4.304, avg. samples / sec: 53477.80
Iteration:   2600, Loss function: 3.569, Average Loss: 4.266, avg. samples / sec: 53414.69
Iteration:   2600, Loss function: 3.285, Average Loss: 4.281, avg. samples / sec: 53492.79
Iteration:   2600, Loss function: 4.789, Average Loss: 4.278, avg. samples / sec: 53465.12
Iteration:   2600, Loss function: 4.123, Average Loss: 4.300, avg. samples / sec: 53453.30
Iteration:   2600, Loss function: 4.303, Average Loss: 4.298, avg. samples / sec: 53473.95
Iteration:   2600, Loss function: 4.536, Average Loss: 4.288, avg. samples / sec: 53465.53
Iteration:   2600, Loss function: 4.518, Average Loss: 4.293, avg. samples / sec: 53407.30
Iteration:   2600, Loss function: 3.336, Average Loss: 4.294, avg. samples / sec: 53454.56
Iteration:   2600, Loss function: 4.942, Average Loss: 4.302, avg. samples / sec: 53457.28
Iteration:   2600, Loss function: 3.608, Average Loss: 4.282, avg. samples / sec: 53456.04
Iteration:   2600, Loss function: 4.227, Average Loss: 4.277, avg. samples / sec: 53411.35
Iteration:   2600, Loss function: 4.560, Average Loss: 4.304, avg. samples / sec: 53457.21
Iteration:   2600, Loss function: 3.859, Average Loss: 4.257, avg. samples / sec: 53437.88
Iteration:   2600, Loss function: 2.616, Average Loss: 4.286, avg. samples / sec: 53466.83
Iteration:   2600, Loss function: 3.395, Average Loss: 4.266, avg. samples / sec: 53466.58
Iteration:   2600, Loss function: 4.819, Average Loss: 4.274, avg. samples / sec: 53449.96
Iteration:   2600, Loss function: 3.722, Average Loss: 4.273, avg. samples / sec: 53461.13
Iteration:   2600, Loss function: 3.705, Average Loss: 4.270, avg. samples / sec: 53344.27
Iteration:   2620, Loss function: 4.445, Average Loss: 4.281, avg. samples / sec: 54107.96
Iteration:   2620, Loss function: 4.112, Average Loss: 4.263, avg. samples / sec: 54101.79
Iteration:   2620, Loss function: 3.482, Average Loss: 4.260, avg. samples / sec: 54108.37
Iteration:   2620, Loss function: 4.357, Average Loss: 4.294, avg. samples / sec: 54119.37
Iteration:   2620, Loss function: 4.534, Average Loss: 4.278, avg. samples / sec: 54124.21
Iteration:   2620, Loss function: 3.684, Average Loss: 4.266, avg. samples / sec: 54044.48
Iteration:   2620, Loss function: 4.457, Average Loss: 4.273, avg. samples / sec: 54110.14
Iteration:   2620, Loss function: 2.557, Average Loss: 4.281, avg. samples / sec: 54013.02
Iteration:   2620, Loss function: 6.010, Average Loss: 4.302, avg. samples / sec: 54057.38
Iteration:   2620, Loss function: 4.654, Average Loss: 4.263, avg. samples / sec: 54070.38
Iteration:   2620, Loss function: 3.656, Average Loss: 4.273, avg. samples / sec: 54157.53
Iteration:   2620, Loss function: 1.958, Average Loss: 4.267, avg. samples / sec: 54049.89
Iteration:   2620, Loss function: 3.386, Average Loss: 4.274, avg. samples / sec: 54087.07
Iteration:   2620, Loss function: 4.674, Average Loss: 4.257, avg. samples / sec: 54106.17
Iteration:   2620, Loss function: 3.150, Average Loss: 4.280, avg. samples / sec: 54040.03
Iteration:   2620, Loss function: 3.568, Average Loss: 4.293, avg. samples / sec: 54045.02
Iteration:   2620, Loss function: 4.078, Average Loss: 4.292, avg. samples / sec: 54047.10
Iteration:   2620, Loss function: 3.047, Average Loss: 4.288, avg. samples / sec: 54054.19
Iteration:   2620, Loss function: 4.371, Average Loss: 4.244, avg. samples / sec: 53826.22
Iteration:   2620, Loss function: 3.994, Average Loss: 4.293, avg. samples / sec: 54049.33
Iteration:   2620, Loss function: 3.578, Average Loss: 4.293, avg. samples / sec: 53810.15
Iteration:   2620, Loss function: 3.408, Average Loss: 4.300, avg. samples / sec: 54065.43
Iteration:   2620, Loss function: 4.737, Average Loss: 4.292, avg. samples / sec: 54022.67
Iteration:   2620, Loss function: 4.361, Average Loss: 4.268, avg. samples / sec: 54165.54
Iteration:   2620, Loss function: 3.895, Average Loss: 4.275, avg. samples / sec: 53828.07
Iteration:   2620, Loss function: 3.288, Average Loss: 4.269, avg. samples / sec: 54063.33
Iteration:   2620, Loss function: 3.949, Average Loss: 4.288, avg. samples / sec: 54004.18
Iteration:   2620, Loss function: 4.018, Average Loss: 4.278, avg. samples / sec: 54056.30
Iteration:   2620, Loss function: 4.865, Average Loss: 4.279, avg. samples / sec: 54030.08
Iteration:   2620, Loss function: 4.063, Average Loss: 4.264, avg. samples / sec: 54020.16
Iteration:   2640, Loss function: 4.858, Average Loss: 4.277, avg. samples / sec: 54068.77
Iteration:   2640, Loss function: 4.195, Average Loss: 4.276, avg. samples / sec: 54104.74
Iteration:   2640, Loss function: 4.077, Average Loss: 4.263, avg. samples / sec: 54017.33
Iteration:   2640, Loss function: 3.869, Average Loss: 4.254, avg. samples / sec: 54167.79
Iteration:   2640, Loss function: 4.130, Average Loss: 4.280, avg. samples / sec: 54323.98
Iteration:   2640, Loss function: 4.378, Average Loss: 4.293, avg. samples / sec: 54027.70
Iteration:   2640, Loss function: 4.543, Average Loss: 4.264, avg. samples / sec: 54008.55
Iteration:   2640, Loss function: 4.487, Average Loss: 4.271, avg. samples / sec: 54334.76
Iteration:   2640, Loss function: 3.978, Average Loss: 4.272, avg. samples / sec: 54015.82
Iteration:   2640, Loss function: 3.627, Average Loss: 4.293, avg. samples / sec: 54063.68
Iteration:   2640, Loss function: 4.731, Average Loss: 4.259, avg. samples / sec: 53975.12
Iteration:   2640, Loss function: 4.263, Average Loss: 4.281, avg. samples / sec: 53858.97
Iteration:   2640, Loss function: 3.672, Average Loss: 4.261, avg. samples / sec: 54106.38
Iteration:   2640, Loss function: 4.050, Average Loss: 4.282, avg. samples / sec: 54093.86
Iteration:   2640, Loss function: 3.391, Average Loss: 4.276, avg. samples / sec: 54149.73
Iteration:   2640, Loss function: 4.973, Average Loss: 4.269, avg. samples / sec: 54073.27
Iteration:   2640, Loss function: 3.900, Average Loss: 4.285, avg. samples / sec: 54070.59
Iteration:   2640, Loss function: 3.619, Average Loss: 4.291, avg. samples / sec: 54095.39
Iteration:   2640, Loss function: 3.398, Average Loss: 4.265, avg. samples / sec: 53982.30
Iteration:   2640, Loss function: 3.668, Average Loss: 4.284, avg. samples / sec: 54114.90
Iteration:   2640, Loss function: 4.004, Average Loss: 4.287, avg. samples / sec: 54071.46
Iteration:   2640, Loss function: 3.972, Average Loss: 4.246, avg. samples / sec: 54058.77
Iteration:   2640, Loss function: 4.896, Average Loss: 4.300, avg. samples / sec: 54073.99
Iteration:   2640, Loss function: 4.028, Average Loss: 4.294, avg. samples / sec: 54046.08
Iteration:   2640, Loss function: 3.445, Average Loss: 4.255, avg. samples / sec: 54031.58
Iteration:   2640, Loss function: 5.224, Average Loss: 4.294, avg. samples / sec: 54053.38
Iteration:   2640, Loss function: 3.098, Average Loss: 4.268, avg. samples / sec: 54072.37
Iteration:   2640, Loss function: 4.585, Average Loss: 4.261, avg. samples / sec: 54047.90
Iteration:   2640, Loss function: 4.590, Average Loss: 4.264, avg. samples / sec: 54100.96
Iteration:   2640, Loss function: 3.816, Average Loss: 4.271, avg. samples / sec: 54089.89
:::MLL 1558640938.309 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558640938.310 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 3.691, Average Loss: 4.274, avg. samples / sec: 53495.26
Iteration:   2660, Loss function: 3.210, Average Loss: 4.272, avg. samples / sec: 53534.48
Iteration:   2660, Loss function: 4.304, Average Loss: 4.274, avg. samples / sec: 53707.86
Iteration:   2660, Loss function: 3.666, Average Loss: 4.256, avg. samples / sec: 53487.91
Iteration:   2660, Loss function: 3.647, Average Loss: 4.256, avg. samples / sec: 53590.87
Iteration:   2660, Loss function: 4.982, Average Loss: 4.259, avg. samples / sec: 53499.63
Iteration:   2660, Loss function: 3.110, Average Loss: 4.248, avg. samples / sec: 53472.93
Iteration:   2660, Loss function: 4.381, Average Loss: 4.272, avg. samples / sec: 53482.51
Iteration:   2660, Loss function: 4.153, Average Loss: 4.287, avg. samples / sec: 53441.24
Iteration:   2660, Loss function: 3.904, Average Loss: 4.285, avg. samples / sec: 53489.44
Iteration:   2660, Loss function: 4.595, Average Loss: 4.270, avg. samples / sec: 53633.50
Iteration:   2660, Loss function: 4.057, Average Loss: 4.248, avg. samples / sec: 53603.23
Iteration:   2660, Loss function: 3.853, Average Loss: 4.288, avg. samples / sec: 53566.53
Iteration:   2660, Loss function: 5.599, Average Loss: 4.259, avg. samples / sec: 53527.47
Iteration:   2660, Loss function: 3.964, Average Loss: 4.261, avg. samples / sec: 53510.46
Iteration:   2660, Loss function: 3.966, Average Loss: 4.275, avg. samples / sec: 53254.68
Iteration:   2660, Loss function: 3.662, Average Loss: 4.257, avg. samples / sec: 53468.61
Iteration:   2660, Loss function: 4.203, Average Loss: 4.265, avg. samples / sec: 53303.53
Iteration:   2660, Loss function: 3.539, Average Loss: 4.251, avg. samples / sec: 53539.28
Iteration:   2660, Loss function: 4.227, Average Loss: 4.294, avg. samples / sec: 53493.70
Iteration:   2660, Loss function: 4.452, Average Loss: 4.274, avg. samples / sec: 53481.54
Iteration:   2660, Loss function: 3.161, Average Loss: 4.274, avg. samples / sec: 53481.19
Iteration:   2660, Loss function: 3.029, Average Loss: 4.241, avg. samples / sec: 53485.27
Iteration:   2660, Loss function: 2.648, Average Loss: 4.288, avg. samples / sec: 53491.34
Iteration:   2660, Loss function: 3.144, Average Loss: 4.272, avg. samples / sec: 53436.80
Iteration:   2660, Loss function: 4.560, Average Loss: 4.258, avg. samples / sec: 53499.87
Iteration:   2660, Loss function: 4.244, Average Loss: 4.286, avg. samples / sec: 53441.97
Iteration:   2660, Loss function: 4.959, Average Loss: 4.267, avg. samples / sec: 53416.67
Iteration:   2660, Loss function: 4.520, Average Loss: 4.264, avg. samples / sec: 53473.83
Iteration:   2660, Loss function: 3.842, Average Loss: 4.289, avg. samples / sec: 53455.00
Iteration:   2680, Loss function: 2.672, Average Loss: 4.265, avg. samples / sec: 53676.11
Iteration:   2680, Loss function: 3.621, Average Loss: 4.241, avg. samples / sec: 53727.72
Iteration:   2680, Loss function: 2.930, Average Loss: 4.253, avg. samples / sec: 53704.71
Iteration:   2680, Loss function: 4.010, Average Loss: 4.253, avg. samples / sec: 53687.40
Iteration:   2680, Loss function: 3.735, Average Loss: 4.283, avg. samples / sec: 53725.02
Iteration:   2680, Loss function: 4.845, Average Loss: 4.268, avg. samples / sec: 53639.26
Iteration:   2680, Loss function: 4.567, Average Loss: 4.249, avg. samples / sec: 53644.60
Iteration:   2680, Loss function: 4.032, Average Loss: 4.268, avg. samples / sec: 53657.49
Iteration:   2680, Loss function: 4.167, Average Loss: 4.265, avg. samples / sec: 53559.51
Iteration:   2680, Loss function: 3.024, Average Loss: 4.279, avg. samples / sec: 53869.04
Iteration:   2680, Loss function: 4.460, Average Loss: 4.267, avg. samples / sec: 53747.47
Iteration:   2680, Loss function: 3.751, Average Loss: 4.254, avg. samples / sec: 53722.44
Iteration:   2680, Loss function: 4.604, Average Loss: 4.289, avg. samples / sec: 53734.38
Iteration:   2680, Loss function: 3.667, Average Loss: 4.253, avg. samples / sec: 53686.95
Iteration:   2680, Loss function: 4.394, Average Loss: 4.283, avg. samples / sec: 53634.17
Iteration:   2680, Loss function: 2.700, Average Loss: 4.265, avg. samples / sec: 53691.71
Iteration:   2680, Loss function: 4.320, Average Loss: 4.266, avg. samples / sec: 53721.86
Iteration:   2680, Loss function: 4.893, Average Loss: 4.276, avg. samples / sec: 53735.28
Iteration:   2680, Loss function: 4.897, Average Loss: 4.270, avg. samples / sec: 53701.39
Iteration:   2680, Loss function: 3.624, Average Loss: 4.241, avg. samples / sec: 53596.01
Iteration:   2680, Loss function: 3.350, Average Loss: 4.257, avg. samples / sec: 53646.40
Iteration:   2680, Loss function: 4.952, Average Loss: 4.282, avg. samples / sec: 53738.48
Iteration:   2680, Loss function: 4.244, Average Loss: 4.259, avg. samples / sec: 53721.25
Iteration:   2680, Loss function: 5.251, Average Loss: 4.263, avg. samples / sec: 53661.35
Iteration:   2680, Loss function: 3.525, Average Loss: 4.245, avg. samples / sec: 53659.15
Iteration:   2680, Loss function: 4.674, Average Loss: 4.257, avg. samples / sec: 53706.65
Iteration:   2680, Loss function: 4.564, Average Loss: 4.270, avg. samples / sec: 53674.23
Iteration:   2680, Loss function: 3.328, Average Loss: 4.237, avg. samples / sec: 53670.69
Iteration:   2680, Loss function: 4.787, Average Loss: 4.267, avg. samples / sec: 53687.36
Iteration:   2680, Loss function: 3.725, Average Loss: 4.279, avg. samples / sec: 53350.16
Iteration:   2700, Loss function: 4.145, Average Loss: 4.265, avg. samples / sec: 53820.34
Iteration:   2700, Loss function: 4.838, Average Loss: 4.239, avg. samples / sec: 53902.50
Iteration:   2700, Loss function: 5.278, Average Loss: 4.242, avg. samples / sec: 53950.72
Iteration:   2700, Loss function: 4.385, Average Loss: 4.246, avg. samples / sec: 53898.70
Iteration:   2700, Loss function: 3.891, Average Loss: 4.251, avg. samples / sec: 53880.07
Iteration:   2700, Loss function: 3.163, Average Loss: 4.274, avg. samples / sec: 53895.88
Iteration:   2700, Loss function: 3.430, Average Loss: 4.271, avg. samples / sec: 54299.80
Iteration:   2700, Loss function: 4.572, Average Loss: 4.266, avg. samples / sec: 53909.73
Iteration:   2700, Loss function: 3.434, Average Loss: 4.266, avg. samples / sec: 53870.00
Iteration:   2700, Loss function: 4.278, Average Loss: 4.270, avg. samples / sec: 53935.92
Iteration:   2700, Loss function: 4.182, Average Loss: 4.231, avg. samples / sec: 53963.43
Iteration:   2700, Loss function: 4.068, Average Loss: 4.257, avg. samples / sec: 53924.96
Iteration:   2700, Loss function: 4.516, Average Loss: 4.266, avg. samples / sec: 53736.71
Iteration:   2700, Loss function: 3.443, Average Loss: 4.279, avg. samples / sec: 53930.49
Iteration:   2700, Loss function: 4.177, Average Loss: 4.272, avg. samples / sec: 53761.00
Iteration:   2700, Loss function: 4.207, Average Loss: 4.240, avg. samples / sec: 53940.23
Iteration:   2700, Loss function: 3.380, Average Loss: 4.267, avg. samples / sec: 53917.12
Iteration:   2700, Loss function: 4.382, Average Loss: 4.249, avg. samples / sec: 53916.99
Iteration:   2700, Loss function: 4.805, Average Loss: 4.262, avg. samples / sec: 53882.90
Iteration:   2700, Loss function: 3.177, Average Loss: 4.244, avg. samples / sec: 53912.83
Iteration:   2700, Loss function: 2.883, Average Loss: 4.273, avg. samples / sec: 53879.62
Iteration:   2700, Loss function: 4.279, Average Loss: 4.255, avg. samples / sec: 53874.97
Iteration:   2700, Loss function: 3.421, Average Loss: 4.248, avg. samples / sec: 53925.37
Iteration:   2700, Loss function: 3.377, Average Loss: 4.255, avg. samples / sec: 53918.02
Iteration:   2700, Loss function: 3.659, Average Loss: 4.279, avg. samples / sec: 53860.64
Iteration:   2700, Loss function: 3.489, Average Loss: 4.245, avg. samples / sec: 53845.72
Iteration:   2700, Loss function: 3.408, Average Loss: 4.267, avg. samples / sec: 53923.06
Iteration:   2700, Loss function: 6.052, Average Loss: 4.257, avg. samples / sec: 53891.12
Iteration:   2700, Loss function: 4.047, Average Loss: 4.262, avg. samples / sec: 53912.91
Iteration:   2700, Loss function: 3.579, Average Loss: 4.262, avg. samples / sec: 53695.19
Iteration:   2720, Loss function: 4.255, Average Loss: 4.258, avg. samples / sec: 53814.71
Iteration:   2720, Loss function: 4.551, Average Loss: 4.244, avg. samples / sec: 53795.60
Iteration:   2720, Loss function: 3.614, Average Loss: 4.239, avg. samples / sec: 53738.02
Iteration:   2720, Loss function: 4.513, Average Loss: 4.235, avg. samples / sec: 53721.88
Iteration:   2720, Loss function: 3.716, Average Loss: 4.260, avg. samples / sec: 53814.77
Iteration:   2720, Loss function: 3.764, Average Loss: 4.274, avg. samples / sec: 53751.86
Iteration:   2720, Loss function: 4.172, Average Loss: 4.262, avg. samples / sec: 53762.17
Iteration:   2720, Loss function: 4.368, Average Loss: 4.266, avg. samples / sec: 53695.19
Iteration:   2720, Loss function: 4.139, Average Loss: 4.244, avg. samples / sec: 53594.19
Iteration:   2720, Loss function: 3.454, Average Loss: 4.257, avg. samples / sec: 53810.11
Iteration:   2720, Loss function: 5.015, Average Loss: 4.243, avg. samples / sec: 53815.61
Iteration:   2720, Loss function: 3.225, Average Loss: 4.274, avg. samples / sec: 53779.72
Iteration:   2720, Loss function: 5.340, Average Loss: 4.277, avg. samples / sec: 53797.95
Iteration:   2720, Loss function: 3.674, Average Loss: 4.262, avg. samples / sec: 53779.16
Iteration:   2720, Loss function: 3.847, Average Loss: 4.253, avg. samples / sec: 53751.82
Iteration:   2720, Loss function: 4.077, Average Loss: 4.272, avg. samples / sec: 53760.27
Iteration:   2720, Loss function: 3.882, Average Loss: 4.228, avg. samples / sec: 53743.27
Iteration:   2720, Loss function: 4.269, Average Loss: 4.255, avg. samples / sec: 53765.82
Iteration:   2720, Loss function: 4.132, Average Loss: 4.260, avg. samples / sec: 53753.01
Iteration:   2720, Loss function: 3.303, Average Loss: 4.255, avg. samples / sec: 53759.18
Iteration:   2720, Loss function: 3.803, Average Loss: 4.263, avg. samples / sec: 53762.95
Iteration:   2720, Loss function: 4.590, Average Loss: 4.262, avg. samples / sec: 53728.35
Iteration:   2720, Loss function: 5.717, Average Loss: 4.267, avg. samples / sec: 53716.91
Iteration:   2720, Loss function: 2.812, Average Loss: 4.236, avg. samples / sec: 53730.42
Iteration:   2720, Loss function: 3.203, Average Loss: 4.241, avg. samples / sec: 53735.07
Iteration:   2720, Loss function: 2.983, Average Loss: 4.244, avg. samples / sec: 53739.40
Iteration:   2720, Loss function: 4.049, Average Loss: 4.253, avg. samples / sec: 53761.95
Iteration:   2720, Loss function: 3.154, Average Loss: 4.239, avg. samples / sec: 53720.69
Iteration:   2720, Loss function: 4.795, Average Loss: 4.259, avg. samples / sec: 53749.99
Iteration:   2720, Loss function: 4.224, Average Loss: 4.260, avg. samples / sec: 53752.19
:::MLL 1558640940.500 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558640940.500 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 2.979, Average Loss: 4.257, avg. samples / sec: 53741.53
Iteration:   2740, Loss function: 3.347, Average Loss: 4.235, avg. samples / sec: 53717.28
Iteration:   2740, Loss function: 4.819, Average Loss: 4.271, avg. samples / sec: 53743.23
Iteration:   2740, Loss function: 3.950, Average Loss: 4.237, avg. samples / sec: 53705.14
Iteration:   2740, Loss function: 3.806, Average Loss: 4.243, avg. samples / sec: 53848.10
Iteration:   2740, Loss function: 4.626, Average Loss: 4.234, avg. samples / sec: 53675.82
Iteration:   2740, Loss function: 4.320, Average Loss: 4.260, avg. samples / sec: 53752.47
Iteration:   2740, Loss function: 4.470, Average Loss: 4.251, avg. samples / sec: 53662.25
Iteration:   2740, Loss function: 2.070, Average Loss: 4.260, avg. samples / sec: 53688.77
Iteration:   2740, Loss function: 3.712, Average Loss: 4.239, avg. samples / sec: 53697.05
Iteration:   2740, Loss function: 3.957, Average Loss: 4.268, avg. samples / sec: 53758.50
Iteration:   2740, Loss function: 4.183, Average Loss: 4.260, avg. samples / sec: 53731.92
Iteration:   2740, Loss function: 3.543, Average Loss: 4.256, avg. samples / sec: 53714.14
Iteration:   2740, Loss function: 5.009, Average Loss: 4.268, avg. samples / sec: 53690.28
Iteration:   2740, Loss function: 4.943, Average Loss: 4.244, avg. samples / sec: 53726.70
Iteration:   2740, Loss function: 3.603, Average Loss: 4.267, avg. samples / sec: 53711.81
Iteration:   2740, Loss function: 3.997, Average Loss: 4.248, avg. samples / sec: 53711.22
Iteration:   2740, Loss function: 4.008, Average Loss: 4.246, avg. samples / sec: 53700.74
Iteration:   2740, Loss function: 4.652, Average Loss: 4.261, avg. samples / sec: 53718.75
Iteration:   2740, Loss function: 4.189, Average Loss: 4.249, avg. samples / sec: 53655.23
Iteration:   2740, Loss function: 4.016, Average Loss: 4.233, avg. samples / sec: 53745.48
Iteration:   2740, Loss function: 3.917, Average Loss: 4.237, avg. samples / sec: 53724.65
Iteration:   2740, Loss function: 3.707, Average Loss: 4.219, avg. samples / sec: 53690.57
Iteration:   2740, Loss function: 3.873, Average Loss: 4.269, avg. samples / sec: 53669.14
Iteration:   2740, Loss function: 2.966, Average Loss: 4.243, avg. samples / sec: 53727.02
Iteration:   2740, Loss function: 4.101, Average Loss: 4.236, avg. samples / sec: 53703.62
Iteration:   2740, Loss function: 3.472, Average Loss: 4.227, avg. samples / sec: 53698.79
Iteration:   2740, Loss function: 3.891, Average Loss: 4.248, avg. samples / sec: 53725.92
Iteration:   2740, Loss function: 3.880, Average Loss: 4.252, avg. samples / sec: 53736.12
Iteration:   2740, Loss function: 2.825, Average Loss: 4.259, avg. samples / sec: 53655.59
Iteration:   2760, Loss function: 4.522, Average Loss: 4.256, avg. samples / sec: 54067.33
Iteration:   2760, Loss function: 3.740, Average Loss: 4.243, avg. samples / sec: 54075.59
Iteration:   2760, Loss function: 4.348, Average Loss: 4.234, avg. samples / sec: 54071.46
Iteration:   2760, Loss function: 4.929, Average Loss: 4.233, avg. samples / sec: 54017.95
Iteration:   2760, Loss function: 4.341, Average Loss: 4.245, avg. samples / sec: 54080.20
Iteration:   2760, Loss function: 4.244, Average Loss: 4.229, avg. samples / sec: 54044.65
Iteration:   2760, Loss function: 3.767, Average Loss: 4.257, avg. samples / sec: 54021.63
Iteration:   2760, Loss function: 3.600, Average Loss: 4.246, avg. samples / sec: 54166.65
Iteration:   2760, Loss function: 3.118, Average Loss: 4.264, avg. samples / sec: 53876.00
Iteration:   2760, Loss function: 4.006, Average Loss: 4.216, avg. samples / sec: 54129.34
Iteration:   2760, Loss function: 3.651, Average Loss: 4.247, avg. samples / sec: 54100.58
Iteration:   2760, Loss function: 3.448, Average Loss: 4.268, avg. samples / sec: 54066.21
Iteration:   2760, Loss function: 2.949, Average Loss: 4.236, avg. samples / sec: 54051.37
Iteration:   2760, Loss function: 3.685, Average Loss: 4.246, avg. samples / sec: 54133.27
Iteration:   2760, Loss function: 3.441, Average Loss: 4.252, avg. samples / sec: 54045.13
Iteration:   2760, Loss function: 3.933, Average Loss: 4.262, avg. samples / sec: 54032.43
Iteration:   2760, Loss function: 4.695, Average Loss: 4.255, avg. samples / sec: 54045.38
Iteration:   2760, Loss function: 3.242, Average Loss: 4.241, avg. samples / sec: 54046.81
Iteration:   2760, Loss function: 3.644, Average Loss: 4.232, avg. samples / sec: 54074.93
Iteration:   2760, Loss function: 3.903, Average Loss: 4.228, avg. samples / sec: 54081.07
Iteration:   2760, Loss function: 3.250, Average Loss: 4.245, avg. samples / sec: 54083.56
Iteration:   2760, Loss function: 4.303, Average Loss: 4.235, avg. samples / sec: 54052.84
Iteration:   2760, Loss function: 3.647, Average Loss: 4.259, avg. samples / sec: 54042.31
Iteration:   2760, Loss function: 4.349, Average Loss: 4.243, avg. samples / sec: 54023.81
Iteration:   2760, Loss function: 3.273, Average Loss: 4.263, avg. samples / sec: 54017.95
Iteration:   2760, Loss function: 3.581, Average Loss: 4.261, avg. samples / sec: 54026.98
Iteration:   2760, Loss function: 4.319, Average Loss: 4.248, avg. samples / sec: 54043.93
Iteration:   2760, Loss function: 3.996, Average Loss: 4.228, avg. samples / sec: 54013.81
Iteration:   2760, Loss function: 2.846, Average Loss: 4.237, avg. samples / sec: 54011.90
Iteration:   2760, Loss function: 3.228, Average Loss: 4.254, avg. samples / sec: 53808.63
Iteration:   2780, Loss function: 4.928, Average Loss: 4.251, avg. samples / sec: 53900.48
Iteration:   2780, Loss function: 4.138, Average Loss: 4.224, avg. samples / sec: 53971.86
Iteration:   2780, Loss function: 4.612, Average Loss: 4.229, avg. samples / sec: 53899.36
Iteration:   2780, Loss function: 3.323, Average Loss: 4.225, avg. samples / sec: 53897.26
Iteration:   2780, Loss function: 4.885, Average Loss: 4.245, avg. samples / sec: 53866.61
Iteration:   2780, Loss function: 3.059, Average Loss: 4.246, avg. samples / sec: 54185.62
Iteration:   2780, Loss function: 3.511, Average Loss: 4.242, avg. samples / sec: 53881.97
Iteration:   2780, Loss function: 3.369, Average Loss: 4.248, avg. samples / sec: 53927.02
Iteration:   2780, Loss function: 4.182, Average Loss: 4.260, avg. samples / sec: 54000.73
Iteration:   2780, Loss function: 4.020, Average Loss: 4.258, avg. samples / sec: 54026.17
Iteration:   2780, Loss function: 5.230, Average Loss: 4.230, avg. samples / sec: 53943.22
Iteration:   2780, Loss function: 3.587, Average Loss: 4.245, avg. samples / sec: 53921.66
Iteration:   2780, Loss function: 4.326, Average Loss: 4.242, avg. samples / sec: 53826.05
Iteration:   2780, Loss function: 4.122, Average Loss: 4.246, avg. samples / sec: 53924.05
Iteration:   2780, Loss function: 4.444, Average Loss: 4.230, avg. samples / sec: 53939.36
Iteration:   2780, Loss function: 6.083, Average Loss: 4.252, avg. samples / sec: 53925.97
Iteration:   2780, Loss function: 5.445, Average Loss: 4.239, avg. samples / sec: 53923.14
Iteration:   2780, Loss function: 4.413, Average Loss: 4.214, avg. samples / sec: 53863.54
Iteration:   2780, Loss function: 4.822, Average Loss: 4.264, avg. samples / sec: 53875.42
Iteration:   2780, Loss function: 3.875, Average Loss: 4.228, avg. samples / sec: 53917.78
Iteration:   2780, Loss function: 4.625, Average Loss: 4.225, avg. samples / sec: 53959.04
Iteration:   2780, Loss function: 4.568, Average Loss: 4.242, avg. samples / sec: 53889.41
Iteration:   2780, Loss function: 3.787, Average Loss: 4.256, avg. samples / sec: 53913.67
Iteration:   2780, Loss function: 3.516, Average Loss: 4.261, avg. samples / sec: 53936.14
Iteration:   2780, Loss function: 3.503, Average Loss: 4.232, avg. samples / sec: 53903.86
Iteration:   2780, Loss function: 3.406, Average Loss: 4.257, avg. samples / sec: 53884.09
Iteration:   2780, Loss function: 5.028, Average Loss: 4.238, avg. samples / sec: 53907.49
Iteration:   2780, Loss function: 4.207, Average Loss: 4.239, avg. samples / sec: 53940.40
Iteration:   2780, Loss function: 3.849, Average Loss: 4.242, avg. samples / sec: 53903.01
Iteration:   2780, Loss function: 3.724, Average Loss: 4.237, avg. samples / sec: 53860.72
:::MLL 1558640942.679 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558640942.680 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 4.547, Average Loss: 4.248, avg. samples / sec: 53792.77
Iteration:   2800, Loss function: 2.332, Average Loss: 4.216, avg. samples / sec: 53866.54
Iteration:   2800, Loss function: 3.597, Average Loss: 4.237, avg. samples / sec: 53893.47
Iteration:   2800, Loss function: 3.875, Average Loss: 4.238, avg. samples / sec: 53901.34
Iteration:   2800, Loss function: 3.698, Average Loss: 4.221, avg. samples / sec: 53857.44
Iteration:   2800, Loss function: 3.101, Average Loss: 4.241, avg. samples / sec: 53809.02
Iteration:   2800, Loss function: 4.948, Average Loss: 4.221, avg. samples / sec: 53732.12
Iteration:   2800, Loss function: 5.110, Average Loss: 4.252, avg. samples / sec: 53811.57
Iteration:   2800, Loss function: 4.461, Average Loss: 4.257, avg. samples / sec: 53941.82
Iteration:   2800, Loss function: 3.633, Average Loss: 4.241, avg. samples / sec: 53715.39
Iteration:   2800, Loss function: 3.680, Average Loss: 4.226, avg. samples / sec: 53860.51
Iteration:   2800, Loss function: 4.688, Average Loss: 4.232, avg. samples / sec: 53884.94
Iteration:   2800, Loss function: 4.896, Average Loss: 4.240, avg. samples / sec: 53779.53
Iteration:   2800, Loss function: 4.116, Average Loss: 4.228, avg. samples / sec: 53767.34
Iteration:   2800, Loss function: 2.606, Average Loss: 4.225, avg. samples / sec: 53826.45
Iteration:   2800, Loss function: 4.321, Average Loss: 4.239, avg. samples / sec: 53823.79
Iteration:   2800, Loss function: 3.554, Average Loss: 4.245, avg. samples / sec: 53778.57
Iteration:   2800, Loss function: 3.961, Average Loss: 4.233, avg. samples / sec: 53827.06
Iteration:   2800, Loss function: 3.483, Average Loss: 4.209, avg. samples / sec: 53778.91
Iteration:   2800, Loss function: 4.435, Average Loss: 4.235, avg. samples / sec: 53768.84
Iteration:   2800, Loss function: 2.803, Average Loss: 4.255, avg. samples / sec: 53690.32
Iteration:   2800, Loss function: 4.078, Average Loss: 4.255, avg. samples / sec: 53793.39
Iteration:   2800, Loss function: 4.281, Average Loss: 4.246, avg. samples / sec: 53761.13
Iteration:   2800, Loss function: 4.393, Average Loss: 4.240, avg. samples / sec: 53731.12
Iteration:   2800, Loss function: 4.378, Average Loss: 4.252, avg. samples / sec: 53764.55
Iteration:   2800, Loss function: 3.532, Average Loss: 4.221, avg. samples / sec: 53748.62
Iteration:   2800, Loss function: 3.814, Average Loss: 4.236, avg. samples / sec: 53770.05
Iteration:   2800, Loss function: 4.739, Average Loss: 4.228, avg. samples / sec: 53720.29
Iteration:   2800, Loss function: 4.014, Average Loss: 4.233, avg. samples / sec: 53802.65
Iteration:   2800, Loss function: 4.478, Average Loss: 4.249, avg. samples / sec: 53732.19
Iteration:   2820, Loss function: 3.729, Average Loss: 4.244, avg. samples / sec: 54118.47
Iteration:   2820, Loss function: 3.747, Average Loss: 4.214, avg. samples / sec: 54177.68
Iteration:   2820, Loss function: 4.766, Average Loss: 4.218, avg. samples / sec: 54067.19
Iteration:   2820, Loss function: 2.946, Average Loss: 4.212, avg. samples / sec: 54035.18
Iteration:   2820, Loss function: 4.368, Average Loss: 4.253, avg. samples / sec: 54137.74
Iteration:   2820, Loss function: 4.569, Average Loss: 4.238, avg. samples / sec: 54187.89
Iteration:   2820, Loss function: 5.595, Average Loss: 4.231, avg. samples / sec: 54333.42
Iteration:   2820, Loss function: 4.950, Average Loss: 4.235, avg. samples / sec: 53959.75
Iteration:   2820, Loss function: 4.088, Average Loss: 4.221, avg. samples / sec: 54120.70
Iteration:   2820, Loss function: 3.609, Average Loss: 4.250, avg. samples / sec: 54157.99
Iteration:   2820, Loss function: 5.544, Average Loss: 4.227, avg. samples / sec: 54105.98
Iteration:   2820, Loss function: 4.047, Average Loss: 4.230, avg. samples / sec: 53809.24
Iteration:   2820, Loss function: 4.468, Average Loss: 4.238, avg. samples / sec: 54148.71
Iteration:   2820, Loss function: 3.264, Average Loss: 4.250, avg. samples / sec: 54145.02
Iteration:   2820, Loss function: 2.679, Average Loss: 4.234, avg. samples / sec: 54153.37
Iteration:   2820, Loss function: 5.133, Average Loss: 4.242, avg. samples / sec: 54133.79
Iteration:   2820, Loss function: 3.771, Average Loss: 4.236, avg. samples / sec: 54072.46
Iteration:   2820, Loss function: 3.733, Average Loss: 4.198, avg. samples / sec: 54121.63
Iteration:   2820, Loss function: 4.544, Average Loss: 4.245, avg. samples / sec: 54102.54
Iteration:   2820, Loss function: 4.613, Average Loss: 4.252, avg. samples / sec: 53958.59
Iteration:   2820, Loss function: 4.018, Average Loss: 4.248, avg. samples / sec: 54195.08
Iteration:   2820, Loss function: 3.870, Average Loss: 4.236, avg. samples / sec: 54079.45
Iteration:   2820, Loss function: 4.192, Average Loss: 4.223, avg. samples / sec: 54133.04
Iteration:   2820, Loss function: 4.178, Average Loss: 4.222, avg. samples / sec: 54137.99
Iteration:   2820, Loss function: 3.360, Average Loss: 4.222, avg. samples / sec: 54031.99
Iteration:   2820, Loss function: 4.693, Average Loss: 4.246, avg. samples / sec: 54117.91
Iteration:   2820, Loss function: 3.806, Average Loss: 4.236, avg. samples / sec: 54065.36
Iteration:   2820, Loss function: 4.553, Average Loss: 4.240, avg. samples / sec: 53842.16
Iteration:   2820, Loss function: 3.970, Average Loss: 4.232, avg. samples / sec: 54106.30
Iteration:   2820, Loss function: 3.745, Average Loss: 4.230, avg. samples / sec: 54009.34
Iteration:   2840, Loss function: 3.628, Average Loss: 4.239, avg. samples / sec: 54131.07
Iteration:   2840, Loss function: 4.428, Average Loss: 4.246, avg. samples / sec: 54169.27
Iteration:   2840, Loss function: 4.747, Average Loss: 4.217, avg. samples / sec: 54113.01
Iteration:   2840, Loss function: 4.794, Average Loss: 4.213, avg. samples / sec: 54130.80
Iteration:   2840, Loss function: 4.488, Average Loss: 4.213, avg. samples / sec: 54109.27
Iteration:   2840, Loss function: 4.498, Average Loss: 4.229, avg. samples / sec: 54209.15
Iteration:   2840, Loss function: 3.861, Average Loss: 4.236, avg. samples / sec: 54417.05
Iteration:   2840, Loss function: 3.800, Average Loss: 4.231, avg. samples / sec: 54132.44
Iteration:   2840, Loss function: 2.577, Average Loss: 4.249, avg. samples / sec: 54333.84
Iteration:   2840, Loss function: 4.191, Average Loss: 4.243, avg. samples / sec: 54201.96
Iteration:   2840, Loss function: 3.368, Average Loss: 4.219, avg. samples / sec: 54251.01
Iteration:   2840, Loss function: 3.776, Average Loss: 4.243, avg. samples / sec: 54187.16
Iteration:   2840, Loss function: 3.845, Average Loss: 4.244, avg. samples / sec: 54163.36
Iteration:   2840, Loss function: 3.489, Average Loss: 4.237, avg. samples / sec: 54169.25
Iteration:   2840, Loss function: 3.358, Average Loss: 4.220, avg. samples / sec: 54138.37
Iteration:   2840, Loss function: 4.474, Average Loss: 4.230, avg. samples / sec: 54130.94
Iteration:   2840, Loss function: 3.199, Average Loss: 4.244, avg. samples / sec: 54119.49
Iteration:   2840, Loss function: 4.281, Average Loss: 4.220, avg. samples / sec: 54186.58
Iteration:   2840, Loss function: 4.989, Average Loss: 4.238, avg. samples / sec: 54157.13
Iteration:   2840, Loss function: 3.766, Average Loss: 4.191, avg. samples / sec: 54144.67
Iteration:   2840, Loss function: 3.280, Average Loss: 4.231, avg. samples / sec: 54141.11
Iteration:   2840, Loss function: 3.942, Average Loss: 4.215, avg. samples / sec: 54097.76
Iteration:   2840, Loss function: 4.430, Average Loss: 4.221, avg. samples / sec: 54118.39
Iteration:   2840, Loss function: 5.199, Average Loss: 4.234, avg. samples / sec: 54131.11
Iteration:   2840, Loss function: 3.869, Average Loss: 4.228, avg. samples / sec: 53958.32
Iteration:   2840, Loss function: 3.914, Average Loss: 4.218, avg. samples / sec: 54151.24
Iteration:   2840, Loss function: 4.679, Average Loss: 4.233, avg. samples / sec: 54158.59
Iteration:   2840, Loss function: 3.492, Average Loss: 4.211, avg. samples / sec: 54144.19
Iteration:   2840, Loss function: 4.086, Average Loss: 4.243, avg. samples / sec: 54149.68
Iteration:   2840, Loss function: 4.205, Average Loss: 4.222, avg. samples / sec: 54129.11
Iteration:   2860, Loss function: 4.603, Average Loss: 4.232, avg. samples / sec: 54093.61
Iteration:   2860, Loss function: 3.810, Average Loss: 4.212, avg. samples / sec: 54116.02
Iteration:   2860, Loss function: 4.170, Average Loss: 4.221, avg. samples / sec: 54128.43
Iteration:   2860, Loss function: 3.994, Average Loss: 4.210, avg. samples / sec: 54085.84
Iteration:   2860, Loss function: 5.420, Average Loss: 4.238, avg. samples / sec: 54085.43
Iteration:   2860, Loss function: 5.950, Average Loss: 4.207, avg. samples / sec: 54066.11
Iteration:   2860, Loss function: 3.919, Average Loss: 4.245, avg. samples / sec: 54036.63
Iteration:   2860, Loss function: 4.083, Average Loss: 4.227, avg. samples / sec: 54076.09
Iteration:   2860, Loss function: 4.794, Average Loss: 4.218, avg. samples / sec: 54111.45
Iteration:   2860, Loss function: 2.890, Average Loss: 4.228, avg. samples / sec: 54117.66
Iteration:   2860, Loss function: 3.306, Average Loss: 4.221, avg. samples / sec: 54103.68
Iteration:   2860, Loss function: 4.403, Average Loss: 4.219, avg. samples / sec: 54115.33
Iteration:   2860, Loss function: 3.594, Average Loss: 4.243, avg. samples / sec: 53913.98
Iteration:   2860, Loss function: 3.650, Average Loss: 4.239, avg. samples / sec: 54102.99
Iteration:   2860, Loss function: 4.123, Average Loss: 4.234, avg. samples / sec: 54079.80
Iteration:   2860, Loss function: 4.549, Average Loss: 4.240, avg. samples / sec: 54040.61
Iteration:   2860, Loss function: 5.076, Average Loss: 4.241, avg. samples / sec: 54056.22
Iteration:   2860, Loss function: 3.842, Average Loss: 4.206, avg. samples / sec: 54122.92
Iteration:   2860, Loss function: 3.208, Average Loss: 4.217, avg. samples / sec: 54108.39
Iteration:   2860, Loss function: 3.651, Average Loss: 4.239, avg. samples / sec: 54056.34
Iteration:   2860, Loss function: 4.056, Average Loss: 4.236, avg. samples / sec: 54076.40
Iteration:   2860, Loss function: 4.884, Average Loss: 4.219, avg. samples / sec: 54149.81
Iteration:   2860, Loss function: 3.913, Average Loss: 4.231, avg. samples / sec: 54092.86
Iteration:   2860, Loss function: 4.044, Average Loss: 4.233, avg. samples / sec: 54107.90
Iteration:   2860, Loss function: 3.795, Average Loss: 4.186, avg. samples / sec: 54068.31
Iteration:   2860, Loss function: 3.365, Average Loss: 4.229, avg. samples / sec: 54086.53
Iteration:   2860, Loss function: 5.450, Average Loss: 4.215, avg. samples / sec: 54015.53
Iteration:   2860, Loss function: 2.982, Average Loss: 4.205, avg. samples / sec: 54062.96
Iteration:   2860, Loss function: 4.695, Average Loss: 4.216, avg. samples / sec: 54042.74
Iteration:   2860, Loss function: 2.898, Average Loss: 4.241, avg. samples / sec: 53906.31
:::MLL 1558640944.856 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558640944.857 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 3.764, Average Loss: 4.224, avg. samples / sec: 53806.55
Iteration:   2880, Loss function: 4.311, Average Loss: 4.210, avg. samples / sec: 53852.11
Iteration:   2880, Loss function: 4.292, Average Loss: 4.209, avg. samples / sec: 53808.59
Iteration:   2880, Loss function: 4.409, Average Loss: 4.204, avg. samples / sec: 53854.77
Iteration:   2880, Loss function: 3.476, Average Loss: 4.237, avg. samples / sec: 53857.12
Iteration:   2880, Loss function: 4.159, Average Loss: 4.216, avg. samples / sec: 53777.72
Iteration:   2880, Loss function: 3.172, Average Loss: 4.237, avg. samples / sec: 53780.56
Iteration:   2880, Loss function: 4.201, Average Loss: 4.219, avg. samples / sec: 53825.89
Iteration:   2880, Loss function: 4.561, Average Loss: 4.235, avg. samples / sec: 53832.72
Iteration:   2880, Loss function: 3.451, Average Loss: 4.218, avg. samples / sec: 53815.63
Iteration:   2880, Loss function: 2.994, Average Loss: 4.239, avg. samples / sec: 54011.39
Iteration:   2880, Loss function: 4.538, Average Loss: 4.221, avg. samples / sec: 53786.51
Iteration:   2880, Loss function: 4.394, Average Loss: 4.227, avg. samples / sec: 53837.12
Iteration:   2880, Loss function: 3.529, Average Loss: 4.237, avg. samples / sec: 53826.49
Iteration:   2880, Loss function: 5.233, Average Loss: 4.221, avg. samples / sec: 53800.62
Iteration:   2880, Loss function: 3.860, Average Loss: 4.235, avg. samples / sec: 53816.04
Iteration:   2880, Loss function: 3.948, Average Loss: 4.210, avg. samples / sec: 53820.30
Iteration:   2880, Loss function: 3.581, Average Loss: 4.227, avg. samples / sec: 53805.61
Iteration:   2880, Loss function: 2.500, Average Loss: 4.201, avg. samples / sec: 53806.90
Iteration:   2880, Loss function: 4.119, Average Loss: 4.224, avg. samples / sec: 53626.60
Iteration:   2880, Loss function: 4.571, Average Loss: 4.182, avg. samples / sec: 53826.67
Iteration:   2880, Loss function: 3.699, Average Loss: 4.202, avg. samples / sec: 53834.57
Iteration:   2880, Loss function: 3.787, Average Loss: 4.237, avg. samples / sec: 53786.02
Iteration:   2880, Loss function: 3.353, Average Loss: 4.217, avg. samples / sec: 53807.23
Iteration:   2880, Loss function: 5.071, Average Loss: 4.230, avg. samples / sec: 53810.43
Iteration:   2880, Loss function: 3.711, Average Loss: 4.226, avg. samples / sec: 53823.38
Iteration:   2880, Loss function: 2.909, Average Loss: 4.236, avg. samples / sec: 53777.17
Iteration:   2880, Loss function: 3.911, Average Loss: 4.221, avg. samples / sec: 53793.98
Iteration:   2880, Loss function: 4.378, Average Loss: 4.208, avg. samples / sec: 53820.18
Iteration:   2880, Loss function: 4.314, Average Loss: 4.209, avg. samples / sec: 53785.28
Iteration:   2900, Loss function: 4.688, Average Loss: 4.218, avg. samples / sec: 54078.79
Iteration:   2900, Loss function: 4.446, Average Loss: 4.207, avg. samples / sec: 54041.17
Iteration:   2900, Loss function: 4.061, Average Loss: 4.199, avg. samples / sec: 54052.86
Iteration:   2900, Loss function: 3.838, Average Loss: 4.230, avg. samples / sec: 54114.30
Iteration:   2900, Loss function: 3.683, Average Loss: 4.208, avg. samples / sec: 54054.87
Iteration:   2900, Loss function: 3.724, Average Loss: 4.233, avg. samples / sec: 54047.10
Iteration:   2900, Loss function: 5.383, Average Loss: 4.204, avg. samples / sec: 53981.12
Iteration:   2900, Loss function: 5.584, Average Loss: 4.218, avg. samples / sec: 54069.01
Iteration:   2900, Loss function: 3.510, Average Loss: 4.235, avg. samples / sec: 54058.52
Iteration:   2900, Loss function: 5.016, Average Loss: 4.218, avg. samples / sec: 54062.81
Iteration:   2900, Loss function: 4.001, Average Loss: 4.222, avg. samples / sec: 54048.61
Iteration:   2900, Loss function: 4.574, Average Loss: 4.220, avg. samples / sec: 54027.29
Iteration:   2900, Loss function: 4.174, Average Loss: 4.214, avg. samples / sec: 54032.67
Iteration:   2900, Loss function: 4.985, Average Loss: 4.229, avg. samples / sec: 54026.65
Iteration:   2900, Loss function: 3.490, Average Loss: 4.223, avg. samples / sec: 54037.98
Iteration:   2900, Loss function: 3.650, Average Loss: 4.180, avg. samples / sec: 54057.59
Iteration:   2900, Loss function: 4.560, Average Loss: 4.219, avg. samples / sec: 54047.49
Iteration:   2900, Loss function: 3.519, Average Loss: 4.194, avg. samples / sec: 54044.28
Iteration:   2900, Loss function: 4.762, Average Loss: 4.213, avg. samples / sec: 54058.77
Iteration:   2900, Loss function: 2.632, Average Loss: 4.199, avg. samples / sec: 54075.34
Iteration:   2900, Loss function: 3.439, Average Loss: 4.233, avg. samples / sec: 54063.43
Iteration:   2900, Loss function: 4.243, Average Loss: 4.232, avg. samples / sec: 54050.64
Iteration:   2900, Loss function: 3.637, Average Loss: 4.230, avg. samples / sec: 54023.42
Iteration:   2900, Loss function: 4.938, Average Loss: 4.223, avg. samples / sec: 54047.28
Iteration:   2900, Loss function: 3.856, Average Loss: 4.216, avg. samples / sec: 54056.53
Iteration:   2900, Loss function: 4.703, Average Loss: 4.237, avg. samples / sec: 54039.78
Iteration:   2900, Loss function: 3.189, Average Loss: 4.228, avg. samples / sec: 54007.89
Iteration:   2900, Loss function: 3.882, Average Loss: 4.200, avg. samples / sec: 54031.74
Iteration:   2900, Loss function: 2.372, Average Loss: 4.202, avg. samples / sec: 54007.91
Iteration:   2900, Loss function: 5.447, Average Loss: 4.211, avg. samples / sec: 54072.81
Iteration:   2920, Loss function: 3.836, Average Loss: 4.214, avg. samples / sec: 54065.51
Iteration:   2920, Loss function: 4.037, Average Loss: 4.226, avg. samples / sec: 54101.50
Iteration:   2920, Loss function: 4.303, Average Loss: 4.228, avg. samples / sec: 54103.68
Iteration:   2920, Loss function: 2.851, Average Loss: 4.201, avg. samples / sec: 54130.57
Iteration:   2920, Loss function: 3.544, Average Loss: 4.205, avg. samples / sec: 54092.76
Iteration:   2920, Loss function: 5.114, Average Loss: 4.204, avg. samples / sec: 54052.09
Iteration:   2920, Loss function: 3.092, Average Loss: 4.218, avg. samples / sec: 54145.88
Iteration:   2920, Loss function: 3.643, Average Loss: 4.196, avg. samples / sec: 53885.27
Iteration:   2920, Loss function: 4.444, Average Loss: 4.214, avg. samples / sec: 54109.06
Iteration:   2920, Loss function: 3.066, Average Loss: 4.221, avg. samples / sec: 54126.16
Iteration:   2920, Loss function: 4.090, Average Loss: 4.236, avg. samples / sec: 54163.71
Iteration:   2920, Loss function: 5.068, Average Loss: 4.214, avg. samples / sec: 54103.72
Iteration:   2920, Loss function: 3.766, Average Loss: 4.216, avg. samples / sec: 54095.46
Iteration:   2920, Loss function: 5.451, Average Loss: 4.227, avg. samples / sec: 54129.70
Iteration:   2920, Loss function: 3.649, Average Loss: 4.213, avg. samples / sec: 54114.44
Iteration:   2920, Loss function: 4.877, Average Loss: 4.227, avg. samples / sec: 54082.13
Iteration:   2920, Loss function: 3.897, Average Loss: 4.223, avg. samples / sec: 54119.64
Iteration:   2920, Loss function: 4.441, Average Loss: 4.229, avg. samples / sec: 54100.48
Iteration:   2920, Loss function: 3.045, Average Loss: 4.229, avg. samples / sec: 54117.16
Iteration:   2920, Loss function: 3.841, Average Loss: 4.222, avg. samples / sec: 54121.44
Iteration:   2920, Loss function: 3.627, Average Loss: 4.213, avg. samples / sec: 54121.86
Iteration:   2920, Loss function: 4.153, Average Loss: 4.217, avg. samples / sec: 54075.36
Iteration:   2920, Loss function: 4.541, Average Loss: 4.208, avg. samples / sec: 54124.92
Iteration:   2920, Loss function: 2.787, Average Loss: 4.217, avg. samples / sec: 54103.26
Iteration:   2920, Loss function: 3.339, Average Loss: 4.191, avg. samples / sec: 54086.82
Iteration:   2920, Loss function: 2.479, Average Loss: 4.177, avg. samples / sec: 54079.20
Iteration:   2920, Loss function: 4.325, Average Loss: 4.208, avg. samples / sec: 54083.79
Iteration:   2920, Loss function: 3.937, Average Loss: 4.191, avg. samples / sec: 54095.91
Iteration:   2920, Loss function: 3.818, Average Loss: 4.196, avg. samples / sec: 54098.74
Iteration:   2920, Loss function: 3.946, Average Loss: 4.197, avg. samples / sec: 54069.03
:::MLL 1558640947.034 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558640947.035 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 5.312, Average Loss: 4.201, avg. samples / sec: 53949.27
Iteration:   2940, Loss function: 4.926, Average Loss: 4.208, avg. samples / sec: 53731.02
Iteration:   2940, Loss function: 4.666, Average Loss: 4.226, avg. samples / sec: 53812.67
Iteration:   2940, Loss function: 3.464, Average Loss: 4.196, avg. samples / sec: 53808.44
Iteration:   2940, Loss function: 3.502, Average Loss: 4.201, avg. samples / sec: 53829.73
Iteration:   2940, Loss function: 3.443, Average Loss: 4.213, avg. samples / sec: 54013.77
Iteration:   2940, Loss function: 4.403, Average Loss: 4.220, avg. samples / sec: 53740.28
Iteration:   2940, Loss function: 3.369, Average Loss: 4.192, avg. samples / sec: 53940.58
Iteration:   2940, Loss function: 4.921, Average Loss: 4.212, avg. samples / sec: 53874.49
Iteration:   2940, Loss function: 4.333, Average Loss: 4.190, avg. samples / sec: 53904.06
Iteration:   2940, Loss function: 4.660, Average Loss: 4.199, avg. samples / sec: 53864.96
Iteration:   2940, Loss function: 4.173, Average Loss: 4.215, avg. samples / sec: 53855.35
Iteration:   2940, Loss function: 3.279, Average Loss: 4.224, avg. samples / sec: 53828.46
Iteration:   2940, Loss function: 3.934, Average Loss: 4.223, avg. samples / sec: 53818.02
Iteration:   2940, Loss function: 4.061, Average Loss: 4.219, avg. samples / sec: 53821.88
Iteration:   2940, Loss function: 3.093, Average Loss: 4.213, avg. samples / sec: 53817.07
Iteration:   2940, Loss function: 4.574, Average Loss: 4.223, avg. samples / sec: 53791.44
Iteration:   2940, Loss function: 3.532, Average Loss: 4.215, avg. samples / sec: 53761.93
Iteration:   2940, Loss function: 3.810, Average Loss: 4.205, avg. samples / sec: 53768.08
Iteration:   2940, Loss function: 3.758, Average Loss: 4.192, avg. samples / sec: 53753.95
Iteration:   2940, Loss function: 3.764, Average Loss: 4.180, avg. samples / sec: 53824.31
Iteration:   2940, Loss function: 3.816, Average Loss: 4.215, avg. samples / sec: 53801.01
Iteration:   2940, Loss function: 4.271, Average Loss: 4.221, avg. samples / sec: 53776.68
Iteration:   2940, Loss function: 4.473, Average Loss: 4.212, avg. samples / sec: 53788.38
Iteration:   2940, Loss function: 4.493, Average Loss: 4.192, avg. samples / sec: 53799.38
Iteration:   2940, Loss function: 3.731, Average Loss: 4.176, avg. samples / sec: 53777.23
Iteration:   2940, Loss function: 4.806, Average Loss: 4.207, avg. samples / sec: 53772.27
Iteration:   2940, Loss function: 4.382, Average Loss: 4.225, avg. samples / sec: 53746.61
Iteration:   2940, Loss function: 4.755, Average Loss: 4.209, avg. samples / sec: 53733.60
Iteration:   2940, Loss function: 4.401, Average Loss: 4.228, avg. samples / sec: 53679.44
Iteration:   2960, Loss function: 2.589, Average Loss: 4.201, avg. samples / sec: 54151.54
Iteration:   2960, Loss function: 3.452, Average Loss: 4.218, avg. samples / sec: 54150.70
Iteration:   2960, Loss function: 4.663, Average Loss: 4.191, avg. samples / sec: 54139.74
Iteration:   2960, Loss function: 4.100, Average Loss: 4.196, avg. samples / sec: 54123.59
Iteration:   2960, Loss function: 3.464, Average Loss: 4.198, avg. samples / sec: 53969.21
Iteration:   2960, Loss function: 4.187, Average Loss: 4.169, avg. samples / sec: 54389.16
Iteration:   2960, Loss function: 4.066, Average Loss: 4.210, avg. samples / sec: 54178.00
Iteration:   2960, Loss function: 4.937, Average Loss: 4.200, avg. samples / sec: 54176.12
Iteration:   2960, Loss function: 5.384, Average Loss: 4.208, avg. samples / sec: 54193.29
Iteration:   2960, Loss function: 3.864, Average Loss: 4.214, avg. samples / sec: 54156.32
Iteration:   2960, Loss function: 4.376, Average Loss: 4.192, avg. samples / sec: 54110.29
Iteration:   2960, Loss function: 3.449, Average Loss: 4.211, avg. samples / sec: 54179.56
Iteration:   2960, Loss function: 2.799, Average Loss: 4.207, avg. samples / sec: 54167.40
Iteration:   2960, Loss function: 3.770, Average Loss: 4.218, avg. samples / sec: 54133.56
Iteration:   2960, Loss function: 5.050, Average Loss: 4.222, avg. samples / sec: 54127.87
Iteration:   2960, Loss function: 3.937, Average Loss: 4.211, avg. samples / sec: 54128.72
Iteration:   2960, Loss function: 3.714, Average Loss: 4.216, avg. samples / sec: 54123.83
Iteration:   2960, Loss function: 3.551, Average Loss: 4.183, avg. samples / sec: 54049.79
Iteration:   2960, Loss function: 3.884, Average Loss: 4.212, avg. samples / sec: 53919.94
Iteration:   2960, Loss function: 4.374, Average Loss: 4.215, avg. samples / sec: 53941.10
Iteration:   2960, Loss function: 5.494, Average Loss: 4.188, avg. samples / sec: 54134.33
Iteration:   2960, Loss function: 3.345, Average Loss: 4.174, avg. samples / sec: 54133.54
Iteration:   2960, Loss function: 4.370, Average Loss: 4.188, avg. samples / sec: 54159.24
Iteration:   2960, Loss function: 3.752, Average Loss: 4.224, avg. samples / sec: 54200.10
Iteration:   2960, Loss function: 2.932, Average Loss: 4.208, avg. samples / sec: 54070.47
Iteration:   2960, Loss function: 3.874, Average Loss: 4.225, avg. samples / sec: 54162.38
Iteration:   2960, Loss function: 3.757, Average Loss: 4.208, avg. samples / sec: 54022.15
Iteration:   2960, Loss function: 4.164, Average Loss: 4.206, avg. samples / sec: 54160.63
Iteration:   2960, Loss function: 4.245, Average Loss: 4.189, avg. samples / sec: 54020.79
Iteration:   2960, Loss function: 3.672, Average Loss: 4.203, avg. samples / sec: 54160.01
Iteration:   2980, Loss function: 3.034, Average Loss: 4.196, avg. samples / sec: 54188.77
Iteration:   2980, Loss function: 4.379, Average Loss: 4.191, avg. samples / sec: 54199.33
Iteration:   2980, Loss function: 4.692, Average Loss: 4.192, avg. samples / sec: 54178.25
Iteration:   2980, Loss function: 3.585, Average Loss: 4.210, avg. samples / sec: 54381.85
Iteration:   2980, Loss function: 4.735, Average Loss: 4.183, avg. samples / sec: 54099.48
Iteration:   2980, Loss function: 3.180, Average Loss: 4.213, avg. samples / sec: 54055.20
Iteration:   2980, Loss function: 4.374, Average Loss: 4.197, avg. samples / sec: 54152.78
Iteration:   2980, Loss function: 4.079, Average Loss: 4.206, avg. samples / sec: 54171.14
Iteration:   2980, Loss function: 3.587, Average Loss: 4.185, avg. samples / sec: 54170.85
Iteration:   2980, Loss function: 4.670, Average Loss: 4.212, avg. samples / sec: 54142.49
Iteration:   2980, Loss function: 3.365, Average Loss: 4.219, avg. samples / sec: 54196.60
Iteration:   2980, Loss function: 3.933, Average Loss: 4.180, avg. samples / sec: 54153.30
Iteration:   2980, Loss function: 3.505, Average Loss: 4.203, avg. samples / sec: 54138.20
Iteration:   2980, Loss function: 4.433, Average Loss: 4.215, avg. samples / sec: 54149.52
Iteration:   2980, Loss function: 4.356, Average Loss: 4.197, avg. samples / sec: 54135.66
Iteration:   2980, Loss function: 4.086, Average Loss: 4.209, avg. samples / sec: 54121.15
Iteration:   2980, Loss function: 4.972, Average Loss: 4.201, avg. samples / sec: 54108.10
Iteration:   2980, Loss function: 3.726, Average Loss: 4.202, avg. samples / sec: 54073.81
Iteration:   2980, Loss function: 3.847, Average Loss: 4.162, avg. samples / sec: 53943.91
Iteration:   2980, Loss function: 4.524, Average Loss: 4.202, avg. samples / sec: 54169.00
Iteration:   2980, Loss function: 4.306, Average Loss: 4.216, avg. samples / sec: 54115.81
Iteration:   2980, Loss function: 3.662, Average Loss: 4.182, avg. samples / sec: 54139.78
Iteration:   2980, Loss function: 3.941, Average Loss: 4.198, avg. samples / sec: 54170.35
Iteration:   2980, Loss function: 3.953, Average Loss: 4.216, avg. samples / sec: 54151.14
Iteration:   2980, Loss function: 3.284, Average Loss: 4.187, avg. samples / sec: 54158.24
Iteration:   2980, Loss function: 4.252, Average Loss: 4.175, avg. samples / sec: 54111.84
Iteration:   2980, Loss function: 4.941, Average Loss: 4.206, avg. samples / sec: 54140.20
Iteration:   2980, Loss function: 3.963, Average Loss: 4.204, avg. samples / sec: 54124.15
Iteration:   2980, Loss function: 4.565, Average Loss: 4.189, avg. samples / sec: 54052.40
Iteration:   2980, Loss function: 5.020, Average Loss: 4.210, avg. samples / sec: 54054.29
Iteration:   3000, Loss function: 3.915, Average Loss: 4.191, avg. samples / sec: 53540.97
Iteration:   3000, Loss function: 3.995, Average Loss: 4.210, avg. samples / sec: 53611.28
Iteration:   3000, Loss function: 2.857, Average Loss: 4.178, avg. samples / sec: 53472.89
Iteration:   3000, Loss function: 5.019, Average Loss: 4.191, avg. samples / sec: 53515.41
Iteration:   3000, Loss function: 2.929, Average Loss: 4.181, avg. samples / sec: 53520.98
Iteration:   3000, Loss function: 2.842, Average Loss: 4.206, avg. samples / sec: 53498.59
Iteration:   3000, Loss function: 3.115, Average Loss: 4.191, avg. samples / sec: 53585.17
Iteration:   3000, Loss function: 2.763, Average Loss: 4.201, avg. samples / sec: 53542.58
Iteration:   3000, Loss function: 3.606, Average Loss: 4.201, avg. samples / sec: 53514.50
Iteration:   3000, Loss function: 4.254, Average Loss: 4.193, avg. samples / sec: 53533.34
Iteration:   3000, Loss function: 3.845, Average Loss: 4.194, avg. samples / sec: 53543.76
Iteration:   3000, Loss function: 4.146, Average Loss: 4.197, avg. samples / sec: 53527.77
Iteration:   3000, Loss function: 4.363, Average Loss: 4.200, avg. samples / sec: 53545.95
Iteration:   3000, Loss function: 2.786, Average Loss: 4.179, avg. samples / sec: 53558.63
Iteration:   3000, Loss function: 3.623, Average Loss: 4.212, avg. samples / sec: 53515.90
Iteration:   3000, Loss function: 4.466, Average Loss: 4.196, avg. samples / sec: 53539.36
Iteration:   3000, Loss function: 4.083, Average Loss: 4.212, avg. samples / sec: 53505.74
Iteration:   3000, Loss function: 4.481, Average Loss: 4.189, avg. samples / sec: 53469.99
Iteration:   3000, Loss function: 4.147, Average Loss: 4.185, avg. samples / sec: 53498.43
Iteration:   3000, Loss function: 4.923, Average Loss: 4.171, avg. samples / sec: 53558.25
Iteration:   3000, Loss function: 4.063, Average Loss: 4.164, avg. samples / sec: 53527.02
Iteration:   3000, Loss function: 3.685, Average Loss: 4.214, avg. samples / sec: 53545.40
Iteration:   3000, Loss function: 5.535, Average Loss: 4.215, avg. samples / sec: 53525.05
Iteration:   3000, Loss function: 4.348, Average Loss: 4.185, avg. samples / sec: 53492.18
Iteration:   3000, Loss function: 2.723, Average Loss: 4.206, avg. samples / sec: 53494.63
Iteration:   3000, Loss function: 4.714, Average Loss: 4.190, avg. samples / sec: 53538.92
Iteration:   3000, Loss function: 2.944, Average Loss: 4.201, avg. samples / sec: 53578.69
Iteration:   3000, Loss function: 3.161, Average Loss: 4.198, avg. samples / sec: 53543.05
Iteration:   3000, Loss function: 3.656, Average Loss: 4.183, avg. samples / sec: 53535.99
Iteration:   3000, Loss function: 4.149, Average Loss: 4.204, avg. samples / sec: 53497.15
:::MLL 1558640949.218 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558640949.218 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 4.100, Average Loss: 4.187, avg. samples / sec: 53600.43
Iteration:   3020, Loss function: 4.350, Average Loss: 4.171, avg. samples / sec: 53653.26
Iteration:   3020, Loss function: 5.775, Average Loss: 4.178, avg. samples / sec: 53672.70
Iteration:   3020, Loss function: 3.105, Average Loss: 4.206, avg. samples / sec: 53577.18
Iteration:   3020, Loss function: 4.755, Average Loss: 4.186, avg. samples / sec: 53597.46
Iteration:   3020, Loss function: 3.727, Average Loss: 4.203, avg. samples / sec: 53628.13
Iteration:   3020, Loss function: 3.418, Average Loss: 4.162, avg. samples / sec: 53765.97
Iteration:   3020, Loss function: 4.065, Average Loss: 4.178, avg. samples / sec: 53703.74
Iteration:   3020, Loss function: 3.649, Average Loss: 4.208, avg. samples / sec: 53664.95
Iteration:   3020, Loss function: 3.711, Average Loss: 4.194, avg. samples / sec: 53639.95
Iteration:   3020, Loss function: 4.908, Average Loss: 4.186, avg. samples / sec: 53645.71
Iteration:   3020, Loss function: 3.665, Average Loss: 4.198, avg. samples / sec: 53631.62
Iteration:   3020, Loss function: 3.009, Average Loss: 4.188, avg. samples / sec: 53625.80
Iteration:   3020, Loss function: 4.645, Average Loss: 4.187, avg. samples / sec: 53640.36
Iteration:   3020, Loss function: 3.948, Average Loss: 4.196, avg. samples / sec: 53613.79
Iteration:   3020, Loss function: 3.209, Average Loss: 4.197, avg. samples / sec: 53657.70
Iteration:   3020, Loss function: 5.239, Average Loss: 4.192, avg. samples / sec: 53613.65
Iteration:   3020, Loss function: 3.256, Average Loss: 4.187, avg. samples / sec: 53599.90
Iteration:   3020, Loss function: 5.075, Average Loss: 4.208, avg. samples / sec: 53623.29
Iteration:   3020, Loss function: 5.139, Average Loss: 4.194, avg. samples / sec: 53611.71
Iteration:   3020, Loss function: 3.321, Average Loss: 4.198, avg. samples / sec: 53625.38
Iteration:   3020, Loss function: 3.892, Average Loss: 4.175, avg. samples / sec: 53601.55
Iteration:   3020, Loss function: 5.036, Average Loss: 4.213, avg. samples / sec: 53618.05
Iteration:   3020, Loss function: 3.429, Average Loss: 4.190, avg. samples / sec: 53631.03
Iteration:   3020, Loss function: 4.640, Average Loss: 4.208, avg. samples / sec: 53608.79
Iteration:   3020, Loss function: 3.289, Average Loss: 4.185, avg. samples / sec: 53616.17
Iteration:   3020, Loss function: 3.795, Average Loss: 4.175, avg. samples / sec: 53644.16
Iteration:   3020, Loss function: 4.149, Average Loss: 4.182, avg. samples / sec: 53589.67
Iteration:   3020, Loss function: 3.657, Average Loss: 4.165, avg. samples / sec: 53570.93
Iteration:   3020, Loss function: 3.930, Average Loss: 4.198, avg. samples / sec: 53641.42
Iteration:   3040, Loss function: 4.145, Average Loss: 4.180, avg. samples / sec: 54060.20
Iteration:   3040, Loss function: 3.554, Average Loss: 4.199, avg. samples / sec: 54096.12
Iteration:   3040, Loss function: 3.569, Average Loss: 4.173, avg. samples / sec: 54038.19
Iteration:   3040, Loss function: 4.187, Average Loss: 4.174, avg. samples / sec: 54027.89
Iteration:   3040, Loss function: 3.168, Average Loss: 4.183, avg. samples / sec: 54056.38
Iteration:   3040, Loss function: 4.577, Average Loss: 4.202, avg. samples / sec: 54045.54
Iteration:   3040, Loss function: 2.658, Average Loss: 4.173, avg. samples / sec: 54097.51
Iteration:   3040, Loss function: 5.115, Average Loss: 4.186, avg. samples / sec: 54082.44
Iteration:   3040, Loss function: 3.589, Average Loss: 4.205, avg. samples / sec: 54087.19
Iteration:   3040, Loss function: 3.255, Average Loss: 4.194, avg. samples / sec: 54061.30
Iteration:   3040, Loss function: 3.655, Average Loss: 4.160, avg. samples / sec: 54116.89
Iteration:   3040, Loss function: 3.306, Average Loss: 4.182, avg. samples / sec: 54039.39
Iteration:   3040, Loss function: 4.942, Average Loss: 4.190, avg. samples / sec: 54041.00
Iteration:   3040, Loss function: 3.834, Average Loss: 4.192, avg. samples / sec: 54037.92
Iteration:   3040, Loss function: 3.517, Average Loss: 4.201, avg. samples / sec: 54043.18
Iteration:   3040, Loss function: 3.528, Average Loss: 4.184, avg. samples / sec: 54068.41
Iteration:   3040, Loss function: 3.917, Average Loss: 4.160, avg. samples / sec: 53902.35
Iteration:   3040, Loss function: 3.581, Average Loss: 4.194, avg. samples / sec: 54053.69
Iteration:   3040, Loss function: 4.822, Average Loss: 4.193, avg. samples / sec: 54017.16
Iteration:   3040, Loss function: 4.599, Average Loss: 4.189, avg. samples / sec: 54042.97
Iteration:   3040, Loss function: 3.359, Average Loss: 4.180, avg. samples / sec: 54005.34
Iteration:   3040, Loss function: 4.583, Average Loss: 4.193, avg. samples / sec: 53981.35
Iteration:   3040, Loss function: 3.666, Average Loss: 4.175, avg. samples / sec: 54077.60
Iteration:   3040, Loss function: 3.981, Average Loss: 4.171, avg. samples / sec: 54032.76
Iteration:   3040, Loss function: 4.414, Average Loss: 4.210, avg. samples / sec: 54042.72
Iteration:   3040, Loss function: 3.271, Average Loss: 4.181, avg. samples / sec: 54011.70
Iteration:   3040, Loss function: 3.647, Average Loss: 4.165, avg. samples / sec: 54047.43
Iteration:   3040, Loss function: 4.431, Average Loss: 4.197, avg. samples / sec: 54060.57
Iteration:   3040, Loss function: 4.001, Average Loss: 4.186, avg. samples / sec: 54007.76
Iteration:   3040, Loss function: 3.288, Average Loss: 4.203, avg. samples / sec: 53931.70
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558640950.420 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=2.58s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17186
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31207
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17290
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04153
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18317
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.26922
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18136
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28086
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07291
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.43222
Current AP: 0.17186 AP goal: 0.23000
:::MLL 1558640954.217 eval_accuracy: {"value": 0.17186384080549263, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558640954.317 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558640954.324 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558640954.324 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 3.594, Average Loss: 4.194, avg. samples / sec: 7393.30
Iteration:   3060, Loss function: 4.629, Average Loss: 4.170, avg. samples / sec: 7393.16
Iteration:   3060, Loss function: 3.786, Average Loss: 4.156, avg. samples / sec: 7398.98
Iteration:   3060, Loss function: 3.491, Average Loss: 4.163, avg. samples / sec: 7395.70
Iteration:   3060, Loss function: 3.459, Average Loss: 4.183, avg. samples / sec: 7397.99
Iteration:   3060, Loss function: 3.165, Average Loss: 4.194, avg. samples / sec: 7393.69
Iteration:   3060, Loss function: 3.289, Average Loss: 4.177, avg. samples / sec: 7393.16
Iteration:   3060, Loss function: 4.125, Average Loss: 4.159, avg. samples / sec: 7394.56
Iteration:   3060, Loss function: 3.589, Average Loss: 4.176, avg. samples / sec: 7386.32
Iteration:   3060, Loss function: 3.765, Average Loss: 4.180, avg. samples / sec: 7393.22
Iteration:   3060, Loss function: 4.018, Average Loss: 4.183, avg. samples / sec: 7394.46
Iteration:   3060, Loss function: 3.503, Average Loss: 4.184, avg. samples / sec: 7393.45
Iteration:   3060, Loss function: 3.233, Average Loss: 4.171, avg. samples / sec: 7394.21
Iteration:   3060, Loss function: 3.365, Average Loss: 4.202, avg. samples / sec: 7394.30
Iteration:   3060, Loss function: 3.417, Average Loss: 4.179, avg. samples / sec: 7394.21
Iteration:   3060, Loss function: 4.271, Average Loss: 4.181, avg. samples / sec: 7394.69
Iteration:   3060, Loss function: 6.286, Average Loss: 4.192, avg. samples / sec: 7393.59
Iteration:   3060, Loss function: 5.049, Average Loss: 4.185, avg. samples / sec: 7393.36
Iteration:   3060, Loss function: 4.059, Average Loss: 4.178, avg. samples / sec: 7393.23
Iteration:   3060, Loss function: 3.538, Average Loss: 4.161, avg. samples / sec: 7393.84
Iteration:   3060, Loss function: 3.714, Average Loss: 4.198, avg. samples / sec: 7392.75
Iteration:   3060, Loss function: 4.049, Average Loss: 4.183, avg. samples / sec: 7393.43
Iteration:   3060, Loss function: 4.031, Average Loss: 4.196, avg. samples / sec: 7393.15
Iteration:   3060, Loss function: 3.060, Average Loss: 4.194, avg. samples / sec: 7394.40
Iteration:   3060, Loss function: 2.390, Average Loss: 4.159, avg. samples / sec: 7392.97
Iteration:   3060, Loss function: 3.166, Average Loss: 4.189, avg. samples / sec: 7393.34
Iteration:   3060, Loss function: 3.114, Average Loss: 4.174, avg. samples / sec: 7393.01
Iteration:   3060, Loss function: 4.946, Average Loss: 4.179, avg. samples / sec: 7393.15
Iteration:   3060, Loss function: 4.406, Average Loss: 4.196, avg. samples / sec: 7393.55
Iteration:   3060, Loss function: 3.418, Average Loss: 4.166, avg. samples / sec: 7388.12
:::MLL 1558640955.326 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558640955.327 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 4.077, Average Loss: 4.157, avg. samples / sec: 53532.59
Iteration:   3080, Loss function: 4.103, Average Loss: 4.150, avg. samples / sec: 53492.54
Iteration:   3080, Loss function: 3.786, Average Loss: 4.170, avg. samples / sec: 53476.26
Iteration:   3080, Loss function: 4.202, Average Loss: 4.152, avg. samples / sec: 53411.67
Iteration:   3080, Loss function: 2.886, Average Loss: 4.184, avg. samples / sec: 53625.56
Iteration:   3080, Loss function: 2.835, Average Loss: 4.182, avg. samples / sec: 53345.98
Iteration:   3080, Loss function: 3.454, Average Loss: 4.172, avg. samples / sec: 53362.48
Iteration:   3080, Loss function: 4.414, Average Loss: 4.182, avg. samples / sec: 53368.34
Iteration:   3080, Loss function: 3.584, Average Loss: 4.165, avg. samples / sec: 53483.08
Iteration:   3080, Loss function: 3.549, Average Loss: 4.168, avg. samples / sec: 53564.88
Iteration:   3080, Loss function: 4.794, Average Loss: 4.155, avg. samples / sec: 53480.99
Iteration:   3080, Loss function: 4.121, Average Loss: 4.184, avg. samples / sec: 53494.35
Iteration:   3080, Loss function: 3.925, Average Loss: 4.163, avg. samples / sec: 53509.14
Iteration:   3080, Loss function: 2.913, Average Loss: 4.160, avg. samples / sec: 53462.31
Iteration:   3080, Loss function: 2.683, Average Loss: 4.174, avg. samples / sec: 53418.25
Iteration:   3080, Loss function: 3.915, Average Loss: 4.169, avg. samples / sec: 53418.13
Iteration:   3080, Loss function: 4.074, Average Loss: 4.170, avg. samples / sec: 53400.56
Iteration:   3080, Loss function: 4.712, Average Loss: 4.170, avg. samples / sec: 53352.53
Iteration:   3080, Loss function: 3.897, Average Loss: 4.151, avg. samples / sec: 53403.86
Iteration:   3080, Loss function: 4.702, Average Loss: 4.166, avg. samples / sec: 53374.93
Iteration:   3080, Loss function: 3.297, Average Loss: 4.188, avg. samples / sec: 53416.77
Iteration:   3080, Loss function: 2.884, Average Loss: 4.170, avg. samples / sec: 53351.47
Iteration:   3080, Loss function: 3.043, Average Loss: 4.170, avg. samples / sec: 53382.70
Iteration:   3080, Loss function: 3.166, Average Loss: 4.169, avg. samples / sec: 53360.85
Iteration:   3080, Loss function: 3.049, Average Loss: 4.189, avg. samples / sec: 53348.16
Iteration:   3080, Loss function: 2.867, Average Loss: 4.183, avg. samples / sec: 53366.91
Iteration:   3080, Loss function: 3.246, Average Loss: 4.182, avg. samples / sec: 53369.34
Iteration:   3080, Loss function: 4.059, Average Loss: 4.151, avg. samples / sec: 53354.63
Iteration:   3080, Loss function: 2.996, Average Loss: 4.185, avg. samples / sec: 53339.52
Iteration:   3080, Loss function: 2.322, Average Loss: 4.157, avg. samples / sec: 53352.14
Iteration:   3100, Loss function: 4.564, Average Loss: 4.140, avg. samples / sec: 53788.25
Iteration:   3100, Loss function: 4.025, Average Loss: 4.145, avg. samples / sec: 53660.95
Iteration:   3100, Loss function: 4.223, Average Loss: 4.163, avg. samples / sec: 53740.42
Iteration:   3100, Loss function: 3.510, Average Loss: 4.133, avg. samples / sec: 53675.58
Iteration:   3100, Loss function: 3.306, Average Loss: 4.156, avg. samples / sec: 53806.72
Iteration:   3100, Loss function: 3.597, Average Loss: 4.173, avg. samples / sec: 53799.49
Iteration:   3100, Loss function: 2.969, Average Loss: 4.172, avg. samples / sec: 53797.02
Iteration:   3100, Loss function: 3.001, Average Loss: 4.145, avg. samples / sec: 53698.01
Iteration:   3100, Loss function: 3.501, Average Loss: 4.167, avg. samples / sec: 53591.20
Iteration:   3100, Loss function: 2.587, Average Loss: 4.155, avg. samples / sec: 53672.08
Iteration:   3100, Loss function: 3.946, Average Loss: 4.178, avg. samples / sec: 53874.92
Iteration:   3100, Loss function: 2.789, Average Loss: 4.162, avg. samples / sec: 53746.78
Iteration:   3100, Loss function: 3.856, Average Loss: 4.166, avg. samples / sec: 53793.18
Iteration:   3100, Loss function: 3.738, Average Loss: 4.160, avg. samples / sec: 53803.51
Iteration:   3100, Loss function: 3.846, Average Loss: 4.156, avg. samples / sec: 53765.35
Iteration:   3100, Loss function: 2.704, Average Loss: 4.156, avg. samples / sec: 53815.76
Iteration:   3100, Loss function: 3.028, Average Loss: 4.172, avg. samples / sec: 53793.20
Iteration:   3100, Loss function: 5.075, Average Loss: 4.159, avg. samples / sec: 53798.64
Iteration:   3100, Loss function: 3.162, Average Loss: 4.173, avg. samples / sec: 53817.11
Iteration:   3100, Loss function: 3.743, Average Loss: 4.177, avg. samples / sec: 53813.00
Iteration:   3100, Loss function: 3.695, Average Loss: 4.159, avg. samples / sec: 53771.67
Iteration:   3100, Loss function: 3.365, Average Loss: 4.177, avg. samples / sec: 53669.73
Iteration:   3100, Loss function: 4.506, Average Loss: 4.162, avg. samples / sec: 53627.72
Iteration:   3100, Loss function: 2.696, Average Loss: 4.172, avg. samples / sec: 53803.61
Iteration:   3100, Loss function: 4.335, Average Loss: 4.152, avg. samples / sec: 53667.98
Iteration:   3100, Loss function: 5.373, Average Loss: 4.158, avg. samples / sec: 53666.40
Iteration:   3100, Loss function: 2.819, Average Loss: 4.138, avg. samples / sec: 53794.62
Iteration:   3100, Loss function: 3.253, Average Loss: 4.140, avg. samples / sec: 53750.32
Iteration:   3100, Loss function: 4.017, Average Loss: 4.154, avg. samples / sec: 53757.87
Iteration:   3100, Loss function: 4.734, Average Loss: 4.146, avg. samples / sec: 53803.24
Iteration:   3120, Loss function: 3.832, Average Loss: 4.147, avg. samples / sec: 53793.65
Iteration:   3120, Loss function: 2.439, Average Loss: 4.114, avg. samples / sec: 53433.24
Iteration:   3120, Loss function: 3.108, Average Loss: 4.125, avg. samples / sec: 53402.40
Iteration:   3120, Loss function: 4.612, Average Loss: 4.159, avg. samples / sec: 53464.31
Iteration:   3120, Loss function: 3.612, Average Loss: 4.164, avg. samples / sec: 53432.29
Iteration:   3120, Loss function: 4.862, Average Loss: 4.135, avg. samples / sec: 53378.13
Iteration:   3120, Loss function: 2.972, Average Loss: 4.150, avg. samples / sec: 53369.05
Iteration:   3120, Loss function: 4.520, Average Loss: 4.141, avg. samples / sec: 53355.29
Iteration:   3120, Loss function: 3.853, Average Loss: 4.151, avg. samples / sec: 53452.25
Iteration:   3120, Loss function: 4.476, Average Loss: 4.139, avg. samples / sec: 53431.03
Iteration:   3120, Loss function: 2.280, Average Loss: 4.133, avg. samples / sec: 53409.10
Iteration:   3120, Loss function: 4.155, Average Loss: 4.149, avg. samples / sec: 53453.36
Iteration:   3120, Loss function: 2.886, Average Loss: 4.146, avg. samples / sec: 53441.24
Iteration:   3120, Loss function: 3.449, Average Loss: 4.171, avg. samples / sec: 53423.03
Iteration:   3120, Loss function: 2.971, Average Loss: 4.150, avg. samples / sec: 53439.03
Iteration:   3120, Loss function: 3.373, Average Loss: 4.149, avg. samples / sec: 53422.30
Iteration:   3120, Loss function: 3.490, Average Loss: 4.162, avg. samples / sec: 53430.16
Iteration:   3120, Loss function: 3.203, Average Loss: 4.169, avg. samples / sec: 53432.67
Iteration:   3120, Loss function: 2.846, Average Loss: 4.128, avg. samples / sec: 53462.02
Iteration:   3120, Loss function: 4.490, Average Loss: 4.167, avg. samples / sec: 53442.80
Iteration:   3120, Loss function: 2.656, Average Loss: 4.138, avg. samples / sec: 53447.81
Iteration:   3120, Loss function: 3.247, Average Loss: 4.159, avg. samples / sec: 53425.99
Iteration:   3120, Loss function: 3.203, Average Loss: 4.158, avg. samples / sec: 53377.28
Iteration:   3120, Loss function: 4.137, Average Loss: 4.140, avg. samples / sec: 53447.63
Iteration:   3120, Loss function: 5.430, Average Loss: 4.162, avg. samples / sec: 53429.02
Iteration:   3120, Loss function: 4.008, Average Loss: 4.149, avg. samples / sec: 53397.16
Iteration:   3120, Loss function: 3.897, Average Loss: 4.142, avg. samples / sec: 53397.97
Iteration:   3120, Loss function: 4.875, Average Loss: 4.123, avg. samples / sec: 53438.24
Iteration:   3120, Loss function: 3.344, Average Loss: 4.136, avg. samples / sec: 53459.47
Iteration:   3120, Loss function: 3.460, Average Loss: 4.147, avg. samples / sec: 53421.13
Iteration:   3140, Loss function: 3.646, Average Loss: 4.111, avg. samples / sec: 53458.84
Iteration:   3140, Loss function: 4.125, Average Loss: 4.125, avg. samples / sec: 53479.81
Iteration:   3140, Loss function: 4.117, Average Loss: 4.106, avg. samples / sec: 53438.00
Iteration:   3140, Loss function: 4.164, Average Loss: 4.150, avg. samples / sec: 53437.72
Iteration:   3140, Loss function: 3.124, Average Loss: 4.136, avg. samples / sec: 53319.04
Iteration:   3140, Loss function: 2.801, Average Loss: 4.133, avg. samples / sec: 53458.35
Iteration:   3140, Loss function: 4.096, Average Loss: 4.130, avg. samples / sec: 53487.67
Iteration:   3140, Loss function: 3.065, Average Loss: 4.141, avg. samples / sec: 53372.81
Iteration:   3140, Loss function: 1.922, Average Loss: 4.142, avg. samples / sec: 53506.62
Iteration:   3140, Loss function: 3.844, Average Loss: 4.121, avg. samples / sec: 53469.59
Iteration:   3140, Loss function: 2.443, Average Loss: 4.131, avg. samples / sec: 53442.70
Iteration:   3140, Loss function: 3.010, Average Loss: 4.140, avg. samples / sec: 53458.55
Iteration:   3140, Loss function: 2.684, Average Loss: 4.123, avg. samples / sec: 53455.41
Iteration:   3140, Loss function: 5.484, Average Loss: 4.141, avg. samples / sec: 53497.09
Iteration:   3140, Loss function: 3.232, Average Loss: 4.136, avg. samples / sec: 53435.71
Iteration:   3140, Loss function: 4.048, Average Loss: 4.149, avg. samples / sec: 53459.47
Iteration:   3140, Loss function: 3.606, Average Loss: 4.163, avg. samples / sec: 53424.75
Iteration:   3140, Loss function: 3.990, Average Loss: 4.146, avg. samples / sec: 53466.81
Iteration:   3140, Loss function: 4.296, Average Loss: 4.108, avg. samples / sec: 53443.45
Iteration:   3140, Loss function: 3.845, Average Loss: 4.145, avg. samples / sec: 53457.34
Iteration:   3140, Loss function: 4.124, Average Loss: 4.133, avg. samples / sec: 53434.62
Iteration:   3140, Loss function: 2.237, Average Loss: 4.133, avg. samples / sec: 53482.43
Iteration:   3140, Loss function: 3.749, Average Loss: 4.124, avg. samples / sec: 53456.12
Iteration:   3140, Loss function: 4.226, Average Loss: 4.152, avg. samples / sec: 53437.94
Iteration:   3140, Loss function: 3.788, Average Loss: 4.159, avg. samples / sec: 53437.19
Iteration:   3140, Loss function: 3.555, Average Loss: 4.155, avg. samples / sec: 53424.69
Iteration:   3140, Loss function: 2.941, Average Loss: 4.113, avg. samples / sec: 53450.08
Iteration:   3140, Loss function: 2.239, Average Loss: 4.123, avg. samples / sec: 53427.44
Iteration:   3140, Loss function: 3.730, Average Loss: 4.125, avg. samples / sec: 53439.28
Iteration:   3140, Loss function: 3.291, Average Loss: 4.126, avg. samples / sec: 53405.88
:::MLL 1558640957.527 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558640957.527 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 3.339, Average Loss: 4.106, avg. samples / sec: 53095.30
Iteration:   3160, Loss function: 2.839, Average Loss: 4.094, avg. samples / sec: 53098.30
Iteration:   3160, Loss function: 3.239, Average Loss: 4.136, avg. samples / sec: 53079.34
Iteration:   3160, Loss function: 6.074, Average Loss: 4.105, avg. samples / sec: 53030.34
Iteration:   3160, Loss function: 2.872, Average Loss: 4.118, avg. samples / sec: 53079.46
Iteration:   3160, Loss function: 4.195, Average Loss: 4.124, avg. samples / sec: 53069.34
Iteration:   3160, Loss function: 2.663, Average Loss: 4.116, avg. samples / sec: 53072.82
Iteration:   3160, Loss function: 4.529, Average Loss: 4.128, avg. samples / sec: 53075.82
Iteration:   3160, Loss function: 3.685, Average Loss: 4.131, avg. samples / sec: 53132.49
Iteration:   3160, Loss function: 4.756, Average Loss: 4.110, avg. samples / sec: 53071.78
Iteration:   3160, Loss function: 2.701, Average Loss: 4.116, avg. samples / sec: 53065.17
Iteration:   3160, Loss function: 3.487, Average Loss: 4.131, avg. samples / sec: 53065.43
Iteration:   3160, Loss function: 3.568, Average Loss: 4.126, avg. samples / sec: 53052.64
Iteration:   3160, Loss function: 2.868, Average Loss: 4.135, avg. samples / sec: 53090.32
Iteration:   3160, Loss function: 3.135, Average Loss: 4.125, avg. samples / sec: 53076.42
Iteration:   3160, Loss function: 3.176, Average Loss: 4.110, avg. samples / sec: 53093.42
Iteration:   3160, Loss function: 4.098, Average Loss: 4.128, avg. samples / sec: 53014.44
Iteration:   3160, Loss function: 3.283, Average Loss: 4.137, avg. samples / sec: 53087.88
Iteration:   3160, Loss function: 4.314, Average Loss: 4.115, avg. samples / sec: 53046.31
Iteration:   3160, Loss function: 3.436, Average Loss: 4.123, avg. samples / sec: 53081.38
Iteration:   3160, Loss function: 4.009, Average Loss: 4.097, avg. samples / sec: 53076.10
Iteration:   3160, Loss function: 2.543, Average Loss: 4.138, avg. samples / sec: 53084.56
Iteration:   3160, Loss function: 4.000, Average Loss: 4.113, avg. samples / sec: 53099.52
Iteration:   3160, Loss function: 3.112, Average Loss: 4.155, avg. samples / sec: 53066.97
Iteration:   3160, Loss function: 3.689, Average Loss: 4.116, avg. samples / sec: 53106.22
Iteration:   3160, Loss function: 2.137, Average Loss: 4.110, avg. samples / sec: 53131.25
Iteration:   3160, Loss function: 3.239, Average Loss: 4.095, avg. samples / sec: 53081.70
Iteration:   3160, Loss function: 4.754, Average Loss: 4.136, avg. samples / sec: 53058.53
Iteration:   3160, Loss function: 3.518, Average Loss: 4.150, avg. samples / sec: 53071.14
Iteration:   3160, Loss function: 3.676, Average Loss: 4.123, avg. samples / sec: 53059.07
Iteration:   3180, Loss function: 3.685, Average Loss: 4.116, avg. samples / sec: 53671.33
Iteration:   3180, Loss function: 3.248, Average Loss: 4.094, avg. samples / sec: 53562.81
Iteration:   3180, Loss function: 3.404, Average Loss: 4.123, avg. samples / sec: 53604.80
Iteration:   3180, Loss function: 3.787, Average Loss: 4.107, avg. samples / sec: 53605.98
Iteration:   3180, Loss function: 4.109, Average Loss: 4.102, avg. samples / sec: 53610.34
Iteration:   3180, Loss function: 4.439, Average Loss: 4.098, avg. samples / sec: 53583.82
Iteration:   3180, Loss function: 3.412, Average Loss: 4.109, avg. samples / sec: 53578.65
Iteration:   3180, Loss function: 2.519, Average Loss: 4.083, avg. samples / sec: 53472.51
Iteration:   3180, Loss function: 4.098, Average Loss: 4.103, avg. samples / sec: 53632.50
Iteration:   3180, Loss function: 3.670, Average Loss: 4.116, avg. samples / sec: 53605.96
Iteration:   3180, Loss function: 4.508, Average Loss: 4.104, avg. samples / sec: 53574.70
Iteration:   3180, Loss function: 3.465, Average Loss: 4.115, avg. samples / sec: 53595.83
Iteration:   3180, Loss function: 2.364, Average Loss: 4.121, avg. samples / sec: 53579.69
Iteration:   3180, Loss function: 2.217, Average Loss: 4.105, avg. samples / sec: 53599.49
Iteration:   3180, Loss function: 3.641, Average Loss: 4.129, avg. samples / sec: 53599.43
Iteration:   3180, Loss function: 3.951, Average Loss: 4.112, avg. samples / sec: 53575.23
Iteration:   3180, Loss function: 3.569, Average Loss: 4.101, avg. samples / sec: 53596.29
Iteration:   3180, Loss function: 3.825, Average Loss: 4.112, avg. samples / sec: 53604.20
Iteration:   3180, Loss function: 3.265, Average Loss: 4.126, avg. samples / sec: 53574.19
Iteration:   3180, Loss function: 3.784, Average Loss: 4.144, avg. samples / sec: 53581.76
Iteration:   3180, Loss function: 4.533, Average Loss: 4.083, avg. samples / sec: 53584.56
Iteration:   3180, Loss function: 3.838, Average Loss: 4.095, avg. samples / sec: 53529.89
Iteration:   3180, Loss function: 3.333, Average Loss: 4.140, avg. samples / sec: 53587.49
Iteration:   3180, Loss function: 4.338, Average Loss: 4.127, avg. samples / sec: 53544.23
Iteration:   3180, Loss function: 3.629, Average Loss: 4.101, avg. samples / sec: 53545.59
Iteration:   3180, Loss function: 3.076, Average Loss: 4.121, avg. samples / sec: 53492.85
Iteration:   3180, Loss function: 4.274, Average Loss: 4.085, avg. samples / sec: 53555.80
Iteration:   3180, Loss function: 3.332, Average Loss: 4.098, avg. samples / sec: 53506.17
Iteration:   3180, Loss function: 5.230, Average Loss: 4.105, avg. samples / sec: 53515.13
Iteration:   3180, Loss function: 3.300, Average Loss: 4.122, avg. samples / sec: 53497.46
Iteration:   3200, Loss function: 2.722, Average Loss: 4.088, avg. samples / sec: 53687.75
Iteration:   3200, Loss function: 3.635, Average Loss: 4.092, avg. samples / sec: 53669.86
Iteration:   3200, Loss function: 4.147, Average Loss: 4.067, avg. samples / sec: 53740.44
Iteration:   3200, Loss function: 2.906, Average Loss: 4.080, avg. samples / sec: 53624.32
Iteration:   3200, Loss function: 3.222, Average Loss: 4.087, avg. samples / sec: 53919.12
Iteration:   3200, Loss function: 3.668, Average Loss: 4.101, avg. samples / sec: 53646.61
Iteration:   3200, Loss function: 3.634, Average Loss: 4.115, avg. samples / sec: 53587.63
Iteration:   3200, Loss function: 3.915, Average Loss: 4.106, avg. samples / sec: 53589.96
Iteration:   3200, Loss function: 4.390, Average Loss: 4.098, avg. samples / sec: 53565.94
Iteration:   3200, Loss function: 4.379, Average Loss: 4.110, avg. samples / sec: 53748.74
Iteration:   3200, Loss function: 3.780, Average Loss: 4.090, avg. samples / sec: 53673.39
Iteration:   3200, Loss function: 3.620, Average Loss: 4.087, avg. samples / sec: 53697.30
Iteration:   3200, Loss function: 3.555, Average Loss: 4.105, avg. samples / sec: 53661.87
Iteration:   3200, Loss function: 2.200, Average Loss: 4.109, avg. samples / sec: 53667.85
Iteration:   3200, Loss function: 3.820, Average Loss: 4.090, avg. samples / sec: 53622.64
Iteration:   3200, Loss function: 3.715, Average Loss: 4.100, avg. samples / sec: 53648.08
Iteration:   3200, Loss function: 4.050, Average Loss: 4.094, avg. samples / sec: 53653.63
Iteration:   3200, Loss function: 2.998, Average Loss: 4.085, avg. samples / sec: 53735.79
Iteration:   3200, Loss function: 2.495, Average Loss: 4.113, avg. samples / sec: 53651.18
Iteration:   3200, Loss function: 2.596, Average Loss: 4.111, avg. samples / sec: 53761.17
Iteration:   3200, Loss function: 3.678, Average Loss: 4.101, avg. samples / sec: 53655.39
Iteration:   3200, Loss function: 2.658, Average Loss: 4.111, avg. samples / sec: 53658.56
Iteration:   3200, Loss function: 4.153, Average Loss: 4.131, avg. samples / sec: 53655.65
Iteration:   3200, Loss function: 3.721, Average Loss: 4.075, avg. samples / sec: 53697.07
Iteration:   3200, Loss function: 2.758, Average Loss: 4.101, avg. samples / sec: 53642.77
Iteration:   3200, Loss function: 3.301, Average Loss: 4.116, avg. samples / sec: 53666.57
Iteration:   3200, Loss function: 3.151, Average Loss: 4.124, avg. samples / sec: 53656.06
Iteration:   3200, Loss function: 3.621, Average Loss: 4.092, avg. samples / sec: 53625.72
Iteration:   3200, Loss function: 3.756, Average Loss: 4.094, avg. samples / sec: 53696.11
Iteration:   3200, Loss function: 2.794, Average Loss: 4.072, avg. samples / sec: 53567.45
:::MLL 1558640959.728 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558640959.729 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 3.672, Average Loss: 4.090, avg. samples / sec: 53229.70
Iteration:   3220, Loss function: 3.133, Average Loss: 4.066, avg. samples / sec: 53188.42
Iteration:   3220, Loss function: 4.150, Average Loss: 4.085, avg. samples / sec: 53240.82
Iteration:   3220, Loss function: 2.747, Average Loss: 4.052, avg. samples / sec: 53083.10
Iteration:   3220, Loss function: 2.974, Average Loss: 4.078, avg. samples / sec: 53061.83
Iteration:   3220, Loss function: 2.972, Average Loss: 4.097, avg. samples / sec: 53111.94
Iteration:   3220, Loss function: 3.225, Average Loss: 4.077, avg. samples / sec: 53088.52
Iteration:   3220, Loss function: 2.037, Average Loss: 4.083, avg. samples / sec: 53023.90
Iteration:   3220, Loss function: 2.679, Average Loss: 4.105, avg. samples / sec: 53060.31
Iteration:   3220, Loss function: 3.744, Average Loss: 4.079, avg. samples / sec: 53160.79
Iteration:   3220, Loss function: 3.765, Average Loss: 4.112, avg. samples / sec: 53152.39
Iteration:   3220, Loss function: 3.510, Average Loss: 4.093, avg. samples / sec: 53097.58
Iteration:   3220, Loss function: 3.893, Average Loss: 4.085, avg. samples / sec: 53074.14
Iteration:   3220, Loss function: 3.173, Average Loss: 4.077, avg. samples / sec: 53077.66
Iteration:   3220, Loss function: 4.120, Average Loss: 4.084, avg. samples / sec: 53051.12
Iteration:   3220, Loss function: 3.996, Average Loss: 4.079, avg. samples / sec: 53055.14
Iteration:   3220, Loss function: 2.889, Average Loss: 4.102, avg. samples / sec: 53024.28
Iteration:   3220, Loss function: 3.293, Average Loss: 4.098, avg. samples / sec: 53081.96
Iteration:   3220, Loss function: 4.048, Average Loss: 4.086, avg. samples / sec: 53093.88
Iteration:   3220, Loss function: 3.442, Average Loss: 4.092, avg. samples / sec: 53044.24
Iteration:   3220, Loss function: 2.650, Average Loss: 4.096, avg. samples / sec: 53069.72
Iteration:   3220, Loss function: 3.850, Average Loss: 4.083, avg. samples / sec: 53101.82
Iteration:   3220, Loss function: 3.490, Average Loss: 4.105, avg. samples / sec: 53084.18
Iteration:   3220, Loss function: 3.534, Average Loss: 4.064, avg. samples / sec: 53152.41
Iteration:   3220, Loss function: 3.107, Average Loss: 4.087, avg. samples / sec: 53066.85
Iteration:   3220, Loss function: 2.942, Average Loss: 4.063, avg. samples / sec: 53053.06
Iteration:   3220, Loss function: 4.974, Average Loss: 4.076, avg. samples / sec: 53040.34
Iteration:   3220, Loss function: 4.504, Average Loss: 4.096, avg. samples / sec: 53021.70
Iteration:   3220, Loss function: 3.803, Average Loss: 4.120, avg. samples / sec: 53013.09
Iteration:   3220, Loss function: 3.085, Average Loss: 4.103, avg. samples / sec: 52983.85
Iteration:   3240, Loss function: 4.032, Average Loss: 4.039, avg. samples / sec: 53659.56
Iteration:   3240, Loss function: 4.354, Average Loss: 4.074, avg. samples / sec: 53711.01
Iteration:   3240, Loss function: 3.223, Average Loss: 4.088, avg. samples / sec: 53722.37
Iteration:   3240, Loss function: 3.407, Average Loss: 4.057, avg. samples / sec: 53557.90
Iteration:   3240, Loss function: 3.631, Average Loss: 4.090, avg. samples / sec: 53655.43
Iteration:   3240, Loss function: 3.801, Average Loss: 4.077, avg. samples / sec: 53564.78
Iteration:   3240, Loss function: 3.178, Average Loss: 4.066, avg. samples / sec: 53648.26
Iteration:   3240, Loss function: 4.032, Average Loss: 4.064, avg. samples / sec: 53643.93
Iteration:   3240, Loss function: 3.402, Average Loss: 4.080, avg. samples / sec: 53517.12
Iteration:   3240, Loss function: 2.672, Average Loss: 4.075, avg. samples / sec: 53679.26
Iteration:   3240, Loss function: 2.661, Average Loss: 4.078, avg. samples / sec: 53692.92
Iteration:   3240, Loss function: 3.888, Average Loss: 4.069, avg. samples / sec: 53672.96
Iteration:   3240, Loss function: 4.055, Average Loss: 4.088, avg. samples / sec: 53678.56
Iteration:   3240, Loss function: 2.588, Average Loss: 4.072, avg. samples / sec: 53668.02
Iteration:   3240, Loss function: 3.011, Average Loss: 4.087, avg. samples / sec: 53701.62
Iteration:   3240, Loss function: 4.120, Average Loss: 4.072, avg. samples / sec: 53689.87
Iteration:   3240, Loss function: 3.198, Average Loss: 4.108, avg. samples / sec: 53737.39
Iteration:   3240, Loss function: 2.390, Average Loss: 4.099, avg. samples / sec: 53602.86
Iteration:   3240, Loss function: 4.577, Average Loss: 4.066, avg. samples / sec: 53549.37
Iteration:   3240, Loss function: 3.039, Average Loss: 4.051, avg. samples / sec: 53684.58
Iteration:   3240, Loss function: 2.958, Average Loss: 4.064, avg. samples / sec: 53636.46
Iteration:   3240, Loss function: 3.044, Average Loss: 4.070, avg. samples / sec: 53655.69
Iteration:   3240, Loss function: 2.517, Average Loss: 4.078, avg. samples / sec: 53641.48
Iteration:   3240, Loss function: 3.059, Average Loss: 4.091, avg. samples / sec: 53652.14
Iteration:   3240, Loss function: 3.099, Average Loss: 4.090, avg. samples / sec: 53729.11
Iteration:   3240, Loss function: 3.868, Average Loss: 4.054, avg. samples / sec: 53656.29
Iteration:   3240, Loss function: 3.579, Average Loss: 4.068, avg. samples / sec: 53666.57
Iteration:   3240, Loss function: 2.843, Average Loss: 4.086, avg. samples / sec: 53639.99
Iteration:   3240, Loss function: 3.268, Average Loss: 4.071, avg. samples / sec: 53635.27
Iteration:   3240, Loss function: 3.386, Average Loss: 4.081, avg. samples / sec: 53594.97
Iteration:   3260, Loss function: 3.492, Average Loss: 4.056, avg. samples / sec: 53794.39
Iteration:   3260, Loss function: 3.511, Average Loss: 4.079, avg. samples / sec: 53753.95
Iteration:   3260, Loss function: 3.161, Average Loss: 4.027, avg. samples / sec: 53735.22
Iteration:   3260, Loss function: 4.392, Average Loss: 4.055, avg. samples / sec: 53751.08
Iteration:   3260, Loss function: 4.213, Average Loss: 4.047, avg. samples / sec: 53740.48
Iteration:   3260, Loss function: 5.386, Average Loss: 4.086, avg. samples / sec: 53729.48
Iteration:   3260, Loss function: 3.348, Average Loss: 4.066, avg. samples / sec: 53717.64
Iteration:   3260, Loss function: 4.187, Average Loss: 4.064, avg. samples / sec: 53732.62
Iteration:   3260, Loss function: 3.693, Average Loss: 4.065, avg. samples / sec: 53687.01
Iteration:   3260, Loss function: 3.267, Average Loss: 4.053, avg. samples / sec: 53786.20
Iteration:   3260, Loss function: 3.527, Average Loss: 4.051, avg. samples / sec: 53774.54
Iteration:   3260, Loss function: 3.013, Average Loss: 4.078, avg. samples / sec: 53734.62
Iteration:   3260, Loss function: 3.402, Average Loss: 4.080, avg. samples / sec: 53779.80
Iteration:   3260, Loss function: 3.939, Average Loss: 4.062, avg. samples / sec: 53739.19
Iteration:   3260, Loss function: 3.135, Average Loss: 4.073, avg. samples / sec: 53781.60
Iteration:   3260, Loss function: 3.106, Average Loss: 4.070, avg. samples / sec: 53792.09
Iteration:   3260, Loss function: 3.838, Average Loss: 4.057, avg. samples / sec: 53728.09
Iteration:   3260, Loss function: 2.786, Average Loss: 4.066, avg. samples / sec: 53759.18
Iteration:   3260, Loss function: 3.841, Average Loss: 4.077, avg. samples / sec: 53732.45
Iteration:   3260, Loss function: 2.994, Average Loss: 4.055, avg. samples / sec: 53757.66
Iteration:   3260, Loss function: 3.384, Average Loss: 4.067, avg. samples / sec: 53695.36
Iteration:   3260, Loss function: 4.029, Average Loss: 4.043, avg. samples / sec: 53728.52
Iteration:   3260, Loss function: 4.318, Average Loss: 4.060, avg. samples / sec: 53733.05
Iteration:   3260, Loss function: 2.568, Average Loss: 4.094, avg. samples / sec: 53715.66
Iteration:   3260, Loss function: 3.414, Average Loss: 4.057, avg. samples / sec: 53753.68
Iteration:   3260, Loss function: 3.048, Average Loss: 4.055, avg. samples / sec: 53708.25
Iteration:   3260, Loss function: 3.523, Average Loss: 4.069, avg. samples / sec: 53680.02
Iteration:   3260, Loss function: 3.530, Average Loss: 4.075, avg. samples / sec: 53720.94
Iteration:   3260, Loss function: 2.459, Average Loss: 4.087, avg. samples / sec: 53693.62
Iteration:   3260, Loss function: 4.170, Average Loss: 4.044, avg. samples / sec: 53711.58
Iteration:   3280, Loss function: 3.758, Average Loss: 4.077, avg. samples / sec: 53515.68
Iteration:   3280, Loss function: 4.068, Average Loss: 4.046, avg. samples / sec: 53483.43
Iteration:   3280, Loss function: 3.848, Average Loss: 4.020, avg. samples / sec: 53501.64
Iteration:   3280, Loss function: 3.370, Average Loss: 4.032, avg. samples / sec: 53504.22
Iteration:   3280, Loss function: 3.827, Average Loss: 4.053, avg. samples / sec: 53534.58
Iteration:   3280, Loss function: 4.542, Average Loss: 4.075, avg. samples / sec: 53507.27
Iteration:   3280, Loss function: 3.276, Average Loss: 4.051, avg. samples / sec: 53525.64
Iteration:   3280, Loss function: 5.195, Average Loss: 4.053, avg. samples / sec: 53510.29
Iteration:   3280, Loss function: 4.946, Average Loss: 4.045, avg. samples / sec: 53475.33
Iteration:   3280, Loss function: 4.228, Average Loss: 4.055, avg. samples / sec: 53560.24
Iteration:   3280, Loss function: 3.063, Average Loss: 4.044, avg. samples / sec: 53525.47
Iteration:   3280, Loss function: 2.783, Average Loss: 4.042, avg. samples / sec: 53543.53
Iteration:   3280, Loss function: 3.666, Average Loss: 4.057, avg. samples / sec: 53574.98
Iteration:   3280, Loss function: 3.262, Average Loss: 4.059, avg. samples / sec: 53527.65
Iteration:   3280, Loss function: 2.678, Average Loss: 4.061, avg. samples / sec: 53536.64
Iteration:   3280, Loss function: 3.010, Average Loss: 4.053, avg. samples / sec: 53548.09
Iteration:   3280, Loss function: 4.221, Average Loss: 4.049, avg. samples / sec: 53557.06
Iteration:   3280, Loss function: 3.806, Average Loss: 4.040, avg. samples / sec: 53500.66
Iteration:   3280, Loss function: 4.136, Average Loss: 4.077, avg. samples / sec: 53559.93
Iteration:   3280, Loss function: 3.322, Average Loss: 4.042, avg. samples / sec: 53539.59
Iteration:   3280, Loss function: 3.536, Average Loss: 4.042, avg. samples / sec: 53515.70
Iteration:   3280, Loss function: 2.456, Average Loss: 4.085, avg. samples / sec: 53531.80
Iteration:   3280, Loss function: 3.192, Average Loss: 4.036, avg. samples / sec: 53551.02
Iteration:   3280, Loss function: 2.492, Average Loss: 4.062, avg. samples / sec: 53541.80
Iteration:   3280, Loss function: 3.475, Average Loss: 4.062, avg. samples / sec: 53473.18
Iteration:   3280, Loss function: 2.921, Average Loss: 4.064, avg. samples / sec: 53468.23
Iteration:   3280, Loss function: 4.125, Average Loss: 4.064, avg. samples / sec: 53460.01
Iteration:   3280, Loss function: 3.546, Average Loss: 4.049, avg. samples / sec: 53489.82
Iteration:   3280, Loss function: 2.901, Average Loss: 4.038, avg. samples / sec: 53469.61
Iteration:   3280, Loss function: 3.195, Average Loss: 4.056, avg. samples / sec: 53412.50
:::MLL 1558640961.925 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558640961.925 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 3.719, Average Loss: 4.037, avg. samples / sec: 53402.34
Iteration:   3300, Loss function: 3.868, Average Loss: 4.066, avg. samples / sec: 53385.97
Iteration:   3300, Loss function: 3.158, Average Loss: 4.014, avg. samples / sec: 53401.83
Iteration:   3300, Loss function: 3.982, Average Loss: 4.046, avg. samples / sec: 53404.65
Iteration:   3300, Loss function: 2.878, Average Loss: 4.029, avg. samples / sec: 53411.63
Iteration:   3300, Loss function: 2.643, Average Loss: 4.008, avg. samples / sec: 53374.09
Iteration:   3300, Loss function: 2.550, Average Loss: 4.040, avg. samples / sec: 53411.06
Iteration:   3300, Loss function: 3.617, Average Loss: 4.043, avg. samples / sec: 53357.17
Iteration:   3300, Loss function: 4.207, Average Loss: 4.071, avg. samples / sec: 53325.11
Iteration:   3300, Loss function: 3.231, Average Loss: 4.047, avg. samples / sec: 53431.27
Iteration:   3300, Loss function: 3.338, Average Loss: 4.032, avg. samples / sec: 53386.60
Iteration:   3300, Loss function: 3.321, Average Loss: 4.036, avg. samples / sec: 53412.48
Iteration:   3300, Loss function: 4.675, Average Loss: 4.032, avg. samples / sec: 53395.22
Iteration:   3300, Loss function: 3.185, Average Loss: 4.027, avg. samples / sec: 53425.60
Iteration:   3300, Loss function: 3.838, Average Loss: 4.032, avg. samples / sec: 53422.77
Iteration:   3300, Loss function: 2.547, Average Loss: 4.041, avg. samples / sec: 53359.60
Iteration:   3300, Loss function: 4.863, Average Loss: 4.036, avg. samples / sec: 53393.38
Iteration:   3300, Loss function: 4.226, Average Loss: 4.044, avg. samples / sec: 53385.67
Iteration:   3300, Loss function: 2.816, Average Loss: 4.052, avg. samples / sec: 53428.25
Iteration:   3300, Loss function: 3.732, Average Loss: 4.074, avg. samples / sec: 53402.62
Iteration:   3300, Loss function: 4.569, Average Loss: 4.046, avg. samples / sec: 53499.61
Iteration:   3300, Loss function: 3.274, Average Loss: 4.066, avg. samples / sec: 53398.58
Iteration:   3300, Loss function: 2.898, Average Loss: 4.026, avg. samples / sec: 53399.24
Iteration:   3300, Loss function: 2.809, Average Loss: 4.028, avg. samples / sec: 53386.70
Iteration:   3300, Loss function: 2.677, Average Loss: 4.043, avg. samples / sec: 53369.21
Iteration:   3300, Loss function: 3.464, Average Loss: 4.055, avg. samples / sec: 53408.41
Iteration:   3300, Loss function: 2.744, Average Loss: 4.052, avg. samples / sec: 53430.68
Iteration:   3300, Loss function: 4.252, Average Loss: 4.060, avg. samples / sec: 53391.09
Iteration:   3300, Loss function: 3.949, Average Loss: 4.036, avg. samples / sec: 53417.30
Iteration:   3300, Loss function: 3.740, Average Loss: 4.029, avg. samples / sec: 53425.46
Iteration:   3320, Loss function: 3.486, Average Loss: 4.055, avg. samples / sec: 53752.91
Iteration:   3320, Loss function: 3.492, Average Loss: 4.002, avg. samples / sec: 53740.01
Iteration:   3320, Loss function: 2.973, Average Loss: 4.033, avg. samples / sec: 53801.46
Iteration:   3320, Loss function: 4.584, Average Loss: 4.019, avg. samples / sec: 53754.16
Iteration:   3320, Loss function: 2.901, Average Loss: 4.037, avg. samples / sec: 53732.25
Iteration:   3320, Loss function: 2.788, Average Loss: 4.058, avg. samples / sec: 53805.65
Iteration:   3320, Loss function: 2.786, Average Loss: 4.027, avg. samples / sec: 53691.37
Iteration:   3320, Loss function: 5.107, Average Loss: 4.000, avg. samples / sec: 53652.59
Iteration:   3320, Loss function: 2.413, Average Loss: 4.025, avg. samples / sec: 53725.59
Iteration:   3320, Loss function: 3.263, Average Loss: 4.020, avg. samples / sec: 53709.54
Iteration:   3320, Loss function: 4.118, Average Loss: 4.030, avg. samples / sec: 53727.78
Iteration:   3320, Loss function: 3.447, Average Loss: 4.031, avg. samples / sec: 53474.90
Iteration:   3320, Loss function: 3.538, Average Loss: 4.021, avg. samples / sec: 53716.03
Iteration:   3320, Loss function: 3.829, Average Loss: 4.056, avg. samples / sec: 53738.29
Iteration:   3320, Loss function: 2.694, Average Loss: 4.031, avg. samples / sec: 53676.27
Iteration:   3320, Loss function: 2.390, Average Loss: 4.020, avg. samples / sec: 53699.75
Iteration:   3320, Loss function: 2.544, Average Loss: 4.031, avg. samples / sec: 53737.33
Iteration:   3320, Loss function: 4.071, Average Loss: 4.014, avg. samples / sec: 53733.99
Iteration:   3320, Loss function: 3.596, Average Loss: 4.018, avg. samples / sec: 53700.63
Iteration:   3320, Loss function: 2.511, Average Loss: 4.038, avg. samples / sec: 53703.31
Iteration:   3320, Loss function: 4.738, Average Loss: 4.040, avg. samples / sec: 53690.06
Iteration:   3320, Loss function: 5.088, Average Loss: 4.041, avg. samples / sec: 53702.58
Iteration:   3320, Loss function: 3.487, Average Loss: 4.045, avg. samples / sec: 53719.20
Iteration:   3320, Loss function: 3.593, Average Loss: 4.063, avg. samples / sec: 53692.04
Iteration:   3320, Loss function: 3.816, Average Loss: 4.018, avg. samples / sec: 53681.10
Iteration:   3320, Loss function: 3.358, Average Loss: 4.048, avg. samples / sec: 53710.44
Iteration:   3320, Loss function: 3.243, Average Loss: 4.037, avg. samples / sec: 53696.32
Iteration:   3320, Loss function: 4.517, Average Loss: 4.019, avg. samples / sec: 53718.59
Iteration:   3320, Loss function: 3.936, Average Loss: 4.022, avg. samples / sec: 53686.31
Iteration:   3320, Loss function: 3.347, Average Loss: 4.026, avg. samples / sec: 53691.94
Iteration:   3340, Loss function: 3.949, Average Loss: 4.047, avg. samples / sec: 53710.38
Iteration:   3340, Loss function: 4.782, Average Loss: 3.992, avg. samples / sec: 53838.56
Iteration:   3340, Loss function: 3.379, Average Loss: 4.007, avg. samples / sec: 53731.73
Iteration:   3340, Loss function: 3.012, Average Loss: 4.024, avg. samples / sec: 53719.16
Iteration:   3340, Loss function: 3.160, Average Loss: 3.990, avg. samples / sec: 53707.61
Iteration:   3340, Loss function: 3.394, Average Loss: 4.014, avg. samples / sec: 53760.51
Iteration:   3340, Loss function: 3.413, Average Loss: 4.022, avg. samples / sec: 53701.82
Iteration:   3340, Loss function: 2.961, Average Loss: 4.045, avg. samples / sec: 53719.32
Iteration:   3340, Loss function: 3.516, Average Loss: 4.010, avg. samples / sec: 53779.14
Iteration:   3340, Loss function: 3.563, Average Loss: 4.010, avg. samples / sec: 53751.68
Iteration:   3340, Loss function: 4.026, Average Loss: 4.015, avg. samples / sec: 53749.83
Iteration:   3340, Loss function: 2.993, Average Loss: 4.035, avg. samples / sec: 53776.00
Iteration:   3340, Loss function: 3.401, Average Loss: 4.021, avg. samples / sec: 53745.32
Iteration:   3340, Loss function: 3.323, Average Loss: 4.021, avg. samples / sec: 53740.59
Iteration:   3340, Loss function: 4.067, Average Loss: 4.014, avg. samples / sec: 53704.42
Iteration:   3340, Loss function: 1.849, Average Loss: 4.026, avg. samples / sec: 53760.43
Iteration:   3340, Loss function: 3.325, Average Loss: 4.008, avg. samples / sec: 53733.29
Iteration:   3340, Loss function: 3.458, Average Loss: 4.008, avg. samples / sec: 53719.08
Iteration:   3340, Loss function: 4.067, Average Loss: 4.000, avg. samples / sec: 53721.04
Iteration:   3340, Loss function: 4.025, Average Loss: 4.027, avg. samples / sec: 53745.24
Iteration:   3340, Loss function: 3.266, Average Loss: 4.015, avg. samples / sec: 53783.64
Iteration:   3340, Loss function: 3.509, Average Loss: 4.026, avg. samples / sec: 53757.54
Iteration:   3340, Loss function: 2.614, Average Loss: 4.049, avg. samples / sec: 53738.58
Iteration:   3340, Loss function: 3.620, Average Loss: 4.044, avg. samples / sec: 53699.14
Iteration:   3340, Loss function: 4.073, Average Loss: 4.012, avg. samples / sec: 53734.23
Iteration:   3340, Loss function: 3.148, Average Loss: 4.035, avg. samples / sec: 53741.90
Iteration:   3340, Loss function: 3.109, Average Loss: 4.001, avg. samples / sec: 53738.13
Iteration:   3340, Loss function: 3.551, Average Loss: 4.014, avg. samples / sec: 53694.95
Iteration:   3340, Loss function: 2.434, Average Loss: 4.018, avg. samples / sec: 53740.95
Iteration:   3340, Loss function: 3.538, Average Loss: 4.033, avg. samples / sec: 53691.14
:::MLL 1558640964.118 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558640964.119 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 3.640, Average Loss: 3.979, avg. samples / sec: 53463.75
Iteration:   3360, Loss function: 3.048, Average Loss: 3.993, avg. samples / sec: 53331.14
Iteration:   3360, Loss function: 2.806, Average Loss: 4.002, avg. samples / sec: 53360.18
Iteration:   3360, Loss function: 2.802, Average Loss: 4.011, avg. samples / sec: 53349.23
Iteration:   3360, Loss function: 2.777, Average Loss: 4.013, avg. samples / sec: 53326.56
Iteration:   3360, Loss function: 3.129, Average Loss: 4.032, avg. samples / sec: 53268.11
Iteration:   3360, Loss function: 3.470, Average Loss: 4.035, avg. samples / sec: 53296.78
Iteration:   3360, Loss function: 3.262, Average Loss: 4.002, avg. samples / sec: 53447.63
Iteration:   3360, Loss function: 2.568, Average Loss: 3.981, avg. samples / sec: 53212.50
Iteration:   3360, Loss function: 5.248, Average Loss: 4.006, avg. samples / sec: 53456.73
Iteration:   3360, Loss function: 3.802, Average Loss: 4.030, avg. samples / sec: 53407.26
Iteration:   3360, Loss function: 2.071, Average Loss: 4.011, avg. samples / sec: 53349.29
Iteration:   3360, Loss function: 3.847, Average Loss: 4.016, avg. samples / sec: 53338.35
Iteration:   3360, Loss function: 3.580, Average Loss: 4.001, avg. samples / sec: 53306.94
Iteration:   3360, Loss function: 2.647, Average Loss: 4.018, avg. samples / sec: 53354.26
Iteration:   3360, Loss function: 3.478, Average Loss: 4.008, avg. samples / sec: 53314.52
Iteration:   3360, Loss function: 3.438, Average Loss: 3.997, avg. samples / sec: 53293.23
Iteration:   3360, Loss function: 3.886, Average Loss: 3.986, avg. samples / sec: 53326.38
Iteration:   3360, Loss function: 4.071, Average Loss: 4.001, avg. samples / sec: 53300.20
Iteration:   3360, Loss function: 4.231, Average Loss: 4.025, avg. samples / sec: 53276.69
Iteration:   3360, Loss function: 3.831, Average Loss: 4.000, avg. samples / sec: 53330.68
Iteration:   3360, Loss function: 3.727, Average Loss: 4.019, avg. samples / sec: 53363.27
Iteration:   3360, Loss function: 2.835, Average Loss: 4.009, avg. samples / sec: 53345.50
Iteration:   3360, Loss function: 3.585, Average Loss: 3.999, avg. samples / sec: 53302.40
Iteration:   3360, Loss function: 2.317, Average Loss: 3.999, avg. samples / sec: 53298.43
Iteration:   3360, Loss function: 2.519, Average Loss: 4.041, avg. samples / sec: 53308.85
Iteration:   3360, Loss function: 3.386, Average Loss: 4.023, avg. samples / sec: 53298.79
Iteration:   3360, Loss function: 4.669, Average Loss: 3.992, avg. samples / sec: 53303.49
Iteration:   3360, Loss function: 4.297, Average Loss: 4.021, avg. samples / sec: 53279.04
Iteration:   3360, Loss function: 3.366, Average Loss: 4.005, avg. samples / sec: 53243.54
Iteration:   3380, Loss function: 2.879, Average Loss: 3.980, avg. samples / sec: 53892.27
Iteration:   3380, Loss function: 3.148, Average Loss: 4.018, avg. samples / sec: 53953.94
Iteration:   3380, Loss function: 3.478, Average Loss: 3.971, avg. samples / sec: 53772.96
Iteration:   3380, Loss function: 3.701, Average Loss: 3.974, avg. samples / sec: 53992.08
Iteration:   3380, Loss function: 3.230, Average Loss: 4.004, avg. samples / sec: 53883.74
Iteration:   3380, Loss function: 3.804, Average Loss: 4.005, avg. samples / sec: 53920.38
Iteration:   3380, Loss function: 3.783, Average Loss: 3.991, avg. samples / sec: 53867.02
Iteration:   3380, Loss function: 4.505, Average Loss: 4.024, avg. samples / sec: 53925.41
Iteration:   3380, Loss function: 3.823, Average Loss: 3.991, avg. samples / sec: 53922.60
Iteration:   3380, Loss function: 3.196, Average Loss: 4.014, avg. samples / sec: 53965.82
Iteration:   3380, Loss function: 3.554, Average Loss: 3.996, avg. samples / sec: 53895.80
Iteration:   3380, Loss function: 3.736, Average Loss: 3.989, avg. samples / sec: 53964.27
Iteration:   3380, Loss function: 3.666, Average Loss: 3.984, avg. samples / sec: 53919.06
Iteration:   3380, Loss function: 3.457, Average Loss: 3.989, avg. samples / sec: 53940.04
Iteration:   3380, Loss function: 2.714, Average Loss: 4.011, avg. samples / sec: 53906.33
Iteration:   3380, Loss function: 2.314, Average Loss: 3.976, avg. samples / sec: 53936.45
Iteration:   3380, Loss function: 3.193, Average Loss: 3.995, avg. samples / sec: 53748.91
Iteration:   3380, Loss function: 2.204, Average Loss: 3.996, avg. samples / sec: 53900.85
Iteration:   3380, Loss function: 3.480, Average Loss: 4.010, avg. samples / sec: 53977.81
Iteration:   3380, Loss function: 2.878, Average Loss: 4.025, avg. samples / sec: 53933.91
Iteration:   3380, Loss function: 3.112, Average Loss: 3.996, avg. samples / sec: 53927.16
Iteration:   3380, Loss function: 4.927, Average Loss: 4.005, avg. samples / sec: 53879.77
Iteration:   3380, Loss function: 3.236, Average Loss: 4.012, avg. samples / sec: 53925.80
Iteration:   3380, Loss function: 3.228, Average Loss: 4.008, avg. samples / sec: 53953.18
Iteration:   3380, Loss function: 3.679, Average Loss: 4.016, avg. samples / sec: 53825.95
Iteration:   3380, Loss function: 2.728, Average Loss: 3.991, avg. samples / sec: 53892.79
Iteration:   3380, Loss function: 3.620, Average Loss: 3.992, avg. samples / sec: 53897.84
Iteration:   3380, Loss function: 4.174, Average Loss: 3.987, avg. samples / sec: 53925.84
Iteration:   3380, Loss function: 2.892, Average Loss: 3.995, avg. samples / sec: 53963.28
Iteration:   3380, Loss function: 2.777, Average Loss: 4.000, avg. samples / sec: 53760.41
Iteration:   3400, Loss function: 3.802, Average Loss: 3.967, avg. samples / sec: 53928.61
Iteration:   3400, Loss function: 2.578, Average Loss: 3.972, avg. samples / sec: 53902.70
Iteration:   3400, Loss function: 4.145, Average Loss: 3.958, avg. samples / sec: 53896.44
Iteration:   3400, Loss function: 4.167, Average Loss: 3.993, avg. samples / sec: 53888.36
Iteration:   3400, Loss function: 3.090, Average Loss: 3.995, avg. samples / sec: 53855.43
Iteration:   3400, Loss function: 2.100, Average Loss: 3.978, avg. samples / sec: 53858.47
Iteration:   3400, Loss function: 4.316, Average Loss: 4.011, avg. samples / sec: 53817.52
Iteration:   3400, Loss function: 5.366, Average Loss: 4.017, avg. samples / sec: 53829.02
Iteration:   3400, Loss function: 4.074, Average Loss: 3.977, avg. samples / sec: 53903.67
Iteration:   3400, Loss function: 3.402, Average Loss: 3.984, avg. samples / sec: 53918.79
Iteration:   3400, Loss function: 4.163, Average Loss: 3.976, avg. samples / sec: 53890.31
Iteration:   3400, Loss function: 2.369, Average Loss: 3.980, avg. samples / sec: 53877.62
Iteration:   3400, Loss function: 3.688, Average Loss: 3.978, avg. samples / sec: 53884.40
Iteration:   3400, Loss function: 2.598, Average Loss: 3.965, avg. samples / sec: 53879.52
Iteration:   3400, Loss function: 3.865, Average Loss: 4.002, avg. samples / sec: 53904.81
Iteration:   3400, Loss function: 2.960, Average Loss: 3.985, avg. samples / sec: 53867.00
Iteration:   3400, Loss function: 4.034, Average Loss: 3.999, avg. samples / sec: 53890.79
Iteration:   3400, Loss function: 4.523, Average Loss: 3.986, avg. samples / sec: 53948.16
Iteration:   3400, Loss function: 3.047, Average Loss: 4.003, avg. samples / sec: 53869.08
Iteration:   3400, Loss function: 4.343, Average Loss: 3.988, avg. samples / sec: 53884.73
Iteration:   3400, Loss function: 2.633, Average Loss: 3.981, avg. samples / sec: 53918.75
Iteration:   3400, Loss function: 3.622, Average Loss: 3.999, avg. samples / sec: 53849.81
Iteration:   3400, Loss function: 3.411, Average Loss: 4.014, avg. samples / sec: 53888.32
Iteration:   3400, Loss function: 3.623, Average Loss: 3.983, avg. samples / sec: 53881.70
Iteration:   3400, Loss function: 3.807, Average Loss: 3.991, avg. samples / sec: 53881.68
Iteration:   3400, Loss function: 4.058, Average Loss: 3.995, avg. samples / sec: 53886.71
Iteration:   3400, Loss function: 4.214, Average Loss: 3.985, avg. samples / sec: 53910.43
Iteration:   3400, Loss function: 3.762, Average Loss: 4.006, avg. samples / sec: 53896.17
Iteration:   3400, Loss function: 3.246, Average Loss: 3.980, avg. samples / sec: 53889.76
Iteration:   3400, Loss function: 3.551, Average Loss: 3.985, avg. samples / sec: 53884.22
Iteration:   3420, Loss function: 2.555, Average Loss: 3.962, avg. samples / sec: 54022.03
Iteration:   3420, Loss function: 3.105, Average Loss: 3.955, avg. samples / sec: 53995.16
Iteration:   3420, Loss function: 2.860, Average Loss: 3.951, avg. samples / sec: 54021.24
Iteration:   3420, Loss function: 3.021, Average Loss: 3.983, avg. samples / sec: 54066.07
Iteration:   3420, Loss function: 3.319, Average Loss: 3.998, avg. samples / sec: 54090.87
Iteration:   3420, Loss function: 2.973, Average Loss: 3.978, avg. samples / sec: 54010.72
Iteration:   3420, Loss function: 3.555, Average Loss: 4.005, avg. samples / sec: 54094.31
Iteration:   3420, Loss function: 2.253, Average Loss: 3.963, avg. samples / sec: 54023.87
Iteration:   3420, Loss function: 4.594, Average Loss: 3.974, avg. samples / sec: 54037.36
Iteration:   3420, Loss function: 3.807, Average Loss: 3.977, avg. samples / sec: 54082.44
Iteration:   3420, Loss function: 3.305, Average Loss: 3.973, avg. samples / sec: 54067.44
Iteration:   3420, Loss function: 3.768, Average Loss: 3.966, avg. samples / sec: 54051.76
Iteration:   3420, Loss function: 3.683, Average Loss: 3.967, avg. samples / sec: 54054.29
Iteration:   3420, Loss function: 2.490, Average Loss: 3.987, avg. samples / sec: 54059.56
Iteration:   3420, Loss function: 2.975, Average Loss: 3.969, avg. samples / sec: 54073.10
Iteration:   3420, Loss function: 2.619, Average Loss: 3.958, avg. samples / sec: 54055.60
Iteration:   3420, Loss function: 3.816, Average Loss: 3.985, avg. samples / sec: 54049.92
Iteration:   3420, Loss function: 3.127, Average Loss: 3.992, avg. samples / sec: 54050.58
Iteration:   3420, Loss function: 2.682, Average Loss: 3.964, avg. samples / sec: 54029.17
Iteration:   3420, Loss function: 3.610, Average Loss: 3.974, avg. samples / sec: 54038.45
Iteration:   3420, Loss function: 2.849, Average Loss: 3.965, avg. samples / sec: 54003.56
Iteration:   3420, Loss function: 2.412, Average Loss: 3.996, avg. samples / sec: 54059.64
Iteration:   3420, Loss function: 3.822, Average Loss: 3.969, avg. samples / sec: 54075.30
Iteration:   3420, Loss function: 3.000, Average Loss: 3.986, avg. samples / sec: 54029.79
Iteration:   3420, Loss function: 3.520, Average Loss: 4.004, avg. samples / sec: 54039.68
Iteration:   3420, Loss function: 3.174, Average Loss: 3.972, avg. samples / sec: 54047.22
Iteration:   3420, Loss function: 3.964, Average Loss: 3.985, avg. samples / sec: 54045.07
Iteration:   3420, Loss function: 4.112, Average Loss: 3.973, avg. samples / sec: 54035.68
Iteration:   3420, Loss function: 3.094, Average Loss: 3.973, avg. samples / sec: 54001.62
Iteration:   3420, Loss function: 3.015, Average Loss: 3.977, avg. samples / sec: 54035.30
:::MLL 1558640966.283 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.60s)
DONE (t=2.50s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22437
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38371
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23539
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31830
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36219
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.51863
Current AP: 0.22437 AP goal: 0.23000
:::MLL 1558640970.026 eval_accuracy: {"value": 0.22436981012236562, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558640970.135 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558640970.142 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558640970.142 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558640970.175 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558640970.176 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.541, Average Loss: 3.973, avg. samples / sec: 7463.05
Iteration:   3440, Loss function: 2.968, Average Loss: 3.947, avg. samples / sec: 7461.40
Iteration:   3440, Loss function: 4.238, Average Loss: 3.940, avg. samples / sec: 7461.16
Iteration:   3440, Loss function: 4.244, Average Loss: 3.976, avg. samples / sec: 7465.34
Iteration:   3440, Loss function: 2.923, Average Loss: 3.971, avg. samples / sec: 7465.38
Iteration:   3440, Loss function: 5.285, Average Loss: 3.954, avg. samples / sec: 7460.14
Iteration:   3440, Loss function: 4.031, Average Loss: 3.967, avg. samples / sec: 7461.02
Iteration:   3440, Loss function: 3.938, Average Loss: 3.985, avg. samples / sec: 7460.45
Iteration:   3440, Loss function: 3.902, Average Loss: 3.996, avg. samples / sec: 7460.69
Iteration:   3440, Loss function: 2.134, Average Loss: 3.976, avg. samples / sec: 7464.61
Iteration:   3440, Loss function: 3.108, Average Loss: 3.952, avg. samples / sec: 7461.26
Iteration:   3440, Loss function: 3.306, Average Loss: 3.964, avg. samples / sec: 7460.69
Iteration:   3440, Loss function: 5.036, Average Loss: 3.951, avg. samples / sec: 7461.12
Iteration:   3440, Loss function: 3.972, Average Loss: 3.962, avg. samples / sec: 7460.76
Iteration:   3440, Loss function: 3.823, Average Loss: 3.964, avg. samples / sec: 7460.16
Iteration:   3440, Loss function: 3.140, Average Loss: 3.948, avg. samples / sec: 7460.51
Iteration:   3440, Loss function: 3.359, Average Loss: 3.956, avg. samples / sec: 7460.90
Iteration:   3440, Loss function: 3.355, Average Loss: 3.978, avg. samples / sec: 7460.52
Iteration:   3440, Loss function: 4.617, Average Loss: 3.954, avg. samples / sec: 7460.58
Iteration:   3440, Loss function: 2.893, Average Loss: 3.960, avg. samples / sec: 7460.83
Iteration:   3440, Loss function: 3.488, Average Loss: 3.950, avg. samples / sec: 7457.07
Iteration:   3440, Loss function: 2.608, Average Loss: 3.993, avg. samples / sec: 7460.38
Iteration:   3440, Loss function: 4.036, Average Loss: 3.976, avg. samples / sec: 7459.41
Iteration:   3440, Loss function: 2.571, Average Loss: 3.957, avg. samples / sec: 7459.72
Iteration:   3440, Loss function: 3.393, Average Loss: 3.962, avg. samples / sec: 7460.09
Iteration:   3440, Loss function: 2.852, Average Loss: 3.957, avg. samples / sec: 7459.26
Iteration:   3440, Loss function: 3.311, Average Loss: 3.965, avg. samples / sec: 7460.01
Iteration:   3440, Loss function: 3.206, Average Loss: 3.965, avg. samples / sec: 7460.60
Iteration:   3440, Loss function: 4.282, Average Loss: 3.993, avg. samples / sec: 7459.74
Iteration:   3440, Loss function: 2.327, Average Loss: 3.962, avg. samples / sec: 7460.60
Iteration:   3460, Loss function: 4.253, Average Loss: 3.966, avg. samples / sec: 53754.73
Iteration:   3460, Loss function: 3.385, Average Loss: 3.945, avg. samples / sec: 53746.45
Iteration:   3460, Loss function: 2.098, Average Loss: 3.963, avg. samples / sec: 53759.90
Iteration:   3460, Loss function: 2.760, Average Loss: 3.957, avg. samples / sec: 53739.73
Iteration:   3460, Loss function: 3.133, Average Loss: 3.965, avg. samples / sec: 53685.09
Iteration:   3460, Loss function: 2.647, Average Loss: 3.979, avg. samples / sec: 53717.13
Iteration:   3460, Loss function: 4.563, Average Loss: 3.988, avg. samples / sec: 53717.99
Iteration:   3460, Loss function: 4.808, Average Loss: 3.933, avg. samples / sec: 53635.34
Iteration:   3460, Loss function: 3.755, Average Loss: 3.931, avg. samples / sec: 53615.95
Iteration:   3460, Loss function: 6.129, Average Loss: 3.948, avg. samples / sec: 53700.70
Iteration:   3460, Loss function: 2.722, Average Loss: 3.954, avg. samples / sec: 53715.53
Iteration:   3460, Loss function: 3.797, Average Loss: 3.945, avg. samples / sec: 53699.63
Iteration:   3460, Loss function: 2.727, Average Loss: 3.952, avg. samples / sec: 53756.19
Iteration:   3460, Loss function: 4.224, Average Loss: 3.959, avg. samples / sec: 53683.92
Iteration:   3460, Loss function: 2.771, Average Loss: 3.939, avg. samples / sec: 53656.08
Iteration:   3460, Loss function: 3.508, Average Loss: 3.950, avg. samples / sec: 53725.10
Iteration:   3460, Loss function: 3.471, Average Loss: 3.946, avg. samples / sec: 53748.93
Iteration:   3460, Loss function: 2.327, Average Loss: 3.945, avg. samples / sec: 53735.12
Iteration:   3460, Loss function: 3.980, Average Loss: 3.932, avg. samples / sec: 53688.65
Iteration:   3460, Loss function: 3.122, Average Loss: 3.968, avg. samples / sec: 53705.03
Iteration:   3460, Loss function: 3.820, Average Loss: 3.965, avg. samples / sec: 53724.69
Iteration:   3460, Loss function: 3.743, Average Loss: 3.980, avg. samples / sec: 53740.42
Iteration:   3460, Loss function: 3.946, Average Loss: 3.956, avg. samples / sec: 53734.09
Iteration:   3460, Loss function: 4.483, Average Loss: 3.940, avg. samples / sec: 53695.38
Iteration:   3460, Loss function: 3.847, Average Loss: 3.953, avg. samples / sec: 53720.59
Iteration:   3460, Loss function: 3.584, Average Loss: 3.942, avg. samples / sec: 53676.48
Iteration:   3460, Loss function: 2.657, Average Loss: 3.945, avg. samples / sec: 53659.21
Iteration:   3460, Loss function: 3.696, Average Loss: 3.952, avg. samples / sec: 53709.41
Iteration:   3460, Loss function: 2.720, Average Loss: 3.979, avg. samples / sec: 53677.99
Iteration:   3460, Loss function: 3.714, Average Loss: 3.960, avg. samples / sec: 53403.03
Iteration:   3480, Loss function: 4.868, Average Loss: 3.959, avg. samples / sec: 53853.88
Iteration:   3480, Loss function: 3.401, Average Loss: 3.955, avg. samples / sec: 53830.60
Iteration:   3480, Loss function: 2.415, Average Loss: 3.968, avg. samples / sec: 53825.29
Iteration:   3480, Loss function: 4.544, Average Loss: 3.920, avg. samples / sec: 53866.73
Iteration:   3480, Loss function: 3.059, Average Loss: 3.922, avg. samples / sec: 53857.18
Iteration:   3480, Loss function: 2.802, Average Loss: 3.952, avg. samples / sec: 53761.15
Iteration:   3480, Loss function: 4.846, Average Loss: 3.954, avg. samples / sec: 53760.80
Iteration:   3480, Loss function: 2.680, Average Loss: 3.981, avg. samples / sec: 53782.36
Iteration:   3480, Loss function: 3.106, Average Loss: 3.936, avg. samples / sec: 53665.77
Iteration:   3480, Loss function: 3.134, Average Loss: 3.932, avg. samples / sec: 53803.08
Iteration:   3480, Loss function: 3.965, Average Loss: 3.930, avg. samples / sec: 53807.97
Iteration:   3480, Loss function: 2.723, Average Loss: 3.935, avg. samples / sec: 53811.44
Iteration:   3480, Loss function: 3.337, Average Loss: 3.938, avg. samples / sec: 53791.35
Iteration:   3480, Loss function: 3.122, Average Loss: 3.942, avg. samples / sec: 53787.47
Iteration:   3480, Loss function: 4.018, Average Loss: 3.945, avg. samples / sec: 53798.95
Iteration:   3480, Loss function: 3.312, Average Loss: 3.925, avg. samples / sec: 53812.94
Iteration:   3480, Loss function: 3.546, Average Loss: 3.952, avg. samples / sec: 53870.58
Iteration:   3480, Loss function: 3.493, Average Loss: 3.967, avg. samples / sec: 53853.66
Iteration:   3480, Loss function: 3.368, Average Loss: 3.954, avg. samples / sec: 53805.20
Iteration:   3480, Loss function: 4.183, Average Loss: 3.958, avg. samples / sec: 53794.09
Iteration:   3480, Loss function: 3.403, Average Loss: 3.931, avg. samples / sec: 53812.59
Iteration:   3480, Loss function: 3.065, Average Loss: 3.927, avg. samples / sec: 53818.33
Iteration:   3480, Loss function: 3.195, Average Loss: 3.968, avg. samples / sec: 53801.11
Iteration:   3480, Loss function: 3.121, Average Loss: 3.934, avg. samples / sec: 53765.33
Iteration:   3480, Loss function: 4.446, Average Loss: 3.947, avg. samples / sec: 53786.61
Iteration:   3480, Loss function: 2.929, Average Loss: 3.944, avg. samples / sec: 53741.28
Iteration:   3480, Loss function: 3.180, Average Loss: 3.933, avg. samples / sec: 53754.32
Iteration:   3480, Loss function: 2.783, Average Loss: 3.942, avg. samples / sec: 53802.01
Iteration:   3480, Loss function: 4.745, Average Loss: 3.934, avg. samples / sec: 53794.02
Iteration:   3480, Loss function: 3.882, Average Loss: 3.940, avg. samples / sec: 53769.76
:::MLL 1558640972.365 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558640972.365 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 3.601, Average Loss: 3.951, avg. samples / sec: 53893.01
Iteration:   3500, Loss function: 3.461, Average Loss: 3.911, avg. samples / sec: 54050.87
Iteration:   3500, Loss function: 3.668, Average Loss: 3.944, avg. samples / sec: 53925.45
Iteration:   3500, Loss function: 2.853, Average Loss: 3.908, avg. samples / sec: 53920.13
Iteration:   3500, Loss function: 2.385, Average Loss: 3.970, avg. samples / sec: 53954.91
Iteration:   3500, Loss function: 4.688, Average Loss: 3.929, avg. samples / sec: 54022.69
Iteration:   3500, Loss function: 2.824, Average Loss: 3.947, avg. samples / sec: 53906.21
Iteration:   3500, Loss function: 3.294, Average Loss: 3.947, avg. samples / sec: 53874.70
Iteration:   3500, Loss function: 3.263, Average Loss: 3.957, avg. samples / sec: 53832.24
Iteration:   3500, Loss function: 3.612, Average Loss: 3.921, avg. samples / sec: 54022.98
Iteration:   3500, Loss function: 4.185, Average Loss: 3.923, avg. samples / sec: 54089.04
Iteration:   3500, Loss function: 2.962, Average Loss: 3.938, avg. samples / sec: 54031.18
Iteration:   3500, Loss function: 3.489, Average Loss: 3.927, avg. samples / sec: 53980.97
Iteration:   3500, Loss function: 4.063, Average Loss: 3.931, avg. samples / sec: 53970.49
Iteration:   3500, Loss function: 3.739, Average Loss: 3.955, avg. samples / sec: 53972.02
Iteration:   3500, Loss function: 4.270, Average Loss: 3.935, avg. samples / sec: 53984.32
Iteration:   3500, Loss function: 4.718, Average Loss: 3.925, avg. samples / sec: 53900.78
Iteration:   3500, Loss function: 3.515, Average Loss: 3.933, avg. samples / sec: 53907.75
Iteration:   3500, Loss function: 3.472, Average Loss: 3.920, avg. samples / sec: 53902.23
Iteration:   3500, Loss function: 2.531, Average Loss: 3.946, avg. samples / sec: 53920.64
Iteration:   3500, Loss function: 3.150, Average Loss: 3.940, avg. samples / sec: 53938.64
Iteration:   3500, Loss function: 4.681, Average Loss: 3.949, avg. samples / sec: 53913.45
Iteration:   3500, Loss function: 4.066, Average Loss: 3.919, avg. samples / sec: 53908.39
Iteration:   3500, Loss function: 3.207, Average Loss: 3.924, avg. samples / sec: 53915.26
Iteration:   3500, Loss function: 2.680, Average Loss: 3.914, avg. samples / sec: 53871.77
Iteration:   3500, Loss function: 3.884, Average Loss: 3.924, avg. samples / sec: 53917.65
Iteration:   3500, Loss function: 4.637, Average Loss: 3.942, avg. samples / sec: 53857.86
Iteration:   3500, Loss function: 2.923, Average Loss: 3.929, avg. samples / sec: 53918.44
Iteration:   3500, Loss function: 3.696, Average Loss: 3.929, avg. samples / sec: 53901.96
Iteration:   3500, Loss function: 2.579, Average Loss: 3.960, avg. samples / sec: 53836.05
Iteration:   3520, Loss function: 3.516, Average Loss: 3.942, avg. samples / sec: 53964.77
Iteration:   3520, Loss function: 3.781, Average Loss: 3.901, avg. samples / sec: 53884.32
Iteration:   3520, Loss function: 4.065, Average Loss: 3.925, avg. samples / sec: 54006.60
Iteration:   3520, Loss function: 3.810, Average Loss: 3.929, avg. samples / sec: 53965.68
Iteration:   3520, Loss function: 3.838, Average Loss: 3.938, avg. samples / sec: 54040.67
Iteration:   3520, Loss function: 3.115, Average Loss: 3.898, avg. samples / sec: 53949.15
Iteration:   3520, Loss function: 3.006, Average Loss: 3.956, avg. samples / sec: 53946.36
Iteration:   3520, Loss function: 3.149, Average Loss: 3.946, avg. samples / sec: 54020.14
Iteration:   3520, Loss function: 3.764, Average Loss: 3.936, avg. samples / sec: 53945.76
Iteration:   3520, Loss function: 3.723, Average Loss: 3.935, avg. samples / sec: 54036.59
Iteration:   3520, Loss function: 5.053, Average Loss: 3.918, avg. samples / sec: 53892.05
Iteration:   3520, Loss function: 3.902, Average Loss: 3.918, avg. samples / sec: 54000.48
Iteration:   3520, Loss function: 3.812, Average Loss: 3.936, avg. samples / sec: 53870.04
Iteration:   3520, Loss function: 2.414, Average Loss: 3.911, avg. samples / sec: 53992.41
Iteration:   3520, Loss function: 2.197, Average Loss: 3.928, avg. samples / sec: 54042.79
Iteration:   3520, Loss function: 3.432, Average Loss: 3.920, avg. samples / sec: 53977.07
Iteration:   3520, Loss function: 2.277, Average Loss: 3.899, avg. samples / sec: 54014.39
Iteration:   3520, Loss function: 2.847, Average Loss: 3.950, avg. samples / sec: 54056.45
Iteration:   3520, Loss function: 2.616, Average Loss: 3.937, avg. samples / sec: 53984.10
Iteration:   3520, Loss function: 3.064, Average Loss: 3.915, avg. samples / sec: 53843.27
Iteration:   3520, Loss function: 3.994, Average Loss: 3.943, avg. samples / sec: 53918.21
Iteration:   3520, Loss function: 2.993, Average Loss: 3.927, avg. samples / sec: 53912.58
Iteration:   3520, Loss function: 2.361, Average Loss: 3.916, avg. samples / sec: 53997.38
Iteration:   3520, Loss function: 4.015, Average Loss: 3.910, avg. samples / sec: 53968.65
Iteration:   3520, Loss function: 3.281, Average Loss: 3.922, avg. samples / sec: 54011.14
Iteration:   3520, Loss function: 3.141, Average Loss: 3.925, avg. samples / sec: 53913.38
Iteration:   3520, Loss function: 3.796, Average Loss: 3.929, avg. samples / sec: 53943.80
Iteration:   3520, Loss function: 3.858, Average Loss: 3.923, avg. samples / sec: 53989.85
Iteration:   3520, Loss function: 3.966, Average Loss: 3.914, avg. samples / sec: 53940.87
Iteration:   3520, Loss function: 2.124, Average Loss: 3.918, avg. samples / sec: 53829.98
Iteration:   3540, Loss function: 2.757, Average Loss: 3.933, avg. samples / sec: 54177.33
Iteration:   3540, Loss function: 2.412, Average Loss: 3.888, avg. samples / sec: 54179.66
Iteration:   3540, Loss function: 3.391, Average Loss: 3.940, avg. samples / sec: 54216.87
Iteration:   3540, Loss function: 3.835, Average Loss: 3.915, avg. samples / sec: 54152.12
Iteration:   3540, Loss function: 2.839, Average Loss: 3.891, avg. samples / sec: 54161.55
Iteration:   3540, Loss function: 3.121, Average Loss: 3.946, avg. samples / sec: 54167.35
Iteration:   3540, Loss function: 2.664, Average Loss: 3.921, avg. samples / sec: 54203.29
Iteration:   3540, Loss function: 2.498, Average Loss: 3.927, avg. samples / sec: 54106.32
Iteration:   3540, Loss function: 4.008, Average Loss: 3.920, avg. samples / sec: 53969.73
Iteration:   3540, Loss function: 2.992, Average Loss: 3.928, avg. samples / sec: 54197.16
Iteration:   3540, Loss function: 3.713, Average Loss: 3.910, avg. samples / sec: 54179.35
Iteration:   3540, Loss function: 3.962, Average Loss: 3.908, avg. samples / sec: 54275.48
Iteration:   3540, Loss function: 4.386, Average Loss: 3.913, avg. samples / sec: 54202.08
Iteration:   3540, Loss function: 2.767, Average Loss: 3.898, avg. samples / sec: 54230.70
Iteration:   3540, Loss function: 3.258, Average Loss: 3.903, avg. samples / sec: 54180.49
Iteration:   3540, Loss function: 3.149, Average Loss: 3.903, avg. samples / sec: 54199.58
Iteration:   3540, Loss function: 3.101, Average Loss: 3.918, avg. samples / sec: 54181.24
Iteration:   3540, Loss function: 3.276, Average Loss: 3.904, avg. samples / sec: 54249.11
Iteration:   3540, Loss function: 2.278, Average Loss: 3.907, avg. samples / sec: 54150.39
Iteration:   3540, Loss function: 4.564, Average Loss: 3.926, avg. samples / sec: 54115.75
Iteration:   3540, Loss function: 2.650, Average Loss: 3.908, avg. samples / sec: 54196.60
Iteration:   3540, Loss function: 4.203, Average Loss: 3.930, avg. samples / sec: 54169.25
Iteration:   3540, Loss function: 3.056, Average Loss: 3.915, avg. samples / sec: 54173.98
Iteration:   3540, Loss function: 3.084, Average Loss: 3.918, avg. samples / sec: 54199.33
Iteration:   3540, Loss function: 2.957, Average Loss: 3.914, avg. samples / sec: 54185.81
Iteration:   3540, Loss function: 4.782, Average Loss: 3.937, avg. samples / sec: 54160.19
Iteration:   3540, Loss function: 2.358, Average Loss: 3.941, avg. samples / sec: 54135.00
Iteration:   3540, Loss function: 2.922, Average Loss: 3.885, avg. samples / sec: 54132.42
Iteration:   3540, Loss function: 2.842, Average Loss: 3.903, avg. samples / sec: 54156.07
Iteration:   3540, Loss function: 3.656, Average Loss: 3.910, avg. samples / sec: 54149.77
:::MLL 1558640974.232 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558640974.232 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 3.842, Average Loss: 3.879, avg. samples / sec: 53954.64
Iteration:   3560, Loss function: 3.688, Average Loss: 3.924, avg. samples / sec: 53815.12
Iteration:   3560, Loss function: 3.494, Average Loss: 3.885, avg. samples / sec: 53847.65
Iteration:   3560, Loss function: 3.402, Average Loss: 3.903, avg. samples / sec: 53802.61
Iteration:   3560, Loss function: 3.474, Average Loss: 3.914, avg. samples / sec: 53854.19
Iteration:   3560, Loss function: 4.003, Average Loss: 3.926, avg. samples / sec: 53761.11
Iteration:   3560, Loss function: 3.018, Average Loss: 3.935, avg. samples / sec: 53796.24
Iteration:   3560, Loss function: 2.930, Average Loss: 3.916, avg. samples / sec: 53796.43
Iteration:   3560, Loss function: 3.931, Average Loss: 3.918, avg. samples / sec: 53910.97
Iteration:   3560, Loss function: 3.773, Average Loss: 3.898, avg. samples / sec: 53916.95
Iteration:   3560, Loss function: 2.255, Average Loss: 3.904, avg. samples / sec: 53912.04
Iteration:   3560, Loss function: 2.451, Average Loss: 3.910, avg. samples / sec: 53813.85
Iteration:   3560, Loss function: 2.557, Average Loss: 3.928, avg. samples / sec: 53914.00
Iteration:   3560, Loss function: 3.421, Average Loss: 3.900, avg. samples / sec: 53806.90
Iteration:   3560, Loss function: 2.629, Average Loss: 3.894, avg. samples / sec: 53825.81
Iteration:   3560, Loss function: 3.779, Average Loss: 3.898, avg. samples / sec: 53815.59
Iteration:   3560, Loss function: 2.397, Average Loss: 3.900, avg. samples / sec: 53837.63
Iteration:   3560, Loss function: 2.918, Average Loss: 3.914, avg. samples / sec: 53844.28
Iteration:   3560, Loss function: 3.247, Average Loss: 3.896, avg. samples / sec: 53795.05
Iteration:   3560, Loss function: 1.703, Average Loss: 3.902, avg. samples / sec: 53801.91
Iteration:   3560, Loss function: 2.996, Average Loss: 3.876, avg. samples / sec: 53849.21
Iteration:   3560, Loss function: 3.080, Average Loss: 3.920, avg. samples / sec: 53816.35
Iteration:   3560, Loss function: 3.061, Average Loss: 3.892, avg. samples / sec: 53794.72
Iteration:   3560, Loss function: 3.363, Average Loss: 3.907, avg. samples / sec: 53823.92
Iteration:   3560, Loss function: 3.470, Average Loss: 3.891, avg. samples / sec: 53833.07
Iteration:   3560, Loss function: 3.932, Average Loss: 3.892, avg. samples / sec: 53765.78
Iteration:   3560, Loss function: 3.015, Average Loss: 3.924, avg. samples / sec: 53813.25
Iteration:   3560, Loss function: 3.520, Average Loss: 3.899, avg. samples / sec: 53831.42
Iteration:   3560, Loss function: 3.634, Average Loss: 3.906, avg. samples / sec: 53796.18
Iteration:   3560, Loss function: 2.526, Average Loss: 3.889, avg. samples / sec: 53739.42
Iteration:   3580, Loss function: 3.780, Average Loss: 3.916, avg. samples / sec: 54206.11
Iteration:   3580, Loss function: 4.588, Average Loss: 3.875, avg. samples / sec: 54199.87
Iteration:   3580, Loss function: 3.325, Average Loss: 3.906, avg. samples / sec: 54276.92
Iteration:   3580, Loss function: 4.690, Average Loss: 3.875, avg. samples / sec: 54210.26
Iteration:   3580, Loss function: 5.182, Average Loss: 3.915, avg. samples / sec: 54236.75
Iteration:   3580, Loss function: 2.337, Average Loss: 3.891, avg. samples / sec: 54195.25
Iteration:   3580, Loss function: 4.439, Average Loss: 3.926, avg. samples / sec: 54242.89
Iteration:   3580, Loss function: 4.164, Average Loss: 3.911, avg. samples / sec: 54154.14
Iteration:   3580, Loss function: 3.517, Average Loss: 3.891, avg. samples / sec: 54231.16
Iteration:   3580, Loss function: 3.355, Average Loss: 3.905, avg. samples / sec: 54197.83
Iteration:   3580, Loss function: 3.615, Average Loss: 3.886, avg. samples / sec: 54230.28
Iteration:   3580, Loss function: 2.713, Average Loss: 3.906, avg. samples / sec: 54091.80
Iteration:   3580, Loss function: 3.577, Average Loss: 3.913, avg. samples / sec: 54268.18
Iteration:   3580, Loss function: 4.186, Average Loss: 3.891, avg. samples / sec: 54194.52
Iteration:   3580, Loss function: 3.403, Average Loss: 3.866, avg. samples / sec: 54229.72
Iteration:   3580, Loss function: 5.658, Average Loss: 3.894, avg. samples / sec: 54196.21
Iteration:   3580, Loss function: 3.214, Average Loss: 3.883, avg. samples / sec: 54244.94
Iteration:   3580, Loss function: 4.008, Average Loss: 3.900, avg. samples / sec: 54232.93
Iteration:   3580, Loss function: 4.425, Average Loss: 3.884, avg. samples / sec: 54176.75
Iteration:   3580, Loss function: 3.718, Average Loss: 3.890, avg. samples / sec: 54100.56
Iteration:   3580, Loss function: 3.447, Average Loss: 3.907, avg. samples / sec: 54169.60
Iteration:   3580, Loss function: 3.952, Average Loss: 3.894, avg. samples / sec: 54182.12
Iteration:   3580, Loss function: 2.750, Average Loss: 3.878, avg. samples / sec: 54207.25
Iteration:   3580, Loss function: 3.061, Average Loss: 3.887, avg. samples / sec: 54219.50
Iteration:   3580, Loss function: 2.922, Average Loss: 3.906, avg. samples / sec: 54186.91
Iteration:   3580, Loss function: 3.120, Average Loss: 3.883, avg. samples / sec: 54186.58
Iteration:   3580, Loss function: 3.287, Average Loss: 3.875, avg. samples / sec: 54231.60
Iteration:   3580, Loss function: 4.215, Average Loss: 3.896, avg. samples / sec: 54212.84
Iteration:   3580, Loss function: 4.464, Average Loss: 3.920, avg. samples / sec: 54103.72
Iteration:   3580, Loss function: 2.997, Average Loss: 3.888, avg. samples / sec: 54075.01
Iteration:   3600, Loss function: 3.531, Average Loss: 3.911, avg. samples / sec: 54212.15
Iteration:   3600, Loss function: 3.604, Average Loss: 3.864, avg. samples / sec: 54100.04
Iteration:   3600, Loss function: 3.716, Average Loss: 3.900, avg. samples / sec: 54347.61
Iteration:   3600, Loss function: 2.872, Average Loss: 3.885, avg. samples / sec: 54284.89
Iteration:   3600, Loss function: 2.665, Average Loss: 3.898, avg. samples / sec: 54239.24
Iteration:   3600, Loss function: 3.333, Average Loss: 3.913, avg. samples / sec: 54259.22
Iteration:   3600, Loss function: 2.592, Average Loss: 3.908, avg. samples / sec: 54240.72
Iteration:   3600, Loss function: 3.506, Average Loss: 3.863, avg. samples / sec: 54181.68
Iteration:   3600, Loss function: 2.480, Average Loss: 3.898, avg. samples / sec: 54290.01
Iteration:   3600, Loss function: 3.484, Average Loss: 3.884, avg. samples / sec: 54233.04
Iteration:   3600, Loss function: 2.885, Average Loss: 3.881, avg. samples / sec: 54262.65
Iteration:   3600, Loss function: 3.132, Average Loss: 3.880, avg. samples / sec: 54268.50
Iteration:   3600, Loss function: 4.319, Average Loss: 3.887, avg. samples / sec: 54298.90
Iteration:   3600, Loss function: 4.596, Average Loss: 3.871, avg. samples / sec: 54313.67
Iteration:   3600, Loss function: 2.798, Average Loss: 3.907, avg. samples / sec: 54312.40
Iteration:   3600, Loss function: 2.841, Average Loss: 3.891, avg. samples / sec: 54210.69
Iteration:   3600, Loss function: 3.898, Average Loss: 3.874, avg. samples / sec: 54234.96
Iteration:   3600, Loss function: 3.784, Average Loss: 3.875, avg. samples / sec: 54259.56
Iteration:   3600, Loss function: 3.242, Average Loss: 3.859, avg. samples / sec: 54240.26
Iteration:   3600, Loss function: 3.103, Average Loss: 3.882, avg. samples / sec: 54314.22
Iteration:   3600, Loss function: 3.318, Average Loss: 3.891, avg. samples / sec: 54264.88
Iteration:   3600, Loss function: 3.473, Average Loss: 3.871, avg. samples / sec: 54237.63
Iteration:   3600, Loss function: 4.057, Average Loss: 3.900, avg. samples / sec: 54213.74
Iteration:   3600, Loss function: 1.776, Average Loss: 3.895, avg. samples / sec: 54252.58
Iteration:   3600, Loss function: 3.310, Average Loss: 3.891, avg. samples / sec: 54228.07
Iteration:   3600, Loss function: 2.407, Average Loss: 3.865, avg. samples / sec: 54266.85
Iteration:   3600, Loss function: 3.679, Average Loss: 3.896, avg. samples / sec: 54231.03
Iteration:   3600, Loss function: 2.045, Average Loss: 3.876, avg. samples / sec: 54229.16
Iteration:   3600, Loss function: 4.605, Average Loss: 3.869, avg. samples / sec: 54230.80
Iteration:   3600, Loss function: 3.475, Average Loss: 3.888, avg. samples / sec: 54241.53
Iteration:   3620, Loss function: 2.368, Average Loss: 3.859, avg. samples / sec: 54492.54
Iteration:   3620, Loss function: 3.659, Average Loss: 3.854, avg. samples / sec: 54506.24
Iteration:   3620, Loss function: 3.044, Average Loss: 3.870, avg. samples / sec: 54412.84
Iteration:   3620, Loss function: 3.133, Average Loss: 3.889, avg. samples / sec: 54414.36
Iteration:   3620, Loss function: 3.490, Average Loss: 3.905, avg. samples / sec: 54443.03
Iteration:   3620, Loss function: 2.847, Average Loss: 3.894, avg. samples / sec: 54447.36
Iteration:   3620, Loss function: 3.375, Average Loss: 3.889, avg. samples / sec: 54380.87
Iteration:   3620, Loss function: 2.987, Average Loss: 3.883, avg. samples / sec: 54547.68
Iteration:   3620, Loss function: 3.742, Average Loss: 3.871, avg. samples / sec: 54490.20
Iteration:   3620, Loss function: 3.388, Average Loss: 3.864, avg. samples / sec: 54487.49
Iteration:   3620, Loss function: 3.416, Average Loss: 3.891, avg. samples / sec: 54514.42
Iteration:   3620, Loss function: 2.726, Average Loss: 3.871, avg. samples / sec: 54463.73
Iteration:   3620, Loss function: 2.682, Average Loss: 3.864, avg. samples / sec: 54469.06
Iteration:   3620, Loss function: 4.930, Average Loss: 3.875, avg. samples / sec: 54456.98
Iteration:   3620, Loss function: 4.476, Average Loss: 3.889, avg. samples / sec: 54425.66
Iteration:   3620, Loss function: 3.586, Average Loss: 3.864, avg. samples / sec: 54473.88
Iteration:   3620, Loss function: 2.398, Average Loss: 3.883, avg. samples / sec: 54530.41
Iteration:   3620, Loss function: 4.231, Average Loss: 3.881, avg. samples / sec: 54536.05
Iteration:   3620, Loss function: 2.814, Average Loss: 3.863, avg. samples / sec: 54490.79
Iteration:   3620, Loss function: 3.432, Average Loss: 3.879, avg. samples / sec: 54493.28
Iteration:   3620, Loss function: 2.454, Average Loss: 3.896, avg. samples / sec: 54455.99
Iteration:   3620, Loss function: 2.766, Average Loss: 3.891, avg. samples / sec: 54484.98
Iteration:   3620, Loss function: 3.341, Average Loss: 3.874, avg. samples / sec: 54436.34
Iteration:   3620, Loss function: 3.431, Average Loss: 3.885, avg. samples / sec: 54478.05
Iteration:   3620, Loss function: 3.654, Average Loss: 3.906, avg. samples / sec: 54059.12
Iteration:   3620, Loss function: 2.225, Average Loss: 3.869, avg. samples / sec: 54486.29
Iteration:   3620, Loss function: 2.496, Average Loss: 3.853, avg. samples / sec: 54446.06
Iteration:   3620, Loss function: 2.793, Average Loss: 3.849, avg. samples / sec: 54406.98
Iteration:   3620, Loss function: 3.890, Average Loss: 3.878, avg. samples / sec: 54405.87
Iteration:   3620, Loss function: 3.626, Average Loss: 3.857, avg. samples / sec: 54444.69
:::MLL 1558640976.407 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558640976.408 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 2.946, Average Loss: 3.844, avg. samples / sec: 53370.49
Iteration:   3640, Loss function: 3.795, Average Loss: 3.897, avg. samples / sec: 53352.10
Iteration:   3640, Loss function: 3.101, Average Loss: 3.854, avg. samples / sec: 53253.78
Iteration:   3640, Loss function: 3.294, Average Loss: 3.881, avg. samples / sec: 53341.12
Iteration:   3640, Loss function: 3.296, Average Loss: 3.860, avg. samples / sec: 53329.69
Iteration:   3640, Loss function: 3.073, Average Loss: 3.879, avg. samples / sec: 53309.40
Iteration:   3640, Loss function: 3.348, Average Loss: 3.879, avg. samples / sec: 53333.34
Iteration:   3640, Loss function: 3.077, Average Loss: 3.842, avg. samples / sec: 53435.49
Iteration:   3640, Loss function: 2.214, Average Loss: 3.873, avg. samples / sec: 53334.92
Iteration:   3640, Loss function: 2.813, Average Loss: 3.874, avg. samples / sec: 53263.92
Iteration:   3640, Loss function: 3.168, Average Loss: 3.852, avg. samples / sec: 53331.43
Iteration:   3640, Loss function: 3.386, Average Loss: 3.878, avg. samples / sec: 53313.73
Iteration:   3640, Loss function: 2.469, Average Loss: 3.866, avg. samples / sec: 53321.08
Iteration:   3640, Loss function: 4.066, Average Loss: 3.867, avg. samples / sec: 53311.41
Iteration:   3640, Loss function: 2.941, Average Loss: 3.859, avg. samples / sec: 53302.30
Iteration:   3640, Loss function: 3.210, Average Loss: 3.866, avg. samples / sec: 53280.80
Iteration:   3640, Loss function: 2.475, Average Loss: 3.876, avg. samples / sec: 53307.70
Iteration:   3640, Loss function: 3.428, Average Loss: 3.862, avg. samples / sec: 53322.43
Iteration:   3640, Loss function: 2.897, Average Loss: 3.871, avg. samples / sec: 53301.27
Iteration:   3640, Loss function: 3.683, Average Loss: 3.847, avg. samples / sec: 53384.32
Iteration:   3640, Loss function: 4.142, Average Loss: 3.892, avg. samples / sec: 53299.34
Iteration:   3640, Loss function: 3.573, Average Loss: 3.870, avg. samples / sec: 53288.96
Iteration:   3640, Loss function: 3.851, Average Loss: 3.854, avg. samples / sec: 53295.77
Iteration:   3640, Loss function: 3.731, Average Loss: 3.857, avg. samples / sec: 53273.14
Iteration:   3640, Loss function: 3.165, Average Loss: 3.842, avg. samples / sec: 53343.48
Iteration:   3640, Loss function: 2.983, Average Loss: 3.895, avg. samples / sec: 53308.73
Iteration:   3640, Loss function: 4.089, Average Loss: 3.873, avg. samples / sec: 53302.82
Iteration:   3640, Loss function: 3.181, Average Loss: 3.866, avg. samples / sec: 53346.67
Iteration:   3640, Loss function: 4.302, Average Loss: 3.885, avg. samples / sec: 53286.38
Iteration:   3640, Loss function: 2.994, Average Loss: 3.857, avg. samples / sec: 53316.35
Iteration:   3660, Loss function: 2.823, Average Loss: 3.870, avg. samples / sec: 53749.79
Iteration:   3660, Loss function: 2.373, Average Loss: 3.867, avg. samples / sec: 53765.44
Iteration:   3660, Loss function: 3.618, Average Loss: 3.848, avg. samples / sec: 53720.06
Iteration:   3660, Loss function: 2.897, Average Loss: 3.855, avg. samples / sec: 53727.11
Iteration:   3660, Loss function: 2.856, Average Loss: 3.832, avg. samples / sec: 53666.81
Iteration:   3660, Loss function: 2.915, Average Loss: 3.868, avg. samples / sec: 53740.73
Iteration:   3660, Loss function: 2.766, Average Loss: 3.883, avg. samples / sec: 53675.72
Iteration:   3660, Loss function: 2.638, Average Loss: 3.862, avg. samples / sec: 53739.54
Iteration:   3660, Loss function: 4.118, Average Loss: 3.859, avg. samples / sec: 53763.59
Iteration:   3660, Loss function: 3.978, Average Loss: 3.852, avg. samples / sec: 53749.73
Iteration:   3660, Loss function: 5.006, Average Loss: 3.859, avg. samples / sec: 53736.61
Iteration:   3660, Loss function: 2.695, Average Loss: 3.870, avg. samples / sec: 53755.65
Iteration:   3660, Loss function: 3.222, Average Loss: 3.864, avg. samples / sec: 53759.18
Iteration:   3660, Loss function: 3.467, Average Loss: 3.836, avg. samples / sec: 53753.79
Iteration:   3660, Loss function: 3.742, Average Loss: 3.859, avg. samples / sec: 53695.83
Iteration:   3660, Loss function: 3.359, Average Loss: 3.863, avg. samples / sec: 53746.28
Iteration:   3660, Loss function: 4.028, Average Loss: 3.876, avg. samples / sec: 53760.23
Iteration:   3660, Loss function: 3.450, Average Loss: 3.869, avg. samples / sec: 53693.62
Iteration:   3660, Loss function: 4.318, Average Loss: 3.846, avg. samples / sec: 53685.68
Iteration:   3660, Loss function: 2.314, Average Loss: 3.832, avg. samples / sec: 53648.59
Iteration:   3660, Loss function: 3.283, Average Loss: 3.861, avg. samples / sec: 53736.36
Iteration:   3660, Loss function: 2.310, Average Loss: 3.851, avg. samples / sec: 53709.50
Iteration:   3660, Loss function: 5.127, Average Loss: 3.845, avg. samples / sec: 53723.07
Iteration:   3660, Loss function: 4.482, Average Loss: 3.886, avg. samples / sec: 53719.43
Iteration:   3660, Loss function: 2.462, Average Loss: 3.840, avg. samples / sec: 53713.73
Iteration:   3660, Loss function: 3.487, Average Loss: 3.851, avg. samples / sec: 53710.38
Iteration:   3660, Loss function: 4.297, Average Loss: 3.887, avg. samples / sec: 53712.28
Iteration:   3660, Loss function: 3.013, Average Loss: 3.867, avg. samples / sec: 53701.92
Iteration:   3660, Loss function: 3.745, Average Loss: 3.854, avg. samples / sec: 53707.33
Iteration:   3660, Loss function: 3.821, Average Loss: 3.862, avg. samples / sec: 53643.52
Iteration:   3680, Loss function: 3.305, Average Loss: 3.861, avg. samples / sec: 53350.55
Iteration:   3680, Loss function: 3.220, Average Loss: 3.840, avg. samples / sec: 53359.45
Iteration:   3680, Loss function: 3.323, Average Loss: 3.821, avg. samples / sec: 53360.79
Iteration:   3680, Loss function: 2.309, Average Loss: 3.862, avg. samples / sec: 53332.42
Iteration:   3680, Loss function: 3.629, Average Loss: 3.831, avg. samples / sec: 53564.56
Iteration:   3680, Loss function: 3.436, Average Loss: 3.878, avg. samples / sec: 53369.66
Iteration:   3680, Loss function: 3.070, Average Loss: 3.842, avg. samples / sec: 53313.77
Iteration:   3680, Loss function: 3.873, Average Loss: 3.857, avg. samples / sec: 53346.89
Iteration:   3680, Loss function: 3.762, Average Loss: 3.850, avg. samples / sec: 53392.59
Iteration:   3680, Loss function: 3.277, Average Loss: 3.847, avg. samples / sec: 53334.15
Iteration:   3680, Loss function: 3.685, Average Loss: 3.856, avg. samples / sec: 53322.41
Iteration:   3680, Loss function: 3.841, Average Loss: 3.849, avg. samples / sec: 53337.56
Iteration:   3680, Loss function: 3.630, Average Loss: 3.851, avg. samples / sec: 53425.52
Iteration:   3680, Loss function: 4.363, Average Loss: 3.854, avg. samples / sec: 53317.54
Iteration:   3680, Loss function: 3.836, Average Loss: 3.870, avg. samples / sec: 53383.00
Iteration:   3680, Loss function: 3.741, Average Loss: 3.854, avg. samples / sec: 53324.48
Iteration:   3680, Loss function: 3.434, Average Loss: 3.842, avg. samples / sec: 53368.10
Iteration:   3680, Loss function: 3.023, Average Loss: 3.870, avg. samples / sec: 53344.41
Iteration:   3680, Loss function: 4.296, Average Loss: 3.839, avg. samples / sec: 53354.77
Iteration:   3680, Loss function: 3.919, Average Loss: 3.836, avg. samples / sec: 53344.99
Iteration:   3680, Loss function: 2.876, Average Loss: 3.826, avg. samples / sec: 53345.78
Iteration:   3680, Loss function: 3.210, Average Loss: 3.862, avg. samples / sec: 53330.76
Iteration:   3680, Loss function: 3.686, Average Loss: 3.837, avg. samples / sec: 53356.54
Iteration:   3680, Loss function: 4.301, Average Loss: 3.862, avg. samples / sec: 53290.95
Iteration:   3680, Loss function: 3.316, Average Loss: 3.856, avg. samples / sec: 53370.57
Iteration:   3680, Loss function: 3.524, Average Loss: 3.879, avg. samples / sec: 53353.29
Iteration:   3680, Loss function: 3.546, Average Loss: 3.845, avg. samples / sec: 53361.09
Iteration:   3680, Loss function: 2.907, Average Loss: 3.836, avg. samples / sec: 53328.28
Iteration:   3680, Loss function: 3.630, Average Loss: 3.853, avg. samples / sec: 53288.78
Iteration:   3680, Loss function: 3.184, Average Loss: 3.848, avg. samples / sec: 53298.95
:::MLL 1558640978.607 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558640978.607 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 3.628, Average Loss: 3.836, avg. samples / sec: 53224.19
Iteration:   3700, Loss function: 3.560, Average Loss: 3.829, avg. samples / sec: 53122.54
Iteration:   3700, Loss function: 3.424, Average Loss: 3.823, avg. samples / sec: 53080.70
Iteration:   3700, Loss function: 3.144, Average Loss: 3.812, avg. samples / sec: 53062.81
Iteration:   3700, Loss function: 2.733, Average Loss: 3.849, avg. samples / sec: 53039.66
Iteration:   3700, Loss function: 3.966, Average Loss: 3.866, avg. samples / sec: 53073.78
Iteration:   3700, Loss function: 3.299, Average Loss: 3.855, avg. samples / sec: 53057.34
Iteration:   3700, Loss function: 3.167, Average Loss: 3.849, avg. samples / sec: 53087.60
Iteration:   3700, Loss function: 2.002, Average Loss: 3.838, avg. samples / sec: 53153.39
Iteration:   3700, Loss function: 2.981, Average Loss: 3.835, avg. samples / sec: 53094.86
Iteration:   3700, Loss function: 4.658, Average Loss: 3.864, avg. samples / sec: 53139.06
Iteration:   3700, Loss function: 2.784, Average Loss: 3.839, avg. samples / sec: 53187.43
Iteration:   3700, Loss function: 3.855, Average Loss: 3.833, avg. samples / sec: 53129.83
Iteration:   3700, Loss function: 1.890, Average Loss: 3.845, avg. samples / sec: 53080.70
Iteration:   3700, Loss function: 3.744, Average Loss: 3.846, avg. samples / sec: 53091.68
Iteration:   3700, Loss function: 3.790, Average Loss: 3.841, avg. samples / sec: 53077.76
Iteration:   3700, Loss function: 3.785, Average Loss: 3.830, avg. samples / sec: 53103.82
Iteration:   3700, Loss function: 3.061, Average Loss: 3.847, avg. samples / sec: 53119.21
Iteration:   3700, Loss function: 4.297, Average Loss: 3.840, avg. samples / sec: 53062.47
Iteration:   3700, Loss function: 3.718, Average Loss: 3.860, avg. samples / sec: 53090.18
Iteration:   3700, Loss function: 2.337, Average Loss: 3.866, avg. samples / sec: 53115.11
Iteration:   3700, Loss function: 2.435, Average Loss: 3.832, avg. samples / sec: 53088.04
Iteration:   3700, Loss function: 3.863, Average Loss: 3.830, avg. samples / sec: 53087.76
Iteration:   3700, Loss function: 3.294, Average Loss: 3.845, avg. samples / sec: 53071.46
Iteration:   3700, Loss function: 3.076, Average Loss: 3.844, avg. samples / sec: 53036.13
Iteration:   3700, Loss function: 3.233, Average Loss: 3.820, avg. samples / sec: 53050.80
Iteration:   3700, Loss function: 3.104, Average Loss: 3.832, avg. samples / sec: 53048.29
Iteration:   3700, Loss function: 3.711, Average Loss: 3.835, avg. samples / sec: 53075.56
Iteration:   3700, Loss function: 2.843, Average Loss: 3.849, avg. samples / sec: 53027.13
Iteration:   3700, Loss function: 2.931, Average Loss: 3.836, avg. samples / sec: 53054.52
Iteration:   3720, Loss function: 2.668, Average Loss: 3.828, avg. samples / sec: 53276.18
Iteration:   3720, Loss function: 3.114, Average Loss: 3.822, avg. samples / sec: 53422.06
Iteration:   3720, Loss function: 3.576, Average Loss: 3.858, avg. samples / sec: 53430.10
Iteration:   3720, Loss function: 3.201, Average Loss: 3.851, avg. samples / sec: 53426.94
Iteration:   3720, Loss function: 3.376, Average Loss: 3.836, avg. samples / sec: 53421.77
Iteration:   3720, Loss function: 2.919, Average Loss: 3.817, avg. samples / sec: 53397.36
Iteration:   3720, Loss function: 4.136, Average Loss: 3.804, avg. samples / sec: 53396.43
Iteration:   3720, Loss function: 2.694, Average Loss: 3.837, avg. samples / sec: 53392.16
Iteration:   3720, Loss function: 3.651, Average Loss: 3.838, avg. samples / sec: 53423.98
Iteration:   3720, Loss function: 3.721, Average Loss: 3.835, avg. samples / sec: 53427.48
Iteration:   3720, Loss function: 3.958, Average Loss: 3.833, avg. samples / sec: 53426.41
Iteration:   3720, Loss function: 4.152, Average Loss: 3.816, avg. samples / sec: 53418.76
Iteration:   3720, Loss function: 4.189, Average Loss: 3.832, avg. samples / sec: 53361.13
Iteration:   3720, Loss function: 3.555, Average Loss: 3.833, avg. samples / sec: 53322.20
Iteration:   3720, Loss function: 3.962, Average Loss: 3.837, avg. samples / sec: 53457.34
Iteration:   3720, Loss function: 3.980, Average Loss: 3.837, avg. samples / sec: 53389.86
Iteration:   3720, Loss function: 4.166, Average Loss: 3.856, avg. samples / sec: 53404.38
Iteration:   3720, Loss function: 3.620, Average Loss: 3.826, avg. samples / sec: 53420.94
Iteration:   3720, Loss function: 2.936, Average Loss: 3.846, avg. samples / sec: 53394.59
Iteration:   3720, Loss function: 3.517, Average Loss: 3.837, avg. samples / sec: 53440.84
Iteration:   3720, Loss function: 4.253, Average Loss: 3.840, avg. samples / sec: 53388.83
Iteration:   3720, Loss function: 2.824, Average Loss: 3.853, avg. samples / sec: 53328.28
Iteration:   3720, Loss function: 2.793, Average Loss: 3.839, avg. samples / sec: 53465.31
Iteration:   3720, Loss function: 2.622, Average Loss: 3.823, avg. samples / sec: 53428.70
Iteration:   3720, Loss function: 3.638, Average Loss: 3.811, avg. samples / sec: 53427.26
Iteration:   3720, Loss function: 3.297, Average Loss: 3.829, avg. samples / sec: 53326.42
Iteration:   3720, Loss function: 3.271, Average Loss: 3.829, avg. samples / sec: 53319.28
Iteration:   3720, Loss function: 4.115, Average Loss: 3.826, avg. samples / sec: 53391.54
Iteration:   3720, Loss function: 4.267, Average Loss: 3.828, avg. samples / sec: 53423.60
Iteration:   3720, Loss function: 3.294, Average Loss: 3.833, avg. samples / sec: 53384.70
Iteration:   3740, Loss function: 3.995, Average Loss: 3.826, avg. samples / sec: 53325.63
Iteration:   3740, Loss function: 2.814, Average Loss: 3.820, avg. samples / sec: 53261.49
Iteration:   3740, Loss function: 3.790, Average Loss: 3.808, avg. samples / sec: 53285.71
Iteration:   3740, Loss function: 3.224, Average Loss: 3.849, avg. samples / sec: 53278.52
Iteration:   3740, Loss function: 3.155, Average Loss: 3.809, avg. samples / sec: 53236.50
Iteration:   3740, Loss function: 3.269, Average Loss: 3.848, avg. samples / sec: 53253.78
Iteration:   3740, Loss function: 4.654, Average Loss: 3.832, avg. samples / sec: 53257.10
Iteration:   3740, Loss function: 2.873, Average Loss: 3.801, avg. samples / sec: 53244.99
Iteration:   3740, Loss function: 3.687, Average Loss: 3.827, avg. samples / sec: 53287.00
Iteration:   3740, Loss function: 1.885, Average Loss: 3.828, avg. samples / sec: 53293.77
Iteration:   3740, Loss function: 3.580, Average Loss: 3.826, avg. samples / sec: 53263.02
Iteration:   3740, Loss function: 3.571, Average Loss: 3.823, avg. samples / sec: 53263.96
Iteration:   3740, Loss function: 4.354, Average Loss: 3.807, avg. samples / sec: 53253.64
Iteration:   3740, Loss function: 2.743, Average Loss: 3.820, avg. samples / sec: 53312.89
Iteration:   3740, Loss function: 5.786, Average Loss: 3.828, avg. samples / sec: 53298.63
Iteration:   3740, Loss function: 3.429, Average Loss: 3.828, avg. samples / sec: 53217.80
Iteration:   3740, Loss function: 4.092, Average Loss: 3.827, avg. samples / sec: 53220.66
Iteration:   3740, Loss function: 3.591, Average Loss: 3.826, avg. samples / sec: 53247.68
Iteration:   3740, Loss function: 2.562, Average Loss: 3.811, avg. samples / sec: 53277.51
Iteration:   3740, Loss function: 3.443, Average Loss: 3.820, avg. samples / sec: 53248.37
Iteration:   3740, Loss function: 2.469, Average Loss: 3.830, avg. samples / sec: 53252.57
Iteration:   3740, Loss function: 2.847, Average Loss: 3.816, avg. samples / sec: 53294.04
Iteration:   3740, Loss function: 3.835, Average Loss: 3.838, avg. samples / sec: 53245.59
Iteration:   3740, Loss function: 4.107, Average Loss: 3.848, avg. samples / sec: 53247.78
Iteration:   3740, Loss function: 4.668, Average Loss: 3.849, avg. samples / sec: 53235.63
Iteration:   3740, Loss function: 2.839, Average Loss: 3.831, avg. samples / sec: 53240.10
Iteration:   3740, Loss function: 3.338, Average Loss: 3.833, avg. samples / sec: 53242.07
Iteration:   3740, Loss function: 3.451, Average Loss: 3.829, avg. samples / sec: 53291.07
Iteration:   3740, Loss function: 2.544, Average Loss: 3.817, avg. samples / sec: 53250.94
Iteration:   3740, Loss function: 3.619, Average Loss: 3.800, avg. samples / sec: 53202.97
Iteration:   3760, Loss function: 3.702, Average Loss: 3.809, avg. samples / sec: 53383.47
Iteration:   3760, Loss function: 3.794, Average Loss: 3.814, avg. samples / sec: 53347.17
Iteration:   3760, Loss function: 2.587, Average Loss: 3.798, avg. samples / sec: 53369.72
Iteration:   3760, Loss function: 3.750, Average Loss: 3.791, avg. samples / sec: 53416.47
Iteration:   3760, Loss function: 2.831, Average Loss: 3.843, avg. samples / sec: 53348.26
Iteration:   3760, Loss function: 4.359, Average Loss: 3.803, avg. samples / sec: 53352.20
Iteration:   3760, Loss function: 3.788, Average Loss: 3.835, avg. samples / sec: 53348.77
Iteration:   3760, Loss function: 2.717, Average Loss: 3.820, avg. samples / sec: 53349.46
Iteration:   3760, Loss function: 4.422, Average Loss: 3.821, avg. samples / sec: 53421.98
Iteration:   3760, Loss function: 5.116, Average Loss: 3.814, avg. samples / sec: 53345.25
Iteration:   3760, Loss function: 4.066, Average Loss: 3.817, avg. samples / sec: 53388.93
Iteration:   3760, Loss function: 3.688, Average Loss: 3.817, avg. samples / sec: 53373.48
Iteration:   3760, Loss function: 4.083, Average Loss: 3.820, avg. samples / sec: 53418.33
Iteration:   3760, Loss function: 4.388, Average Loss: 3.822, avg. samples / sec: 53334.49
Iteration:   3760, Loss function: 4.488, Average Loss: 3.822, avg. samples / sec: 53393.15
Iteration:   3760, Loss function: 2.686, Average Loss: 3.803, avg. samples / sec: 53343.56
Iteration:   3760, Loss function: 3.481, Average Loss: 3.838, avg. samples / sec: 53384.96
Iteration:   3760, Loss function: 2.559, Average Loss: 3.816, avg. samples / sec: 53353.25
Iteration:   3760, Loss function: 2.926, Average Loss: 3.811, avg. samples / sec: 53358.97
Iteration:   3760, Loss function: 3.219, Average Loss: 3.833, avg. samples / sec: 53372.81
Iteration:   3760, Loss function: 3.494, Average Loss: 3.818, avg. samples / sec: 53369.13
Iteration:   3760, Loss function: 2.696, Average Loss: 3.837, avg. samples / sec: 53370.51
Iteration:   3760, Loss function: 2.793, Average Loss: 3.819, avg. samples / sec: 53339.88
Iteration:   3760, Loss function: 3.768, Average Loss: 3.814, avg. samples / sec: 53353.43
Iteration:   3760, Loss function: 4.201, Average Loss: 3.809, avg. samples / sec: 53347.13
Iteration:   3760, Loss function: 4.113, Average Loss: 3.821, avg. samples / sec: 53357.78
Iteration:   3760, Loss function: 4.279, Average Loss: 3.808, avg. samples / sec: 53402.28
Iteration:   3760, Loss function: 2.984, Average Loss: 3.807, avg. samples / sec: 53332.84
Iteration:   3760, Loss function: 3.214, Average Loss: 3.811, avg. samples / sec: 53303.93
Iteration:   3760, Loss function: 4.232, Average Loss: 3.791, avg. samples / sec: 53388.66
:::MLL 1558640980.815 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558640980.816 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 3.527, Average Loss: 3.800, avg. samples / sec: 53043.62
Iteration:   3780, Loss function: 5.078, Average Loss: 3.784, avg. samples / sec: 53065.35
Iteration:   3780, Loss function: 1.977, Average Loss: 3.790, avg. samples / sec: 53056.68
Iteration:   3780, Loss function: 3.670, Average Loss: 3.826, avg. samples / sec: 53089.00
Iteration:   3780, Loss function: 4.119, Average Loss: 3.799, avg. samples / sec: 53072.48
Iteration:   3780, Loss function: 2.644, Average Loss: 3.810, avg. samples / sec: 53039.22
Iteration:   3780, Loss function: 3.824, Average Loss: 3.809, avg. samples / sec: 53075.32
Iteration:   3780, Loss function: 3.637, Average Loss: 3.839, avg. samples / sec: 53044.65
Iteration:   3780, Loss function: 3.793, Average Loss: 3.814, avg. samples / sec: 53040.90
Iteration:   3780, Loss function: 3.100, Average Loss: 3.808, avg. samples / sec: 53055.20
Iteration:   3780, Loss function: 3.606, Average Loss: 3.794, avg. samples / sec: 53093.34
Iteration:   3780, Loss function: 3.807, Average Loss: 3.807, avg. samples / sec: 53048.07
Iteration:   3780, Loss function: 3.107, Average Loss: 3.809, avg. samples / sec: 53080.58
Iteration:   3780, Loss function: 2.896, Average Loss: 3.828, avg. samples / sec: 53093.48
Iteration:   3780, Loss function: 2.541, Average Loss: 3.809, avg. samples / sec: 53094.98
Iteration:   3780, Loss function: 3.216, Average Loss: 3.811, avg. samples / sec: 53072.28
Iteration:   3780, Loss function: 2.512, Average Loss: 3.803, avg. samples / sec: 53034.02
Iteration:   3780, Loss function: 3.170, Average Loss: 3.833, avg. samples / sec: 53068.62
Iteration:   3780, Loss function: 3.374, Average Loss: 3.808, avg. samples / sec: 53068.98
Iteration:   3780, Loss function: 3.414, Average Loss: 3.803, avg. samples / sec: 53068.96
Iteration:   3780, Loss function: 2.810, Average Loss: 3.812, avg. samples / sec: 53037.39
Iteration:   3780, Loss function: 3.359, Average Loss: 3.796, avg. samples / sec: 53089.96
Iteration:   3780, Loss function: 3.520, Average Loss: 3.781, avg. samples / sec: 53103.72
Iteration:   3780, Loss function: 3.682, Average Loss: 3.813, avg. samples / sec: 53042.32
Iteration:   3780, Loss function: 2.500, Average Loss: 3.816, avg. samples / sec: 53086.42
Iteration:   3780, Loss function: 3.494, Average Loss: 3.823, avg. samples / sec: 53054.56
Iteration:   3780, Loss function: 3.715, Average Loss: 3.798, avg. samples / sec: 53072.94
Iteration:   3780, Loss function: 2.942, Average Loss: 3.800, avg. samples / sec: 53083.58
Iteration:   3780, Loss function: 3.124, Average Loss: 3.801, avg. samples / sec: 53062.39
Iteration:   3780, Loss function: 3.977, Average Loss: 3.803, avg. samples / sec: 53070.42
Iteration:   3800, Loss function: 3.552, Average Loss: 3.789, avg. samples / sec: 53435.41
Iteration:   3800, Loss function: 3.961, Average Loss: 3.831, avg. samples / sec: 53438.69
Iteration:   3800, Loss function: 2.634, Average Loss: 3.780, avg. samples / sec: 53380.86
Iteration:   3800, Loss function: 3.286, Average Loss: 3.775, avg. samples / sec: 53369.09
Iteration:   3800, Loss function: 2.286, Average Loss: 3.807, avg. samples / sec: 53626.23
Iteration:   3800, Loss function: 3.441, Average Loss: 3.818, avg. samples / sec: 53374.95
Iteration:   3800, Loss function: 3.176, Average Loss: 3.803, avg. samples / sec: 53381.59
Iteration:   3800, Loss function: 3.690, Average Loss: 3.793, avg. samples / sec: 53321.20
Iteration:   3800, Loss function: 3.638, Average Loss: 3.809, avg. samples / sec: 53393.11
Iteration:   3800, Loss function: 3.972, Average Loss: 3.801, avg. samples / sec: 53404.89
Iteration:   3800, Loss function: 3.772, Average Loss: 3.802, avg. samples / sec: 53392.69
Iteration:   3800, Loss function: 3.170, Average Loss: 3.795, avg. samples / sec: 53420.17
Iteration:   3800, Loss function: 3.135, Average Loss: 3.800, avg. samples / sec: 53372.19
Iteration:   3800, Loss function: 2.902, Average Loss: 3.830, avg. samples / sec: 53387.33
Iteration:   3800, Loss function: 5.213, Average Loss: 3.793, avg. samples / sec: 53413.33
Iteration:   3800, Loss function: 2.931, Average Loss: 3.794, avg. samples / sec: 53373.07
Iteration:   3800, Loss function: 3.556, Average Loss: 3.791, avg. samples / sec: 53400.64
Iteration:   3800, Loss function: 3.885, Average Loss: 3.816, avg. samples / sec: 53397.99
Iteration:   3800, Loss function: 4.077, Average Loss: 3.809, avg. samples / sec: 53385.37
Iteration:   3800, Loss function: 3.210, Average Loss: 3.794, avg. samples / sec: 53389.57
Iteration:   3800, Loss function: 2.738, Average Loss: 3.783, avg. samples / sec: 53338.01
Iteration:   3800, Loss function: 3.149, Average Loss: 3.786, avg. samples / sec: 53374.53
Iteration:   3800, Loss function: 3.618, Average Loss: 3.770, avg. samples / sec: 53379.32
Iteration:   3800, Loss function: 3.648, Average Loss: 3.818, avg. samples / sec: 53345.19
Iteration:   3800, Loss function: 3.804, Average Loss: 3.804, avg. samples / sec: 53348.75
Iteration:   3800, Loss function: 2.574, Average Loss: 3.808, avg. samples / sec: 53376.83
Iteration:   3800, Loss function: 1.644, Average Loss: 3.801, avg. samples / sec: 53353.66
Iteration:   3800, Loss function: 2.754, Average Loss: 3.789, avg. samples / sec: 53365.52
Iteration:   3800, Loss function: 2.817, Average Loss: 3.795, avg. samples / sec: 53123.12
Iteration:   3800, Loss function: 2.691, Average Loss: 3.804, avg. samples / sec: 53316.80
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558640982.088 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.60s)
DONE (t=2.48s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22862
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39133
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05981
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23819
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36910
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21970
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32239
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33769
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10273
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52334
Current AP: 0.22862 AP goal: 0.23000
:::MLL 1558640985.833 eval_accuracy: {"value": 0.2286175550186052, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558640985.915 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558640985.922 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558640985.922 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 2.926, Average Loss: 3.813, avg. samples / sec: 7490.48
Iteration:   3820, Loss function: 3.413, Average Loss: 3.789, avg. samples / sec: 7490.76
Iteration:   3820, Loss function: 3.305, Average Loss: 3.784, avg. samples / sec: 7489.13
Iteration:   3820, Loss function: 4.436, Average Loss: 3.798, avg. samples / sec: 7489.95
Iteration:   3820, Loss function: 3.860, Average Loss: 3.819, avg. samples / sec: 7489.33
Iteration:   3820, Loss function: 2.694, Average Loss: 3.771, avg. samples / sec: 7489.90
Iteration:   3820, Loss function: 3.569, Average Loss: 3.768, avg. samples / sec: 7489.42
Iteration:   3820, Loss function: 3.922, Average Loss: 3.808, avg. samples / sec: 7494.45
Iteration:   3820, Loss function: 4.068, Average Loss: 3.784, avg. samples / sec: 7493.68
Iteration:   3820, Loss function: 3.776, Average Loss: 3.784, avg. samples / sec: 7493.78
Iteration:   3820, Loss function: 2.445, Average Loss: 3.795, avg. samples / sec: 7487.70
Iteration:   3820, Loss function: 2.586, Average Loss: 3.792, avg. samples / sec: 7490.27
Iteration:   3820, Loss function: 4.214, Average Loss: 3.789, avg. samples / sec: 7490.66
Iteration:   3820, Loss function: 4.081, Average Loss: 3.791, avg. samples / sec: 7489.82
Iteration:   3820, Loss function: 2.887, Average Loss: 3.792, avg. samples / sec: 7490.21
Iteration:   3820, Loss function: 3.465, Average Loss: 3.785, avg. samples / sec: 7489.78
Iteration:   3820, Loss function: 4.133, Average Loss: 3.782, avg. samples / sec: 7491.20
Iteration:   3820, Loss function: 2.606, Average Loss: 3.801, avg. samples / sec: 7489.38
Iteration:   3820, Loss function: 3.878, Average Loss: 3.797, avg. samples / sec: 7490.67
Iteration:   3820, Loss function: 3.310, Average Loss: 3.810, avg. samples / sec: 7490.15
Iteration:   3820, Loss function: 2.810, Average Loss: 3.777, avg. samples / sec: 7490.44
Iteration:   3820, Loss function: 1.885, Average Loss: 3.789, avg. samples / sec: 7490.89
Iteration:   3820, Loss function: 2.527, Average Loss: 3.797, avg. samples / sec: 7490.19
Iteration:   3820, Loss function: 2.729, Average Loss: 3.787, avg. samples / sec: 7490.58
Iteration:   3820, Loss function: 4.018, Average Loss: 3.775, avg. samples / sec: 7490.15
Iteration:   3820, Loss function: 2.852, Average Loss: 3.796, avg. samples / sec: 7489.82
Iteration:   3820, Loss function: 2.832, Average Loss: 3.760, avg. samples / sec: 7489.80
Iteration:   3820, Loss function: 4.627, Average Loss: 3.788, avg. samples / sec: 7489.00
Iteration:   3820, Loss function: 3.070, Average Loss: 3.816, avg. samples / sec: 7488.86
Iteration:   3820, Loss function: 2.747, Average Loss: 3.790, avg. samples / sec: 7489.56
:::MLL 1558640986.890 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558640986.891 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 4.216, Average Loss: 3.778, avg. samples / sec: 52278.44
Iteration:   3840, Loss function: 4.355, Average Loss: 3.776, avg. samples / sec: 52272.70
Iteration:   3840, Loss function: 3.989, Average Loss: 3.798, avg. samples / sec: 52222.55
Iteration:   3840, Loss function: 2.530, Average Loss: 3.802, avg. samples / sec: 52134.46
Iteration:   3840, Loss function: 3.002, Average Loss: 3.786, avg. samples / sec: 52147.50
Iteration:   3840, Loss function: 3.763, Average Loss: 3.779, avg. samples / sec: 52139.76
Iteration:   3840, Loss function: 2.984, Average Loss: 3.759, avg. samples / sec: 52157.30
Iteration:   3840, Loss function: 3.443, Average Loss: 3.790, avg. samples / sec: 52248.15
Iteration:   3840, Loss function: 3.817, Average Loss: 3.777, avg. samples / sec: 52134.50
Iteration:   3840, Loss function: 2.990, Average Loss: 3.761, avg. samples / sec: 52079.26
Iteration:   3840, Loss function: 3.109, Average Loss: 3.810, avg. samples / sec: 52072.54
Iteration:   3840, Loss function: 2.316, Average Loss: 3.778, avg. samples / sec: 52200.73
Iteration:   3840, Loss function: 3.659, Average Loss: 3.780, avg. samples / sec: 52225.45
Iteration:   3840, Loss function: 3.627, Average Loss: 3.782, avg. samples / sec: 52204.39
Iteration:   3840, Loss function: 3.792, Average Loss: 3.800, avg. samples / sec: 52152.96
Iteration:   3840, Loss function: 3.429, Average Loss: 3.783, avg. samples / sec: 52125.93
Iteration:   3840, Loss function: 3.457, Average Loss: 3.783, avg. samples / sec: 52102.77
Iteration:   3840, Loss function: 3.887, Average Loss: 3.789, avg. samples / sec: 52116.14
Iteration:   3840, Loss function: 3.099, Average Loss: 3.784, avg. samples / sec: 52154.95
Iteration:   3840, Loss function: 2.855, Average Loss: 3.782, avg. samples / sec: 52100.54
Iteration:   3840, Loss function: 3.874, Average Loss: 3.780, avg. samples / sec: 52103.77
Iteration:   3840, Loss function: 2.586, Average Loss: 3.775, avg. samples / sec: 52107.16
Iteration:   3840, Loss function: 3.612, Average Loss: 3.792, avg. samples / sec: 52114.60
Iteration:   3840, Loss function: 2.890, Average Loss: 3.781, avg. samples / sec: 52164.68
Iteration:   3840, Loss function: 3.391, Average Loss: 3.778, avg. samples / sec: 52152.92
Iteration:   3840, Loss function: 3.751, Average Loss: 3.771, avg. samples / sec: 52105.02
Iteration:   3840, Loss function: 3.260, Average Loss: 3.805, avg. samples / sec: 52161.57
Iteration:   3840, Loss function: 3.064, Average Loss: 3.787, avg. samples / sec: 52111.54
Iteration:   3840, Loss function: 3.549, Average Loss: 3.763, avg. samples / sec: 52114.91
Iteration:   3840, Loss function: 4.123, Average Loss: 3.755, avg. samples / sec: 52120.75
Iteration:   3860, Loss function: 2.868, Average Loss: 3.793, avg. samples / sec: 53078.54
Iteration:   3860, Loss function: 3.545, Average Loss: 3.779, avg. samples / sec: 53076.76
Iteration:   3860, Loss function: 2.682, Average Loss: 3.770, avg. samples / sec: 52915.65
Iteration:   3860, Loss function: 3.214, Average Loss: 3.777, avg. samples / sec: 53042.66
Iteration:   3860, Loss function: 2.596, Average Loss: 3.798, avg. samples / sec: 53121.23
Iteration:   3860, Loss function: 2.826, Average Loss: 3.751, avg. samples / sec: 53044.51
Iteration:   3860, Loss function: 3.395, Average Loss: 3.768, avg. samples / sec: 52944.36
Iteration:   3860, Loss function: 4.328, Average Loss: 3.769, avg. samples / sec: 53067.15
Iteration:   3860, Loss function: 3.330, Average Loss: 3.788, avg. samples / sec: 52951.70
Iteration:   3860, Loss function: 3.129, Average Loss: 3.776, avg. samples / sec: 53005.95
Iteration:   3860, Loss function: 3.249, Average Loss: 3.751, avg. samples / sec: 53048.29
Iteration:   3860, Loss function: 3.543, Average Loss: 3.776, avg. samples / sec: 53090.86
Iteration:   3860, Loss function: 2.392, Average Loss: 3.784, avg. samples / sec: 53082.56
Iteration:   3860, Loss function: 2.932, Average Loss: 3.773, avg. samples / sec: 52965.37
Iteration:   3860, Loss function: 3.308, Average Loss: 3.778, avg. samples / sec: 53054.74
Iteration:   3860, Loss function: 3.501, Average Loss: 3.774, avg. samples / sec: 53085.08
Iteration:   3860, Loss function: 3.426, Average Loss: 3.770, avg. samples / sec: 53076.42
Iteration:   3860, Loss function: 3.897, Average Loss: 3.774, avg. samples / sec: 53061.41
Iteration:   3860, Loss function: 3.109, Average Loss: 3.787, avg. samples / sec: 53069.94
Iteration:   3860, Loss function: 3.012, Average Loss: 3.792, avg. samples / sec: 53037.37
Iteration:   3860, Loss function: 2.885, Average Loss: 3.774, avg. samples / sec: 53060.47
Iteration:   3860, Loss function: 3.036, Average Loss: 3.766, avg. samples / sec: 53083.22
Iteration:   3860, Loss function: 3.013, Average Loss: 3.791, avg. samples / sec: 53083.34
Iteration:   3860, Loss function: 4.295, Average Loss: 3.772, avg. samples / sec: 52954.74
Iteration:   3860, Loss function: 3.402, Average Loss: 3.769, avg. samples / sec: 53060.43
Iteration:   3860, Loss function: 4.344, Average Loss: 3.762, avg. samples / sec: 53068.56
Iteration:   3860, Loss function: 3.037, Average Loss: 3.772, avg. samples / sec: 53041.42
Iteration:   3860, Loss function: 4.203, Average Loss: 3.773, avg. samples / sec: 52969.03
Iteration:   3860, Loss function: 4.294, Average Loss: 3.783, avg. samples / sec: 53056.32
Iteration:   3860, Loss function: 2.759, Average Loss: 3.750, avg. samples / sec: 52943.86
Iteration:   3880, Loss function: 4.459, Average Loss: 3.736, avg. samples / sec: 53357.35
Iteration:   3880, Loss function: 3.875, Average Loss: 3.764, avg. samples / sec: 53266.80
Iteration:   3880, Loss function: 2.748, Average Loss: 3.757, avg. samples / sec: 53300.22
Iteration:   3880, Loss function: 3.069, Average Loss: 3.788, avg. samples / sec: 53215.35
Iteration:   3880, Loss function: 3.520, Average Loss: 3.771, avg. samples / sec: 53245.05
Iteration:   3880, Loss function: 3.184, Average Loss: 3.771, avg. samples / sec: 53211.23
Iteration:   3880, Loss function: 3.979, Average Loss: 3.770, avg. samples / sec: 53297.80
Iteration:   3880, Loss function: 3.447, Average Loss: 3.790, avg. samples / sec: 53227.73
Iteration:   3880, Loss function: 3.511, Average Loss: 3.782, avg. samples / sec: 53274.27
Iteration:   3880, Loss function: 3.539, Average Loss: 3.762, avg. samples / sec: 53206.51
Iteration:   3880, Loss function: 4.314, Average Loss: 3.746, avg. samples / sec: 53167.35
Iteration:   3880, Loss function: 2.689, Average Loss: 3.763, avg. samples / sec: 53278.78
Iteration:   3880, Loss function: 3.601, Average Loss: 3.769, avg. samples / sec: 53264.83
Iteration:   3880, Loss function: 3.388, Average Loss: 3.761, avg. samples / sec: 53304.19
Iteration:   3880, Loss function: 2.796, Average Loss: 3.767, avg. samples / sec: 53240.14
Iteration:   3880, Loss function: 2.703, Average Loss: 3.765, avg. samples / sec: 53271.79
Iteration:   3880, Loss function: 3.684, Average Loss: 3.754, avg. samples / sec: 53236.38
Iteration:   3880, Loss function: 3.434, Average Loss: 3.775, avg. samples / sec: 53211.73
Iteration:   3880, Loss function: 2.694, Average Loss: 3.767, avg. samples / sec: 53217.20
Iteration:   3880, Loss function: 3.790, Average Loss: 3.763, avg. samples / sec: 53267.47
Iteration:   3880, Loss function: 3.697, Average Loss: 3.783, avg. samples / sec: 53224.27
Iteration:   3880, Loss function: 1.622, Average Loss: 3.764, avg. samples / sec: 53210.13
Iteration:   3880, Loss function: 3.785, Average Loss: 3.775, avg. samples / sec: 53220.72
Iteration:   3880, Loss function: 1.497, Average Loss: 3.765, avg. samples / sec: 53226.46
Iteration:   3880, Loss function: 2.662, Average Loss: 3.779, avg. samples / sec: 53210.65
Iteration:   3880, Loss function: 2.651, Average Loss: 3.763, avg. samples / sec: 53206.67
Iteration:   3880, Loss function: 3.783, Average Loss: 3.744, avg. samples / sec: 53364.65
Iteration:   3880, Loss function: 2.661, Average Loss: 3.770, avg. samples / sec: 53245.17
Iteration:   3880, Loss function: 3.559, Average Loss: 3.757, avg. samples / sec: 53217.42
Iteration:   3880, Loss function: 4.455, Average Loss: 3.756, avg. samples / sec: 53205.30
Iteration:   3900, Loss function: 4.039, Average Loss: 3.739, avg. samples / sec: 53500.44
Iteration:   3900, Loss function: 2.734, Average Loss: 3.730, avg. samples / sec: 53361.41
Iteration:   3900, Loss function: 2.525, Average Loss: 3.756, avg. samples / sec: 53353.92
Iteration:   3900, Loss function: 2.165, Average Loss: 3.778, avg. samples / sec: 53410.42
Iteration:   3900, Loss function: 3.506, Average Loss: 3.762, avg. samples / sec: 53385.87
Iteration:   3900, Loss function: 3.362, Average Loss: 3.783, avg. samples / sec: 53365.92
Iteration:   3900, Loss function: 1.999, Average Loss: 3.774, avg. samples / sec: 53400.46
Iteration:   3900, Loss function: 2.589, Average Loss: 3.762, avg. samples / sec: 53381.10
Iteration:   3900, Loss function: 3.000, Average Loss: 3.762, avg. samples / sec: 53356.97
Iteration:   3900, Loss function: 2.941, Average Loss: 3.754, avg. samples / sec: 53332.56
Iteration:   3900, Loss function: 4.015, Average Loss: 3.756, avg. samples / sec: 53423.68
Iteration:   3900, Loss function: 4.020, Average Loss: 3.760, avg. samples / sec: 53441.36
Iteration:   3900, Loss function: 2.769, Average Loss: 3.759, avg. samples / sec: 53396.05
Iteration:   3900, Loss function: 2.355, Average Loss: 3.757, avg. samples / sec: 53430.00
Iteration:   3900, Loss function: 3.505, Average Loss: 3.761, avg. samples / sec: 53355.47
Iteration:   3900, Loss function: 3.497, Average Loss: 3.767, avg. samples / sec: 53430.44
Iteration:   3900, Loss function: 3.247, Average Loss: 3.775, avg. samples / sec: 53417.68
Iteration:   3900, Loss function: 2.607, Average Loss: 3.750, avg. samples / sec: 53454.78
Iteration:   3900, Loss function: 3.471, Average Loss: 3.763, avg. samples / sec: 53356.87
Iteration:   3900, Loss function: 2.834, Average Loss: 3.769, avg. samples / sec: 53397.00
Iteration:   3900, Loss function: 4.236, Average Loss: 3.746, avg. samples / sec: 53393.21
Iteration:   3900, Loss function: 4.312, Average Loss: 3.757, avg. samples / sec: 53401.43
Iteration:   3900, Loss function: 2.741, Average Loss: 3.757, avg. samples / sec: 53373.92
Iteration:   3900, Loss function: 2.868, Average Loss: 3.757, avg. samples / sec: 53381.12
Iteration:   3900, Loss function: 4.028, Average Loss: 3.758, avg. samples / sec: 53408.80
Iteration:   3900, Loss function: 3.658, Average Loss: 3.752, avg. samples / sec: 53388.46
Iteration:   3900, Loss function: 4.211, Average Loss: 3.746, avg. samples / sec: 53397.91
Iteration:   3900, Loss function: 2.178, Average Loss: 3.736, avg. samples / sec: 53382.78
Iteration:   3900, Loss function: 3.087, Average Loss: 3.754, avg. samples / sec: 53322.16
Iteration:   3900, Loss function: 2.691, Average Loss: 3.773, avg. samples / sec: 53369.86
:::MLL 1558640989.103 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558640989.104 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 2.520, Average Loss: 3.748, avg. samples / sec: 52910.80
Iteration:   3920, Loss function: 2.823, Average Loss: 3.750, avg. samples / sec: 52893.86
Iteration:   3920, Loss function: 3.484, Average Loss: 3.767, avg. samples / sec: 52865.81
Iteration:   3920, Loss function: 4.302, Average Loss: 3.756, avg. samples / sec: 52895.00
Iteration:   3920, Loss function: 4.605, Average Loss: 3.780, avg. samples / sec: 52867.24
Iteration:   3920, Loss function: 2.685, Average Loss: 3.732, avg. samples / sec: 52831.76
Iteration:   3920, Loss function: 3.708, Average Loss: 3.725, avg. samples / sec: 52829.74
Iteration:   3920, Loss function: 2.925, Average Loss: 3.750, avg. samples / sec: 52867.87
Iteration:   3920, Loss function: 3.438, Average Loss: 3.764, avg. samples / sec: 52839.47
Iteration:   3920, Loss function: 2.518, Average Loss: 3.752, avg. samples / sec: 52848.80
Iteration:   3920, Loss function: 4.000, Average Loss: 3.748, avg. samples / sec: 52874.59
Iteration:   3920, Loss function: 3.830, Average Loss: 3.753, avg. samples / sec: 52907.51
Iteration:   3920, Loss function: 4.544, Average Loss: 3.762, avg. samples / sec: 52966.05
Iteration:   3920, Loss function: 2.936, Average Loss: 3.738, avg. samples / sec: 52910.45
Iteration:   3920, Loss function: 2.783, Average Loss: 3.751, avg. samples / sec: 52880.96
Iteration:   3920, Loss function: 3.024, Average Loss: 3.757, avg. samples / sec: 52905.02
Iteration:   3920, Loss function: 3.068, Average Loss: 3.764, avg. samples / sec: 52881.04
Iteration:   3920, Loss function: 2.293, Average Loss: 3.747, avg. samples / sec: 52909.27
Iteration:   3920, Loss function: 2.798, Average Loss: 3.745, avg. samples / sec: 52873.17
Iteration:   3920, Loss function: 4.572, Average Loss: 3.763, avg. samples / sec: 52897.08
Iteration:   3920, Loss function: 3.190, Average Loss: 3.744, avg. samples / sec: 52892.12
Iteration:   3920, Loss function: 2.363, Average Loss: 3.747, avg. samples / sec: 52916.35
Iteration:   3920, Loss function: 4.102, Average Loss: 3.754, avg. samples / sec: 52844.64
Iteration:   3920, Loss function: 3.384, Average Loss: 3.744, avg. samples / sec: 52916.78
Iteration:   3920, Loss function: 2.641, Average Loss: 3.763, avg. samples / sec: 52876.00
Iteration:   3920, Loss function: 4.040, Average Loss: 3.752, avg. samples / sec: 52879.10
Iteration:   3920, Loss function: 3.767, Average Loss: 3.729, avg. samples / sec: 52915.06
Iteration:   3920, Loss function: 3.334, Average Loss: 3.745, avg. samples / sec: 52909.39
Iteration:   3920, Loss function: 4.295, Average Loss: 3.753, avg. samples / sec: 52874.52
Iteration:   3920, Loss function: 2.813, Average Loss: 3.742, avg. samples / sec: 52879.02
Iteration:   3940, Loss function: 5.042, Average Loss: 3.743, avg. samples / sec: 53432.06
Iteration:   3940, Loss function: 4.301, Average Loss: 3.747, avg. samples / sec: 53485.86
Iteration:   3940, Loss function: 2.748, Average Loss: 3.752, avg. samples / sec: 53439.19
Iteration:   3940, Loss function: 2.321, Average Loss: 3.725, avg. samples / sec: 53449.06
Iteration:   3940, Loss function: 3.743, Average Loss: 3.772, avg. samples / sec: 53420.58
Iteration:   3940, Loss function: 2.489, Average Loss: 3.743, avg. samples / sec: 53424.95
Iteration:   3940, Loss function: 3.132, Average Loss: 3.714, avg. samples / sec: 53411.63
Iteration:   3940, Loss function: 3.404, Average Loss: 3.739, avg. samples / sec: 53427.26
Iteration:   3940, Loss function: 2.378, Average Loss: 3.751, avg. samples / sec: 53417.42
Iteration:   3940, Loss function: 2.563, Average Loss: 3.735, avg. samples / sec: 53315.12
Iteration:   3940, Loss function: 3.505, Average Loss: 3.747, avg. samples / sec: 53320.55
Iteration:   3940, Loss function: 2.770, Average Loss: 3.745, avg. samples / sec: 53471.13
Iteration:   3940, Loss function: 2.502, Average Loss: 3.734, avg. samples / sec: 53456.69
Iteration:   3940, Loss function: 3.212, Average Loss: 3.737, avg. samples / sec: 53446.71
Iteration:   3940, Loss function: 3.795, Average Loss: 3.730, avg. samples / sec: 53435.28
Iteration:   3940, Loss function: 3.379, Average Loss: 3.744, avg. samples / sec: 53409.63
Iteration:   3940, Loss function: 2.698, Average Loss: 3.756, avg. samples / sec: 53444.71
Iteration:   3940, Loss function: 3.363, Average Loss: 3.740, avg. samples / sec: 53419.75
Iteration:   3940, Loss function: 2.517, Average Loss: 3.756, avg. samples / sec: 53422.34
Iteration:   3940, Loss function: 3.508, Average Loss: 3.743, avg. samples / sec: 53409.83
Iteration:   3940, Loss function: 2.772, Average Loss: 3.751, avg. samples / sec: 53398.70
Iteration:   3940, Loss function: 3.030, Average Loss: 3.737, avg. samples / sec: 53452.79
Iteration:   3940, Loss function: 3.475, Average Loss: 3.752, avg. samples / sec: 53367.48
Iteration:   3940, Loss function: 4.417, Average Loss: 3.760, avg. samples / sec: 53380.13
Iteration:   3940, Loss function: 2.875, Average Loss: 3.739, avg. samples / sec: 53389.92
Iteration:   3940, Loss function: 3.260, Average Loss: 3.744, avg. samples / sec: 53430.18
Iteration:   3940, Loss function: 2.444, Average Loss: 3.738, avg. samples / sec: 53376.19
Iteration:   3940, Loss function: 2.761, Average Loss: 3.731, avg. samples / sec: 53398.15
Iteration:   3940, Loss function: 2.913, Average Loss: 3.719, avg. samples / sec: 53382.03
Iteration:   3940, Loss function: 4.031, Average Loss: 3.742, avg. samples / sec: 53370.91
Iteration:   3960, Loss function: 3.885, Average Loss: 3.726, avg. samples / sec: 53603.08
Iteration:   3960, Loss function: 2.912, Average Loss: 3.721, avg. samples / sec: 53492.26
Iteration:   3960, Loss function: 4.406, Average Loss: 3.742, avg. samples / sec: 53449.17
Iteration:   3960, Loss function: 2.998, Average Loss: 3.748, avg. samples / sec: 53462.28
Iteration:   3960, Loss function: 2.585, Average Loss: 3.761, avg. samples / sec: 53479.25
Iteration:   3960, Loss function: 3.534, Average Loss: 3.734, avg. samples / sec: 53434.43
Iteration:   3960, Loss function: 4.197, Average Loss: 3.707, avg. samples / sec: 53497.13
Iteration:   3960, Loss function: 2.503, Average Loss: 3.739, avg. samples / sec: 53494.75
Iteration:   3960, Loss function: 3.085, Average Loss: 3.735, avg. samples / sec: 53479.75
Iteration:   3960, Loss function: 4.207, Average Loss: 3.733, avg. samples / sec: 53431.92
Iteration:   3960, Loss function: 3.914, Average Loss: 3.737, avg. samples / sec: 53490.51
Iteration:   3960, Loss function: 3.935, Average Loss: 3.739, avg. samples / sec: 53495.00
Iteration:   3960, Loss function: 2.305, Average Loss: 3.725, avg. samples / sec: 53483.77
Iteration:   3960, Loss function: 4.224, Average Loss: 3.729, avg. samples / sec: 53502.45
Iteration:   3960, Loss function: 3.190, Average Loss: 3.743, avg. samples / sec: 53542.98
Iteration:   3960, Loss function: 4.403, Average Loss: 3.742, avg. samples / sec: 53517.36
Iteration:   3960, Loss function: 3.568, Average Loss: 3.749, avg. samples / sec: 53532.04
Iteration:   3960, Loss function: 2.536, Average Loss: 3.732, avg. samples / sec: 53471.43
Iteration:   3960, Loss function: 3.630, Average Loss: 3.747, avg. samples / sec: 53467.88
Iteration:   3960, Loss function: 3.126, Average Loss: 3.747, avg. samples / sec: 53459.45
Iteration:   3960, Loss function: 2.923, Average Loss: 3.703, avg. samples / sec: 53531.00
Iteration:   3960, Loss function: 2.954, Average Loss: 3.732, avg. samples / sec: 53503.81
Iteration:   3960, Loss function: 4.566, Average Loss: 3.741, avg. samples / sec: 53498.96
Iteration:   3960, Loss function: 3.053, Average Loss: 3.733, avg. samples / sec: 53530.50
Iteration:   3960, Loss function: 3.046, Average Loss: 3.730, avg. samples / sec: 53492.56
Iteration:   3960, Loss function: 3.574, Average Loss: 3.721, avg. samples / sec: 53504.26
Iteration:   3960, Loss function: 4.002, Average Loss: 3.735, avg. samples / sec: 53484.30
Iteration:   3960, Loss function: 2.963, Average Loss: 3.740, avg. samples / sec: 53333.40
Iteration:   3960, Loss function: 3.224, Average Loss: 3.724, avg. samples / sec: 53419.57
Iteration:   3960, Loss function: 2.963, Average Loss: 3.733, avg. samples / sec: 53448.11
:::MLL 1558640991.313 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558640991.313 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.508, Average Loss: 3.719, avg. samples / sec: 52966.11
Iteration:   3980, Loss function: 3.313, Average Loss: 3.731, avg. samples / sec: 52991.78
Iteration:   3980, Loss function: 3.384, Average Loss: 3.732, avg. samples / sec: 52962.94
Iteration:   3980, Loss function: 3.751, Average Loss: 3.722, avg. samples / sec: 52896.58
Iteration:   3980, Loss function: 2.864, Average Loss: 3.738, avg. samples / sec: 52873.96
Iteration:   3980, Loss function: 3.611, Average Loss: 3.709, avg. samples / sec: 52847.83
Iteration:   3980, Loss function: 3.626, Average Loss: 3.733, avg. samples / sec: 52861.72
Iteration:   3980, Loss function: 3.261, Average Loss: 3.748, avg. samples / sec: 52848.46
Iteration:   3980, Loss function: 3.515, Average Loss: 3.727, avg. samples / sec: 52925.55
Iteration:   3980, Loss function: 2.992, Average Loss: 3.731, avg. samples / sec: 52938.05
Iteration:   3980, Loss function: 3.703, Average Loss: 3.731, avg. samples / sec: 52877.19
Iteration:   3980, Loss function: 2.250, Average Loss: 3.717, avg. samples / sec: 52966.03
Iteration:   3980, Loss function: 2.925, Average Loss: 3.722, avg. samples / sec: 52948.97
Iteration:   3980, Loss function: 3.344, Average Loss: 3.738, avg. samples / sec: 52885.33
Iteration:   3980, Loss function: 3.780, Average Loss: 3.703, avg. samples / sec: 52691.95
Iteration:   3980, Loss function: 4.434, Average Loss: 3.718, avg. samples / sec: 52861.53
Iteration:   3980, Loss function: 2.840, Average Loss: 3.739, avg. samples / sec: 52897.42
Iteration:   3980, Loss function: 3.468, Average Loss: 3.726, avg. samples / sec: 52867.02
Iteration:   3980, Loss function: 1.968, Average Loss: 3.727, avg. samples / sec: 52902.98
Iteration:   3980, Loss function: 4.666, Average Loss: 3.739, avg. samples / sec: 52821.28
Iteration:   3980, Loss function: 3.659, Average Loss: 3.741, avg. samples / sec: 52859.24
Iteration:   3980, Loss function: 3.322, Average Loss: 3.715, avg. samples / sec: 52822.43
Iteration:   3980, Loss function: 2.521, Average Loss: 3.733, avg. samples / sec: 52820.77
Iteration:   3980, Loss function: 4.168, Average Loss: 3.737, avg. samples / sec: 52857.76
Iteration:   3980, Loss function: 2.916, Average Loss: 3.696, avg. samples / sec: 52852.33
Iteration:   3980, Loss function: 3.756, Average Loss: 3.717, avg. samples / sec: 52855.82
Iteration:   3980, Loss function: 4.647, Average Loss: 3.726, avg. samples / sec: 52852.74
Iteration:   3980, Loss function: 3.547, Average Loss: 3.728, avg. samples / sec: 52850.82
Iteration:   3980, Loss function: 3.507, Average Loss: 3.725, avg. samples / sec: 52844.54
Iteration:   3980, Loss function: 2.524, Average Loss: 3.728, avg. samples / sec: 52809.53
Iteration:   4000, Loss function: 3.010, Average Loss: 3.711, avg. samples / sec: 53239.01
Iteration:   4000, Loss function: 2.739, Average Loss: 3.736, avg. samples / sec: 53428.27
Iteration:   4000, Loss function: 3.564, Average Loss: 3.714, avg. samples / sec: 53373.72
Iteration:   4000, Loss function: 2.969, Average Loss: 3.729, avg. samples / sec: 53378.25
Iteration:   4000, Loss function: 4.085, Average Loss: 3.728, avg. samples / sec: 53298.67
Iteration:   4000, Loss function: 2.606, Average Loss: 3.703, avg. samples / sec: 53362.18
Iteration:   4000, Loss function: 2.743, Average Loss: 3.726, avg. samples / sec: 53329.47
Iteration:   4000, Loss function: 2.222, Average Loss: 3.721, avg. samples / sec: 53229.98
Iteration:   4000, Loss function: 3.140, Average Loss: 3.722, avg. samples / sec: 53340.07
Iteration:   4000, Loss function: 3.478, Average Loss: 3.726, avg. samples / sec: 53360.89
Iteration:   4000, Loss function: 2.226, Average Loss: 3.693, avg. samples / sec: 53389.82
Iteration:   4000, Loss function: 2.906, Average Loss: 3.722, avg. samples / sec: 53432.31
Iteration:   4000, Loss function: 2.936, Average Loss: 3.731, avg. samples / sec: 53372.12
Iteration:   4000, Loss function: 3.603, Average Loss: 3.719, avg. samples / sec: 53384.34
Iteration:   4000, Loss function: 3.730, Average Loss: 3.738, avg. samples / sec: 53393.98
Iteration:   4000, Loss function: 4.323, Average Loss: 3.722, avg. samples / sec: 53420.48
Iteration:   4000, Loss function: 2.974, Average Loss: 3.723, avg. samples / sec: 53369.80
Iteration:   4000, Loss function: 3.745, Average Loss: 3.720, avg. samples / sec: 53257.62
Iteration:   4000, Loss function: 2.467, Average Loss: 3.732, avg. samples / sec: 53349.05
Iteration:   4000, Loss function: 3.133, Average Loss: 3.718, avg. samples / sec: 53401.55
Iteration:   4000, Loss function: 3.361, Average Loss: 3.713, avg. samples / sec: 53302.10
Iteration:   4000, Loss function: 3.123, Average Loss: 3.716, avg. samples / sec: 53342.63
Iteration:   4000, Loss function: 3.278, Average Loss: 3.706, avg. samples / sec: 53370.65
Iteration:   4000, Loss function: 4.801, Average Loss: 3.731, avg. samples / sec: 53378.47
Iteration:   4000, Loss function: 4.353, Average Loss: 3.731, avg. samples / sec: 53352.53
Iteration:   4000, Loss function: 3.381, Average Loss: 3.711, avg. samples / sec: 53267.34
Iteration:   4000, Loss function: 3.853, Average Loss: 3.691, avg. samples / sec: 53366.06
Iteration:   4000, Loss function: 3.667, Average Loss: 3.720, avg. samples / sec: 53421.33
Iteration:   4000, Loss function: 2.441, Average Loss: 3.711, avg. samples / sec: 53381.10
Iteration:   4000, Loss function: 4.080, Average Loss: 3.720, avg. samples / sec: 53366.51
Iteration:   4020, Loss function: 3.216, Average Loss: 3.724, avg. samples / sec: 53309.13
Iteration:   4020, Loss function: 4.092, Average Loss: 3.707, avg. samples / sec: 53279.91
Iteration:   4020, Loss function: 3.718, Average Loss: 3.707, avg. samples / sec: 53293.59
Iteration:   4020, Loss function: 3.747, Average Loss: 3.719, avg. samples / sec: 53348.34
Iteration:   4020, Loss function: 3.099, Average Loss: 3.729, avg. samples / sec: 53272.88
Iteration:   4020, Loss function: 3.828, Average Loss: 3.718, avg. samples / sec: 53349.88
Iteration:   4020, Loss function: 3.205, Average Loss: 3.696, avg. samples / sec: 53297.64
Iteration:   4020, Loss function: 2.854, Average Loss: 3.720, avg. samples / sec: 53277.21
Iteration:   4020, Loss function: 2.973, Average Loss: 3.720, avg. samples / sec: 53309.42
Iteration:   4020, Loss function: 3.221, Average Loss: 3.711, avg. samples / sec: 53328.30
Iteration:   4020, Loss function: 2.323, Average Loss: 3.685, avg. samples / sec: 53262.25
Iteration:   4020, Loss function: 4.192, Average Loss: 3.720, avg. samples / sec: 53242.49
Iteration:   4020, Loss function: 3.431, Average Loss: 3.701, avg. samples / sec: 53303.23
Iteration:   4020, Loss function: 3.226, Average Loss: 3.715, avg. samples / sec: 53252.99
Iteration:   4020, Loss function: 3.177, Average Loss: 3.724, avg. samples / sec: 53249.43
Iteration:   4020, Loss function: 2.995, Average Loss: 3.712, avg. samples / sec: 53288.39
Iteration:   4020, Loss function: 2.449, Average Loss: 3.708, avg. samples / sec: 53287.55
Iteration:   4020, Loss function: 3.592, Average Loss: 3.709, avg. samples / sec: 53247.68
Iteration:   4020, Loss function: 3.529, Average Loss: 3.728, avg. samples / sec: 53278.50
Iteration:   4020, Loss function: 4.069, Average Loss: 3.714, avg. samples / sec: 53279.71
Iteration:   4020, Loss function: 3.501, Average Loss: 3.716, avg. samples / sec: 53271.29
Iteration:   4020, Loss function: 4.461, Average Loss: 3.713, avg. samples / sec: 53320.61
Iteration:   4020, Loss function: 3.716, Average Loss: 3.709, avg. samples / sec: 53288.63
Iteration:   4020, Loss function: 3.321, Average Loss: 3.726, avg. samples / sec: 53254.66
Iteration:   4020, Loss function: 2.231, Average Loss: 3.706, avg. samples / sec: 53290.25
Iteration:   4020, Loss function: 3.519, Average Loss: 3.681, avg. samples / sec: 53294.46
Iteration:   4020, Loss function: 3.281, Average Loss: 3.712, avg. samples / sec: 53279.35
Iteration:   4020, Loss function: 3.701, Average Loss: 3.724, avg. samples / sec: 53263.94
Iteration:   4020, Loss function: 4.105, Average Loss: 3.718, avg. samples / sec: 53239.19
Iteration:   4020, Loss function: 4.084, Average Loss: 3.720, avg. samples / sec: 53264.26
Iteration:   4040, Loss function: 3.021, Average Loss: 3.720, avg. samples / sec: 53354.02
Iteration:   4040, Loss function: 3.714, Average Loss: 3.715, avg. samples / sec: 53393.01
Iteration:   4040, Loss function: 3.279, Average Loss: 3.712, avg. samples / sec: 53334.37
Iteration:   4040, Loss function: 3.380, Average Loss: 3.696, avg. samples / sec: 53317.18
Iteration:   4040, Loss function: 2.477, Average Loss: 3.698, avg. samples / sec: 53301.59
Iteration:   4040, Loss function: 2.847, Average Loss: 3.709, avg. samples / sec: 53318.39
Iteration:   4040, Loss function: 4.230, Average Loss: 3.720, avg. samples / sec: 53280.01
Iteration:   4040, Loss function: 2.927, Average Loss: 3.694, avg. samples / sec: 53280.92
Iteration:   4040, Loss function: 3.235, Average Loss: 3.715, avg. samples / sec: 53289.86
Iteration:   4040, Loss function: 3.475, Average Loss: 3.691, avg. samples / sec: 53356.26
Iteration:   4040, Loss function: 2.685, Average Loss: 3.679, avg. samples / sec: 53345.07
Iteration:   4040, Loss function: 3.702, Average Loss: 3.718, avg. samples / sec: 53341.18
Iteration:   4040, Loss function: 3.422, Average Loss: 3.710, avg. samples / sec: 53311.11
Iteration:   4040, Loss function: 2.986, Average Loss: 3.700, avg. samples / sec: 53358.63
Iteration:   4040, Loss function: 2.944, Average Loss: 3.719, avg. samples / sec: 53357.13
Iteration:   4040, Loss function: 2.889, Average Loss: 3.708, avg. samples / sec: 53339.10
Iteration:   4040, Loss function: 3.460, Average Loss: 3.705, avg. samples / sec: 53351.15
Iteration:   4040, Loss function: 2.397, Average Loss: 3.707, avg. samples / sec: 53354.30
Iteration:   4040, Loss function: 3.084, Average Loss: 3.707, avg. samples / sec: 53378.78
Iteration:   4040, Loss function: 3.332, Average Loss: 3.716, avg. samples / sec: 53385.89
Iteration:   4040, Loss function: 3.151, Average Loss: 3.716, avg. samples / sec: 53320.33
Iteration:   4040, Loss function: 4.025, Average Loss: 3.717, avg. samples / sec: 53347.40
Iteration:   4040, Loss function: 3.184, Average Loss: 3.704, avg. samples / sec: 53318.07
Iteration:   4040, Loss function: 2.806, Average Loss: 3.714, avg. samples / sec: 53355.53
Iteration:   4040, Loss function: 3.375, Average Loss: 3.697, avg. samples / sec: 53342.65
Iteration:   4040, Loss function: 5.716, Average Loss: 3.711, avg. samples / sec: 53321.10
Iteration:   4040, Loss function: 2.455, Average Loss: 3.702, avg. samples / sec: 53319.74
Iteration:   4040, Loss function: 3.376, Average Loss: 3.702, avg. samples / sec: 53294.62
Iteration:   4040, Loss function: 3.716, Average Loss: 3.677, avg. samples / sec: 53311.98
Iteration:   4040, Loss function: 3.882, Average Loss: 3.712, avg. samples / sec: 53324.34
:::MLL 1558640993.523 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558640993.524 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 3.380, Average Loss: 3.687, avg. samples / sec: 52923.42
Iteration:   4060, Loss function: 3.953, Average Loss: 3.691, avg. samples / sec: 52974.31
Iteration:   4060, Loss function: 4.329, Average Loss: 3.693, avg. samples / sec: 52918.63
Iteration:   4060, Loss function: 2.682, Average Loss: 3.705, avg. samples / sec: 52897.42
Iteration:   4060, Loss function: 3.135, Average Loss: 3.715, avg. samples / sec: 52926.18
Iteration:   4060, Loss function: 2.382, Average Loss: 3.710, avg. samples / sec: 52854.59
Iteration:   4060, Loss function: 2.733, Average Loss: 3.703, avg. samples / sec: 52911.02
Iteration:   4060, Loss function: 2.435, Average Loss: 3.704, avg. samples / sec: 52943.06
Iteration:   4060, Loss function: 4.404, Average Loss: 3.710, avg. samples / sec: 52831.58
Iteration:   4060, Loss function: 1.861, Average Loss: 3.711, avg. samples / sec: 52936.34
Iteration:   4060, Loss function: 3.686, Average Loss: 3.703, avg. samples / sec: 52923.94
Iteration:   4060, Loss function: 3.373, Average Loss: 3.701, avg. samples / sec: 52927.56
Iteration:   4060, Loss function: 2.877, Average Loss: 3.694, avg. samples / sec: 52951.00
Iteration:   4060, Loss function: 3.384, Average Loss: 3.706, avg. samples / sec: 52909.73
Iteration:   4060, Loss function: 3.039, Average Loss: 3.684, avg. samples / sec: 52902.74
Iteration:   4060, Loss function: 4.623, Average Loss: 3.710, avg. samples / sec: 52933.84
Iteration:   4060, Loss function: 3.209, Average Loss: 3.692, avg. samples / sec: 52914.18
Iteration:   4060, Loss function: 2.390, Average Loss: 3.702, avg. samples / sec: 52976.88
Iteration:   4060, Loss function: 4.007, Average Loss: 3.666, avg. samples / sec: 52906.87
Iteration:   4060, Loss function: 3.430, Average Loss: 3.707, avg. samples / sec: 52898.57
Iteration:   4060, Loss function: 2.423, Average Loss: 3.696, avg. samples / sec: 52945.29
Iteration:   4060, Loss function: 4.214, Average Loss: 3.706, avg. samples / sec: 52899.48
Iteration:   4060, Loss function: 2.820, Average Loss: 3.706, avg. samples / sec: 52928.25
Iteration:   4060, Loss function: 2.724, Average Loss: 3.669, avg. samples / sec: 52941.37
Iteration:   4060, Loss function: 4.282, Average Loss: 3.702, avg. samples / sec: 52883.38
Iteration:   4060, Loss function: 3.659, Average Loss: 3.711, avg. samples / sec: 52894.32
Iteration:   4060, Loss function: 3.431, Average Loss: 3.701, avg. samples / sec: 52868.62
Iteration:   4060, Loss function: 2.981, Average Loss: 3.699, avg. samples / sec: 52908.28
Iteration:   4060, Loss function: 3.392, Average Loss: 3.708, avg. samples / sec: 52883.78
Iteration:   4060, Loss function: 3.109, Average Loss: 3.688, avg. samples / sec: 52863.29
Iteration:   4080, Loss function: 3.367, Average Loss: 3.709, avg. samples / sec: 53562.95
Iteration:   4080, Loss function: 3.200, Average Loss: 3.683, avg. samples / sec: 53498.51
Iteration:   4080, Loss function: 3.576, Average Loss: 3.706, avg. samples / sec: 53458.72
Iteration:   4080, Loss function: 2.579, Average Loss: 3.703, avg. samples / sec: 53494.31
Iteration:   4080, Loss function: 2.805, Average Loss: 3.682, avg. samples / sec: 53430.77
Iteration:   4080, Loss function: 2.648, Average Loss: 3.678, avg. samples / sec: 53397.93
Iteration:   4080, Loss function: 2.550, Average Loss: 3.695, avg. samples / sec: 53419.67
Iteration:   4080, Loss function: 3.520, Average Loss: 3.700, avg. samples / sec: 53443.21
Iteration:   4080, Loss function: 2.195, Average Loss: 3.696, avg. samples / sec: 53406.53
Iteration:   4080, Loss function: 2.654, Average Loss: 3.700, avg. samples / sec: 53446.83
Iteration:   4080, Loss function: 4.151, Average Loss: 3.660, avg. samples / sec: 53467.32
Iteration:   4080, Loss function: 2.800, Average Loss: 3.682, avg. samples / sec: 53466.91
Iteration:   4080, Loss function: 3.130, Average Loss: 3.671, avg. samples / sec: 53456.49
Iteration:   4080, Loss function: 3.653, Average Loss: 3.705, avg. samples / sec: 53506.13
Iteration:   4080, Loss function: 3.319, Average Loss: 3.697, avg. samples / sec: 53450.73
Iteration:   4080, Loss function: 2.332, Average Loss: 3.694, avg. samples / sec: 53451.38
Iteration:   4080, Loss function: 4.215, Average Loss: 3.698, avg. samples / sec: 53478.96
Iteration:   4080, Loss function: 2.946, Average Loss: 3.695, avg. samples / sec: 53504.08
Iteration:   4080, Loss function: 3.173, Average Loss: 3.696, avg. samples / sec: 53442.94
Iteration:   4080, Loss function: 2.921, Average Loss: 3.688, avg. samples / sec: 53437.07
Iteration:   4080, Loss function: 4.488, Average Loss: 3.698, avg. samples / sec: 53452.82
Iteration:   4080, Loss function: 2.487, Average Loss: 3.679, avg. samples / sec: 53519.52
Iteration:   4080, Loss function: 4.508, Average Loss: 3.695, avg. samples / sec: 53462.97
Iteration:   4080, Loss function: 4.392, Average Loss: 3.663, avg. samples / sec: 53459.53
Iteration:   4080, Loss function: 3.535, Average Loss: 3.690, avg. samples / sec: 53440.33
Iteration:   4080, Loss function: 2.956, Average Loss: 3.694, avg. samples / sec: 53443.09
Iteration:   4080, Loss function: 3.841, Average Loss: 3.693, avg. samples / sec: 53408.57
Iteration:   4080, Loss function: 4.084, Average Loss: 3.695, avg. samples / sec: 53451.98
Iteration:   4080, Loss function: 3.485, Average Loss: 3.700, avg. samples / sec: 53461.33
Iteration:   4080, Loss function: 3.363, Average Loss: 3.701, avg. samples / sec: 53391.98
Iteration:   4100, Loss function: 3.511, Average Loss: 3.674, avg. samples / sec: 53477.18
Iteration:   4100, Loss function: 3.190, Average Loss: 3.676, avg. samples / sec: 53533.16
Iteration:   4100, Loss function: 3.778, Average Loss: 3.708, avg. samples / sec: 53423.29
Iteration:   4100, Loss function: 2.431, Average Loss: 3.691, avg. samples / sec: 53542.31
Iteration:   4100, Loss function: 3.186, Average Loss: 3.696, avg. samples / sec: 53502.68
Iteration:   4100, Loss function: 2.681, Average Loss: 3.667, avg. samples / sec: 53526.67
Iteration:   4100, Loss function: 3.536, Average Loss: 3.697, avg. samples / sec: 53516.15
Iteration:   4100, Loss function: 3.071, Average Loss: 3.690, avg. samples / sec: 53542.50
Iteration:   4100, Loss function: 3.092, Average Loss: 3.689, avg. samples / sec: 53469.04
Iteration:   4100, Loss function: 3.184, Average Loss: 3.653, avg. samples / sec: 53517.87
Iteration:   4100, Loss function: 2.707, Average Loss: 3.692, avg. samples / sec: 53523.42
Iteration:   4100, Loss function: 3.221, Average Loss: 3.689, avg. samples / sec: 53523.71
Iteration:   4100, Loss function: 2.602, Average Loss: 3.689, avg. samples / sec: 53490.71
Iteration:   4100, Loss function: 3.892, Average Loss: 3.690, avg. samples / sec: 53521.23
Iteration:   4100, Loss function: 3.946, Average Loss: 3.699, avg. samples / sec: 53571.34
Iteration:   4100, Loss function: 3.696, Average Loss: 3.691, avg. samples / sec: 53503.67
Iteration:   4100, Loss function: 3.723, Average Loss: 3.693, avg. samples / sec: 53504.52
Iteration:   4100, Loss function: 3.513, Average Loss: 3.689, avg. samples / sec: 53521.23
Iteration:   4100, Loss function: 3.055, Average Loss: 3.679, avg. samples / sec: 53502.57
Iteration:   4100, Loss function: 4.317, Average Loss: 3.698, avg. samples / sec: 53484.24
Iteration:   4100, Loss function: 3.967, Average Loss: 3.695, avg. samples / sec: 53541.09
Iteration:   4100, Loss function: 4.192, Average Loss: 3.689, avg. samples / sec: 53507.69
Iteration:   4100, Loss function: 3.653, Average Loss: 3.675, avg. samples / sec: 53459.43
Iteration:   4100, Loss function: 3.789, Average Loss: 3.669, avg. samples / sec: 53466.42
Iteration:   4100, Loss function: 2.435, Average Loss: 3.673, avg. samples / sec: 53485.90
Iteration:   4100, Loss function: 3.474, Average Loss: 3.685, avg. samples / sec: 53506.23
Iteration:   4100, Loss function: 3.568, Average Loss: 3.692, avg. samples / sec: 53507.39
Iteration:   4100, Loss function: 3.316, Average Loss: 3.679, avg. samples / sec: 53482.51
Iteration:   4100, Loss function: 3.431, Average Loss: 3.663, avg. samples / sec: 53475.94
Iteration:   4100, Loss function: 2.918, Average Loss: 3.685, avg. samples / sec: 53382.50
:::MLL 1558640995.727 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558640995.728 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 3.598, Average Loss: 3.665, avg. samples / sec: 53264.28
Iteration:   4120, Loss function: 3.679, Average Loss: 3.684, avg. samples / sec: 53254.90
Iteration:   4120, Loss function: 3.652, Average Loss: 3.682, avg. samples / sec: 53271.51
Iteration:   4120, Loss function: 2.809, Average Loss: 3.705, avg. samples / sec: 53140.10
Iteration:   4120, Loss function: 2.720, Average Loss: 3.677, avg. samples / sec: 53130.61
Iteration:   4120, Loss function: 4.212, Average Loss: 3.685, avg. samples / sec: 53131.05
Iteration:   4120, Loss function: 3.156, Average Loss: 3.669, avg. samples / sec: 53100.98
Iteration:   4120, Loss function: 3.468, Average Loss: 3.692, avg. samples / sec: 53090.40
Iteration:   4120, Loss function: 2.802, Average Loss: 3.681, avg. samples / sec: 53081.40
Iteration:   4120, Loss function: 3.631, Average Loss: 3.682, avg. samples / sec: 53212.94
Iteration:   4120, Loss function: 4.598, Average Loss: 3.688, avg. samples / sec: 53185.99
Iteration:   4120, Loss function: 2.639, Average Loss: 3.672, avg. samples / sec: 53250.50
Iteration:   4120, Loss function: 3.334, Average Loss: 3.664, avg. samples / sec: 53213.00
Iteration:   4120, Loss function: 3.029, Average Loss: 3.647, avg. samples / sec: 53125.74
Iteration:   4120, Loss function: 3.212, Average Loss: 3.692, avg. samples / sec: 53161.73
Iteration:   4120, Loss function: 3.194, Average Loss: 3.686, avg. samples / sec: 53120.31
Iteration:   4120, Loss function: 2.909, Average Loss: 3.679, avg. samples / sec: 53120.95
Iteration:   4120, Loss function: 2.369, Average Loss: 3.692, avg. samples / sec: 53117.43
Iteration:   4120, Loss function: 3.430, Average Loss: 3.690, avg. samples / sec: 53123.66
Iteration:   4120, Loss function: 3.246, Average Loss: 3.661, avg. samples / sec: 53150.20
Iteration:   4120, Loss function: 3.583, Average Loss: 3.669, avg. samples / sec: 53142.25
Iteration:   4120, Loss function: 3.359, Average Loss: 3.669, avg. samples / sec: 53111.42
Iteration:   4120, Loss function: 3.747, Average Loss: 3.687, avg. samples / sec: 53105.88
Iteration:   4120, Loss function: 2.463, Average Loss: 3.679, avg. samples / sec: 53268.65
Iteration:   4120, Loss function: 2.619, Average Loss: 3.680, avg. samples / sec: 53127.26
Iteration:   4120, Loss function: 3.625, Average Loss: 3.689, avg. samples / sec: 53103.22
Iteration:   4120, Loss function: 3.811, Average Loss: 3.687, avg. samples / sec: 53115.29
Iteration:   4120, Loss function: 3.762, Average Loss: 3.685, avg. samples / sec: 53059.15
Iteration:   4120, Loss function: 4.383, Average Loss: 3.659, avg. samples / sec: 53113.53
Iteration:   4120, Loss function: 3.042, Average Loss: 3.682, avg. samples / sec: 53071.88
Iteration:   4140, Loss function: 2.860, Average Loss: 3.695, avg. samples / sec: 53402.66
Iteration:   4140, Loss function: 4.379, Average Loss: 3.658, avg. samples / sec: 53254.90
Iteration:   4140, Loss function: 4.066, Average Loss: 3.663, avg. samples / sec: 53394.89
Iteration:   4140, Loss function: 4.626, Average Loss: 3.680, avg. samples / sec: 53571.76
Iteration:   4140, Loss function: 2.899, Average Loss: 3.668, avg. samples / sec: 53348.24
Iteration:   4140, Loss function: 3.016, Average Loss: 3.680, avg. samples / sec: 53251.26
Iteration:   4140, Loss function: 4.631, Average Loss: 3.679, avg. samples / sec: 53341.30
Iteration:   4140, Loss function: 3.625, Average Loss: 3.676, avg. samples / sec: 53246.90
Iteration:   4140, Loss function: 2.254, Average Loss: 3.681, avg. samples / sec: 53378.15
Iteration:   4140, Loss function: 3.761, Average Loss: 3.674, avg. samples / sec: 53408.01
Iteration:   4140, Loss function: 3.522, Average Loss: 3.653, avg. samples / sec: 53417.70
Iteration:   4140, Loss function: 2.178, Average Loss: 3.683, avg. samples / sec: 53431.29
Iteration:   4140, Loss function: 2.777, Average Loss: 3.636, avg. samples / sec: 53368.97
Iteration:   4140, Loss function: 2.874, Average Loss: 3.670, avg. samples / sec: 53412.40
Iteration:   4140, Loss function: 2.929, Average Loss: 3.662, avg. samples / sec: 53397.75
Iteration:   4140, Loss function: 4.123, Average Loss: 3.670, avg. samples / sec: 53365.54
Iteration:   4140, Loss function: 3.899, Average Loss: 3.681, avg. samples / sec: 53442.01
Iteration:   4140, Loss function: 3.177, Average Loss: 3.671, avg. samples / sec: 53272.98
Iteration:   4140, Loss function: 4.227, Average Loss: 3.684, avg. samples / sec: 53374.33
Iteration:   4140, Loss function: 2.836, Average Loss: 3.678, avg. samples / sec: 53416.39
Iteration:   4140, Loss function: 2.581, Average Loss: 3.662, avg. samples / sec: 53294.56
Iteration:   4140, Loss function: 3.641, Average Loss: 3.681, avg. samples / sec: 53403.43
Iteration:   4140, Loss function: 4.115, Average Loss: 3.664, avg. samples / sec: 53309.72
Iteration:   4140, Loss function: 4.222, Average Loss: 3.687, avg. samples / sec: 53351.09
Iteration:   4140, Loss function: 3.635, Average Loss: 3.646, avg. samples / sec: 53415.66
Iteration:   4140, Loss function: 3.019, Average Loss: 3.686, avg. samples / sec: 53319.26
Iteration:   4140, Loss function: 3.347, Average Loss: 3.678, avg. samples / sec: 53423.70
Iteration:   4140, Loss function: 4.346, Average Loss: 3.668, avg. samples / sec: 53361.17
Iteration:   4140, Loss function: 3.572, Average Loss: 3.681, avg. samples / sec: 53248.43
Iteration:   4140, Loss function: 2.796, Average Loss: 3.673, avg. samples / sec: 53360.59
Iteration:   4160, Loss function: 4.249, Average Loss: 3.691, avg. samples / sec: 53324.71
Iteration:   4160, Loss function: 4.214, Average Loss: 3.658, avg. samples / sec: 53350.38
Iteration:   4160, Loss function: 2.402, Average Loss: 3.659, avg. samples / sec: 53345.07
Iteration:   4160, Loss function: 3.097, Average Loss: 3.672, avg. samples / sec: 53329.45
Iteration:   4160, Loss function: 2.938, Average Loss: 3.673, avg. samples / sec: 53350.40
Iteration:   4160, Loss function: 3.834, Average Loss: 3.675, avg. samples / sec: 53354.93
Iteration:   4160, Loss function: 4.214, Average Loss: 3.669, avg. samples / sec: 53334.55
Iteration:   4160, Loss function: 2.685, Average Loss: 3.653, avg. samples / sec: 53285.35
Iteration:   4160, Loss function: 3.386, Average Loss: 3.668, avg. samples / sec: 53329.33
Iteration:   4160, Loss function: 3.995, Average Loss: 3.673, avg. samples / sec: 53285.17
Iteration:   4160, Loss function: 3.161, Average Loss: 3.679, avg. samples / sec: 53379.50
Iteration:   4160, Loss function: 3.566, Average Loss: 3.669, avg. samples / sec: 53339.60
Iteration:   4160, Loss function: 3.288, Average Loss: 3.656, avg. samples / sec: 53332.07
Iteration:   4160, Loss function: 2.877, Average Loss: 3.634, avg. samples / sec: 53297.22
Iteration:   4160, Loss function: 4.196, Average Loss: 3.666, avg. samples / sec: 53375.52
Iteration:   4160, Loss function: 3.348, Average Loss: 3.676, avg. samples / sec: 53365.05
Iteration:   4160, Loss function: 3.275, Average Loss: 3.665, avg. samples / sec: 53315.43
Iteration:   4160, Loss function: 3.767, Average Loss: 3.674, avg. samples / sec: 53325.09
Iteration:   4160, Loss function: 4.262, Average Loss: 3.672, avg. samples / sec: 53332.25
Iteration:   4160, Loss function: 4.390, Average Loss: 3.644, avg. samples / sec: 53263.64
Iteration:   4160, Loss function: 2.752, Average Loss: 3.666, avg. samples / sec: 53284.97
Iteration:   4160, Loss function: 2.525, Average Loss: 3.675, avg. samples / sec: 53315.85
Iteration:   4160, Loss function: 3.374, Average Loss: 3.663, avg. samples / sec: 53330.82
Iteration:   4160, Loss function: 2.878, Average Loss: 3.679, avg. samples / sec: 53321.22
Iteration:   4160, Loss function: 2.659, Average Loss: 3.676, avg. samples / sec: 53248.57
Iteration:   4160, Loss function: 4.934, Average Loss: 3.672, avg. samples / sec: 53273.71
Iteration:   4160, Loss function: 1.809, Average Loss: 3.683, avg. samples / sec: 53282.51
Iteration:   4160, Loss function: 2.803, Average Loss: 3.656, avg. samples / sec: 53286.96
Iteration:   4160, Loss function: 3.609, Average Loss: 3.641, avg. samples / sec: 53289.38
Iteration:   4160, Loss function: 3.662, Average Loss: 3.656, avg. samples / sec: 53267.26
Iteration:   4180, Loss function: 3.722, Average Loss: 3.655, avg. samples / sec: 53576.29
Iteration:   4180, Loss function: 3.437, Average Loss: 3.670, avg. samples / sec: 53613.32
Iteration:   4180, Loss function: 4.480, Average Loss: 3.649, avg. samples / sec: 53614.18
Iteration:   4180, Loss function: 3.260, Average Loss: 3.652, avg. samples / sec: 53574.59
Iteration:   4180, Loss function: 3.623, Average Loss: 3.686, avg. samples / sec: 53516.51
Iteration:   4180, Loss function: 3.944, Average Loss: 3.661, avg. samples / sec: 53564.15
Iteration:   4180, Loss function: 2.635, Average Loss: 3.664, avg. samples / sec: 53622.50
Iteration:   4180, Loss function: 3.442, Average Loss: 3.663, avg. samples / sec: 53549.96
Iteration:   4180, Loss function: 2.924, Average Loss: 3.660, avg. samples / sec: 53580.44
Iteration:   4180, Loss function: 3.255, Average Loss: 3.668, avg. samples / sec: 53541.76
Iteration:   4180, Loss function: 3.806, Average Loss: 3.669, avg. samples / sec: 53625.78
Iteration:   4180, Loss function: 4.369, Average Loss: 3.631, avg. samples / sec: 53617.11
Iteration:   4180, Loss function: 3.907, Average Loss: 3.635, avg. samples / sec: 53629.52
Iteration:   4180, Loss function: 3.841, Average Loss: 3.674, avg. samples / sec: 53554.44
Iteration:   4180, Loss function: 4.992, Average Loss: 3.662, avg. samples / sec: 53634.58
Iteration:   4180, Loss function: 2.924, Average Loss: 3.668, avg. samples / sec: 53628.76
Iteration:   4180, Loss function: 2.055, Average Loss: 3.669, avg. samples / sec: 53616.52
Iteration:   4180, Loss function: 3.681, Average Loss: 3.648, avg. samples / sec: 53562.17
Iteration:   4180, Loss function: 3.988, Average Loss: 3.654, avg. samples / sec: 53599.88
Iteration:   4180, Loss function: 3.487, Average Loss: 3.666, avg. samples / sec: 53596.23
Iteration:   4180, Loss function: 2.892, Average Loss: 3.654, avg. samples / sec: 53599.54
Iteration:   4180, Loss function: 3.166, Average Loss: 3.663, avg. samples / sec: 53575.92
Iteration:   4180, Loss function: 2.776, Average Loss: 3.662, avg. samples / sec: 53549.56
Iteration:   4180, Loss function: 3.916, Average Loss: 3.635, avg. samples / sec: 53628.89
Iteration:   4180, Loss function: 2.657, Average Loss: 3.669, avg. samples / sec: 53588.33
Iteration:   4180, Loss function: 2.799, Average Loss: 3.650, avg. samples / sec: 53604.77
Iteration:   4180, Loss function: 2.971, Average Loss: 3.648, avg. samples / sec: 53618.97
Iteration:   4180, Loss function: 3.360, Average Loss: 3.667, avg. samples / sec: 53554.81
Iteration:   4180, Loss function: 2.605, Average Loss: 3.655, avg. samples / sec: 53538.61
Iteration:   4180, Loss function: 3.910, Average Loss: 3.678, avg. samples / sec: 53562.58
:::MLL 1558640997.932 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558640997.933 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558640998.004 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=2.52s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23257
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39538
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23914
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05921
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24214
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22140
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10155
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52842
Current AP: 0.23257 AP goal: 0.23000
:::MLL 1558641001.822 eval_accuracy: {"value": 0.23256696773618687, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558641001.911 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558641001.918 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558641002.463 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 07:49:58 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:45 PM
ENDING TIMING RUN AT 2019-05-23 07:49:58 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:45 PM
ENDING TIMING RUN AT 2019-05-23 07:49:59 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:46 PM
ENDING TIMING RUN AT 2019-05-23 07:49:59 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:46 PM
ENDING TIMING RUN AT 2019-05-23 07:50:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:51 PM
ENDING TIMING RUN AT 2019-05-23 07:50:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:54 PM
ENDING TIMING RUN AT 2019-05-23 07:49:59 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:46 PM
ENDING TIMING RUN AT 2019-05-23 07:50:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:51 PM
ENDING TIMING RUN AT 2019-05-23 07:50:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:49 PM
ENDING TIMING RUN AT 2019-05-23 07:50:01 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:48 PM
ENDING TIMING RUN AT 2019-05-23 07:50:01 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:48 PM
ENDING TIMING RUN AT 2019-05-23 07:50:00 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:47 PM
ENDING TIMING RUN AT 2019-05-23 07:49:59 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:46 PM
ENDING TIMING RUN AT 2019-05-23 07:49:59 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:46 PM
ENDING TIMING RUN AT 2019-05-23 07:50:01 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:48 PM
ENDING TIMING RUN AT 2019-05-23 07:50:00 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:47 PM
ENDING TIMING RUN AT 2019-05-23 07:50:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:49 PM
ENDING TIMING RUN AT 2019-05-23 07:50:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:54 PM
ENDING TIMING RUN AT 2019-05-23 07:50:01 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:48 PM
ENDING TIMING RUN AT 2019-05-23 07:50:01 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:48 PM
ENDING TIMING RUN AT 2019-05-23 07:50:03 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:50 PM
ENDING TIMING RUN AT 2019-05-23 07:50:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:51 PM
ENDING TIMING RUN AT 2019-05-23 07:49:59 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:46 PM
ENDING TIMING RUN AT 2019-05-23 07:50:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:58 PM
ENDING TIMING RUN AT 2019-05-23 07:49:59 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:46 PM
ENDING TIMING RUN AT 2019-05-23 07:50:01 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:48 PM
ENDING TIMING RUN AT 2019-05-23 07:49:57 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:44 PM
ENDING TIMING RUN AT 2019-05-23 07:49:57 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:44 PM
ENDING TIMING RUN AT 2019-05-23 07:50:01 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:48 PM
ENDING TIMING RUN AT 2019-05-23 07:49:57 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:46:44 PM
