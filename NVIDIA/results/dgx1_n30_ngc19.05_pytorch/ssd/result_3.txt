Beginning trial 1 of 5
Gathering sys log on sc-sdgx-344
:::MLL 1558639931.910 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558639931.911 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558639931.912 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558639931.912 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558639931.913 submission_platform: {"value": "30xDGX-1 with V100", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558639931.914 submission_entry: {"value": "{'hardware': 'DGX-1 with V100', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.2 LTS / NVIDIA DGX Server 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz', 'num_cores': '40', 'num_vcpus': '80', 'accelerator': 'Tesla V100-SXM2-16GB', 'num_accelerators': '8', 'sys_mem_size': '503 GB', 'sys_storage_type': 'SATA SSD', 'sys_storage_size': '1x 7T + 1x 446.6G', 'cpu_accel_interconnect': 'QPI', 'network_card': 'Mellanox Technologies MT27700 Family [ConnectX-4]', 'num_network_cards': '4', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558639931.915 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558639931.915 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558639983.782 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639984.403 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639982.127 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639978.225 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639980.041 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639980.010 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639985.288 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639982.394 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639983.073 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639981.156 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639981.329 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639980.943 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639980.558 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639982.506 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639980.970 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639980.182 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639985.942 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639986.435 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639991.176 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639982.883 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639983.142 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639985.467 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639986.175 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639991.797 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639985.092 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639990.081 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639984.150 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639986.505 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639984.701 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558639985.272 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node sc-sdgx-344
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-345
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-346
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-344
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-352
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-345
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-344 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-346
Launching on node sc-sdgx-353
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-345 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-346 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
Launching on node sc-sdgx-354
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-352
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-353
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-355
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-352 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-353 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-360
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-354
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-355
Launching on node sc-sdgx-361
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-354 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-360
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-362
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-355 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-360 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-361
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-363
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-361 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-364
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-362
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-369
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-363
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-362 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-364
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-370
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-363 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-364 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-369
+ set +x
Launching on node sc-sdgx-371
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-369 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ set +x
Launching on node sc-sdgx-372
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-370
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-377
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-371
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-370 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-378
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-372
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-371 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-377
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-379
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-372 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-377 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-380
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-378
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-385
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-379
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-378 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-386
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-380
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-379 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-385
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-387
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-380 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-385 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-388
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-386
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-394
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-387
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-386 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-388
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-395
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-387 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-388 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-394
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-396
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-394 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ set +x
Launching on node sc-sdgx-397
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-395
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-398
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-396
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-395 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-397
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-405
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-396 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-397 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-398
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-405
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-398 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-405 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=172.22.0.145 --master_port=4427' -e SLURM_JOB_ID=326640 -e SLURM_NTASKS_PER_NODE=8 cont_326640 ./run_and_time.sh
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:33:06 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=172.22.0.145 --master_port=4427
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:33:04 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:33:12 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:33:10 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:33:07 PM
STARTING TIMING RUN AT 2019-05-23 07:33:07 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:33:03 PM
running benchmark
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:33:06 PM
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:33:04 PM
running benchmark
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 07:33:12 PM
+ echo 'running benchmark'
running benchmark
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=172.22.0.145 --master_port=4427
Run vars: id 326640 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=172.22.0.145 --master_port=4427
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 07:33:07 PM
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:03 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
running benchmark
+ export TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
+ TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:10 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:11 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:10 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:10 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:33:06 PM
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 07:33:07 PM
running benchmark
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:09 PM
STARTING TIMING RUN AT 2019-05-23 07:33:05 PM
running benchmark
running benchmark
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:33:08 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=172.22.0.145 --master_port=4427 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558639994.286 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.286 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.287 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.287 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.287 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.287 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.287 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.288 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.500 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.501 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.502 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639989.502 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639989.504 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.504 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.504 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639989.504 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639991.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.301 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639991.302 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.302 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.302 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.302 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.526 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.526 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.526 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.527 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.529 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.529 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639989.529 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.530 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.745 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.745 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.745 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.745 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.746 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.747 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.747 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639989.747 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639988.773 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.774 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.774 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.774 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.774 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.774 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.775 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.775 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639994.918 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.919 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.920 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639996.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639996.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.920 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639994.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.921 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639996.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639996.088 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639996.088 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639996.088 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558639996.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639996.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639987.771 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.771 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.771 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.771 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.771 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.771 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.771 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.771 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639993.201 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.201 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.203 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639993.203 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.203 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639993.204 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.205 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.205 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639990.311 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.311 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.311 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.312 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.313 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.313 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639990.315 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.315 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639994.541 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.541 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.541 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.542 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.542 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.543 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639994.543 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.543 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639990.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.324 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.324 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.325 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.325 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.325 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639990.326 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639991.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558639993.875 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.875 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.875 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.875 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.257 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.876 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.877 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.877 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639993.877 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639991.259 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639991.035 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.035 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.035 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.035 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.036 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.036 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.036 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.036 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639990.908 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.908 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.909 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.909 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.909 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.910 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.910 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639990.911 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639992.328 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639992.328 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639992.329 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639992.329 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639992.331 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639992.331 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639992.331 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639992.331 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558639989.476 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.476 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.477 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.074 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.074 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.074 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.074 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639987.612 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.612 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.612 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.612 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.614 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.614 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639987.614 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639987.615 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.632 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.632 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.633 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.633 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.633 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.633 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.634 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.634 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639991.709 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.709 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.711 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.711 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.712 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.712 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639991.712 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558639991.713 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639988.699 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.699 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.699 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.700 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.700 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.700 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.701 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.701 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.493 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.494 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558639996.570 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639996.570 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639996.570 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639996.570 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639990.494 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.494 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.494 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639990.495 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639990.496 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639990.496 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558639996.572 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639996.572 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639996.572 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639996.575 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639994.637 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.638 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.639 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.640 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639994.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639994.641 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639988.171 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.171 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.172 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.172 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558639988.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639988.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.468 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.468 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558639989.470 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.470 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639989.470 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558639989.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.453 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.453 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.455 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558639989.455 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558639989.457 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
5 Using seed = 3543261729
1 Using seed = 3543261725
0 Using seed = 3543261724
:::MLL 1558639999.679 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
3 Using seed = 3543261727
7 Using seed = 3543261731
6 Using seed = 3543261730
4 Using seed = 3543261728
14 Using seed = 3543261738
13 Using seed = 3543261737
12 Using seed = 3543261736
15 Using seed = 3543261739
8 Using seed = 3543261732
11 Using seed = 3543261735
9 Using seed = 3543261733
10 Using seed = 3543261734
16 Using seed = 3543261740
17 Using seed = 3543261741
18 Using seed = 3543261742
21 Using seed = 3543261745
23 Using seed = 3543261747
22 Using seed = 3543261746
19 Using seed = 3543261743
20 Using seed = 3543261744
29 Using seed = 3543261753
25 Using seed = 3543261749
26 Using seed = 3543261750
24 Using seed = 3543261748
31 Using seed = 3543261755
30 Using seed = 3543261754
27 Using seed = 3543261751
28 Using seed = 3543261752
36 Using seed = 3543261760
37 Using seed = 3543261761
38 Using seed = 3543261762
39 Using seed = 3543261763
32 Using seed = 3543261756
33 Using seed = 3543261757
34 Using seed = 3543261758
35 Using seed = 3543261759
40 Using seed = 3543261764
41 Using seed = 3543261765
42 Using seed = 3543261766
45 Using seed = 3543261769
47 Using seed = 3543261771
46 Using seed = 3543261770
43 Using seed = 3543261767
44 Using seed = 3543261768
49 Using seed = 3543261773
48 Using seed = 3543261772
51 Using seed = 3543261775
50 Using seed = 3543261774
55 Using seed = 3543261779
52 Using seed = 3543261776
53 Using seed = 3543261777
54 Using seed = 3543261778
61 Using seed = 3543261785
62 Using seed = 3543261786
63 Using seed = 3543261787
60 Using seed = 3543261784
57 Using seed = 3543261781
58 Using seed = 3543261782
56 Using seed = 3543261780
59 Using seed = 3543261783
69 Using seed = 3543261793
70 Using seed = 3543261794
68 Using seed = 3543261792
71 Using seed = 3543261795
65 Using seed = 3543261789
67 Using seed = 3543261791
64 Using seed = 3543261788
66 Using seed = 3543261790
74 Using seed = 3543261798
75 Using seed = 3543261799
73 Using seed = 3543261797
72 Using seed = 3543261796
77 Using seed = 3543261801
78 Using seed = 3543261802
79 Using seed = 3543261803
76 Using seed = 3543261800
87 Using seed = 3543261811
84 Using seed = 3543261808
86 Using seed = 3543261810
83 Using seed = 3543261807
85 Using seed = 3543261809
82 Using seed = 3543261806
80 Using seed = 3543261804
81 Using seed = 3543261805
93 Using seed = 3543261817
94 Using seed = 3543261818
95 Using seed = 3543261819
92 Using seed = 3543261816
89 Using seed = 3543261813
90 Using seed = 3543261814
88 Using seed = 3543261812
91 Using seed = 3543261815
99 Using seed = 3543261823
96 Using seed = 3543261820
98 Using seed = 3543261822
97 Using seed = 3543261821
101 Using seed = 3543261825
103 Using seed = 3543261827
100 Using seed = 3543261824
102 Using seed = 3543261826
110 Using seed = 3543261834
109 Using seed = 3543261833
108 Using seed = 3543261832
111 Using seed = 3543261835
105 Using seed = 3543261829
104 Using seed = 3543261828
106 Using seed = 3543261830
107 Using seed = 3543261831
118 Using seed = 3543261842
117 Using seed = 3543261841
119 Using seed = 3543261843
116 Using seed = 3543261840
112 Using seed = 3543261836
113 Using seed = 3543261837
114 Using seed = 3543261838
115 Using seed = 3543261839
126 Using seed = 3543261850
124 Using seed = 3543261848
125 Using seed = 3543261849
127 Using seed = 3543261851
120 Using seed = 3543261844
121 Using seed = 3543261845
123 Using seed = 3543261847
122 Using seed = 3543261846
133 Using seed = 3543261857
132 Using seed = 3543261856
134 Using seed = 3543261858
135 Using seed = 3543261859
130 Using seed = 3543261854
129 Using seed = 3543261853
131 Using seed = 3543261855
128 Using seed = 3543261852
139 Using seed = 3543261863
137 Using seed = 3543261861
138 Using seed = 3543261862
136 Using seed = 3543261860
142 Using seed = 3543261866
143 Using seed = 3543261867
141 Using seed = 3543261865
140 Using seed = 3543261864
146 Using seed = 3543261870
147 Using seed = 3543261871
145 Using seed = 3543261869
144 Using seed = 3543261868
149 Using seed = 3543261873
150 Using seed = 3543261874
148 Using seed = 3543261872
151 Using seed = 3543261875
157 Using seed = 3543261881
159 Using seed = 3543261883
158 Using seed = 3543261882
156 Using seed = 3543261880
153 Using seed = 3543261877
155 Using seed = 3543261879
152 Using seed = 3543261876
154 Using seed = 3543261878
167 Using seed = 3543261891
166 Using seed = 3543261890
165 Using seed = 3543261889
164 Using seed = 3543261888
160 Using seed = 3543261884
161 Using seed = 3543261885
163 Using seed = 3543261887
162 Using seed = 3543261886
171 Using seed = 3543261895
168 Using seed = 3543261892
169 Using seed = 3543261893
170 Using seed = 3543261894
175 Using seed = 3543261899
174 Using seed = 3543261898
173 Using seed = 3543261897
172 Using seed = 3543261896
181 Using seed = 3543261905
182 Using seed = 3543261906
183 Using seed = 3543261907
180 Using seed = 3543261904
177 Using seed = 3543261901
176 Using seed = 3543261900
179 Using seed = 3543261903
178 Using seed = 3543261902
184 Using seed = 3543261908
185 Using seed = 3543261909
187 Using seed = 3543261911
186 Using seed = 3543261910
191 Using seed = 3543261915
189 Using seed = 3543261913
188 Using seed = 3543261912
190 Using seed = 3543261914
193 Using seed = 3543261917
194 Using seed = 3543261918
192 Using seed = 3543261916
197 Using seed = 3543261921
195 Using seed = 3543261919
198 Using seed = 3543261922
199 Using seed = 3543261923
196 Using seed = 3543261920
206 Using seed = 3543261930
207 Using seed = 3543261931
205 Using seed = 3543261929
204 Using seed = 3543261928
200 Using seed = 3543261924
202 Using seed = 3543261926
203 Using seed = 3543261927
201 Using seed = 3543261925
213 Using seed = 3543261937
214 Using seed = 3543261938
215 Using seed = 3543261939
212 Using seed = 3543261936
211 Using seed = 3543261935
210 Using seed = 3543261934
208 Using seed = 3543261932
209 Using seed = 3543261933
221 Using seed = 3543261945
222 Using seed = 3543261946
223 Using seed = 3543261947
220 Using seed = 3543261944
219 Using seed = 3543261943
217 Using seed = 3543261941
216 Using seed = 3543261940
218 Using seed = 3543261942
227 Using seed = 3543261951
225 Using seed = 3543261949
224 Using seed = 3543261948
226 Using seed = 3543261950
229 Using seed = 3543261953
231 Using seed = 3543261955
228 Using seed = 3543261952
230 Using seed = 3543261954
236 Using seed = 3543261960
239 Using seed = 3543261963
238 Using seed = 3543261962
237 Using seed = 3543261961
233 Using seed = 3543261957
235 Using seed = 3543261959
234 Using seed = 3543261958
232 Using seed = 3543261956
2 Using seed = 3543261726
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1558640004.416 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558640004.416 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558640004.424 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558640004.424 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1558640004.425 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558640004.425 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558640013.233 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558640013.234 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.45s)
creating index...
Done (t=0.45s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
Done (t=0.47s)
creating index...
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
Done (t=0.48s)
creating index...
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
Done (t=0.48s)
creating index...
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
Done (t=0.50s)
creating index...
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.55s)
creating index...
Done (t=0.66s)
creating index...
time_check a: 1558640014.607262611
time_check a: 1558640014.886150122
time_check a: 1558640019.728776455
time_check a: 1558640020.185147762
time_check a: 1558640014.485837460
time_check a: 1558640013.767586708
time_check a: 1558640021.636420250
time_check a: 1558640014.063959599
time_check a: 1558640019.692658663
time_check a: 1558640014.419869661
time_check a: 1558640016.432109118
time_check a: 1558640021.355704069
time_check a: 1558640013.217947245
time_check a: 1558640017.475667953
time_check a: 1558640014.743210554
time_check a: 1558640019.055278540
time_check a: 1558640016.203569889
time_check a: 1558640015.512174845
time_check a: 1558640014.213786125
time_check a: 1558640015.572111845
time_check a: 1558640018.445003271
time_check a: 1558640012.754601717
time_check a: 1558640013.058725357
time_check a: 1558640016.091256380
time_check a: 1558640016.827574253
time_check a: 1558640015.099288940
time_check a: 1558640016.696929216
time_check a: 1558640015.560595751
time_check a: 1558640014.896533489
time_check a: 1558640019.789875984
time_check b: 1558640018.277708769
time_check b: 1558640016.893550873
time_check b: 1558640017.744477034
time_check b: 1558640022.112405300
time_check b: 1558640018.175264835
time_check b: 1558640019.259750128
time_check b: 1558640022.747688770
time_check b: 1558640020.508551598
time_check b: 1558640019.775774956
time_check b: 1558640023.907192230
time_check b: 1558640019.249581337
time_check b: 1558640019.222696304
time_check b: 1558640018.585223913
time_check b: 1558640016.457035065
time_check b: 1558640025.368890285
time_check b: 1558640018.159847498
time_check b: 1558640023.475087166
time_check b: 1558640017.513792992
time_check b: 1558640016.783235550
time_check b: 1558640018.642318010
time_check b: 1558640025.108301401
time_check b: 1558640020.192441702
time_check b: 1558640021.234587908
time_check b: 1558640020.431572199
time_check b: 1558640019.967314243
time_check b: 1558640018.855369806
time_check b: 1558640023.479315758
time_check b: 1558640018.528445721
time_check b: 1558640023.559114695
time_check b: 1558640018.059215307
:::MLL 1558640020.152 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558640020.153 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.683, Average Loss: 0.023, avg. samples / sec: 132.48
Iteration:      0, Loss function: 22.177, Average Loss: 0.022, avg. samples / sec: 132.89
Iteration:      0, Loss function: 22.894, Average Loss: 0.023, avg. samples / sec: 141.94
Iteration:      0, Loss function: 22.013, Average Loss: 0.022, avg. samples / sec: 131.67
Iteration:      0, Loss function: 22.566, Average Loss: 0.023, avg. samples / sec: 130.53
Iteration:      0, Loss function: 22.618, Average Loss: 0.023, avg. samples / sec: 131.37
Iteration:      0, Loss function: 22.683, Average Loss: 0.023, avg. samples / sec: 131.70
Iteration:      0, Loss function: 23.158, Average Loss: 0.023, avg. samples / sec: 131.89
Iteration:      0, Loss function: 22.823, Average Loss: 0.023, avg. samples / sec: 132.62
Iteration:      0, Loss function: 22.566, Average Loss: 0.023, avg. samples / sec: 133.22
Iteration:      0, Loss function: 22.795, Average Loss: 0.023, avg. samples / sec: 130.99
Iteration:      0, Loss function: 22.994, Average Loss: 0.023, avg. samples / sec: 134.72
Iteration:      0, Loss function: 23.364, Average Loss: 0.023, avg. samples / sec: 131.25
Iteration:      0, Loss function: 23.401, Average Loss: 0.023, avg. samples / sec: 135.62
Iteration:      0, Loss function: 22.670, Average Loss: 0.023, avg. samples / sec: 132.19
Iteration:      0, Loss function: 23.181, Average Loss: 0.023, avg. samples / sec: 131.97
Iteration:      0, Loss function: 22.368, Average Loss: 0.022, avg. samples / sec: 131.17
Iteration:      0, Loss function: 23.854, Average Loss: 0.024, avg. samples / sec: 164.71
Iteration:      0, Loss function: 22.945, Average Loss: 0.023, avg. samples / sec: 132.44
Iteration:      0, Loss function: 23.091, Average Loss: 0.023, avg. samples / sec: 132.58
Iteration:      0, Loss function: 22.599, Average Loss: 0.023, avg. samples / sec: 132.23
Iteration:      0, Loss function: 23.647, Average Loss: 0.024, avg. samples / sec: 132.39
Iteration:      0, Loss function: 22.905, Average Loss: 0.023, avg. samples / sec: 134.80
Iteration:      0, Loss function: 22.543, Average Loss: 0.023, avg. samples / sec: 129.31
Iteration:      0, Loss function: 22.192, Average Loss: 0.022, avg. samples / sec: 130.64
Iteration:      0, Loss function: 22.577, Average Loss: 0.023, avg. samples / sec: 132.27
Iteration:      0, Loss function: 22.988, Average Loss: 0.023, avg. samples / sec: 133.92
Iteration:      0, Loss function: 22.639, Average Loss: 0.023, avg. samples / sec: 131.29
Iteration:      0, Loss function: 21.984, Average Loss: 0.022, avg. samples / sec: 129.96
Iteration:      0, Loss function: 22.748, Average Loss: 0.023, avg. samples / sec: 127.67
Iteration:     20, Loss function: 20.705, Average Loss: 0.444, avg. samples / sec: 33241.52
Iteration:     20, Loss function: 20.637, Average Loss: 0.442, avg. samples / sec: 35612.82
Iteration:     20, Loss function: 21.306, Average Loss: 0.446, avg. samples / sec: 34198.39
Iteration:     20, Loss function: 20.836, Average Loss: 0.445, avg. samples / sec: 33611.64
Iteration:     20, Loss function: 21.053, Average Loss: 0.441, avg. samples / sec: 35707.08
Iteration:     20, Loss function: 20.518, Average Loss: 0.442, avg. samples / sec: 33294.27
Iteration:     20, Loss function: 20.607, Average Loss: 0.445, avg. samples / sec: 34284.75
Iteration:     20, Loss function: 20.764, Average Loss: 0.445, avg. samples / sec: 34520.22
Iteration:     20, Loss function: 20.241, Average Loss: 0.442, avg. samples / sec: 33949.04
Iteration:     20, Loss function: 20.253, Average Loss: 0.443, avg. samples / sec: 33005.64
Iteration:     20, Loss function: 20.217, Average Loss: 0.443, avg. samples / sec: 34223.54
Iteration:     20, Loss function: 20.323, Average Loss: 0.441, avg. samples / sec: 33382.37
Iteration:     20, Loss function: 21.902, Average Loss: 0.444, avg. samples / sec: 34101.96
Iteration:     20, Loss function: 20.287, Average Loss: 0.449, avg. samples / sec: 34311.88
Iteration:     20, Loss function: 20.726, Average Loss: 0.445, avg. samples / sec: 32461.90
Iteration:     20, Loss function: 20.275, Average Loss: 0.445, avg. samples / sec: 33160.86
Iteration:     20, Loss function: 20.597, Average Loss: 0.446, avg. samples / sec: 33548.64
Iteration:     20, Loss function: 20.691, Average Loss: 0.442, avg. samples / sec: 36095.35
Iteration:     20, Loss function: 21.214, Average Loss: 0.443, avg. samples / sec: 34452.59
Iteration:     20, Loss function: 20.994, Average Loss: 0.445, avg. samples / sec: 32398.60
Iteration:     20, Loss function: 20.339, Average Loss: 0.444, avg. samples / sec: 33284.23
Iteration:     20, Loss function: 21.341, Average Loss: 0.444, avg. samples / sec: 34993.94
Iteration:     20, Loss function: 21.315, Average Loss: 0.444, avg. samples / sec: 34582.33
Iteration:     20, Loss function: 20.693, Average Loss: 0.447, avg. samples / sec: 34103.46
Iteration:     20, Loss function: 20.602, Average Loss: 0.444, avg. samples / sec: 33693.48
Iteration:     20, Loss function: 20.528, Average Loss: 0.443, avg. samples / sec: 33525.66
Iteration:     20, Loss function: 20.672, Average Loss: 0.444, avg. samples / sec: 34994.48
Iteration:     20, Loss function: 21.237, Average Loss: 0.443, avg. samples / sec: 35003.28
Iteration:     20, Loss function: 20.567, Average Loss: 0.447, avg. samples / sec: 34423.62
Iteration:     20, Loss function: 21.072, Average Loss: 0.443, avg. samples / sec: 36009.78
Iteration:     40, Loss function: 18.640, Average Loss: 0.830, avg. samples / sec: 49663.04
Iteration:     40, Loss function: 18.918, Average Loss: 0.830, avg. samples / sec: 49635.00
Iteration:     40, Loss function: 18.239, Average Loss: 0.838, avg. samples / sec: 50147.96
Iteration:     40, Loss function: 18.249, Average Loss: 0.838, avg. samples / sec: 50033.00
Iteration:     40, Loss function: 18.602, Average Loss: 0.842, avg. samples / sec: 49877.14
Iteration:     40, Loss function: 19.565, Average Loss: 0.838, avg. samples / sec: 49975.66
Iteration:     40, Loss function: 18.482, Average Loss: 0.836, avg. samples / sec: 50034.71
Iteration:     40, Loss function: 18.564, Average Loss: 0.829, avg. samples / sec: 49667.49
Iteration:     40, Loss function: 18.926, Average Loss: 0.835, avg. samples / sec: 49442.01
Iteration:     40, Loss function: 19.209, Average Loss: 0.841, avg. samples / sec: 49880.78
Iteration:     40, Loss function: 19.023, Average Loss: 0.837, avg. samples / sec: 50004.26
Iteration:     40, Loss function: 18.832, Average Loss: 0.833, avg. samples / sec: 49940.70
Iteration:     40, Loss function: 20.455, Average Loss: 0.842, avg. samples / sec: 49926.64
Iteration:     40, Loss function: 18.633, Average Loss: 0.839, avg. samples / sec: 49754.58
Iteration:     40, Loss function: 19.000, Average Loss: 0.832, avg. samples / sec: 49896.02
Iteration:     40, Loss function: 19.037, Average Loss: 0.837, avg. samples / sec: 49658.23
Iteration:     40, Loss function: 18.420, Average Loss: 0.834, avg. samples / sec: 49351.13
Iteration:     40, Loss function: 19.517, Average Loss: 0.836, avg. samples / sec: 49235.63
Iteration:     40, Loss function: 18.819, Average Loss: 0.831, avg. samples / sec: 49648.45
Iteration:     40, Loss function: 18.588, Average Loss: 0.836, avg. samples / sec: 49691.88
Iteration:     40, Loss function: 19.013, Average Loss: 0.836, avg. samples / sec: 49480.67
Iteration:     40, Loss function: 18.904, Average Loss: 0.835, avg. samples / sec: 49751.00
Iteration:     40, Loss function: 19.054, Average Loss: 0.835, avg. samples / sec: 49373.12
Iteration:     40, Loss function: 18.800, Average Loss: 0.835, avg. samples / sec: 49188.46
Iteration:     40, Loss function: 19.291, Average Loss: 0.834, avg. samples / sec: 49105.43
Iteration:     40, Loss function: 18.495, Average Loss: 0.828, avg. samples / sec: 48981.03
Iteration:     40, Loss function: 18.142, Average Loss: 0.835, avg. samples / sec: 49278.93
Iteration:     40, Loss function: 19.246, Average Loss: 0.836, avg. samples / sec: 48824.79
Iteration:     40, Loss function: 19.532, Average Loss: 0.833, avg. samples / sec: 49316.21
Iteration:     40, Loss function: 19.314, Average Loss: 0.831, avg. samples / sec: 48423.14
Iteration:     60, Loss function: 11.597, Average Loss: 1.109, avg. samples / sec: 51519.13
Iteration:     60, Loss function: 11.307, Average Loss: 1.106, avg. samples / sec: 51367.29
Iteration:     60, Loss function: 12.342, Average Loss: 1.100, avg. samples / sec: 52556.06
Iteration:     60, Loss function: 13.318, Average Loss: 1.110, avg. samples / sec: 51092.99
Iteration:     60, Loss function: 13.311, Average Loss: 1.107, avg. samples / sec: 51247.53
Iteration:     60, Loss function: 13.013, Average Loss: 1.102, avg. samples / sec: 51264.76
Iteration:     60, Loss function: 11.484, Average Loss: 1.110, avg. samples / sec: 51199.76
Iteration:     60, Loss function: 11.623, Average Loss: 1.099, avg. samples / sec: 51092.99
Iteration:     60, Loss function: 12.585, Average Loss: 1.103, avg. samples / sec: 51001.26
Iteration:     60, Loss function: 11.767, Average Loss: 1.101, avg. samples / sec: 51203.61
Iteration:     60, Loss function: 14.900, Average Loss: 1.109, avg. samples / sec: 51169.68
Iteration:     60, Loss function: 13.734, Average Loss: 1.107, avg. samples / sec: 50968.28
Iteration:     60, Loss function: 11.341, Average Loss: 1.097, avg. samples / sec: 51305.59
Iteration:     60, Loss function: 11.701, Average Loss: 1.101, avg. samples / sec: 51256.70
Iteration:     60, Loss function: 12.632, Average Loss: 1.094, avg. samples / sec: 51500.94
Iteration:     60, Loss function: 11.916, Average Loss: 1.104, avg. samples / sec: 51166.95
Iteration:     60, Loss function: 12.635, Average Loss: 1.103, avg. samples / sec: 51171.33
Iteration:     60, Loss function: 13.600, Average Loss: 1.104, avg. samples / sec: 51715.01
Iteration:     60, Loss function: 11.743, Average Loss: 1.105, avg. samples / sec: 51199.01
Iteration:     60, Loss function: 10.528, Average Loss: 1.097, avg. samples / sec: 51571.73
Iteration:     60, Loss function: 13.325, Average Loss: 1.111, avg. samples / sec: 51167.28
Iteration:     60, Loss function: 13.591, Average Loss: 1.111, avg. samples / sec: 50688.91
Iteration:     60, Loss function: 12.940, Average Loss: 1.098, avg. samples / sec: 51267.26
Iteration:     60, Loss function: 14.993, Average Loss: 1.108, avg. samples / sec: 50693.67
Iteration:     60, Loss function: 12.068, Average Loss: 1.105, avg. samples / sec: 51066.99
Iteration:     60, Loss function: 12.643, Average Loss: 1.100, avg. samples / sec: 51139.88
Iteration:     60, Loss function: 13.530, Average Loss: 1.098, avg. samples / sec: 50557.11
Iteration:     60, Loss function: 12.496, Average Loss: 1.100, avg. samples / sec: 50954.59
Iteration:     60, Loss function: 11.496, Average Loss: 1.095, avg. samples / sec: 50223.81
Iteration:     60, Loss function: 12.408, Average Loss: 1.104, avg. samples / sec: 50162.06
:::MLL 1558640023.673 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558640023.673 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 10.832, Average Loss: 1.302, avg. samples / sec: 51157.70
Iteration:     80, Loss function: 11.135, Average Loss: 1.314, avg. samples / sec: 50963.47
Iteration:     80, Loss function: 10.071, Average Loss: 1.314, avg. samples / sec: 51092.01
Iteration:     80, Loss function: 12.010, Average Loss: 1.315, avg. samples / sec: 51155.49
Iteration:     80, Loss function: 11.925, Average Loss: 1.306, avg. samples / sec: 50888.99
Iteration:     80, Loss function: 11.384, Average Loss: 1.320, avg. samples / sec: 51089.69
Iteration:     80, Loss function: 11.728, Average Loss: 1.311, avg. samples / sec: 50851.77
Iteration:     80, Loss function: 11.340, Average Loss: 1.299, avg. samples / sec: 51538.80
Iteration:     80, Loss function: 12.280, Average Loss: 1.305, avg. samples / sec: 50792.63
Iteration:     80, Loss function: 11.096, Average Loss: 1.306, avg. samples / sec: 51754.43
Iteration:     80, Loss function: 10.489, Average Loss: 1.311, avg. samples / sec: 50791.77
Iteration:     80, Loss function: 10.378, Average Loss: 1.303, avg. samples / sec: 50578.04
Iteration:     80, Loss function: 11.943, Average Loss: 1.313, avg. samples / sec: 50650.09
Iteration:     80, Loss function: 12.115, Average Loss: 1.318, avg. samples / sec: 50491.15
Iteration:     80, Loss function: 10.175, Average Loss: 1.302, avg. samples / sec: 51296.93
Iteration:     80, Loss function: 10.822, Average Loss: 1.312, avg. samples / sec: 50666.37
Iteration:     80, Loss function: 10.611, Average Loss: 1.307, avg. samples / sec: 50607.93
Iteration:     80, Loss function: 11.125, Average Loss: 1.319, avg. samples / sec: 50728.22
Iteration:     80, Loss function: 11.635, Average Loss: 1.304, avg. samples / sec: 50777.05
Iteration:     80, Loss function: 11.877, Average Loss: 1.298, avg. samples / sec: 50692.76
Iteration:     80, Loss function: 11.580, Average Loss: 1.303, avg. samples / sec: 50790.25
Iteration:     80, Loss function: 10.708, Average Loss: 1.308, avg. samples / sec: 50712.94
Iteration:     80, Loss function: 11.518, Average Loss: 1.301, avg. samples / sec: 50235.50
Iteration:     80, Loss function: 11.165, Average Loss: 1.314, avg. samples / sec: 49822.07
Iteration:     80, Loss function: 11.437, Average Loss: 1.303, avg. samples / sec: 50009.32
Iteration:     80, Loss function: 10.864, Average Loss: 1.322, avg. samples / sec: 49462.02
Iteration:     80, Loss function: 11.379, Average Loss: 1.295, avg. samples / sec: 49750.14
Iteration:     80, Loss function: 11.438, Average Loss: 1.313, avg. samples / sec: 49442.79
Iteration:     80, Loss function: 10.888, Average Loss: 1.304, avg. samples / sec: 49149.19
Iteration:     80, Loss function: 9.284, Average Loss: 1.298, avg. samples / sec: 48315.15
Iteration:    100, Loss function: 9.602, Average Loss: 1.485, avg. samples / sec: 49863.13
Iteration:    100, Loss function: 9.004, Average Loss: 1.479, avg. samples / sec: 49157.86
Iteration:    100, Loss function: 9.092, Average Loss: 1.484, avg. samples / sec: 50351.95
Iteration:    100, Loss function: 9.827, Average Loss: 1.483, avg. samples / sec: 49114.54
Iteration:    100, Loss function: 9.692, Average Loss: 1.468, avg. samples / sec: 49004.86
Iteration:    100, Loss function: 8.927, Average Loss: 1.493, avg. samples / sec: 48870.10
Iteration:    100, Loss function: 9.257, Average Loss: 1.473, avg. samples / sec: 49077.32
Iteration:    100, Loss function: 10.000, Average Loss: 1.474, avg. samples / sec: 49081.39
Iteration:    100, Loss function: 8.898, Average Loss: 1.477, avg. samples / sec: 48745.62
Iteration:    100, Loss function: 9.864, Average Loss: 1.489, avg. samples / sec: 48760.90
Iteration:    100, Loss function: 9.240, Average Loss: 1.488, avg. samples / sec: 48459.32
Iteration:    100, Loss function: 10.296, Average Loss: 1.492, avg. samples / sec: 49474.75
Iteration:    100, Loss function: 9.423, Average Loss: 1.490, avg. samples / sec: 48800.87
Iteration:    100, Loss function: 9.172, Average Loss: 1.480, avg. samples / sec: 48531.98
Iteration:    100, Loss function: 9.211, Average Loss: 1.474, avg. samples / sec: 48775.97
Iteration:    100, Loss function: 10.098, Average Loss: 1.472, avg. samples / sec: 48731.56
Iteration:    100, Loss function: 9.046, Average Loss: 1.482, avg. samples / sec: 48305.84
Iteration:    100, Loss function: 9.923, Average Loss: 1.484, avg. samples / sec: 48511.10
Iteration:    100, Loss function: 9.533, Average Loss: 1.479, avg. samples / sec: 48116.93
Iteration:    100, Loss function: 9.747, Average Loss: 1.478, avg. samples / sec: 48283.94
Iteration:    100, Loss function: 10.429, Average Loss: 1.483, avg. samples / sec: 48648.13
Iteration:    100, Loss function: 9.074, Average Loss: 1.478, avg. samples / sec: 48521.84
Iteration:    100, Loss function: 9.090, Average Loss: 1.471, avg. samples / sec: 49119.07
Iteration:    100, Loss function: 9.193, Average Loss: 1.475, avg. samples / sec: 48811.72
Iteration:    100, Loss function: 9.396, Average Loss: 1.481, avg. samples / sec: 48187.79
Iteration:    100, Loss function: 9.796, Average Loss: 1.485, avg. samples / sec: 48020.15
Iteration:    100, Loss function: 9.108, Average Loss: 1.472, avg. samples / sec: 50844.25
Iteration:    100, Loss function: 9.484, Average Loss: 1.484, avg. samples / sec: 48247.61
Iteration:    100, Loss function: 9.167, Average Loss: 1.465, avg. samples / sec: 48570.26
Iteration:    100, Loss function: 10.382, Average Loss: 1.474, avg. samples / sec: 48801.21
Iteration:    120, Loss function: 9.172, Average Loss: 1.623, avg. samples / sec: 50988.78
Iteration:    120, Loss function: 8.324, Average Loss: 1.644, avg. samples / sec: 51274.27
Iteration:    120, Loss function: 8.710, Average Loss: 1.632, avg. samples / sec: 50719.36
Iteration:    120, Loss function: 8.684, Average Loss: 1.637, avg. samples / sec: 50616.42
Iteration:    120, Loss function: 9.264, Average Loss: 1.637, avg. samples / sec: 51200.95
Iteration:    120, Loss function: 9.811, Average Loss: 1.630, avg. samples / sec: 51278.26
Iteration:    120, Loss function: 8.627, Average Loss: 1.622, avg. samples / sec: 51771.58
Iteration:    120, Loss function: 9.896, Average Loss: 1.617, avg. samples / sec: 50660.47
Iteration:    120, Loss function: 9.355, Average Loss: 1.627, avg. samples / sec: 51409.73
Iteration:    120, Loss function: 9.192, Average Loss: 1.631, avg. samples / sec: 50436.36
Iteration:    120, Loss function: 9.428, Average Loss: 1.635, avg. samples / sec: 50469.01
Iteration:    120, Loss function: 8.909, Average Loss: 1.629, avg. samples / sec: 51505.65
Iteration:    120, Loss function: 9.071, Average Loss: 1.631, avg. samples / sec: 51421.30
Iteration:    120, Loss function: 8.320, Average Loss: 1.639, avg. samples / sec: 51047.39
Iteration:    120, Loss function: 9.229, Average Loss: 1.635, avg. samples / sec: 51631.47
Iteration:    120, Loss function: 9.103, Average Loss: 1.619, avg. samples / sec: 51130.93
Iteration:    120, Loss function: 10.621, Average Loss: 1.630, avg. samples / sec: 51255.79
Iteration:    120, Loss function: 8.459, Average Loss: 1.631, avg. samples / sec: 51265.41
Iteration:    120, Loss function: 8.342, Average Loss: 1.646, avg. samples / sec: 50605.33
Iteration:    120, Loss function: 8.969, Average Loss: 1.625, avg. samples / sec: 51271.53
Iteration:    120, Loss function: 9.665, Average Loss: 1.628, avg. samples / sec: 52423.73
Iteration:    120, Loss function: 9.292, Average Loss: 1.634, avg. samples / sec: 51225.66
Iteration:    120, Loss function: 8.598, Average Loss: 1.634, avg. samples / sec: 51383.00
Iteration:    120, Loss function: 8.474, Average Loss: 1.618, avg. samples / sec: 50588.77
Iteration:    120, Loss function: 8.928, Average Loss: 1.632, avg. samples / sec: 51010.21
Iteration:    120, Loss function: 9.171, Average Loss: 1.641, avg. samples / sec: 50715.88
Iteration:    120, Loss function: 8.793, Average Loss: 1.612, avg. samples / sec: 51713.15
Iteration:    120, Loss function: 8.837, Average Loss: 1.627, avg. samples / sec: 50105.56
Iteration:    120, Loss function: 8.728, Average Loss: 1.624, avg. samples / sec: 50131.00
Iteration:    120, Loss function: 8.923, Average Loss: 1.636, avg. samples / sec: 50250.82
:::MLL 1558640025.985 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558640025.985 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 8.839, Average Loss: 1.788, avg. samples / sec: 53155.98
Iteration:    140, Loss function: 8.401, Average Loss: 1.773, avg. samples / sec: 53175.13
Iteration:    140, Loss function: 7.648, Average Loss: 1.769, avg. samples / sec: 54165.09
Iteration:    140, Loss function: 8.844, Average Loss: 1.761, avg. samples / sec: 53166.36
Iteration:    140, Loss function: 9.456, Average Loss: 1.759, avg. samples / sec: 53201.05
Iteration:    140, Loss function: 8.342, Average Loss: 1.778, avg. samples / sec: 53580.93
Iteration:    140, Loss function: 8.757, Average Loss: 1.767, avg. samples / sec: 52996.90
Iteration:    140, Loss function: 8.346, Average Loss: 1.771, avg. samples / sec: 53181.43
Iteration:    140, Loss function: 9.681, Average Loss: 1.778, avg. samples / sec: 53304.54
Iteration:    140, Loss function: 10.356, Average Loss: 1.757, avg. samples / sec: 53799.79
Iteration:    140, Loss function: 8.446, Average Loss: 1.777, avg. samples / sec: 53000.69
Iteration:    140, Loss function: 8.148, Average Loss: 1.770, avg. samples / sec: 53363.90
Iteration:    140, Loss function: 9.045, Average Loss: 1.778, avg. samples / sec: 52962.60
Iteration:    140, Loss function: 8.430, Average Loss: 1.773, avg. samples / sec: 53187.51
Iteration:    140, Loss function: 8.360, Average Loss: 1.777, avg. samples / sec: 53154.17
Iteration:    140, Loss function: 8.966, Average Loss: 1.776, avg. samples / sec: 52905.74
Iteration:    140, Loss function: 8.795, Average Loss: 1.784, avg. samples / sec: 53139.70
Iteration:    140, Loss function: 8.955, Average Loss: 1.773, avg. samples / sec: 53175.03
Iteration:    140, Loss function: 8.404, Average Loss: 1.767, avg. samples / sec: 53199.96
Iteration:    140, Loss function: 8.206, Average Loss: 1.764, avg. samples / sec: 53104.44
Iteration:    140, Loss function: 8.505, Average Loss: 1.775, avg. samples / sec: 53120.23
Iteration:    140, Loss function: 8.497, Average Loss: 1.758, avg. samples / sec: 53185.17
Iteration:    140, Loss function: 7.961, Average Loss: 1.792, avg. samples / sec: 53329.41
Iteration:    140, Loss function: 8.921, Average Loss: 1.777, avg. samples / sec: 53891.94
Iteration:    140, Loss function: 8.206, Average Loss: 1.788, avg. samples / sec: 52778.60
Iteration:    140, Loss function: 8.914, Average Loss: 1.775, avg. samples / sec: 52692.26
Iteration:    140, Loss function: 9.390, Average Loss: 1.776, avg. samples / sec: 52560.65
Iteration:    140, Loss function: 8.822, Average Loss: 1.777, avg. samples / sec: 52599.16
Iteration:    140, Loss function: 8.004, Average Loss: 1.773, avg. samples / sec: 52152.17
Iteration:    140, Loss function: 8.920, Average Loss: 1.768, avg. samples / sec: 53085.74
Iteration:    160, Loss function: 9.208, Average Loss: 1.904, avg. samples / sec: 53322.47
Iteration:    160, Loss function: 8.887, Average Loss: 1.914, avg. samples / sec: 53964.21
Iteration:    160, Loss function: 9.155, Average Loss: 1.911, avg. samples / sec: 53156.74
Iteration:    160, Loss function: 9.258, Average Loss: 1.902, avg. samples / sec: 53177.54
Iteration:    160, Loss function: 8.869, Average Loss: 1.896, avg. samples / sec: 53166.20
Iteration:    160, Loss function: 8.447, Average Loss: 1.911, avg. samples / sec: 53215.49
Iteration:    160, Loss function: 8.936, Average Loss: 1.914, avg. samples / sec: 53308.57
Iteration:    160, Loss function: 9.000, Average Loss: 1.931, avg. samples / sec: 53041.28
Iteration:    160, Loss function: 8.928, Average Loss: 1.906, avg. samples / sec: 53079.94
Iteration:    160, Loss function: 9.196, Average Loss: 1.915, avg. samples / sec: 53659.92
Iteration:    160, Loss function: 8.063, Average Loss: 1.898, avg. samples / sec: 53166.73
Iteration:    160, Loss function: 8.968, Average Loss: 1.902, avg. samples / sec: 53324.16
Iteration:    160, Loss function: 8.158, Average Loss: 1.913, avg. samples / sec: 53148.24
Iteration:    160, Loss function: 8.831, Average Loss: 1.910, avg. samples / sec: 53958.88
Iteration:    160, Loss function: 8.160, Average Loss: 1.911, avg. samples / sec: 53054.02
Iteration:    160, Loss function: 9.001, Average Loss: 1.911, avg. samples / sec: 53030.60
Iteration:    160, Loss function: 7.430, Average Loss: 1.908, avg. samples / sec: 54211.74
Iteration:    160, Loss function: 8.954, Average Loss: 1.916, avg. samples / sec: 53667.48
Iteration:    160, Loss function: 8.539, Average Loss: 1.927, avg. samples / sec: 53560.77
Iteration:    160, Loss function: 9.235, Average Loss: 1.913, avg. samples / sec: 53135.83
Iteration:    160, Loss function: 8.690, Average Loss: 1.912, avg. samples / sec: 53108.94
Iteration:    160, Loss function: 9.057, Average Loss: 1.913, avg. samples / sec: 53264.08
Iteration:    160, Loss function: 8.772, Average Loss: 1.911, avg. samples / sec: 53083.12
Iteration:    160, Loss function: 8.289, Average Loss: 1.898, avg. samples / sec: 53218.36
Iteration:    160, Loss function: 8.531, Average Loss: 1.924, avg. samples / sec: 53036.81
Iteration:    160, Loss function: 8.787, Average Loss: 1.910, avg. samples / sec: 52944.80
Iteration:    160, Loss function: 8.435, Average Loss: 1.932, avg. samples / sec: 53161.27
Iteration:    160, Loss function: 8.788, Average Loss: 1.908, avg. samples / sec: 54041.27
Iteration:    160, Loss function: 9.398, Average Loss: 1.906, avg. samples / sec: 52575.46
Iteration:    160, Loss function: 8.986, Average Loss: 1.911, avg. samples / sec: 52360.84
Iteration:    180, Loss function: 7.968, Average Loss: 2.041, avg. samples / sec: 54018.65
Iteration:    180, Loss function: 8.808, Average Loss: 2.068, avg. samples / sec: 53696.15
Iteration:    180, Loss function: 10.001, Average Loss: 2.044, avg. samples / sec: 53663.05
Iteration:    180, Loss function: 8.913, Average Loss: 2.046, avg. samples / sec: 53615.34
Iteration:    180, Loss function: 8.261, Average Loss: 2.049, avg. samples / sec: 53435.20
Iteration:    180, Loss function: 8.206, Average Loss: 2.037, avg. samples / sec: 53522.26
Iteration:    180, Loss function: 8.044, Average Loss: 2.037, avg. samples / sec: 53305.93
Iteration:    180, Loss function: 8.597, Average Loss: 2.034, avg. samples / sec: 53520.05
Iteration:    180, Loss function: 9.017, Average Loss: 2.060, avg. samples / sec: 53664.81
Iteration:    180, Loss function: 8.064, Average Loss: 2.041, avg. samples / sec: 53379.89
Iteration:    180, Loss function: 8.445, Average Loss: 2.038, avg. samples / sec: 53529.22
Iteration:    180, Loss function: 7.970, Average Loss: 2.054, avg. samples / sec: 53755.73
Iteration:    180, Loss function: 8.455, Average Loss: 2.044, avg. samples / sec: 53580.60
Iteration:    180, Loss function: 8.805, Average Loss: 2.029, avg. samples / sec: 53287.22
Iteration:    180, Loss function: 8.436, Average Loss: 2.046, avg. samples / sec: 53466.97
Iteration:    180, Loss function: 9.162, Average Loss: 2.027, avg. samples / sec: 53334.17
Iteration:    180, Loss function: 8.863, Average Loss: 2.047, avg. samples / sec: 53488.79
Iteration:    180, Loss function: 9.016, Average Loss: 2.048, avg. samples / sec: 53303.25
Iteration:    180, Loss function: 9.010, Average Loss: 2.041, avg. samples / sec: 53239.86
Iteration:    180, Loss function: 8.934, Average Loss: 2.045, avg. samples / sec: 53402.34
Iteration:    180, Loss function: 8.613, Average Loss: 2.063, avg. samples / sec: 53605.49
Iteration:    180, Loss function: 8.076, Average Loss: 2.046, avg. samples / sec: 54139.24
Iteration:    180, Loss function: 8.480, Average Loss: 2.038, avg. samples / sec: 53655.69
Iteration:    180, Loss function: 7.661, Average Loss: 2.032, avg. samples / sec: 53439.09
Iteration:    180, Loss function: 8.745, Average Loss: 2.038, avg. samples / sec: 53313.37
Iteration:    180, Loss function: 8.570, Average Loss: 2.046, avg. samples / sec: 53301.92
Iteration:    180, Loss function: 8.492, Average Loss: 2.043, avg. samples / sec: 52422.95
Iteration:    180, Loss function: 7.850, Average Loss: 2.035, avg. samples / sec: 52318.13
Iteration:    180, Loss function: 8.452, Average Loss: 2.037, avg. samples / sec: 52964.18
Iteration:    180, Loss function: 8.668, Average Loss: 2.039, avg. samples / sec: 52276.17
Iteration:    200, Loss function: 8.095, Average Loss: 2.162, avg. samples / sec: 53261.73
Iteration:    200, Loss function: 8.651, Average Loss: 2.164, avg. samples / sec: 53073.48
Iteration:    200, Loss function: 8.582, Average Loss: 2.172, avg. samples / sec: 53224.51
Iteration:    200, Loss function: 8.244, Average Loss: 2.172, avg. samples / sec: 53164.40
Iteration:    200, Loss function: 8.454, Average Loss: 2.160, avg. samples / sec: 53202.67
Iteration:    200, Loss function: 7.948, Average Loss: 2.169, avg. samples / sec: 53021.40
Iteration:    200, Loss function: 8.628, Average Loss: 2.173, avg. samples / sec: 54173.87
Iteration:    200, Loss function: 8.124, Average Loss: 2.158, avg. samples / sec: 52626.03
Iteration:    200, Loss function: 7.792, Average Loss: 2.192, avg. samples / sec: 52817.39
Iteration:    200, Loss function: 8.079, Average Loss: 2.164, avg. samples / sec: 53904.87
Iteration:    200, Loss function: 7.942, Average Loss: 2.193, avg. samples / sec: 52342.75
Iteration:    200, Loss function: 8.815, Average Loss: 2.162, avg. samples / sec: 52787.65
Iteration:    200, Loss function: 7.880, Average Loss: 2.158, avg. samples / sec: 52673.49
Iteration:    200, Loss function: 9.095, Average Loss: 2.158, avg. samples / sec: 53577.24
Iteration:    200, Loss function: 8.028, Average Loss: 2.166, avg. samples / sec: 52461.92
Iteration:    200, Loss function: 7.781, Average Loss: 2.178, avg. samples / sec: 52624.24
Iteration:    200, Loss function: 7.833, Average Loss: 2.166, avg. samples / sec: 52183.90
Iteration:    200, Loss function: 8.522, Average Loss: 2.180, avg. samples / sec: 52407.00
Iteration:    200, Loss function: 8.114, Average Loss: 2.176, avg. samples / sec: 52303.14
Iteration:    200, Loss function: 9.586, Average Loss: 2.172, avg. samples / sec: 53395.72
Iteration:    200, Loss function: 9.430, Average Loss: 2.173, avg. samples / sec: 52274.06
Iteration:    200, Loss function: 8.835, Average Loss: 2.153, avg. samples / sec: 52447.06
Iteration:    200, Loss function: 8.893, Average Loss: 2.173, avg. samples / sec: 52163.02
Iteration:    200, Loss function: 7.487, Average Loss: 2.165, avg. samples / sec: 52425.46
Iteration:    200, Loss function: 8.984, Average Loss: 2.163, avg. samples / sec: 52483.14
Iteration:    200, Loss function: 8.813, Average Loss: 2.171, avg. samples / sec: 52350.84
Iteration:    200, Loss function: 9.016, Average Loss: 2.168, avg. samples / sec: 51985.61
Iteration:    200, Loss function: 8.937, Average Loss: 2.176, avg. samples / sec: 52138.72
Iteration:    200, Loss function: 7.999, Average Loss: 2.168, avg. samples / sec: 51966.44
Iteration:    200, Loss function: 8.306, Average Loss: 2.190, avg. samples / sec: 51646.19
:::MLL 1558640028.209 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558640028.209 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 8.246, Average Loss: 2.281, avg. samples / sec: 52990.06
Iteration:    220, Loss function: 8.741, Average Loss: 2.281, avg. samples / sec: 51697.36
Iteration:    220, Loss function: 8.032, Average Loss: 2.272, avg. samples / sec: 52619.72
Iteration:    220, Loss function: 8.358, Average Loss: 2.284, avg. samples / sec: 51738.36
Iteration:    220, Loss function: 8.443, Average Loss: 2.292, avg. samples / sec: 51821.14
Iteration:    220, Loss function: 8.098, Average Loss: 2.277, avg. samples / sec: 52335.97
Iteration:    220, Loss function: 8.631, Average Loss: 2.298, avg. samples / sec: 52427.69
Iteration:    220, Loss function: 9.054, Average Loss: 2.286, avg. samples / sec: 52345.61
Iteration:    220, Loss function: 7.468, Average Loss: 2.299, avg. samples / sec: 52362.14
Iteration:    220, Loss function: 8.319, Average Loss: 2.288, avg. samples / sec: 52438.87
Iteration:    220, Loss function: 8.104, Average Loss: 2.287, avg. samples / sec: 52800.82
Iteration:    220, Loss function: 8.236, Average Loss: 2.293, avg. samples / sec: 52423.12
Iteration:    220, Loss function: 8.313, Average Loss: 2.279, avg. samples / sec: 52301.53
Iteration:    220, Loss function: 7.876, Average Loss: 2.277, avg. samples / sec: 52079.01
Iteration:    220, Loss function: 7.991, Average Loss: 2.286, avg. samples / sec: 52635.15
Iteration:    220, Loss function: 8.122, Average Loss: 2.309, avg. samples / sec: 52014.33
Iteration:    220, Loss function: 7.875, Average Loss: 2.288, avg. samples / sec: 51639.98
Iteration:    220, Loss function: 7.749, Average Loss: 2.285, avg. samples / sec: 52019.67
Iteration:    220, Loss function: 8.126, Average Loss: 2.286, avg. samples / sec: 52714.85
Iteration:    220, Loss function: 8.588, Average Loss: 2.293, avg. samples / sec: 52318.11
Iteration:    220, Loss function: 8.454, Average Loss: 2.312, avg. samples / sec: 52918.87
Iteration:    220, Loss function: 7.438, Average Loss: 2.275, avg. samples / sec: 51599.03
Iteration:    220, Loss function: 8.793, Average Loss: 2.319, avg. samples / sec: 51925.60
Iteration:    220, Loss function: 7.706, Average Loss: 2.279, avg. samples / sec: 51917.98
Iteration:    220, Loss function: 7.593, Average Loss: 2.289, avg. samples / sec: 51534.24
Iteration:    220, Loss function: 8.363, Average Loss: 2.283, avg. samples / sec: 51608.86
Iteration:    220, Loss function: 8.562, Average Loss: 2.283, avg. samples / sec: 51785.85
Iteration:    220, Loss function: 6.916, Average Loss: 2.292, avg. samples / sec: 51338.39
Iteration:    220, Loss function: 9.730, Average Loss: 2.296, avg. samples / sec: 51763.75
Iteration:    220, Loss function: 7.976, Average Loss: 2.291, avg. samples / sec: 50801.10
Iteration:    240, Loss function: 9.438, Average Loss: 2.402, avg. samples / sec: 53608.40
Iteration:    240, Loss function: 9.545, Average Loss: 2.392, avg. samples / sec: 53461.27
Iteration:    240, Loss function: 8.666, Average Loss: 2.411, avg. samples / sec: 53328.84
Iteration:    240, Loss function: 8.118, Average Loss: 2.397, avg. samples / sec: 53078.50
Iteration:    240, Loss function: 9.135, Average Loss: 2.391, avg. samples / sec: 52915.83
Iteration:    240, Loss function: 9.260, Average Loss: 2.390, avg. samples / sec: 53036.51
Iteration:    240, Loss function: 9.177, Average Loss: 2.391, avg. samples / sec: 52885.23
Iteration:    240, Loss function: 9.036, Average Loss: 2.402, avg. samples / sec: 54301.68
Iteration:    240, Loss function: 8.516, Average Loss: 2.395, avg. samples / sec: 52952.12
Iteration:    240, Loss function: 8.151, Average Loss: 2.422, avg. samples / sec: 53150.02
Iteration:    240, Loss function: 7.551, Average Loss: 2.404, avg. samples / sec: 52969.79
Iteration:    240, Loss function: 8.282, Average Loss: 2.398, avg. samples / sec: 52943.98
Iteration:    240, Loss function: 8.215, Average Loss: 2.388, avg. samples / sec: 53182.52
Iteration:    240, Loss function: 9.189, Average Loss: 2.408, avg. samples / sec: 52783.87
Iteration:    240, Loss function: 9.795, Average Loss: 2.390, avg. samples / sec: 52776.70
Iteration:    240, Loss function: 8.473, Average Loss: 2.428, avg. samples / sec: 53123.14
Iteration:    240, Loss function: 8.994, Average Loss: 2.399, avg. samples / sec: 53595.64
Iteration:    240, Loss function: 8.858, Average Loss: 2.422, avg. samples / sec: 53034.21
Iteration:    240, Loss function: 7.863, Average Loss: 2.400, avg. samples / sec: 53203.52
Iteration:    240, Loss function: 9.104, Average Loss: 2.396, avg. samples / sec: 52417.82
Iteration:    240, Loss function: 8.150, Average Loss: 2.399, avg. samples / sec: 52893.75
Iteration:    240, Loss function: 9.154, Average Loss: 2.393, avg. samples / sec: 53072.58
Iteration:    240, Loss function: 8.488, Average Loss: 2.405, avg. samples / sec: 53888.25
Iteration:    240, Loss function: 9.018, Average Loss: 2.401, avg. samples / sec: 52856.27
Iteration:    240, Loss function: 8.567, Average Loss: 2.408, avg. samples / sec: 52505.49
Iteration:    240, Loss function: 7.895, Average Loss: 2.403, avg. samples / sec: 53484.30
Iteration:    240, Loss function: 8.535, Average Loss: 2.394, avg. samples / sec: 53079.92
Iteration:    240, Loss function: 8.063, Average Loss: 2.411, avg. samples / sec: 52201.60
Iteration:    240, Loss function: 8.119, Average Loss: 2.408, avg. samples / sec: 51917.62
Iteration:    240, Loss function: 8.428, Average Loss: 2.398, avg. samples / sec: 51887.63
Iteration:    260, Loss function: 8.021, Average Loss: 2.526, avg. samples / sec: 50303.05
Iteration:    260, Loss function: 8.191, Average Loss: 2.510, avg. samples / sec: 50792.11
Iteration:    260, Loss function: 7.973, Average Loss: 2.510, avg. samples / sec: 49938.70
Iteration:    260, Loss function: 8.377, Average Loss: 2.523, avg. samples / sec: 50935.05
Iteration:    260, Loss function: 8.469, Average Loss: 2.524, avg. samples / sec: 50681.99
Iteration:    260, Loss function: 7.951, Average Loss: 2.526, avg. samples / sec: 50404.14
Iteration:    260, Loss function: 8.319, Average Loss: 2.526, avg. samples / sec: 49968.61
Iteration:    260, Loss function: 8.016, Average Loss: 2.514, avg. samples / sec: 49926.94
Iteration:    260, Loss function: 8.804, Average Loss: 2.519, avg. samples / sec: 50518.98
Iteration:    260, Loss function: 7.151, Average Loss: 2.510, avg. samples / sec: 49886.85
Iteration:    260, Loss function: 8.016, Average Loss: 2.516, avg. samples / sec: 49802.97
Iteration:    260, Loss function: 8.811, Average Loss: 2.513, avg. samples / sec: 49503.58
Iteration:    260, Loss function: 7.801, Average Loss: 2.505, avg. samples / sec: 49972.84
Iteration:    260, Loss function: 7.666, Average Loss: 2.516, avg. samples / sec: 50012.23
Iteration:    260, Loss function: 7.385, Average Loss: 2.522, avg. samples / sec: 50048.05
Iteration:    260, Loss function: 8.561, Average Loss: 2.521, avg. samples / sec: 50087.22
Iteration:    260, Loss function: 9.018, Average Loss: 2.541, avg. samples / sec: 49975.25
Iteration:    260, Loss function: 8.551, Average Loss: 2.515, avg. samples / sec: 49951.55
Iteration:    260, Loss function: 7.578, Average Loss: 2.519, avg. samples / sec: 49748.61
Iteration:    260, Loss function: 9.249, Average Loss: 2.514, avg. samples / sec: 49999.08
Iteration:    260, Loss function: 7.078, Average Loss: 2.535, avg. samples / sec: 49770.05
Iteration:    260, Loss function: 7.425, Average Loss: 2.519, avg. samples / sec: 49952.60
Iteration:    260, Loss function: 8.205, Average Loss: 2.515, avg. samples / sec: 50939.37
Iteration:    260, Loss function: 7.883, Average Loss: 2.506, avg. samples / sec: 49827.38
Iteration:    260, Loss function: 8.056, Average Loss: 2.519, avg. samples / sec: 49948.47
Iteration:    260, Loss function: 7.362, Average Loss: 2.507, avg. samples / sec: 49691.18
Iteration:    260, Loss function: 7.743, Average Loss: 2.515, avg. samples / sec: 49750.23
Iteration:    260, Loss function: 7.702, Average Loss: 2.531, avg. samples / sec: 49577.63
Iteration:    260, Loss function: 8.389, Average Loss: 2.546, avg. samples / sec: 49414.71
Iteration:    260, Loss function: 7.920, Average Loss: 2.516, avg. samples / sec: 48884.61
:::MLL 1558640030.465 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558640030.466 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 7.489, Average Loss: 2.615, avg. samples / sec: 53498.15
Iteration:    280, Loss function: 8.495, Average Loss: 2.622, avg. samples / sec: 53727.39
Iteration:    280, Loss function: 8.694, Average Loss: 2.615, avg. samples / sec: 53202.19
Iteration:    280, Loss function: 7.935, Average Loss: 2.630, avg. samples / sec: 53183.12
Iteration:    280, Loss function: 7.746, Average Loss: 2.624, avg. samples / sec: 53342.85
Iteration:    280, Loss function: 7.458, Average Loss: 2.629, avg. samples / sec: 53341.64
Iteration:    280, Loss function: 6.877, Average Loss: 2.613, avg. samples / sec: 53464.13
Iteration:    280, Loss function: 7.609, Average Loss: 2.612, avg. samples / sec: 53586.45
Iteration:    280, Loss function: 7.599, Average Loss: 2.614, avg. samples / sec: 53515.58
Iteration:    280, Loss function: 6.865, Average Loss: 2.619, avg. samples / sec: 53374.81
Iteration:    280, Loss function: 8.376, Average Loss: 2.629, avg. samples / sec: 53273.53
Iteration:    280, Loss function: 7.565, Average Loss: 2.610, avg. samples / sec: 53200.58
Iteration:    280, Loss function: 7.681, Average Loss: 2.611, avg. samples / sec: 53290.77
Iteration:    280, Loss function: 7.934, Average Loss: 2.606, avg. samples / sec: 53392.18
Iteration:    280, Loss function: 8.598, Average Loss: 2.617, avg. samples / sec: 53424.85
Iteration:    280, Loss function: 7.999, Average Loss: 2.612, avg. samples / sec: 53506.55
Iteration:    280, Loss function: 8.065, Average Loss: 2.635, avg. samples / sec: 53422.28
Iteration:    280, Loss function: 7.004, Average Loss: 2.616, avg. samples / sec: 53402.89
Iteration:    280, Loss function: 7.929, Average Loss: 2.647, avg. samples / sec: 53364.67
Iteration:    280, Loss function: 7.677, Average Loss: 2.620, avg. samples / sec: 53213.20
Iteration:    280, Loss function: 8.060, Average Loss: 2.622, avg. samples / sec: 53356.69
Iteration:    280, Loss function: 7.393, Average Loss: 2.628, avg. samples / sec: 53149.00
Iteration:    280, Loss function: 7.803, Average Loss: 2.615, avg. samples / sec: 53370.37
Iteration:    280, Loss function: 7.353, Average Loss: 2.618, avg. samples / sec: 53390.38
Iteration:    280, Loss function: 7.965, Average Loss: 2.617, avg. samples / sec: 53266.82
Iteration:    280, Loss function: 7.187, Average Loss: 2.621, avg. samples / sec: 53209.20
Iteration:    280, Loss function: 9.550, Average Loss: 2.611, avg. samples / sec: 53167.43
Iteration:    280, Loss function: 7.084, Average Loss: 2.614, avg. samples / sec: 53505.30
Iteration:    280, Loss function: 8.358, Average Loss: 2.633, avg. samples / sec: 52491.49
Iteration:    280, Loss function: 8.003, Average Loss: 2.650, avg. samples / sec: 52025.03
Iteration:    300, Loss function: 7.603, Average Loss: 2.720, avg. samples / sec: 51376.78
Iteration:    300, Loss function: 7.561, Average Loss: 2.710, avg. samples / sec: 51277.70
Iteration:    300, Loss function: 8.138, Average Loss: 2.710, avg. samples / sec: 51418.99
Iteration:    300, Loss function: 8.603, Average Loss: 2.717, avg. samples / sec: 51391.79
Iteration:    300, Loss function: 7.582, Average Loss: 2.708, avg. samples / sec: 51340.53
Iteration:    300, Loss function: 6.946, Average Loss: 2.708, avg. samples / sec: 51260.39
Iteration:    300, Loss function: 7.027, Average Loss: 2.728, avg. samples / sec: 51263.12
Iteration:    300, Loss function: 7.137, Average Loss: 2.709, avg. samples / sec: 51069.49
Iteration:    300, Loss function: 7.183, Average Loss: 2.728, avg. samples / sec: 51331.92
Iteration:    300, Loss function: 7.308, Average Loss: 2.703, avg. samples / sec: 51279.01
Iteration:    300, Loss function: 6.941, Average Loss: 2.716, avg. samples / sec: 51204.97
Iteration:    300, Loss function: 7.202, Average Loss: 2.710, avg. samples / sec: 51320.63
Iteration:    300, Loss function: 7.515, Average Loss: 2.709, avg. samples / sec: 51157.83
Iteration:    300, Loss function: 7.352, Average Loss: 2.726, avg. samples / sec: 51066.61
Iteration:    300, Loss function: 7.038, Average Loss: 2.728, avg. samples / sec: 52229.07
Iteration:    300, Loss function: 6.746, Average Loss: 2.713, avg. samples / sec: 51230.26
Iteration:    300, Loss function: 7.791, Average Loss: 2.715, avg. samples / sec: 51260.54
Iteration:    300, Loss function: 6.805, Average Loss: 2.708, avg. samples / sec: 51661.26
Iteration:    300, Loss function: 7.818, Average Loss: 2.707, avg. samples / sec: 51083.38
Iteration:    300, Loss function: 6.573, Average Loss: 2.719, avg. samples / sec: 50889.74
Iteration:    300, Loss function: 7.750, Average Loss: 2.745, avg. samples / sec: 51133.14
Iteration:    300, Loss function: 8.118, Average Loss: 2.717, avg. samples / sec: 51274.68
Iteration:    300, Loss function: 7.698, Average Loss: 2.710, avg. samples / sec: 51379.66
Iteration:    300, Loss function: 7.008, Average Loss: 2.719, avg. samples / sec: 51116.82
Iteration:    300, Loss function: 7.326, Average Loss: 2.747, avg. samples / sec: 53003.38
Iteration:    300, Loss function: 7.748, Average Loss: 2.708, avg. samples / sec: 51111.48
Iteration:    300, Loss function: 7.621, Average Loss: 2.724, avg. samples / sec: 50889.76
Iteration:    300, Loss function: 5.921, Average Loss: 2.725, avg. samples / sec: 50588.80
Iteration:    300, Loss function: 7.760, Average Loss: 2.714, avg. samples / sec: 50755.20
Iteration:    300, Loss function: 8.072, Average Loss: 2.709, avg. samples / sec: 50360.50
Iteration:    320, Loss function: 7.125, Average Loss: 2.812, avg. samples / sec: 53462.08
Iteration:    320, Loss function: 8.994, Average Loss: 2.819, avg. samples / sec: 53719.26
Iteration:    320, Loss function: 6.119, Average Loss: 2.801, avg. samples / sec: 53646.26
Iteration:    320, Loss function: 6.637, Average Loss: 2.800, avg. samples / sec: 53652.37
Iteration:    320, Loss function: 7.623, Average Loss: 2.814, avg. samples / sec: 54118.45
Iteration:    320, Loss function: 7.107, Average Loss: 2.799, avg. samples / sec: 53524.44
Iteration:    320, Loss function: 7.171, Average Loss: 2.810, avg. samples / sec: 53618.26
Iteration:    320, Loss function: 6.907, Average Loss: 2.796, avg. samples / sec: 53457.70
Iteration:    320, Loss function: 7.913, Average Loss: 2.797, avg. samples / sec: 53518.18
Iteration:    320, Loss function: 7.522, Average Loss: 2.816, avg. samples / sec: 53639.83
Iteration:    320, Loss function: 7.909, Average Loss: 2.813, avg. samples / sec: 54226.99
Iteration:    320, Loss function: 7.343, Average Loss: 2.798, avg. samples / sec: 53537.25
Iteration:    320, Loss function: 7.998, Average Loss: 2.834, avg. samples / sec: 53756.97
Iteration:    320, Loss function: 7.416, Average Loss: 2.821, avg. samples / sec: 53485.56
Iteration:    320, Loss function: 7.075, Average Loss: 2.799, avg. samples / sec: 54421.38
Iteration:    320, Loss function: 7.027, Average Loss: 2.814, avg. samples / sec: 53652.73
Iteration:    320, Loss function: 7.781, Average Loss: 2.800, avg. samples / sec: 53397.50
Iteration:    320, Loss function: 6.446, Average Loss: 2.799, avg. samples / sec: 53524.52
Iteration:    320, Loss function: 7.250, Average Loss: 2.798, avg. samples / sec: 53473.18
Iteration:    320, Loss function: 6.912, Average Loss: 2.803, avg. samples / sec: 53459.00
Iteration:    320, Loss function: 8.052, Average Loss: 2.806, avg. samples / sec: 53571.13
Iteration:    320, Loss function: 5.952, Average Loss: 2.803, avg. samples / sec: 54134.48
Iteration:    320, Loss function: 7.195, Average Loss: 2.809, avg. samples / sec: 53564.78
Iteration:    320, Loss function: 6.243, Average Loss: 2.801, avg. samples / sec: 53521.51
Iteration:    320, Loss function: 7.131, Average Loss: 2.799, avg. samples / sec: 53411.75
Iteration:    320, Loss function: 7.904, Average Loss: 2.800, avg. samples / sec: 53011.63
Iteration:    320, Loss function: 8.060, Average Loss: 2.818, avg. samples / sec: 52968.79
Iteration:    320, Loss function: 8.153, Average Loss: 2.805, avg. samples / sec: 52587.40
Iteration:    320, Loss function: 6.711, Average Loss: 2.798, avg. samples / sec: 52790.02
Iteration:    320, Loss function: 7.686, Average Loss: 2.838, avg. samples / sec: 52519.28
Iteration:    340, Loss function: 6.918, Average Loss: 2.887, avg. samples / sec: 54304.30
Iteration:    340, Loss function: 8.118, Average Loss: 2.901, avg. samples / sec: 53181.25
Iteration:    340, Loss function: 6.295, Average Loss: 2.885, avg. samples / sec: 53243.05
Iteration:    340, Loss function: 7.067, Average Loss: 2.880, avg. samples / sec: 53217.22
Iteration:    340, Loss function: 7.334, Average Loss: 2.884, avg. samples / sec: 53147.42
Iteration:    340, Loss function: 5.576, Average Loss: 2.900, avg. samples / sec: 53322.73
Iteration:    340, Loss function: 7.436, Average Loss: 2.886, avg. samples / sec: 53212.96
Iteration:    340, Loss function: 6.902, Average Loss: 2.885, avg. samples / sec: 53525.27
Iteration:    340, Loss function: 6.703, Average Loss: 2.885, avg. samples / sec: 53108.30
Iteration:    340, Loss function: 7.128, Average Loss: 2.899, avg. samples / sec: 53107.84
Iteration:    340, Loss function: 6.383, Average Loss: 2.903, avg. samples / sec: 53729.83
Iteration:    340, Loss function: 6.934, Average Loss: 2.896, avg. samples / sec: 53144.93
Iteration:    340, Loss function: 7.028, Average Loss: 2.893, avg. samples / sec: 53360.08
Iteration:    340, Loss function: 7.195, Average Loss: 2.905, avg. samples / sec: 53026.97
Iteration:    340, Loss function: 7.945, Average Loss: 2.884, avg. samples / sec: 53354.44
Iteration:    340, Loss function: 7.506, Average Loss: 2.888, avg. samples / sec: 53114.21
Iteration:    340, Loss function: 8.196, Average Loss: 2.886, avg. samples / sec: 53150.42
Iteration:    340, Loss function: 8.319, Average Loss: 2.890, avg. samples / sec: 53172.62
Iteration:    340, Loss function: 7.061, Average Loss: 2.910, avg. samples / sec: 53019.07
Iteration:    340, Loss function: 7.166, Average Loss: 2.896, avg. samples / sec: 53192.53
Iteration:    340, Loss function: 7.347, Average Loss: 2.888, avg. samples / sec: 53151.89
Iteration:    340, Loss function: 7.540, Average Loss: 2.889, avg. samples / sec: 53988.05
Iteration:    340, Loss function: 7.743, Average Loss: 2.913, avg. samples / sec: 52967.90
Iteration:    340, Loss function: 7.578, Average Loss: 2.889, avg. samples / sec: 53278.14
Iteration:    340, Loss function: 8.595, Average Loss: 2.900, avg. samples / sec: 52888.92
Iteration:    340, Loss function: 6.740, Average Loss: 2.881, avg. samples / sec: 53040.84
Iteration:    340, Loss function: 8.775, Average Loss: 2.889, avg. samples / sec: 52698.88
Iteration:    340, Loss function: 6.135, Average Loss: 2.896, avg. samples / sec: 52216.30
Iteration:    340, Loss function: 6.636, Average Loss: 2.888, avg. samples / sec: 52420.36
Iteration:    340, Loss function: 7.688, Average Loss: 2.927, avg. samples / sec: 52233.95
:::MLL 1558640032.709 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558640032.710 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 7.937, Average Loss: 2.992, avg. samples / sec: 52617.64
Iteration:    360, Loss function: 6.600, Average Loss: 2.988, avg. samples / sec: 52403.22
Iteration:    360, Loss function: 6.782, Average Loss: 2.976, avg. samples / sec: 52409.85
Iteration:    360, Loss function: 8.187, Average Loss: 2.974, avg. samples / sec: 53373.38
Iteration:    360, Loss function: 7.236, Average Loss: 2.975, avg. samples / sec: 52175.96
Iteration:    360, Loss function: 5.826, Average Loss: 2.976, avg. samples / sec: 52855.24
Iteration:    360, Loss function: 7.389, Average Loss: 2.977, avg. samples / sec: 52297.43
Iteration:    360, Loss function: 5.891, Average Loss: 2.969, avg. samples / sec: 52590.78
Iteration:    360, Loss function: 7.582, Average Loss: 2.981, avg. samples / sec: 53310.71
Iteration:    360, Loss function: 7.179, Average Loss: 2.964, avg. samples / sec: 52386.26
Iteration:    360, Loss function: 4.660, Average Loss: 2.972, avg. samples / sec: 52597.73
Iteration:    360, Loss function: 7.028, Average Loss: 2.982, avg. samples / sec: 52379.40
Iteration:    360, Loss function: 6.859, Average Loss: 2.986, avg. samples / sec: 52362.57
Iteration:    360, Loss function: 5.768, Average Loss: 2.987, avg. samples / sec: 52386.37
Iteration:    360, Loss function: 6.018, Average Loss: 2.976, avg. samples / sec: 52295.26
Iteration:    360, Loss function: 7.166, Average Loss: 2.964, avg. samples / sec: 52214.75
Iteration:    360, Loss function: 6.081, Average Loss: 2.966, avg. samples / sec: 52607.31
Iteration:    360, Loss function: 7.207, Average Loss: 2.980, avg. samples / sec: 52221.47
Iteration:    360, Loss function: 6.618, Average Loss: 3.016, avg. samples / sec: 54460.87
Iteration:    360, Loss function: 7.654, Average Loss: 2.978, avg. samples / sec: 52411.00
Iteration:    360, Loss function: 7.082, Average Loss: 2.999, avg. samples / sec: 52386.47
Iteration:    360, Loss function: 7.444, Average Loss: 2.999, avg. samples / sec: 52397.55
Iteration:    360, Loss function: 6.679, Average Loss: 2.977, avg. samples / sec: 52365.56
Iteration:    360, Loss function: 6.861, Average Loss: 2.976, avg. samples / sec: 52374.69
Iteration:    360, Loss function: 7.012, Average Loss: 2.979, avg. samples / sec: 52326.52
Iteration:    360, Loss function: 7.557, Average Loss: 2.976, avg. samples / sec: 52396.25
Iteration:    360, Loss function: 7.549, Average Loss: 2.971, avg. samples / sec: 52178.47
Iteration:    360, Loss function: 6.745, Average Loss: 2.986, avg. samples / sec: 51746.62
Iteration:    360, Loss function: 7.815, Average Loss: 2.989, avg. samples / sec: 52010.20
Iteration:    360, Loss function: 7.991, Average Loss: 2.975, avg. samples / sec: 51712.82
Iteration:    380, Loss function: 6.681, Average Loss: 3.054, avg. samples / sec: 54242.60
Iteration:    380, Loss function: 6.603, Average Loss: 3.057, avg. samples / sec: 53869.08
Iteration:    380, Loss function: 6.319, Average Loss: 3.058, avg. samples / sec: 54139.10
Iteration:    380, Loss function: 6.547, Average Loss: 3.054, avg. samples / sec: 54058.46
Iteration:    380, Loss function: 6.475, Average Loss: 3.079, avg. samples / sec: 54033.42
Iteration:    380, Loss function: 5.772, Average Loss: 3.066, avg. samples / sec: 53739.34
Iteration:    380, Loss function: 6.432, Average Loss: 3.067, avg. samples / sec: 53506.11
Iteration:    380, Loss function: 6.889, Average Loss: 3.057, avg. samples / sec: 54373.88
Iteration:    380, Loss function: 6.798, Average Loss: 3.066, avg. samples / sec: 54243.27
Iteration:    380, Loss function: 7.100, Average Loss: 3.056, avg. samples / sec: 53825.73
Iteration:    380, Loss function: 6.003, Average Loss: 3.056, avg. samples / sec: 53570.30
Iteration:    380, Loss function: 6.561, Average Loss: 3.041, avg. samples / sec: 53617.56
Iteration:    380, Loss function: 6.338, Average Loss: 3.049, avg. samples / sec: 53796.45
Iteration:    380, Loss function: 7.218, Average Loss: 3.059, avg. samples / sec: 53461.31
Iteration:    380, Loss function: 6.434, Average Loss: 3.077, avg. samples / sec: 53678.83
Iteration:    380, Loss function: 6.754, Average Loss: 3.061, avg. samples / sec: 53601.02
Iteration:    380, Loss function: 6.968, Average Loss: 3.043, avg. samples / sec: 53334.58
Iteration:    380, Loss function: 8.043, Average Loss: 3.041, avg. samples / sec: 53352.59
Iteration:    380, Loss function: 6.971, Average Loss: 3.057, avg. samples / sec: 53296.07
Iteration:    380, Loss function: 6.932, Average Loss: 3.051, avg. samples / sec: 53389.84
Iteration:    380, Loss function: 6.089, Average Loss: 3.052, avg. samples / sec: 53287.59
Iteration:    380, Loss function: 6.190, Average Loss: 3.067, avg. samples / sec: 53031.16
Iteration:    380, Loss function: 6.744, Average Loss: 3.065, avg. samples / sec: 53817.98
Iteration:    380, Loss function: 6.361, Average Loss: 3.064, avg. samples / sec: 53178.56
Iteration:    380, Loss function: 6.894, Average Loss: 3.055, avg. samples / sec: 53015.38
Iteration:    380, Loss function: 6.665, Average Loss: 3.055, avg. samples / sec: 53232.09
Iteration:    380, Loss function: 7.586, Average Loss: 3.058, avg. samples / sec: 52960.73
Iteration:    380, Loss function: 6.218, Average Loss: 3.056, avg. samples / sec: 52966.92
Iteration:    380, Loss function: 6.186, Average Loss: 3.055, avg. samples / sec: 52638.67
Iteration:    380, Loss function: 6.318, Average Loss: 3.095, avg. samples / sec: 52767.29
Iteration:    400, Loss function: 8.400, Average Loss: 3.130, avg. samples / sec: 53127.40
Iteration:    400, Loss function: 7.449, Average Loss: 3.133, avg. samples / sec: 53516.13
Iteration:    400, Loss function: 5.804, Average Loss: 3.112, avg. samples / sec: 53317.50
Iteration:    400, Loss function: 7.362, Average Loss: 3.139, avg. samples / sec: 53569.63
Iteration:    400, Loss function: 6.702, Average Loss: 3.116, avg. samples / sec: 53394.13
Iteration:    400, Loss function: 7.560, Average Loss: 3.130, avg. samples / sec: 53669.10
Iteration:    400, Loss function: 6.942, Average Loss: 3.173, avg. samples / sec: 54191.68
Iteration:    400, Loss function: 6.434, Average Loss: 3.142, avg. samples / sec: 53586.74
Iteration:    400, Loss function: 5.487, Average Loss: 3.131, avg. samples / sec: 53742.37
Iteration:    400, Loss function: 8.143, Average Loss: 3.135, avg. samples / sec: 52900.56
Iteration:    400, Loss function: 7.723, Average Loss: 3.144, avg. samples / sec: 53019.53
Iteration:    400, Loss function: 7.168, Average Loss: 3.139, avg. samples / sec: 53037.15
Iteration:    400, Loss function: 6.756, Average Loss: 3.141, avg. samples / sec: 53514.01
Iteration:    400, Loss function: 7.263, Average Loss: 3.139, avg. samples / sec: 53246.64
Iteration:    400, Loss function: 7.117, Average Loss: 3.135, avg. samples / sec: 53093.90
Iteration:    400, Loss function: 7.202, Average Loss: 3.134, avg. samples / sec: 53148.70
Iteration:    400, Loss function: 7.649, Average Loss: 3.146, avg. samples / sec: 52903.57
Iteration:    400, Loss function: 7.884, Average Loss: 3.131, avg. samples / sec: 53893.49
Iteration:    400, Loss function: 6.911, Average Loss: 3.118, avg. samples / sec: 53161.67
Iteration:    400, Loss function: 6.952, Average Loss: 3.130, avg. samples / sec: 52897.68
Iteration:    400, Loss function: 7.239, Average Loss: 3.151, avg. samples / sec: 52686.25
Iteration:    400, Loss function: 7.267, Average Loss: 3.139, avg. samples / sec: 52882.75
Iteration:    400, Loss function: 6.227, Average Loss: 3.132, avg. samples / sec: 52588.54
Iteration:    400, Loss function: 6.086, Average Loss: 3.129, avg. samples / sec: 53444.40
Iteration:    400, Loss function: 7.033, Average Loss: 3.154, avg. samples / sec: 52996.92
Iteration:    400, Loss function: 8.042, Average Loss: 3.130, avg. samples / sec: 53178.68
Iteration:    400, Loss function: 6.249, Average Loss: 3.123, avg. samples / sec: 52910.96
Iteration:    400, Loss function: 7.715, Average Loss: 3.130, avg. samples / sec: 53468.19
Iteration:    400, Loss function: 7.903, Average Loss: 3.124, avg. samples / sec: 53043.68
Iteration:    400, Loss function: 6.562, Average Loss: 3.137, avg. samples / sec: 51868.21
:::MLL 1558640034.944 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558640034.944 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 8.047, Average Loss: 3.208, avg. samples / sec: 50971.50
Iteration:    420, Loss function: 6.215, Average Loss: 3.217, avg. samples / sec: 50987.47
Iteration:    420, Loss function: 6.374, Average Loss: 3.213, avg. samples / sec: 50983.08
Iteration:    420, Loss function: 5.618, Average Loss: 3.208, avg. samples / sec: 50769.24
Iteration:    420, Loss function: 6.807, Average Loss: 3.213, avg. samples / sec: 50908.86
Iteration:    420, Loss function: 6.377, Average Loss: 3.188, avg. samples / sec: 50762.71
Iteration:    420, Loss function: 7.967, Average Loss: 3.190, avg. samples / sec: 50845.79
Iteration:    420, Loss function: 6.567, Average Loss: 3.210, avg. samples / sec: 50939.08
Iteration:    420, Loss function: 7.243, Average Loss: 3.192, avg. samples / sec: 51024.69
Iteration:    420, Loss function: 7.264, Average Loss: 3.214, avg. samples / sec: 50733.84
Iteration:    420, Loss function: 6.268, Average Loss: 3.209, avg. samples / sec: 51085.60
Iteration:    420, Loss function: 6.616, Average Loss: 3.217, avg. samples / sec: 50771.44
Iteration:    420, Loss function: 6.632, Average Loss: 3.222, avg. samples / sec: 50873.47
Iteration:    420, Loss function: 6.822, Average Loss: 3.216, avg. samples / sec: 50793.76
Iteration:    420, Loss function: 6.187, Average Loss: 3.225, avg. samples / sec: 50978.46
Iteration:    420, Loss function: 7.554, Average Loss: 3.204, avg. samples / sec: 50709.71
Iteration:    420, Loss function: 5.650, Average Loss: 3.254, avg. samples / sec: 50691.36
Iteration:    420, Loss function: 6.742, Average Loss: 3.233, avg. samples / sec: 50948.60
Iteration:    420, Loss function: 5.529, Average Loss: 3.205, avg. samples / sec: 50866.09
Iteration:    420, Loss function: 6.843, Average Loss: 3.212, avg. samples / sec: 51539.76
Iteration:    420, Loss function: 6.623, Average Loss: 3.203, avg. samples / sec: 50886.62
Iteration:    420, Loss function: 6.248, Average Loss: 3.207, avg. samples / sec: 50856.40
Iteration:    420, Loss function: 7.001, Average Loss: 3.206, avg. samples / sec: 50603.35
Iteration:    420, Loss function: 6.003, Average Loss: 3.213, avg. samples / sec: 50622.06
Iteration:    420, Loss function: 7.247, Average Loss: 3.202, avg. samples / sec: 50761.20
Iteration:    420, Loss function: 6.830, Average Loss: 3.198, avg. samples / sec: 50818.27
Iteration:    420, Loss function: 5.506, Average Loss: 3.215, avg. samples / sec: 50735.56
Iteration:    420, Loss function: 7.201, Average Loss: 3.201, avg. samples / sec: 50869.32
Iteration:    420, Loss function: 7.678, Average Loss: 3.202, avg. samples / sec: 50719.89
Iteration:    420, Loss function: 6.484, Average Loss: 3.207, avg. samples / sec: 50083.70
Iteration:    440, Loss function: 7.374, Average Loss: 3.280, avg. samples / sec: 53173.16
Iteration:    440, Loss function: 7.233, Average Loss: 3.275, avg. samples / sec: 53023.32
Iteration:    440, Loss function: 6.519, Average Loss: 3.288, avg. samples / sec: 53120.97
Iteration:    440, Loss function: 6.345, Average Loss: 3.284, avg. samples / sec: 53004.39
Iteration:    440, Loss function: 4.597, Average Loss: 3.275, avg. samples / sec: 53463.40
Iteration:    440, Loss function: 6.947, Average Loss: 3.279, avg. samples / sec: 53064.21
Iteration:    440, Loss function: 7.888, Average Loss: 3.271, avg. samples / sec: 53112.48
Iteration:    440, Loss function: 6.376, Average Loss: 3.286, avg. samples / sec: 52932.41
Iteration:    440, Loss function: 6.379, Average Loss: 3.289, avg. samples / sec: 52984.69
Iteration:    440, Loss function: 5.870, Average Loss: 3.255, avg. samples / sec: 52925.93
Iteration:    440, Loss function: 5.646, Average Loss: 3.280, avg. samples / sec: 52868.49
Iteration:    440, Loss function: 6.418, Average Loss: 3.297, avg. samples / sec: 53024.98
Iteration:    440, Loss function: 5.642, Average Loss: 3.285, avg. samples / sec: 52967.64
Iteration:    440, Loss function: 5.695, Average Loss: 3.291, avg. samples / sec: 52722.76
Iteration:    440, Loss function: 6.053, Average Loss: 3.272, avg. samples / sec: 52920.24
Iteration:    440, Loss function: 7.089, Average Loss: 3.256, avg. samples / sec: 52773.48
Iteration:    440, Loss function: 7.772, Average Loss: 3.298, avg. samples / sec: 52842.32
Iteration:    440, Loss function: 5.246, Average Loss: 3.267, avg. samples / sec: 53104.56
Iteration:    440, Loss function: 6.307, Average Loss: 3.280, avg. samples / sec: 53040.74
Iteration:    440, Loss function: 6.310, Average Loss: 3.282, avg. samples / sec: 52950.35
Iteration:    440, Loss function: 7.073, Average Loss: 3.279, avg. samples / sec: 53074.40
Iteration:    440, Loss function: 6.842, Average Loss: 3.303, avg. samples / sec: 52875.31
Iteration:    440, Loss function: 5.955, Average Loss: 3.273, avg. samples / sec: 53000.21
Iteration:    440, Loss function: 5.678, Average Loss: 3.325, avg. samples / sec: 52863.33
Iteration:    440, Loss function: 6.053, Average Loss: 3.277, avg. samples / sec: 52932.07
Iteration:    440, Loss function: 6.599, Average Loss: 3.277, avg. samples / sec: 52918.99
Iteration:    440, Loss function: 6.583, Average Loss: 3.256, avg. samples / sec: 52573.89
Iteration:    440, Loss function: 6.204, Average Loss: 3.279, avg. samples / sec: 52922.55
Iteration:    440, Loss function: 6.459, Average Loss: 3.263, avg. samples / sec: 52864.34
Iteration:    440, Loss function: 6.353, Average Loss: 3.271, avg. samples / sec: 52785.99
Iteration:    460, Loss function: 5.994, Average Loss: 3.343, avg. samples / sec: 53847.03
Iteration:    460, Loss function: 6.387, Average Loss: 3.329, avg. samples / sec: 54521.17
Iteration:    460, Loss function: 6.175, Average Loss: 3.348, avg. samples / sec: 53730.98
Iteration:    460, Loss function: 7.999, Average Loss: 3.320, avg. samples / sec: 54380.38
Iteration:    460, Loss function: 5.865, Average Loss: 3.368, avg. samples / sec: 54180.87
Iteration:    460, Loss function: 5.947, Average Loss: 3.351, avg. samples / sec: 53922.32
Iteration:    460, Loss function: 6.290, Average Loss: 3.337, avg. samples / sec: 53891.04
Iteration:    460, Loss function: 6.543, Average Loss: 3.339, avg. samples / sec: 54120.22
Iteration:    460, Loss function: 6.161, Average Loss: 3.323, avg. samples / sec: 53877.93
Iteration:    460, Loss function: 7.155, Average Loss: 3.353, avg. samples / sec: 53815.33
Iteration:    460, Loss function: 6.266, Average Loss: 3.358, avg. samples / sec: 53875.30
Iteration:    460, Loss function: 6.573, Average Loss: 3.352, avg. samples / sec: 53821.51
Iteration:    460, Loss function: 6.684, Average Loss: 3.346, avg. samples / sec: 53807.68
Iteration:    460, Loss function: 5.556, Average Loss: 3.350, avg. samples / sec: 53736.18
Iteration:    460, Loss function: 6.284, Average Loss: 3.352, avg. samples / sec: 53896.11
Iteration:    460, Loss function: 5.216, Average Loss: 3.340, avg. samples / sec: 54029.71
Iteration:    460, Loss function: 5.429, Average Loss: 3.335, avg. samples / sec: 53912.04
Iteration:    460, Loss function: 6.950, Average Loss: 3.317, avg. samples / sec: 53899.86
Iteration:    460, Loss function: 7.835, Average Loss: 3.340, avg. samples / sec: 53921.22
Iteration:    460, Loss function: 6.587, Average Loss: 3.362, avg. samples / sec: 53823.46
Iteration:    460, Loss function: 6.190, Average Loss: 3.333, avg. samples / sec: 54217.66
Iteration:    460, Loss function: 6.612, Average Loss: 3.346, avg. samples / sec: 54052.94
Iteration:    460, Loss function: 6.030, Average Loss: 3.346, avg. samples / sec: 53879.52
Iteration:    460, Loss function: 6.224, Average Loss: 3.339, avg. samples / sec: 53888.91
Iteration:    460, Loss function: 6.914, Average Loss: 3.390, avg. samples / sec: 53870.87
Iteration:    460, Loss function: 7.031, Average Loss: 3.348, avg. samples / sec: 53838.08
Iteration:    460, Loss function: 6.401, Average Loss: 3.339, avg. samples / sec: 53536.80
Iteration:    460, Loss function: 7.432, Average Loss: 3.350, avg. samples / sec: 53805.71
Iteration:    460, Loss function: 6.165, Average Loss: 3.361, avg. samples / sec: 53404.83
Iteration:    460, Loss function: 5.613, Average Loss: 3.345, avg. samples / sec: 52959.96
Iteration:    480, Loss function: 7.036, Average Loss: 3.406, avg. samples / sec: 52289.01
Iteration:    480, Loss function: 6.742, Average Loss: 3.419, avg. samples / sec: 52338.80
Iteration:    480, Loss function: 6.802, Average Loss: 3.413, avg. samples / sec: 52152.40
Iteration:    480, Loss function: 7.289, Average Loss: 3.382, avg. samples / sec: 52201.76
Iteration:    480, Loss function: 6.832, Average Loss: 3.401, avg. samples / sec: 52432.37
Iteration:    480, Loss function: 6.457, Average Loss: 3.451, avg. samples / sec: 52477.71
Iteration:    480, Loss function: 7.068, Average Loss: 3.413, avg. samples / sec: 52245.57
Iteration:    480, Loss function: 8.703, Average Loss: 3.388, avg. samples / sec: 52217.06
Iteration:    480, Loss function: 6.900, Average Loss: 3.405, avg. samples / sec: 52175.18
Iteration:    480, Loss function: 6.143, Average Loss: 3.432, avg. samples / sec: 52144.53
Iteration:    480, Loss function: 5.279, Average Loss: 3.415, avg. samples / sec: 52176.90
Iteration:    480, Loss function: 6.177, Average Loss: 3.392, avg. samples / sec: 52315.64
Iteration:    480, Loss function: 6.125, Average Loss: 3.401, avg. samples / sec: 52424.31
Iteration:    480, Loss function: 5.558, Average Loss: 3.407, avg. samples / sec: 53045.17
Iteration:    480, Loss function: 6.703, Average Loss: 3.416, avg. samples / sec: 52165.59
Iteration:    480, Loss function: 6.015, Average Loss: 3.419, avg. samples / sec: 52122.98
Iteration:    480, Loss function: 6.458, Average Loss: 3.379, avg. samples / sec: 52217.68
Iteration:    480, Loss function: 6.460, Average Loss: 3.393, avg. samples / sec: 52234.22
Iteration:    480, Loss function: 6.353, Average Loss: 3.415, avg. samples / sec: 52270.05
Iteration:    480, Loss function: 6.552, Average Loss: 3.426, avg. samples / sec: 52196.56
Iteration:    480, Loss function: 7.055, Average Loss: 3.424, avg. samples / sec: 52641.78
Iteration:    480, Loss function: 6.520, Average Loss: 3.404, avg. samples / sec: 52223.27
Iteration:    480, Loss function: 5.952, Average Loss: 3.407, avg. samples / sec: 51958.22
Iteration:    480, Loss function: 6.091, Average Loss: 3.402, avg. samples / sec: 52067.72
Iteration:    480, Loss function: 6.693, Average Loss: 3.408, avg. samples / sec: 52168.00
Iteration:    480, Loss function: 5.836, Average Loss: 3.411, avg. samples / sec: 52219.80
Iteration:    480, Loss function: 5.858, Average Loss: 3.396, avg. samples / sec: 51714.08
Iteration:    480, Loss function: 6.352, Average Loss: 3.412, avg. samples / sec: 51731.86
Iteration:    480, Loss function: 6.557, Average Loss: 3.415, avg. samples / sec: 51424.87
Iteration:    480, Loss function: 7.631, Average Loss: 3.407, avg. samples / sec: 51584.32
:::MLL 1558640037.158 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558640037.158 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 6.687, Average Loss: 3.467, avg. samples / sec: 53639.40
Iteration:    500, Loss function: 6.616, Average Loss: 3.457, avg. samples / sec: 53817.13
Iteration:    500, Loss function: 5.999, Average Loss: 3.439, avg. samples / sec: 53667.22
Iteration:    500, Loss function: 6.289, Average Loss: 3.478, avg. samples / sec: 53596.48
Iteration:    500, Loss function: 6.456, Average Loss: 3.442, avg. samples / sec: 53888.95
Iteration:    500, Loss function: 7.312, Average Loss: 3.475, avg. samples / sec: 53757.21
Iteration:    500, Loss function: 5.654, Average Loss: 3.475, avg. samples / sec: 54590.06
Iteration:    500, Loss function: 5.305, Average Loss: 3.467, avg. samples / sec: 53675.74
Iteration:    500, Loss function: 6.664, Average Loss: 3.480, avg. samples / sec: 53480.54
Iteration:    500, Loss function: 5.338, Average Loss: 3.472, avg. samples / sec: 53645.52
Iteration:    500, Loss function: 5.633, Average Loss: 3.493, avg. samples / sec: 53662.91
Iteration:    500, Loss function: 7.103, Average Loss: 3.477, avg. samples / sec: 54198.02
Iteration:    500, Loss function: 6.816, Average Loss: 3.479, avg. samples / sec: 53755.61
Iteration:    500, Loss function: 6.285, Average Loss: 3.468, avg. samples / sec: 53697.99
Iteration:    500, Loss function: 6.323, Average Loss: 3.458, avg. samples / sec: 53678.97
Iteration:    500, Loss function: 6.499, Average Loss: 3.462, avg. samples / sec: 53496.87
Iteration:    500, Loss function: 6.573, Average Loss: 3.488, avg. samples / sec: 53712.38
Iteration:    500, Loss function: 5.396, Average Loss: 3.469, avg. samples / sec: 53718.79
Iteration:    500, Loss function: 6.041, Average Loss: 3.468, avg. samples / sec: 53718.34
Iteration:    500, Loss function: 7.606, Average Loss: 3.453, avg. samples / sec: 53496.22
Iteration:    500, Loss function: 6.541, Average Loss: 3.465, avg. samples / sec: 53732.27
Iteration:    500, Loss function: 7.146, Average Loss: 3.458, avg. samples / sec: 53637.09
Iteration:    500, Loss function: 6.435, Average Loss: 3.468, avg. samples / sec: 54349.07
Iteration:    500, Loss function: 6.002, Average Loss: 3.466, avg. samples / sec: 53677.34
Iteration:    500, Loss function: 6.722, Average Loss: 3.465, avg. samples / sec: 53703.21
Iteration:    500, Loss function: 5.685, Average Loss: 3.512, avg. samples / sec: 53403.78
Iteration:    500, Loss function: 6.193, Average Loss: 3.486, avg. samples / sec: 53656.00
Iteration:    500, Loss function: 5.592, Average Loss: 3.475, avg. samples / sec: 53616.20
Iteration:    500, Loss function: 6.573, Average Loss: 3.457, avg. samples / sec: 53737.76
Iteration:    500, Loss function: 6.568, Average Loss: 3.482, avg. samples / sec: 52870.91
Iteration:    520, Loss function: 6.663, Average Loss: 3.524, avg. samples / sec: 53042.80
Iteration:    520, Loss function: 6.298, Average Loss: 3.532, avg. samples / sec: 53043.24
Iteration:    520, Loss function: 5.536, Average Loss: 3.536, avg. samples / sec: 53015.58
Iteration:    520, Loss function: 6.421, Average Loss: 3.523, avg. samples / sec: 53089.64
Iteration:    520, Loss function: 6.003, Average Loss: 3.547, avg. samples / sec: 53062.65
Iteration:    520, Loss function: 6.901, Average Loss: 3.517, avg. samples / sec: 52885.77
Iteration:    520, Loss function: 6.730, Average Loss: 3.496, avg. samples / sec: 52920.36
Iteration:    520, Loss function: 7.549, Average Loss: 3.526, avg. samples / sec: 53042.38
Iteration:    520, Loss function: 6.558, Average Loss: 3.527, avg. samples / sec: 53005.53
Iteration:    520, Loss function: 6.296, Average Loss: 3.541, avg. samples / sec: 53930.71
Iteration:    520, Loss function: 6.437, Average Loss: 3.529, avg. samples / sec: 52984.98
Iteration:    520, Loss function: 7.006, Average Loss: 3.521, avg. samples / sec: 53226.38
Iteration:    520, Loss function: 6.366, Average Loss: 3.523, avg. samples / sec: 53126.86
Iteration:    520, Loss function: 6.530, Average Loss: 3.538, avg. samples / sec: 53001.15
Iteration:    520, Loss function: 5.937, Average Loss: 3.529, avg. samples / sec: 52926.74
Iteration:    520, Loss function: 6.200, Average Loss: 3.514, avg. samples / sec: 52970.49
Iteration:    520, Loss function: 6.022, Average Loss: 3.542, avg. samples / sec: 53003.54
Iteration:    520, Loss function: 6.414, Average Loss: 3.514, avg. samples / sec: 53051.62
Iteration:    520, Loss function: 7.109, Average Loss: 3.527, avg. samples / sec: 53048.85
Iteration:    520, Loss function: 6.476, Average Loss: 3.521, avg. samples / sec: 53061.93
Iteration:    520, Loss function: 6.951, Average Loss: 3.497, avg. samples / sec: 52786.07
Iteration:    520, Loss function: 6.376, Average Loss: 3.511, avg. samples / sec: 53051.56
Iteration:    520, Loss function: 6.258, Average Loss: 3.535, avg. samples / sec: 53079.74
Iteration:    520, Loss function: 6.594, Average Loss: 3.521, avg. samples / sec: 53033.92
Iteration:    520, Loss function: 5.499, Average Loss: 3.528, avg. samples / sec: 53044.75
Iteration:    520, Loss function: 6.093, Average Loss: 3.524, avg. samples / sec: 53037.23
Iteration:    520, Loss function: 6.339, Average Loss: 3.561, avg. samples / sec: 53037.49
Iteration:    520, Loss function: 5.973, Average Loss: 3.549, avg. samples / sec: 53035.15
Iteration:    520, Loss function: 6.439, Average Loss: 3.536, avg. samples / sec: 52761.33
Iteration:    520, Loss function: 6.456, Average Loss: 3.514, avg. samples / sec: 53015.28
Iteration:    540, Loss function: 5.129, Average Loss: 3.576, avg. samples / sec: 54339.27
Iteration:    540, Loss function: 4.846, Average Loss: 3.580, avg. samples / sec: 54375.85
Iteration:    540, Loss function: 5.768, Average Loss: 3.580, avg. samples / sec: 54418.90
Iteration:    540, Loss function: 6.847, Average Loss: 3.556, avg. samples / sec: 54372.39
Iteration:    540, Loss function: 4.432, Average Loss: 3.602, avg. samples / sec: 54327.30
Iteration:    540, Loss function: 6.431, Average Loss: 3.582, avg. samples / sec: 54333.80
Iteration:    540, Loss function: 6.111, Average Loss: 3.590, avg. samples / sec: 54273.87
Iteration:    540, Loss function: 5.903, Average Loss: 3.587, avg. samples / sec: 54282.84
Iteration:    540, Loss function: 5.394, Average Loss: 3.581, avg. samples / sec: 54427.32
Iteration:    540, Loss function: 6.441, Average Loss: 3.574, avg. samples / sec: 54635.69
Iteration:    540, Loss function: 5.407, Average Loss: 3.567, avg. samples / sec: 54528.07
Iteration:    540, Loss function: 6.139, Average Loss: 3.569, avg. samples / sec: 54429.78
Iteration:    540, Loss function: 5.834, Average Loss: 3.586, avg. samples / sec: 54334.57
Iteration:    540, Loss function: 7.097, Average Loss: 3.578, avg. samples / sec: 54285.33
Iteration:    540, Loss function: 5.027, Average Loss: 3.583, avg. samples / sec: 54273.05
Iteration:    540, Loss function: 7.317, Average Loss: 3.593, avg. samples / sec: 54322.59
Iteration:    540, Loss function: 6.574, Average Loss: 3.594, avg. samples / sec: 54558.81
Iteration:    540, Loss function: 7.032, Average Loss: 3.592, avg. samples / sec: 54276.31
Iteration:    540, Loss function: 5.311, Average Loss: 3.580, avg. samples / sec: 54279.07
Iteration:    540, Loss function: 6.537, Average Loss: 3.573, avg. samples / sec: 54445.05
Iteration:    540, Loss function: 5.039, Average Loss: 3.584, avg. samples / sec: 54416.48
Iteration:    540, Loss function: 6.436, Average Loss: 3.601, avg. samples / sec: 54338.43
Iteration:    540, Loss function: 6.709, Average Loss: 3.548, avg. samples / sec: 54338.13
Iteration:    540, Loss function: 5.798, Average Loss: 3.588, avg. samples / sec: 54309.07
Iteration:    540, Loss function: 6.588, Average Loss: 3.575, avg. samples / sec: 54299.65
Iteration:    540, Loss function: 6.022, Average Loss: 3.586, avg. samples / sec: 54275.65
Iteration:    540, Loss function: 6.482, Average Loss: 3.578, avg. samples / sec: 54285.66
Iteration:    540, Loss function: 6.141, Average Loss: 3.612, avg. samples / sec: 54279.49
Iteration:    540, Loss function: 6.314, Average Loss: 3.609, avg. samples / sec: 54220.39
Iteration:    540, Loss function: 6.504, Average Loss: 3.586, avg. samples / sec: 53452.67
:::MLL 1558640039.353 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558640039.354 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 6.529, Average Loss: 3.636, avg. samples / sec: 53232.38
Iteration:    560, Loss function: 7.537, Average Loss: 3.600, avg. samples / sec: 53296.76
Iteration:    560, Loss function: 6.158, Average Loss: 3.644, avg. samples / sec: 53109.36
Iteration:    560, Loss function: 4.934, Average Loss: 3.636, avg. samples / sec: 53040.64
Iteration:    560, Loss function: 5.361, Average Loss: 3.625, avg. samples / sec: 53127.30
Iteration:    560, Loss function: 5.328, Average Loss: 3.658, avg. samples / sec: 53320.07
Iteration:    560, Loss function: 4.659, Average Loss: 3.625, avg. samples / sec: 53021.37
Iteration:    560, Loss function: 5.975, Average Loss: 3.651, avg. samples / sec: 52905.54
Iteration:    560, Loss function: 4.993, Average Loss: 3.626, avg. samples / sec: 52677.19
Iteration:    560, Loss function: 6.583, Average Loss: 3.625, avg. samples / sec: 52912.71
Iteration:    560, Loss function: 5.582, Average Loss: 3.662, avg. samples / sec: 53183.02
Iteration:    560, Loss function: 5.548, Average Loss: 3.641, avg. samples / sec: 52851.39
Iteration:    560, Loss function: 6.383, Average Loss: 3.630, avg. samples / sec: 53023.94
Iteration:    560, Loss function: 4.886, Average Loss: 3.628, avg. samples / sec: 52806.82
Iteration:    560, Loss function: 5.652, Average Loss: 3.632, avg. samples / sec: 52603.44
Iteration:    560, Loss function: 5.724, Average Loss: 3.634, avg. samples / sec: 52808.02
Iteration:    560, Loss function: 5.903, Average Loss: 3.634, avg. samples / sec: 53568.81
Iteration:    560, Loss function: 4.765, Average Loss: 3.640, avg. samples / sec: 52572.42
Iteration:    560, Loss function: 6.099, Average Loss: 3.646, avg. samples / sec: 52419.69
Iteration:    560, Loss function: 6.478, Average Loss: 3.626, avg. samples / sec: 52116.99
Iteration:    560, Loss function: 5.066, Average Loss: 3.622, avg. samples / sec: 52178.26
Iteration:    560, Loss function: 5.867, Average Loss: 3.636, avg. samples / sec: 52111.67
Iteration:    560, Loss function: 4.797, Average Loss: 3.630, avg. samples / sec: 52184.01
Iteration:    560, Loss function: 5.162, Average Loss: 3.629, avg. samples / sec: 51960.96
Iteration:    560, Loss function: 6.011, Average Loss: 3.607, avg. samples / sec: 51616.44
Iteration:    560, Loss function: 5.463, Average Loss: 3.628, avg. samples / sec: 51847.77
Iteration:    560, Loss function: 5.693, Average Loss: 3.635, avg. samples / sec: 51620.58
Iteration:    560, Loss function: 5.639, Average Loss: 3.617, avg. samples / sec: 51180.05
Iteration:    560, Loss function: 6.171, Average Loss: 3.614, avg. samples / sec: 50549.34
Iteration:    560, Loss function: 6.920, Average Loss: 3.639, avg. samples / sec: 50605.04
Iteration:    580, Loss function: 6.857, Average Loss: 3.687, avg. samples / sec: 52524.02
Iteration:    580, Loss function: 6.374, Average Loss: 3.676, avg. samples / sec: 52092.45
Iteration:    580, Loss function: 6.518, Average Loss: 3.657, avg. samples / sec: 53269.54
Iteration:    580, Loss function: 5.954, Average Loss: 3.692, avg. samples / sec: 53229.74
Iteration:    580, Loss function: 6.898, Average Loss: 3.710, avg. samples / sec: 51974.83
Iteration:    580, Loss function: 7.003, Average Loss: 3.689, avg. samples / sec: 52701.21
Iteration:    580, Loss function: 6.384, Average Loss: 3.670, avg. samples / sec: 53687.50
Iteration:    580, Loss function: 5.751, Average Loss: 3.692, avg. samples / sec: 52272.57
Iteration:    580, Loss function: 6.362, Average Loss: 3.674, avg. samples / sec: 51814.56
Iteration:    580, Loss function: 6.645, Average Loss: 3.684, avg. samples / sec: 52165.31
Iteration:    580, Loss function: 6.147, Average Loss: 3.692, avg. samples / sec: 51969.81
Iteration:    580, Loss function: 6.407, Average Loss: 3.699, avg. samples / sec: 51735.19
Iteration:    580, Loss function: 6.812, Average Loss: 3.679, avg. samples / sec: 52727.33
Iteration:    580, Loss function: 6.175, Average Loss: 3.674, avg. samples / sec: 51994.24
Iteration:    580, Loss function: 5.560, Average Loss: 3.704, avg. samples / sec: 51828.61
Iteration:    580, Loss function: 6.196, Average Loss: 3.687, avg. samples / sec: 51536.52
Iteration:    580, Loss function: 5.880, Average Loss: 3.682, avg. samples / sec: 52559.87
Iteration:    580, Loss function: 7.321, Average Loss: 3.680, avg. samples / sec: 52464.13
Iteration:    580, Loss function: 6.644, Average Loss: 3.685, avg. samples / sec: 51597.59
Iteration:    580, Loss function: 6.056, Average Loss: 3.683, avg. samples / sec: 52986.14
Iteration:    580, Loss function: 6.798, Average Loss: 3.651, avg. samples / sec: 51520.99
Iteration:    580, Loss function: 6.643, Average Loss: 3.678, avg. samples / sec: 51875.77
Iteration:    580, Loss function: 6.563, Average Loss: 3.665, avg. samples / sec: 54147.94
Iteration:    580, Loss function: 6.831, Average Loss: 3.676, avg. samples / sec: 51540.64
Iteration:    580, Loss function: 6.459, Average Loss: 3.708, avg. samples / sec: 51515.72
Iteration:    580, Loss function: 7.061, Average Loss: 3.670, avg. samples / sec: 52323.30
Iteration:    580, Loss function: 6.730, Average Loss: 3.685, avg. samples / sec: 51879.57
Iteration:    580, Loss function: 6.022, Average Loss: 3.677, avg. samples / sec: 51427.79
Iteration:    580, Loss function: 6.739, Average Loss: 3.687, avg. samples / sec: 54019.81
Iteration:    580, Loss function: 5.267, Average Loss: 3.699, avg. samples / sec: 51923.03
Iteration:    600, Loss function: 5.208, Average Loss: 3.723, avg. samples / sec: 54649.19
Iteration:    600, Loss function: 5.706, Average Loss: 3.759, avg. samples / sec: 54802.77
Iteration:    600, Loss function: 6.194, Average Loss: 3.710, avg. samples / sec: 54677.18
Iteration:    600, Loss function: 5.682, Average Loss: 3.736, avg. samples / sec: 54801.07
Iteration:    600, Loss function: 7.117, Average Loss: 3.741, avg. samples / sec: 54692.73
Iteration:    600, Loss function: 6.074, Average Loss: 3.738, avg. samples / sec: 54700.52
Iteration:    600, Loss function: 6.139, Average Loss: 3.728, avg. samples / sec: 54704.70
Iteration:    600, Loss function: 5.045, Average Loss: 3.732, avg. samples / sec: 55195.71
Iteration:    600, Loss function: 5.497, Average Loss: 3.740, avg. samples / sec: 54611.64
Iteration:    600, Loss function: 6.028, Average Loss: 3.734, avg. samples / sec: 54826.01
Iteration:    600, Loss function: 6.375, Average Loss: 3.727, avg. samples / sec: 54890.59
Iteration:    600, Loss function: 6.045, Average Loss: 3.746, avg. samples / sec: 54649.29
Iteration:    600, Loss function: 5.518, Average Loss: 3.752, avg. samples / sec: 54660.17
Iteration:    600, Loss function: 6.380, Average Loss: 3.730, avg. samples / sec: 54660.76
Iteration:    600, Loss function: 5.284, Average Loss: 3.728, avg. samples / sec: 55136.76
Iteration:    600, Loss function: 4.976, Average Loss: 3.716, avg. samples / sec: 54562.21
Iteration:    600, Loss function: 6.398, Average Loss: 3.702, avg. samples / sec: 54774.08
Iteration:    600, Loss function: 5.596, Average Loss: 3.722, avg. samples / sec: 54542.29
Iteration:    600, Loss function: 5.677, Average Loss: 3.736, avg. samples / sec: 54408.64
Iteration:    600, Loss function: 5.043, Average Loss: 3.728, avg. samples / sec: 54601.86
Iteration:    600, Loss function: 5.444, Average Loss: 3.715, avg. samples / sec: 54634.40
Iteration:    600, Loss function: 7.015, Average Loss: 3.733, avg. samples / sec: 54550.97
Iteration:    600, Loss function: 6.814, Average Loss: 3.726, avg. samples / sec: 54408.85
Iteration:    600, Loss function: 6.186, Average Loss: 3.733, avg. samples / sec: 54751.23
Iteration:    600, Loss function: 6.152, Average Loss: 3.729, avg. samples / sec: 54492.86
Iteration:    600, Loss function: 5.000, Average Loss: 3.730, avg. samples / sec: 54092.20
Iteration:    600, Loss function: 5.500, Average Loss: 3.722, avg. samples / sec: 54609.90
Iteration:    600, Loss function: 5.872, Average Loss: 3.757, avg. samples / sec: 54622.69
Iteration:    600, Loss function: 5.948, Average Loss: 3.722, avg. samples / sec: 54655.19
Iteration:    600, Loss function: 6.186, Average Loss: 3.745, avg. samples / sec: 54723.82
Iteration:    620, Loss function: 5.235, Average Loss: 3.757, avg. samples / sec: 53642.22
Iteration:    620, Loss function: 5.865, Average Loss: 3.769, avg. samples / sec: 53836.40
Iteration:    620, Loss function: 5.810, Average Loss: 3.767, avg. samples / sec: 53571.56
Iteration:    620, Loss function: 5.599, Average Loss: 3.780, avg. samples / sec: 53702.68
Iteration:    620, Loss function: 6.413, Average Loss: 3.781, avg. samples / sec: 53901.98
Iteration:    620, Loss function: 6.711, Average Loss: 3.772, avg. samples / sec: 53668.08
Iteration:    620, Loss function: 6.296, Average Loss: 3.790, avg. samples / sec: 53716.87
Iteration:    620, Loss function: 6.258, Average Loss: 3.773, avg. samples / sec: 53672.41
Iteration:    620, Loss function: 6.415, Average Loss: 3.782, avg. samples / sec: 53522.18
Iteration:    620, Loss function: 6.469, Average Loss: 3.787, avg. samples / sec: 53615.26
Iteration:    620, Loss function: 6.565, Average Loss: 3.787, avg. samples / sec: 53579.99
Iteration:    620, Loss function: 7.100, Average Loss: 3.766, avg. samples / sec: 53721.04
Iteration:    620, Loss function: 6.411, Average Loss: 3.769, avg. samples / sec: 53874.82
Iteration:    620, Loss function: 5.645, Average Loss: 3.777, avg. samples / sec: 53579.71
Iteration:    620, Loss function: 5.884, Average Loss: 3.764, avg. samples / sec: 53653.94
Iteration:    620, Loss function: 5.154, Average Loss: 3.779, avg. samples / sec: 53626.34
Iteration:    620, Loss function: 5.855, Average Loss: 3.790, avg. samples / sec: 53594.97
Iteration:    620, Loss function: 5.602, Average Loss: 3.773, avg. samples / sec: 53791.83
Iteration:    620, Loss function: 6.318, Average Loss: 3.788, avg. samples / sec: 54106.38
Iteration:    620, Loss function: 6.555, Average Loss: 3.766, avg. samples / sec: 53762.36
Iteration:    620, Loss function: 5.399, Average Loss: 3.773, avg. samples / sec: 53692.90
Iteration:    620, Loss function: 5.924, Average Loss: 3.766, avg. samples / sec: 53755.18
Iteration:    620, Loss function: 6.691, Average Loss: 3.777, avg. samples / sec: 53698.16
Iteration:    620, Loss function: 5.957, Average Loss: 3.744, avg. samples / sec: 53510.98
Iteration:    620, Loss function: 6.462, Average Loss: 3.758, avg. samples / sec: 53688.75
Iteration:    620, Loss function: 6.192, Average Loss: 3.767, avg. samples / sec: 53393.58
Iteration:    620, Loss function: 6.723, Average Loss: 3.802, avg. samples / sec: 53684.49
Iteration:    620, Loss function: 5.871, Average Loss: 3.776, avg. samples / sec: 53650.96
Iteration:    620, Loss function: 6.409, Average Loss: 3.768, avg. samples / sec: 53652.28
Iteration:    620, Loss function: 5.719, Average Loss: 3.802, avg. samples / sec: 52294.48
:::MLL 1558640041.565 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558640041.566 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 5.756, Average Loss: 3.847, avg. samples / sec: 55301.06
Iteration:    640, Loss function: 6.416, Average Loss: 3.815, avg. samples / sec: 53841.93
Iteration:    640, Loss function: 5.761, Average Loss: 3.813, avg. samples / sec: 53923.22
Iteration:    640, Loss function: 6.433, Average Loss: 3.815, avg. samples / sec: 53975.27
Iteration:    640, Loss function: 5.147, Average Loss: 3.827, avg. samples / sec: 53966.71
Iteration:    640, Loss function: 5.457, Average Loss: 3.797, avg. samples / sec: 53646.69
Iteration:    640, Loss function: 5.032, Average Loss: 3.809, avg. samples / sec: 54037.46
Iteration:    640, Loss function: 5.296, Average Loss: 3.812, avg. samples / sec: 53733.37
Iteration:    640, Loss function: 5.975, Average Loss: 3.817, avg. samples / sec: 53645.20
Iteration:    640, Loss function: 5.648, Average Loss: 3.816, avg. samples / sec: 53746.51
Iteration:    640, Loss function: 5.496, Average Loss: 3.823, avg. samples / sec: 53825.05
Iteration:    640, Loss function: 6.475, Average Loss: 3.818, avg. samples / sec: 54040.75
Iteration:    640, Loss function: 4.891, Average Loss: 3.827, avg. samples / sec: 53788.09
Iteration:    640, Loss function: 6.601, Average Loss: 3.832, avg. samples / sec: 53715.74
Iteration:    640, Loss function: 5.553, Average Loss: 3.830, avg. samples / sec: 53768.74
Iteration:    640, Loss function: 6.375, Average Loss: 3.806, avg. samples / sec: 53804.07
Iteration:    640, Loss function: 5.364, Average Loss: 3.824, avg. samples / sec: 53737.70
Iteration:    640, Loss function: 6.346, Average Loss: 3.806, avg. samples / sec: 53780.50
Iteration:    640, Loss function: 4.538, Average Loss: 3.815, avg. samples / sec: 53930.55
Iteration:    640, Loss function: 6.696, Average Loss: 3.829, avg. samples / sec: 53755.30
Iteration:    640, Loss function: 5.569, Average Loss: 3.822, avg. samples / sec: 53596.19
Iteration:    640, Loss function: 5.681, Average Loss: 3.788, avg. samples / sec: 53787.23
Iteration:    640, Loss function: 5.095, Average Loss: 3.815, avg. samples / sec: 53585.37
Iteration:    640, Loss function: 5.850, Average Loss: 3.816, avg. samples / sec: 53722.09
Iteration:    640, Loss function: 4.626, Average Loss: 3.803, avg. samples / sec: 53731.00
Iteration:    640, Loss function: 6.382, Average Loss: 3.825, avg. samples / sec: 53458.65
Iteration:    640, Loss function: 5.600, Average Loss: 3.809, avg. samples / sec: 53779.86
Iteration:    640, Loss function: 6.691, Average Loss: 3.803, avg. samples / sec: 53649.53
Iteration:    640, Loss function: 5.255, Average Loss: 3.841, avg. samples / sec: 53752.60
Iteration:    640, Loss function: 5.377, Average Loss: 3.807, avg. samples / sec: 53685.62
Iteration:    660, Loss function: 7.079, Average Loss: 3.855, avg. samples / sec: 53633.42
Iteration:    660, Loss function: 4.635, Average Loss: 3.853, avg. samples / sec: 53467.09
Iteration:    660, Loss function: 5.853, Average Loss: 3.859, avg. samples / sec: 53449.25
Iteration:    660, Loss function: 7.519, Average Loss: 3.850, avg. samples / sec: 53463.54
Iteration:    660, Loss function: 5.981, Average Loss: 3.871, avg. samples / sec: 53521.73
Iteration:    660, Loss function: 6.707, Average Loss: 3.854, avg. samples / sec: 53477.95
Iteration:    660, Loss function: 5.774, Average Loss: 3.852, avg. samples / sec: 53408.45
Iteration:    660, Loss function: 4.999, Average Loss: 3.843, avg. samples / sec: 53451.72
Iteration:    660, Loss function: 6.323, Average Loss: 3.855, avg. samples / sec: 53196.87
Iteration:    660, Loss function: 4.591, Average Loss: 3.870, avg. samples / sec: 53418.49
Iteration:    660, Loss function: 6.202, Average Loss: 3.847, avg. samples / sec: 53296.74
Iteration:    660, Loss function: 6.325, Average Loss: 3.853, avg. samples / sec: 53305.06
Iteration:    660, Loss function: 4.850, Average Loss: 3.861, avg. samples / sec: 53390.04
Iteration:    660, Loss function: 5.770, Average Loss: 3.835, avg. samples / sec: 53323.19
Iteration:    660, Loss function: 6.837, Average Loss: 3.842, avg. samples / sec: 53617.15
Iteration:    660, Loss function: 6.273, Average Loss: 3.865, avg. samples / sec: 53267.14
Iteration:    660, Loss function: 5.791, Average Loss: 3.859, avg. samples / sec: 53569.14
Iteration:    660, Loss function: 5.183, Average Loss: 3.881, avg. samples / sec: 53014.28
Iteration:    660, Loss function: 6.222, Average Loss: 3.873, avg. samples / sec: 53255.25
Iteration:    660, Loss function: 6.807, Average Loss: 3.856, avg. samples / sec: 53468.21
Iteration:    660, Loss function: 5.801, Average Loss: 3.847, avg. samples / sec: 53452.57
Iteration:    660, Loss function: 5.250, Average Loss: 3.821, avg. samples / sec: 53391.66
Iteration:    660, Loss function: 5.439, Average Loss: 3.850, avg. samples / sec: 53175.81
Iteration:    660, Loss function: 4.923, Average Loss: 3.852, avg. samples / sec: 53183.72
Iteration:    660, Loss function: 4.447, Average Loss: 3.849, avg. samples / sec: 53434.98
Iteration:    660, Loss function: 6.612, Average Loss: 3.860, avg. samples / sec: 53372.43
Iteration:    660, Loss function: 4.582, Average Loss: 3.873, avg. samples / sec: 53414.24
Iteration:    660, Loss function: 6.825, Average Loss: 3.853, avg. samples / sec: 53419.87
Iteration:    660, Loss function: 4.990, Average Loss: 3.864, avg. samples / sec: 52676.31
Iteration:    660, Loss function: 6.997, Average Loss: 3.861, avg. samples / sec: 52678.77
Iteration:    680, Loss function: 4.576, Average Loss: 3.909, avg. samples / sec: 54814.90
Iteration:    680, Loss function: 4.642, Average Loss: 3.912, avg. samples / sec: 54599.05
Iteration:    680, Loss function: 5.769, Average Loss: 3.872, avg. samples / sec: 54423.58
Iteration:    680, Loss function: 7.680, Average Loss: 3.899, avg. samples / sec: 54429.70
Iteration:    680, Loss function: 5.889, Average Loss: 3.897, avg. samples / sec: 54432.24
Iteration:    680, Loss function: 4.885, Average Loss: 3.894, avg. samples / sec: 54265.09
Iteration:    680, Loss function: 6.555, Average Loss: 3.877, avg. samples / sec: 54330.80
Iteration:    680, Loss function: 4.959, Average Loss: 3.884, avg. samples / sec: 54271.38
Iteration:    680, Loss function: 5.736, Average Loss: 3.894, avg. samples / sec: 54045.09
Iteration:    680, Loss function: 4.643, Average Loss: 3.892, avg. samples / sec: 54261.29
Iteration:    680, Loss function: 5.804, Average Loss: 3.912, avg. samples / sec: 54434.41
Iteration:    680, Loss function: 5.059, Average Loss: 3.887, avg. samples / sec: 54231.35
Iteration:    680, Loss function: 5.661, Average Loss: 3.896, avg. samples / sec: 54306.68
Iteration:    680, Loss function: 5.005, Average Loss: 3.878, avg. samples / sec: 54236.08
Iteration:    680, Loss function: 5.236, Average Loss: 3.907, avg. samples / sec: 54205.63
Iteration:    680, Loss function: 6.850, Average Loss: 3.887, avg. samples / sec: 54264.92
Iteration:    680, Loss function: 6.801, Average Loss: 3.901, avg. samples / sec: 55015.43
Iteration:    680, Loss function: 6.065, Average Loss: 3.882, avg. samples / sec: 54441.56
Iteration:    680, Loss function: 5.210, Average Loss: 3.898, avg. samples / sec: 55060.46
Iteration:    680, Loss function: 5.704, Average Loss: 3.894, avg. samples / sec: 54464.83
Iteration:    680, Loss function: 5.138, Average Loss: 3.892, avg. samples / sec: 54031.49
Iteration:    680, Loss function: 4.877, Average Loss: 3.860, avg. samples / sec: 54291.54
Iteration:    680, Loss function: 5.294, Average Loss: 3.886, avg. samples / sec: 54256.82
Iteration:    680, Loss function: 6.335, Average Loss: 3.887, avg. samples / sec: 54048.82
Iteration:    680, Loss function: 6.935, Average Loss: 3.882, avg. samples / sec: 54096.24
Iteration:    680, Loss function: 4.854, Average Loss: 3.890, avg. samples / sec: 54269.92
Iteration:    680, Loss function: 5.992, Average Loss: 3.887, avg. samples / sec: 54276.92
Iteration:    680, Loss function: 5.521, Average Loss: 3.888, avg. samples / sec: 54293.52
Iteration:    680, Loss function: 5.801, Average Loss: 3.904, avg. samples / sec: 54001.35
Iteration:    680, Loss function: 5.812, Average Loss: 3.881, avg. samples / sec: 53677.38
:::MLL 1558640043.741 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558640043.742 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 5.198, Average Loss: 3.916, avg. samples / sec: 54383.68
Iteration:    700, Loss function: 5.420, Average Loss: 3.931, avg. samples / sec: 54537.80
Iteration:    700, Loss function: 6.514, Average Loss: 3.945, avg. samples / sec: 54067.71
Iteration:    700, Loss function: 6.503, Average Loss: 3.927, avg. samples / sec: 54250.80
Iteration:    700, Loss function: 5.243, Average Loss: 3.929, avg. samples / sec: 54218.43
Iteration:    700, Loss function: 6.169, Average Loss: 3.926, avg. samples / sec: 54205.27
Iteration:    700, Loss function: 5.847, Average Loss: 3.914, avg. samples / sec: 54978.40
Iteration:    700, Loss function: 7.313, Average Loss: 3.929, avg. samples / sec: 54120.30
Iteration:    700, Loss function: 5.914, Average Loss: 3.936, avg. samples / sec: 54149.64
Iteration:    700, Loss function: 6.155, Average Loss: 3.910, avg. samples / sec: 54010.79
Iteration:    700, Loss function: 5.513, Average Loss: 3.945, avg. samples / sec: 54123.94
Iteration:    700, Loss function: 5.937, Average Loss: 3.888, avg. samples / sec: 54294.05
Iteration:    700, Loss function: 6.271, Average Loss: 3.931, avg. samples / sec: 54061.88
Iteration:    700, Loss function: 6.839, Average Loss: 3.913, avg. samples / sec: 54062.11
Iteration:    700, Loss function: 7.152, Average Loss: 3.927, avg. samples / sec: 54064.89
Iteration:    700, Loss function: 6.713, Average Loss: 3.918, avg. samples / sec: 54099.28
Iteration:    700, Loss function: 4.320, Average Loss: 3.946, avg. samples / sec: 53791.25
Iteration:    700, Loss function: 6.385, Average Loss: 3.934, avg. samples / sec: 54083.85
Iteration:    700, Loss function: 5.055, Average Loss: 3.931, avg. samples / sec: 54102.97
Iteration:    700, Loss function: 6.473, Average Loss: 3.939, avg. samples / sec: 54287.12
Iteration:    700, Loss function: 6.771, Average Loss: 3.922, avg. samples / sec: 54202.88
Iteration:    700, Loss function: 5.582, Average Loss: 3.928, avg. samples / sec: 53947.37
Iteration:    700, Loss function: 6.098, Average Loss: 3.913, avg. samples / sec: 54198.85
Iteration:    700, Loss function: 6.266, Average Loss: 3.923, avg. samples / sec: 54173.98
Iteration:    700, Loss function: 6.102, Average Loss: 3.931, avg. samples / sec: 53822.13
Iteration:    700, Loss function: 4.941, Average Loss: 3.927, avg. samples / sec: 53966.21
Iteration:    700, Loss function: 5.543, Average Loss: 3.923, avg. samples / sec: 54079.26
Iteration:    700, Loss function: 5.866, Average Loss: 3.926, avg. samples / sec: 54050.97
Iteration:    700, Loss function: 5.510, Average Loss: 3.925, avg. samples / sec: 54039.61
Iteration:    700, Loss function: 5.913, Average Loss: 3.927, avg. samples / sec: 53683.08
Iteration:    720, Loss function: 5.310, Average Loss: 3.972, avg. samples / sec: 53775.59
Iteration:    720, Loss function: 6.392, Average Loss: 3.992, avg. samples / sec: 53663.77
Iteration:    720, Loss function: 6.190, Average Loss: 3.975, avg. samples / sec: 53685.11
Iteration:    720, Loss function: 5.114, Average Loss: 3.968, avg. samples / sec: 53442.03
Iteration:    720, Loss function: 6.249, Average Loss: 3.965, avg. samples / sec: 53701.21
Iteration:    720, Loss function: 5.745, Average Loss: 3.979, avg. samples / sec: 53646.81
Iteration:    720, Loss function: 5.552, Average Loss: 3.948, avg. samples / sec: 53660.48
Iteration:    720, Loss function: 6.101, Average Loss: 3.971, avg. samples / sec: 53691.71
Iteration:    720, Loss function: 5.828, Average Loss: 3.954, avg. samples / sec: 53376.77
Iteration:    720, Loss function: 4.514, Average Loss: 3.972, avg. samples / sec: 53703.31
Iteration:    720, Loss function: 4.353, Average Loss: 3.960, avg. samples / sec: 53556.25
Iteration:    720, Loss function: 5.482, Average Loss: 3.969, avg. samples / sec: 53796.49
Iteration:    720, Loss function: 4.582, Average Loss: 3.921, avg. samples / sec: 53533.04
Iteration:    720, Loss function: 5.373, Average Loss: 3.949, avg. samples / sec: 53458.35
Iteration:    720, Loss function: 5.523, Average Loss: 3.951, avg. samples / sec: 53402.22
Iteration:    720, Loss function: 5.788, Average Loss: 3.952, avg. samples / sec: 53582.36
Iteration:    720, Loss function: 4.819, Average Loss: 3.953, avg. samples / sec: 53535.68
Iteration:    720, Loss function: 6.318, Average Loss: 3.966, avg. samples / sec: 53387.49
Iteration:    720, Loss function: 5.625, Average Loss: 3.965, avg. samples / sec: 53620.19
Iteration:    720, Loss function: 5.590, Average Loss: 3.967, avg. samples / sec: 53407.78
Iteration:    720, Loss function: 4.602, Average Loss: 3.961, avg. samples / sec: 53686.07
Iteration:    720, Loss function: 5.805, Average Loss: 3.960, avg. samples / sec: 53560.12
Iteration:    720, Loss function: 4.264, Average Loss: 3.962, avg. samples / sec: 53698.83
Iteration:    720, Loss function: 4.799, Average Loss: 3.973, avg. samples / sec: 53464.33
Iteration:    720, Loss function: 6.364, Average Loss: 3.984, avg. samples / sec: 53419.38
Iteration:    720, Loss function: 5.395, Average Loss: 3.958, avg. samples / sec: 53296.13
Iteration:    720, Loss function: 5.979, Average Loss: 3.965, avg. samples / sec: 52881.52
Iteration:    720, Loss function: 5.975, Average Loss: 3.954, avg. samples / sec: 53048.43
Iteration:    720, Loss function: 5.960, Average Loss: 3.962, avg. samples / sec: 53027.11
Iteration:    720, Loss function: 6.258, Average Loss: 3.973, avg. samples / sec: 52894.08
Iteration:    740, Loss function: 6.198, Average Loss: 4.020, avg. samples / sec: 52836.32
Iteration:    740, Loss function: 6.225, Average Loss: 3.978, avg. samples / sec: 53171.58
Iteration:    740, Loss function: 4.443, Average Loss: 3.997, avg. samples / sec: 52932.01
Iteration:    740, Loss function: 5.954, Average Loss: 3.998, avg. samples / sec: 53099.54
Iteration:    740, Loss function: 5.697, Average Loss: 4.001, avg. samples / sec: 52836.71
Iteration:    740, Loss function: 6.403, Average Loss: 3.988, avg. samples / sec: 52796.45
Iteration:    740, Loss function: 6.369, Average Loss: 4.009, avg. samples / sec: 52704.70
Iteration:    740, Loss function: 4.472, Average Loss: 4.003, avg. samples / sec: 52662.08
Iteration:    740, Loss function: 5.444, Average Loss: 3.999, avg. samples / sec: 52655.92
Iteration:    740, Loss function: 6.673, Average Loss: 3.984, avg. samples / sec: 52900.58
Iteration:    740, Loss function: 5.147, Average Loss: 3.993, avg. samples / sec: 52658.36
Iteration:    740, Loss function: 5.234, Average Loss: 3.996, avg. samples / sec: 53370.16
Iteration:    740, Loss function: 5.059, Average Loss: 3.996, avg. samples / sec: 52883.34
Iteration:    740, Loss function: 5.281, Average Loss: 3.979, avg. samples / sec: 52853.22
Iteration:    740, Loss function: 5.208, Average Loss: 4.001, avg. samples / sec: 52854.17
Iteration:    740, Loss function: 6.426, Average Loss: 3.992, avg. samples / sec: 52869.48
Iteration:    740, Loss function: 4.960, Average Loss: 3.982, avg. samples / sec: 52822.22
Iteration:    740, Loss function: 6.054, Average Loss: 3.993, avg. samples / sec: 53234.97
Iteration:    740, Loss function: 5.523, Average Loss: 3.990, avg. samples / sec: 52844.56
Iteration:    740, Loss function: 6.115, Average Loss: 3.986, avg. samples / sec: 53147.50
Iteration:    740, Loss function: 5.672, Average Loss: 3.990, avg. samples / sec: 53045.15
Iteration:    740, Loss function: 5.230, Average Loss: 4.001, avg. samples / sec: 52528.25
Iteration:    740, Loss function: 5.781, Average Loss: 3.988, avg. samples / sec: 52493.42
Iteration:    740, Loss function: 5.933, Average Loss: 3.973, avg. samples / sec: 52414.84
Iteration:    740, Loss function: 4.342, Average Loss: 3.998, avg. samples / sec: 52107.93
Iteration:    740, Loss function: 6.170, Average Loss: 3.951, avg. samples / sec: 52389.49
Iteration:    740, Loss function: 4.724, Average Loss: 4.010, avg. samples / sec: 52407.74
Iteration:    740, Loss function: 4.157, Average Loss: 3.988, avg. samples / sec: 52364.96
Iteration:    740, Loss function: 4.683, Average Loss: 4.004, avg. samples / sec: 52209.14
Iteration:    740, Loss function: 4.900, Average Loss: 4.007, avg. samples / sec: 53037.61
Iteration:    760, Loss function: 5.928, Average Loss: 4.024, avg. samples / sec: 54779.06
Iteration:    760, Loss function: 7.253, Average Loss: 4.055, avg. samples / sec: 54412.09
Iteration:    760, Loss function: 6.909, Average Loss: 4.016, avg. samples / sec: 54397.85
Iteration:    760, Loss function: 6.852, Average Loss: 4.033, avg. samples / sec: 54301.56
Iteration:    760, Loss function: 8.249, Average Loss: 4.039, avg. samples / sec: 54536.66
Iteration:    760, Loss function: 6.353, Average Loss: 4.035, avg. samples / sec: 54404.80
Iteration:    760, Loss function: 5.970, Average Loss: 4.037, avg. samples / sec: 54575.31
Iteration:    760, Loss function: 6.552, Average Loss: 4.034, avg. samples / sec: 54555.24
Iteration:    760, Loss function: 5.510, Average Loss: 4.009, avg. samples / sec: 54826.69
Iteration:    760, Loss function: 5.950, Average Loss: 4.036, avg. samples / sec: 54919.44
Iteration:    760, Loss function: 5.794, Average Loss: 4.048, avg. samples / sec: 55368.35
Iteration:    760, Loss function: 5.704, Average Loss: 4.024, avg. samples / sec: 54384.75
Iteration:    760, Loss function: 6.255, Average Loss: 3.994, avg. samples / sec: 54925.07
Iteration:    760, Loss function: 6.199, Average Loss: 4.038, avg. samples / sec: 54240.34
Iteration:    760, Loss function: 5.949, Average Loss: 4.039, avg. samples / sec: 54393.40
Iteration:    760, Loss function: 5.936, Average Loss: 4.038, avg. samples / sec: 54385.78
Iteration:    760, Loss function: 5.972, Average Loss: 4.026, avg. samples / sec: 54530.43
Iteration:    760, Loss function: 6.456, Average Loss: 4.035, avg. samples / sec: 54567.59
Iteration:    760, Loss function: 5.943, Average Loss: 4.039, avg. samples / sec: 54404.23
Iteration:    760, Loss function: 4.261, Average Loss: 4.020, avg. samples / sec: 54404.72
Iteration:    760, Loss function: 6.300, Average Loss: 4.030, avg. samples / sec: 54394.13
Iteration:    760, Loss function: 5.935, Average Loss: 4.030, avg. samples / sec: 54516.78
Iteration:    760, Loss function: 6.571, Average Loss: 4.018, avg. samples / sec: 54345.64
Iteration:    760, Loss function: 5.909, Average Loss: 4.023, avg. samples / sec: 54525.75
Iteration:    760, Loss function: 5.968, Average Loss: 4.034, avg. samples / sec: 54372.87
Iteration:    760, Loss function: 5.801, Average Loss: 4.050, avg. samples / sec: 54872.83
Iteration:    760, Loss function: 5.788, Average Loss: 4.038, avg. samples / sec: 55069.30
Iteration:    760, Loss function: 7.530, Average Loss: 4.026, avg. samples / sec: 54847.48
Iteration:    760, Loss function: 5.885, Average Loss: 4.047, avg. samples / sec: 53649.61
Iteration:    760, Loss function: 6.750, Average Loss: 4.032, avg. samples / sec: 53375.97
:::MLL 1558640045.938 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558640045.939 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 5.024, Average Loss: 4.068, avg. samples / sec: 54111.64
Iteration:    780, Loss function: 5.555, Average Loss: 4.086, avg. samples / sec: 53871.26
Iteration:    780, Loss function: 4.550, Average Loss: 4.061, avg. samples / sec: 54095.50
Iteration:    780, Loss function: 6.940, Average Loss: 4.069, avg. samples / sec: 54014.88
Iteration:    780, Loss function: 4.810, Average Loss: 4.079, avg. samples / sec: 54864.05
Iteration:    780, Loss function: 6.008, Average Loss: 4.084, avg. samples / sec: 54016.17
Iteration:    780, Loss function: 5.924, Average Loss: 4.068, avg. samples / sec: 54176.79
Iteration:    780, Loss function: 4.843, Average Loss: 4.073, avg. samples / sec: 53948.86
Iteration:    780, Loss function: 5.181, Average Loss: 4.069, avg. samples / sec: 53932.04
Iteration:    780, Loss function: 5.319, Average Loss: 4.042, avg. samples / sec: 53952.19
Iteration:    780, Loss function: 5.321, Average Loss: 4.074, avg. samples / sec: 54060.22
Iteration:    780, Loss function: 5.602, Average Loss: 4.080, avg. samples / sec: 54049.19
Iteration:    780, Loss function: 5.054, Average Loss: 4.057, avg. samples / sec: 53670.16
Iteration:    780, Loss function: 4.556, Average Loss: 4.064, avg. samples / sec: 54083.75
Iteration:    780, Loss function: 4.854, Average Loss: 4.062, avg. samples / sec: 54128.03
Iteration:    780, Loss function: 5.375, Average Loss: 4.075, avg. samples / sec: 54065.90
Iteration:    780, Loss function: 5.939, Average Loss: 4.059, avg. samples / sec: 54003.81
Iteration:    780, Loss function: 5.309, Average Loss: 4.029, avg. samples / sec: 53820.50
Iteration:    780, Loss function: 4.452, Average Loss: 4.069, avg. samples / sec: 53748.11
Iteration:    780, Loss function: 5.782, Average Loss: 4.058, avg. samples / sec: 53951.13
Iteration:    780, Loss function: 5.315, Average Loss: 4.067, avg. samples / sec: 53708.60
Iteration:    780, Loss function: 5.336, Average Loss: 4.068, avg. samples / sec: 53925.27
Iteration:    780, Loss function: 5.498, Average Loss: 4.056, avg. samples / sec: 53943.10
Iteration:    780, Loss function: 5.775, Average Loss: 4.087, avg. samples / sec: 53967.95
Iteration:    780, Loss function: 5.660, Average Loss: 4.052, avg. samples / sec: 53912.95
Iteration:    780, Loss function: 6.313, Average Loss: 4.084, avg. samples / sec: 53967.68
Iteration:    780, Loss function: 6.337, Average Loss: 4.078, avg. samples / sec: 53854.54
Iteration:    780, Loss function: 5.411, Average Loss: 4.065, avg. samples / sec: 53981.22
Iteration:    780, Loss function: 4.727, Average Loss: 4.071, avg. samples / sec: 54915.65
Iteration:    780, Loss function: 4.256, Average Loss: 4.047, avg. samples / sec: 53256.56
Iteration:    800, Loss function: 5.827, Average Loss: 4.114, avg. samples / sec: 54029.30
Iteration:    800, Loss function: 5.744, Average Loss: 4.099, avg. samples / sec: 54070.61
Iteration:    800, Loss function: 5.584, Average Loss: 4.107, avg. samples / sec: 54074.47
Iteration:    800, Loss function: 4.533, Average Loss: 4.094, avg. samples / sec: 54267.70
Iteration:    800, Loss function: 5.050, Average Loss: 4.105, avg. samples / sec: 53990.71
Iteration:    800, Loss function: 5.435, Average Loss: 4.094, avg. samples / sec: 54253.52
Iteration:    800, Loss function: 4.325, Average Loss: 4.098, avg. samples / sec: 53845.16
Iteration:    800, Loss function: 4.710, Average Loss: 4.073, avg. samples / sec: 54527.75
Iteration:    800, Loss function: 4.315, Average Loss: 4.093, avg. samples / sec: 54082.02
Iteration:    800, Loss function: 5.322, Average Loss: 4.110, avg. samples / sec: 53957.74
Iteration:    800, Loss function: 6.048, Average Loss: 4.087, avg. samples / sec: 54214.03
Iteration:    800, Loss function: 5.210, Average Loss: 4.088, avg. samples / sec: 54003.56
Iteration:    800, Loss function: 5.316, Average Loss: 4.093, avg. samples / sec: 53895.57
Iteration:    800, Loss function: 4.852, Average Loss: 4.069, avg. samples / sec: 53951.40
Iteration:    800, Loss function: 5.418, Average Loss: 4.091, avg. samples / sec: 53900.37
Iteration:    800, Loss function: 6.006, Average Loss: 4.097, avg. samples / sec: 53911.88
Iteration:    800, Loss function: 4.230, Average Loss: 4.052, avg. samples / sec: 54044.09
Iteration:    800, Loss function: 4.999, Average Loss: 4.081, avg. samples / sec: 53865.25
Iteration:    800, Loss function: 4.443, Average Loss: 4.096, avg. samples / sec: 53803.33
Iteration:    800, Loss function: 4.248, Average Loss: 4.102, avg. samples / sec: 53887.94
Iteration:    800, Loss function: 4.816, Average Loss: 4.071, avg. samples / sec: 54045.33
Iteration:    800, Loss function: 6.119, Average Loss: 4.109, avg. samples / sec: 54052.26
Iteration:    800, Loss function: 5.695, Average Loss: 4.093, avg. samples / sec: 53969.19
Iteration:    800, Loss function: 6.453, Average Loss: 4.086, avg. samples / sec: 54009.71
Iteration:    800, Loss function: 4.359, Average Loss: 4.096, avg. samples / sec: 54045.29
Iteration:    800, Loss function: 5.752, Average Loss: 4.087, avg. samples / sec: 53671.61
Iteration:    800, Loss function: 5.593, Average Loss: 4.098, avg. samples / sec: 54054.62
Iteration:    800, Loss function: 6.717, Average Loss: 4.115, avg. samples / sec: 53985.32
Iteration:    800, Loss function: 4.897, Average Loss: 4.089, avg. samples / sec: 54011.82
Iteration:    800, Loss function: 5.104, Average Loss: 4.081, avg. samples / sec: 53868.60
Iteration:    820, Loss function: 5.449, Average Loss: 4.137, avg. samples / sec: 54416.84
Iteration:    820, Loss function: 4.943, Average Loss: 4.098, avg. samples / sec: 54543.62
Iteration:    820, Loss function: 4.936, Average Loss: 4.129, avg. samples / sec: 54535.81
Iteration:    820, Loss function: 4.978, Average Loss: 4.116, avg. samples / sec: 54491.24
Iteration:    820, Loss function: 5.003, Average Loss: 4.116, avg. samples / sec: 54560.83
Iteration:    820, Loss function: 5.164, Average Loss: 4.123, avg. samples / sec: 54474.22
Iteration:    820, Loss function: 5.738, Average Loss: 4.128, avg. samples / sec: 54376.06
Iteration:    820, Loss function: 5.257, Average Loss: 4.122, avg. samples / sec: 54688.00
Iteration:    820, Loss function: 4.868, Average Loss: 4.117, avg. samples / sec: 54696.55
Iteration:    820, Loss function: 5.564, Average Loss: 4.091, avg. samples / sec: 54480.64
Iteration:    820, Loss function: 4.523, Average Loss: 4.109, avg. samples / sec: 54476.51
Iteration:    820, Loss function: 5.203, Average Loss: 4.116, avg. samples / sec: 54613.63
Iteration:    820, Loss function: 5.484, Average Loss: 4.134, avg. samples / sec: 54343.21
Iteration:    820, Loss function: 5.169, Average Loss: 4.131, avg. samples / sec: 54366.14
Iteration:    820, Loss function: 5.235, Average Loss: 4.112, avg. samples / sec: 54455.55
Iteration:    820, Loss function: 5.073, Average Loss: 4.115, avg. samples / sec: 54349.87
Iteration:    820, Loss function: 4.907, Average Loss: 4.114, avg. samples / sec: 54604.68
Iteration:    820, Loss function: 5.154, Average Loss: 4.125, avg. samples / sec: 54429.17
Iteration:    820, Loss function: 4.271, Average Loss: 4.111, avg. samples / sec: 54543.52
Iteration:    820, Loss function: 5.542, Average Loss: 4.075, avg. samples / sec: 54377.68
Iteration:    820, Loss function: 5.143, Average Loss: 4.120, avg. samples / sec: 54447.45
Iteration:    820, Loss function: 6.652, Average Loss: 4.125, avg. samples / sec: 54406.29
Iteration:    820, Loss function: 4.806, Average Loss: 4.096, avg. samples / sec: 54395.71
Iteration:    820, Loss function: 5.558, Average Loss: 4.105, avg. samples / sec: 54352.43
Iteration:    820, Loss function: 4.838, Average Loss: 4.115, avg. samples / sec: 54170.91
Iteration:    820, Loss function: 5.097, Average Loss: 4.106, avg. samples / sec: 54401.04
Iteration:    820, Loss function: 4.833, Average Loss: 4.109, avg. samples / sec: 54173.54
Iteration:    820, Loss function: 5.723, Average Loss: 4.111, avg. samples / sec: 54399.84
Iteration:    820, Loss function: 5.213, Average Loss: 4.135, avg. samples / sec: 54335.98
Iteration:    820, Loss function: 4.630, Average Loss: 4.136, avg. samples / sec: 54380.64
:::MLL 1558640048.101 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558640048.102 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 5.305, Average Loss: 4.140, avg. samples / sec: 54535.35
Iteration:    840, Loss function: 4.965, Average Loss: 4.148, avg. samples / sec: 54460.30
Iteration:    840, Loss function: 5.109, Average Loss: 4.154, avg. samples / sec: 54549.15
Iteration:    840, Loss function: 5.054, Average Loss: 4.142, avg. samples / sec: 54502.47
Iteration:    840, Loss function: 5.188, Average Loss: 4.097, avg. samples / sec: 54686.09
Iteration:    840, Loss function: 5.444, Average Loss: 4.146, avg. samples / sec: 54373.57
Iteration:    840, Loss function: 5.173, Average Loss: 4.153, avg. samples / sec: 54425.47
Iteration:    840, Loss function: 5.164, Average Loss: 4.117, avg. samples / sec: 54337.69
Iteration:    840, Loss function: 5.105, Average Loss: 4.135, avg. samples / sec: 54479.12
Iteration:    840, Loss function: 5.860, Average Loss: 4.158, avg. samples / sec: 54411.18
Iteration:    840, Loss function: 5.440, Average Loss: 4.141, avg. samples / sec: 54420.89
Iteration:    840, Loss function: 4.854, Average Loss: 4.156, avg. samples / sec: 54635.56
Iteration:    840, Loss function: 5.307, Average Loss: 4.119, avg. samples / sec: 54512.84
Iteration:    840, Loss function: 4.943, Average Loss: 4.133, avg. samples / sec: 54433.92
Iteration:    840, Loss function: 5.365, Average Loss: 4.140, avg. samples / sec: 54454.96
Iteration:    840, Loss function: 5.454, Average Loss: 4.143, avg. samples / sec: 54205.77
Iteration:    840, Loss function: 6.110, Average Loss: 4.132, avg. samples / sec: 54483.08
Iteration:    840, Loss function: 4.720, Average Loss: 4.120, avg. samples / sec: 54206.36
Iteration:    840, Loss function: 5.546, Average Loss: 4.133, avg. samples / sec: 54478.26
Iteration:    840, Loss function: 4.816, Average Loss: 4.138, avg. samples / sec: 54253.66
Iteration:    840, Loss function: 5.189, Average Loss: 4.135, avg. samples / sec: 54228.30
Iteration:    840, Loss function: 5.911, Average Loss: 4.161, avg. samples / sec: 54484.52
Iteration:    840, Loss function: 4.590, Average Loss: 4.128, avg. samples / sec: 54162.82
Iteration:    840, Loss function: 4.761, Average Loss: 4.158, avg. samples / sec: 54006.75
Iteration:    840, Loss function: 4.830, Average Loss: 4.136, avg. samples / sec: 54430.96
Iteration:    840, Loss function: 5.506, Average Loss: 4.138, avg. samples / sec: 54298.84
Iteration:    840, Loss function: 5.490, Average Loss: 4.146, avg. samples / sec: 53708.55
Iteration:    840, Loss function: 5.786, Average Loss: 4.130, avg. samples / sec: 53986.21
Iteration:    840, Loss function: 4.828, Average Loss: 4.151, avg. samples / sec: 53610.02
Iteration:    840, Loss function: 5.054, Average Loss: 4.136, avg. samples / sec: 52420.88
Iteration:    860, Loss function: 5.417, Average Loss: 4.173, avg. samples / sec: 53942.46
Iteration:    860, Loss function: 5.433, Average Loss: 4.155, avg. samples / sec: 54142.80
Iteration:    860, Loss function: 4.021, Average Loss: 4.160, avg. samples / sec: 55970.47
Iteration:    860, Loss function: 3.760, Average Loss: 4.158, avg. samples / sec: 54162.30
Iteration:    860, Loss function: 6.163, Average Loss: 4.185, avg. samples / sec: 54109.02
Iteration:    860, Loss function: 4.217, Average Loss: 4.135, avg. samples / sec: 53774.63
Iteration:    860, Loss function: 4.720, Average Loss: 4.158, avg. samples / sec: 53777.68
Iteration:    860, Loss function: 4.824, Average Loss: 4.173, avg. samples / sec: 53734.71
Iteration:    860, Loss function: 4.658, Average Loss: 4.156, avg. samples / sec: 53999.40
Iteration:    860, Loss function: 5.978, Average Loss: 4.170, avg. samples / sec: 53663.13
Iteration:    860, Loss function: 5.460, Average Loss: 4.173, avg. samples / sec: 53655.82
Iteration:    860, Loss function: 4.433, Average Loss: 4.161, avg. samples / sec: 53558.27
Iteration:    860, Loss function: 5.154, Average Loss: 4.182, avg. samples / sec: 53774.15
Iteration:    860, Loss function: 5.558, Average Loss: 4.163, avg. samples / sec: 53825.13
Iteration:    860, Loss function: 5.719, Average Loss: 4.168, avg. samples / sec: 53671.12
Iteration:    860, Loss function: 5.604, Average Loss: 4.146, avg. samples / sec: 53919.90
Iteration:    860, Loss function: 4.064, Average Loss: 4.163, avg. samples / sec: 54271.21
Iteration:    860, Loss function: 5.851, Average Loss: 4.155, avg. samples / sec: 53750.30
Iteration:    860, Loss function: 4.695, Average Loss: 4.183, avg. samples / sec: 53813.52
Iteration:    860, Loss function: 5.010, Average Loss: 4.162, avg. samples / sec: 53750.22
Iteration:    860, Loss function: 5.452, Average Loss: 4.116, avg. samples / sec: 53505.38
Iteration:    860, Loss function: 5.809, Average Loss: 4.160, avg. samples / sec: 53741.08
Iteration:    860, Loss function: 4.846, Average Loss: 4.136, avg. samples / sec: 53672.82
Iteration:    860, Loss function: 4.321, Average Loss: 4.150, avg. samples / sec: 54211.42
Iteration:    860, Loss function: 3.204, Average Loss: 4.173, avg. samples / sec: 54547.82
Iteration:    860, Loss function: 5.421, Average Loss: 4.164, avg. samples / sec: 53740.91
Iteration:    860, Loss function: 5.995, Average Loss: 4.165, avg. samples / sec: 53723.17
Iteration:    860, Loss function: 4.862, Average Loss: 4.163, avg. samples / sec: 53871.82
Iteration:    860, Loss function: 5.178, Average Loss: 4.182, avg. samples / sec: 53592.97
Iteration:    860, Loss function: 4.791, Average Loss: 4.158, avg. samples / sec: 53771.77
Iteration:    880, Loss function: 4.808, Average Loss: 4.206, avg. samples / sec: 54432.22
Iteration:    880, Loss function: 3.649, Average Loss: 4.157, avg. samples / sec: 54453.93
Iteration:    880, Loss function: 5.322, Average Loss: 4.196, avg. samples / sec: 54214.34
Iteration:    880, Loss function: 4.752, Average Loss: 4.190, avg. samples / sec: 54381.87
Iteration:    880, Loss function: 4.936, Average Loss: 4.186, avg. samples / sec: 54317.76
Iteration:    880, Loss function: 5.687, Average Loss: 4.190, avg. samples / sec: 54318.15
Iteration:    880, Loss function: 4.743, Average Loss: 4.200, avg. samples / sec: 54337.67
Iteration:    880, Loss function: 4.665, Average Loss: 4.171, avg. samples / sec: 54293.17
Iteration:    880, Loss function: 6.143, Average Loss: 4.186, avg. samples / sec: 54315.94
Iteration:    880, Loss function: 4.778, Average Loss: 4.190, avg. samples / sec: 54315.54
Iteration:    880, Loss function: 5.511, Average Loss: 4.181, avg. samples / sec: 54234.37
Iteration:    880, Loss function: 4.458, Average Loss: 4.176, avg. samples / sec: 54134.23
Iteration:    880, Loss function: 5.525, Average Loss: 4.180, avg. samples / sec: 54503.94
Iteration:    880, Loss function: 4.962, Average Loss: 4.165, avg. samples / sec: 54294.49
Iteration:    880, Loss function: 5.570, Average Loss: 4.196, avg. samples / sec: 54458.32
Iteration:    880, Loss function: 6.193, Average Loss: 4.184, avg. samples / sec: 54348.57
Iteration:    880, Loss function: 5.737, Average Loss: 4.184, avg. samples / sec: 53976.30
Iteration:    880, Loss function: 4.939, Average Loss: 4.179, avg. samples / sec: 54317.00
Iteration:    880, Loss function: 4.600, Average Loss: 4.184, avg. samples / sec: 54303.13
Iteration:    880, Loss function: 5.334, Average Loss: 4.163, avg. samples / sec: 54335.77
Iteration:    880, Loss function: 5.948, Average Loss: 4.138, avg. samples / sec: 54291.50
Iteration:    880, Loss function: 4.722, Average Loss: 4.187, avg. samples / sec: 54358.57
Iteration:    880, Loss function: 4.843, Average Loss: 4.178, avg. samples / sec: 53886.28
Iteration:    880, Loss function: 6.249, Average Loss: 4.183, avg. samples / sec: 54084.33
Iteration:    880, Loss function: 5.245, Average Loss: 4.191, avg. samples / sec: 54319.35
Iteration:    880, Loss function: 4.858, Average Loss: 4.174, avg. samples / sec: 54315.04
Iteration:    880, Loss function: 4.404, Average Loss: 4.201, avg. samples / sec: 54336.37
Iteration:    880, Loss function: 5.224, Average Loss: 4.206, avg. samples / sec: 54250.28
Iteration:    880, Loss function: 5.991, Average Loss: 4.189, avg. samples / sec: 54228.15
Iteration:    880, Loss function: 4.847, Average Loss: 4.178, avg. samples / sec: 53945.60
Iteration:    900, Loss function: 4.495, Average Loss: 4.216, avg. samples / sec: 52935.03
Iteration:    900, Loss function: 5.618, Average Loss: 4.175, avg. samples / sec: 52840.87
Iteration:    900, Loss function: 4.170, Average Loss: 4.210, avg. samples / sec: 52893.82
Iteration:    900, Loss function: 5.598, Average Loss: 4.200, avg. samples / sec: 52956.87
Iteration:    900, Loss function: 5.609, Average Loss: 4.226, avg. samples / sec: 52918.12
Iteration:    900, Loss function: 5.049, Average Loss: 4.204, avg. samples / sec: 53084.78
Iteration:    900, Loss function: 4.821, Average Loss: 4.215, avg. samples / sec: 52884.79
Iteration:    900, Loss function: 3.788, Average Loss: 4.193, avg. samples / sec: 52899.72
Iteration:    900, Loss function: 5.669, Average Loss: 4.208, avg. samples / sec: 52860.89
Iteration:    900, Loss function: 5.431, Average Loss: 4.196, avg. samples / sec: 52895.35
Iteration:    900, Loss function: 4.296, Average Loss: 4.212, avg. samples / sec: 52844.78
Iteration:    900, Loss function: 5.004, Average Loss: 4.205, avg. samples / sec: 52911.26
Iteration:    900, Loss function: 5.041, Average Loss: 4.159, avg. samples / sec: 52927.91
Iteration:    900, Loss function: 5.676, Average Loss: 4.207, avg. samples / sec: 52908.64
Iteration:    900, Loss function: 5.890, Average Loss: 4.206, avg. samples / sec: 52875.59
Iteration:    900, Loss function: 5.769, Average Loss: 4.202, avg. samples / sec: 52916.78
Iteration:    900, Loss function: 5.573, Average Loss: 4.217, avg. samples / sec: 52774.84
Iteration:    900, Loss function: 3.792, Average Loss: 4.198, avg. samples / sec: 52735.03
Iteration:    900, Loss function: 5.682, Average Loss: 4.183, avg. samples / sec: 52880.01
Iteration:    900, Loss function: 5.741, Average Loss: 4.208, avg. samples / sec: 52904.27
Iteration:    900, Loss function: 5.838, Average Loss: 4.212, avg. samples / sec: 52687.81
Iteration:    900, Loss function: 5.986, Average Loss: 4.222, avg. samples / sec: 52893.27
Iteration:    900, Loss function: 4.141, Average Loss: 4.210, avg. samples / sec: 52861.09
Iteration:    900, Loss function: 5.034, Average Loss: 4.195, avg. samples / sec: 52882.83
Iteration:    900, Loss function: 5.562, Average Loss: 4.223, avg. samples / sec: 52881.78
Iteration:    900, Loss function: 5.490, Average Loss: 4.232, avg. samples / sec: 52446.05
Iteration:    900, Loss function: 4.804, Average Loss: 4.206, avg. samples / sec: 52892.71
Iteration:    900, Loss function: 5.385, Average Loss: 4.196, avg. samples / sec: 53223.79
Iteration:    900, Loss function: 5.711, Average Loss: 4.183, avg. samples / sec: 52632.10
Iteration:    900, Loss function: 6.353, Average Loss: 4.212, avg. samples / sec: 52583.05
:::MLL 1558640050.294 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558640050.295 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 4.756, Average Loss: 4.254, avg. samples / sec: 54259.91
Iteration:    920, Loss function: 5.048, Average Loss: 4.227, avg. samples / sec: 53915.30
Iteration:    920, Loss function: 5.011, Average Loss: 4.194, avg. samples / sec: 53761.50
Iteration:    920, Loss function: 4.906, Average Loss: 4.239, avg. samples / sec: 54058.85
Iteration:    920, Loss function: 4.927, Average Loss: 4.244, avg. samples / sec: 53778.65
Iteration:    920, Loss function: 5.596, Average Loss: 4.227, avg. samples / sec: 53814.30
Iteration:    920, Loss function: 3.534, Average Loss: 4.227, avg. samples / sec: 54070.20
Iteration:    920, Loss function: 4.114, Average Loss: 4.226, avg. samples / sec: 53788.77
Iteration:    920, Loss function: 5.134, Average Loss: 4.205, avg. samples / sec: 54134.69
Iteration:    920, Loss function: 5.866, Average Loss: 4.237, avg. samples / sec: 53597.03
Iteration:    920, Loss function: 5.021, Average Loss: 4.230, avg. samples / sec: 53841.52
Iteration:    920, Loss function: 3.195, Average Loss: 4.214, avg. samples / sec: 53781.15
Iteration:    920, Loss function: 5.880, Average Loss: 4.233, avg. samples / sec: 54004.51
Iteration:    920, Loss function: 4.524, Average Loss: 4.220, avg. samples / sec: 53708.00
Iteration:    920, Loss function: 4.860, Average Loss: 4.213, avg. samples / sec: 53734.62
Iteration:    920, Loss function: 5.365, Average Loss: 4.219, avg. samples / sec: 53937.17
Iteration:    920, Loss function: 3.773, Average Loss: 4.224, avg. samples / sec: 53770.46
Iteration:    920, Loss function: 4.971, Average Loss: 4.205, avg. samples / sec: 53837.94
Iteration:    920, Loss function: 4.778, Average Loss: 4.241, avg. samples / sec: 53861.56
Iteration:    920, Loss function: 5.418, Average Loss: 4.229, avg. samples / sec: 53796.14
Iteration:    920, Loss function: 5.275, Average Loss: 4.183, avg. samples / sec: 53785.40
Iteration:    920, Loss function: 4.480, Average Loss: 4.231, avg. samples / sec: 53800.82
Iteration:    920, Loss function: 5.611, Average Loss: 4.229, avg. samples / sec: 54151.97
Iteration:    920, Loss function: 5.287, Average Loss: 4.221, avg. samples / sec: 53559.69
Iteration:    920, Loss function: 5.195, Average Loss: 4.219, avg. samples / sec: 53819.62
Iteration:    920, Loss function: 4.482, Average Loss: 4.237, avg. samples / sec: 53811.89
Iteration:    920, Loss function: 5.391, Average Loss: 4.223, avg. samples / sec: 53775.57
Iteration:    920, Loss function: 6.227, Average Loss: 4.214, avg. samples / sec: 53805.03
Iteration:    920, Loss function: 4.587, Average Loss: 4.246, avg. samples / sec: 53784.37
Iteration:    920, Loss function: 6.019, Average Loss: 4.231, avg. samples / sec: 53724.14
Iteration:    940, Loss function: 5.479, Average Loss: 4.242, avg. samples / sec: 53934.70
Iteration:    940, Loss function: 5.135, Average Loss: 4.274, avg. samples / sec: 53529.72
Iteration:    940, Loss function: 5.403, Average Loss: 4.253, avg. samples / sec: 53673.13
Iteration:    940, Loss function: 5.270, Average Loss: 4.244, avg. samples / sec: 53595.58
Iteration:    940, Loss function: 5.971, Average Loss: 4.258, avg. samples / sec: 53581.64
Iteration:    940, Loss function: 5.073, Average Loss: 4.247, avg. samples / sec: 53623.89
Iteration:    940, Loss function: 5.718, Average Loss: 4.243, avg. samples / sec: 53586.74
Iteration:    940, Loss function: 4.396, Average Loss: 4.243, avg. samples / sec: 53786.18
Iteration:    940, Loss function: 5.324, Average Loss: 4.236, avg. samples / sec: 53593.26
Iteration:    940, Loss function: 4.240, Average Loss: 4.223, avg. samples / sec: 53517.04
Iteration:    940, Loss function: 4.540, Average Loss: 4.231, avg. samples / sec: 53546.93
Iteration:    940, Loss function: 6.145, Average Loss: 4.209, avg. samples / sec: 53398.21
Iteration:    940, Loss function: 5.916, Average Loss: 4.234, avg. samples / sec: 53558.18
Iteration:    940, Loss function: 4.079, Average Loss: 4.226, avg. samples / sec: 53680.83
Iteration:    940, Loss function: 4.029, Average Loss: 4.255, avg. samples / sec: 53383.77
Iteration:    940, Loss function: 4.510, Average Loss: 4.261, avg. samples / sec: 53678.87
Iteration:    940, Loss function: 5.474, Average Loss: 4.234, avg. samples / sec: 53608.53
Iteration:    940, Loss function: 5.707, Average Loss: 4.255, avg. samples / sec: 53596.72
Iteration:    940, Loss function: 6.580, Average Loss: 4.244, avg. samples / sec: 53568.91
Iteration:    940, Loss function: 5.140, Average Loss: 4.241, avg. samples / sec: 53565.17
Iteration:    940, Loss function: 5.300, Average Loss: 4.250, avg. samples / sec: 53375.58
Iteration:    940, Loss function: 5.498, Average Loss: 4.231, avg. samples / sec: 53572.27
Iteration:    940, Loss function: 5.642, Average Loss: 4.233, avg. samples / sec: 53515.82
Iteration:    940, Loss function: 5.194, Average Loss: 4.251, avg. samples / sec: 53314.94
Iteration:    940, Loss function: 4.809, Average Loss: 4.201, avg. samples / sec: 53495.77
Iteration:    940, Loss function: 6.730, Average Loss: 4.259, avg. samples / sec: 53487.43
Iteration:    940, Loss function: 3.988, Average Loss: 4.245, avg. samples / sec: 53107.72
Iteration:    940, Loss function: 4.315, Average Loss: 4.252, avg. samples / sec: 53577.69
Iteration:    940, Loss function: 4.242, Average Loss: 4.233, avg. samples / sec: 53393.70
Iteration:    940, Loss function: 5.219, Average Loss: 4.248, avg. samples / sec: 53080.44
Iteration:    960, Loss function: 4.228, Average Loss: 4.273, avg. samples / sec: 54946.98
Iteration:    960, Loss function: 5.136, Average Loss: 4.296, avg. samples / sec: 54472.43
Iteration:    960, Loss function: 4.515, Average Loss: 4.265, avg. samples / sec: 54892.66
Iteration:    960, Loss function: 5.637, Average Loss: 4.252, avg. samples / sec: 54774.85
Iteration:    960, Loss function: 6.308, Average Loss: 4.231, avg. samples / sec: 54663.60
Iteration:    960, Loss function: 4.866, Average Loss: 4.261, avg. samples / sec: 54525.29
Iteration:    960, Loss function: 4.690, Average Loss: 4.252, avg. samples / sec: 54578.84
Iteration:    960, Loss function: 3.775, Average Loss: 4.258, avg. samples / sec: 54363.75
Iteration:    960, Loss function: 4.322, Average Loss: 4.276, avg. samples / sec: 54505.90
Iteration:    960, Loss function: 4.492, Average Loss: 4.268, avg. samples / sec: 54484.68
Iteration:    960, Loss function: 5.459, Average Loss: 4.252, avg. samples / sec: 54581.73
Iteration:    960, Loss function: 5.063, Average Loss: 4.271, avg. samples / sec: 54416.73
Iteration:    960, Loss function: 5.310, Average Loss: 4.264, avg. samples / sec: 54484.41
Iteration:    960, Loss function: 5.946, Average Loss: 4.259, avg. samples / sec: 54741.80
Iteration:    960, Loss function: 4.227, Average Loss: 4.272, avg. samples / sec: 54636.75
Iteration:    960, Loss function: 4.633, Average Loss: 4.250, avg. samples / sec: 54534.46
Iteration:    960, Loss function: 4.470, Average Loss: 4.262, avg. samples / sec: 54717.04
Iteration:    960, Loss function: 5.919, Average Loss: 4.216, avg. samples / sec: 54641.56
Iteration:    960, Loss function: 3.676, Average Loss: 4.244, avg. samples / sec: 54384.90
Iteration:    960, Loss function: 5.830, Average Loss: 4.262, avg. samples / sec: 54517.94
Iteration:    960, Loss function: 6.258, Average Loss: 4.260, avg. samples / sec: 54552.96
Iteration:    960, Loss function: 3.869, Average Loss: 4.271, avg. samples / sec: 54497.73
Iteration:    960, Loss function: 4.965, Average Loss: 4.274, avg. samples / sec: 55019.33
Iteration:    960, Loss function: 6.954, Average Loss: 4.247, avg. samples / sec: 54372.60
Iteration:    960, Loss function: 5.840, Average Loss: 4.264, avg. samples / sec: 54279.58
Iteration:    960, Loss function: 6.724, Average Loss: 4.270, avg. samples / sec: 54576.36
Iteration:    960, Loss function: 7.071, Average Loss: 4.266, avg. samples / sec: 54500.99
Iteration:    960, Loss function: 5.732, Average Loss: 4.251, avg. samples / sec: 54552.85
Iteration:    960, Loss function: 6.520, Average Loss: 4.250, avg. samples / sec: 53887.61
Iteration:    960, Loss function: 4.633, Average Loss: 4.276, avg. samples / sec: 53770.77
:::MLL 1558640052.471 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558640052.472 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 4.741, Average Loss: 4.311, avg. samples / sec: 54177.89
Iteration:    980, Loss function: 5.906, Average Loss: 4.247, avg. samples / sec: 54180.27
Iteration:    980, Loss function: 5.891, Average Loss: 4.267, avg. samples / sec: 54216.01
Iteration:    980, Loss function: 4.908, Average Loss: 4.265, avg. samples / sec: 54144.15
Iteration:    980, Loss function: 5.109, Average Loss: 4.284, avg. samples / sec: 54008.53
Iteration:    980, Loss function: 5.204, Average Loss: 4.278, avg. samples / sec: 54103.39
Iteration:    980, Loss function: 6.955, Average Loss: 4.280, avg. samples / sec: 54280.10
Iteration:    980, Loss function: 4.326, Average Loss: 4.294, avg. samples / sec: 54026.07
Iteration:    980, Loss function: 6.230, Average Loss: 4.288, avg. samples / sec: 54089.64
Iteration:    980, Loss function: 4.415, Average Loss: 4.278, avg. samples / sec: 53998.87
Iteration:    980, Loss function: 5.894, Average Loss: 4.279, avg. samples / sec: 53958.84
Iteration:    980, Loss function: 3.908, Average Loss: 4.267, avg. samples / sec: 54030.21
Iteration:    980, Loss function: 5.452, Average Loss: 4.232, avg. samples / sec: 54135.71
Iteration:    980, Loss function: 5.058, Average Loss: 4.291, avg. samples / sec: 54189.20
Iteration:    980, Loss function: 7.444, Average Loss: 4.261, avg. samples / sec: 54157.28
Iteration:    980, Loss function: 3.991, Average Loss: 4.266, avg. samples / sec: 54192.08
Iteration:    980, Loss function: 6.519, Average Loss: 4.288, avg. samples / sec: 53957.58
Iteration:    980, Loss function: 4.260, Average Loss: 4.286, avg. samples / sec: 53968.03
Iteration:    980, Loss function: 4.530, Average Loss: 4.268, avg. samples / sec: 53808.81
Iteration:    980, Loss function: 4.882, Average Loss: 4.282, avg. samples / sec: 53932.45
Iteration:    980, Loss function: 5.436, Average Loss: 4.293, avg. samples / sec: 54100.88
Iteration:    980, Loss function: 4.714, Average Loss: 4.281, avg. samples / sec: 54053.38
Iteration:    980, Loss function: 6.234, Average Loss: 4.293, avg. samples / sec: 54029.79
Iteration:    980, Loss function: 4.388, Average Loss: 4.282, avg. samples / sec: 53991.11
Iteration:    980, Loss function: 4.797, Average Loss: 4.267, avg. samples / sec: 54649.84
Iteration:    980, Loss function: 5.589, Average Loss: 4.279, avg. samples / sec: 53809.90
Iteration:    980, Loss function: 4.683, Average Loss: 4.292, avg. samples / sec: 54656.73
Iteration:    980, Loss function: 4.985, Average Loss: 4.265, avg. samples / sec: 54050.02
Iteration:    980, Loss function: 4.934, Average Loss: 4.285, avg. samples / sec: 53588.39
Iteration:    980, Loss function: 5.549, Average Loss: 4.277, avg. samples / sec: 54000.96
Iteration:   1000, Loss function: 6.606, Average Loss: 4.263, avg. samples / sec: 53841.25
Iteration:   1000, Loss function: 5.414, Average Loss: 4.329, avg. samples / sec: 53698.83
Iteration:   1000, Loss function: 5.287, Average Loss: 4.302, avg. samples / sec: 53848.25
Iteration:   1000, Loss function: 5.108, Average Loss: 4.294, avg. samples / sec: 53861.11
Iteration:   1000, Loss function: 4.938, Average Loss: 4.295, avg. samples / sec: 53859.81
Iteration:   1000, Loss function: 4.774, Average Loss: 4.295, avg. samples / sec: 53762.75
Iteration:   1000, Loss function: 4.951, Average Loss: 4.306, avg. samples / sec: 53806.10
Iteration:   1000, Loss function: 4.398, Average Loss: 4.304, avg. samples / sec: 53884.17
Iteration:   1000, Loss function: 5.867, Average Loss: 4.314, avg. samples / sec: 53778.30
Iteration:   1000, Loss function: 4.748, Average Loss: 4.291, avg. samples / sec: 54093.07
Iteration:   1000, Loss function: 4.313, Average Loss: 4.275, avg. samples / sec: 53839.48
Iteration:   1000, Loss function: 4.462, Average Loss: 4.304, avg. samples / sec: 53842.55
Iteration:   1000, Loss function: 3.927, Average Loss: 4.281, avg. samples / sec: 53622.58
Iteration:   1000, Loss function: 4.574, Average Loss: 4.288, avg. samples / sec: 53556.66
Iteration:   1000, Loss function: 5.328, Average Loss: 4.301, avg. samples / sec: 53885.93
Iteration:   1000, Loss function: 5.245, Average Loss: 4.247, avg. samples / sec: 53709.76
Iteration:   1000, Loss function: 5.812, Average Loss: 4.285, avg. samples / sec: 53701.80
Iteration:   1000, Loss function: 4.536, Average Loss: 4.292, avg. samples / sec: 53907.51
Iteration:   1000, Loss function: 3.482, Average Loss: 4.280, avg. samples / sec: 53697.01
Iteration:   1000, Loss function: 5.082, Average Loss: 4.297, avg. samples / sec: 53797.41
Iteration:   1000, Loss function: 5.360, Average Loss: 4.300, avg. samples / sec: 53658.43
Iteration:   1000, Loss function: 4.747, Average Loss: 4.295, avg. samples / sec: 53546.97
Iteration:   1000, Loss function: 5.565, Average Loss: 4.292, avg. samples / sec: 53834.69
Iteration:   1000, Loss function: 4.647, Average Loss: 4.295, avg. samples / sec: 53821.43
Iteration:   1000, Loss function: 5.040, Average Loss: 4.278, avg. samples / sec: 53825.64
Iteration:   1000, Loss function: 6.047, Average Loss: 4.304, avg. samples / sec: 53836.36
Iteration:   1000, Loss function: 4.717, Average Loss: 4.304, avg. samples / sec: 53685.99
Iteration:   1000, Loss function: 5.661, Average Loss: 4.310, avg. samples / sec: 53701.98
Iteration:   1000, Loss function: 5.466, Average Loss: 4.308, avg. samples / sec: 53801.31
Iteration:   1000, Loss function: 3.992, Average Loss: 4.280, avg. samples / sec: 53642.69
Iteration:   1020, Loss function: 5.248, Average Loss: 4.350, avg. samples / sec: 53435.02
Iteration:   1020, Loss function: 5.348, Average Loss: 4.288, avg. samples / sec: 53453.00
Iteration:   1020, Loss function: 6.629, Average Loss: 4.328, avg. samples / sec: 53423.09
Iteration:   1020, Loss function: 5.031, Average Loss: 4.278, avg. samples / sec: 53141.63
Iteration:   1020, Loss function: 4.339, Average Loss: 4.313, avg. samples / sec: 53347.66
Iteration:   1020, Loss function: 4.730, Average Loss: 4.312, avg. samples / sec: 53307.10
Iteration:   1020, Loss function: 4.866, Average Loss: 4.297, avg. samples / sec: 53477.44
Iteration:   1020, Loss function: 5.221, Average Loss: 4.301, avg. samples / sec: 53568.55
Iteration:   1020, Loss function: 5.715, Average Loss: 4.328, avg. samples / sec: 53261.43
Iteration:   1020, Loss function: 6.893, Average Loss: 4.299, avg. samples / sec: 53265.81
Iteration:   1020, Loss function: 4.945, Average Loss: 4.265, avg. samples / sec: 53372.51
Iteration:   1020, Loss function: 4.240, Average Loss: 4.318, avg. samples / sec: 53482.03
Iteration:   1020, Loss function: 4.664, Average Loss: 4.318, avg. samples / sec: 53104.04
Iteration:   1020, Loss function: 5.988, Average Loss: 4.310, avg. samples / sec: 53186.03
Iteration:   1020, Loss function: 3.940, Average Loss: 4.329, avg. samples / sec: 53421.71
Iteration:   1020, Loss function: 4.961, Average Loss: 4.311, avg. samples / sec: 53335.18
Iteration:   1020, Loss function: 5.791, Average Loss: 4.316, avg. samples / sec: 53323.46
Iteration:   1020, Loss function: 4.542, Average Loss: 4.323, avg. samples / sec: 53389.51
Iteration:   1020, Loss function: 3.033, Average Loss: 4.321, avg. samples / sec: 53377.30
Iteration:   1020, Loss function: 4.842, Average Loss: 4.294, avg. samples / sec: 53346.77
Iteration:   1020, Loss function: 4.412, Average Loss: 4.306, avg. samples / sec: 53067.37
Iteration:   1020, Loss function: 4.266, Average Loss: 4.325, avg. samples / sec: 52977.69
Iteration:   1020, Loss function: 5.002, Average Loss: 4.311, avg. samples / sec: 53197.29
Iteration:   1020, Loss function: 5.979, Average Loss: 4.314, avg. samples / sec: 53167.61
Iteration:   1020, Loss function: 4.557, Average Loss: 4.304, avg. samples / sec: 53061.55
Iteration:   1020, Loss function: 5.598, Average Loss: 4.313, avg. samples / sec: 53103.44
Iteration:   1020, Loss function: 4.872, Average Loss: 4.312, avg. samples / sec: 52821.09
Iteration:   1020, Loss function: 5.680, Average Loss: 4.297, avg. samples / sec: 53002.18
Iteration:   1020, Loss function: 5.224, Average Loss: 4.320, avg. samples / sec: 52942.13
Iteration:   1020, Loss function: 4.992, Average Loss: 4.325, avg. samples / sec: 52831.82
Iteration:   1040, Loss function: 4.630, Average Loss: 4.356, avg. samples / sec: 53526.82
Iteration:   1040, Loss function: 5.068, Average Loss: 4.318, avg. samples / sec: 53757.87
Iteration:   1040, Loss function: 4.990, Average Loss: 4.294, avg. samples / sec: 53584.13
Iteration:   1040, Loss function: 5.029, Average Loss: 4.336, avg. samples / sec: 53771.24
Iteration:   1040, Loss function: 5.200, Average Loss: 4.328, avg. samples / sec: 54090.95
Iteration:   1040, Loss function: 4.574, Average Loss: 4.337, avg. samples / sec: 53952.87
Iteration:   1040, Loss function: 5.090, Average Loss: 4.329, avg. samples / sec: 53552.00
Iteration:   1040, Loss function: 4.368, Average Loss: 4.304, avg. samples / sec: 53487.49
Iteration:   1040, Loss function: 5.171, Average Loss: 4.343, avg. samples / sec: 53483.39
Iteration:   1040, Loss function: 4.855, Average Loss: 4.309, avg. samples / sec: 53569.28
Iteration:   1040, Loss function: 5.830, Average Loss: 4.329, avg. samples / sec: 53551.06
Iteration:   1040, Loss function: 6.667, Average Loss: 4.349, avg. samples / sec: 53640.21
Iteration:   1040, Loss function: 5.851, Average Loss: 4.311, avg. samples / sec: 53657.74
Iteration:   1040, Loss function: 4.471, Average Loss: 4.339, avg. samples / sec: 54089.58
Iteration:   1040, Loss function: 4.744, Average Loss: 4.319, avg. samples / sec: 53887.45
Iteration:   1040, Loss function: 4.864, Average Loss: 4.309, avg. samples / sec: 53702.72
Iteration:   1040, Loss function: 4.591, Average Loss: 4.327, avg. samples / sec: 53590.77
Iteration:   1040, Loss function: 4.431, Average Loss: 4.288, avg. samples / sec: 53512.39
Iteration:   1040, Loss function: 4.215, Average Loss: 4.323, avg. samples / sec: 53844.19
Iteration:   1040, Loss function: 6.326, Average Loss: 4.335, avg. samples / sec: 53492.58
Iteration:   1040, Loss function: 6.063, Average Loss: 4.334, avg. samples / sec: 53571.23
Iteration:   1040, Loss function: 3.381, Average Loss: 4.323, avg. samples / sec: 53720.26
Iteration:   1040, Loss function: 6.239, Average Loss: 4.319, avg. samples / sec: 53788.75
Iteration:   1040, Loss function: 3.454, Average Loss: 4.311, avg. samples / sec: 53852.59
Iteration:   1040, Loss function: 5.015, Average Loss: 4.332, avg. samples / sec: 53874.10
Iteration:   1040, Loss function: 4.603, Average Loss: 4.328, avg. samples / sec: 53577.26
Iteration:   1040, Loss function: 4.820, Average Loss: 4.329, avg. samples / sec: 53709.68
Iteration:   1040, Loss function: 4.311, Average Loss: 4.338, avg. samples / sec: 53508.95
Iteration:   1040, Loss function: 5.055, Average Loss: 4.334, avg. samples / sec: 53465.94
Iteration:   1040, Loss function: 4.748, Average Loss: 4.327, avg. samples / sec: 53331.06
:::MLL 1558640054.671 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558640054.672 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 5.959, Average Loss: 4.327, avg. samples / sec: 52763.18
Iteration:   1060, Loss function: 5.371, Average Loss: 4.374, avg. samples / sec: 52540.84
Iteration:   1060, Loss function: 5.333, Average Loss: 4.312, avg. samples / sec: 52712.42
Iteration:   1060, Loss function: 5.134, Average Loss: 4.350, avg. samples / sec: 52646.22
Iteration:   1060, Loss function: 5.094, Average Loss: 4.335, avg. samples / sec: 52587.46
Iteration:   1060, Loss function: 5.542, Average Loss: 4.367, avg. samples / sec: 52638.51
Iteration:   1060, Loss function: 5.176, Average Loss: 4.332, avg. samples / sec: 52628.88
Iteration:   1060, Loss function: 4.738, Average Loss: 4.338, avg. samples / sec: 52577.61
Iteration:   1060, Loss function: 4.107, Average Loss: 4.320, avg. samples / sec: 52601.99
Iteration:   1060, Loss function: 5.009, Average Loss: 4.339, avg. samples / sec: 52599.55
Iteration:   1060, Loss function: 4.291, Average Loss: 4.348, avg. samples / sec: 52530.40
Iteration:   1060, Loss function: 6.138, Average Loss: 4.362, avg. samples / sec: 52570.32
Iteration:   1060, Loss function: 4.539, Average Loss: 4.319, avg. samples / sec: 52759.90
Iteration:   1060, Loss function: 4.038, Average Loss: 4.307, avg. samples / sec: 52442.67
Iteration:   1060, Loss function: 5.073, Average Loss: 4.350, avg. samples / sec: 52648.32
Iteration:   1060, Loss function: 5.885, Average Loss: 4.341, avg. samples / sec: 52584.09
Iteration:   1060, Loss function: 4.853, Average Loss: 4.327, avg. samples / sec: 52298.25
Iteration:   1060, Loss function: 5.129, Average Loss: 4.351, avg. samples / sec: 52606.90
Iteration:   1060, Loss function: 5.701, Average Loss: 4.305, avg. samples / sec: 52571.85
Iteration:   1060, Loss function: 4.183, Average Loss: 4.349, avg. samples / sec: 52600.02
Iteration:   1060, Loss function: 4.236, Average Loss: 4.343, avg. samples / sec: 52655.17
Iteration:   1060, Loss function: 5.337, Average Loss: 4.339, avg. samples / sec: 52593.13
Iteration:   1060, Loss function: 5.494, Average Loss: 4.337, avg. samples / sec: 52559.02
Iteration:   1060, Loss function: 5.233, Average Loss: 4.332, avg. samples / sec: 52580.12
Iteration:   1060, Loss function: 5.120, Average Loss: 4.339, avg. samples / sec: 52618.05
Iteration:   1060, Loss function: 3.891, Average Loss: 4.353, avg. samples / sec: 52621.51
Iteration:   1060, Loss function: 5.216, Average Loss: 4.344, avg. samples / sec: 52588.29
Iteration:   1060, Loss function: 5.624, Average Loss: 4.344, avg. samples / sec: 52721.97
Iteration:   1060, Loss function: 5.927, Average Loss: 4.323, avg. samples / sec: 52391.28
Iteration:   1060, Loss function: 4.318, Average Loss: 4.357, avg. samples / sec: 51834.02
Iteration:   1080, Loss function: 6.160, Average Loss: 4.389, avg. samples / sec: 54164.04
Iteration:   1080, Loss function: 4.666, Average Loss: 4.349, avg. samples / sec: 54133.46
Iteration:   1080, Loss function: 5.663, Average Loss: 4.348, avg. samples / sec: 54087.67
Iteration:   1080, Loss function: 5.234, Average Loss: 4.364, avg. samples / sec: 54339.24
Iteration:   1080, Loss function: 4.164, Average Loss: 4.325, avg. samples / sec: 53957.91
Iteration:   1080, Loss function: 4.402, Average Loss: 4.316, avg. samples / sec: 54142.20
Iteration:   1080, Loss function: 4.940, Average Loss: 4.375, avg. samples / sec: 54031.02
Iteration:   1080, Loss function: 4.336, Average Loss: 4.351, avg. samples / sec: 54050.25
Iteration:   1080, Loss function: 5.268, Average Loss: 4.335, avg. samples / sec: 54045.38
Iteration:   1080, Loss function: 5.728, Average Loss: 4.374, avg. samples / sec: 54076.59
Iteration:   1080, Loss function: 4.931, Average Loss: 4.349, avg. samples / sec: 54029.19
Iteration:   1080, Loss function: 5.302, Average Loss: 4.344, avg. samples / sec: 53859.30
Iteration:   1080, Loss function: 4.529, Average Loss: 4.324, avg. samples / sec: 54131.96
Iteration:   1080, Loss function: 4.768, Average Loss: 4.366, avg. samples / sec: 54768.38
Iteration:   1080, Loss function: 5.205, Average Loss: 4.367, avg. samples / sec: 54103.82
Iteration:   1080, Loss function: 4.453, Average Loss: 4.354, avg. samples / sec: 54073.95
Iteration:   1080, Loss function: 5.162, Average Loss: 4.345, avg. samples / sec: 54102.14
Iteration:   1080, Loss function: 3.808, Average Loss: 4.352, avg. samples / sec: 54089.37
Iteration:   1080, Loss function: 4.324, Average Loss: 4.353, avg. samples / sec: 54098.65
Iteration:   1080, Loss function: 4.637, Average Loss: 4.337, avg. samples / sec: 53908.31
Iteration:   1080, Loss function: 3.665, Average Loss: 4.360, avg. samples / sec: 53880.09
Iteration:   1080, Loss function: 4.911, Average Loss: 4.363, avg. samples / sec: 53701.25
Iteration:   1080, Loss function: 4.325, Average Loss: 4.344, avg. samples / sec: 54073.52
Iteration:   1080, Loss function: 4.869, Average Loss: 4.359, avg. samples / sec: 54087.90
Iteration:   1080, Loss function: 4.963, Average Loss: 4.366, avg. samples / sec: 53974.56
Iteration:   1080, Loss function: 4.998, Average Loss: 4.369, avg. samples / sec: 54076.07
Iteration:   1080, Loss function: 5.997, Average Loss: 4.357, avg. samples / sec: 54030.40
Iteration:   1080, Loss function: 4.492, Average Loss: 4.359, avg. samples / sec: 54091.03
Iteration:   1080, Loss function: 4.846, Average Loss: 4.339, avg. samples / sec: 53961.50
Iteration:   1080, Loss function: 4.189, Average Loss: 4.336, avg. samples / sec: 54083.41
Iteration:   1100, Loss function: 5.972, Average Loss: 4.403, avg. samples / sec: 54218.52
Iteration:   1100, Loss function: 5.374, Average Loss: 4.373, avg. samples / sec: 54593.21
Iteration:   1100, Loss function: 5.617, Average Loss: 4.379, avg. samples / sec: 54469.80
Iteration:   1100, Loss function: 4.793, Average Loss: 4.368, avg. samples / sec: 54340.59
Iteration:   1100, Loss function: 5.047, Average Loss: 4.325, avg. samples / sec: 54318.57
Iteration:   1100, Loss function: 4.437, Average Loss: 4.380, avg. samples / sec: 54306.58
Iteration:   1100, Loss function: 4.883, Average Loss: 4.385, avg. samples / sec: 54272.57
Iteration:   1100, Loss function: 4.420, Average Loss: 4.336, avg. samples / sec: 54224.75
Iteration:   1100, Loss function: 5.710, Average Loss: 4.351, avg. samples / sec: 54471.02
Iteration:   1100, Loss function: 3.976, Average Loss: 4.356, avg. samples / sec: 54188.45
Iteration:   1100, Loss function: 4.571, Average Loss: 4.359, avg. samples / sec: 54273.97
Iteration:   1100, Loss function: 5.156, Average Loss: 4.362, avg. samples / sec: 54159.32
Iteration:   1100, Loss function: 5.251, Average Loss: 4.364, avg. samples / sec: 54228.84
Iteration:   1100, Loss function: 5.597, Average Loss: 4.373, avg. samples / sec: 54433.25
Iteration:   1100, Loss function: 5.473, Average Loss: 4.347, avg. samples / sec: 54225.88
Iteration:   1100, Loss function: 5.539, Average Loss: 4.368, avg. samples / sec: 54017.85
Iteration:   1100, Loss function: 4.679, Average Loss: 4.356, avg. samples / sec: 54255.61
Iteration:   1100, Loss function: 5.122, Average Loss: 4.352, avg. samples / sec: 54277.59
Iteration:   1100, Loss function: 5.898, Average Loss: 4.368, avg. samples / sec: 54220.48
Iteration:   1100, Loss function: 5.170, Average Loss: 4.351, avg. samples / sec: 54346.16
Iteration:   1100, Loss function: 5.032, Average Loss: 4.382, avg. samples / sec: 54283.36
Iteration:   1100, Loss function: 5.137, Average Loss: 4.334, avg. samples / sec: 54165.83
Iteration:   1100, Loss function: 4.767, Average Loss: 4.365, avg. samples / sec: 54240.43
Iteration:   1100, Loss function: 5.241, Average Loss: 4.379, avg. samples / sec: 54273.03
Iteration:   1100, Loss function: 4.416, Average Loss: 4.377, avg. samples / sec: 54270.25
Iteration:   1100, Loss function: 5.446, Average Loss: 4.382, avg. samples / sec: 54185.52
Iteration:   1100, Loss function: 5.134, Average Loss: 4.363, avg. samples / sec: 54231.95
Iteration:   1100, Loss function: 5.517, Average Loss: 4.371, avg. samples / sec: 54243.31
Iteration:   1100, Loss function: 4.095, Average Loss: 4.366, avg. samples / sec: 54240.66
Iteration:   1100, Loss function: 4.500, Average Loss: 4.350, avg. samples / sec: 54287.52
:::MLL 1558640056.865 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558640056.866 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 5.013, Average Loss: 4.347, avg. samples / sec: 53311.64
Iteration:   1120, Loss function: 5.234, Average Loss: 4.371, avg. samples / sec: 53340.09
Iteration:   1120, Loss function: 5.530, Average Loss: 4.388, avg. samples / sec: 53195.91
Iteration:   1120, Loss function: 6.480, Average Loss: 4.383, avg. samples / sec: 53149.32
Iteration:   1120, Loss function: 3.918, Average Loss: 4.369, avg. samples / sec: 53240.50
Iteration:   1120, Loss function: 4.747, Average Loss: 4.365, avg. samples / sec: 53225.04
Iteration:   1120, Loss function: 6.672, Average Loss: 4.385, avg. samples / sec: 53218.54
Iteration:   1120, Loss function: 5.081, Average Loss: 4.369, avg. samples / sec: 53182.72
Iteration:   1120, Loss function: 6.063, Average Loss: 4.363, avg. samples / sec: 53180.77
Iteration:   1120, Loss function: 4.827, Average Loss: 4.397, avg. samples / sec: 53106.88
Iteration:   1120, Loss function: 4.086, Average Loss: 4.382, avg. samples / sec: 53034.99
Iteration:   1120, Loss function: 4.729, Average Loss: 4.336, avg. samples / sec: 53029.56
Iteration:   1120, Loss function: 4.029, Average Loss: 4.374, avg. samples / sec: 53127.32
Iteration:   1120, Loss function: 6.337, Average Loss: 4.391, avg. samples / sec: 53029.11
Iteration:   1120, Loss function: 6.842, Average Loss: 4.377, avg. samples / sec: 53269.54
Iteration:   1120, Loss function: 4.603, Average Loss: 4.366, avg. samples / sec: 53225.62
Iteration:   1120, Loss function: 5.522, Average Loss: 4.347, avg. samples / sec: 53222.91
Iteration:   1120, Loss function: 5.295, Average Loss: 4.393, avg. samples / sec: 53210.91
Iteration:   1120, Loss function: 6.475, Average Loss: 4.380, avg. samples / sec: 53114.71
Iteration:   1120, Loss function: 4.688, Average Loss: 4.364, avg. samples / sec: 53105.94
Iteration:   1120, Loss function: 6.742, Average Loss: 4.377, avg. samples / sec: 53124.48
Iteration:   1120, Loss function: 4.880, Average Loss: 4.374, avg. samples / sec: 53079.72
Iteration:   1120, Loss function: 3.922, Average Loss: 4.396, avg. samples / sec: 53122.90
Iteration:   1120, Loss function: 4.416, Average Loss: 4.362, avg. samples / sec: 53087.32
Iteration:   1120, Loss function: 4.168, Average Loss: 4.385, avg. samples / sec: 53087.58
Iteration:   1120, Loss function: 5.650, Average Loss: 4.382, avg. samples / sec: 53129.83
Iteration:   1120, Loss function: 4.735, Average Loss: 4.388, avg. samples / sec: 53081.10
Iteration:   1120, Loss function: 4.814, Average Loss: 4.364, avg. samples / sec: 53118.61
Iteration:   1120, Loss function: 4.350, Average Loss: 4.373, avg. samples / sec: 53096.12
Iteration:   1120, Loss function: 4.928, Average Loss: 4.414, avg. samples / sec: 52113.71
Iteration:   1140, Loss function: 4.165, Average Loss: 4.392, avg. samples / sec: 53762.58
Iteration:   1140, Loss function: 4.254, Average Loss: 4.421, avg. samples / sec: 54672.95
Iteration:   1140, Loss function: 5.119, Average Loss: 4.380, avg. samples / sec: 53700.90
Iteration:   1140, Loss function: 5.931, Average Loss: 4.383, avg. samples / sec: 53750.26
Iteration:   1140, Loss function: 5.176, Average Loss: 4.390, avg. samples / sec: 54006.85
Iteration:   1140, Loss function: 4.747, Average Loss: 4.408, avg. samples / sec: 53770.40
Iteration:   1140, Loss function: 5.695, Average Loss: 4.360, avg. samples / sec: 53561.16
Iteration:   1140, Loss function: 5.238, Average Loss: 4.404, avg. samples / sec: 53811.13
Iteration:   1140, Loss function: 4.972, Average Loss: 4.395, avg. samples / sec: 53776.35
Iteration:   1140, Loss function: 5.129, Average Loss: 4.384, avg. samples / sec: 53555.38
Iteration:   1140, Loss function: 5.593, Average Loss: 4.397, avg. samples / sec: 53583.82
Iteration:   1140, Loss function: 4.843, Average Loss: 4.384, avg. samples / sec: 53747.23
Iteration:   1140, Loss function: 5.732, Average Loss: 4.377, avg. samples / sec: 53622.46
Iteration:   1140, Loss function: 5.687, Average Loss: 4.376, avg. samples / sec: 53685.78
Iteration:   1140, Loss function: 6.023, Average Loss: 4.346, avg. samples / sec: 53712.18
Iteration:   1140, Loss function: 4.665, Average Loss: 4.404, avg. samples / sec: 53734.21
Iteration:   1140, Loss function: 5.285, Average Loss: 4.358, avg. samples / sec: 53698.16
Iteration:   1140, Loss function: 4.613, Average Loss: 4.411, avg. samples / sec: 53794.58
Iteration:   1140, Loss function: 4.306, Average Loss: 4.373, avg. samples / sec: 53774.48
Iteration:   1140, Loss function: 4.160, Average Loss: 4.389, avg. samples / sec: 53501.76
Iteration:   1140, Loss function: 5.431, Average Loss: 4.374, avg. samples / sec: 53794.19
Iteration:   1140, Loss function: 4.522, Average Loss: 4.391, avg. samples / sec: 53760.98
Iteration:   1140, Loss function: 4.981, Average Loss: 4.385, avg. samples / sec: 53630.48
Iteration:   1140, Loss function: 5.633, Average Loss: 4.400, avg. samples / sec: 53801.03
Iteration:   1140, Loss function: 4.667, Average Loss: 4.389, avg. samples / sec: 53736.51
Iteration:   1140, Loss function: 4.211, Average Loss: 4.394, avg. samples / sec: 53769.09
Iteration:   1140, Loss function: 5.318, Average Loss: 4.393, avg. samples / sec: 53758.42
Iteration:   1140, Loss function: 4.766, Average Loss: 4.383, avg. samples / sec: 53779.69
Iteration:   1140, Loss function: 6.385, Average Loss: 4.379, avg. samples / sec: 53757.68
Iteration:   1140, Loss function: 4.403, Average Loss: 4.380, avg. samples / sec: 53421.02
Iteration:   1160, Loss function: 5.431, Average Loss: 4.403, avg. samples / sec: 53990.98
Iteration:   1160, Loss function: 4.836, Average Loss: 4.393, avg. samples / sec: 54049.56
Iteration:   1160, Loss function: 4.268, Average Loss: 4.383, avg. samples / sec: 54110.22
Iteration:   1160, Loss function: 5.581, Average Loss: 4.431, avg. samples / sec: 53975.19
Iteration:   1160, Loss function: 4.620, Average Loss: 4.361, avg. samples / sec: 54115.29
Iteration:   1160, Loss function: 5.203, Average Loss: 4.403, avg. samples / sec: 54251.28
Iteration:   1160, Loss function: 5.977, Average Loss: 4.397, avg. samples / sec: 54022.98
Iteration:   1160, Loss function: 4.940, Average Loss: 4.419, avg. samples / sec: 53985.77
Iteration:   1160, Loss function: 3.952, Average Loss: 4.393, avg. samples / sec: 53941.72
Iteration:   1160, Loss function: 5.304, Average Loss: 4.395, avg. samples / sec: 54034.77
Iteration:   1160, Loss function: 5.094, Average Loss: 4.405, avg. samples / sec: 54026.29
Iteration:   1160, Loss function: 4.108, Average Loss: 4.419, avg. samples / sec: 53995.10
Iteration:   1160, Loss function: 5.040, Average Loss: 4.372, avg. samples / sec: 53979.55
Iteration:   1160, Loss function: 4.912, Average Loss: 4.405, avg. samples / sec: 53967.81
Iteration:   1160, Loss function: 5.758, Average Loss: 4.386, avg. samples / sec: 53995.87
Iteration:   1160, Loss function: 5.134, Average Loss: 4.368, avg. samples / sec: 54031.35
Iteration:   1160, Loss function: 5.160, Average Loss: 4.382, avg. samples / sec: 54047.26
Iteration:   1160, Loss function: 5.248, Average Loss: 4.401, avg. samples / sec: 54025.42
Iteration:   1160, Loss function: 4.983, Average Loss: 4.415, avg. samples / sec: 54008.69
Iteration:   1160, Loss function: 5.398, Average Loss: 4.414, avg. samples / sec: 53951.92
Iteration:   1160, Loss function: 5.318, Average Loss: 4.396, avg. samples / sec: 54042.89
Iteration:   1160, Loss function: 5.483, Average Loss: 4.395, avg. samples / sec: 54007.72
Iteration:   1160, Loss function: 4.704, Average Loss: 4.402, avg. samples / sec: 53760.25
Iteration:   1160, Loss function: 4.554, Average Loss: 4.390, avg. samples / sec: 54214.41
Iteration:   1160, Loss function: 5.255, Average Loss: 4.408, avg. samples / sec: 53993.57
Iteration:   1160, Loss function: 5.364, Average Loss: 4.400, avg. samples / sec: 54022.46
Iteration:   1160, Loss function: 4.427, Average Loss: 4.382, avg. samples / sec: 54058.93
Iteration:   1160, Loss function: 5.038, Average Loss: 4.401, avg. samples / sec: 54001.02
Iteration:   1160, Loss function: 4.535, Average Loss: 4.387, avg. samples / sec: 53947.35
Iteration:   1160, Loss function: 5.458, Average Loss: 4.394, avg. samples / sec: 54009.48
Iteration:   1180, Loss function: 3.772, Average Loss: 4.408, avg. samples / sec: 53770.97
Iteration:   1180, Loss function: 5.026, Average Loss: 4.403, avg. samples / sec: 53800.47
Iteration:   1180, Loss function: 4.016, Average Loss: 4.403, avg. samples / sec: 53702.11
Iteration:   1180, Loss function: 5.346, Average Loss: 4.435, avg. samples / sec: 53723.34
Iteration:   1180, Loss function: 4.313, Average Loss: 4.426, avg. samples / sec: 53766.17
Iteration:   1180, Loss function: 4.307, Average Loss: 4.390, avg. samples / sec: 53708.72
Iteration:   1180, Loss function: 5.912, Average Loss: 4.406, avg. samples / sec: 53759.22
Iteration:   1180, Loss function: 6.111, Average Loss: 4.419, avg. samples / sec: 53792.20
Iteration:   1180, Loss function: 4.605, Average Loss: 4.418, avg. samples / sec: 53754.36
Iteration:   1180, Loss function: 7.041, Average Loss: 4.392, avg. samples / sec: 53912.02
Iteration:   1180, Loss function: 4.417, Average Loss: 4.395, avg. samples / sec: 53792.36
Iteration:   1180, Loss function: 4.994, Average Loss: 4.372, avg. samples / sec: 53701.35
Iteration:   1180, Loss function: 4.436, Average Loss: 4.403, avg. samples / sec: 53720.37
Iteration:   1180, Loss function: 5.060, Average Loss: 4.432, avg. samples / sec: 53746.18
Iteration:   1180, Loss function: 3.533, Average Loss: 4.377, avg. samples / sec: 53718.40
Iteration:   1180, Loss function: 5.263, Average Loss: 4.422, avg. samples / sec: 53812.76
Iteration:   1180, Loss function: 5.364, Average Loss: 4.377, avg. samples / sec: 53772.37
Iteration:   1180, Loss function: 4.650, Average Loss: 4.410, avg. samples / sec: 53749.11
Iteration:   1180, Loss function: 5.736, Average Loss: 4.412, avg. samples / sec: 53508.48
Iteration:   1180, Loss function: 3.886, Average Loss: 4.396, avg. samples / sec: 53790.06
Iteration:   1180, Loss function: 5.119, Average Loss: 4.403, avg. samples / sec: 53748.66
Iteration:   1180, Loss function: 4.525, Average Loss: 4.410, avg. samples / sec: 53754.65
Iteration:   1180, Loss function: 4.109, Average Loss: 4.409, avg. samples / sec: 53781.52
Iteration:   1180, Loss function: 4.912, Average Loss: 4.419, avg. samples / sec: 53773.46
Iteration:   1180, Loss function: 4.232, Average Loss: 4.397, avg. samples / sec: 53754.71
Iteration:   1180, Loss function: 5.133, Average Loss: 4.426, avg. samples / sec: 53713.02
Iteration:   1180, Loss function: 5.232, Average Loss: 4.404, avg. samples / sec: 53709.82
Iteration:   1180, Loss function: 3.645, Average Loss: 4.414, avg. samples / sec: 53733.58
Iteration:   1180, Loss function: 5.321, Average Loss: 4.390, avg. samples / sec: 53730.24
Iteration:   1180, Loss function: 4.571, Average Loss: 4.400, avg. samples / sec: 53739.50
:::MLL 1558640059.051 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558640059.051 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 4.621, Average Loss: 4.416, avg. samples / sec: 53258.77
Iteration:   1200, Loss function: 5.446, Average Loss: 4.442, avg. samples / sec: 53307.14
Iteration:   1200, Loss function: 3.798, Average Loss: 4.383, avg. samples / sec: 53303.13
Iteration:   1200, Loss function: 4.826, Average Loss: 4.419, avg. samples / sec: 53440.88
Iteration:   1200, Loss function: 4.157, Average Loss: 4.408, avg. samples / sec: 53186.47
Iteration:   1200, Loss function: 3.888, Average Loss: 4.428, avg. samples / sec: 53149.96
Iteration:   1200, Loss function: 5.020, Average Loss: 4.391, avg. samples / sec: 53231.57
Iteration:   1200, Loss function: 4.820, Average Loss: 4.412, avg. samples / sec: 53093.54
Iteration:   1200, Loss function: 5.070, Average Loss: 4.448, avg. samples / sec: 53076.72
Iteration:   1200, Loss function: 4.063, Average Loss: 4.419, avg. samples / sec: 53304.82
Iteration:   1200, Loss function: 5.621, Average Loss: 4.406, avg. samples / sec: 53083.48
Iteration:   1200, Loss function: 5.567, Average Loss: 4.409, avg. samples / sec: 53265.45
Iteration:   1200, Loss function: 3.690, Average Loss: 4.430, avg. samples / sec: 53278.60
Iteration:   1200, Loss function: 4.295, Average Loss: 4.426, avg. samples / sec: 53157.56
Iteration:   1200, Loss function: 5.049, Average Loss: 4.426, avg. samples / sec: 53251.91
Iteration:   1200, Loss function: 5.021, Average Loss: 4.413, avg. samples / sec: 53013.31
Iteration:   1200, Loss function: 4.628, Average Loss: 4.409, avg. samples / sec: 53316.35
Iteration:   1200, Loss function: 4.097, Average Loss: 4.412, avg. samples / sec: 53223.23
Iteration:   1200, Loss function: 4.721, Average Loss: 4.418, avg. samples / sec: 53154.93
Iteration:   1200, Loss function: 4.547, Average Loss: 4.402, avg. samples / sec: 52979.43
Iteration:   1200, Loss function: 4.739, Average Loss: 4.402, avg. samples / sec: 53068.86
Iteration:   1200, Loss function: 5.153, Average Loss: 4.418, avg. samples / sec: 53023.60
Iteration:   1200, Loss function: 4.973, Average Loss: 4.432, avg. samples / sec: 52768.73
Iteration:   1200, Loss function: 4.484, Average Loss: 4.396, avg. samples / sec: 53001.64
Iteration:   1200, Loss function: 5.650, Average Loss: 4.426, avg. samples / sec: 52667.33
Iteration:   1200, Loss function: 5.353, Average Loss: 4.416, avg. samples / sec: 52559.55
Iteration:   1200, Loss function: 5.152, Average Loss: 4.406, avg. samples / sec: 52688.16
Iteration:   1200, Loss function: 4.709, Average Loss: 4.417, avg. samples / sec: 52206.46
Iteration:   1200, Loss function: 4.581, Average Loss: 4.384, avg. samples / sec: 51693.51
Iteration:   1200, Loss function: 5.099, Average Loss: 4.397, avg. samples / sec: 51612.88
Iteration:   1220, Loss function: 3.873, Average Loss: 4.451, avg. samples / sec: 52199.92
Iteration:   1220, Loss function: 4.804, Average Loss: 4.436, avg. samples / sec: 51960.82
Iteration:   1220, Loss function: 4.898, Average Loss: 4.417, avg. samples / sec: 52078.36
Iteration:   1220, Loss function: 5.719, Average Loss: 4.429, avg. samples / sec: 52480.62
Iteration:   1220, Loss function: 3.543, Average Loss: 4.391, avg. samples / sec: 53434.68
Iteration:   1220, Loss function: 4.474, Average Loss: 4.390, avg. samples / sec: 51847.90
Iteration:   1220, Loss function: 3.950, Average Loss: 4.439, avg. samples / sec: 52280.46
Iteration:   1220, Loss function: 5.295, Average Loss: 4.418, avg. samples / sec: 51957.89
Iteration:   1220, Loss function: 4.373, Average Loss: 4.420, avg. samples / sec: 51890.69
Iteration:   1220, Loss function: 5.054, Average Loss: 4.417, avg. samples / sec: 52070.68
Iteration:   1220, Loss function: 3.848, Average Loss: 4.403, avg. samples / sec: 53448.74
Iteration:   1220, Loss function: 5.509, Average Loss: 4.399, avg. samples / sec: 51831.01
Iteration:   1220, Loss function: 5.436, Average Loss: 4.410, avg. samples / sec: 52173.54
Iteration:   1220, Loss function: 6.361, Average Loss: 4.416, avg. samples / sec: 51853.70
Iteration:   1220, Loss function: 5.642, Average Loss: 4.413, avg. samples / sec: 52423.50
Iteration:   1220, Loss function: 4.307, Average Loss: 4.431, avg. samples / sec: 51917.39
Iteration:   1220, Loss function: 4.016, Average Loss: 4.439, avg. samples / sec: 51864.98
Iteration:   1220, Loss function: 5.136, Average Loss: 4.424, avg. samples / sec: 51678.20
Iteration:   1220, Loss function: 6.318, Average Loss: 4.406, avg. samples / sec: 52036.01
Iteration:   1220, Loss function: 4.959, Average Loss: 4.430, avg. samples / sec: 52067.87
Iteration:   1220, Loss function: 4.698, Average Loss: 4.432, avg. samples / sec: 51865.63
Iteration:   1220, Loss function: 4.441, Average Loss: 4.423, avg. samples / sec: 51806.03
Iteration:   1220, Loss function: 4.928, Average Loss: 4.438, avg. samples / sec: 51816.64
Iteration:   1220, Loss function: 4.606, Average Loss: 4.417, avg. samples / sec: 51872.64
Iteration:   1220, Loss function: 3.581, Average Loss: 4.419, avg. samples / sec: 51478.03
Iteration:   1220, Loss function: 4.638, Average Loss: 4.421, avg. samples / sec: 52883.98
Iteration:   1220, Loss function: 4.488, Average Loss: 4.449, avg. samples / sec: 51553.82
Iteration:   1220, Loss function: 5.267, Average Loss: 4.412, avg. samples / sec: 51740.68
Iteration:   1220, Loss function: 5.329, Average Loss: 4.418, avg. samples / sec: 51773.75
Iteration:   1220, Loss function: 5.975, Average Loss: 4.438, avg. samples / sec: 52120.19
Iteration:   1240, Loss function: 4.767, Average Loss: 4.436, avg. samples / sec: 53769.99
Iteration:   1240, Loss function: 4.728, Average Loss: 4.429, avg. samples / sec: 53970.39
Iteration:   1240, Loss function: 4.658, Average Loss: 4.430, avg. samples / sec: 53893.16
Iteration:   1240, Loss function: 4.672, Average Loss: 4.446, avg. samples / sec: 53966.77
Iteration:   1240, Loss function: 5.041, Average Loss: 4.440, avg. samples / sec: 53892.58
Iteration:   1240, Loss function: 5.823, Average Loss: 4.424, avg. samples / sec: 53608.12
Iteration:   1240, Loss function: 6.559, Average Loss: 4.458, avg. samples / sec: 53408.37
Iteration:   1240, Loss function: 5.048, Average Loss: 4.412, avg. samples / sec: 53659.17
Iteration:   1240, Loss function: 5.155, Average Loss: 4.458, avg. samples / sec: 53897.82
Iteration:   1240, Loss function: 5.466, Average Loss: 4.430, avg. samples / sec: 53651.45
Iteration:   1240, Loss function: 4.366, Average Loss: 4.389, avg. samples / sec: 53599.07
Iteration:   1240, Loss function: 4.534, Average Loss: 4.418, avg. samples / sec: 53639.87
Iteration:   1240, Loss function: 5.077, Average Loss: 4.445, avg. samples / sec: 53559.67
Iteration:   1240, Loss function: 5.714, Average Loss: 4.449, avg. samples / sec: 53590.47
Iteration:   1240, Loss function: 4.525, Average Loss: 4.428, avg. samples / sec: 53607.18
Iteration:   1240, Loss function: 4.021, Average Loss: 4.420, avg. samples / sec: 53856.85
Iteration:   1240, Loss function: 4.209, Average Loss: 4.424, avg. samples / sec: 53793.20
Iteration:   1240, Loss function: 5.599, Average Loss: 4.416, avg. samples / sec: 53732.25
Iteration:   1240, Loss function: 4.914, Average Loss: 4.398, avg. samples / sec: 53507.00
Iteration:   1240, Loss function: 4.784, Average Loss: 4.438, avg. samples / sec: 53679.18
Iteration:   1240, Loss function: 5.616, Average Loss: 4.435, avg. samples / sec: 53644.91
Iteration:   1240, Loss function: 4.795, Average Loss: 4.419, avg. samples / sec: 53630.97
Iteration:   1240, Loss function: 4.988, Average Loss: 4.424, avg. samples / sec: 53624.89
Iteration:   1240, Loss function: 4.202, Average Loss: 4.411, avg. samples / sec: 53635.25
Iteration:   1240, Loss function: 5.047, Average Loss: 4.440, avg. samples / sec: 53626.15
Iteration:   1240, Loss function: 5.030, Average Loss: 4.432, avg. samples / sec: 53622.76
Iteration:   1240, Loss function: 4.694, Average Loss: 4.420, avg. samples / sec: 53649.22
Iteration:   1240, Loss function: 4.519, Average Loss: 4.447, avg. samples / sec: 53590.89
Iteration:   1240, Loss function: 4.622, Average Loss: 4.427, avg. samples / sec: 53665.03
Iteration:   1240, Loss function: 4.531, Average Loss: 4.409, avg. samples / sec: 53181.81
:::MLL 1558640061.269 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558640061.270 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 4.740, Average Loss: 4.439, avg. samples / sec: 53874.10
Iteration:   1260, Loss function: 3.426, Average Loss: 4.435, avg. samples / sec: 53734.28
Iteration:   1260, Loss function: 3.970, Average Loss: 4.464, avg. samples / sec: 53806.90
Iteration:   1260, Loss function: 5.666, Average Loss: 4.438, avg. samples / sec: 53843.39
Iteration:   1260, Loss function: 5.966, Average Loss: 4.456, avg. samples / sec: 53720.90
Iteration:   1260, Loss function: 4.724, Average Loss: 4.454, avg. samples / sec: 53785.77
Iteration:   1260, Loss function: 5.282, Average Loss: 4.425, avg. samples / sec: 53748.09
Iteration:   1260, Loss function: 4.624, Average Loss: 4.451, avg. samples / sec: 53782.18
Iteration:   1260, Loss function: 6.224, Average Loss: 4.432, avg. samples / sec: 53708.57
Iteration:   1260, Loss function: 5.463, Average Loss: 4.395, avg. samples / sec: 53736.28
Iteration:   1260, Loss function: 4.728, Average Loss: 4.466, avg. samples / sec: 53683.14
Iteration:   1260, Loss function: 4.959, Average Loss: 4.426, avg. samples / sec: 54296.79
Iteration:   1260, Loss function: 5.079, Average Loss: 4.450, avg. samples / sec: 53636.23
Iteration:   1260, Loss function: 4.926, Average Loss: 4.404, avg. samples / sec: 53767.51
Iteration:   1260, Loss function: 4.913, Average Loss: 4.441, avg. samples / sec: 53459.95
Iteration:   1260, Loss function: 5.138, Average Loss: 4.447, avg. samples / sec: 53777.19
Iteration:   1260, Loss function: 4.950, Average Loss: 4.427, avg. samples / sec: 53764.84
Iteration:   1260, Loss function: 3.441, Average Loss: 4.427, avg. samples / sec: 53567.53
Iteration:   1260, Loss function: 3.999, Average Loss: 4.441, avg. samples / sec: 53739.50
Iteration:   1260, Loss function: 5.141, Average Loss: 4.431, avg. samples / sec: 53703.64
Iteration:   1260, Loss function: 4.590, Average Loss: 4.443, avg. samples / sec: 53714.82
Iteration:   1260, Loss function: 5.126, Average Loss: 4.429, avg. samples / sec: 53713.47
Iteration:   1260, Loss function: 4.237, Average Loss: 4.450, avg. samples / sec: 53635.81
Iteration:   1260, Loss function: 4.573, Average Loss: 4.424, avg. samples / sec: 53685.46
Iteration:   1260, Loss function: 5.285, Average Loss: 4.440, avg. samples / sec: 53410.74
Iteration:   1260, Loss function: 4.584, Average Loss: 4.455, avg. samples / sec: 53704.75
Iteration:   1260, Loss function: 4.476, Average Loss: 4.439, avg. samples / sec: 53719.16
Iteration:   1260, Loss function: 4.322, Average Loss: 4.428, avg. samples / sec: 53521.65
Iteration:   1260, Loss function: 3.737, Average Loss: 4.431, avg. samples / sec: 53513.44
Iteration:   1260, Loss function: 4.535, Average Loss: 4.425, avg. samples / sec: 53476.49
Iteration:   1280, Loss function: 5.043, Average Loss: 4.455, avg. samples / sec: 54925.99
Iteration:   1280, Loss function: 4.941, Average Loss: 4.477, avg. samples / sec: 54529.34
Iteration:   1280, Loss function: 3.597, Average Loss: 4.440, avg. samples / sec: 54566.33
Iteration:   1280, Loss function: 3.654, Average Loss: 4.450, avg. samples / sec: 54424.57
Iteration:   1280, Loss function: 3.880, Average Loss: 4.462, avg. samples / sec: 54539.76
Iteration:   1280, Loss function: 3.762, Average Loss: 4.444, avg. samples / sec: 54657.28
Iteration:   1280, Loss function: 4.931, Average Loss: 4.477, avg. samples / sec: 54587.08
Iteration:   1280, Loss function: 3.867, Average Loss: 4.466, avg. samples / sec: 54519.53
Iteration:   1280, Loss function: 6.135, Average Loss: 4.416, avg. samples / sec: 54599.73
Iteration:   1280, Loss function: 5.398, Average Loss: 4.440, avg. samples / sec: 54510.18
Iteration:   1280, Loss function: 4.197, Average Loss: 4.458, avg. samples / sec: 54477.40
Iteration:   1280, Loss function: 5.798, Average Loss: 4.445, avg. samples / sec: 54391.40
Iteration:   1280, Loss function: 4.404, Average Loss: 4.428, avg. samples / sec: 54666.91
Iteration:   1280, Loss function: 5.100, Average Loss: 4.447, avg. samples / sec: 54418.14
Iteration:   1280, Loss function: 4.316, Average Loss: 4.399, avg. samples / sec: 54461.38
Iteration:   1280, Loss function: 5.591, Average Loss: 4.436, avg. samples / sec: 54728.75
Iteration:   1280, Loss function: 4.656, Average Loss: 4.454, avg. samples / sec: 54606.98
Iteration:   1280, Loss function: 5.356, Average Loss: 4.455, avg. samples / sec: 54514.13
Iteration:   1280, Loss function: 4.895, Average Loss: 4.435, avg. samples / sec: 54407.13
Iteration:   1280, Loss function: 5.458, Average Loss: 4.447, avg. samples / sec: 54522.50
Iteration:   1280, Loss function: 4.984, Average Loss: 4.459, avg. samples / sec: 54395.96
Iteration:   1280, Loss function: 3.902, Average Loss: 4.434, avg. samples / sec: 54566.01
Iteration:   1280, Loss function: 6.097, Average Loss: 4.447, avg. samples / sec: 54603.66
Iteration:   1280, Loss function: 4.416, Average Loss: 4.435, avg. samples / sec: 54457.67
Iteration:   1280, Loss function: 5.171, Average Loss: 4.444, avg. samples / sec: 54513.01
Iteration:   1280, Loss function: 4.401, Average Loss: 4.448, avg. samples / sec: 54542.61
Iteration:   1280, Loss function: 4.745, Average Loss: 4.468, avg. samples / sec: 54522.37
Iteration:   1280, Loss function: 5.186, Average Loss: 4.436, avg. samples / sec: 54493.95
Iteration:   1280, Loss function: 4.430, Average Loss: 4.429, avg. samples / sec: 54555.68
Iteration:   1280, Loss function: 5.049, Average Loss: 4.452, avg. samples / sec: 53888.93
Iteration:   1300, Loss function: 5.722, Average Loss: 4.469, avg. samples / sec: 51075.25
Iteration:   1300, Loss function: 5.300, Average Loss: 4.447, avg. samples / sec: 50947.14
Iteration:   1300, Loss function: 7.161, Average Loss: 4.470, avg. samples / sec: 50952.21
Iteration:   1300, Loss function: 6.384, Average Loss: 4.444, avg. samples / sec: 50960.65
Iteration:   1300, Loss function: 5.491, Average Loss: 4.484, avg. samples / sec: 50869.59
Iteration:   1300, Loss function: 4.093, Average Loss: 4.452, avg. samples / sec: 50944.79
Iteration:   1300, Loss function: 4.949, Average Loss: 4.479, avg. samples / sec: 50809.18
Iteration:   1300, Loss function: 3.641, Average Loss: 4.459, avg. samples / sec: 50947.66
Iteration:   1300, Loss function: 5.374, Average Loss: 4.454, avg. samples / sec: 50764.36
Iteration:   1300, Loss function: 5.153, Average Loss: 4.473, avg. samples / sec: 50788.71
Iteration:   1300, Loss function: 3.936, Average Loss: 4.455, avg. samples / sec: 51016.91
Iteration:   1300, Loss function: 3.832, Average Loss: 4.450, avg. samples / sec: 50935.27
Iteration:   1300, Loss function: 5.714, Average Loss: 4.459, avg. samples / sec: 51547.58
Iteration:   1300, Loss function: 4.121, Average Loss: 4.467, avg. samples / sec: 50934.55
Iteration:   1300, Loss function: 5.135, Average Loss: 4.443, avg. samples / sec: 50975.87
Iteration:   1300, Loss function: 4.006, Average Loss: 4.433, avg. samples / sec: 51002.01
Iteration:   1300, Loss function: 5.151, Average Loss: 4.481, avg. samples / sec: 50968.41
Iteration:   1300, Loss function: 4.533, Average Loss: 4.459, avg. samples / sec: 50586.97
Iteration:   1300, Loss function: 4.645, Average Loss: 4.437, avg. samples / sec: 50730.75
Iteration:   1300, Loss function: 5.298, Average Loss: 4.442, avg. samples / sec: 50859.85
Iteration:   1300, Loss function: 4.108, Average Loss: 4.457, avg. samples / sec: 50624.78
Iteration:   1300, Loss function: 4.834, Average Loss: 4.441, avg. samples / sec: 50730.95
Iteration:   1300, Loss function: 5.440, Average Loss: 4.429, avg. samples / sec: 50573.44
Iteration:   1300, Loss function: 4.940, Average Loss: 4.451, avg. samples / sec: 50750.54
Iteration:   1300, Loss function: 4.191, Average Loss: 4.447, avg. samples / sec: 50606.10
Iteration:   1300, Loss function: 4.794, Average Loss: 4.404, avg. samples / sec: 50568.04
Iteration:   1300, Loss function: 4.318, Average Loss: 4.440, avg. samples / sec: 50660.47
Iteration:   1300, Loss function: 4.973, Average Loss: 4.465, avg. samples / sec: 50597.99
Iteration:   1300, Loss function: 3.569, Average Loss: 4.455, avg. samples / sec: 50625.15
Iteration:   1300, Loss function: 4.108, Average Loss: 4.452, avg. samples / sec: 50388.39
Iteration:   1320, Loss function: 4.649, Average Loss: 4.478, avg. samples / sec: 54944.56
Iteration:   1320, Loss function: 4.901, Average Loss: 4.484, avg. samples / sec: 54902.00
Iteration:   1320, Loss function: 6.529, Average Loss: 4.459, avg. samples / sec: 55393.90
Iteration:   1320, Loss function: 4.650, Average Loss: 4.431, avg. samples / sec: 55179.59
Iteration:   1320, Loss function: 5.491, Average Loss: 4.475, avg. samples / sec: 54601.53
Iteration:   1320, Loss function: 3.773, Average Loss: 4.460, avg. samples / sec: 55115.19
Iteration:   1320, Loss function: 4.611, Average Loss: 4.461, avg. samples / sec: 55000.87
Iteration:   1320, Loss function: 4.854, Average Loss: 4.447, avg. samples / sec: 54999.62
Iteration:   1320, Loss function: 4.244, Average Loss: 4.458, avg. samples / sec: 54890.33
Iteration:   1320, Loss function: 4.459, Average Loss: 4.490, avg. samples / sec: 54705.49
Iteration:   1320, Loss function: 5.026, Average Loss: 4.451, avg. samples / sec: 54680.91
Iteration:   1320, Loss function: 4.617, Average Loss: 4.416, avg. samples / sec: 55185.98
Iteration:   1320, Loss function: 5.460, Average Loss: 4.460, avg. samples / sec: 54692.24
Iteration:   1320, Loss function: 4.440, Average Loss: 4.465, avg. samples / sec: 54703.37
Iteration:   1320, Loss function: 3.964, Average Loss: 4.442, avg. samples / sec: 55069.43
Iteration:   1320, Loss function: 5.542, Average Loss: 4.442, avg. samples / sec: 54951.93
Iteration:   1320, Loss function: 5.340, Average Loss: 4.455, avg. samples / sec: 54980.23
Iteration:   1320, Loss function: 4.361, Average Loss: 4.473, avg. samples / sec: 54489.17
Iteration:   1320, Loss function: 4.407, Average Loss: 4.452, avg. samples / sec: 54697.46
Iteration:   1320, Loss function: 6.573, Average Loss: 4.470, avg. samples / sec: 55073.54
Iteration:   1320, Loss function: 5.187, Average Loss: 4.443, avg. samples / sec: 54817.91
Iteration:   1320, Loss function: 4.271, Average Loss: 4.452, avg. samples / sec: 54724.12
Iteration:   1320, Loss function: 4.373, Average Loss: 4.461, avg. samples / sec: 54675.75
Iteration:   1320, Loss function: 3.911, Average Loss: 4.474, avg. samples / sec: 54669.52
Iteration:   1320, Loss function: 5.182, Average Loss: 4.462, avg. samples / sec: 54613.74
Iteration:   1320, Loss function: 4.137, Average Loss: 4.456, avg. samples / sec: 54896.04
Iteration:   1320, Loss function: 5.102, Average Loss: 4.485, avg. samples / sec: 54668.12
Iteration:   1320, Loss function: 3.450, Average Loss: 4.438, avg. samples / sec: 54643.49
Iteration:   1320, Loss function: 4.478, Average Loss: 4.450, avg. samples / sec: 54316.50
Iteration:   1320, Loss function: 4.359, Average Loss: 4.463, avg. samples / sec: 54861.70
:::MLL 1558640063.475 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558640063.475 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 3.968, Average Loss: 4.486, avg. samples / sec: 54025.15
Iteration:   1340, Loss function: 4.789, Average Loss: 4.439, avg. samples / sec: 54054.97
Iteration:   1340, Loss function: 3.779, Average Loss: 4.454, avg. samples / sec: 54425.28
Iteration:   1340, Loss function: 4.688, Average Loss: 4.456, avg. samples / sec: 54090.39
Iteration:   1340, Loss function: 3.806, Average Loss: 4.464, avg. samples / sec: 54051.68
Iteration:   1340, Loss function: 5.492, Average Loss: 4.465, avg. samples / sec: 54015.36
Iteration:   1340, Loss function: 3.846, Average Loss: 4.467, avg. samples / sec: 54091.78
Iteration:   1340, Loss function: 3.970, Average Loss: 4.469, avg. samples / sec: 54012.73
Iteration:   1340, Loss function: 4.433, Average Loss: 4.452, avg. samples / sec: 54020.47
Iteration:   1340, Loss function: 4.952, Average Loss: 4.483, avg. samples / sec: 53999.96
Iteration:   1340, Loss function: 4.354, Average Loss: 4.461, avg. samples / sec: 54015.26
Iteration:   1340, Loss function: 6.472, Average Loss: 4.492, avg. samples / sec: 54020.66
Iteration:   1340, Loss function: 4.882, Average Loss: 4.419, avg. samples / sec: 54028.70
Iteration:   1340, Loss function: 3.576, Average Loss: 4.487, avg. samples / sec: 53892.13
Iteration:   1340, Loss function: 5.279, Average Loss: 4.454, avg. samples / sec: 54062.71
Iteration:   1340, Loss function: 4.880, Average Loss: 4.467, avg. samples / sec: 54292.92
Iteration:   1340, Loss function: 4.608, Average Loss: 4.480, avg. samples / sec: 54059.08
Iteration:   1340, Loss function: 5.732, Average Loss: 4.446, avg. samples / sec: 54036.13
Iteration:   1340, Loss function: 5.395, Average Loss: 4.447, avg. samples / sec: 54028.90
Iteration:   1340, Loss function: 4.617, Average Loss: 4.469, avg. samples / sec: 54010.87
Iteration:   1340, Loss function: 3.533, Average Loss: 4.473, avg. samples / sec: 54052.36
Iteration:   1340, Loss function: 4.869, Average Loss: 4.449, avg. samples / sec: 54048.61
Iteration:   1340, Loss function: 4.583, Average Loss: 4.471, avg. samples / sec: 54051.28
Iteration:   1340, Loss function: 4.106, Average Loss: 4.462, avg. samples / sec: 54080.67
Iteration:   1340, Loss function: 4.724, Average Loss: 4.461, avg. samples / sec: 53992.37
Iteration:   1340, Loss function: 5.713, Average Loss: 4.477, avg. samples / sec: 54035.95
Iteration:   1340, Loss function: 3.883, Average Loss: 4.488, avg. samples / sec: 54066.21
Iteration:   1340, Loss function: 3.459, Average Loss: 4.453, avg. samples / sec: 54046.31
Iteration:   1340, Loss function: 3.126, Average Loss: 4.453, avg. samples / sec: 54003.38
Iteration:   1340, Loss function: 4.855, Average Loss: 4.448, avg. samples / sec: 54067.52
Iteration:   1360, Loss function: 4.867, Average Loss: 4.461, avg. samples / sec: 54507.11
Iteration:   1360, Loss function: 4.537, Average Loss: 4.460, avg. samples / sec: 54264.17
Iteration:   1360, Loss function: 5.390, Average Loss: 4.442, avg. samples / sec: 54258.89
Iteration:   1360, Loss function: 6.150, Average Loss: 4.457, avg. samples / sec: 54252.29
Iteration:   1360, Loss function: 4.109, Average Loss: 4.476, avg. samples / sec: 54274.81
Iteration:   1360, Loss function: 4.300, Average Loss: 4.496, avg. samples / sec: 54286.64
Iteration:   1360, Loss function: 4.205, Average Loss: 4.469, avg. samples / sec: 54261.67
Iteration:   1360, Loss function: 3.391, Average Loss: 4.452, avg. samples / sec: 54526.49
Iteration:   1360, Loss function: 4.919, Average Loss: 4.492, avg. samples / sec: 54508.75
Iteration:   1360, Loss function: 4.627, Average Loss: 4.490, avg. samples / sec: 54159.15
Iteration:   1360, Loss function: 5.256, Average Loss: 4.471, avg. samples / sec: 54189.54
Iteration:   1360, Loss function: 4.240, Average Loss: 4.466, avg. samples / sec: 54114.75
Iteration:   1360, Loss function: 5.276, Average Loss: 4.452, avg. samples / sec: 54307.14
Iteration:   1360, Loss function: 4.229, Average Loss: 4.466, avg. samples / sec: 54367.23
Iteration:   1360, Loss function: 4.756, Average Loss: 4.454, avg. samples / sec: 54271.36
Iteration:   1360, Loss function: 5.517, Average Loss: 4.453, avg. samples / sec: 54279.95
Iteration:   1360, Loss function: 4.225, Average Loss: 4.493, avg. samples / sec: 54186.37
Iteration:   1360, Loss function: 5.118, Average Loss: 4.479, avg. samples / sec: 54286.29
Iteration:   1360, Loss function: 4.393, Average Loss: 4.489, avg. samples / sec: 54256.67
Iteration:   1360, Loss function: 4.198, Average Loss: 4.477, avg. samples / sec: 54267.89
Iteration:   1360, Loss function: 4.314, Average Loss: 4.451, avg. samples / sec: 54276.44
Iteration:   1360, Loss function: 4.435, Average Loss: 4.487, avg. samples / sec: 54073.68
Iteration:   1360, Loss function: 5.379, Average Loss: 4.472, avg. samples / sec: 54235.42
Iteration:   1360, Loss function: 4.882, Average Loss: 4.471, avg. samples / sec: 54269.21
Iteration:   1360, Loss function: 3.998, Average Loss: 4.481, avg. samples / sec: 54287.48
Iteration:   1360, Loss function: 4.850, Average Loss: 4.456, avg. samples / sec: 54285.28
Iteration:   1360, Loss function: 3.587, Average Loss: 4.475, avg. samples / sec: 54248.32
Iteration:   1360, Loss function: 4.712, Average Loss: 4.457, avg. samples / sec: 54281.77
Iteration:   1360, Loss function: 4.592, Average Loss: 4.426, avg. samples / sec: 53186.17
Iteration:   1360, Loss function: 4.773, Average Loss: 4.464, avg. samples / sec: 52976.30
Iteration:   1380, Loss function: 4.189, Average Loss: 4.469, avg. samples / sec: 54024.82
Iteration:   1380, Loss function: 4.192, Average Loss: 4.488, avg. samples / sec: 54073.12
Iteration:   1380, Loss function: 5.318, Average Loss: 4.457, avg. samples / sec: 53777.27
Iteration:   1380, Loss function: 4.474, Average Loss: 4.469, avg. samples / sec: 55086.71
Iteration:   1380, Loss function: 5.353, Average Loss: 4.473, avg. samples / sec: 53851.56
Iteration:   1380, Loss function: 4.253, Average Loss: 4.469, avg. samples / sec: 53679.55
Iteration:   1380, Loss function: 5.211, Average Loss: 4.462, avg. samples / sec: 53687.40
Iteration:   1380, Loss function: 5.107, Average Loss: 4.472, avg. samples / sec: 53713.18
Iteration:   1380, Loss function: 4.425, Average Loss: 4.498, avg. samples / sec: 53697.89
Iteration:   1380, Loss function: 3.805, Average Loss: 4.465, avg. samples / sec: 53469.51
Iteration:   1380, Loss function: 4.241, Average Loss: 4.495, avg. samples / sec: 53742.02
Iteration:   1380, Loss function: 4.657, Average Loss: 4.480, avg. samples / sec: 53677.62
Iteration:   1380, Loss function: 4.145, Average Loss: 4.434, avg. samples / sec: 54802.20
Iteration:   1380, Loss function: 4.918, Average Loss: 4.450, avg. samples / sec: 53596.21
Iteration:   1380, Loss function: 4.041, Average Loss: 4.491, avg. samples / sec: 53739.34
Iteration:   1380, Loss function: 4.970, Average Loss: 4.462, avg. samples / sec: 53714.57
Iteration:   1380, Loss function: 5.475, Average Loss: 4.480, avg. samples / sec: 53735.24
Iteration:   1380, Loss function: 3.252, Average Loss: 4.458, avg. samples / sec: 53726.67
Iteration:   1380, Loss function: 4.480, Average Loss: 4.463, avg. samples / sec: 53680.89
Iteration:   1380, Loss function: 5.482, Average Loss: 4.468, avg. samples / sec: 53675.40
Iteration:   1380, Loss function: 3.891, Average Loss: 4.475, avg. samples / sec: 53732.66
Iteration:   1380, Loss function: 4.587, Average Loss: 4.482, avg. samples / sec: 53696.91
Iteration:   1380, Loss function: 4.754, Average Loss: 4.458, avg. samples / sec: 53709.45
Iteration:   1380, Loss function: 5.928, Average Loss: 4.490, avg. samples / sec: 53722.17
Iteration:   1380, Loss function: 4.306, Average Loss: 4.476, avg. samples / sec: 53674.54
Iteration:   1380, Loss function: 4.172, Average Loss: 4.496, avg. samples / sec: 53618.60
Iteration:   1380, Loss function: 5.431, Average Loss: 4.461, avg. samples / sec: 53694.48
Iteration:   1380, Loss function: 5.166, Average Loss: 4.460, avg. samples / sec: 53573.98
Iteration:   1380, Loss function: 4.697, Average Loss: 4.492, avg. samples / sec: 53357.35
Iteration:   1380, Loss function: 3.687, Average Loss: 4.472, avg. samples / sec: 53538.81
:::MLL 1558640065.655 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558640065.655 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 3.720, Average Loss: 4.488, avg. samples / sec: 53446.47
Iteration:   1400, Loss function: 4.862, Average Loss: 4.475, avg. samples / sec: 53616.01
Iteration:   1400, Loss function: 4.396, Average Loss: 4.472, avg. samples / sec: 53524.93
Iteration:   1400, Loss function: 6.038, Average Loss: 4.481, avg. samples / sec: 53519.60
Iteration:   1400, Loss function: 3.052, Average Loss: 4.435, avg. samples / sec: 53539.59
Iteration:   1400, Loss function: 4.943, Average Loss: 4.498, avg. samples / sec: 53509.70
Iteration:   1400, Loss function: 4.556, Average Loss: 4.469, avg. samples / sec: 53232.27
Iteration:   1400, Loss function: 3.725, Average Loss: 4.470, avg. samples / sec: 53462.43
Iteration:   1400, Loss function: 4.250, Average Loss: 4.470, avg. samples / sec: 53410.46
Iteration:   1400, Loss function: 4.647, Average Loss: 4.464, avg. samples / sec: 53447.63
Iteration:   1400, Loss function: 5.779, Average Loss: 4.497, avg. samples / sec: 53463.95
Iteration:   1400, Loss function: 4.501, Average Loss: 4.469, avg. samples / sec: 53595.19
Iteration:   1400, Loss function: 5.364, Average Loss: 4.457, avg. samples / sec: 53347.07
Iteration:   1400, Loss function: 3.623, Average Loss: 4.450, avg. samples / sec: 53462.53
Iteration:   1400, Loss function: 5.496, Average Loss: 4.495, avg. samples / sec: 53518.40
Iteration:   1400, Loss function: 4.921, Average Loss: 4.476, avg. samples / sec: 53333.38
Iteration:   1400, Loss function: 5.295, Average Loss: 4.497, avg. samples / sec: 53615.28
Iteration:   1400, Loss function: 5.033, Average Loss: 4.493, avg. samples / sec: 53566.94
Iteration:   1400, Loss function: 4.643, Average Loss: 4.475, avg. samples / sec: 53503.18
Iteration:   1400, Loss function: 4.342, Average Loss: 4.461, avg. samples / sec: 53491.02
Iteration:   1400, Loss function: 4.871, Average Loss: 4.486, avg. samples / sec: 53479.63
Iteration:   1400, Loss function: 5.083, Average Loss: 4.465, avg. samples / sec: 53448.66
Iteration:   1400, Loss function: 4.541, Average Loss: 4.459, avg. samples / sec: 53430.71
Iteration:   1400, Loss function: 4.658, Average Loss: 4.479, avg. samples / sec: 53425.52
Iteration:   1400, Loss function: 4.346, Average Loss: 4.470, avg. samples / sec: 53412.82
Iteration:   1400, Loss function: 3.484, Average Loss: 4.469, avg. samples / sec: 53652.02
Iteration:   1400, Loss function: 4.504, Average Loss: 4.465, avg. samples / sec: 53581.38
Iteration:   1400, Loss function: 4.211, Average Loss: 4.491, avg. samples / sec: 53585.72
Iteration:   1400, Loss function: 4.388, Average Loss: 4.467, avg. samples / sec: 53445.40
Iteration:   1400, Loss function: 3.629, Average Loss: 4.478, avg. samples / sec: 53413.88
Iteration:   1420, Loss function: 4.892, Average Loss: 4.473, avg. samples / sec: 54816.39
Iteration:   1420, Loss function: 4.533, Average Loss: 4.474, avg. samples / sec: 54794.27
Iteration:   1420, Loss function: 4.811, Average Loss: 4.441, avg. samples / sec: 54769.87
Iteration:   1420, Loss function: 4.312, Average Loss: 4.483, avg. samples / sec: 54905.51
Iteration:   1420, Loss function: 5.097, Average Loss: 4.501, avg. samples / sec: 54800.66
Iteration:   1420, Loss function: 4.843, Average Loss: 4.478, avg. samples / sec: 54722.50
Iteration:   1420, Loss function: 5.368, Average Loss: 4.508, avg. samples / sec: 54758.52
Iteration:   1420, Loss function: 5.168, Average Loss: 4.478, avg. samples / sec: 54634.08
Iteration:   1420, Loss function: 5.189, Average Loss: 4.489, avg. samples / sec: 54737.57
Iteration:   1420, Loss function: 5.099, Average Loss: 4.476, avg. samples / sec: 54775.27
Iteration:   1420, Loss function: 6.511, Average Loss: 4.498, avg. samples / sec: 54609.38
Iteration:   1420, Loss function: 4.904, Average Loss: 4.469, avg. samples / sec: 54762.31
Iteration:   1420, Loss function: 4.981, Average Loss: 4.465, avg. samples / sec: 54954.99
Iteration:   1420, Loss function: 4.658, Average Loss: 4.454, avg. samples / sec: 54822.66
Iteration:   1420, Loss function: 3.801, Average Loss: 4.457, avg. samples / sec: 54789.69
Iteration:   1420, Loss function: 3.818, Average Loss: 4.471, avg. samples / sec: 54662.01
Iteration:   1420, Loss function: 4.025, Average Loss: 4.475, avg. samples / sec: 54842.35
Iteration:   1420, Loss function: 5.501, Average Loss: 4.484, avg. samples / sec: 54734.38
Iteration:   1420, Loss function: 4.443, Average Loss: 4.473, avg. samples / sec: 54777.15
Iteration:   1420, Loss function: 4.524, Average Loss: 4.498, avg. samples / sec: 54700.33
Iteration:   1420, Loss function: 4.559, Average Loss: 4.491, avg. samples / sec: 54754.78
Iteration:   1420, Loss function: 4.117, Average Loss: 4.500, avg. samples / sec: 54688.06
Iteration:   1420, Loss function: 4.465, Average Loss: 4.493, avg. samples / sec: 54828.36
Iteration:   1420, Loss function: 3.416, Average Loss: 4.472, avg. samples / sec: 54778.13
Iteration:   1420, Loss function: 4.229, Average Loss: 4.496, avg. samples / sec: 54659.51
Iteration:   1420, Loss function: 4.669, Average Loss: 4.467, avg. samples / sec: 54842.87
Iteration:   1420, Loss function: 3.751, Average Loss: 4.468, avg. samples / sec: 54793.03
Iteration:   1420, Loss function: 4.792, Average Loss: 4.488, avg. samples / sec: 54754.46
Iteration:   1420, Loss function: 5.958, Average Loss: 4.466, avg. samples / sec: 54695.85
Iteration:   1420, Loss function: 3.786, Average Loss: 4.481, avg. samples / sec: 54804.67
Iteration:   1440, Loss function: 4.543, Average Loss: 4.472, avg. samples / sec: 55142.39
Iteration:   1440, Loss function: 4.110, Average Loss: 4.458, avg. samples / sec: 55106.94
Iteration:   1440, Loss function: 4.052, Average Loss: 4.512, avg. samples / sec: 55051.06
Iteration:   1440, Loss function: 5.459, Average Loss: 4.510, avg. samples / sec: 55038.05
Iteration:   1440, Loss function: 3.909, Average Loss: 4.478, avg. samples / sec: 55005.93
Iteration:   1440, Loss function: 4.949, Average Loss: 4.501, avg. samples / sec: 55037.64
Iteration:   1440, Loss function: 4.703, Average Loss: 4.494, avg. samples / sec: 55029.90
Iteration:   1440, Loss function: 3.815, Average Loss: 4.449, avg. samples / sec: 54983.51
Iteration:   1440, Loss function: 4.690, Average Loss: 4.483, avg. samples / sec: 54996.08
Iteration:   1440, Loss function: 4.501, Average Loss: 4.480, avg. samples / sec: 55022.17
Iteration:   1440, Loss function: 4.259, Average Loss: 4.458, avg. samples / sec: 55049.34
Iteration:   1440, Loss function: 3.728, Average Loss: 4.481, avg. samples / sec: 54995.33
Iteration:   1440, Loss function: 3.890, Average Loss: 4.485, avg. samples / sec: 54973.77
Iteration:   1440, Loss function: 4.479, Average Loss: 4.471, avg. samples / sec: 55001.62
Iteration:   1440, Loss function: 5.186, Average Loss: 4.477, avg. samples / sec: 55148.04
Iteration:   1440, Loss function: 4.368, Average Loss: 4.484, avg. samples / sec: 55099.81
Iteration:   1440, Loss function: 4.491, Average Loss: 4.479, avg. samples / sec: 55032.35
Iteration:   1440, Loss function: 6.053, Average Loss: 4.507, avg. samples / sec: 55071.15
Iteration:   1440, Loss function: 6.367, Average Loss: 4.478, avg. samples / sec: 55104.96
Iteration:   1440, Loss function: 3.903, Average Loss: 4.495, avg. samples / sec: 55087.64
Iteration:   1440, Loss function: 4.770, Average Loss: 4.493, avg. samples / sec: 55010.98
Iteration:   1440, Loss function: 3.672, Average Loss: 4.501, avg. samples / sec: 55021.65
Iteration:   1440, Loss function: 4.574, Average Loss: 4.471, avg. samples / sec: 54848.54
Iteration:   1440, Loss function: 4.954, Average Loss: 4.492, avg. samples / sec: 55004.56
Iteration:   1440, Loss function: 3.855, Average Loss: 4.491, avg. samples / sec: 55057.42
Iteration:   1440, Loss function: 4.589, Average Loss: 4.477, avg. samples / sec: 55032.89
Iteration:   1440, Loss function: 3.742, Average Loss: 4.494, avg. samples / sec: 54999.90
Iteration:   1440, Loss function: 4.564, Average Loss: 4.474, avg. samples / sec: 55033.56
Iteration:   1440, Loss function: 6.147, Average Loss: 4.487, avg. samples / sec: 55077.50
Iteration:   1440, Loss function: 4.681, Average Loss: 4.471, avg. samples / sec: 55000.44
Iteration:   1460, Loss function: 4.521, Average Loss: 4.471, avg. samples / sec: 54893.71
Iteration:   1460, Loss function: 3.983, Average Loss: 4.509, avg. samples / sec: 54976.79
Iteration:   1460, Loss function: 3.744, Average Loss: 4.477, avg. samples / sec: 54918.56
Iteration:   1460, Loss function: 3.716, Average Loss: 4.477, avg. samples / sec: 54868.83
Iteration:   1460, Loss function: 3.827, Average Loss: 4.456, avg. samples / sec: 54887.29
Iteration:   1460, Loss function: 5.287, Average Loss: 4.488, avg. samples / sec: 54863.15
Iteration:   1460, Loss function: 4.505, Average Loss: 4.490, avg. samples / sec: 54884.81
Iteration:   1460, Loss function: 3.667, Average Loss: 4.496, avg. samples / sec: 54849.93
Iteration:   1460, Loss function: 4.297, Average Loss: 4.468, avg. samples / sec: 54790.46
Iteration:   1460, Loss function: 4.735, Average Loss: 4.483, avg. samples / sec: 54859.88
Iteration:   1460, Loss function: 4.668, Average Loss: 4.510, avg. samples / sec: 54791.24
Iteration:   1460, Loss function: 3.922, Average Loss: 4.468, avg. samples / sec: 54856.42
Iteration:   1460, Loss function: 4.415, Average Loss: 4.449, avg. samples / sec: 54812.68
Iteration:   1460, Loss function: 3.465, Average Loss: 4.501, avg. samples / sec: 54786.58
Iteration:   1460, Loss function: 4.182, Average Loss: 4.494, avg. samples / sec: 54975.29
Iteration:   1460, Loss function: 5.144, Average Loss: 4.509, avg. samples / sec: 54875.58
Iteration:   1460, Loss function: 5.054, Average Loss: 4.480, avg. samples / sec: 54832.96
Iteration:   1460, Loss function: 4.510, Average Loss: 4.493, avg. samples / sec: 54868.30
Iteration:   1460, Loss function: 4.900, Average Loss: 4.494, avg. samples / sec: 54868.06
Iteration:   1460, Loss function: 4.900, Average Loss: 4.481, avg. samples / sec: 54732.49
Iteration:   1460, Loss function: 4.325, Average Loss: 4.484, avg. samples / sec: 54746.78
Iteration:   1460, Loss function: 4.285, Average Loss: 4.480, avg. samples / sec: 54878.10
Iteration:   1460, Loss function: 4.305, Average Loss: 4.496, avg. samples / sec: 54823.43
Iteration:   1460, Loss function: 3.693, Average Loss: 4.485, avg. samples / sec: 54852.98
Iteration:   1460, Loss function: 3.853, Average Loss: 4.496, avg. samples / sec: 54869.36
Iteration:   1460, Loss function: 3.877, Average Loss: 4.472, avg. samples / sec: 54840.62
Iteration:   1460, Loss function: 4.254, Average Loss: 4.475, avg. samples / sec: 54853.50
Iteration:   1460, Loss function: 4.407, Average Loss: 4.468, avg. samples / sec: 54885.54
Iteration:   1460, Loss function: 3.866, Average Loss: 4.488, avg. samples / sec: 54849.82
Iteration:   1460, Loss function: 4.141, Average Loss: 4.472, avg. samples / sec: 54780.13
:::MLL 1558640067.805 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558640067.806 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.914, Average Loss: 4.469, avg. samples / sec: 54245.83
Iteration:   1480, Loss function: 4.027, Average Loss: 4.488, avg. samples / sec: 54213.95
Iteration:   1480, Loss function: 6.019, Average Loss: 4.517, avg. samples / sec: 54211.57
Iteration:   1480, Loss function: 4.572, Average Loss: 4.488, avg. samples / sec: 54380.59
Iteration:   1480, Loss function: 4.684, Average Loss: 4.478, avg. samples / sec: 54105.26
Iteration:   1480, Loss function: 5.260, Average Loss: 4.488, avg. samples / sec: 54106.96
Iteration:   1480, Loss function: 5.021, Average Loss: 4.459, avg. samples / sec: 54070.63
Iteration:   1480, Loss function: 4.612, Average Loss: 4.511, avg. samples / sec: 53918.15
Iteration:   1480, Loss function: 3.327, Average Loss: 4.477, avg. samples / sec: 54222.44
Iteration:   1480, Loss function: 4.044, Average Loss: 4.496, avg. samples / sec: 54202.96
Iteration:   1480, Loss function: 3.587, Average Loss: 4.473, avg. samples / sec: 54242.60
Iteration:   1480, Loss function: 4.148, Average Loss: 4.479, avg. samples / sec: 54210.49
Iteration:   1480, Loss function: 5.292, Average Loss: 4.480, avg. samples / sec: 54031.41
Iteration:   1480, Loss function: 4.676, Average Loss: 4.480, avg. samples / sec: 53942.19
Iteration:   1480, Loss function: 4.417, Average Loss: 4.476, avg. samples / sec: 54188.54
Iteration:   1480, Loss function: 4.580, Average Loss: 4.494, avg. samples / sec: 53956.79
Iteration:   1480, Loss function: 3.953, Average Loss: 4.469, avg. samples / sec: 53719.86
Iteration:   1480, Loss function: 4.112, Average Loss: 4.475, avg. samples / sec: 54162.44
Iteration:   1480, Loss function: 4.901, Average Loss: 4.493, avg. samples / sec: 54112.18
Iteration:   1480, Loss function: 5.059, Average Loss: 4.492, avg. samples / sec: 54064.47
Iteration:   1480, Loss function: 4.690, Average Loss: 4.499, avg. samples / sec: 53955.00
Iteration:   1480, Loss function: 4.295, Average Loss: 4.491, avg. samples / sec: 54090.85
Iteration:   1480, Loss function: 4.084, Average Loss: 4.498, avg. samples / sec: 54062.44
Iteration:   1480, Loss function: 4.861, Average Loss: 4.495, avg. samples / sec: 53927.52
Iteration:   1480, Loss function: 4.309, Average Loss: 4.485, avg. samples / sec: 54021.16
Iteration:   1480, Loss function: 3.794, Average Loss: 4.442, avg. samples / sec: 53791.15
Iteration:   1480, Loss function: 4.187, Average Loss: 4.479, avg. samples / sec: 53868.85
Iteration:   1480, Loss function: 4.687, Average Loss: 4.467, avg. samples / sec: 53841.11
Iteration:   1480, Loss function: 3.047, Average Loss: 4.504, avg. samples / sec: 53721.94
Iteration:   1480, Loss function: 3.510, Average Loss: 4.460, avg. samples / sec: 53621.13
Iteration:   1500, Loss function: 4.558, Average Loss: 4.470, avg. samples / sec: 55158.45
Iteration:   1500, Loss function: 4.522, Average Loss: 4.484, avg. samples / sec: 54876.82
Iteration:   1500, Loss function: 5.488, Average Loss: 4.516, avg. samples / sec: 54665.79
Iteration:   1500, Loss function: 4.177, Average Loss: 4.484, avg. samples / sec: 54704.47
Iteration:   1500, Loss function: 4.509, Average Loss: 4.495, avg. samples / sec: 54610.98
Iteration:   1500, Loss function: 4.981, Average Loss: 4.492, avg. samples / sec: 54865.95
Iteration:   1500, Loss function: 3.880, Average Loss: 4.482, avg. samples / sec: 54799.00
Iteration:   1500, Loss function: 5.189, Average Loss: 4.470, avg. samples / sec: 54568.27
Iteration:   1500, Loss function: 4.985, Average Loss: 4.459, avg. samples / sec: 54713.41
Iteration:   1500, Loss function: 4.815, Average Loss: 4.447, avg. samples / sec: 55063.49
Iteration:   1500, Loss function: 3.715, Average Loss: 4.461, avg. samples / sec: 55218.55
Iteration:   1500, Loss function: 3.086, Average Loss: 4.477, avg. samples / sec: 54748.42
Iteration:   1500, Loss function: 3.905, Average Loss: 4.494, avg. samples / sec: 54673.70
Iteration:   1500, Loss function: 4.783, Average Loss: 4.509, avg. samples / sec: 54609.40
Iteration:   1500, Loss function: 4.507, Average Loss: 4.504, avg. samples / sec: 55092.42
Iteration:   1500, Loss function: 5.791, Average Loss: 4.483, avg. samples / sec: 54943.36
Iteration:   1500, Loss function: 4.472, Average Loss: 4.492, avg. samples / sec: 54743.14
Iteration:   1500, Loss function: 5.327, Average Loss: 4.492, avg. samples / sec: 54816.05
Iteration:   1500, Loss function: 5.191, Average Loss: 4.479, avg. samples / sec: 54709.88
Iteration:   1500, Loss function: 4.448, Average Loss: 4.474, avg. samples / sec: 54601.89
Iteration:   1500, Loss function: 5.189, Average Loss: 4.480, avg. samples / sec: 54563.92
Iteration:   1500, Loss function: 3.900, Average Loss: 4.504, avg. samples / sec: 54769.29
Iteration:   1500, Loss function: 4.982, Average Loss: 4.494, avg. samples / sec: 54728.26
Iteration:   1500, Loss function: 4.097, Average Loss: 4.495, avg. samples / sec: 54765.63
Iteration:   1500, Loss function: 4.885, Average Loss: 4.492, avg. samples / sec: 54491.76
Iteration:   1500, Loss function: 5.339, Average Loss: 4.503, avg. samples / sec: 54684.64
Iteration:   1500, Loss function: 4.815, Average Loss: 4.491, avg. samples / sec: 54664.70
Iteration:   1500, Loss function: 4.816, Average Loss: 4.474, avg. samples / sec: 54968.39
Iteration:   1500, Loss function: 4.095, Average Loss: 4.480, avg. samples / sec: 54587.80
Iteration:   1500, Loss function: 4.478, Average Loss: 4.493, avg. samples / sec: 54399.53
Iteration:   1520, Loss function: 4.176, Average Loss: 4.474, avg. samples / sec: 54811.70
Iteration:   1520, Loss function: 4.897, Average Loss: 4.484, avg. samples / sec: 54876.14
Iteration:   1520, Loss function: 4.013, Average Loss: 4.508, avg. samples / sec: 55106.75
Iteration:   1520, Loss function: 3.354, Average Loss: 4.491, avg. samples / sec: 55125.67
Iteration:   1520, Loss function: 3.731, Average Loss: 4.520, avg. samples / sec: 54807.87
Iteration:   1520, Loss function: 4.443, Average Loss: 4.479, avg. samples / sec: 54845.87
Iteration:   1520, Loss function: 4.491, Average Loss: 4.505, avg. samples / sec: 54964.72
Iteration:   1520, Loss function: 5.509, Average Loss: 4.481, avg. samples / sec: 54843.80
Iteration:   1520, Loss function: 4.328, Average Loss: 4.496, avg. samples / sec: 54818.74
Iteration:   1520, Loss function: 5.762, Average Loss: 4.483, avg. samples / sec: 54740.42
Iteration:   1520, Loss function: 5.210, Average Loss: 4.494, avg. samples / sec: 54771.76
Iteration:   1520, Loss function: 4.148, Average Loss: 4.446, avg. samples / sec: 54795.31
Iteration:   1520, Loss function: 3.838, Average Loss: 4.492, avg. samples / sec: 54989.99
Iteration:   1520, Loss function: 3.637, Average Loss: 4.478, avg. samples / sec: 54961.06
Iteration:   1520, Loss function: 4.085, Average Loss: 4.464, avg. samples / sec: 54723.12
Iteration:   1520, Loss function: 5.213, Average Loss: 4.494, avg. samples / sec: 54788.65
Iteration:   1520, Loss function: 4.519, Average Loss: 4.480, avg. samples / sec: 54848.20
Iteration:   1520, Loss function: 3.270, Average Loss: 4.498, avg. samples / sec: 54821.49
Iteration:   1520, Loss function: 5.263, Average Loss: 4.486, avg. samples / sec: 54862.72
Iteration:   1520, Loss function: 5.272, Average Loss: 4.496, avg. samples / sec: 54841.18
Iteration:   1520, Loss function: 4.409, Average Loss: 4.496, avg. samples / sec: 54851.87
Iteration:   1520, Loss function: 4.583, Average Loss: 4.492, avg. samples / sec: 54836.68
Iteration:   1520, Loss function: 4.546, Average Loss: 4.472, avg. samples / sec: 54809.78
Iteration:   1520, Loss function: 4.785, Average Loss: 4.477, avg. samples / sec: 54671.60
Iteration:   1520, Loss function: 3.377, Average Loss: 4.494, avg. samples / sec: 54772.93
Iteration:   1520, Loss function: 6.085, Average Loss: 4.494, avg. samples / sec: 54836.19
Iteration:   1520, Loss function: 4.505, Average Loss: 4.503, avg. samples / sec: 54800.13
Iteration:   1520, Loss function: 5.009, Average Loss: 4.476, avg. samples / sec: 54845.04
Iteration:   1520, Loss function: 4.907, Average Loss: 4.463, avg. samples / sec: 54602.99
Iteration:   1520, Loss function: 4.265, Average Loss: 4.478, avg. samples / sec: 54815.22
:::MLL 1558640069.960 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558640069.960 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.273, Average Loss: 4.471, avg. samples / sec: 54132.75
Iteration:   1540, Loss function: 4.339, Average Loss: 4.496, avg. samples / sec: 54388.90
Iteration:   1540, Loss function: 4.912, Average Loss: 4.480, avg. samples / sec: 54277.80
Iteration:   1540, Loss function: 4.278, Average Loss: 4.507, avg. samples / sec: 54270.86
Iteration:   1540, Loss function: 3.943, Average Loss: 4.496, avg. samples / sec: 54243.45
Iteration:   1540, Loss function: 4.297, Average Loss: 4.482, avg. samples / sec: 54139.66
Iteration:   1540, Loss function: 4.786, Average Loss: 4.502, avg. samples / sec: 54168.77
Iteration:   1540, Loss function: 4.376, Average Loss: 4.464, avg. samples / sec: 54321.55
Iteration:   1540, Loss function: 4.400, Average Loss: 4.490, avg. samples / sec: 54233.64
Iteration:   1540, Loss function: 4.797, Average Loss: 4.452, avg. samples / sec: 54222.73
Iteration:   1540, Loss function: 4.960, Average Loss: 4.478, avg. samples / sec: 54193.33
Iteration:   1540, Loss function: 4.378, Average Loss: 4.457, avg. samples / sec: 54404.38
Iteration:   1540, Loss function: 3.766, Average Loss: 4.520, avg. samples / sec: 54145.11
Iteration:   1540, Loss function: 4.744, Average Loss: 4.497, avg. samples / sec: 54374.53
Iteration:   1540, Loss function: 5.535, Average Loss: 4.498, avg. samples / sec: 54296.58
Iteration:   1540, Loss function: 4.298, Average Loss: 4.480, avg. samples / sec: 54121.13
Iteration:   1540, Loss function: 4.890, Average Loss: 4.495, avg. samples / sec: 54218.79
Iteration:   1540, Loss function: 3.351, Average Loss: 4.478, avg. samples / sec: 54272.62
Iteration:   1540, Loss function: 5.469, Average Loss: 4.483, avg. samples / sec: 54214.80
Iteration:   1540, Loss function: 4.012, Average Loss: 4.476, avg. samples / sec: 54105.63
Iteration:   1540, Loss function: 4.254, Average Loss: 4.496, avg. samples / sec: 54168.29
Iteration:   1540, Loss function: 3.630, Average Loss: 4.484, avg. samples / sec: 54167.75
Iteration:   1540, Loss function: 4.475, Average Loss: 4.471, avg. samples / sec: 54203.08
Iteration:   1540, Loss function: 5.095, Average Loss: 4.498, avg. samples / sec: 54177.29
Iteration:   1540, Loss function: 4.215, Average Loss: 4.495, avg. samples / sec: 54166.00
Iteration:   1540, Loss function: 4.673, Average Loss: 4.481, avg. samples / sec: 54236.92
Iteration:   1540, Loss function: 4.723, Average Loss: 4.504, avg. samples / sec: 54180.79
Iteration:   1540, Loss function: 4.646, Average Loss: 4.479, avg. samples / sec: 54112.76
Iteration:   1540, Loss function: 5.273, Average Loss: 4.502, avg. samples / sec: 53873.83
Iteration:   1540, Loss function: 3.709, Average Loss: 4.490, avg. samples / sec: 53558.04
Iteration:   1560, Loss function: 4.337, Average Loss: 4.464, avg. samples / sec: 54365.18
Iteration:   1560, Loss function: 3.391, Average Loss: 4.464, avg. samples / sec: 54684.32
Iteration:   1560, Loss function: 4.015, Average Loss: 4.480, avg. samples / sec: 54513.22
Iteration:   1560, Loss function: 4.186, Average Loss: 4.476, avg. samples / sec: 54402.72
Iteration:   1560, Loss function: 3.997, Average Loss: 4.503, avg. samples / sec: 54334.26
Iteration:   1560, Loss function: 3.762, Average Loss: 4.491, avg. samples / sec: 54340.77
Iteration:   1560, Loss function: 3.278, Average Loss: 4.519, avg. samples / sec: 54406.40
Iteration:   1560, Loss function: 5.035, Average Loss: 4.482, avg. samples / sec: 54266.47
Iteration:   1560, Loss function: 4.598, Average Loss: 4.490, avg. samples / sec: 54373.84
Iteration:   1560, Loss function: 3.624, Average Loss: 4.491, avg. samples / sec: 54197.89
Iteration:   1560, Loss function: 3.624, Average Loss: 4.475, avg. samples / sec: 54369.06
Iteration:   1560, Loss function: 4.492, Average Loss: 4.456, avg. samples / sec: 54363.96
Iteration:   1560, Loss function: 4.540, Average Loss: 4.472, avg. samples / sec: 54487.55
Iteration:   1560, Loss function: 3.782, Average Loss: 4.463, avg. samples / sec: 54330.28
Iteration:   1560, Loss function: 4.614, Average Loss: 4.499, avg. samples / sec: 54305.26
Iteration:   1560, Loss function: 5.502, Average Loss: 4.458, avg. samples / sec: 54335.18
Iteration:   1560, Loss function: 5.553, Average Loss: 4.504, avg. samples / sec: 54799.57
Iteration:   1560, Loss function: 5.259, Average Loss: 4.488, avg. samples / sec: 54351.36
Iteration:   1560, Loss function: 4.772, Average Loss: 4.503, avg. samples / sec: 54384.52
Iteration:   1560, Loss function: 3.650, Average Loss: 4.491, avg. samples / sec: 54290.32
Iteration:   1560, Loss function: 4.622, Average Loss: 4.497, avg. samples / sec: 54223.15
Iteration:   1560, Loss function: 4.722, Average Loss: 4.483, avg. samples / sec: 54339.75
Iteration:   1560, Loss function: 6.064, Average Loss: 4.496, avg. samples / sec: 54345.20
Iteration:   1560, Loss function: 4.234, Average Loss: 4.495, avg. samples / sec: 54189.77
Iteration:   1560, Loss function: 4.176, Average Loss: 4.506, avg. samples / sec: 54364.80
Iteration:   1560, Loss function: 4.568, Average Loss: 4.477, avg. samples / sec: 54255.48
Iteration:   1560, Loss function: 4.564, Average Loss: 4.484, avg. samples / sec: 54353.52
Iteration:   1560, Loss function: 4.703, Average Loss: 4.494, avg. samples / sec: 54341.13
Iteration:   1560, Loss function: 4.048, Average Loss: 4.481, avg. samples / sec: 54419.17
Iteration:   1560, Loss function: 3.948, Average Loss: 4.488, avg. samples / sec: 54713.84
Iteration:   1580, Loss function: 4.597, Average Loss: 4.460, avg. samples / sec: 54675.56
Iteration:   1580, Loss function: 5.587, Average Loss: 4.503, avg. samples / sec: 54695.51
Iteration:   1580, Loss function: 4.723, Average Loss: 4.490, avg. samples / sec: 54741.00
Iteration:   1580, Loss function: 3.593, Average Loss: 4.496, avg. samples / sec: 54780.30
Iteration:   1580, Loss function: 5.003, Average Loss: 4.461, avg. samples / sec: 54789.22
Iteration:   1580, Loss function: 5.067, Average Loss: 4.475, avg. samples / sec: 54737.23
Iteration:   1580, Loss function: 4.659, Average Loss: 4.483, avg. samples / sec: 54699.54
Iteration:   1580, Loss function: 4.623, Average Loss: 4.517, avg. samples / sec: 54686.13
Iteration:   1580, Loss function: 3.495, Average Loss: 4.473, avg. samples / sec: 54621.12
Iteration:   1580, Loss function: 4.141, Average Loss: 4.480, avg. samples / sec: 54601.48
Iteration:   1580, Loss function: 5.620, Average Loss: 4.476, avg. samples / sec: 54695.15
Iteration:   1580, Loss function: 3.752, Average Loss: 4.459, avg. samples / sec: 54684.03
Iteration:   1580, Loss function: 5.519, Average Loss: 4.450, avg. samples / sec: 54659.57
Iteration:   1580, Loss function: 3.499, Average Loss: 4.491, avg. samples / sec: 54604.04
Iteration:   1580, Loss function: 4.317, Average Loss: 4.500, avg. samples / sec: 54631.03
Iteration:   1580, Loss function: 3.952, Average Loss: 4.493, avg. samples / sec: 54734.92
Iteration:   1580, Loss function: 4.027, Average Loss: 4.502, avg. samples / sec: 54702.15
Iteration:   1580, Loss function: 5.017, Average Loss: 4.487, avg. samples / sec: 54663.41
Iteration:   1580, Loss function: 5.041, Average Loss: 4.490, avg. samples / sec: 54697.82
Iteration:   1580, Loss function: 5.006, Average Loss: 4.497, avg. samples / sec: 54754.25
Iteration:   1580, Loss function: 4.632, Average Loss: 4.494, avg. samples / sec: 54696.36
Iteration:   1580, Loss function: 4.855, Average Loss: 4.466, avg. samples / sec: 54367.61
Iteration:   1580, Loss function: 3.639, Average Loss: 4.483, avg. samples / sec: 54698.40
Iteration:   1580, Loss function: 4.621, Average Loss: 4.501, avg. samples / sec: 54595.18
Iteration:   1580, Loss function: 3.704, Average Loss: 4.498, avg. samples / sec: 54695.34
Iteration:   1580, Loss function: 3.559, Average Loss: 4.475, avg. samples / sec: 54665.57
Iteration:   1580, Loss function: 4.593, Average Loss: 4.488, avg. samples / sec: 54699.50
Iteration:   1580, Loss function: 5.628, Average Loss: 4.482, avg. samples / sec: 54670.41
Iteration:   1580, Loss function: 4.826, Average Loss: 4.496, avg. samples / sec: 54513.96
Iteration:   1580, Loss function: 4.003, Average Loss: 4.486, avg. samples / sec: 54520.90
Iteration:   1600, Loss function: 3.944, Average Loss: 4.456, avg. samples / sec: 54886.22
Iteration:   1600, Loss function: 4.025, Average Loss: 4.496, avg. samples / sec: 54865.78
Iteration:   1600, Loss function: 3.299, Average Loss: 4.501, avg. samples / sec: 54816.39
Iteration:   1600, Loss function: 4.118, Average Loss: 4.474, avg. samples / sec: 54861.01
Iteration:   1600, Loss function: 5.102, Average Loss: 4.487, avg. samples / sec: 54770.27
Iteration:   1600, Loss function: 4.159, Average Loss: 4.470, avg. samples / sec: 54810.55
Iteration:   1600, Loss function: 4.340, Average Loss: 4.457, avg. samples / sec: 54842.31
Iteration:   1600, Loss function: 5.031, Average Loss: 4.520, avg. samples / sec: 54794.27
Iteration:   1600, Loss function: 5.087, Average Loss: 4.453, avg. samples / sec: 54853.43
Iteration:   1600, Loss function: 3.982, Average Loss: 4.484, avg. samples / sec: 54788.30
Iteration:   1600, Loss function: 4.525, Average Loss: 4.480, avg. samples / sec: 54806.25
Iteration:   1600, Loss function: 4.670, Average Loss: 4.490, avg. samples / sec: 54838.85
Iteration:   1600, Loss function: 5.395, Average Loss: 4.503, avg. samples / sec: 54823.34
Iteration:   1600, Loss function: 4.796, Average Loss: 4.484, avg. samples / sec: 54810.15
Iteration:   1600, Loss function: 4.305, Average Loss: 4.489, avg. samples / sec: 54801.49
Iteration:   1600, Loss function: 4.865, Average Loss: 4.493, avg. samples / sec: 54805.61
Iteration:   1600, Loss function: 6.438, Average Loss: 4.488, avg. samples / sec: 54780.32
Iteration:   1600, Loss function: 4.354, Average Loss: 4.496, avg. samples / sec: 55006.90
Iteration:   1600, Loss function: 4.170, Average Loss: 4.477, avg. samples / sec: 54860.71
Iteration:   1600, Loss function: 4.366, Average Loss: 4.501, avg. samples / sec: 54782.24
Iteration:   1600, Loss function: 4.013, Average Loss: 4.462, avg. samples / sec: 54793.86
Iteration:   1600, Loss function: 3.252, Average Loss: 4.482, avg. samples / sec: 54566.20
Iteration:   1600, Loss function: 3.720, Average Loss: 4.461, avg. samples / sec: 54544.68
Iteration:   1600, Loss function: 4.700, Average Loss: 4.501, avg. samples / sec: 54757.25
Iteration:   1600, Loss function: 4.744, Average Loss: 4.500, avg. samples / sec: 54819.12
Iteration:   1600, Loss function: 3.777, Average Loss: 4.482, avg. samples / sec: 54779.10
Iteration:   1600, Loss function: 5.504, Average Loss: 4.484, avg. samples / sec: 54949.98
Iteration:   1600, Loss function: 5.695, Average Loss: 4.482, avg. samples / sec: 54810.27
Iteration:   1600, Loss function: 4.643, Average Loss: 4.488, avg. samples / sec: 54785.43
Iteration:   1600, Loss function: 4.860, Average Loss: 4.502, avg. samples / sec: 54670.88
:::MLL 1558640072.116 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558640072.117 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 4.039, Average Loss: 4.458, avg. samples / sec: 54292.44
Iteration:   1620, Loss function: 4.350, Average Loss: 4.497, avg. samples / sec: 54375.43
Iteration:   1620, Loss function: 3.747, Average Loss: 4.490, avg. samples / sec: 54393.36
Iteration:   1620, Loss function: 4.059, Average Loss: 4.495, avg. samples / sec: 54577.99
Iteration:   1620, Loss function: 3.789, Average Loss: 4.489, avg. samples / sec: 54264.03
Iteration:   1620, Loss function: 3.884, Average Loss: 4.484, avg. samples / sec: 54348.38
Iteration:   1620, Loss function: 6.036, Average Loss: 4.486, avg. samples / sec: 54335.10
Iteration:   1620, Loss function: 4.165, Average Loss: 4.469, avg. samples / sec: 54313.63
Iteration:   1620, Loss function: 3.711, Average Loss: 4.508, avg. samples / sec: 54362.16
Iteration:   1620, Loss function: 4.748, Average Loss: 4.516, avg. samples / sec: 54312.40
Iteration:   1620, Loss function: 4.573, Average Loss: 4.485, avg. samples / sec: 54311.35
Iteration:   1620, Loss function: 4.591, Average Loss: 4.457, avg. samples / sec: 54294.44
Iteration:   1620, Loss function: 4.266, Average Loss: 4.474, avg. samples / sec: 54231.81
Iteration:   1620, Loss function: 4.179, Average Loss: 4.461, avg. samples / sec: 54441.31
Iteration:   1620, Loss function: 5.305, Average Loss: 4.490, avg. samples / sec: 54387.60
Iteration:   1620, Loss function: 3.849, Average Loss: 4.482, avg. samples / sec: 54339.98
Iteration:   1620, Loss function: 3.767, Average Loss: 4.490, avg. samples / sec: 54355.42
Iteration:   1620, Loss function: 3.722, Average Loss: 4.479, avg. samples / sec: 54377.47
Iteration:   1620, Loss function: 4.173, Average Loss: 4.486, avg. samples / sec: 54332.18
Iteration:   1620, Loss function: 4.198, Average Loss: 4.499, avg. samples / sec: 54366.83
Iteration:   1620, Loss function: 4.337, Average Loss: 4.499, avg. samples / sec: 54477.99
Iteration:   1620, Loss function: 3.530, Average Loss: 4.461, avg. samples / sec: 54119.39
Iteration:   1620, Loss function: 5.724, Average Loss: 4.484, avg. samples / sec: 54350.73
Iteration:   1620, Loss function: 5.590, Average Loss: 4.461, avg. samples / sec: 54329.46
Iteration:   1620, Loss function: 4.694, Average Loss: 4.500, avg. samples / sec: 54315.85
Iteration:   1620, Loss function: 3.976, Average Loss: 4.501, avg. samples / sec: 54299.84
Iteration:   1620, Loss function: 4.194, Average Loss: 4.475, avg. samples / sec: 54295.80
Iteration:   1620, Loss function: 4.265, Average Loss: 4.484, avg. samples / sec: 54336.94
Iteration:   1620, Loss function: 3.948, Average Loss: 4.477, avg. samples / sec: 54321.50
Iteration:   1620, Loss function: 4.308, Average Loss: 4.486, avg. samples / sec: 54293.06
Iteration:   1640, Loss function: 3.552, Average Loss: 4.462, avg. samples / sec: 54841.58
Iteration:   1640, Loss function: 4.494, Average Loss: 4.471, avg. samples / sec: 54921.77
Iteration:   1640, Loss function: 5.276, Average Loss: 4.491, avg. samples / sec: 54856.74
Iteration:   1640, Loss function: 2.908, Average Loss: 4.483, avg. samples / sec: 54882.10
Iteration:   1640, Loss function: 4.473, Average Loss: 4.472, avg. samples / sec: 54918.97
Iteration:   1640, Loss function: 5.113, Average Loss: 4.511, avg. samples / sec: 54863.38
Iteration:   1640, Loss function: 6.920, Average Loss: 4.460, avg. samples / sec: 54880.84
Iteration:   1640, Loss function: 4.003, Average Loss: 4.460, avg. samples / sec: 54943.14
Iteration:   1640, Loss function: 4.068, Average Loss: 4.488, avg. samples / sec: 54835.61
Iteration:   1640, Loss function: 4.027, Average Loss: 4.515, avg. samples / sec: 54819.85
Iteration:   1640, Loss function: 4.491, Average Loss: 4.492, avg. samples / sec: 54674.61
Iteration:   1640, Loss function: 4.154, Average Loss: 4.488, avg. samples / sec: 54880.56
Iteration:   1640, Loss function: 4.138, Average Loss: 4.480, avg. samples / sec: 54842.27
Iteration:   1640, Loss function: 4.796, Average Loss: 4.495, avg. samples / sec: 54851.08
Iteration:   1640, Loss function: 4.711, Average Loss: 4.483, avg. samples / sec: 54879.32
Iteration:   1640, Loss function: 6.449, Average Loss: 4.501, avg. samples / sec: 54907.31
Iteration:   1640, Loss function: 3.913, Average Loss: 4.488, avg. samples / sec: 54796.72
Iteration:   1640, Loss function: 5.427, Average Loss: 4.461, avg. samples / sec: 54859.41
Iteration:   1640, Loss function: 3.601, Average Loss: 4.476, avg. samples / sec: 54817.42
Iteration:   1640, Loss function: 3.753, Average Loss: 4.479, avg. samples / sec: 54909.17
Iteration:   1640, Loss function: 4.700, Average Loss: 4.485, avg. samples / sec: 54923.34
Iteration:   1640, Loss function: 3.520, Average Loss: 4.500, avg. samples / sec: 54840.03
Iteration:   1640, Loss function: 4.143, Average Loss: 4.493, avg. samples / sec: 54869.51
Iteration:   1640, Loss function: 4.830, Average Loss: 4.459, avg. samples / sec: 54840.45
Iteration:   1640, Loss function: 4.341, Average Loss: 4.493, avg. samples / sec: 54790.80
Iteration:   1640, Loss function: 3.476, Average Loss: 4.479, avg. samples / sec: 54582.45
Iteration:   1640, Loss function: 3.863, Average Loss: 4.492, avg. samples / sec: 54570.81
Iteration:   1640, Loss function: 4.725, Average Loss: 4.491, avg. samples / sec: 54564.70
Iteration:   1640, Loss function: 4.693, Average Loss: 4.474, avg. samples / sec: 54883.27
Iteration:   1640, Loss function: 3.369, Average Loss: 4.483, avg. samples / sec: 54879.81
Iteration:   1660, Loss function: 5.292, Average Loss: 4.486, avg. samples / sec: 54866.59
Iteration:   1660, Loss function: 5.929, Average Loss: 4.483, avg. samples / sec: 54818.31
Iteration:   1660, Loss function: 4.371, Average Loss: 4.492, avg. samples / sec: 54902.11
Iteration:   1660, Loss function: 4.201, Average Loss: 4.491, avg. samples / sec: 55077.52
Iteration:   1660, Loss function: 4.162, Average Loss: 4.492, avg. samples / sec: 55062.09
Iteration:   1660, Loss function: 3.715, Average Loss: 4.479, avg. samples / sec: 55058.74
Iteration:   1660, Loss function: 3.275, Average Loss: 4.469, avg. samples / sec: 54817.57
Iteration:   1660, Loss function: 4.611, Average Loss: 4.470, avg. samples / sec: 54745.31
Iteration:   1660, Loss function: 3.131, Average Loss: 4.479, avg. samples / sec: 54991.49
Iteration:   1660, Loss function: 3.101, Average Loss: 4.513, avg. samples / sec: 54839.69
Iteration:   1660, Loss function: 4.510, Average Loss: 4.457, avg. samples / sec: 54779.10
Iteration:   1660, Loss function: 3.710, Average Loss: 4.461, avg. samples / sec: 54743.55
Iteration:   1660, Loss function: 3.960, Average Loss: 4.485, avg. samples / sec: 54729.98
Iteration:   1660, Loss function: 3.523, Average Loss: 4.458, avg. samples / sec: 54498.17
Iteration:   1660, Loss function: 5.500, Average Loss: 4.505, avg. samples / sec: 54678.21
Iteration:   1660, Loss function: 4.766, Average Loss: 4.470, avg. samples / sec: 54868.34
Iteration:   1660, Loss function: 4.701, Average Loss: 4.492, avg. samples / sec: 54804.11
Iteration:   1660, Loss function: 5.543, Average Loss: 4.491, avg. samples / sec: 54820.51
Iteration:   1660, Loss function: 5.658, Average Loss: 4.474, avg. samples / sec: 54887.89
Iteration:   1660, Loss function: 4.717, Average Loss: 4.464, avg. samples / sec: 54838.92
Iteration:   1660, Loss function: 3.375, Average Loss: 4.475, avg. samples / sec: 54787.52
Iteration:   1660, Loss function: 4.773, Average Loss: 4.502, avg. samples / sec: 54826.67
Iteration:   1660, Loss function: 5.405, Average Loss: 4.497, avg. samples / sec: 54785.69
Iteration:   1660, Loss function: 4.061, Average Loss: 4.461, avg. samples / sec: 54805.18
Iteration:   1660, Loss function: 4.374, Average Loss: 4.492, avg. samples / sec: 54805.73
Iteration:   1660, Loss function: 4.613, Average Loss: 4.482, avg. samples / sec: 54867.33
Iteration:   1660, Loss function: 4.420, Average Loss: 4.477, avg. samples / sec: 54760.10
Iteration:   1660, Loss function: 3.516, Average Loss: 4.487, avg. samples / sec: 54768.72
Iteration:   1660, Loss function: 4.648, Average Loss: 4.496, avg. samples / sec: 54677.37
Iteration:   1660, Loss function: 3.845, Average Loss: 4.490, avg. samples / sec: 54615.85
:::MLL 1558640074.279 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558640074.279 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 5.120, Average Loss: 4.457, avg. samples / sec: 53709.60
Iteration:   1680, Loss function: 3.966, Average Loss: 4.490, avg. samples / sec: 53535.01
Iteration:   1680, Loss function: 4.017, Average Loss: 4.505, avg. samples / sec: 53640.42
Iteration:   1680, Loss function: 5.436, Average Loss: 4.468, avg. samples / sec: 53420.68
Iteration:   1680, Loss function: 4.165, Average Loss: 4.474, avg. samples / sec: 53664.56
Iteration:   1680, Loss function: 2.579, Average Loss: 4.477, avg. samples / sec: 53359.29
Iteration:   1680, Loss function: 6.100, Average Loss: 4.450, avg. samples / sec: 53452.69
Iteration:   1680, Loss function: 3.673, Average Loss: 4.483, avg. samples / sec: 53385.97
Iteration:   1680, Loss function: 3.969, Average Loss: 4.508, avg. samples / sec: 53427.75
Iteration:   1680, Loss function: 3.909, Average Loss: 4.499, avg. samples / sec: 53589.94
Iteration:   1680, Loss function: 4.845, Average Loss: 4.486, avg. samples / sec: 53473.54
Iteration:   1680, Loss function: 4.293, Average Loss: 4.467, avg. samples / sec: 53520.56
Iteration:   1680, Loss function: 5.124, Average Loss: 4.483, avg. samples / sec: 53320.65
Iteration:   1680, Loss function: 4.476, Average Loss: 4.461, avg. samples / sec: 53441.20
Iteration:   1680, Loss function: 5.257, Average Loss: 4.464, avg. samples / sec: 53361.37
Iteration:   1680, Loss function: 5.282, Average Loss: 4.475, avg. samples / sec: 53344.31
Iteration:   1680, Loss function: 4.482, Average Loss: 4.491, avg. samples / sec: 53333.51
Iteration:   1680, Loss function: 3.446, Average Loss: 4.462, avg. samples / sec: 53511.96
Iteration:   1680, Loss function: 4.177, Average Loss: 4.492, avg. samples / sec: 53716.03
Iteration:   1680, Loss function: 3.903, Average Loss: 4.461, avg. samples / sec: 53450.34
Iteration:   1680, Loss function: 4.685, Average Loss: 4.472, avg. samples / sec: 53440.84
Iteration:   1680, Loss function: 3.654, Average Loss: 4.475, avg. samples / sec: 53245.99
Iteration:   1680, Loss function: 4.811, Average Loss: 4.495, avg. samples / sec: 53550.70
Iteration:   1680, Loss function: 4.346, Average Loss: 4.489, avg. samples / sec: 53382.03
Iteration:   1680, Loss function: 4.948, Average Loss: 4.494, avg. samples / sec: 53419.12
Iteration:   1680, Loss function: 3.573, Average Loss: 4.476, avg. samples / sec: 53388.64
Iteration:   1680, Loss function: 4.262, Average Loss: 4.487, avg. samples / sec: 53443.57
Iteration:   1680, Loss function: 3.272, Average Loss: 4.482, avg. samples / sec: 53352.08
Iteration:   1680, Loss function: 4.045, Average Loss: 4.490, avg. samples / sec: 53391.56
Iteration:   1680, Loss function: 4.755, Average Loss: 4.483, avg. samples / sec: 53386.50
Iteration:   1700, Loss function: 4.553, Average Loss: 4.452, avg. samples / sec: 54491.03
Iteration:   1700, Loss function: 4.369, Average Loss: 4.483, avg. samples / sec: 54440.44
Iteration:   1700, Loss function: 4.673, Average Loss: 4.504, avg. samples / sec: 54529.36
Iteration:   1700, Loss function: 3.865, Average Loss: 4.469, avg. samples / sec: 54511.91
Iteration:   1700, Loss function: 4.066, Average Loss: 4.481, avg. samples / sec: 54515.54
Iteration:   1700, Loss function: 5.323, Average Loss: 4.483, avg. samples / sec: 54547.82
Iteration:   1700, Loss function: 4.351, Average Loss: 4.469, avg. samples / sec: 54574.84
Iteration:   1700, Loss function: 5.971, Average Loss: 4.477, avg. samples / sec: 54505.63
Iteration:   1700, Loss function: 3.990, Average Loss: 4.460, avg. samples / sec: 54529.61
Iteration:   1700, Loss function: 5.997, Average Loss: 4.469, avg. samples / sec: 54483.06
Iteration:   1700, Loss function: 4.489, Average Loss: 4.458, avg. samples / sec: 54520.67
Iteration:   1700, Loss function: 3.960, Average Loss: 4.499, avg. samples / sec: 54364.15
Iteration:   1700, Loss function: 5.442, Average Loss: 4.489, avg. samples / sec: 54493.85
Iteration:   1700, Loss function: 3.216, Average Loss: 4.478, avg. samples / sec: 54687.95
Iteration:   1700, Loss function: 3.848, Average Loss: 4.491, avg. samples / sec: 54440.49
Iteration:   1700, Loss function: 3.675, Average Loss: 4.490, avg. samples / sec: 54544.70
Iteration:   1700, Loss function: 3.103, Average Loss: 4.446, avg. samples / sec: 54328.00
Iteration:   1700, Loss function: 5.221, Average Loss: 4.487, avg. samples / sec: 54517.25
Iteration:   1700, Loss function: 4.788, Average Loss: 4.455, avg. samples / sec: 54483.36
Iteration:   1700, Loss function: 5.172, Average Loss: 4.471, avg. samples / sec: 54345.89
Iteration:   1700, Loss function: 3.868, Average Loss: 4.497, avg. samples / sec: 54325.94
Iteration:   1700, Loss function: 4.640, Average Loss: 4.474, avg. samples / sec: 54476.68
Iteration:   1700, Loss function: 4.741, Average Loss: 4.496, avg. samples / sec: 54536.62
Iteration:   1700, Loss function: 4.407, Average Loss: 4.488, avg. samples / sec: 54391.19
Iteration:   1700, Loss function: 4.205, Average Loss: 4.492, avg. samples / sec: 54473.56
Iteration:   1700, Loss function: 5.154, Average Loss: 4.460, avg. samples / sec: 54344.06
Iteration:   1700, Loss function: 4.348, Average Loss: 4.482, avg. samples / sec: 54500.87
Iteration:   1700, Loss function: 3.659, Average Loss: 4.483, avg. samples / sec: 54458.24
Iteration:   1700, Loss function: 5.010, Average Loss: 4.472, avg. samples / sec: 54442.00
Iteration:   1700, Loss function: 3.886, Average Loss: 4.467, avg. samples / sec: 53234.55
Iteration:   1720, Loss function: 3.550, Average Loss: 4.450, avg. samples / sec: 53831.75
Iteration:   1720, Loss function: 3.235, Average Loss: 4.483, avg. samples / sec: 53821.43
Iteration:   1720, Loss function: 4.290, Average Loss: 4.464, avg. samples / sec: 53822.79
Iteration:   1720, Loss function: 4.941, Average Loss: 4.471, avg. samples / sec: 53811.34
Iteration:   1720, Loss function: 4.345, Average Loss: 4.454, avg. samples / sec: 53816.81
Iteration:   1720, Loss function: 3.583, Average Loss: 4.479, avg. samples / sec: 53779.00
Iteration:   1720, Loss function: 6.556, Average Loss: 4.484, avg. samples / sec: 53768.39
Iteration:   1720, Loss function: 4.378, Average Loss: 4.483, avg. samples / sec: 53766.17
Iteration:   1720, Loss function: 4.141, Average Loss: 4.502, avg. samples / sec: 53757.19
Iteration:   1720, Loss function: 2.939, Average Loss: 4.491, avg. samples / sec: 53789.83
Iteration:   1720, Loss function: 4.105, Average Loss: 4.487, avg. samples / sec: 53790.72
Iteration:   1720, Loss function: 5.528, Average Loss: 4.451, avg. samples / sec: 53884.79
Iteration:   1720, Loss function: 3.818, Average Loss: 4.474, avg. samples / sec: 53671.39
Iteration:   1720, Loss function: 3.299, Average Loss: 4.489, avg. samples / sec: 53745.98
Iteration:   1720, Loss function: 3.488, Average Loss: 4.490, avg. samples / sec: 53802.42
Iteration:   1720, Loss function: 3.911, Average Loss: 4.471, avg. samples / sec: 53795.23
Iteration:   1720, Loss function: 4.318, Average Loss: 4.455, avg. samples / sec: 53784.95
Iteration:   1720, Loss function: 4.680, Average Loss: 4.491, avg. samples / sec: 53742.41
Iteration:   1720, Loss function: 4.599, Average Loss: 4.483, avg. samples / sec: 53777.52
Iteration:   1720, Loss function: 4.903, Average Loss: 4.476, avg. samples / sec: 53650.94
Iteration:   1720, Loss function: 4.474, Average Loss: 4.470, avg. samples / sec: 53792.77
Iteration:   1720, Loss function: 3.447, Average Loss: 4.466, avg. samples / sec: 55057.55
Iteration:   1720, Loss function: 3.698, Average Loss: 4.459, avg. samples / sec: 53833.23
Iteration:   1720, Loss function: 3.798, Average Loss: 4.489, avg. samples / sec: 53802.63
Iteration:   1720, Loss function: 3.666, Average Loss: 4.483, avg. samples / sec: 53793.43
Iteration:   1720, Loss function: 5.852, Average Loss: 4.465, avg. samples / sec: 53528.34
Iteration:   1720, Loss function: 5.151, Average Loss: 4.487, avg. samples / sec: 53805.03
Iteration:   1720, Loss function: 4.230, Average Loss: 4.478, avg. samples / sec: 53798.17
Iteration:   1720, Loss function: 3.343, Average Loss: 4.472, avg. samples / sec: 53783.29
Iteration:   1720, Loss function: 5.460, Average Loss: 4.495, avg. samples / sec: 53674.21
Iteration:   1740, Loss function: 5.993, Average Loss: 4.451, avg. samples / sec: 54175.08
Iteration:   1740, Loss function: 4.200, Average Loss: 4.475, avg. samples / sec: 54145.61
Iteration:   1740, Loss function: 4.880, Average Loss: 4.480, avg. samples / sec: 54262.58
Iteration:   1740, Loss function: 4.571, Average Loss: 4.491, avg. samples / sec: 54391.19
Iteration:   1740, Loss function: 4.405, Average Loss: 4.475, avg. samples / sec: 54178.22
Iteration:   1740, Loss function: 4.402, Average Loss: 4.452, avg. samples / sec: 54165.75
Iteration:   1740, Loss function: 6.898, Average Loss: 4.487, avg. samples / sec: 54172.54
Iteration:   1740, Loss function: 3.884, Average Loss: 4.477, avg. samples / sec: 54183.79
Iteration:   1740, Loss function: 3.626, Average Loss: 4.450, avg. samples / sec: 54205.23
Iteration:   1740, Loss function: 5.466, Average Loss: 4.469, avg. samples / sec: 54091.34
Iteration:   1740, Loss function: 6.294, Average Loss: 4.480, avg. samples / sec: 54215.32
Iteration:   1740, Loss function: 3.558, Average Loss: 4.470, avg. samples / sec: 54079.58
Iteration:   1740, Loss function: 3.067, Average Loss: 4.501, avg. samples / sec: 54085.88
Iteration:   1740, Loss function: 5.491, Average Loss: 4.487, avg. samples / sec: 54088.33
Iteration:   1740, Loss function: 4.019, Average Loss: 4.488, avg. samples / sec: 54258.45
Iteration:   1740, Loss function: 4.657, Average Loss: 4.474, avg. samples / sec: 54194.85
Iteration:   1740, Loss function: 4.279, Average Loss: 4.476, avg. samples / sec: 54171.33
Iteration:   1740, Loss function: 4.037, Average Loss: 4.486, avg. samples / sec: 54159.32
Iteration:   1740, Loss function: 3.419, Average Loss: 4.467, avg. samples / sec: 54152.99
Iteration:   1740, Loss function: 3.932, Average Loss: 4.456, avg. samples / sec: 54152.85
Iteration:   1740, Loss function: 4.432, Average Loss: 4.494, avg. samples / sec: 54309.09
Iteration:   1740, Loss function: 4.811, Average Loss: 4.488, avg. samples / sec: 54126.20
Iteration:   1740, Loss function: 5.047, Average Loss: 4.467, avg. samples / sec: 54148.02
Iteration:   1740, Loss function: 3.325, Average Loss: 4.467, avg. samples / sec: 54146.98
Iteration:   1740, Loss function: 4.446, Average Loss: 4.482, avg. samples / sec: 54167.19
Iteration:   1740, Loss function: 5.034, Average Loss: 4.461, avg. samples / sec: 54143.40
Iteration:   1740, Loss function: 4.928, Average Loss: 4.464, avg. samples / sec: 54175.81
Iteration:   1740, Loss function: 4.880, Average Loss: 4.476, avg. samples / sec: 54154.89
Iteration:   1740, Loss function: 3.841, Average Loss: 4.485, avg. samples / sec: 54153.37
Iteration:   1740, Loss function: 5.343, Average Loss: 4.473, avg. samples / sec: 54135.85
:::MLL 1558640076.453 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558640076.453 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 4.175, Average Loss: 4.446, avg. samples / sec: 54326.32
Iteration:   1760, Loss function: 4.833, Average Loss: 4.477, avg. samples / sec: 54297.94
Iteration:   1760, Loss function: 3.714, Average Loss: 4.482, avg. samples / sec: 54504.30
Iteration:   1760, Loss function: 5.058, Average Loss: 4.469, avg. samples / sec: 54357.52
Iteration:   1760, Loss function: 5.276, Average Loss: 4.468, avg. samples / sec: 54438.38
Iteration:   1760, Loss function: 4.108, Average Loss: 4.470, avg. samples / sec: 54415.41
Iteration:   1760, Loss function: 4.309, Average Loss: 4.476, avg. samples / sec: 54406.48
Iteration:   1760, Loss function: 4.690, Average Loss: 4.500, avg. samples / sec: 54437.79
Iteration:   1760, Loss function: 4.671, Average Loss: 4.449, avg. samples / sec: 54328.94
Iteration:   1760, Loss function: 4.405, Average Loss: 4.477, avg. samples / sec: 54349.01
Iteration:   1760, Loss function: 4.391, Average Loss: 4.478, avg. samples / sec: 54228.22
Iteration:   1760, Loss function: 4.124, Average Loss: 4.452, avg. samples / sec: 54346.96
Iteration:   1760, Loss function: 4.699, Average Loss: 4.485, avg. samples / sec: 54321.00
Iteration:   1760, Loss function: 5.276, Average Loss: 4.459, avg. samples / sec: 54471.40
Iteration:   1760, Loss function: 3.363, Average Loss: 4.472, avg. samples / sec: 54348.59
Iteration:   1760, Loss function: 5.612, Average Loss: 4.461, avg. samples / sec: 54354.75
Iteration:   1760, Loss function: 5.102, Average Loss: 4.484, avg. samples / sec: 54115.33
Iteration:   1760, Loss function: 3.859, Average Loss: 4.477, avg. samples / sec: 54370.71
Iteration:   1760, Loss function: 4.058, Average Loss: 4.457, avg. samples / sec: 54380.38
Iteration:   1760, Loss function: 4.615, Average Loss: 4.464, avg. samples / sec: 54360.67
Iteration:   1760, Loss function: 4.086, Average Loss: 4.484, avg. samples / sec: 54351.69
Iteration:   1760, Loss function: 4.970, Average Loss: 4.469, avg. samples / sec: 54350.35
Iteration:   1760, Loss function: 3.801, Average Loss: 4.484, avg. samples / sec: 54258.36
Iteration:   1760, Loss function: 3.599, Average Loss: 4.472, avg. samples / sec: 54293.04
Iteration:   1760, Loss function: 5.478, Average Loss: 4.486, avg. samples / sec: 54297.88
Iteration:   1760, Loss function: 3.450, Average Loss: 4.484, avg. samples / sec: 54293.84
Iteration:   1760, Loss function: 4.377, Average Loss: 4.464, avg. samples / sec: 54323.95
Iteration:   1760, Loss function: 3.196, Average Loss: 4.476, avg. samples / sec: 54326.95
Iteration:   1760, Loss function: 4.697, Average Loss: 4.466, avg. samples / sec: 54335.45
Iteration:   1760, Loss function: 4.305, Average Loss: 4.482, avg. samples / sec: 54290.24
Iteration:   1780, Loss function: 4.502, Average Loss: 4.447, avg. samples / sec: 54879.02
Iteration:   1780, Loss function: 6.558, Average Loss: 4.464, avg. samples / sec: 54904.10
Iteration:   1780, Loss function: 3.945, Average Loss: 4.444, avg. samples / sec: 54933.06
Iteration:   1780, Loss function: 4.216, Average Loss: 4.465, avg. samples / sec: 54892.04
Iteration:   1780, Loss function: 4.870, Average Loss: 4.475, avg. samples / sec: 54922.59
Iteration:   1780, Loss function: 4.385, Average Loss: 4.485, avg. samples / sec: 54923.53
Iteration:   1780, Loss function: 4.796, Average Loss: 4.469, avg. samples / sec: 54876.44
Iteration:   1780, Loss function: 4.964, Average Loss: 4.453, avg. samples / sec: 54919.08
Iteration:   1780, Loss function: 5.017, Average Loss: 4.477, avg. samples / sec: 54880.41
Iteration:   1780, Loss function: 4.255, Average Loss: 4.501, avg. samples / sec: 54871.18
Iteration:   1780, Loss function: 3.544, Average Loss: 4.470, avg. samples / sec: 54784.41
Iteration:   1780, Loss function: 3.580, Average Loss: 4.482, avg. samples / sec: 54785.77
Iteration:   1780, Loss function: 4.535, Average Loss: 4.471, avg. samples / sec: 54982.65
Iteration:   1780, Loss function: 3.563, Average Loss: 4.455, avg. samples / sec: 54787.33
Iteration:   1780, Loss function: 4.251, Average Loss: 4.482, avg. samples / sec: 54901.00
Iteration:   1780, Loss function: 3.936, Average Loss: 4.451, avg. samples / sec: 54880.45
Iteration:   1780, Loss function: 3.732, Average Loss: 4.468, avg. samples / sec: 54887.66
Iteration:   1780, Loss function: 4.025, Average Loss: 4.485, avg. samples / sec: 54910.09
Iteration:   1780, Loss function: 4.739, Average Loss: 4.484, avg. samples / sec: 54862.85
Iteration:   1780, Loss function: 4.023, Average Loss: 4.466, avg. samples / sec: 54883.60
Iteration:   1780, Loss function: 2.840, Average Loss: 4.460, avg. samples / sec: 54914.54
Iteration:   1780, Loss function: 3.690, Average Loss: 4.460, avg. samples / sec: 54833.60
Iteration:   1780, Loss function: 3.672, Average Loss: 4.474, avg. samples / sec: 54847.22
Iteration:   1780, Loss function: 4.269, Average Loss: 4.485, avg. samples / sec: 54886.82
Iteration:   1780, Loss function: 4.764, Average Loss: 4.485, avg. samples / sec: 54846.88
Iteration:   1780, Loss function: 3.372, Average Loss: 4.471, avg. samples / sec: 54609.04
Iteration:   1780, Loss function: 4.396, Average Loss: 4.472, avg. samples / sec: 54894.20
Iteration:   1780, Loss function: 4.018, Average Loss: 4.463, avg. samples / sec: 54799.43
Iteration:   1780, Loss function: 4.352, Average Loss: 4.483, avg. samples / sec: 54916.25
Iteration:   1780, Loss function: 4.548, Average Loss: 4.466, avg. samples / sec: 54896.98
Iteration:   1800, Loss function: 4.589, Average Loss: 4.444, avg. samples / sec: 54677.83
Iteration:   1800, Loss function: 5.061, Average Loss: 4.472, avg. samples / sec: 54834.84
Iteration:   1800, Loss function: 5.389, Average Loss: 4.463, avg. samples / sec: 54740.61
Iteration:   1800, Loss function: 4.762, Average Loss: 4.471, avg. samples / sec: 55009.80
Iteration:   1800, Loss function: 4.382, Average Loss: 4.474, avg. samples / sec: 54711.29
Iteration:   1800, Loss function: 4.575, Average Loss: 4.459, avg. samples / sec: 54675.05
Iteration:   1800, Loss function: 3.799, Average Loss: 4.479, avg. samples / sec: 54723.88
Iteration:   1800, Loss function: 3.933, Average Loss: 4.487, avg. samples / sec: 54694.83
Iteration:   1800, Loss function: 4.112, Average Loss: 4.470, avg. samples / sec: 54692.47
Iteration:   1800, Loss function: 4.262, Average Loss: 4.509, avg. samples / sec: 54711.46
Iteration:   1800, Loss function: 4.455, Average Loss: 4.450, avg. samples / sec: 54681.59
Iteration:   1800, Loss function: 4.496, Average Loss: 4.463, avg. samples / sec: 54969.80
Iteration:   1800, Loss function: 4.302, Average Loss: 4.476, avg. samples / sec: 54709.54
Iteration:   1800, Loss function: 4.619, Average Loss: 4.443, avg. samples / sec: 54624.70
Iteration:   1800, Loss function: 4.930, Average Loss: 4.458, avg. samples / sec: 54822.51
Iteration:   1800, Loss function: 4.596, Average Loss: 4.481, avg. samples / sec: 54782.15
Iteration:   1800, Loss function: 4.022, Average Loss: 4.471, avg. samples / sec: 54630.21
Iteration:   1800, Loss function: 3.432, Average Loss: 4.482, avg. samples / sec: 54723.86
Iteration:   1800, Loss function: 5.470, Average Loss: 4.460, avg. samples / sec: 54708.72
Iteration:   1800, Loss function: 4.534, Average Loss: 4.483, avg. samples / sec: 54745.33
Iteration:   1800, Loss function: 4.193, Average Loss: 4.470, avg. samples / sec: 54737.40
Iteration:   1800, Loss function: 4.611, Average Loss: 4.450, avg. samples / sec: 54718.42
Iteration:   1800, Loss function: 3.925, Average Loss: 4.490, avg. samples / sec: 54759.82
Iteration:   1800, Loss function: 4.417, Average Loss: 4.471, avg. samples / sec: 54761.76
Iteration:   1800, Loss function: 4.662, Average Loss: 4.477, avg. samples / sec: 54728.79
Iteration:   1800, Loss function: 4.461, Average Loss: 4.481, avg. samples / sec: 54729.73
Iteration:   1800, Loss function: 3.981, Average Loss: 4.467, avg. samples / sec: 54684.64
Iteration:   1800, Loss function: 4.447, Average Loss: 4.470, avg. samples / sec: 54774.95
Iteration:   1800, Loss function: 4.467, Average Loss: 4.457, avg. samples / sec: 54679.36
Iteration:   1800, Loss function: 3.428, Average Loss: 4.479, avg. samples / sec: 54724.20
:::MLL 1558640078.601 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558640078.601 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 4.294, Average Loss: 4.444, avg. samples / sec: 54642.75
Iteration:   1820, Loss function: 5.347, Average Loss: 4.466, avg. samples / sec: 55014.39
Iteration:   1820, Loss function: 3.519, Average Loss: 4.454, avg. samples / sec: 54745.50
Iteration:   1820, Loss function: 4.955, Average Loss: 4.471, avg. samples / sec: 54634.04
Iteration:   1820, Loss function: 4.584, Average Loss: 4.474, avg. samples / sec: 54720.93
Iteration:   1820, Loss function: 4.966, Average Loss: 4.468, avg. samples / sec: 54682.14
Iteration:   1820, Loss function: 6.223, Average Loss: 4.463, avg. samples / sec: 54570.19
Iteration:   1820, Loss function: 4.777, Average Loss: 4.454, avg. samples / sec: 54644.10
Iteration:   1820, Loss function: 4.996, Average Loss: 4.478, avg. samples / sec: 54605.91
Iteration:   1820, Loss function: 4.652, Average Loss: 4.472, avg. samples / sec: 54572.41
Iteration:   1820, Loss function: 4.343, Average Loss: 4.479, avg. samples / sec: 54764.78
Iteration:   1820, Loss function: 4.094, Average Loss: 4.485, avg. samples / sec: 54569.90
Iteration:   1820, Loss function: 3.703, Average Loss: 4.452, avg. samples / sec: 54684.32
Iteration:   1820, Loss function: 4.339, Average Loss: 4.472, avg. samples / sec: 54523.91
Iteration:   1820, Loss function: 4.984, Average Loss: 4.508, avg. samples / sec: 54552.15
Iteration:   1820, Loss function: 3.946, Average Loss: 4.475, avg. samples / sec: 54808.42
Iteration:   1820, Loss function: 4.635, Average Loss: 4.476, avg. samples / sec: 54678.87
Iteration:   1820, Loss function: 4.374, Average Loss: 4.464, avg. samples / sec: 54692.96
Iteration:   1820, Loss function: 3.103, Average Loss: 4.439, avg. samples / sec: 54545.67
Iteration:   1820, Loss function: 4.261, Average Loss: 4.453, avg. samples / sec: 54761.93
Iteration:   1820, Loss function: 4.234, Average Loss: 4.461, avg. samples / sec: 54656.69
Iteration:   1820, Loss function: 4.002, Average Loss: 4.484, avg. samples / sec: 54634.02
Iteration:   1820, Loss function: 4.135, Average Loss: 4.446, avg. samples / sec: 54657.86
Iteration:   1820, Loss function: 3.834, Average Loss: 4.461, avg. samples / sec: 54476.01
Iteration:   1820, Loss function: 4.015, Average Loss: 4.466, avg. samples / sec: 54627.75
Iteration:   1820, Loss function: 4.604, Average Loss: 4.481, avg. samples / sec: 54625.84
Iteration:   1820, Loss function: 4.283, Average Loss: 4.488, avg. samples / sec: 54589.62
Iteration:   1820, Loss function: 3.840, Average Loss: 4.466, avg. samples / sec: 54598.90
Iteration:   1820, Loss function: 4.976, Average Loss: 4.471, avg. samples / sec: 54576.96
Iteration:   1820, Loss function: 4.016, Average Loss: 4.467, avg. samples / sec: 54569.56
Iteration:   1840, Loss function: 5.252, Average Loss: 4.469, avg. samples / sec: 54475.80
Iteration:   1840, Loss function: 4.316, Average Loss: 4.448, avg. samples / sec: 54384.48
Iteration:   1840, Loss function: 3.741, Average Loss: 4.478, avg. samples / sec: 54556.08
Iteration:   1840, Loss function: 3.919, Average Loss: 4.469, avg. samples / sec: 54560.92
Iteration:   1840, Loss function: 4.227, Average Loss: 4.449, avg. samples / sec: 54483.36
Iteration:   1840, Loss function: 4.220, Average Loss: 4.460, avg. samples / sec: 54477.86
Iteration:   1840, Loss function: 3.939, Average Loss: 4.507, avg. samples / sec: 54564.23
Iteration:   1840, Loss function: 3.577, Average Loss: 4.468, avg. samples / sec: 54503.59
Iteration:   1840, Loss function: 4.311, Average Loss: 4.442, avg. samples / sec: 54586.57
Iteration:   1840, Loss function: 3.764, Average Loss: 4.470, avg. samples / sec: 54488.27
Iteration:   1840, Loss function: 4.682, Average Loss: 4.463, avg. samples / sec: 54411.14
Iteration:   1840, Loss function: 4.649, Average Loss: 4.473, avg. samples / sec: 54342.49
Iteration:   1840, Loss function: 3.924, Average Loss: 4.443, avg. samples / sec: 54396.80
Iteration:   1840, Loss function: 5.533, Average Loss: 4.461, avg. samples / sec: 54429.99
Iteration:   1840, Loss function: 4.785, Average Loss: 4.470, avg. samples / sec: 54417.97
Iteration:   1840, Loss function: 3.521, Average Loss: 4.438, avg. samples / sec: 54083.66
Iteration:   1840, Loss function: 3.943, Average Loss: 4.474, avg. samples / sec: 54353.29
Iteration:   1840, Loss function: 4.341, Average Loss: 4.480, avg. samples / sec: 54464.72
Iteration:   1840, Loss function: 4.176, Average Loss: 4.458, avg. samples / sec: 54152.58
Iteration:   1840, Loss function: 4.815, Average Loss: 4.460, avg. samples / sec: 54478.01
Iteration:   1840, Loss function: 3.394, Average Loss: 4.455, avg. samples / sec: 54456.18
Iteration:   1840, Loss function: 2.824, Average Loss: 4.478, avg. samples / sec: 54502.57
Iteration:   1840, Loss function: 5.378, Average Loss: 4.445, avg. samples / sec: 54441.39
Iteration:   1840, Loss function: 3.795, Average Loss: 4.457, avg. samples / sec: 54411.37
Iteration:   1840, Loss function: 4.324, Average Loss: 4.463, avg. samples / sec: 54513.05
Iteration:   1840, Loss function: 4.676, Average Loss: 4.449, avg. samples / sec: 54380.11
Iteration:   1840, Loss function: 5.084, Average Loss: 4.469, avg. samples / sec: 54514.91
Iteration:   1840, Loss function: 4.136, Average Loss: 4.482, avg. samples / sec: 54477.80
Iteration:   1840, Loss function: 4.473, Average Loss: 4.470, avg. samples / sec: 54318.64
Iteration:   1840, Loss function: 4.492, Average Loss: 4.463, avg. samples / sec: 54507.87
Iteration:   1860, Loss function: 4.929, Average Loss: 4.434, avg. samples / sec: 55181.27
Iteration:   1860, Loss function: 2.734, Average Loss: 4.465, avg. samples / sec: 54786.24
Iteration:   1860, Loss function: 4.024, Average Loss: 4.450, avg. samples / sec: 54748.50
Iteration:   1860, Loss function: 4.599, Average Loss: 4.464, avg. samples / sec: 54787.05
Iteration:   1860, Loss function: 4.425, Average Loss: 4.461, avg. samples / sec: 55013.41
Iteration:   1860, Loss function: 4.987, Average Loss: 4.474, avg. samples / sec: 54755.99
Iteration:   1860, Loss function: 4.893, Average Loss: 4.463, avg. samples / sec: 54778.51
Iteration:   1860, Loss function: 3.176, Average Loss: 4.442, avg. samples / sec: 54777.83
Iteration:   1860, Loss function: 4.248, Average Loss: 4.504, avg. samples / sec: 54762.61
Iteration:   1860, Loss function: 4.942, Average Loss: 4.455, avg. samples / sec: 54770.70
Iteration:   1860, Loss function: 4.963, Average Loss: 4.459, avg. samples / sec: 54741.19
Iteration:   1860, Loss function: 5.727, Average Loss: 4.467, avg. samples / sec: 54812.30
Iteration:   1860, Loss function: 4.537, Average Loss: 4.442, avg. samples / sec: 54734.28
Iteration:   1860, Loss function: 4.407, Average Loss: 4.462, avg. samples / sec: 54712.39
Iteration:   1860, Loss function: 4.550, Average Loss: 4.468, avg. samples / sec: 54880.11
Iteration:   1860, Loss function: 2.940, Average Loss: 4.455, avg. samples / sec: 54746.65
Iteration:   1860, Loss function: 3.773, Average Loss: 4.469, avg. samples / sec: 54764.91
Iteration:   1860, Loss function: 4.185, Average Loss: 4.438, avg. samples / sec: 54741.61
Iteration:   1860, Loss function: 5.576, Average Loss: 4.477, avg. samples / sec: 54763.93
Iteration:   1860, Loss function: 3.994, Average Loss: 4.456, avg. samples / sec: 54789.28
Iteration:   1860, Loss function: 4.239, Average Loss: 4.454, avg. samples / sec: 54787.09
Iteration:   1860, Loss function: 4.132, Average Loss: 4.442, avg. samples / sec: 54776.93
Iteration:   1860, Loss function: 6.246, Average Loss: 4.455, avg. samples / sec: 54765.61
Iteration:   1860, Loss function: 3.564, Average Loss: 4.475, avg. samples / sec: 54803.37
Iteration:   1860, Loss function: 4.146, Average Loss: 4.441, avg. samples / sec: 54786.98
Iteration:   1860, Loss function: 3.600, Average Loss: 4.474, avg. samples / sec: 54750.16
Iteration:   1860, Loss function: 3.734, Average Loss: 4.459, avg. samples / sec: 54694.43
Iteration:   1860, Loss function: 3.069, Average Loss: 4.467, avg. samples / sec: 54755.71
Iteration:   1860, Loss function: 4.951, Average Loss: 4.468, avg. samples / sec: 54708.50
Iteration:   1860, Loss function: 4.627, Average Loss: 4.461, avg. samples / sec: 54751.35
Iteration:   1880, Loss function: 4.839, Average Loss: 4.432, avg. samples / sec: 54447.30
Iteration:   1880, Loss function: 4.482, Average Loss: 4.458, avg. samples / sec: 54528.93
Iteration:   1880, Loss function: 4.841, Average Loss: 4.451, avg. samples / sec: 54716.70
Iteration:   1880, Loss function: 3.447, Average Loss: 4.456, avg. samples / sec: 54519.06
Iteration:   1880, Loss function: 4.007, Average Loss: 4.455, avg. samples / sec: 54480.37
Iteration:   1880, Loss function: 4.250, Average Loss: 4.449, avg. samples / sec: 54474.64
Iteration:   1880, Loss function: 4.425, Average Loss: 4.437, avg. samples / sec: 54494.19
Iteration:   1880, Loss function: 3.152, Average Loss: 4.439, avg. samples / sec: 54507.21
Iteration:   1880, Loss function: 4.161, Average Loss: 4.497, avg. samples / sec: 54481.36
Iteration:   1880, Loss function: 4.533, Average Loss: 4.458, avg. samples / sec: 54461.94
Iteration:   1880, Loss function: 3.796, Average Loss: 4.460, avg. samples / sec: 54490.94
Iteration:   1880, Loss function: 4.735, Average Loss: 4.455, avg. samples / sec: 54455.51
Iteration:   1880, Loss function: 4.345, Average Loss: 4.464, avg. samples / sec: 54429.34
Iteration:   1880, Loss function: 5.220, Average Loss: 4.465, avg. samples / sec: 54462.66
Iteration:   1880, Loss function: 4.420, Average Loss: 4.438, avg. samples / sec: 54558.76
Iteration:   1880, Loss function: 5.343, Average Loss: 4.453, avg. samples / sec: 54520.81
Iteration:   1880, Loss function: 4.063, Average Loss: 4.456, avg. samples / sec: 54567.78
Iteration:   1880, Loss function: 4.616, Average Loss: 4.448, avg. samples / sec: 54491.76
Iteration:   1880, Loss function: 4.926, Average Loss: 4.470, avg. samples / sec: 54487.53
Iteration:   1880, Loss function: 5.125, Average Loss: 4.477, avg. samples / sec: 54498.34
Iteration:   1880, Loss function: 5.287, Average Loss: 4.442, avg. samples / sec: 54462.83
Iteration:   1880, Loss function: 3.528, Average Loss: 4.451, avg. samples / sec: 54466.68
Iteration:   1880, Loss function: 5.355, Average Loss: 4.468, avg. samples / sec: 54328.14
Iteration:   1880, Loss function: 4.423, Average Loss: 4.457, avg. samples / sec: 54277.95
Iteration:   1880, Loss function: 3.510, Average Loss: 4.464, avg. samples / sec: 54558.40
Iteration:   1880, Loss function: 4.900, Average Loss: 4.435, avg. samples / sec: 54466.58
Iteration:   1880, Loss function: 3.827, Average Loss: 4.475, avg. samples / sec: 54476.83
Iteration:   1880, Loss function: 3.705, Average Loss: 4.460, avg. samples / sec: 54527.94
Iteration:   1880, Loss function: 3.256, Average Loss: 4.459, avg. samples / sec: 53983.39
Iteration:   1880, Loss function: 4.190, Average Loss: 4.469, avg. samples / sec: 53319.48
:::MLL 1558640080.762 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558640080.763 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 3.978, Average Loss: 4.424, avg. samples / sec: 54215.45
Iteration:   1900, Loss function: 4.296, Average Loss: 4.456, avg. samples / sec: 54177.10
Iteration:   1900, Loss function: 3.937, Average Loss: 4.443, avg. samples / sec: 54193.48
Iteration:   1900, Loss function: 3.302, Average Loss: 4.456, avg. samples / sec: 54206.09
Iteration:   1900, Loss function: 3.390, Average Loss: 4.451, avg. samples / sec: 54183.68
Iteration:   1900, Loss function: 4.573, Average Loss: 4.451, avg. samples / sec: 54153.51
Iteration:   1900, Loss function: 4.617, Average Loss: 4.445, avg. samples / sec: 54117.12
Iteration:   1900, Loss function: 3.236, Average Loss: 4.448, avg. samples / sec: 54135.08
Iteration:   1900, Loss function: 3.244, Average Loss: 4.436, avg. samples / sec: 54128.01
Iteration:   1900, Loss function: 3.997, Average Loss: 4.451, avg. samples / sec: 54101.75
Iteration:   1900, Loss function: 3.357, Average Loss: 4.433, avg. samples / sec: 54107.67
Iteration:   1900, Loss function: 3.986, Average Loss: 4.490, avg. samples / sec: 54115.29
Iteration:   1900, Loss function: 4.635, Average Loss: 4.462, avg. samples / sec: 54157.49
Iteration:   1900, Loss function: 4.296, Average Loss: 4.462, avg. samples / sec: 54155.86
Iteration:   1900, Loss function: 3.412, Average Loss: 4.462, avg. samples / sec: 54313.74
Iteration:   1900, Loss function: 4.460, Average Loss: 4.436, avg. samples / sec: 54188.58
Iteration:   1900, Loss function: 5.022, Average Loss: 4.445, avg. samples / sec: 54138.08
Iteration:   1900, Loss function: 3.735, Average Loss: 4.454, avg. samples / sec: 54118.31
Iteration:   1900, Loss function: 4.619, Average Loss: 4.463, avg. samples / sec: 55341.08
Iteration:   1900, Loss function: 4.180, Average Loss: 4.442, avg. samples / sec: 54156.22
Iteration:   1900, Loss function: 4.142, Average Loss: 4.468, avg. samples / sec: 54102.47
Iteration:   1900, Loss function: 4.087, Average Loss: 4.431, avg. samples / sec: 54044.69
Iteration:   1900, Loss function: 3.960, Average Loss: 4.449, avg. samples / sec: 54142.30
Iteration:   1900, Loss function: 4.587, Average Loss: 4.462, avg. samples / sec: 54136.02
Iteration:   1900, Loss function: 3.182, Average Loss: 4.448, avg. samples / sec: 54086.78
Iteration:   1900, Loss function: 5.543, Average Loss: 4.472, avg. samples / sec: 54113.13
Iteration:   1900, Loss function: 3.430, Average Loss: 4.469, avg. samples / sec: 54148.33
Iteration:   1900, Loss function: 4.017, Average Loss: 4.426, avg. samples / sec: 54145.50
Iteration:   1900, Loss function: 3.204, Average Loss: 4.452, avg. samples / sec: 54655.06
Iteration:   1900, Loss function: 3.826, Average Loss: 4.451, avg. samples / sec: 54127.43
Iteration:   1920, Loss function: 3.819, Average Loss: 4.415, avg. samples / sec: 54946.91
Iteration:   1920, Loss function: 4.042, Average Loss: 4.449, avg. samples / sec: 55084.34
Iteration:   1920, Loss function: 4.461, Average Loss: 4.441, avg. samples / sec: 54976.56
Iteration:   1920, Loss function: 3.654, Average Loss: 4.451, avg. samples / sec: 55009.41
Iteration:   1920, Loss function: 5.522, Average Loss: 4.434, avg. samples / sec: 55036.67
Iteration:   1920, Loss function: 4.717, Average Loss: 4.435, avg. samples / sec: 55021.80
Iteration:   1920, Loss function: 3.381, Average Loss: 4.443, avg. samples / sec: 54986.55
Iteration:   1920, Loss function: 3.183, Average Loss: 4.456, avg. samples / sec: 55028.40
Iteration:   1920, Loss function: 3.360, Average Loss: 4.457, avg. samples / sec: 55011.37
Iteration:   1920, Loss function: 6.217, Average Loss: 4.454, avg. samples / sec: 54741.06
Iteration:   1920, Loss function: 4.240, Average Loss: 4.447, avg. samples / sec: 54931.71
Iteration:   1920, Loss function: 4.361, Average Loss: 4.443, avg. samples / sec: 54871.18
Iteration:   1920, Loss function: 3.687, Average Loss: 4.463, avg. samples / sec: 54857.85
Iteration:   1920, Loss function: 3.201, Average Loss: 4.465, avg. samples / sec: 55034.91
Iteration:   1920, Loss function: 4.475, Average Loss: 4.431, avg. samples / sec: 55030.10
Iteration:   1920, Loss function: 3.476, Average Loss: 4.446, avg. samples / sec: 55028.64
Iteration:   1920, Loss function: 4.114, Average Loss: 4.488, avg. samples / sec: 54820.79
Iteration:   1920, Loss function: 3.207, Average Loss: 4.446, avg. samples / sec: 54964.27
Iteration:   1920, Loss function: 5.045, Average Loss: 4.442, avg. samples / sec: 55005.57
Iteration:   1920, Loss function: 5.256, Average Loss: 4.444, avg. samples / sec: 54953.08
Iteration:   1920, Loss function: 3.341, Average Loss: 4.435, avg. samples / sec: 54963.74
Iteration:   1920, Loss function: 4.377, Average Loss: 4.433, avg. samples / sec: 54922.52
Iteration:   1920, Loss function: 4.945, Average Loss: 4.467, avg. samples / sec: 54995.91
Iteration:   1920, Loss function: 6.068, Average Loss: 4.456, avg. samples / sec: 54942.31
Iteration:   1920, Loss function: 4.610, Average Loss: 4.452, avg. samples / sec: 54709.84
Iteration:   1920, Loss function: 3.968, Average Loss: 4.469, avg. samples / sec: 54965.32
Iteration:   1920, Loss function: 5.499, Average Loss: 4.419, avg. samples / sec: 54959.92
Iteration:   1920, Loss function: 4.695, Average Loss: 4.458, avg. samples / sec: 54953.28
Iteration:   1920, Loss function: 3.484, Average Loss: 4.451, avg. samples / sec: 54975.10
Iteration:   1920, Loss function: 4.947, Average Loss: 4.447, avg. samples / sec: 54935.09
Iteration:   1940, Loss function: 4.000, Average Loss: 4.420, avg. samples / sec: 54553.50
Iteration:   1940, Loss function: 4.500, Average Loss: 4.417, avg. samples / sec: 54951.80
Iteration:   1940, Loss function: 4.265, Average Loss: 4.435, avg. samples / sec: 54588.60
Iteration:   1940, Loss function: 4.721, Average Loss: 4.447, avg. samples / sec: 54840.33
Iteration:   1940, Loss function: 4.536, Average Loss: 4.457, avg. samples / sec: 54630.88
Iteration:   1940, Loss function: 4.008, Average Loss: 4.444, avg. samples / sec: 54616.66
Iteration:   1940, Loss function: 3.288, Average Loss: 4.444, avg. samples / sec: 54543.29
Iteration:   1940, Loss function: 3.775, Average Loss: 4.451, avg. samples / sec: 54862.14
Iteration:   1940, Loss function: 4.316, Average Loss: 4.441, avg. samples / sec: 54713.05
Iteration:   1940, Loss function: 4.181, Average Loss: 4.457, avg. samples / sec: 54602.56
Iteration:   1940, Loss function: 4.544, Average Loss: 4.450, avg. samples / sec: 54569.26
Iteration:   1940, Loss function: 4.941, Average Loss: 4.448, avg. samples / sec: 54628.22
Iteration:   1940, Loss function: 3.933, Average Loss: 4.457, avg. samples / sec: 54573.57
Iteration:   1940, Loss function: 4.132, Average Loss: 4.441, avg. samples / sec: 54482.20
Iteration:   1940, Loss function: 4.255, Average Loss: 4.485, avg. samples / sec: 54674.42
Iteration:   1940, Loss function: 4.130, Average Loss: 4.433, avg. samples / sec: 54694.77
Iteration:   1940, Loss function: 4.339, Average Loss: 4.441, avg. samples / sec: 54643.87
Iteration:   1940, Loss function: 4.570, Average Loss: 4.467, avg. samples / sec: 54591.80
Iteration:   1940, Loss function: 5.861, Average Loss: 4.455, avg. samples / sec: 54643.42
Iteration:   1940, Loss function: 4.390, Average Loss: 4.434, avg. samples / sec: 54624.09
Iteration:   1940, Loss function: 5.325, Average Loss: 4.433, avg. samples / sec: 54380.70
Iteration:   1940, Loss function: 4.318, Average Loss: 4.429, avg. samples / sec: 54588.31
Iteration:   1940, Loss function: 4.292, Average Loss: 4.447, avg. samples / sec: 54661.18
Iteration:   1940, Loss function: 4.475, Average Loss: 4.467, avg. samples / sec: 54632.20
Iteration:   1940, Loss function: 4.686, Average Loss: 4.441, avg. samples / sec: 54572.31
Iteration:   1940, Loss function: 3.042, Average Loss: 4.453, avg. samples / sec: 54623.68
Iteration:   1940, Loss function: 4.642, Average Loss: 4.445, avg. samples / sec: 54540.96
Iteration:   1940, Loss function: 4.583, Average Loss: 4.464, avg. samples / sec: 54578.86
Iteration:   1940, Loss function: 3.768, Average Loss: 4.446, avg. samples / sec: 54659.74
Iteration:   1940, Loss function: 5.749, Average Loss: 4.466, avg. samples / sec: 54252.16
:::MLL 1558640082.917 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558640082.917 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 5.037, Average Loss: 4.437, avg. samples / sec: 54264.38
Iteration:   1960, Loss function: 4.368, Average Loss: 4.415, avg. samples / sec: 54054.37
Iteration:   1960, Loss function: 4.869, Average Loss: 4.413, avg. samples / sec: 54099.63
Iteration:   1960, Loss function: 4.556, Average Loss: 4.450, avg. samples / sec: 54244.16
Iteration:   1960, Loss function: 3.558, Average Loss: 4.430, avg. samples / sec: 54379.65
Iteration:   1960, Loss function: 5.140, Average Loss: 4.445, avg. samples / sec: 54143.40
Iteration:   1960, Loss function: 3.804, Average Loss: 4.462, avg. samples / sec: 54367.59
Iteration:   1960, Loss function: 3.444, Average Loss: 4.449, avg. samples / sec: 54105.90
Iteration:   1960, Loss function: 3.590, Average Loss: 4.481, avg. samples / sec: 54196.60
Iteration:   1960, Loss function: 5.104, Average Loss: 4.441, avg. samples / sec: 54043.12
Iteration:   1960, Loss function: 5.024, Average Loss: 4.456, avg. samples / sec: 54032.61
Iteration:   1960, Loss function: 4.448, Average Loss: 4.447, avg. samples / sec: 54027.33
Iteration:   1960, Loss function: 4.155, Average Loss: 4.442, avg. samples / sec: 54058.64
Iteration:   1960, Loss function: 3.699, Average Loss: 4.437, avg. samples / sec: 54136.06
Iteration:   1960, Loss function: 4.089, Average Loss: 4.448, avg. samples / sec: 54019.17
Iteration:   1960, Loss function: 4.556, Average Loss: 4.440, avg. samples / sec: 54003.46
Iteration:   1960, Loss function: 4.611, Average Loss: 4.429, avg. samples / sec: 53944.73
Iteration:   1960, Loss function: 3.955, Average Loss: 4.447, avg. samples / sec: 54178.16
Iteration:   1960, Loss function: 4.170, Average Loss: 4.429, avg. samples / sec: 54119.64
Iteration:   1960, Loss function: 4.913, Average Loss: 4.463, avg. samples / sec: 54162.42
Iteration:   1960, Loss function: 3.487, Average Loss: 4.444, avg. samples / sec: 54176.25
Iteration:   1960, Loss function: 3.473, Average Loss: 4.428, avg. samples / sec: 54067.69
Iteration:   1960, Loss function: 4.524, Average Loss: 4.441, avg. samples / sec: 54097.74
Iteration:   1960, Loss function: 3.806, Average Loss: 4.423, avg. samples / sec: 54067.50
Iteration:   1960, Loss function: 4.334, Average Loss: 4.436, avg. samples / sec: 54023.50
Iteration:   1960, Loss function: 4.190, Average Loss: 4.435, avg. samples / sec: 54103.70
Iteration:   1960, Loss function: 4.987, Average Loss: 4.465, avg. samples / sec: 54371.32
Iteration:   1960, Loss function: 4.448, Average Loss: 4.461, avg. samples / sec: 54069.47
Iteration:   1960, Loss function: 5.315, Average Loss: 4.449, avg. samples / sec: 54061.90
Iteration:   1960, Loss function: 3.807, Average Loss: 4.442, avg. samples / sec: 54067.65
Iteration:   1980, Loss function: 4.632, Average Loss: 4.413, avg. samples / sec: 55012.42
Iteration:   1980, Loss function: 3.453, Average Loss: 4.446, avg. samples / sec: 55020.56
Iteration:   1980, Loss function: 4.898, Average Loss: 4.439, avg. samples / sec: 54870.75
Iteration:   1980, Loss function: 3.529, Average Loss: 4.419, avg. samples / sec: 54861.72
Iteration:   1980, Loss function: 3.813, Average Loss: 4.438, avg. samples / sec: 54993.14
Iteration:   1980, Loss function: 4.218, Average Loss: 4.443, avg. samples / sec: 54948.63
Iteration:   1980, Loss function: 3.838, Average Loss: 4.440, avg. samples / sec: 54938.77
Iteration:   1980, Loss function: 4.573, Average Loss: 4.478, avg. samples / sec: 54905.73
Iteration:   1980, Loss function: 3.887, Average Loss: 4.442, avg. samples / sec: 54847.05
Iteration:   1980, Loss function: 4.164, Average Loss: 4.435, avg. samples / sec: 54896.38
Iteration:   1980, Loss function: 3.411, Average Loss: 4.434, avg. samples / sec: 54944.17
Iteration:   1980, Loss function: 3.546, Average Loss: 4.453, avg. samples / sec: 54838.55
Iteration:   1980, Loss function: 3.972, Average Loss: 4.443, avg. samples / sec: 54901.60
Iteration:   1980, Loss function: 4.975, Average Loss: 4.424, avg. samples / sec: 54969.16
Iteration:   1980, Loss function: 4.579, Average Loss: 4.456, avg. samples / sec: 54880.77
Iteration:   1980, Loss function: 3.509, Average Loss: 4.446, avg. samples / sec: 54835.33
Iteration:   1980, Loss function: 3.798, Average Loss: 4.465, avg. samples / sec: 55056.05
Iteration:   1980, Loss function: 4.123, Average Loss: 4.427, avg. samples / sec: 54709.16
Iteration:   1980, Loss function: 3.561, Average Loss: 4.423, avg. samples / sec: 54858.92
Iteration:   1980, Loss function: 3.884, Average Loss: 4.418, avg. samples / sec: 54979.00
Iteration:   1980, Loss function: 4.748, Average Loss: 4.423, avg. samples / sec: 54948.35
Iteration:   1980, Loss function: 3.626, Average Loss: 4.428, avg. samples / sec: 54951.91
Iteration:   1980, Loss function: 4.259, Average Loss: 4.431, avg. samples / sec: 54932.89
Iteration:   1980, Loss function: 4.068, Average Loss: 4.441, avg. samples / sec: 54798.83
Iteration:   1980, Loss function: 5.278, Average Loss: 4.457, avg. samples / sec: 54805.33
Iteration:   1980, Loss function: 3.088, Average Loss: 4.457, avg. samples / sec: 54925.97
Iteration:   1980, Loss function: 6.098, Average Loss: 4.434, avg. samples / sec: 54882.59
Iteration:   1980, Loss function: 5.139, Average Loss: 4.442, avg. samples / sec: 54784.36
Iteration:   1980, Loss function: 3.576, Average Loss: 4.445, avg. samples / sec: 54910.48
Iteration:   1980, Loss function: 3.760, Average Loss: 4.440, avg. samples / sec: 54874.85
Iteration:   2000, Loss function: 3.023, Average Loss: 4.428, avg. samples / sec: 55021.74
Iteration:   2000, Loss function: 4.563, Average Loss: 4.440, avg. samples / sec: 54849.50
Iteration:   2000, Loss function: 3.353, Average Loss: 4.411, avg. samples / sec: 54758.57
Iteration:   2000, Loss function: 3.413, Average Loss: 4.435, avg. samples / sec: 54829.06
Iteration:   2000, Loss function: 4.689, Average Loss: 4.438, avg. samples / sec: 54935.95
Iteration:   2000, Loss function: 4.516, Average Loss: 4.446, avg. samples / sec: 54909.90
Iteration:   2000, Loss function: 3.474, Average Loss: 4.414, avg. samples / sec: 54837.06
Iteration:   2000, Loss function: 5.229, Average Loss: 4.422, avg. samples / sec: 54910.22
Iteration:   2000, Loss function: 3.074, Average Loss: 4.422, avg. samples / sec: 54966.97
Iteration:   2000, Loss function: 2.609, Average Loss: 4.428, avg. samples / sec: 54892.30
Iteration:   2000, Loss function: 4.712, Average Loss: 4.438, avg. samples / sec: 54890.26
Iteration:   2000, Loss function: 4.683, Average Loss: 4.443, avg. samples / sec: 54900.21
Iteration:   2000, Loss function: 3.519, Average Loss: 4.424, avg. samples / sec: 54875.52
Iteration:   2000, Loss function: 4.387, Average Loss: 4.469, avg. samples / sec: 54837.40
Iteration:   2000, Loss function: 3.860, Average Loss: 4.455, avg. samples / sec: 54850.68
Iteration:   2000, Loss function: 4.034, Average Loss: 4.448, avg. samples / sec: 54799.02
Iteration:   2000, Loss function: 4.516, Average Loss: 4.454, avg. samples / sec: 54783.58
Iteration:   2000, Loss function: 4.726, Average Loss: 4.429, avg. samples / sec: 54876.22
Iteration:   2000, Loss function: 4.372, Average Loss: 4.437, avg. samples / sec: 54684.03
Iteration:   2000, Loss function: 4.945, Average Loss: 4.420, avg. samples / sec: 54850.72
Iteration:   2000, Loss function: 4.505, Average Loss: 4.426, avg. samples / sec: 54885.03
Iteration:   2000, Loss function: 4.921, Average Loss: 4.415, avg. samples / sec: 54824.20
Iteration:   2000, Loss function: 3.992, Average Loss: 4.451, avg. samples / sec: 54879.77
Iteration:   2000, Loss function: 4.500, Average Loss: 4.432, avg. samples / sec: 54874.19
Iteration:   2000, Loss function: 3.402, Average Loss: 4.417, avg. samples / sec: 54785.43
Iteration:   2000, Loss function: 4.632, Average Loss: 4.455, avg. samples / sec: 54849.42
Iteration:   2000, Loss function: 4.398, Average Loss: 4.421, avg. samples / sec: 54869.98
Iteration:   2000, Loss function: 4.102, Average Loss: 4.443, avg. samples / sec: 54879.24
Iteration:   2000, Loss function: 4.979, Average Loss: 4.436, avg. samples / sec: 54920.55
Iteration:   2000, Loss function: 3.515, Average Loss: 4.435, avg. samples / sec: 54786.88
Iteration:   2020, Loss function: 4.207, Average Loss: 4.407, avg. samples / sec: 54726.03
Iteration:   2020, Loss function: 4.981, Average Loss: 4.433, avg. samples / sec: 54628.83
Iteration:   2020, Loss function: 4.296, Average Loss: 4.430, avg. samples / sec: 54687.17
Iteration:   2020, Loss function: 5.264, Average Loss: 4.415, avg. samples / sec: 54687.17
Iteration:   2020, Loss function: 3.902, Average Loss: 4.415, avg. samples / sec: 54686.96
Iteration:   2020, Loss function: 4.119, Average Loss: 4.424, avg. samples / sec: 54470.05
Iteration:   2020, Loss function: 4.190, Average Loss: 4.427, avg. samples / sec: 54675.58
Iteration:   2020, Loss function: 5.409, Average Loss: 4.420, avg. samples / sec: 54667.06
Iteration:   2020, Loss function: 4.782, Average Loss: 4.438, avg. samples / sec: 54628.13
Iteration:   2020, Loss function: 3.849, Average Loss: 4.445, avg. samples / sec: 54749.69
Iteration:   2020, Loss function: 3.576, Average Loss: 4.455, avg. samples / sec: 54713.43
Iteration:   2020, Loss function: 4.358, Average Loss: 4.437, avg. samples / sec: 54602.33
Iteration:   2020, Loss function: 5.105, Average Loss: 4.468, avg. samples / sec: 54681.23
Iteration:   2020, Loss function: 5.096, Average Loss: 4.432, avg. samples / sec: 54613.29
Iteration:   2020, Loss function: 2.842, Average Loss: 4.418, avg. samples / sec: 54622.94
Iteration:   2020, Loss function: 4.139, Average Loss: 4.434, avg. samples / sec: 54608.83
Iteration:   2020, Loss function: 3.530, Average Loss: 4.439, avg. samples / sec: 54707.23
Iteration:   2020, Loss function: 4.653, Average Loss: 4.409, avg. samples / sec: 54679.19
Iteration:   2020, Loss function: 3.943, Average Loss: 4.415, avg. samples / sec: 54675.24
Iteration:   2020, Loss function: 6.281, Average Loss: 4.431, avg. samples / sec: 54644.72
Iteration:   2020, Loss function: 4.524, Average Loss: 4.434, avg. samples / sec: 54647.32
Iteration:   2020, Loss function: 3.862, Average Loss: 4.430, avg. samples / sec: 54622.14
Iteration:   2020, Loss function: 3.708, Average Loss: 4.432, avg. samples / sec: 54628.45
Iteration:   2020, Loss function: 5.371, Average Loss: 4.448, avg. samples / sec: 54611.03
Iteration:   2020, Loss function: 4.991, Average Loss: 4.412, avg. samples / sec: 54647.58
Iteration:   2020, Loss function: 3.226, Average Loss: 4.419, avg. samples / sec: 54641.47
Iteration:   2020, Loss function: 4.441, Average Loss: 4.444, avg. samples / sec: 54648.78
Iteration:   2020, Loss function: 3.856, Average Loss: 4.453, avg. samples / sec: 54624.62
Iteration:   2020, Loss function: 4.554, Average Loss: 4.430, avg. samples / sec: 54713.20
Iteration:   2020, Loss function: 4.529, Average Loss: 4.430, avg. samples / sec: 54622.86
:::MLL 1558640085.065 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558640085.066 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 6.281, Average Loss: 4.426, avg. samples / sec: 54008.32
Iteration:   2040, Loss function: 4.638, Average Loss: 4.449, avg. samples / sec: 54039.20
Iteration:   2040, Loss function: 4.816, Average Loss: 4.420, avg. samples / sec: 53998.04
Iteration:   2040, Loss function: 3.825, Average Loss: 4.414, avg. samples / sec: 53945.93
Iteration:   2040, Loss function: 4.615, Average Loss: 4.427, avg. samples / sec: 54067.79
Iteration:   2040, Loss function: 3.018, Average Loss: 4.430, avg. samples / sec: 53842.34
Iteration:   2040, Loss function: 5.409, Average Loss: 4.430, avg. samples / sec: 54029.86
Iteration:   2040, Loss function: 5.142, Average Loss: 4.466, avg. samples / sec: 54009.09
Iteration:   2040, Loss function: 4.690, Average Loss: 4.412, avg. samples / sec: 54034.72
Iteration:   2040, Loss function: 4.403, Average Loss: 4.411, avg. samples / sec: 53950.33
Iteration:   2040, Loss function: 3.307, Average Loss: 4.442, avg. samples / sec: 53982.01
Iteration:   2040, Loss function: 4.229, Average Loss: 4.433, avg. samples / sec: 53990.69
Iteration:   2040, Loss function: 5.348, Average Loss: 4.430, avg. samples / sec: 53954.00
Iteration:   2040, Loss function: 4.590, Average Loss: 4.424, avg. samples / sec: 54154.14
Iteration:   2040, Loss function: 4.369, Average Loss: 4.403, avg. samples / sec: 53718.32
Iteration:   2040, Loss function: 5.141, Average Loss: 4.431, avg. samples / sec: 54058.93
Iteration:   2040, Loss function: 3.977, Average Loss: 4.408, avg. samples / sec: 54020.14
Iteration:   2040, Loss function: 4.646, Average Loss: 4.447, avg. samples / sec: 54052.90
Iteration:   2040, Loss function: 4.858, Average Loss: 4.426, avg. samples / sec: 54053.27
Iteration:   2040, Loss function: 3.871, Average Loss: 4.439, avg. samples / sec: 53970.39
Iteration:   2040, Loss function: 3.451, Average Loss: 4.409, avg. samples / sec: 54045.77
Iteration:   2040, Loss function: 5.358, Average Loss: 4.449, avg. samples / sec: 54071.84
Iteration:   2040, Loss function: 4.054, Average Loss: 4.423, avg. samples / sec: 54014.93
Iteration:   2040, Loss function: 4.063, Average Loss: 4.411, avg. samples / sec: 53938.62
Iteration:   2040, Loss function: 4.358, Average Loss: 4.439, avg. samples / sec: 54023.66
Iteration:   2040, Loss function: 3.666, Average Loss: 4.427, avg. samples / sec: 54042.39
Iteration:   2040, Loss function: 3.979, Average Loss: 4.422, avg. samples / sec: 54007.68
Iteration:   2040, Loss function: 4.291, Average Loss: 4.414, avg. samples / sec: 53969.15
Iteration:   2040, Loss function: 3.618, Average Loss: 4.419, avg. samples / sec: 53164.28
Iteration:   2040, Loss function: 4.099, Average Loss: 4.430, avg. samples / sec: 52901.53
Iteration:   2060, Loss function: 4.437, Average Loss: 4.401, avg. samples / sec: 54217.24
Iteration:   2060, Loss function: 5.677, Average Loss: 4.435, avg. samples / sec: 54058.31
Iteration:   2060, Loss function: 4.186, Average Loss: 4.418, avg. samples / sec: 53975.85
Iteration:   2060, Loss function: 3.279, Average Loss: 4.463, avg. samples / sec: 53985.13
Iteration:   2060, Loss function: 4.037, Average Loss: 4.443, avg. samples / sec: 53929.97
Iteration:   2060, Loss function: 5.033, Average Loss: 4.426, avg. samples / sec: 53953.38
Iteration:   2060, Loss function: 4.770, Average Loss: 4.404, avg. samples / sec: 53968.80
Iteration:   2060, Loss function: 3.820, Average Loss: 4.425, avg. samples / sec: 55077.89
Iteration:   2060, Loss function: 3.657, Average Loss: 4.421, avg. samples / sec: 53930.30
Iteration:   2060, Loss function: 3.929, Average Loss: 4.416, avg. samples / sec: 54775.89
Iteration:   2060, Loss function: 4.099, Average Loss: 4.410, avg. samples / sec: 53944.17
Iteration:   2060, Loss function: 3.526, Average Loss: 4.420, avg. samples / sec: 53930.30
Iteration:   2060, Loss function: 6.095, Average Loss: 4.433, avg. samples / sec: 53943.57
Iteration:   2060, Loss function: 4.508, Average Loss: 4.408, avg. samples / sec: 53900.72
Iteration:   2060, Loss function: 5.084, Average Loss: 4.427, avg. samples / sec: 53727.56
Iteration:   2060, Loss function: 3.350, Average Loss: 4.402, avg. samples / sec: 53957.83
Iteration:   2060, Loss function: 5.206, Average Loss: 4.433, avg. samples / sec: 53938.33
Iteration:   2060, Loss function: 4.731, Average Loss: 4.440, avg. samples / sec: 53921.55
Iteration:   2060, Loss function: 4.793, Average Loss: 4.409, avg. samples / sec: 53982.48
Iteration:   2060, Loss function: 4.658, Average Loss: 4.421, avg. samples / sec: 53914.08
Iteration:   2060, Loss function: 3.403, Average Loss: 4.415, avg. samples / sec: 54017.91
Iteration:   2060, Loss function: 3.562, Average Loss: 4.422, avg. samples / sec: 53772.27
Iteration:   2060, Loss function: 4.275, Average Loss: 4.422, avg. samples / sec: 53926.98
Iteration:   2060, Loss function: 3.546, Average Loss: 4.407, avg. samples / sec: 53921.08
Iteration:   2060, Loss function: 4.160, Average Loss: 4.432, avg. samples / sec: 53956.01
Iteration:   2060, Loss function: 4.592, Average Loss: 4.425, avg. samples / sec: 53869.92
Iteration:   2060, Loss function: 5.043, Average Loss: 4.420, avg. samples / sec: 53966.59
Iteration:   2060, Loss function: 4.375, Average Loss: 4.448, avg. samples / sec: 53876.00
Iteration:   2060, Loss function: 3.592, Average Loss: 4.423, avg. samples / sec: 53701.00
Iteration:   2060, Loss function: 4.041, Average Loss: 4.424, avg. samples / sec: 53918.58
Iteration:   2080, Loss function: 4.503, Average Loss: 4.400, avg. samples / sec: 54487.28
Iteration:   2080, Loss function: 3.608, Average Loss: 4.418, avg. samples / sec: 54712.60
Iteration:   2080, Loss function: 4.646, Average Loss: 4.456, avg. samples / sec: 54457.23
Iteration:   2080, Loss function: 3.572, Average Loss: 4.398, avg. samples / sec: 54450.27
Iteration:   2080, Loss function: 4.256, Average Loss: 4.401, avg. samples / sec: 54487.47
Iteration:   2080, Loss function: 2.551, Average Loss: 4.419, avg. samples / sec: 54435.48
Iteration:   2080, Loss function: 4.564, Average Loss: 4.408, avg. samples / sec: 54444.71
Iteration:   2080, Loss function: 3.166, Average Loss: 4.417, avg. samples / sec: 54413.79
Iteration:   2080, Loss function: 4.519, Average Loss: 4.441, avg. samples / sec: 54411.33
Iteration:   2080, Loss function: 4.722, Average Loss: 4.420, avg. samples / sec: 54426.67
Iteration:   2080, Loss function: 4.310, Average Loss: 4.434, avg. samples / sec: 54318.30
Iteration:   2080, Loss function: 4.155, Average Loss: 4.421, avg. samples / sec: 54433.44
Iteration:   2080, Loss function: 4.301, Average Loss: 4.421, avg. samples / sec: 54669.45
Iteration:   2080, Loss function: 3.765, Average Loss: 4.429, avg. samples / sec: 54411.23
Iteration:   2080, Loss function: 3.794, Average Loss: 4.414, avg. samples / sec: 54369.41
Iteration:   2080, Loss function: 5.429, Average Loss: 4.409, avg. samples / sec: 54469.71
Iteration:   2080, Loss function: 3.186, Average Loss: 4.427, avg. samples / sec: 54454.68
Iteration:   2080, Loss function: 3.262, Average Loss: 4.420, avg. samples / sec: 54471.06
Iteration:   2080, Loss function: 3.867, Average Loss: 4.419, avg. samples / sec: 54448.88
Iteration:   2080, Loss function: 4.795, Average Loss: 4.392, avg. samples / sec: 54382.31
Iteration:   2080, Loss function: 3.753, Average Loss: 4.416, avg. samples / sec: 54184.33
Iteration:   2080, Loss function: 4.753, Average Loss: 4.416, avg. samples / sec: 54462.68
Iteration:   2080, Loss function: 4.226, Average Loss: 4.424, avg. samples / sec: 54468.81
Iteration:   2080, Loss function: 4.427, Average Loss: 4.444, avg. samples / sec: 54510.21
Iteration:   2080, Loss function: 3.973, Average Loss: 4.435, avg. samples / sec: 54414.40
Iteration:   2080, Loss function: 3.878, Average Loss: 4.403, avg. samples / sec: 54439.60
Iteration:   2080, Loss function: 4.203, Average Loss: 4.429, avg. samples / sec: 54429.05
Iteration:   2080, Loss function: 3.837, Average Loss: 4.419, avg. samples / sec: 54455.84
Iteration:   2080, Loss function: 5.853, Average Loss: 4.422, avg. samples / sec: 54402.70
Iteration:   2080, Loss function: 3.295, Average Loss: 4.414, avg. samples / sec: 54366.92
:::MLL 1558640087.236 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558640087.236 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 4.342, Average Loss: 4.395, avg. samples / sec: 54311.10
Iteration:   2100, Loss function: 3.703, Average Loss: 4.397, avg. samples / sec: 54535.67
Iteration:   2100, Loss function: 3.654, Average Loss: 4.415, avg. samples / sec: 54528.62
Iteration:   2100, Loss function: 4.706, Average Loss: 4.423, avg. samples / sec: 54277.82
Iteration:   2100, Loss function: 3.702, Average Loss: 4.427, avg. samples / sec: 54490.58
Iteration:   2100, Loss function: 3.516, Average Loss: 4.414, avg. samples / sec: 54495.22
Iteration:   2100, Loss function: 4.908, Average Loss: 4.435, avg. samples / sec: 54460.87
Iteration:   2100, Loss function: 3.988, Average Loss: 4.409, avg. samples / sec: 54527.27
Iteration:   2100, Loss function: 3.513, Average Loss: 4.450, avg. samples / sec: 54391.36
Iteration:   2100, Loss function: 4.201, Average Loss: 4.413, avg. samples / sec: 54476.60
Iteration:   2100, Loss function: 4.448, Average Loss: 4.397, avg. samples / sec: 54405.66
Iteration:   2100, Loss function: 3.476, Average Loss: 4.412, avg. samples / sec: 54429.19
Iteration:   2100, Loss function: 3.915, Average Loss: 4.414, avg. samples / sec: 54612.08
Iteration:   2100, Loss function: 3.417, Average Loss: 4.419, avg. samples / sec: 54467.56
Iteration:   2100, Loss function: 3.515, Average Loss: 4.415, avg. samples / sec: 54599.05
Iteration:   2100, Loss function: 3.831, Average Loss: 4.392, avg. samples / sec: 54578.71
Iteration:   2100, Loss function: 4.389, Average Loss: 4.403, avg. samples / sec: 54358.49
Iteration:   2100, Loss function: 4.499, Average Loss: 4.420, avg. samples / sec: 54520.62
Iteration:   2100, Loss function: 4.731, Average Loss: 4.417, avg. samples / sec: 54438.28
Iteration:   2100, Loss function: 2.817, Average Loss: 4.403, avg. samples / sec: 54416.08
Iteration:   2100, Loss function: 4.589, Average Loss: 4.419, avg. samples / sec: 54435.65
Iteration:   2100, Loss function: 3.578, Average Loss: 4.419, avg. samples / sec: 54264.69
Iteration:   2100, Loss function: 4.800, Average Loss: 4.417, avg. samples / sec: 54424.55
Iteration:   2100, Loss function: 4.589, Average Loss: 4.400, avg. samples / sec: 54447.99
Iteration:   2100, Loss function: 4.939, Average Loss: 4.431, avg. samples / sec: 54434.03
Iteration:   2100, Loss function: 4.438, Average Loss: 4.437, avg. samples / sec: 54397.62
Iteration:   2100, Loss function: 4.572, Average Loss: 4.408, avg. samples / sec: 54486.75
Iteration:   2100, Loss function: 4.429, Average Loss: 4.424, avg. samples / sec: 54433.88
Iteration:   2100, Loss function: 3.527, Average Loss: 4.407, avg. samples / sec: 54402.09
Iteration:   2100, Loss function: 4.387, Average Loss: 4.418, avg. samples / sec: 54400.83
Iteration:   2120, Loss function: 5.698, Average Loss: 4.424, avg. samples / sec: 54921.71
Iteration:   2120, Loss function: 3.761, Average Loss: 4.396, avg. samples / sec: 54755.88
Iteration:   2120, Loss function: 2.968, Average Loss: 4.416, avg. samples / sec: 54880.45
Iteration:   2120, Loss function: 4.395, Average Loss: 4.405, avg. samples / sec: 54862.23
Iteration:   2120, Loss function: 3.750, Average Loss: 4.409, avg. samples / sec: 54805.82
Iteration:   2120, Loss function: 4.178, Average Loss: 4.410, avg. samples / sec: 54831.66
Iteration:   2120, Loss function: 4.049, Average Loss: 4.404, avg. samples / sec: 54816.99
Iteration:   2120, Loss function: 4.017, Average Loss: 4.400, avg. samples / sec: 54801.41
Iteration:   2120, Loss function: 3.635, Average Loss: 4.420, avg. samples / sec: 54770.65
Iteration:   2120, Loss function: 5.140, Average Loss: 4.447, avg. samples / sec: 54785.51
Iteration:   2120, Loss function: 4.511, Average Loss: 4.398, avg. samples / sec: 54783.30
Iteration:   2120, Loss function: 5.192, Average Loss: 4.416, avg. samples / sec: 54694.17
Iteration:   2120, Loss function: 4.795, Average Loss: 4.432, avg. samples / sec: 54758.42
Iteration:   2120, Loss function: 4.504, Average Loss: 4.398, avg. samples / sec: 54828.95
Iteration:   2120, Loss function: 3.927, Average Loss: 4.388, avg. samples / sec: 54552.11
Iteration:   2120, Loss function: 3.681, Average Loss: 4.415, avg. samples / sec: 54839.79
Iteration:   2120, Loss function: 3.687, Average Loss: 4.387, avg. samples / sec: 54705.76
Iteration:   2120, Loss function: 5.038, Average Loss: 4.427, avg. samples / sec: 54864.30
Iteration:   2120, Loss function: 4.597, Average Loss: 4.416, avg. samples / sec: 54708.59
Iteration:   2120, Loss function: 3.908, Average Loss: 4.414, avg. samples / sec: 54801.17
Iteration:   2120, Loss function: 4.347, Average Loss: 4.403, avg. samples / sec: 54796.51
Iteration:   2120, Loss function: 5.301, Average Loss: 4.393, avg. samples / sec: 54816.39
Iteration:   2120, Loss function: 4.547, Average Loss: 4.422, avg. samples / sec: 54776.34
Iteration:   2120, Loss function: 3.583, Average Loss: 4.404, avg. samples / sec: 54617.80
Iteration:   2120, Loss function: 4.825, Average Loss: 4.435, avg. samples / sec: 54809.85
Iteration:   2120, Loss function: 3.680, Average Loss: 4.416, avg. samples / sec: 54898.11
Iteration:   2120, Loss function: 4.219, Average Loss: 4.412, avg. samples / sec: 54779.21
Iteration:   2120, Loss function: 4.220, Average Loss: 4.421, avg. samples / sec: 54798.47
Iteration:   2120, Loss function: 5.117, Average Loss: 4.404, avg. samples / sec: 54848.14
Iteration:   2120, Loss function: 5.136, Average Loss: 4.401, avg. samples / sec: 54762.46
Iteration:   2140, Loss function: 3.993, Average Loss: 4.418, avg. samples / sec: 54499.96
Iteration:   2140, Loss function: 4.163, Average Loss: 4.382, avg. samples / sec: 54765.65
Iteration:   2140, Loss function: 3.283, Average Loss: 4.444, avg. samples / sec: 54517.27
Iteration:   2140, Loss function: 3.922, Average Loss: 4.402, avg. samples / sec: 54420.96
Iteration:   2140, Loss function: 4.435, Average Loss: 4.409, avg. samples / sec: 54400.77
Iteration:   2140, Loss function: 4.606, Average Loss: 4.397, avg. samples / sec: 54388.28
Iteration:   2140, Loss function: 5.017, Average Loss: 4.396, avg. samples / sec: 54436.55
Iteration:   2140, Loss function: 3.930, Average Loss: 4.428, avg. samples / sec: 54465.33
Iteration:   2140, Loss function: 4.800, Average Loss: 4.406, avg. samples / sec: 54395.75
Iteration:   2140, Loss function: 3.321, Average Loss: 4.409, avg. samples / sec: 54463.82
Iteration:   2140, Loss function: 3.893, Average Loss: 4.402, avg. samples / sec: 54419.08
Iteration:   2140, Loss function: 4.496, Average Loss: 4.395, avg. samples / sec: 54444.06
Iteration:   2140, Loss function: 3.792, Average Loss: 4.412, avg. samples / sec: 54416.75
Iteration:   2140, Loss function: 3.977, Average Loss: 4.407, avg. samples / sec: 54369.66
Iteration:   2140, Loss function: 3.747, Average Loss: 4.394, avg. samples / sec: 54451.25
Iteration:   2140, Loss function: 5.508, Average Loss: 4.412, avg. samples / sec: 54431.23
Iteration:   2140, Loss function: 4.882, Average Loss: 4.396, avg. samples / sec: 54485.89
Iteration:   2140, Loss function: 3.662, Average Loss: 4.411, avg. samples / sec: 54490.52
Iteration:   2140, Loss function: 4.323, Average Loss: 4.424, avg. samples / sec: 54419.32
Iteration:   2140, Loss function: 4.372, Average Loss: 4.409, avg. samples / sec: 54433.55
Iteration:   2140, Loss function: 5.203, Average Loss: 4.399, avg. samples / sec: 54438.26
Iteration:   2140, Loss function: 5.152, Average Loss: 4.417, avg. samples / sec: 54419.40
Iteration:   2140, Loss function: 4.048, Average Loss: 4.387, avg. samples / sec: 54385.38
Iteration:   2140, Loss function: 3.232, Average Loss: 4.427, avg. samples / sec: 54455.97
Iteration:   2140, Loss function: 4.875, Average Loss: 4.389, avg. samples / sec: 54419.21
Iteration:   2140, Loss function: 4.908, Average Loss: 4.416, avg. samples / sec: 54427.22
Iteration:   2140, Loss function: 5.740, Average Loss: 4.419, avg. samples / sec: 54443.96
Iteration:   2140, Loss function: 4.400, Average Loss: 4.414, avg. samples / sec: 54408.29
Iteration:   2140, Loss function: 4.685, Average Loss: 4.399, avg. samples / sec: 54441.31
Iteration:   2140, Loss function: 4.371, Average Loss: 4.399, avg. samples / sec: 54419.42
Iteration:   2160, Loss function: 4.576, Average Loss: 4.415, avg. samples / sec: 54879.75
Iteration:   2160, Loss function: 3.564, Average Loss: 4.382, avg. samples / sec: 54859.52
Iteration:   2160, Loss function: 3.828, Average Loss: 4.396, avg. samples / sec: 54982.03
Iteration:   2160, Loss function: 4.829, Average Loss: 4.407, avg. samples / sec: 54936.48
Iteration:   2160, Loss function: 4.169, Average Loss: 4.392, avg. samples / sec: 54939.70
Iteration:   2160, Loss function: 3.371, Average Loss: 4.398, avg. samples / sec: 54926.80
Iteration:   2160, Loss function: 4.891, Average Loss: 4.392, avg. samples / sec: 54940.51
Iteration:   2160, Loss function: 4.137, Average Loss: 4.442, avg. samples / sec: 54869.96
Iteration:   2160, Loss function: 3.312, Average Loss: 4.407, avg. samples / sec: 54979.09
Iteration:   2160, Loss function: 3.474, Average Loss: 4.424, avg. samples / sec: 54934.26
Iteration:   2160, Loss function: 2.977, Average Loss: 4.406, avg. samples / sec: 54936.27
Iteration:   2160, Loss function: 4.392, Average Loss: 4.402, avg. samples / sec: 54928.52
Iteration:   2160, Loss function: 3.790, Average Loss: 4.392, avg. samples / sec: 54953.64
Iteration:   2160, Loss function: 3.731, Average Loss: 4.405, avg. samples / sec: 54897.39
Iteration:   2160, Loss function: 4.169, Average Loss: 4.408, avg. samples / sec: 54846.73
Iteration:   2160, Loss function: 4.336, Average Loss: 4.413, avg. samples / sec: 54983.12
Iteration:   2160, Loss function: 5.375, Average Loss: 4.407, avg. samples / sec: 54949.61
Iteration:   2160, Loss function: 3.412, Average Loss: 4.387, avg. samples / sec: 54965.97
Iteration:   2160, Loss function: 3.956, Average Loss: 4.414, avg. samples / sec: 54920.64
Iteration:   2160, Loss function: 3.390, Average Loss: 4.400, avg. samples / sec: 54942.29
Iteration:   2160, Loss function: 4.872, Average Loss: 4.421, avg. samples / sec: 54937.06
Iteration:   2160, Loss function: 2.752, Average Loss: 4.391, avg. samples / sec: 54918.95
Iteration:   2160, Loss function: 4.082, Average Loss: 4.397, avg. samples / sec: 54937.79
Iteration:   2160, Loss function: 3.205, Average Loss: 4.383, avg. samples / sec: 54938.17
Iteration:   2160, Loss function: 3.677, Average Loss: 4.422, avg. samples / sec: 54918.31
Iteration:   2160, Loss function: 4.271, Average Loss: 4.398, avg. samples / sec: 54988.03
Iteration:   2160, Loss function: 4.353, Average Loss: 4.416, avg. samples / sec: 54922.61
Iteration:   2160, Loss function: 2.940, Average Loss: 4.415, avg. samples / sec: 54916.30
Iteration:   2160, Loss function: 5.377, Average Loss: 4.418, avg. samples / sec: 54910.00
Iteration:   2160, Loss function: 3.770, Average Loss: 4.396, avg. samples / sec: 54926.01
:::MLL 1558640089.388 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558640089.388 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 4.753, Average Loss: 4.375, avg. samples / sec: 54700.50
Iteration:   2180, Loss function: 3.438, Average Loss: 4.413, avg. samples / sec: 54557.62
Iteration:   2180, Loss function: 4.277, Average Loss: 4.386, avg. samples / sec: 54657.07
Iteration:   2180, Loss function: 2.926, Average Loss: 4.397, avg. samples / sec: 54618.39
Iteration:   2180, Loss function: 4.176, Average Loss: 4.402, avg. samples / sec: 54601.65
Iteration:   2180, Loss function: 4.599, Average Loss: 4.402, avg. samples / sec: 54620.55
Iteration:   2180, Loss function: 3.764, Average Loss: 4.417, avg. samples / sec: 54616.97
Iteration:   2180, Loss function: 3.631, Average Loss: 4.405, avg. samples / sec: 54596.56
Iteration:   2180, Loss function: 3.498, Average Loss: 4.395, avg. samples / sec: 54634.38
Iteration:   2180, Loss function: 4.594, Average Loss: 4.391, avg. samples / sec: 54561.78
Iteration:   2180, Loss function: 3.575, Average Loss: 4.391, avg. samples / sec: 54538.35
Iteration:   2180, Loss function: 3.420, Average Loss: 4.395, avg. samples / sec: 54578.44
Iteration:   2180, Loss function: 5.169, Average Loss: 4.403, avg. samples / sec: 54643.34
Iteration:   2180, Loss function: 4.530, Average Loss: 4.391, avg. samples / sec: 54560.14
Iteration:   2180, Loss function: 4.517, Average Loss: 4.436, avg. samples / sec: 54455.59
Iteration:   2180, Loss function: 3.963, Average Loss: 4.400, avg. samples / sec: 54589.49
Iteration:   2180, Loss function: 4.255, Average Loss: 4.400, avg. samples / sec: 54598.35
Iteration:   2180, Loss function: 4.757, Average Loss: 4.412, avg. samples / sec: 54663.16
Iteration:   2180, Loss function: 5.203, Average Loss: 4.384, avg. samples / sec: 54600.85
Iteration:   2180, Loss function: 4.123, Average Loss: 4.410, avg. samples / sec: 54598.01
Iteration:   2180, Loss function: 3.579, Average Loss: 4.394, avg. samples / sec: 54599.20
Iteration:   2180, Loss function: 4.248, Average Loss: 4.387, avg. samples / sec: 54594.78
Iteration:   2180, Loss function: 3.219, Average Loss: 4.412, avg. samples / sec: 54582.87
Iteration:   2180, Loss function: 5.253, Average Loss: 4.374, avg. samples / sec: 54605.38
Iteration:   2180, Loss function: 3.697, Average Loss: 4.391, avg. samples / sec: 54554.24
Iteration:   2180, Loss function: 6.177, Average Loss: 4.398, avg. samples / sec: 54621.91
Iteration:   2180, Loss function: 4.680, Average Loss: 4.412, avg. samples / sec: 54625.19
Iteration:   2180, Loss function: 3.932, Average Loss: 4.408, avg. samples / sec: 54617.76
Iteration:   2180, Loss function: 3.853, Average Loss: 4.416, avg. samples / sec: 54617.84
Iteration:   2180, Loss function: 3.082, Average Loss: 4.384, avg. samples / sec: 54614.18
Iteration:   2200, Loss function: 3.696, Average Loss: 4.394, avg. samples / sec: 55070.38
Iteration:   2200, Loss function: 2.579, Average Loss: 4.387, avg. samples / sec: 55094.75
Iteration:   2200, Loss function: 4.887, Average Loss: 4.375, avg. samples / sec: 54825.05
Iteration:   2200, Loss function: 3.276, Average Loss: 4.426, avg. samples / sec: 55205.35
Iteration:   2200, Loss function: 3.521, Average Loss: 4.389, avg. samples / sec: 55015.49
Iteration:   2200, Loss function: 4.807, Average Loss: 4.382, avg. samples / sec: 55068.50
Iteration:   2200, Loss function: 4.091, Average Loss: 4.392, avg. samples / sec: 55016.37
Iteration:   2200, Loss function: 3.803, Average Loss: 4.384, avg. samples / sec: 54951.13
Iteration:   2200, Loss function: 3.341, Average Loss: 4.387, avg. samples / sec: 55029.17
Iteration:   2200, Loss function: 3.769, Average Loss: 4.390, avg. samples / sec: 55054.13
Iteration:   2200, Loss function: 4.229, Average Loss: 4.413, avg. samples / sec: 54989.77
Iteration:   2200, Loss function: 3.980, Average Loss: 4.407, avg. samples / sec: 54861.97
Iteration:   2200, Loss function: 3.622, Average Loss: 4.393, avg. samples / sec: 55065.10
Iteration:   2200, Loss function: 4.452, Average Loss: 4.404, avg. samples / sec: 55181.21
Iteration:   2200, Loss function: 3.743, Average Loss: 4.403, avg. samples / sec: 55033.11
Iteration:   2200, Loss function: 4.996, Average Loss: 4.387, avg. samples / sec: 55026.72
Iteration:   2200, Loss function: 3.979, Average Loss: 4.380, avg. samples / sec: 55035.45
Iteration:   2200, Loss function: 4.711, Average Loss: 4.385, avg. samples / sec: 55060.41
Iteration:   2200, Loss function: 3.838, Average Loss: 4.400, avg. samples / sec: 55014.07
Iteration:   2200, Loss function: 4.622, Average Loss: 4.374, avg. samples / sec: 55037.23
Iteration:   2200, Loss function: 3.539, Average Loss: 4.376, avg. samples / sec: 55005.63
Iteration:   2200, Loss function: 4.941, Average Loss: 4.393, avg. samples / sec: 54989.62
Iteration:   2200, Loss function: 5.480, Average Loss: 4.409, avg. samples / sec: 54974.95
Iteration:   2200, Loss function: 5.384, Average Loss: 4.397, avg. samples / sec: 55003.47
Iteration:   2200, Loss function: 3.591, Average Loss: 4.394, avg. samples / sec: 54949.87
Iteration:   2200, Loss function: 3.477, Average Loss: 4.404, avg. samples / sec: 55031.37
Iteration:   2200, Loss function: 4.290, Average Loss: 4.404, avg. samples / sec: 54775.40
Iteration:   2200, Loss function: 4.334, Average Loss: 4.411, avg. samples / sec: 55012.18
Iteration:   2200, Loss function: 4.992, Average Loss: 4.401, avg. samples / sec: 54996.77
Iteration:   2200, Loss function: 3.474, Average Loss: 4.379, avg. samples / sec: 55004.13
Iteration:   2220, Loss function: 4.916, Average Loss: 4.375, avg. samples / sec: 54077.11
Iteration:   2220, Loss function: 3.785, Average Loss: 4.399, avg. samples / sec: 54129.90
Iteration:   2220, Loss function: 5.063, Average Loss: 4.378, avg. samples / sec: 54025.20
Iteration:   2220, Loss function: 4.134, Average Loss: 4.390, avg. samples / sec: 53982.44
Iteration:   2220, Loss function: 3.422, Average Loss: 4.381, avg. samples / sec: 53948.24
Iteration:   2220, Loss function: 2.496, Average Loss: 4.388, avg. samples / sec: 53983.10
Iteration:   2220, Loss function: 3.632, Average Loss: 4.391, avg. samples / sec: 53910.68
Iteration:   2220, Loss function: 4.270, Average Loss: 4.386, avg. samples / sec: 53967.21
Iteration:   2220, Loss function: 4.972, Average Loss: 4.421, avg. samples / sec: 53919.94
Iteration:   2220, Loss function: 5.381, Average Loss: 4.398, avg. samples / sec: 54004.04
Iteration:   2220, Loss function: 4.559, Average Loss: 4.383, avg. samples / sec: 53916.33
Iteration:   2220, Loss function: 4.332, Average Loss: 4.385, avg. samples / sec: 53921.51
Iteration:   2220, Loss function: 4.491, Average Loss: 4.399, avg. samples / sec: 54168.81
Iteration:   2220, Loss function: 4.632, Average Loss: 4.386, avg. samples / sec: 53941.90
Iteration:   2220, Loss function: 3.199, Average Loss: 4.390, avg. samples / sec: 54045.56
Iteration:   2220, Loss function: 3.760, Average Loss: 4.395, avg. samples / sec: 53988.50
Iteration:   2220, Loss function: 4.722, Average Loss: 4.378, avg. samples / sec: 53991.23
Iteration:   2220, Loss function: 4.023, Average Loss: 4.373, avg. samples / sec: 53990.71
Iteration:   2220, Loss function: 4.744, Average Loss: 4.398, avg. samples / sec: 54021.66
Iteration:   2220, Loss function: 4.841, Average Loss: 4.392, avg. samples / sec: 53981.93
Iteration:   2220, Loss function: 2.690, Average Loss: 4.386, avg. samples / sec: 53965.08
Iteration:   2220, Loss function: 4.743, Average Loss: 4.372, avg. samples / sec: 53970.43
Iteration:   2220, Loss function: 5.757, Average Loss: 4.408, avg. samples / sec: 53792.55
Iteration:   2220, Loss function: 5.277, Average Loss: 4.401, avg. samples / sec: 53822.52
Iteration:   2220, Loss function: 4.502, Average Loss: 4.392, avg. samples / sec: 53996.55
Iteration:   2220, Loss function: 4.171, Average Loss: 4.398, avg. samples / sec: 53965.04
Iteration:   2220, Loss function: 4.134, Average Loss: 4.407, avg. samples / sec: 53941.76
Iteration:   2220, Loss function: 3.997, Average Loss: 4.400, avg. samples / sec: 53967.83
Iteration:   2220, Loss function: 3.055, Average Loss: 4.370, avg. samples / sec: 53956.50
Iteration:   2220, Loss function: 4.565, Average Loss: 4.374, avg. samples / sec: 53713.96
:::MLL 1558640091.549 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558640091.549 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 4.426, Average Loss: 4.381, avg. samples / sec: 54253.46
Iteration:   2240, Loss function: 3.565, Average Loss: 4.366, avg. samples / sec: 54040.40
Iteration:   2240, Loss function: 4.167, Average Loss: 4.395, avg. samples / sec: 54033.01
Iteration:   2240, Loss function: 4.021, Average Loss: 4.386, avg. samples / sec: 54002.92
Iteration:   2240, Loss function: 3.247, Average Loss: 4.376, avg. samples / sec: 54053.29
Iteration:   2240, Loss function: 4.404, Average Loss: 4.366, avg. samples / sec: 54479.57
Iteration:   2240, Loss function: 3.329, Average Loss: 4.374, avg. samples / sec: 54003.31
Iteration:   2240, Loss function: 5.077, Average Loss: 4.395, avg. samples / sec: 54068.52
Iteration:   2240, Loss function: 3.699, Average Loss: 4.372, avg. samples / sec: 53956.63
Iteration:   2240, Loss function: 3.641, Average Loss: 4.387, avg. samples / sec: 53998.47
Iteration:   2240, Loss function: 3.428, Average Loss: 4.376, avg. samples / sec: 54038.45
Iteration:   2240, Loss function: 4.026, Average Loss: 4.409, avg. samples / sec: 54015.40
Iteration:   2240, Loss function: 3.979, Average Loss: 4.407, avg. samples / sec: 54192.39
Iteration:   2240, Loss function: 3.841, Average Loss: 4.382, avg. samples / sec: 53963.05
Iteration:   2240, Loss function: 4.595, Average Loss: 4.367, avg. samples / sec: 54131.71
Iteration:   2240, Loss function: 3.056, Average Loss: 4.383, avg. samples / sec: 53991.71
Iteration:   2240, Loss function: 4.270, Average Loss: 4.397, avg. samples / sec: 53936.16
Iteration:   2240, Loss function: 3.884, Average Loss: 4.364, avg. samples / sec: 54110.41
Iteration:   2240, Loss function: 3.010, Average Loss: 4.397, avg. samples / sec: 54106.30
Iteration:   2240, Loss function: 4.088, Average Loss: 4.386, avg. samples / sec: 54092.24
Iteration:   2240, Loss function: 4.126, Average Loss: 4.377, avg. samples / sec: 54036.92
Iteration:   2240, Loss function: 3.447, Average Loss: 4.381, avg. samples / sec: 53994.71
Iteration:   2240, Loss function: 5.550, Average Loss: 4.391, avg. samples / sec: 53992.76
Iteration:   2240, Loss function: 3.889, Average Loss: 4.385, avg. samples / sec: 54027.56
Iteration:   2240, Loss function: 4.191, Average Loss: 4.371, avg. samples / sec: 53964.15
Iteration:   2240, Loss function: 4.429, Average Loss: 4.399, avg. samples / sec: 53957.25
Iteration:   2240, Loss function: 3.959, Average Loss: 4.395, avg. samples / sec: 54023.81
Iteration:   2240, Loss function: 4.636, Average Loss: 4.392, avg. samples / sec: 54010.76
Iteration:   2240, Loss function: 5.140, Average Loss: 4.395, avg. samples / sec: 54003.33
Iteration:   2240, Loss function: 4.043, Average Loss: 4.363, avg. samples / sec: 54035.72
Iteration:   2260, Loss function: 5.160, Average Loss: 4.362, avg. samples / sec: 54969.50
Iteration:   2260, Loss function: 3.894, Average Loss: 4.391, avg. samples / sec: 54979.39
Iteration:   2260, Loss function: 4.131, Average Loss: 4.375, avg. samples / sec: 54767.89
Iteration:   2260, Loss function: 4.480, Average Loss: 4.383, avg. samples / sec: 54983.31
Iteration:   2260, Loss function: 4.174, Average Loss: 4.365, avg. samples / sec: 54966.78
Iteration:   2260, Loss function: 4.051, Average Loss: 4.402, avg. samples / sec: 54981.68
Iteration:   2260, Loss function: 4.871, Average Loss: 4.376, avg. samples / sec: 54923.27
Iteration:   2260, Loss function: 4.211, Average Loss: 4.389, avg. samples / sec: 54947.96
Iteration:   2260, Loss function: 4.831, Average Loss: 4.384, avg. samples / sec: 54917.54
Iteration:   2260, Loss function: 2.911, Average Loss: 4.402, avg. samples / sec: 54963.69
Iteration:   2260, Loss function: 4.983, Average Loss: 4.376, avg. samples / sec: 54950.28
Iteration:   2260, Loss function: 4.187, Average Loss: 4.386, avg. samples / sec: 55021.25
Iteration:   2260, Loss function: 4.612, Average Loss: 4.369, avg. samples / sec: 54918.99
Iteration:   2260, Loss function: 2.129, Average Loss: 4.373, avg. samples / sec: 54969.72
Iteration:   2260, Loss function: 4.697, Average Loss: 4.394, avg. samples / sec: 54994.60
Iteration:   2260, Loss function: 4.579, Average Loss: 4.368, avg. samples / sec: 55019.68
Iteration:   2260, Loss function: 4.582, Average Loss: 4.373, avg. samples / sec: 54968.41
Iteration:   2260, Loss function: 5.428, Average Loss: 4.368, avg. samples / sec: 54835.23
Iteration:   2260, Loss function: 4.752, Average Loss: 4.379, avg. samples / sec: 54879.15
Iteration:   2260, Loss function: 5.533, Average Loss: 4.389, avg. samples / sec: 54953.77
Iteration:   2260, Loss function: 4.388, Average Loss: 4.378, avg. samples / sec: 54928.71
Iteration:   2260, Loss function: 4.528, Average Loss: 4.360, avg. samples / sec: 54850.83
Iteration:   2260, Loss function: 5.085, Average Loss: 4.364, avg. samples / sec: 54728.18
Iteration:   2260, Loss function: 4.026, Average Loss: 4.395, avg. samples / sec: 54850.21
Iteration:   2260, Loss function: 4.454, Average Loss: 4.382, avg. samples / sec: 54951.09
Iteration:   2260, Loss function: 4.691, Average Loss: 4.393, avg. samples / sec: 54991.51
Iteration:   2260, Loss function: 4.360, Average Loss: 4.391, avg. samples / sec: 54978.66
Iteration:   2260, Loss function: 3.414, Average Loss: 4.394, avg. samples / sec: 54958.01
Iteration:   2260, Loss function: 5.242, Average Loss: 4.396, avg. samples / sec: 54932.74
Iteration:   2260, Loss function: 3.787, Average Loss: 4.355, avg. samples / sec: 54935.50
Iteration:   2280, Loss function: 4.438, Average Loss: 4.357, avg. samples / sec: 55003.81
Iteration:   2280, Loss function: 3.684, Average Loss: 4.385, avg. samples / sec: 54961.12
Iteration:   2280, Loss function: 4.335, Average Loss: 4.375, avg. samples / sec: 55122.52
Iteration:   2280, Loss function: 4.766, Average Loss: 4.379, avg. samples / sec: 55103.82
Iteration:   2280, Loss function: 4.343, Average Loss: 4.381, avg. samples / sec: 55059.40
Iteration:   2280, Loss function: 3.557, Average Loss: 4.372, avg. samples / sec: 55057.25
Iteration:   2280, Loss function: 4.240, Average Loss: 4.367, avg. samples / sec: 55080.60
Iteration:   2280, Loss function: 3.254, Average Loss: 4.386, avg. samples / sec: 55046.50
Iteration:   2280, Loss function: 3.547, Average Loss: 4.369, avg. samples / sec: 55083.10
Iteration:   2280, Loss function: 3.603, Average Loss: 4.394, avg. samples / sec: 55058.41
Iteration:   2280, Loss function: 5.052, Average Loss: 4.366, avg. samples / sec: 55022.06
Iteration:   2280, Loss function: 5.350, Average Loss: 4.401, avg. samples / sec: 55024.96
Iteration:   2280, Loss function: 5.186, Average Loss: 4.367, avg. samples / sec: 55021.14
Iteration:   2280, Loss function: 3.549, Average Loss: 4.383, avg. samples / sec: 55034.55
Iteration:   2280, Loss function: 3.806, Average Loss: 4.389, avg. samples / sec: 55064.11
Iteration:   2280, Loss function: 4.487, Average Loss: 4.394, avg. samples / sec: 55139.58
Iteration:   2280, Loss function: 3.993, Average Loss: 4.385, avg. samples / sec: 55092.72
Iteration:   2280, Loss function: 3.923, Average Loss: 4.365, avg. samples / sec: 55063.86
Iteration:   2280, Loss function: 3.330, Average Loss: 4.374, avg. samples / sec: 55071.62
Iteration:   2280, Loss function: 4.657, Average Loss: 4.378, avg. samples / sec: 55074.23
Iteration:   2280, Loss function: 4.181, Average Loss: 4.365, avg. samples / sec: 55040.22
Iteration:   2280, Loss function: 4.611, Average Loss: 4.356, avg. samples / sec: 55055.94
Iteration:   2280, Loss function: 4.018, Average Loss: 4.360, avg. samples / sec: 55055.12
Iteration:   2280, Loss function: 4.340, Average Loss: 4.387, avg. samples / sec: 55107.44
Iteration:   2280, Loss function: 5.043, Average Loss: 4.384, avg. samples / sec: 55076.23
Iteration:   2280, Loss function: 4.853, Average Loss: 4.361, avg. samples / sec: 54985.59
Iteration:   2280, Loss function: 4.156, Average Loss: 4.391, avg. samples / sec: 55063.62
Iteration:   2280, Loss function: 3.602, Average Loss: 4.383, avg. samples / sec: 55029.26
Iteration:   2280, Loss function: 4.235, Average Loss: 4.392, avg. samples / sec: 55028.89
Iteration:   2280, Loss function: 3.102, Average Loss: 4.351, avg. samples / sec: 55068.01
:::MLL 1558640092.979 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.07 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=2.76s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.15211
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.28833
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.14552
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03715
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.15769
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.24496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.16691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06944
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.27616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.40281
Current AP: 0.15211 AP goal: 0.23000
:::MLL 1558640097.338 eval_accuracy: {"value": 0.15211062088367433, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558640097.439 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558640097.445 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558640097.446 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 3.920, Average Loss: 4.349, avg. samples / sec: 6540.84
Iteration:   2300, Loss function: 3.809, Average Loss: 4.367, avg. samples / sec: 6542.12
Iteration:   2300, Loss function: 3.986, Average Loss: 4.381, avg. samples / sec: 6540.33
Iteration:   2300, Loss function: 3.611, Average Loss: 4.371, avg. samples / sec: 6539.59
Iteration:   2300, Loss function: 3.531, Average Loss: 4.361, avg. samples / sec: 6542.71
Iteration:   2300, Loss function: 3.521, Average Loss: 4.381, avg. samples / sec: 6539.91
Iteration:   2300, Loss function: 3.666, Average Loss: 4.361, avg. samples / sec: 6540.19
Iteration:   2300, Loss function: 4.450, Average Loss: 4.370, avg. samples / sec: 6539.39
Iteration:   2300, Loss function: 3.689, Average Loss: 4.378, avg. samples / sec: 6543.25
Iteration:   2300, Loss function: 3.923, Average Loss: 4.378, avg. samples / sec: 6538.96
Iteration:   2300, Loss function: 5.214, Average Loss: 4.365, avg. samples / sec: 6539.58
Iteration:   2300, Loss function: 3.949, Average Loss: 4.386, avg. samples / sec: 6539.37
Iteration:   2300, Loss function: 4.494, Average Loss: 4.375, avg. samples / sec: 6538.92
Iteration:   2300, Loss function: 3.582, Average Loss: 4.381, avg. samples / sec: 6539.67
Iteration:   2300, Loss function: 4.274, Average Loss: 4.359, avg. samples / sec: 6540.79
Iteration:   2300, Loss function: 5.515, Average Loss: 4.391, avg. samples / sec: 6539.32
Iteration:   2300, Loss function: 4.651, Average Loss: 4.378, avg. samples / sec: 6539.47
Iteration:   2300, Loss function: 4.953, Average Loss: 4.377, avg. samples / sec: 6539.72
Iteration:   2300, Loss function: 3.518, Average Loss: 4.365, avg. samples / sec: 6538.93
Iteration:   2300, Loss function: 3.180, Average Loss: 4.351, avg. samples / sec: 6539.31
Iteration:   2300, Loss function: 4.371, Average Loss: 4.385, avg. samples / sec: 6536.98
Iteration:   2300, Loss function: 3.497, Average Loss: 4.379, avg. samples / sec: 6538.41
Iteration:   2300, Loss function: 3.018, Average Loss: 4.387, avg. samples / sec: 6536.31
Iteration:   2300, Loss function: 3.958, Average Loss: 4.357, avg. samples / sec: 6539.00
Iteration:   2300, Loss function: 4.214, Average Loss: 4.357, avg. samples / sec: 6539.12
Iteration:   2300, Loss function: 3.079, Average Loss: 4.363, avg. samples / sec: 6536.05
Iteration:   2300, Loss function: 4.479, Average Loss: 4.392, avg. samples / sec: 6539.23
Iteration:   2300, Loss function: 3.743, Average Loss: 4.375, avg. samples / sec: 6538.74
Iteration:   2300, Loss function: 3.715, Average Loss: 4.339, avg. samples / sec: 6539.56
Iteration:   2300, Loss function: 4.071, Average Loss: 4.382, avg. samples / sec: 6538.80
:::MLL 1558640098.226 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558640098.227 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 4.087, Average Loss: 4.379, avg. samples / sec: 53259.05
Iteration:   2320, Loss function: 5.196, Average Loss: 4.371, avg. samples / sec: 53204.80
Iteration:   2320, Loss function: 3.442, Average Loss: 4.345, avg. samples / sec: 53130.45
Iteration:   2320, Loss function: 3.842, Average Loss: 4.380, avg. samples / sec: 53329.45
Iteration:   2320, Loss function: 3.842, Average Loss: 4.367, avg. samples / sec: 53230.18
Iteration:   2320, Loss function: 4.798, Average Loss: 4.376, avg. samples / sec: 53247.60
Iteration:   2320, Loss function: 4.233, Average Loss: 4.374, avg. samples / sec: 53248.30
Iteration:   2320, Loss function: 5.299, Average Loss: 4.359, avg. samples / sec: 53227.91
Iteration:   2320, Loss function: 4.214, Average Loss: 4.363, avg. samples / sec: 53197.45
Iteration:   2320, Loss function: 4.402, Average Loss: 4.381, avg. samples / sec: 53233.10
Iteration:   2320, Loss function: 4.675, Average Loss: 4.357, avg. samples / sec: 53284.71
Iteration:   2320, Loss function: 5.488, Average Loss: 4.356, avg. samples / sec: 53171.88
Iteration:   2320, Loss function: 4.402, Average Loss: 4.378, avg. samples / sec: 53183.36
Iteration:   2320, Loss function: 4.785, Average Loss: 4.362, avg. samples / sec: 53148.36
Iteration:   2320, Loss function: 4.286, Average Loss: 4.377, avg. samples / sec: 53195.34
Iteration:   2320, Loss function: 4.283, Average Loss: 4.370, avg. samples / sec: 53403.59
Iteration:   2320, Loss function: 5.046, Average Loss: 4.377, avg. samples / sec: 53237.12
Iteration:   2320, Loss function: 4.381, Average Loss: 4.374, avg. samples / sec: 53270.77
Iteration:   2320, Loss function: 3.510, Average Loss: 4.390, avg. samples / sec: 53274.17
Iteration:   2320, Loss function: 5.143, Average Loss: 4.375, avg. samples / sec: 53203.64
Iteration:   2320, Loss function: 4.211, Average Loss: 4.358, avg. samples / sec: 53230.14
Iteration:   2320, Loss function: 5.256, Average Loss: 4.348, avg. samples / sec: 53233.66
Iteration:   2320, Loss function: 5.716, Average Loss: 4.387, avg. samples / sec: 53152.03
Iteration:   2320, Loss function: 4.738, Average Loss: 4.351, avg. samples / sec: 53246.37
Iteration:   2320, Loss function: 5.821, Average Loss: 4.375, avg. samples / sec: 53220.84
Iteration:   2320, Loss function: 4.207, Average Loss: 4.357, avg. samples / sec: 53229.34
Iteration:   2320, Loss function: 4.310, Average Loss: 4.377, avg. samples / sec: 53261.33
Iteration:   2320, Loss function: 4.447, Average Loss: 4.390, avg. samples / sec: 53223.59
Iteration:   2320, Loss function: 3.611, Average Loss: 4.357, avg. samples / sec: 53191.21
Iteration:   2320, Loss function: 4.293, Average Loss: 4.339, avg. samples / sec: 53204.76
Iteration:   2340, Loss function: 3.343, Average Loss: 4.355, avg. samples / sec: 53660.29
Iteration:   2340, Loss function: 3.041, Average Loss: 4.338, avg. samples / sec: 53582.95
Iteration:   2340, Loss function: 4.562, Average Loss: 4.379, avg. samples / sec: 53572.11
Iteration:   2340, Loss function: 4.188, Average Loss: 4.360, avg. samples / sec: 53748.42
Iteration:   2340, Loss function: 4.128, Average Loss: 4.358, avg. samples / sec: 53696.64
Iteration:   2340, Loss function: 6.500, Average Loss: 4.371, avg. samples / sec: 53529.24
Iteration:   2340, Loss function: 4.582, Average Loss: 4.366, avg. samples / sec: 53661.42
Iteration:   2340, Loss function: 3.022, Average Loss: 4.354, avg. samples / sec: 53674.00
Iteration:   2340, Loss function: 3.448, Average Loss: 4.375, avg. samples / sec: 53658.56
Iteration:   2340, Loss function: 4.177, Average Loss: 4.371, avg. samples / sec: 53455.51
Iteration:   2340, Loss function: 4.838, Average Loss: 4.370, avg. samples / sec: 53690.77
Iteration:   2340, Loss function: 4.440, Average Loss: 4.356, avg. samples / sec: 53582.23
Iteration:   2340, Loss function: 4.355, Average Loss: 4.357, avg. samples / sec: 53713.32
Iteration:   2340, Loss function: 3.336, Average Loss: 4.369, avg. samples / sec: 53670.43
Iteration:   2340, Loss function: 3.150, Average Loss: 4.385, avg. samples / sec: 53701.82
Iteration:   2340, Loss function: 3.994, Average Loss: 4.341, avg. samples / sec: 53685.05
Iteration:   2340, Loss function: 4.295, Average Loss: 4.371, avg. samples / sec: 53690.40
Iteration:   2340, Loss function: 3.618, Average Loss: 4.372, avg. samples / sec: 53646.83
Iteration:   2340, Loss function: 4.619, Average Loss: 4.350, avg. samples / sec: 53684.35
Iteration:   2340, Loss function: 3.874, Average Loss: 4.385, avg. samples / sec: 53641.32
Iteration:   2340, Loss function: 4.495, Average Loss: 4.367, avg. samples / sec: 53648.40
Iteration:   2340, Loss function: 4.013, Average Loss: 4.355, avg. samples / sec: 53667.34
Iteration:   2340, Loss function: 3.680, Average Loss: 4.354, avg. samples / sec: 53702.64
Iteration:   2340, Loss function: 4.977, Average Loss: 4.375, avg. samples / sec: 53493.15
Iteration:   2340, Loss function: 5.004, Average Loss: 4.370, avg. samples / sec: 53360.34
Iteration:   2340, Loss function: 3.388, Average Loss: 4.389, avg. samples / sec: 53676.23
Iteration:   2340, Loss function: 3.458, Average Loss: 4.369, avg. samples / sec: 53651.43
Iteration:   2340, Loss function: 4.080, Average Loss: 4.355, avg. samples / sec: 53396.31
Iteration:   2340, Loss function: 5.193, Average Loss: 4.372, avg. samples / sec: 53394.35
Iteration:   2340, Loss function: 3.416, Average Loss: 4.332, avg. samples / sec: 53652.39
Iteration:   2360, Loss function: 4.088, Average Loss: 4.364, avg. samples / sec: 54006.38
Iteration:   2360, Loss function: 4.386, Average Loss: 4.367, avg. samples / sec: 53992.39
Iteration:   2360, Loss function: 3.670, Average Loss: 4.332, avg. samples / sec: 53927.83
Iteration:   2360, Loss function: 3.961, Average Loss: 4.349, avg. samples / sec: 53826.88
Iteration:   2360, Loss function: 3.744, Average Loss: 4.361, avg. samples / sec: 53870.11
Iteration:   2360, Loss function: 3.566, Average Loss: 4.365, avg. samples / sec: 54138.91
Iteration:   2360, Loss function: 4.953, Average Loss: 4.366, avg. samples / sec: 53859.11
Iteration:   2360, Loss function: 3.775, Average Loss: 4.349, avg. samples / sec: 53905.82
Iteration:   2360, Loss function: 3.529, Average Loss: 4.347, avg. samples / sec: 54120.36
Iteration:   2360, Loss function: 3.443, Average Loss: 4.368, avg. samples / sec: 54137.91
Iteration:   2360, Loss function: 4.281, Average Loss: 4.335, avg. samples / sec: 54027.25
Iteration:   2360, Loss function: 4.243, Average Loss: 4.355, avg. samples / sec: 53797.76
Iteration:   2360, Loss function: 4.522, Average Loss: 4.371, avg. samples / sec: 53793.90
Iteration:   2360, Loss function: 4.751, Average Loss: 4.355, avg. samples / sec: 53832.49
Iteration:   2360, Loss function: 3.642, Average Loss: 4.351, avg. samples / sec: 53784.37
Iteration:   2360, Loss function: 3.281, Average Loss: 4.367, avg. samples / sec: 53814.44
Iteration:   2360, Loss function: 5.360, Average Loss: 4.352, avg. samples / sec: 53854.91
Iteration:   2360, Loss function: 4.720, Average Loss: 4.361, avg. samples / sec: 53881.72
Iteration:   2360, Loss function: 3.331, Average Loss: 4.365, avg. samples / sec: 53829.51
Iteration:   2360, Loss function: 4.132, Average Loss: 4.381, avg. samples / sec: 53843.49
Iteration:   2360, Loss function: 3.338, Average Loss: 4.349, avg. samples / sec: 53784.03
Iteration:   2360, Loss function: 4.887, Average Loss: 4.379, avg. samples / sec: 53815.98
Iteration:   2360, Loss function: 3.439, Average Loss: 4.367, avg. samples / sec: 53803.14
Iteration:   2360, Loss function: 4.954, Average Loss: 4.347, avg. samples / sec: 53853.88
Iteration:   2360, Loss function: 3.457, Average Loss: 4.368, avg. samples / sec: 53792.46
Iteration:   2360, Loss function: 4.170, Average Loss: 4.359, avg. samples / sec: 53804.46
Iteration:   2360, Loss function: 4.309, Average Loss: 4.382, avg. samples / sec: 53832.78
Iteration:   2360, Loss function: 3.407, Average Loss: 4.332, avg. samples / sec: 53866.50
Iteration:   2360, Loss function: 5.096, Average Loss: 4.369, avg. samples / sec: 53823.05
Iteration:   2360, Loss function: 5.035, Average Loss: 4.365, avg. samples / sec: 53816.44
:::MLL 1558640100.420 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558640100.421 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 4.170, Average Loss: 4.325, avg. samples / sec: 53425.24
Iteration:   2380, Loss function: 3.734, Average Loss: 4.360, avg. samples / sec: 53408.21
Iteration:   2380, Loss function: 5.322, Average Loss: 4.342, avg. samples / sec: 53476.32
Iteration:   2380, Loss function: 4.400, Average Loss: 4.348, avg. samples / sec: 53500.38
Iteration:   2380, Loss function: 5.154, Average Loss: 4.354, avg. samples / sec: 53278.30
Iteration:   2380, Loss function: 2.909, Average Loss: 4.364, avg. samples / sec: 53418.84
Iteration:   2380, Loss function: 4.017, Average Loss: 4.359, avg. samples / sec: 53345.52
Iteration:   2380, Loss function: 3.973, Average Loss: 4.358, avg. samples / sec: 53381.00
Iteration:   2380, Loss function: 4.027, Average Loss: 4.350, avg. samples / sec: 53370.24
Iteration:   2380, Loss function: 3.075, Average Loss: 4.343, avg. samples / sec: 53357.03
Iteration:   2380, Loss function: 3.872, Average Loss: 4.365, avg. samples / sec: 53388.08
Iteration:   2380, Loss function: 4.431, Average Loss: 4.347, avg. samples / sec: 53352.16
Iteration:   2380, Loss function: 4.359, Average Loss: 4.357, avg. samples / sec: 53279.91
Iteration:   2380, Loss function: 3.815, Average Loss: 4.334, avg. samples / sec: 53309.32
Iteration:   2380, Loss function: 3.738, Average Loss: 4.351, avg. samples / sec: 53308.87
Iteration:   2380, Loss function: 2.912, Average Loss: 4.355, avg. samples / sec: 53283.68
Iteration:   2380, Loss function: 4.050, Average Loss: 4.374, avg. samples / sec: 53462.89
Iteration:   2380, Loss function: 4.045, Average Loss: 4.344, avg. samples / sec: 53415.23
Iteration:   2380, Loss function: 4.786, Average Loss: 4.354, avg. samples / sec: 53408.57
Iteration:   2380, Loss function: 3.389, Average Loss: 4.375, avg. samples / sec: 53351.11
Iteration:   2380, Loss function: 3.586, Average Loss: 4.360, avg. samples / sec: 53333.93
Iteration:   2380, Loss function: 4.329, Average Loss: 4.344, avg. samples / sec: 53299.34
Iteration:   2380, Loss function: 3.432, Average Loss: 4.364, avg. samples / sec: 53358.30
Iteration:   2380, Loss function: 2.209, Average Loss: 4.354, avg. samples / sec: 53290.25
Iteration:   2380, Loss function: 3.057, Average Loss: 4.375, avg. samples / sec: 53358.40
Iteration:   2380, Loss function: 3.890, Average Loss: 4.343, avg. samples / sec: 53311.66
Iteration:   2380, Loss function: 4.179, Average Loss: 4.359, avg. samples / sec: 53354.89
Iteration:   2380, Loss function: 3.926, Average Loss: 4.359, avg. samples / sec: 53281.46
Iteration:   2380, Loss function: 3.834, Average Loss: 4.365, avg. samples / sec: 53322.71
Iteration:   2380, Loss function: 5.008, Average Loss: 4.330, avg. samples / sec: 53287.04
Iteration:   2400, Loss function: 4.260, Average Loss: 4.356, avg. samples / sec: 53590.32
Iteration:   2400, Loss function: 3.248, Average Loss: 4.321, avg. samples / sec: 53498.35
Iteration:   2400, Loss function: 4.720, Average Loss: 4.356, avg. samples / sec: 53649.67
Iteration:   2400, Loss function: 4.296, Average Loss: 4.343, avg. samples / sec: 53601.47
Iteration:   2400, Loss function: 3.781, Average Loss: 4.331, avg. samples / sec: 53628.44
Iteration:   2400, Loss function: 5.465, Average Loss: 4.345, avg. samples / sec: 53596.95
Iteration:   2400, Loss function: 4.580, Average Loss: 4.354, avg. samples / sec: 53446.75
Iteration:   2400, Loss function: 3.447, Average Loss: 4.340, avg. samples / sec: 53603.71
Iteration:   2400, Loss function: 3.831, Average Loss: 4.345, avg. samples / sec: 53608.42
Iteration:   2400, Loss function: 4.636, Average Loss: 4.344, avg. samples / sec: 53365.68
Iteration:   2400, Loss function: 4.508, Average Loss: 4.355, avg. samples / sec: 53479.27
Iteration:   2400, Loss function: 3.827, Average Loss: 4.341, avg. samples / sec: 53399.32
Iteration:   2400, Loss function: 3.291, Average Loss: 4.362, avg. samples / sec: 53546.69
Iteration:   2400, Loss function: 5.314, Average Loss: 4.353, avg. samples / sec: 53465.81
Iteration:   2400, Loss function: 3.417, Average Loss: 4.350, avg. samples / sec: 53674.35
Iteration:   2400, Loss function: 4.174, Average Loss: 4.339, avg. samples / sec: 53607.71
Iteration:   2400, Loss function: 4.497, Average Loss: 4.361, avg. samples / sec: 53616.13
Iteration:   2400, Loss function: 3.920, Average Loss: 4.367, avg. samples / sec: 53579.73
Iteration:   2400, Loss function: 3.736, Average Loss: 4.352, avg. samples / sec: 53579.48
Iteration:   2400, Loss function: 4.777, Average Loss: 4.352, avg. samples / sec: 53536.78
Iteration:   2400, Loss function: 4.534, Average Loss: 4.367, avg. samples / sec: 53438.08
Iteration:   2400, Loss function: 2.967, Average Loss: 4.342, avg. samples / sec: 53476.14
Iteration:   2400, Loss function: 3.826, Average Loss: 4.348, avg. samples / sec: 53301.43
Iteration:   2400, Loss function: 3.310, Average Loss: 4.355, avg. samples / sec: 53568.24
Iteration:   2400, Loss function: 4.022, Average Loss: 4.322, avg. samples / sec: 53643.34
Iteration:   2400, Loss function: 3.259, Average Loss: 4.333, avg. samples / sec: 53571.05
Iteration:   2400, Loss function: 4.025, Average Loss: 4.358, avg. samples / sec: 53574.00
Iteration:   2400, Loss function: 5.324, Average Loss: 4.353, avg. samples / sec: 53243.34
Iteration:   2400, Loss function: 3.689, Average Loss: 4.366, avg. samples / sec: 53539.55
Iteration:   2400, Loss function: 3.812, Average Loss: 4.370, avg. samples / sec: 53461.27
Iteration:   2420, Loss function: 3.490, Average Loss: 4.318, avg. samples / sec: 53687.75
Iteration:   2420, Loss function: 4.857, Average Loss: 4.355, avg. samples / sec: 53737.55
Iteration:   2420, Loss function: 3.328, Average Loss: 4.332, avg. samples / sec: 53748.21
Iteration:   2420, Loss function: 3.392, Average Loss: 4.352, avg. samples / sec: 53513.56
Iteration:   2420, Loss function: 5.239, Average Loss: 4.355, avg. samples / sec: 53597.97
Iteration:   2420, Loss function: 3.137, Average Loss: 4.347, avg. samples / sec: 53694.41
Iteration:   2420, Loss function: 4.459, Average Loss: 4.340, avg. samples / sec: 53590.59
Iteration:   2420, Loss function: 4.273, Average Loss: 4.347, avg. samples / sec: 53871.03
Iteration:   2420, Loss function: 4.480, Average Loss: 4.326, avg. samples / sec: 53604.31
Iteration:   2420, Loss function: 4.565, Average Loss: 4.343, avg. samples / sec: 53636.79
Iteration:   2420, Loss function: 4.565, Average Loss: 4.352, avg. samples / sec: 53643.48
Iteration:   2420, Loss function: 3.605, Average Loss: 4.339, avg. samples / sec: 53587.84
Iteration:   2420, Loss function: 4.171, Average Loss: 4.349, avg. samples / sec: 53875.91
Iteration:   2420, Loss function: 4.912, Average Loss: 4.338, avg. samples / sec: 53609.91
Iteration:   2420, Loss function: 5.440, Average Loss: 4.341, avg. samples / sec: 53595.93
Iteration:   2420, Loss function: 4.543, Average Loss: 4.356, avg. samples / sec: 53594.95
Iteration:   2420, Loss function: 5.740, Average Loss: 4.351, avg. samples / sec: 53654.69
Iteration:   2420, Loss function: 3.492, Average Loss: 4.347, avg. samples / sec: 53616.52
Iteration:   2420, Loss function: 4.518, Average Loss: 4.339, avg. samples / sec: 53622.23
Iteration:   2420, Loss function: 5.669, Average Loss: 4.339, avg. samples / sec: 53629.60
Iteration:   2420, Loss function: 3.563, Average Loss: 4.364, avg. samples / sec: 53589.00
Iteration:   2420, Loss function: 3.610, Average Loss: 4.362, avg. samples / sec: 53724.81
Iteration:   2420, Loss function: 4.603, Average Loss: 4.357, avg. samples / sec: 53618.68
Iteration:   2420, Loss function: 3.461, Average Loss: 4.347, avg. samples / sec: 53636.21
Iteration:   2420, Loss function: 5.320, Average Loss: 4.362, avg. samples / sec: 53572.33
Iteration:   2420, Loss function: 4.185, Average Loss: 4.349, avg. samples / sec: 53569.97
Iteration:   2420, Loss function: 3.568, Average Loss: 4.363, avg. samples / sec: 53713.69
Iteration:   2420, Loss function: 3.456, Average Loss: 4.333, avg. samples / sec: 53619.97
Iteration:   2420, Loss function: 4.112, Average Loss: 4.354, avg. samples / sec: 53592.50
Iteration:   2420, Loss function: 5.251, Average Loss: 4.319, avg. samples / sec: 53584.60
Iteration:   2440, Loss function: 4.348, Average Loss: 4.317, avg. samples / sec: 53670.28
Iteration:   2440, Loss function: 4.561, Average Loss: 4.347, avg. samples / sec: 53689.93
Iteration:   2440, Loss function: 3.458, Average Loss: 4.346, avg. samples / sec: 53666.93
Iteration:   2440, Loss function: 4.247, Average Loss: 4.345, avg. samples / sec: 53716.15
Iteration:   2440, Loss function: 3.534, Average Loss: 4.348, avg. samples / sec: 53647.69
Iteration:   2440, Loss function: 3.240, Average Loss: 4.335, avg. samples / sec: 53698.77
Iteration:   2440, Loss function: 4.186, Average Loss: 4.342, avg. samples / sec: 53644.89
Iteration:   2440, Loss function: 5.695, Average Loss: 4.336, avg. samples / sec: 53641.97
Iteration:   2440, Loss function: 5.154, Average Loss: 4.348, avg. samples / sec: 53650.51
Iteration:   2440, Loss function: 5.598, Average Loss: 4.337, avg. samples / sec: 53668.18
Iteration:   2440, Loss function: 4.487, Average Loss: 4.339, avg. samples / sec: 53674.90
Iteration:   2440, Loss function: 3.563, Average Loss: 4.334, avg. samples / sec: 53663.19
Iteration:   2440, Loss function: 4.695, Average Loss: 4.339, avg. samples / sec: 53630.01
Iteration:   2440, Loss function: 4.711, Average Loss: 4.331, avg. samples / sec: 53506.62
Iteration:   2440, Loss function: 3.763, Average Loss: 4.350, avg. samples / sec: 53682.37
Iteration:   2440, Loss function: 3.756, Average Loss: 4.326, avg. samples / sec: 53611.20
Iteration:   2440, Loss function: 5.355, Average Loss: 4.342, avg. samples / sec: 53661.27
Iteration:   2440, Loss function: 3.691, Average Loss: 4.342, avg. samples / sec: 53636.79
Iteration:   2440, Loss function: 3.760, Average Loss: 4.333, avg. samples / sec: 53632.70
Iteration:   2440, Loss function: 4.905, Average Loss: 4.354, avg. samples / sec: 53667.04
Iteration:   2440, Loss function: 4.354, Average Loss: 4.346, avg. samples / sec: 53669.73
Iteration:   2440, Loss function: 4.573, Average Loss: 4.358, avg. samples / sec: 53680.08
Iteration:   2440, Loss function: 4.041, Average Loss: 4.346, avg. samples / sec: 53702.74
Iteration:   2440, Loss function: 4.786, Average Loss: 4.337, avg. samples / sec: 53663.81
Iteration:   2440, Loss function: 3.881, Average Loss: 4.356, avg. samples / sec: 53644.03
Iteration:   2440, Loss function: 4.864, Average Loss: 4.330, avg. samples / sec: 53678.58
Iteration:   2440, Loss function: 6.653, Average Loss: 4.359, avg. samples / sec: 53654.88
Iteration:   2440, Loss function: 4.579, Average Loss: 4.314, avg. samples / sec: 53676.13
Iteration:   2440, Loss function: 2.117, Average Loss: 4.357, avg. samples / sec: 53601.66
Iteration:   2440, Loss function: 3.940, Average Loss: 4.351, avg. samples / sec: 53653.65
:::MLL 1558640102.617 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558640102.617 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 3.574, Average Loss: 4.306, avg. samples / sec: 52617.76
Iteration:   2460, Loss function: 4.699, Average Loss: 4.337, avg. samples / sec: 52692.32
Iteration:   2460, Loss function: 4.609, Average Loss: 4.340, avg. samples / sec: 52698.39
Iteration:   2460, Loss function: 2.953, Average Loss: 4.328, avg. samples / sec: 52789.45
Iteration:   2460, Loss function: 4.343, Average Loss: 4.346, avg. samples / sec: 52671.31
Iteration:   2460, Loss function: 2.896, Average Loss: 4.330, avg. samples / sec: 52703.89
Iteration:   2460, Loss function: 3.748, Average Loss: 4.334, avg. samples / sec: 52859.92
Iteration:   2460, Loss function: 3.995, Average Loss: 4.332, avg. samples / sec: 52653.68
Iteration:   2460, Loss function: 4.385, Average Loss: 4.329, avg. samples / sec: 52629.82
Iteration:   2460, Loss function: 4.212, Average Loss: 4.324, avg. samples / sec: 52659.95
Iteration:   2460, Loss function: 3.253, Average Loss: 4.334, avg. samples / sec: 52640.83
Iteration:   2460, Loss function: 4.197, Average Loss: 4.327, avg. samples / sec: 52620.80
Iteration:   2460, Loss function: 3.820, Average Loss: 4.345, avg. samples / sec: 52628.45
Iteration:   2460, Loss function: 3.210, Average Loss: 4.332, avg. samples / sec: 52632.63
Iteration:   2460, Loss function: 4.310, Average Loss: 4.324, avg. samples / sec: 52658.42
Iteration:   2460, Loss function: 4.255, Average Loss: 4.342, avg. samples / sec: 52644.63
Iteration:   2460, Loss function: 3.553, Average Loss: 4.336, avg. samples / sec: 52537.35
Iteration:   2460, Loss function: 5.544, Average Loss: 4.349, avg. samples / sec: 52663.30
Iteration:   2460, Loss function: 3.596, Average Loss: 4.326, avg. samples / sec: 52648.23
Iteration:   2460, Loss function: 4.081, Average Loss: 4.353, avg. samples / sec: 52640.48
Iteration:   2460, Loss function: 5.161, Average Loss: 4.352, avg. samples / sec: 52675.74
Iteration:   2460, Loss function: 4.975, Average Loss: 4.332, avg. samples / sec: 52640.85
Iteration:   2460, Loss function: 3.603, Average Loss: 4.332, avg. samples / sec: 52594.98
Iteration:   2460, Loss function: 3.034, Average Loss: 4.345, avg. samples / sec: 52699.79
Iteration:   2460, Loss function: 4.597, Average Loss: 4.339, avg. samples / sec: 52624.93
Iteration:   2460, Loss function: 4.079, Average Loss: 4.310, avg. samples / sec: 52673.34
Iteration:   2460, Loss function: 5.163, Average Loss: 4.320, avg. samples / sec: 52639.99
Iteration:   2460, Loss function: 6.270, Average Loss: 4.345, avg. samples / sec: 52599.95
Iteration:   2460, Loss function: 4.139, Average Loss: 4.354, avg. samples / sec: 52658.65
Iteration:   2460, Loss function: 3.802, Average Loss: 4.349, avg. samples / sec: 52636.66
Iteration:   2480, Loss function: 3.136, Average Loss: 4.334, avg. samples / sec: 53605.47
Iteration:   2480, Loss function: 4.838, Average Loss: 4.328, avg. samples / sec: 53676.11
Iteration:   2480, Loss function: 4.279, Average Loss: 4.323, avg. samples / sec: 53601.84
Iteration:   2480, Loss function: 4.405, Average Loss: 4.330, avg. samples / sec: 53680.63
Iteration:   2480, Loss function: 4.500, Average Loss: 4.313, avg. samples / sec: 53651.88
Iteration:   2480, Loss function: 4.617, Average Loss: 4.327, avg. samples / sec: 53632.50
Iteration:   2480, Loss function: 4.550, Average Loss: 4.302, avg. samples / sec: 53391.19
Iteration:   2480, Loss function: 3.830, Average Loss: 4.324, avg. samples / sec: 53592.46
Iteration:   2480, Loss function: 4.259, Average Loss: 4.328, avg. samples / sec: 53585.41
Iteration:   2480, Loss function: 3.406, Average Loss: 4.318, avg. samples / sec: 53573.88
Iteration:   2480, Loss function: 3.600, Average Loss: 4.331, avg. samples / sec: 53601.82
Iteration:   2480, Loss function: 4.457, Average Loss: 4.334, avg. samples / sec: 53361.58
Iteration:   2480, Loss function: 4.342, Average Loss: 4.346, avg. samples / sec: 53780.60
Iteration:   2480, Loss function: 5.351, Average Loss: 4.327, avg. samples / sec: 53433.64
Iteration:   2480, Loss function: 4.641, Average Loss: 4.347, avg. samples / sec: 53478.37
Iteration:   2480, Loss function: 4.786, Average Loss: 4.337, avg. samples / sec: 53493.29
Iteration:   2480, Loss function: 4.794, Average Loss: 4.326, avg. samples / sec: 53380.07
Iteration:   2480, Loss function: 4.229, Average Loss: 4.327, avg. samples / sec: 53602.41
Iteration:   2480, Loss function: 3.493, Average Loss: 4.342, avg. samples / sec: 53573.98
Iteration:   2480, Loss function: 4.128, Average Loss: 4.345, avg. samples / sec: 53583.46
Iteration:   2480, Loss function: 4.616, Average Loss: 4.328, avg. samples / sec: 53587.88
Iteration:   2480, Loss function: 5.464, Average Loss: 4.329, avg. samples / sec: 53342.21
Iteration:   2480, Loss function: 5.067, Average Loss: 4.320, avg. samples / sec: 53570.07
Iteration:   2480, Loss function: 5.285, Average Loss: 4.345, avg. samples / sec: 53613.18
Iteration:   2480, Loss function: 3.522, Average Loss: 4.333, avg. samples / sec: 53583.39
Iteration:   2480, Loss function: 3.704, Average Loss: 4.344, avg. samples / sec: 53607.24
Iteration:   2480, Loss function: 3.987, Average Loss: 4.309, avg. samples / sec: 53582.36
Iteration:   2480, Loss function: 4.343, Average Loss: 4.339, avg. samples / sec: 53552.30
Iteration:   2480, Loss function: 4.844, Average Loss: 4.303, avg. samples / sec: 53563.68
Iteration:   2480, Loss function: 4.535, Average Loss: 4.345, avg. samples / sec: 53583.13
Iteration:   2500, Loss function: 5.115, Average Loss: 4.303, avg. samples / sec: 53970.70
Iteration:   2500, Loss function: 4.083, Average Loss: 4.332, avg. samples / sec: 53984.14
Iteration:   2500, Loss function: 3.941, Average Loss: 4.324, avg. samples / sec: 53956.17
Iteration:   2500, Loss function: 4.330, Average Loss: 4.334, avg. samples / sec: 53681.51
Iteration:   2500, Loss function: 3.834, Average Loss: 4.323, avg. samples / sec: 53688.18
Iteration:   2500, Loss function: 4.557, Average Loss: 4.327, avg. samples / sec: 53988.15
Iteration:   2500, Loss function: 3.327, Average Loss: 4.315, avg. samples / sec: 53701.51
Iteration:   2500, Loss function: 2.709, Average Loss: 4.317, avg. samples / sec: 53768.33
Iteration:   2500, Loss function: 3.420, Average Loss: 4.330, avg. samples / sec: 53824.35
Iteration:   2500, Loss function: 3.974, Average Loss: 4.315, avg. samples / sec: 53722.23
Iteration:   2500, Loss function: 2.907, Average Loss: 4.320, avg. samples / sec: 53731.12
Iteration:   2500, Loss function: 3.722, Average Loss: 4.326, avg. samples / sec: 53655.72
Iteration:   2500, Loss function: 4.051, Average Loss: 4.324, avg. samples / sec: 53684.08
Iteration:   2500, Loss function: 6.003, Average Loss: 4.311, avg. samples / sec: 53660.15
Iteration:   2500, Loss function: 3.667, Average Loss: 4.321, avg. samples / sec: 53705.32
Iteration:   2500, Loss function: 2.984, Average Loss: 4.349, avg. samples / sec: 53706.67
Iteration:   2500, Loss function: 3.549, Average Loss: 4.320, avg. samples / sec: 53751.98
Iteration:   2500, Loss function: 4.937, Average Loss: 4.319, avg. samples / sec: 53712.59
Iteration:   2500, Loss function: 4.141, Average Loss: 4.319, avg. samples / sec: 53757.31
Iteration:   2500, Loss function: 3.243, Average Loss: 4.343, avg. samples / sec: 53763.63
Iteration:   2500, Loss function: 3.251, Average Loss: 4.327, avg. samples / sec: 53735.48
Iteration:   2500, Loss function: 3.170, Average Loss: 4.336, avg. samples / sec: 53732.94
Iteration:   2500, Loss function: 3.644, Average Loss: 4.327, avg. samples / sec: 53744.17
Iteration:   2500, Loss function: 4.311, Average Loss: 4.338, avg. samples / sec: 53717.62
Iteration:   2500, Loss function: 4.415, Average Loss: 4.343, avg. samples / sec: 53528.97
Iteration:   2500, Loss function: 4.419, Average Loss: 4.334, avg. samples / sec: 53760.57
Iteration:   2500, Loss function: 4.098, Average Loss: 4.348, avg. samples / sec: 53732.00
Iteration:   2500, Loss function: 3.817, Average Loss: 4.340, avg. samples / sec: 53756.51
Iteration:   2500, Loss function: 2.987, Average Loss: 4.295, avg. samples / sec: 53721.74
Iteration:   2500, Loss function: 2.683, Average Loss: 4.302, avg. samples / sec: 53684.82
:::MLL 1558640104.824 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558640104.824 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 3.887, Average Loss: 4.300, avg. samples / sec: 53076.52
Iteration:   2520, Loss function: 3.820, Average Loss: 4.329, avg. samples / sec: 53061.73
Iteration:   2520, Loss function: 3.867, Average Loss: 4.324, avg. samples / sec: 53062.85
Iteration:   2520, Loss function: 4.773, Average Loss: 4.319, avg. samples / sec: 53009.54
Iteration:   2520, Loss function: 3.850, Average Loss: 4.320, avg. samples / sec: 53187.94
Iteration:   2520, Loss function: 4.093, Average Loss: 4.326, avg. samples / sec: 53111.28
Iteration:   2520, Loss function: 2.621, Average Loss: 4.315, avg. samples / sec: 53150.30
Iteration:   2520, Loss function: 4.166, Average Loss: 4.305, avg. samples / sec: 53109.42
Iteration:   2520, Loss function: 4.556, Average Loss: 4.312, avg. samples / sec: 53171.76
Iteration:   2520, Loss function: 3.809, Average Loss: 4.310, avg. samples / sec: 53090.96
Iteration:   2520, Loss function: 4.359, Average Loss: 4.341, avg. samples / sec: 53178.38
Iteration:   2520, Loss function: 3.618, Average Loss: 4.329, avg. samples / sec: 53122.34
Iteration:   2520, Loss function: 3.187, Average Loss: 4.314, avg. samples / sec: 53056.36
Iteration:   2520, Loss function: 4.678, Average Loss: 4.310, avg. samples / sec: 53090.58
Iteration:   2520, Loss function: 4.217, Average Loss: 4.310, avg. samples / sec: 53079.66
Iteration:   2520, Loss function: 4.691, Average Loss: 4.317, avg. samples / sec: 53067.67
Iteration:   2520, Loss function: 4.083, Average Loss: 4.320, avg. samples / sec: 53191.13
Iteration:   2520, Loss function: 5.559, Average Loss: 4.341, avg. samples / sec: 53208.52
Iteration:   2520, Loss function: 3.714, Average Loss: 4.325, avg. samples / sec: 53155.11
Iteration:   2520, Loss function: 4.135, Average Loss: 4.310, avg. samples / sec: 53126.62
Iteration:   2520, Loss function: 3.019, Average Loss: 4.308, avg. samples / sec: 53112.63
Iteration:   2520, Loss function: 3.666, Average Loss: 4.331, avg. samples / sec: 53137.62
Iteration:   2520, Loss function: 4.248, Average Loss: 4.326, avg. samples / sec: 53144.35
Iteration:   2520, Loss function: 4.379, Average Loss: 4.308, avg. samples / sec: 53100.22
Iteration:   2520, Loss function: 3.894, Average Loss: 4.334, avg. samples / sec: 53105.32
Iteration:   2520, Loss function: 4.034, Average Loss: 4.320, avg. samples / sec: 53101.92
Iteration:   2520, Loss function: 4.369, Average Loss: 4.341, avg. samples / sec: 53106.12
Iteration:   2520, Loss function: 2.914, Average Loss: 4.297, avg. samples / sec: 53138.68
Iteration:   2520, Loss function: 3.449, Average Loss: 4.336, avg. samples / sec: 53077.28
Iteration:   2520, Loss function: 3.717, Average Loss: 4.297, avg. samples / sec: 53087.94
Iteration:   2540, Loss function: 3.706, Average Loss: 4.296, avg. samples / sec: 53667.08
Iteration:   2540, Loss function: 3.291, Average Loss: 4.316, avg. samples / sec: 53741.10
Iteration:   2540, Loss function: 3.421, Average Loss: 4.321, avg. samples / sec: 53593.91
Iteration:   2540, Loss function: 3.675, Average Loss: 4.317, avg. samples / sec: 53944.57
Iteration:   2540, Loss function: 3.600, Average Loss: 4.322, avg. samples / sec: 53657.64
Iteration:   2540, Loss function: 4.075, Average Loss: 4.316, avg. samples / sec: 53700.98
Iteration:   2540, Loss function: 5.060, Average Loss: 4.334, avg. samples / sec: 53685.41
Iteration:   2540, Loss function: 3.296, Average Loss: 4.307, avg. samples / sec: 53751.80
Iteration:   2540, Loss function: 4.387, Average Loss: 4.308, avg. samples / sec: 53680.28
Iteration:   2540, Loss function: 3.362, Average Loss: 4.323, avg. samples / sec: 53676.62
Iteration:   2540, Loss function: 4.888, Average Loss: 4.321, avg. samples / sec: 53561.56
Iteration:   2540, Loss function: 3.444, Average Loss: 4.306, avg. samples / sec: 53721.08
Iteration:   2540, Loss function: 3.007, Average Loss: 4.311, avg. samples / sec: 53627.50
Iteration:   2540, Loss function: 3.176, Average Loss: 4.297, avg. samples / sec: 53678.73
Iteration:   2540, Loss function: 4.341, Average Loss: 4.304, avg. samples / sec: 53692.25
Iteration:   2540, Loss function: 4.447, Average Loss: 4.319, avg. samples / sec: 53663.05
Iteration:   2540, Loss function: 4.677, Average Loss: 4.309, avg. samples / sec: 53642.09
Iteration:   2540, Loss function: 3.693, Average Loss: 4.307, avg. samples / sec: 53644.48
Iteration:   2540, Loss function: 4.504, Average Loss: 4.336, avg. samples / sec: 53587.16
Iteration:   2540, Loss function: 3.757, Average Loss: 4.315, avg. samples / sec: 53585.49
Iteration:   2540, Loss function: 4.133, Average Loss: 4.333, avg. samples / sec: 53713.39
Iteration:   2540, Loss function: 3.337, Average Loss: 4.321, avg. samples / sec: 53629.93
Iteration:   2540, Loss function: 4.133, Average Loss: 4.332, avg. samples / sec: 53634.27
Iteration:   2540, Loss function: 3.155, Average Loss: 4.316, avg. samples / sec: 53361.25
Iteration:   2540, Loss function: 3.495, Average Loss: 4.325, avg. samples / sec: 53609.65
Iteration:   2540, Loss function: 3.350, Average Loss: 4.294, avg. samples / sec: 53688.60
Iteration:   2540, Loss function: 3.633, Average Loss: 4.301, avg. samples / sec: 53386.64
Iteration:   2540, Loss function: 5.139, Average Loss: 4.338, avg. samples / sec: 53643.15
Iteration:   2540, Loss function: 3.746, Average Loss: 4.310, avg. samples / sec: 53363.64
Iteration:   2540, Loss function: 4.808, Average Loss: 4.289, avg. samples / sec: 53677.21
Iteration:   2560, Loss function: 5.746, Average Loss: 4.292, avg. samples / sec: 53537.19
Iteration:   2560, Loss function: 4.621, Average Loss: 4.310, avg. samples / sec: 53581.89
Iteration:   2560, Loss function: 4.799, Average Loss: 4.318, avg. samples / sec: 53611.04
Iteration:   2560, Loss function: 3.181, Average Loss: 4.311, avg. samples / sec: 53577.06
Iteration:   2560, Loss function: 5.434, Average Loss: 4.326, avg. samples / sec: 53573.56
Iteration:   2560, Loss function: 3.544, Average Loss: 4.309, avg. samples / sec: 53546.10
Iteration:   2560, Loss function: 4.667, Average Loss: 4.296, avg. samples / sec: 53813.72
Iteration:   2560, Loss function: 3.112, Average Loss: 4.300, avg. samples / sec: 53527.51
Iteration:   2560, Loss function: 3.831, Average Loss: 4.315, avg. samples / sec: 53522.91
Iteration:   2560, Loss function: 3.597, Average Loss: 4.311, avg. samples / sec: 53782.40
Iteration:   2560, Loss function: 3.744, Average Loss: 4.313, avg. samples / sec: 53523.79
Iteration:   2560, Loss function: 3.988, Average Loss: 4.317, avg. samples / sec: 53522.65
Iteration:   2560, Loss function: 3.715, Average Loss: 4.301, avg. samples / sec: 53791.29
Iteration:   2560, Loss function: 3.673, Average Loss: 4.310, avg. samples / sec: 53759.86
Iteration:   2560, Loss function: 5.721, Average Loss: 4.300, avg. samples / sec: 53512.39
Iteration:   2560, Loss function: 2.450, Average Loss: 4.299, avg. samples / sec: 53481.72
Iteration:   2560, Loss function: 4.400, Average Loss: 4.308, avg. samples / sec: 53512.18
Iteration:   2560, Loss function: 6.321, Average Loss: 4.293, avg. samples / sec: 53516.43
Iteration:   2560, Loss function: 3.727, Average Loss: 4.323, avg. samples / sec: 53699.98
Iteration:   2560, Loss function: 4.001, Average Loss: 4.323, avg. samples / sec: 53601.19
Iteration:   2560, Loss function: 3.325, Average Loss: 4.331, avg. samples / sec: 53542.96
Iteration:   2560, Loss function: 4.703, Average Loss: 4.301, avg. samples / sec: 53527.61
Iteration:   2560, Loss function: 4.411, Average Loss: 4.332, avg. samples / sec: 53560.65
Iteration:   2560, Loss function: 2.987, Average Loss: 4.301, avg. samples / sec: 53491.36
Iteration:   2560, Loss function: 4.418, Average Loss: 4.303, avg. samples / sec: 53517.34
Iteration:   2560, Loss function: 4.115, Average Loss: 4.313, avg. samples / sec: 53486.15
Iteration:   2560, Loss function: 4.297, Average Loss: 4.335, avg. samples / sec: 53543.68
Iteration:   2560, Loss function: 3.839, Average Loss: 4.290, avg. samples / sec: 53517.97
Iteration:   2560, Loss function: 3.787, Average Loss: 4.314, avg. samples / sec: 53469.08
Iteration:   2560, Loss function: 3.182, Average Loss: 4.286, avg. samples / sec: 53529.22
Iteration:   2580, Loss function: 5.022, Average Loss: 4.284, avg. samples / sec: 53684.74
Iteration:   2580, Loss function: 3.716, Average Loss: 4.316, avg. samples / sec: 53690.32
Iteration:   2580, Loss function: 4.520, Average Loss: 4.304, avg. samples / sec: 53563.52
Iteration:   2580, Loss function: 4.114, Average Loss: 4.304, avg. samples / sec: 53659.56
Iteration:   2580, Loss function: 4.520, Average Loss: 4.301, avg. samples / sec: 53674.70
Iteration:   2580, Loss function: 2.898, Average Loss: 4.286, avg. samples / sec: 53660.72
Iteration:   2580, Loss function: 3.674, Average Loss: 4.302, avg. samples / sec: 53601.43
Iteration:   2580, Loss function: 3.598, Average Loss: 4.315, avg. samples / sec: 53667.57
Iteration:   2580, Loss function: 3.755, Average Loss: 4.297, avg. samples / sec: 53697.07
Iteration:   2580, Loss function: 3.195, Average Loss: 4.320, avg. samples / sec: 53602.76
Iteration:   2580, Loss function: 4.025, Average Loss: 4.309, avg. samples / sec: 53663.25
Iteration:   2580, Loss function: 3.926, Average Loss: 4.333, avg. samples / sec: 53912.72
Iteration:   2580, Loss function: 3.494, Average Loss: 4.308, avg. samples / sec: 53635.25
Iteration:   2580, Loss function: 3.349, Average Loss: 4.307, avg. samples / sec: 53647.67
Iteration:   2580, Loss function: 4.280, Average Loss: 4.294, avg. samples / sec: 53663.11
Iteration:   2580, Loss function: 3.216, Average Loss: 4.293, avg. samples / sec: 53672.82
Iteration:   2580, Loss function: 4.625, Average Loss: 4.306, avg. samples / sec: 53634.80
Iteration:   2580, Loss function: 4.027, Average Loss: 4.302, avg. samples / sec: 53645.89
Iteration:   2580, Loss function: 3.431, Average Loss: 4.288, avg. samples / sec: 53645.89
Iteration:   2580, Loss function: 3.683, Average Loss: 4.301, avg. samples / sec: 53833.62
Iteration:   2580, Loss function: 3.935, Average Loss: 4.321, avg. samples / sec: 53670.22
Iteration:   2580, Loss function: 4.473, Average Loss: 4.332, avg. samples / sec: 53687.17
Iteration:   2580, Loss function: 2.924, Average Loss: 4.320, avg. samples / sec: 53650.45
Iteration:   2580, Loss function: 3.881, Average Loss: 4.311, avg. samples / sec: 53734.83
Iteration:   2580, Loss function: 3.653, Average Loss: 4.293, avg. samples / sec: 53670.86
Iteration:   2580, Loss function: 2.890, Average Loss: 4.294, avg. samples / sec: 53680.67
Iteration:   2580, Loss function: 5.280, Average Loss: 4.310, avg. samples / sec: 53656.27
Iteration:   2580, Loss function: 4.423, Average Loss: 4.315, avg. samples / sec: 53494.41
Iteration:   2580, Loss function: 5.147, Average Loss: 4.282, avg. samples / sec: 53689.81
Iteration:   2580, Loss function: 4.924, Average Loss: 4.283, avg. samples / sec: 53681.86
:::MLL 1558640107.021 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558640107.022 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 3.840, Average Loss: 4.274, avg. samples / sec: 53179.26
Iteration:   2600, Loss function: 3.966, Average Loss: 4.315, avg. samples / sec: 53190.22
Iteration:   2600, Loss function: 3.574, Average Loss: 4.302, avg. samples / sec: 53199.88
Iteration:   2600, Loss function: 2.776, Average Loss: 4.296, avg. samples / sec: 53229.94
Iteration:   2600, Loss function: 2.556, Average Loss: 4.292, avg. samples / sec: 53118.51
Iteration:   2600, Loss function: 3.826, Average Loss: 4.292, avg. samples / sec: 53191.25
Iteration:   2600, Loss function: 4.173, Average Loss: 4.296, avg. samples / sec: 53228.39
Iteration:   2600, Loss function: 2.768, Average Loss: 4.329, avg. samples / sec: 53216.84
Iteration:   2600, Loss function: 4.114, Average Loss: 4.286, avg. samples / sec: 53231.47
Iteration:   2600, Loss function: 3.849, Average Loss: 4.289, avg. samples / sec: 53198.56
Iteration:   2600, Loss function: 5.137, Average Loss: 4.305, avg. samples / sec: 53197.27
Iteration:   2600, Loss function: 2.954, Average Loss: 4.286, avg. samples / sec: 53206.51
Iteration:   2600, Loss function: 4.227, Average Loss: 4.284, avg. samples / sec: 53162.59
Iteration:   2600, Loss function: 4.448, Average Loss: 4.310, avg. samples / sec: 53189.22
Iteration:   2600, Loss function: 4.762, Average Loss: 4.313, avg. samples / sec: 53181.21
Iteration:   2600, Loss function: 3.096, Average Loss: 4.299, avg. samples / sec: 53225.22
Iteration:   2600, Loss function: 3.655, Average Loss: 4.299, avg. samples / sec: 53188.14
Iteration:   2600, Loss function: 3.769, Average Loss: 4.294, avg. samples / sec: 53198.70
Iteration:   2600, Loss function: 3.699, Average Loss: 4.281, avg. samples / sec: 53199.80
Iteration:   2600, Loss function: 4.151, Average Loss: 4.276, avg. samples / sec: 53304.56
Iteration:   2600, Loss function: 4.940, Average Loss: 4.298, avg. samples / sec: 53065.17
Iteration:   2600, Loss function: 3.539, Average Loss: 4.297, avg. samples / sec: 53205.61
Iteration:   2600, Loss function: 3.317, Average Loss: 4.308, avg. samples / sec: 53233.94
Iteration:   2600, Loss function: 4.038, Average Loss: 4.314, avg. samples / sec: 53190.69
Iteration:   2600, Loss function: 4.541, Average Loss: 4.317, avg. samples / sec: 53183.50
Iteration:   2600, Loss function: 3.426, Average Loss: 4.289, avg. samples / sec: 53194.84
Iteration:   2600, Loss function: 4.031, Average Loss: 4.300, avg. samples / sec: 53222.95
Iteration:   2600, Loss function: 4.920, Average Loss: 4.332, avg. samples / sec: 53176.01
Iteration:   2600, Loss function: 4.133, Average Loss: 4.310, avg. samples / sec: 53176.36
Iteration:   2600, Loss function: 4.117, Average Loss: 4.276, avg. samples / sec: 53170.80
Iteration:   2620, Loss function: 4.266, Average Loss: 4.276, avg. samples / sec: 52748.65
Iteration:   2620, Loss function: 3.886, Average Loss: 4.301, avg. samples / sec: 52742.86
Iteration:   2620, Loss function: 2.597, Average Loss: 4.280, avg. samples / sec: 52806.52
Iteration:   2620, Loss function: 4.024, Average Loss: 4.294, avg. samples / sec: 52747.56
Iteration:   2620, Loss function: 4.064, Average Loss: 4.315, avg. samples / sec: 52802.62
Iteration:   2620, Loss function: 5.669, Average Loss: 4.309, avg. samples / sec: 52774.50
Iteration:   2620, Loss function: 3.093, Average Loss: 4.300, avg. samples / sec: 52769.29
Iteration:   2620, Loss function: 4.216, Average Loss: 4.291, avg. samples / sec: 52799.56
Iteration:   2620, Loss function: 3.986, Average Loss: 4.283, avg. samples / sec: 52754.41
Iteration:   2620, Loss function: 3.179, Average Loss: 4.285, avg. samples / sec: 52730.71
Iteration:   2620, Loss function: 2.602, Average Loss: 4.292, avg. samples / sec: 52701.35
Iteration:   2620, Loss function: 3.784, Average Loss: 4.278, avg. samples / sec: 52699.10
Iteration:   2620, Loss function: 3.813, Average Loss: 4.289, avg. samples / sec: 52670.11
Iteration:   2620, Loss function: 4.979, Average Loss: 4.277, avg. samples / sec: 52753.33
Iteration:   2620, Loss function: 4.361, Average Loss: 4.315, avg. samples / sec: 52454.52
Iteration:   2620, Loss function: 4.606, Average Loss: 4.300, avg. samples / sec: 52788.42
Iteration:   2620, Loss function: 4.420, Average Loss: 4.282, avg. samples / sec: 52766.54
Iteration:   2620, Loss function: 4.450, Average Loss: 4.295, avg. samples / sec: 52734.55
Iteration:   2620, Loss function: 4.201, Average Loss: 4.296, avg. samples / sec: 52736.43
Iteration:   2620, Loss function: 3.656, Average Loss: 4.331, avg. samples / sec: 52736.43
Iteration:   2620, Loss function: 3.768, Average Loss: 4.311, avg. samples / sec: 52715.10
Iteration:   2620, Loss function: 3.999, Average Loss: 4.313, avg. samples / sec: 52720.35
Iteration:   2620, Loss function: 3.831, Average Loss: 4.292, avg. samples / sec: 52529.76
Iteration:   2620, Loss function: 4.484, Average Loss: 4.307, avg. samples / sec: 52726.29
Iteration:   2620, Loss function: 3.404, Average Loss: 4.301, avg. samples / sec: 52700.91
Iteration:   2620, Loss function: 3.427, Average Loss: 4.328, avg. samples / sec: 52493.03
Iteration:   2620, Loss function: 3.797, Average Loss: 4.297, avg. samples / sec: 52521.40
Iteration:   2620, Loss function: 4.340, Average Loss: 4.273, avg. samples / sec: 52761.37
Iteration:   2620, Loss function: 3.836, Average Loss: 4.272, avg. samples / sec: 52654.30
Iteration:   2620, Loss function: 3.758, Average Loss: 4.284, avg. samples / sec: 52469.85
Iteration:   2640, Loss function: 3.311, Average Loss: 4.271, avg. samples / sec: 53786.69
Iteration:   2640, Loss function: 4.357, Average Loss: 4.312, avg. samples / sec: 54030.83
Iteration:   2640, Loss function: 3.729, Average Loss: 4.326, avg. samples / sec: 54118.35
Iteration:   2640, Loss function: 4.616, Average Loss: 4.282, avg. samples / sec: 53898.91
Iteration:   2640, Loss function: 4.004, Average Loss: 4.288, avg. samples / sec: 53781.05
Iteration:   2640, Loss function: 4.898, Average Loss: 4.275, avg. samples / sec: 53805.32
Iteration:   2640, Loss function: 3.082, Average Loss: 4.289, avg. samples / sec: 53840.04
Iteration:   2640, Loss function: 4.571, Average Loss: 4.273, avg. samples / sec: 53850.14
Iteration:   2640, Loss function: 3.302, Average Loss: 4.309, avg. samples / sec: 53760.80
Iteration:   2640, Loss function: 3.840, Average Loss: 4.298, avg. samples / sec: 53741.61
Iteration:   2640, Loss function: 4.162, Average Loss: 4.292, avg. samples / sec: 54038.02
Iteration:   2640, Loss function: 5.003, Average Loss: 4.292, avg. samples / sec: 53761.11
Iteration:   2640, Loss function: 3.726, Average Loss: 4.277, avg. samples / sec: 54069.20
Iteration:   2640, Loss function: 4.783, Average Loss: 4.276, avg. samples / sec: 53825.27
Iteration:   2640, Loss function: 4.634, Average Loss: 4.279, avg. samples / sec: 53766.75
Iteration:   2640, Loss function: 3.553, Average Loss: 4.273, avg. samples / sec: 53718.83
Iteration:   2640, Loss function: 3.105, Average Loss: 4.301, avg. samples / sec: 53722.03
Iteration:   2640, Loss function: 3.917, Average Loss: 4.289, avg. samples / sec: 53736.36
Iteration:   2640, Loss function: 4.551, Average Loss: 4.293, avg. samples / sec: 53908.58
Iteration:   2640, Loss function: 3.304, Average Loss: 4.305, avg. samples / sec: 53853.51
Iteration:   2640, Loss function: 4.864, Average Loss: 4.298, avg. samples / sec: 53805.73
Iteration:   2640, Loss function: 4.164, Average Loss: 4.316, avg. samples / sec: 53832.22
Iteration:   2640, Loss function: 4.209, Average Loss: 4.274, avg. samples / sec: 53776.68
Iteration:   2640, Loss function: 4.896, Average Loss: 4.300, avg. samples / sec: 53744.48
Iteration:   2640, Loss function: 3.281, Average Loss: 4.302, avg. samples / sec: 53806.68
Iteration:   2640, Loss function: 4.785, Average Loss: 4.326, avg. samples / sec: 53775.24
Iteration:   2640, Loss function: 3.192, Average Loss: 4.298, avg. samples / sec: 53784.74
Iteration:   2640, Loss function: 4.088, Average Loss: 4.272, avg. samples / sec: 53790.41
Iteration:   2640, Loss function: 4.885, Average Loss: 4.274, avg. samples / sec: 53783.22
Iteration:   2640, Loss function: 3.917, Average Loss: 4.283, avg. samples / sec: 53731.86
:::MLL 1558640109.229 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558640109.229 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 5.268, Average Loss: 4.308, avg. samples / sec: 53281.36
Iteration:   2660, Loss function: 5.055, Average Loss: 4.265, avg. samples / sec: 53182.32
Iteration:   2660, Loss function: 4.158, Average Loss: 4.292, avg. samples / sec: 53376.43
Iteration:   2660, Loss function: 3.774, Average Loss: 4.275, avg. samples / sec: 53344.51
Iteration:   2660, Loss function: 4.048, Average Loss: 4.283, avg. samples / sec: 53311.59
Iteration:   2660, Loss function: 4.642, Average Loss: 4.281, avg. samples / sec: 53212.56
Iteration:   2660, Loss function: 3.746, Average Loss: 4.291, avg. samples / sec: 53268.87
Iteration:   2660, Loss function: 4.412, Average Loss: 4.287, avg. samples / sec: 53244.02
Iteration:   2660, Loss function: 3.556, Average Loss: 4.285, avg. samples / sec: 53260.64
Iteration:   2660, Loss function: 4.146, Average Loss: 4.268, avg. samples / sec: 53223.83
Iteration:   2660, Loss function: 4.164, Average Loss: 4.279, avg. samples / sec: 53197.41
Iteration:   2660, Loss function: 2.899, Average Loss: 4.272, avg. samples / sec: 53268.25
Iteration:   2660, Loss function: 4.106, Average Loss: 4.304, avg. samples / sec: 53217.40
Iteration:   2660, Loss function: 4.540, Average Loss: 4.263, avg. samples / sec: 53203.16
Iteration:   2660, Loss function: 4.250, Average Loss: 4.275, avg. samples / sec: 53223.23
Iteration:   2660, Loss function: 4.163, Average Loss: 4.282, avg. samples / sec: 53240.26
Iteration:   2660, Loss function: 4.620, Average Loss: 4.270, avg. samples / sec: 53187.63
Iteration:   2660, Loss function: 3.124, Average Loss: 4.295, avg. samples / sec: 53303.97
Iteration:   2660, Loss function: 4.111, Average Loss: 4.307, avg. samples / sec: 53224.17
Iteration:   2660, Loss function: 2.654, Average Loss: 4.265, avg. samples / sec: 53247.54
Iteration:   2660, Loss function: 4.511, Average Loss: 4.297, avg. samples / sec: 53234.75
Iteration:   2660, Loss function: 3.844, Average Loss: 4.320, avg. samples / sec: 53271.53
Iteration:   2660, Loss function: 4.350, Average Loss: 4.290, avg. samples / sec: 53117.31
Iteration:   2660, Loss function: 3.037, Average Loss: 4.311, avg. samples / sec: 53215.39
Iteration:   2660, Loss function: 4.552, Average Loss: 4.290, avg. samples / sec: 53251.73
Iteration:   2660, Loss function: 4.103, Average Loss: 4.268, avg. samples / sec: 53253.29
Iteration:   2660, Loss function: 3.335, Average Loss: 4.294, avg. samples / sec: 53201.47
Iteration:   2660, Loss function: 4.418, Average Loss: 4.275, avg. samples / sec: 53272.22
Iteration:   2660, Loss function: 4.808, Average Loss: 4.321, avg. samples / sec: 52854.88
Iteration:   2660, Loss function: 4.999, Average Loss: 4.271, avg. samples / sec: 53119.45
Iteration:   2680, Loss function: 3.994, Average Loss: 4.263, avg. samples / sec: 53585.66
Iteration:   2680, Loss function: 3.032, Average Loss: 4.303, avg. samples / sec: 53553.97
Iteration:   2680, Loss function: 4.377, Average Loss: 4.282, avg. samples / sec: 53594.87
Iteration:   2680, Loss function: 3.687, Average Loss: 4.279, avg. samples / sec: 53515.15
Iteration:   2680, Loss function: 4.591, Average Loss: 4.276, avg. samples / sec: 53581.74
Iteration:   2680, Loss function: 3.782, Average Loss: 4.286, avg. samples / sec: 53505.68
Iteration:   2680, Loss function: 4.973, Average Loss: 4.297, avg. samples / sec: 53531.49
Iteration:   2680, Loss function: 4.643, Average Loss: 4.280, avg. samples / sec: 53505.05
Iteration:   2680, Loss function: 4.285, Average Loss: 4.263, avg. samples / sec: 53541.01
Iteration:   2680, Loss function: 4.184, Average Loss: 4.287, avg. samples / sec: 53415.66
Iteration:   2680, Loss function: 5.033, Average Loss: 4.264, avg. samples / sec: 53508.93
Iteration:   2680, Loss function: 4.235, Average Loss: 4.272, avg. samples / sec: 53566.06
Iteration:   2680, Loss function: 4.099, Average Loss: 4.278, avg. samples / sec: 53531.82
Iteration:   2680, Loss function: 5.278, Average Loss: 4.272, avg. samples / sec: 53503.95
Iteration:   2680, Loss function: 3.218, Average Loss: 4.303, avg. samples / sec: 53563.84
Iteration:   2680, Loss function: 4.216, Average Loss: 4.263, avg. samples / sec: 53518.34
Iteration:   2680, Loss function: 4.100, Average Loss: 4.287, avg. samples / sec: 53533.69
Iteration:   2680, Loss function: 5.383, Average Loss: 4.286, avg. samples / sec: 53293.37
Iteration:   2680, Loss function: 5.058, Average Loss: 4.314, avg. samples / sec: 53520.07
Iteration:   2680, Loss function: 3.380, Average Loss: 4.290, avg. samples / sec: 53510.09
Iteration:   2680, Loss function: 5.118, Average Loss: 4.305, avg. samples / sec: 53498.04
Iteration:   2680, Loss function: 4.387, Average Loss: 4.268, avg. samples / sec: 53292.46
Iteration:   2680, Loss function: 5.391, Average Loss: 4.294, avg. samples / sec: 53551.24
Iteration:   2680, Loss function: 4.545, Average Loss: 4.289, avg. samples / sec: 53532.65
Iteration:   2680, Loss function: 2.990, Average Loss: 4.265, avg. samples / sec: 53537.61
Iteration:   2680, Loss function: 3.360, Average Loss: 4.294, avg. samples / sec: 53456.95
Iteration:   2680, Loss function: 4.515, Average Loss: 4.271, avg. samples / sec: 53524.09
Iteration:   2680, Loss function: 2.738, Average Loss: 4.311, avg. samples / sec: 53573.45
Iteration:   2680, Loss function: 2.982, Average Loss: 4.271, avg. samples / sec: 53159.35
Iteration:   2680, Loss function: 3.091, Average Loss: 4.264, avg. samples / sec: 53649.71
Iteration:   2700, Loss function: 4.121, Average Loss: 4.260, avg. samples / sec: 53557.21
Iteration:   2700, Loss function: 3.244, Average Loss: 4.296, avg. samples / sec: 53514.44
Iteration:   2700, Loss function: 4.783, Average Loss: 4.279, avg. samples / sec: 53612.22
Iteration:   2700, Loss function: 4.282, Average Loss: 4.281, avg. samples / sec: 53537.80
Iteration:   2700, Loss function: 3.658, Average Loss: 4.293, avg. samples / sec: 53590.67
Iteration:   2700, Loss function: 4.574, Average Loss: 4.267, avg. samples / sec: 53816.85
Iteration:   2700, Loss function: 5.275, Average Loss: 4.260, avg. samples / sec: 53592.30
Iteration:   2700, Loss function: 3.796, Average Loss: 4.273, avg. samples / sec: 53515.98
Iteration:   2700, Loss function: 4.296, Average Loss: 4.285, avg. samples / sec: 53545.40
Iteration:   2700, Loss function: 4.305, Average Loss: 4.273, avg. samples / sec: 53564.72
Iteration:   2700, Loss function: 4.507, Average Loss: 4.283, avg. samples / sec: 53751.31
Iteration:   2700, Loss function: 4.349, Average Loss: 4.268, avg. samples / sec: 53822.52
Iteration:   2700, Loss function: 3.217, Average Loss: 4.270, avg. samples / sec: 53572.74
Iteration:   2700, Loss function: 4.439, Average Loss: 4.265, avg. samples / sec: 53539.89
Iteration:   2700, Loss function: 3.175, Average Loss: 4.283, avg. samples / sec: 53543.98
Iteration:   2700, Loss function: 3.764, Average Loss: 4.263, avg. samples / sec: 53546.46
Iteration:   2700, Loss function: 3.014, Average Loss: 4.267, avg. samples / sec: 53554.38
Iteration:   2700, Loss function: 3.827, Average Loss: 4.297, avg. samples / sec: 53550.59
Iteration:   2700, Loss function: 3.317, Average Loss: 4.283, avg. samples / sec: 53600.39
Iteration:   2700, Loss function: 3.332, Average Loss: 4.303, avg. samples / sec: 53570.32
Iteration:   2700, Loss function: 4.849, Average Loss: 4.293, avg. samples / sec: 53580.91
Iteration:   2700, Loss function: 4.008, Average Loss: 4.297, avg. samples / sec: 53553.87
Iteration:   2700, Loss function: 3.816, Average Loss: 4.263, avg. samples / sec: 53541.01
Iteration:   2700, Loss function: 3.301, Average Loss: 4.298, avg. samples / sec: 53558.35
Iteration:   2700, Loss function: 5.141, Average Loss: 4.287, avg. samples / sec: 53528.89
Iteration:   2700, Loss function: 3.363, Average Loss: 4.285, avg. samples / sec: 53548.05
Iteration:   2700, Loss function: 3.763, Average Loss: 4.309, avg. samples / sec: 53574.45
Iteration:   2700, Loss function: 4.477, Average Loss: 4.269, avg. samples / sec: 53557.68
Iteration:   2700, Loss function: 4.215, Average Loss: 4.262, avg. samples / sec: 53528.30
Iteration:   2700, Loss function: 4.180, Average Loss: 4.258, avg. samples / sec: 53570.18
Iteration:   2720, Loss function: 3.138, Average Loss: 4.254, avg. samples / sec: 53714.59
Iteration:   2720, Loss function: 4.386, Average Loss: 4.295, avg. samples / sec: 53670.00
Iteration:   2720, Loss function: 3.996, Average Loss: 4.274, avg. samples / sec: 53679.69
Iteration:   2720, Loss function: 4.642, Average Loss: 4.279, avg. samples / sec: 53719.96
Iteration:   2720, Loss function: 4.085, Average Loss: 4.254, avg. samples / sec: 53732.31
Iteration:   2720, Loss function: 4.258, Average Loss: 4.260, avg. samples / sec: 53708.43
Iteration:   2720, Loss function: 4.250, Average Loss: 4.280, avg. samples / sec: 53750.24
Iteration:   2720, Loss function: 3.727, Average Loss: 4.267, avg. samples / sec: 53706.08
Iteration:   2720, Loss function: 4.330, Average Loss: 4.280, avg. samples / sec: 53728.74
Iteration:   2720, Loss function: 3.367, Average Loss: 4.267, avg. samples / sec: 53695.58
Iteration:   2720, Loss function: 2.697, Average Loss: 4.258, avg. samples / sec: 53717.23
Iteration:   2720, Loss function: 3.101, Average Loss: 4.260, avg. samples / sec: 53745.14
Iteration:   2720, Loss function: 4.563, Average Loss: 4.256, avg. samples / sec: 53715.27
Iteration:   2720, Loss function: 4.178, Average Loss: 4.254, avg. samples / sec: 53721.78
Iteration:   2720, Loss function: 2.344, Average Loss: 4.276, avg. samples / sec: 53685.27
Iteration:   2720, Loss function: 4.165, Average Loss: 4.260, avg. samples / sec: 53659.17
Iteration:   2720, Loss function: 3.257, Average Loss: 4.294, avg. samples / sec: 53745.18
Iteration:   2720, Loss function: 3.662, Average Loss: 4.287, avg. samples / sec: 53734.79
Iteration:   2720, Loss function: 3.980, Average Loss: 4.299, avg. samples / sec: 53693.02
Iteration:   2720, Loss function: 4.218, Average Loss: 4.280, avg. samples / sec: 53741.22
Iteration:   2720, Loss function: 4.694, Average Loss: 4.258, avg. samples / sec: 53716.33
Iteration:   2720, Loss function: 3.915, Average Loss: 4.278, avg. samples / sec: 53701.58
Iteration:   2720, Loss function: 4.186, Average Loss: 4.299, avg. samples / sec: 53697.85
Iteration:   2720, Loss function: 2.556, Average Loss: 4.288, avg. samples / sec: 53701.98
Iteration:   2720, Loss function: 3.545, Average Loss: 4.285, avg. samples / sec: 53426.78
Iteration:   2720, Loss function: 5.058, Average Loss: 4.267, avg. samples / sec: 53721.17
Iteration:   2720, Loss function: 3.563, Average Loss: 4.303, avg. samples / sec: 53713.08
Iteration:   2720, Loss function: 4.878, Average Loss: 4.258, avg. samples / sec: 53718.34
Iteration:   2720, Loss function: 3.350, Average Loss: 4.254, avg. samples / sec: 53708.66
Iteration:   2720, Loss function: 3.877, Average Loss: 4.280, avg. samples / sec: 53633.34
:::MLL 1558640111.426 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558640111.427 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 3.417, Average Loss: 4.244, avg. samples / sec: 53069.64
Iteration:   2740, Loss function: 4.745, Average Loss: 4.295, avg. samples / sec: 53157.10
Iteration:   2740, Loss function: 3.945, Average Loss: 4.265, avg. samples / sec: 53118.23
Iteration:   2740, Loss function: 4.076, Average Loss: 4.273, avg. samples / sec: 53087.84
Iteration:   2740, Loss function: 3.260, Average Loss: 4.273, avg. samples / sec: 53081.20
Iteration:   2740, Loss function: 4.057, Average Loss: 4.258, avg. samples / sec: 53066.47
Iteration:   2740, Loss function: 3.809, Average Loss: 4.268, avg. samples / sec: 53102.28
Iteration:   2740, Loss function: 3.608, Average Loss: 4.251, avg. samples / sec: 53079.62
Iteration:   2740, Loss function: 4.246, Average Loss: 4.252, avg. samples / sec: 53033.40
Iteration:   2740, Loss function: 3.889, Average Loss: 4.250, avg. samples / sec: 53080.88
Iteration:   2740, Loss function: 5.523, Average Loss: 4.259, avg. samples / sec: 53074.38
Iteration:   2740, Loss function: 4.497, Average Loss: 4.253, avg. samples / sec: 53073.46
Iteration:   2740, Loss function: 4.696, Average Loss: 4.248, avg. samples / sec: 53080.94
Iteration:   2740, Loss function: 5.415, Average Loss: 4.277, avg. samples / sec: 53056.48
Iteration:   2740, Loss function: 3.100, Average Loss: 4.263, avg. samples / sec: 53099.44
Iteration:   2740, Loss function: 4.612, Average Loss: 4.258, avg. samples / sec: 53013.23
Iteration:   2740, Loss function: 3.523, Average Loss: 4.284, avg. samples / sec: 53068.42
Iteration:   2740, Loss function: 5.222, Average Loss: 4.280, avg. samples / sec: 53071.84
Iteration:   2740, Loss function: 2.421, Average Loss: 4.277, avg. samples / sec: 53083.70
Iteration:   2740, Loss function: 3.588, Average Loss: 4.290, avg. samples / sec: 53086.34
Iteration:   2740, Loss function: 3.879, Average Loss: 4.273, avg. samples / sec: 53080.36
Iteration:   2740, Loss function: 3.323, Average Loss: 4.258, avg. samples / sec: 53076.50
Iteration:   2740, Loss function: 4.255, Average Loss: 4.284, avg. samples / sec: 53095.16
Iteration:   2740, Loss function: 2.787, Average Loss: 4.275, avg. samples / sec: 53180.15
Iteration:   2740, Loss function: 3.943, Average Loss: 4.264, avg. samples / sec: 53093.44
Iteration:   2740, Loss function: 4.345, Average Loss: 4.295, avg. samples / sec: 53088.50
Iteration:   2740, Loss function: 5.127, Average Loss: 4.281, avg. samples / sec: 53062.51
Iteration:   2740, Loss function: 3.597, Average Loss: 4.249, avg. samples / sec: 53084.20
Iteration:   2740, Loss function: 4.089, Average Loss: 4.291, avg. samples / sec: 53018.15
Iteration:   2740, Loss function: 3.275, Average Loss: 4.249, avg. samples / sec: 53046.93
Iteration:   2760, Loss function: 3.369, Average Loss: 4.239, avg. samples / sec: 53503.79
Iteration:   2760, Loss function: 4.520, Average Loss: 4.256, avg. samples / sec: 53649.36
Iteration:   2760, Loss function: 3.122, Average Loss: 4.264, avg. samples / sec: 53635.52
Iteration:   2760, Loss function: 4.308, Average Loss: 4.258, avg. samples / sec: 53607.75
Iteration:   2760, Loss function: 2.979, Average Loss: 4.251, avg. samples / sec: 53681.96
Iteration:   2760, Loss function: 4.734, Average Loss: 4.242, avg. samples / sec: 53624.48
Iteration:   2760, Loss function: 4.508, Average Loss: 4.249, avg. samples / sec: 53612.89
Iteration:   2760, Loss function: 3.381, Average Loss: 4.262, avg. samples / sec: 53561.44
Iteration:   2760, Loss function: 3.920, Average Loss: 4.273, avg. samples / sec: 53595.76
Iteration:   2760, Loss function: 3.746, Average Loss: 4.292, avg. samples / sec: 53337.26
Iteration:   2760, Loss function: 5.157, Average Loss: 4.251, avg. samples / sec: 53568.61
Iteration:   2760, Loss function: 3.775, Average Loss: 4.258, avg. samples / sec: 53371.56
Iteration:   2760, Loss function: 4.091, Average Loss: 4.258, avg. samples / sec: 53581.89
Iteration:   2760, Loss function: 3.870, Average Loss: 4.244, avg. samples / sec: 53525.58
Iteration:   2760, Loss function: 3.720, Average Loss: 4.270, avg. samples / sec: 53345.44
Iteration:   2760, Loss function: 4.782, Average Loss: 4.279, avg. samples / sec: 53599.96
Iteration:   2760, Loss function: 3.882, Average Loss: 4.265, avg. samples / sec: 53618.77
Iteration:   2760, Loss function: 4.061, Average Loss: 4.272, avg. samples / sec: 53578.57
Iteration:   2760, Loss function: 2.516, Average Loss: 4.282, avg. samples / sec: 53596.52
Iteration:   2760, Loss function: 3.375, Average Loss: 4.283, avg. samples / sec: 53576.12
Iteration:   2760, Loss function: 4.021, Average Loss: 4.268, avg. samples / sec: 53573.21
Iteration:   2760, Loss function: 3.731, Average Loss: 4.252, avg. samples / sec: 53583.60
Iteration:   2760, Loss function: 3.780, Average Loss: 4.277, avg. samples / sec: 53612.87
Iteration:   2760, Loss function: 3.568, Average Loss: 4.281, avg. samples / sec: 53635.17
Iteration:   2760, Loss function: 4.598, Average Loss: 4.297, avg. samples / sec: 53585.68
Iteration:   2760, Loss function: 3.749, Average Loss: 4.242, avg. samples / sec: 53576.59
Iteration:   2760, Loss function: 4.185, Average Loss: 4.242, avg. samples / sec: 53324.50
Iteration:   2760, Loss function: 3.882, Average Loss: 4.265, avg. samples / sec: 53529.48
Iteration:   2760, Loss function: 6.104, Average Loss: 4.248, avg. samples / sec: 53597.84
Iteration:   2760, Loss function: 3.392, Average Loss: 4.264, avg. samples / sec: 53427.97
Iteration:   2780, Loss function: 4.119, Average Loss: 4.235, avg. samples / sec: 52904.71
Iteration:   2780, Loss function: 2.888, Average Loss: 4.285, avg. samples / sec: 53069.78
Iteration:   2780, Loss function: 3.825, Average Loss: 4.254, avg. samples / sec: 53062.75
Iteration:   2780, Loss function: 3.453, Average Loss: 4.263, avg. samples / sec: 53099.64
Iteration:   2780, Loss function: 4.839, Average Loss: 4.255, avg. samples / sec: 52866.20
Iteration:   2780, Loss function: 4.080, Average Loss: 4.263, avg. samples / sec: 52890.09
Iteration:   2780, Loss function: 4.621, Average Loss: 4.242, avg. samples / sec: 52956.87
Iteration:   2780, Loss function: 4.308, Average Loss: 4.251, avg. samples / sec: 52831.26
Iteration:   2780, Loss function: 5.065, Average Loss: 4.245, avg. samples / sec: 52862.99
Iteration:   2780, Loss function: 3.228, Average Loss: 4.266, avg. samples / sec: 52894.18
Iteration:   2780, Loss function: 3.729, Average Loss: 4.238, avg. samples / sec: 53147.22
Iteration:   2780, Loss function: 4.610, Average Loss: 4.265, avg. samples / sec: 52829.11
Iteration:   2780, Loss function: 3.583, Average Loss: 4.244, avg. samples / sec: 52836.22
Iteration:   2780, Loss function: 4.990, Average Loss: 4.256, avg. samples / sec: 52889.97
Iteration:   2780, Loss function: 3.963, Average Loss: 4.236, avg. samples / sec: 52822.99
Iteration:   2780, Loss function: 3.948, Average Loss: 4.275, avg. samples / sec: 52993.85
Iteration:   2780, Loss function: 3.305, Average Loss: 4.243, avg. samples / sec: 52773.00
Iteration:   2780, Loss function: 3.752, Average Loss: 4.276, avg. samples / sec: 52883.90
Iteration:   2780, Loss function: 3.307, Average Loss: 4.266, avg. samples / sec: 52897.64
Iteration:   2780, Loss function: 3.494, Average Loss: 4.262, avg. samples / sec: 52900.75
Iteration:   2780, Loss function: 4.499, Average Loss: 4.248, avg. samples / sec: 52896.92
Iteration:   2780, Loss function: 4.273, Average Loss: 4.285, avg. samples / sec: 52889.93
Iteration:   2780, Loss function: 3.434, Average Loss: 4.276, avg. samples / sec: 52884.28
Iteration:   2780, Loss function: 5.118, Average Loss: 4.260, avg. samples / sec: 53013.57
Iteration:   2780, Loss function: 3.811, Average Loss: 4.273, avg. samples / sec: 52874.87
Iteration:   2780, Loss function: 4.509, Average Loss: 4.252, avg. samples / sec: 52931.15
Iteration:   2780, Loss function: 4.414, Average Loss: 4.242, avg. samples / sec: 52914.94
Iteration:   2780, Loss function: 4.672, Average Loss: 4.264, avg. samples / sec: 52909.47
Iteration:   2780, Loss function: 3.490, Average Loss: 4.294, avg. samples / sec: 52887.75
Iteration:   2780, Loss function: 4.418, Average Loss: 4.264, avg. samples / sec: 52823.28
:::MLL 1558640113.637 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558640113.638 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 5.964, Average Loss: 4.282, avg. samples / sec: 53242.91
Iteration:   2800, Loss function: 3.580, Average Loss: 4.230, avg. samples / sec: 53223.65
Iteration:   2800, Loss function: 4.746, Average Loss: 4.245, avg. samples / sec: 53179.93
Iteration:   2800, Loss function: 3.079, Average Loss: 4.260, avg. samples / sec: 53302.66
Iteration:   2800, Loss function: 4.533, Average Loss: 4.251, avg. samples / sec: 53333.44
Iteration:   2800, Loss function: 4.367, Average Loss: 4.245, avg. samples / sec: 53263.86
Iteration:   2800, Loss function: 2.966, Average Loss: 4.239, avg. samples / sec: 53367.15
Iteration:   2800, Loss function: 4.550, Average Loss: 4.256, avg. samples / sec: 53179.39
Iteration:   2800, Loss function: 5.141, Average Loss: 4.249, avg. samples / sec: 53194.62
Iteration:   2800, Loss function: 4.988, Average Loss: 4.261, avg. samples / sec: 53192.75
Iteration:   2800, Loss function: 4.696, Average Loss: 4.263, avg. samples / sec: 53210.53
Iteration:   2800, Loss function: 4.303, Average Loss: 4.250, avg. samples / sec: 53178.56
Iteration:   2800, Loss function: 4.272, Average Loss: 4.232, avg. samples / sec: 53214.73
Iteration:   2800, Loss function: 3.049, Average Loss: 4.240, avg. samples / sec: 53157.28
Iteration:   2800, Loss function: 4.407, Average Loss: 4.260, avg. samples / sec: 53423.64
Iteration:   2800, Loss function: 3.450, Average Loss: 4.234, avg. samples / sec: 53155.28
Iteration:   2800, Loss function: 4.463, Average Loss: 4.257, avg. samples / sec: 53294.60
Iteration:   2800, Loss function: 3.261, Average Loss: 4.278, avg. samples / sec: 53141.44
Iteration:   2800, Loss function: 2.954, Average Loss: 4.236, avg. samples / sec: 53038.57
Iteration:   2800, Loss function: 4.997, Average Loss: 4.248, avg. samples / sec: 53212.09
Iteration:   2800, Loss function: 4.402, Average Loss: 4.274, avg. samples / sec: 53158.38
Iteration:   2800, Loss function: 2.921, Average Loss: 4.281, avg. samples / sec: 53187.37
Iteration:   2800, Loss function: 3.675, Average Loss: 4.257, avg. samples / sec: 53173.89
Iteration:   2800, Loss function: 4.857, Average Loss: 4.268, avg. samples / sec: 53198.84
Iteration:   2800, Loss function: 4.748, Average Loss: 4.290, avg. samples / sec: 53181.99
Iteration:   2800, Loss function: 3.744, Average Loss: 4.235, avg. samples / sec: 53165.12
Iteration:   2800, Loss function: 4.108, Average Loss: 4.261, avg. samples / sec: 53110.68
Iteration:   2800, Loss function: 3.472, Average Loss: 4.263, avg. samples / sec: 53162.51
Iteration:   2800, Loss function: 4.373, Average Loss: 4.265, avg. samples / sec: 53131.37
Iteration:   2800, Loss function: 3.591, Average Loss: 4.247, avg. samples / sec: 53138.48
Iteration:   2820, Loss function: 2.824, Average Loss: 4.227, avg. samples / sec: 54156.66
Iteration:   2820, Loss function: 3.636, Average Loss: 4.282, avg. samples / sec: 54122.61
Iteration:   2820, Loss function: 4.011, Average Loss: 4.241, avg. samples / sec: 54144.21
Iteration:   2820, Loss function: 1.841, Average Loss: 4.247, avg. samples / sec: 54120.97
Iteration:   2820, Loss function: 3.729, Average Loss: 4.233, avg. samples / sec: 54110.29
Iteration:   2820, Loss function: 4.174, Average Loss: 4.244, avg. samples / sec: 54143.09
Iteration:   2820, Loss function: 3.525, Average Loss: 4.256, avg. samples / sec: 54117.31
Iteration:   2820, Loss function: 4.228, Average Loss: 4.243, avg. samples / sec: 54143.13
Iteration:   2820, Loss function: 3.690, Average Loss: 4.250, avg. samples / sec: 54024.68
Iteration:   2820, Loss function: 4.425, Average Loss: 4.261, avg. samples / sec: 54002.63
Iteration:   2820, Loss function: 4.718, Average Loss: 4.249, avg. samples / sec: 54246.17
Iteration:   2820, Loss function: 3.744, Average Loss: 4.228, avg. samples / sec: 54123.02
Iteration:   2820, Loss function: 4.338, Average Loss: 4.228, avg. samples / sec: 54106.42
Iteration:   2820, Loss function: 3.029, Average Loss: 4.264, avg. samples / sec: 54165.02
Iteration:   2820, Loss function: 4.978, Average Loss: 4.273, avg. samples / sec: 54072.69
Iteration:   2820, Loss function: 4.688, Average Loss: 4.252, avg. samples / sec: 54139.28
Iteration:   2820, Loss function: 3.738, Average Loss: 4.255, avg. samples / sec: 54184.27
Iteration:   2820, Loss function: 3.874, Average Loss: 4.268, avg. samples / sec: 54122.03
Iteration:   2820, Loss function: 3.219, Average Loss: 4.276, avg. samples / sec: 54113.86
Iteration:   2820, Loss function: 3.469, Average Loss: 4.236, avg. samples / sec: 54077.17
Iteration:   2820, Loss function: 4.107, Average Loss: 4.257, avg. samples / sec: 54188.99
Iteration:   2820, Loss function: 2.882, Average Loss: 4.231, avg. samples / sec: 54059.16
Iteration:   2820, Loss function: 4.338, Average Loss: 4.226, avg. samples / sec: 54151.81
Iteration:   2820, Loss function: 4.272, Average Loss: 4.261, avg. samples / sec: 53851.46
Iteration:   2820, Loss function: 4.329, Average Loss: 4.241, avg. samples / sec: 53838.89
Iteration:   2820, Loss function: 4.839, Average Loss: 4.263, avg. samples / sec: 54155.01
Iteration:   2820, Loss function: 5.542, Average Loss: 4.255, avg. samples / sec: 53892.40
Iteration:   2820, Loss function: 4.126, Average Loss: 4.247, avg. samples / sec: 53735.22
Iteration:   2820, Loss function: 3.735, Average Loss: 4.288, avg. samples / sec: 54077.04
Iteration:   2820, Loss function: 3.222, Average Loss: 4.240, avg. samples / sec: 54104.88
Iteration:   2840, Loss function: 3.491, Average Loss: 4.217, avg. samples / sec: 54153.24
Iteration:   2840, Loss function: 4.688, Average Loss: 4.273, avg. samples / sec: 54139.62
Iteration:   2840, Loss function: 4.437, Average Loss: 4.230, avg. samples / sec: 54179.56
Iteration:   2840, Loss function: 6.100, Average Loss: 4.246, avg. samples / sec: 54248.59
Iteration:   2840, Loss function: 3.575, Average Loss: 4.248, avg. samples / sec: 54225.82
Iteration:   2840, Loss function: 5.039, Average Loss: 4.238, avg. samples / sec: 54484.92
Iteration:   2840, Loss function: 3.965, Average Loss: 4.248, avg. samples / sec: 54228.32
Iteration:   2840, Loss function: 3.910, Average Loss: 4.224, avg. samples / sec: 54259.26
Iteration:   2840, Loss function: 4.070, Average Loss: 4.240, avg. samples / sec: 54202.94
Iteration:   2840, Loss function: 3.791, Average Loss: 4.245, avg. samples / sec: 54184.79
Iteration:   2840, Loss function: 3.346, Average Loss: 4.242, avg. samples / sec: 54206.86
Iteration:   2840, Loss function: 4.167, Average Loss: 4.223, avg. samples / sec: 54164.40
Iteration:   2840, Loss function: 3.747, Average Loss: 4.256, avg. samples / sec: 54436.13
Iteration:   2840, Loss function: 3.241, Average Loss: 4.222, avg. samples / sec: 54188.39
Iteration:   2840, Loss function: 4.470, Average Loss: 4.257, avg. samples / sec: 54175.00
Iteration:   2840, Loss function: 3.527, Average Loss: 4.243, avg. samples / sec: 54436.38
Iteration:   2840, Loss function: 3.920, Average Loss: 4.271, avg. samples / sec: 54206.32
Iteration:   2840, Loss function: 3.329, Average Loss: 4.250, avg. samples / sec: 54265.18
Iteration:   2840, Loss function: 3.926, Average Loss: 4.247, avg. samples / sec: 54214.34
Iteration:   2840, Loss function: 4.316, Average Loss: 4.247, avg. samples / sec: 54201.06
Iteration:   2840, Loss function: 4.820, Average Loss: 4.227, avg. samples / sec: 54229.99
Iteration:   2840, Loss function: 4.033, Average Loss: 4.265, avg. samples / sec: 54198.83
Iteration:   2840, Loss function: 3.391, Average Loss: 4.256, avg. samples / sec: 54159.86
Iteration:   2840, Loss function: 3.788, Average Loss: 4.236, avg. samples / sec: 54207.52
Iteration:   2840, Loss function: 4.698, Average Loss: 4.251, avg. samples / sec: 54210.30
Iteration:   2840, Loss function: 4.579, Average Loss: 4.264, avg. samples / sec: 54210.78
Iteration:   2840, Loss function: 3.745, Average Loss: 4.268, avg. samples / sec: 54179.14
Iteration:   2840, Loss function: 3.474, Average Loss: 4.282, avg. samples / sec: 54258.53
Iteration:   2840, Loss function: 3.838, Average Loss: 4.218, avg. samples / sec: 54189.27
Iteration:   2840, Loss function: 4.926, Average Loss: 4.234, avg. samples / sec: 54218.16
Iteration:   2860, Loss function: 5.387, Average Loss: 4.209, avg. samples / sec: 54252.24
Iteration:   2860, Loss function: 3.609, Average Loss: 4.268, avg. samples / sec: 54213.11
Iteration:   2860, Loss function: 4.340, Average Loss: 4.246, avg. samples / sec: 54178.25
Iteration:   2860, Loss function: 5.268, Average Loss: 4.225, avg. samples / sec: 54097.45
Iteration:   2860, Loss function: 2.943, Average Loss: 4.250, avg. samples / sec: 54251.24
Iteration:   2860, Loss function: 4.977, Average Loss: 4.245, avg. samples / sec: 54225.17
Iteration:   2860, Loss function: 5.909, Average Loss: 4.256, avg. samples / sec: 54248.07
Iteration:   2860, Loss function: 4.618, Average Loss: 4.246, avg. samples / sec: 54442.04
Iteration:   2860, Loss function: 4.186, Average Loss: 4.214, avg. samples / sec: 54217.35
Iteration:   2860, Loss function: 4.952, Average Loss: 4.236, avg. samples / sec: 54240.20
Iteration:   2860, Loss function: 4.097, Average Loss: 4.244, avg. samples / sec: 54152.22
Iteration:   2860, Loss function: 4.877, Average Loss: 4.235, avg. samples / sec: 54190.10
Iteration:   2860, Loss function: 3.696, Average Loss: 4.231, avg. samples / sec: 54146.25
Iteration:   2860, Loss function: 3.162, Average Loss: 4.216, avg. samples / sec: 54161.73
Iteration:   2860, Loss function: 3.844, Average Loss: 4.218, avg. samples / sec: 54181.45
Iteration:   2860, Loss function: 3.147, Average Loss: 4.238, avg. samples / sec: 54124.71
Iteration:   2860, Loss function: 3.713, Average Loss: 4.239, avg. samples / sec: 54152.26
Iteration:   2860, Loss function: 4.070, Average Loss: 4.212, avg. samples / sec: 54284.13
Iteration:   2860, Loss function: 4.207, Average Loss: 4.232, avg. samples / sec: 54228.68
Iteration:   2860, Loss function: 3.607, Average Loss: 4.238, avg. samples / sec: 54187.41
Iteration:   2860, Loss function: 4.419, Average Loss: 4.242, avg. samples / sec: 54180.66
Iteration:   2860, Loss function: 4.161, Average Loss: 4.223, avg. samples / sec: 54198.12
Iteration:   2860, Loss function: 3.004, Average Loss: 4.263, avg. samples / sec: 54232.08
Iteration:   2860, Loss function: 3.973, Average Loss: 4.262, avg. samples / sec: 54160.30
Iteration:   2860, Loss function: 5.138, Average Loss: 4.263, avg. samples / sec: 54189.68
Iteration:   2860, Loss function: 4.312, Average Loss: 4.246, avg. samples / sec: 54189.18
Iteration:   2860, Loss function: 3.365, Average Loss: 4.244, avg. samples / sec: 54156.66
Iteration:   2860, Loss function: 3.263, Average Loss: 4.275, avg. samples / sec: 54185.83
Iteration:   2860, Loss function: 4.673, Average Loss: 4.229, avg. samples / sec: 54231.99
Iteration:   2860, Loss function: 3.835, Average Loss: 4.259, avg. samples / sec: 54154.39
:::MLL 1558640115.812 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558640115.813 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 3.426, Average Loss: 4.210, avg. samples / sec: 53826.98
Iteration:   2880, Loss function: 3.673, Average Loss: 4.265, avg. samples / sec: 53886.46
Iteration:   2880, Loss function: 3.703, Average Loss: 4.228, avg. samples / sec: 54000.31
Iteration:   2880, Loss function: 4.655, Average Loss: 4.206, avg. samples / sec: 54160.82
Iteration:   2880, Loss function: 4.229, Average Loss: 4.218, avg. samples / sec: 53935.52
Iteration:   2880, Loss function: 3.962, Average Loss: 4.243, avg. samples / sec: 53838.72
Iteration:   2880, Loss function: 2.637, Average Loss: 4.241, avg. samples / sec: 53870.25
Iteration:   2880, Loss function: 2.587, Average Loss: 4.238, avg. samples / sec: 53878.26
Iteration:   2880, Loss function: 4.293, Average Loss: 4.231, avg. samples / sec: 53888.60
Iteration:   2880, Loss function: 4.283, Average Loss: 4.240, avg. samples / sec: 53828.99
Iteration:   2880, Loss function: 3.675, Average Loss: 4.252, avg. samples / sec: 53824.31
Iteration:   2880, Loss function: 4.283, Average Loss: 4.241, avg. samples / sec: 53857.82
Iteration:   2880, Loss function: 3.762, Average Loss: 4.210, avg. samples / sec: 53845.30
Iteration:   2880, Loss function: 3.845, Average Loss: 4.215, avg. samples / sec: 53833.85
Iteration:   2880, Loss function: 3.625, Average Loss: 4.251, avg. samples / sec: 53749.79
Iteration:   2880, Loss function: 4.370, Average Loss: 4.210, avg. samples / sec: 53779.18
Iteration:   2880, Loss function: 3.943, Average Loss: 4.238, avg. samples / sec: 53833.97
Iteration:   2880, Loss function: 3.981, Average Loss: 4.235, avg. samples / sec: 53868.54
Iteration:   2880, Loss function: 4.888, Average Loss: 4.256, avg. samples / sec: 53876.96
Iteration:   2880, Loss function: 3.745, Average Loss: 4.240, avg. samples / sec: 53883.91
Iteration:   2880, Loss function: 2.835, Average Loss: 4.261, avg. samples / sec: 53870.68
Iteration:   2880, Loss function: 4.299, Average Loss: 4.220, avg. samples / sec: 53871.86
Iteration:   2880, Loss function: 4.961, Average Loss: 4.232, avg. samples / sec: 53824.99
Iteration:   2880, Loss function: 4.909, Average Loss: 4.239, avg. samples / sec: 53851.23
Iteration:   2880, Loss function: 4.283, Average Loss: 4.257, avg. samples / sec: 53854.30
Iteration:   2880, Loss function: 4.017, Average Loss: 4.236, avg. samples / sec: 53646.81
Iteration:   2880, Loss function: 4.033, Average Loss: 4.271, avg. samples / sec: 53850.69
Iteration:   2880, Loss function: 3.208, Average Loss: 4.235, avg. samples / sec: 53822.79
Iteration:   2880, Loss function: 3.973, Average Loss: 4.257, avg. samples / sec: 53857.94
Iteration:   2880, Loss function: 2.976, Average Loss: 4.230, avg. samples / sec: 53806.41
Iteration:   2900, Loss function: 4.184, Average Loss: 4.207, avg. samples / sec: 54160.30
Iteration:   2900, Loss function: 3.761, Average Loss: 4.209, avg. samples / sec: 54211.78
Iteration:   2900, Loss function: 4.106, Average Loss: 4.228, avg. samples / sec: 54222.19
Iteration:   2900, Loss function: 3.703, Average Loss: 4.228, avg. samples / sec: 54212.70
Iteration:   2900, Loss function: 4.378, Average Loss: 4.235, avg. samples / sec: 54221.33
Iteration:   2900, Loss function: 3.408, Average Loss: 4.238, avg. samples / sec: 54211.90
Iteration:   2900, Loss function: 4.880, Average Loss: 4.222, avg. samples / sec: 54042.39
Iteration:   2900, Loss function: 4.288, Average Loss: 4.238, avg. samples / sec: 54153.95
Iteration:   2900, Loss function: 2.350, Average Loss: 4.230, avg. samples / sec: 54246.15
Iteration:   2900, Loss function: 4.317, Average Loss: 4.246, avg. samples / sec: 54178.45
Iteration:   2900, Loss function: 4.151, Average Loss: 4.208, avg. samples / sec: 54229.49
Iteration:   2900, Loss function: 5.019, Average Loss: 4.214, avg. samples / sec: 54035.30
Iteration:   2900, Loss function: 6.694, Average Loss: 4.249, avg. samples / sec: 54226.15
Iteration:   2900, Loss function: 4.340, Average Loss: 4.204, avg. samples / sec: 54177.56
Iteration:   2900, Loss function: 3.830, Average Loss: 4.263, avg. samples / sec: 53884.92
Iteration:   2900, Loss function: 3.217, Average Loss: 4.246, avg. samples / sec: 54202.29
Iteration:   2900, Loss function: 3.530, Average Loss: 4.231, avg. samples / sec: 54211.11
Iteration:   2900, Loss function: 4.502, Average Loss: 4.217, avg. samples / sec: 54183.64
Iteration:   2900, Loss function: 4.864, Average Loss: 4.228, avg. samples / sec: 54159.49
Iteration:   2900, Loss function: 2.643, Average Loss: 4.233, avg. samples / sec: 54153.35
Iteration:   2900, Loss function: 3.541, Average Loss: 4.256, avg. samples / sec: 54151.72
Iteration:   2900, Loss function: 5.116, Average Loss: 4.246, avg. samples / sec: 54175.14
Iteration:   2900, Loss function: 4.607, Average Loss: 4.234, avg. samples / sec: 54196.77
Iteration:   2900, Loss function: 3.781, Average Loss: 4.250, avg. samples / sec: 54211.57
Iteration:   2900, Loss function: 3.779, Average Loss: 4.231, avg. samples / sec: 54190.70
Iteration:   2900, Loss function: 5.432, Average Loss: 4.267, avg. samples / sec: 54176.77
Iteration:   2900, Loss function: 5.241, Average Loss: 4.225, avg. samples / sec: 54121.24
Iteration:   2900, Loss function: 4.030, Average Loss: 4.238, avg. samples / sec: 53849.52
Iteration:   2900, Loss function: 4.134, Average Loss: 4.225, avg. samples / sec: 54216.24
Iteration:   2900, Loss function: 3.155, Average Loss: 4.214, avg. samples / sec: 53920.21
Iteration:   2920, Loss function: 2.893, Average Loss: 4.204, avg. samples / sec: 54339.73
Iteration:   2920, Loss function: 4.156, Average Loss: 4.263, avg. samples / sec: 54547.82
Iteration:   2920, Loss function: 5.606, Average Loss: 4.211, avg. samples / sec: 54467.38
Iteration:   2920, Loss function: 3.855, Average Loss: 4.201, avg. samples / sec: 54205.21
Iteration:   2920, Loss function: 4.714, Average Loss: 4.233, avg. samples / sec: 54598.21
Iteration:   2920, Loss function: 3.567, Average Loss: 4.232, avg. samples / sec: 54258.74
Iteration:   2920, Loss function: 4.364, Average Loss: 4.238, avg. samples / sec: 54313.88
Iteration:   2920, Loss function: 2.982, Average Loss: 4.235, avg. samples / sec: 54276.50
Iteration:   2920, Loss function: 3.859, Average Loss: 4.224, avg. samples / sec: 54237.67
Iteration:   2920, Loss function: 3.423, Average Loss: 4.225, avg. samples / sec: 54248.78
Iteration:   2920, Loss function: 5.065, Average Loss: 4.228, avg. samples / sec: 54288.88
Iteration:   2920, Loss function: 3.762, Average Loss: 4.215, avg. samples / sec: 54284.70
Iteration:   2920, Loss function: 3.161, Average Loss: 4.205, avg. samples / sec: 54301.56
Iteration:   2920, Loss function: 3.087, Average Loss: 4.220, avg. samples / sec: 54544.11
Iteration:   2920, Loss function: 4.023, Average Loss: 4.202, avg. samples / sec: 54307.98
Iteration:   2920, Loss function: 4.267, Average Loss: 4.232, avg. samples / sec: 54249.99
Iteration:   2920, Loss function: 3.686, Average Loss: 4.203, avg. samples / sec: 54531.45
Iteration:   2920, Loss function: 3.562, Average Loss: 4.245, avg. samples / sec: 54237.34
Iteration:   2920, Loss function: 3.327, Average Loss: 4.255, avg. samples / sec: 54424.95
Iteration:   2920, Loss function: 4.804, Average Loss: 4.243, avg. samples / sec: 54280.60
Iteration:   2920, Loss function: 3.956, Average Loss: 4.228, avg. samples / sec: 54271.76
Iteration:   2920, Loss function: 4.892, Average Loss: 4.247, avg. samples / sec: 54306.29
Iteration:   2920, Loss function: 4.858, Average Loss: 4.246, avg. samples / sec: 54302.92
Iteration:   2920, Loss function: 3.687, Average Loss: 4.219, avg. samples / sec: 54279.58
Iteration:   2920, Loss function: 3.761, Average Loss: 4.215, avg. samples / sec: 54258.59
Iteration:   2920, Loss function: 3.885, Average Loss: 4.231, avg. samples / sec: 54278.57
Iteration:   2920, Loss function: 4.464, Average Loss: 4.230, avg. samples / sec: 54295.93
Iteration:   2920, Loss function: 8.261, Average Loss: 4.263, avg. samples / sec: 54292.12
Iteration:   2920, Loss function: 5.046, Average Loss: 4.225, avg. samples / sec: 54279.12
Iteration:   2920, Loss function: 4.273, Average Loss: 4.222, avg. samples / sec: 54270.34
:::MLL 1558640117.985 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558640117.986 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.628, Average Loss: 4.260, avg. samples / sec: 53895.01
Iteration:   2940, Loss function: 4.813, Average Loss: 4.204, avg. samples / sec: 53938.89
Iteration:   2940, Loss function: 3.285, Average Loss: 4.198, avg. samples / sec: 53842.09
Iteration:   2940, Loss function: 4.437, Average Loss: 4.208, avg. samples / sec: 53878.74
Iteration:   2940, Loss function: 4.434, Average Loss: 4.231, avg. samples / sec: 53971.32
Iteration:   2940, Loss function: 5.084, Average Loss: 4.226, avg. samples / sec: 53936.12
Iteration:   2940, Loss function: 3.902, Average Loss: 4.214, avg. samples / sec: 53946.40
Iteration:   2940, Loss function: 3.593, Average Loss: 4.216, avg. samples / sec: 53885.49
Iteration:   2940, Loss function: 3.580, Average Loss: 4.224, avg. samples / sec: 53922.48
Iteration:   2940, Loss function: 4.263, Average Loss: 4.237, avg. samples / sec: 53873.15
Iteration:   2940, Loss function: 4.882, Average Loss: 4.232, avg. samples / sec: 53859.19
Iteration:   2940, Loss function: 5.339, Average Loss: 4.201, avg. samples / sec: 53903.07
Iteration:   2940, Loss function: 3.788, Average Loss: 4.228, avg. samples / sec: 53850.59
Iteration:   2940, Loss function: 3.696, Average Loss: 4.200, avg. samples / sec: 53913.55
Iteration:   2940, Loss function: 4.005, Average Loss: 4.202, avg. samples / sec: 53830.68
Iteration:   2940, Loss function: 4.823, Average Loss: 4.212, avg. samples / sec: 53802.01
Iteration:   2940, Loss function: 4.693, Average Loss: 4.240, avg. samples / sec: 53879.19
Iteration:   2940, Loss function: 3.224, Average Loss: 4.240, avg. samples / sec: 53982.67
Iteration:   2940, Loss function: 3.282, Average Loss: 4.227, avg. samples / sec: 53951.15
Iteration:   2940, Loss function: 4.641, Average Loss: 4.219, avg. samples / sec: 53927.62
Iteration:   2940, Loss function: 2.760, Average Loss: 4.219, avg. samples / sec: 53959.25
Iteration:   2940, Loss function: 3.149, Average Loss: 4.238, avg. samples / sec: 53841.07
Iteration:   2940, Loss function: 3.601, Average Loss: 4.212, avg. samples / sec: 53882.61
Iteration:   2940, Loss function: 4.336, Average Loss: 4.244, avg. samples / sec: 53870.68
Iteration:   2940, Loss function: 4.599, Average Loss: 4.220, avg. samples / sec: 53874.08
Iteration:   2940, Loss function: 3.451, Average Loss: 4.218, avg. samples / sec: 53885.51
Iteration:   2940, Loss function: 4.653, Average Loss: 4.226, avg. samples / sec: 53814.85
Iteration:   2940, Loss function: 4.327, Average Loss: 4.252, avg. samples / sec: 53709.82
Iteration:   2940, Loss function: 4.288, Average Loss: 4.222, avg. samples / sec: 52811.23
Iteration:   2940, Loss function: 3.394, Average Loss: 4.254, avg. samples / sec: 52828.20
Iteration:   2960, Loss function: 4.935, Average Loss: 4.200, avg. samples / sec: 53314.10
Iteration:   2960, Loss function: 3.942, Average Loss: 4.252, avg. samples / sec: 53279.89
Iteration:   2960, Loss function: 5.193, Average Loss: 4.194, avg. samples / sec: 53293.13
Iteration:   2960, Loss function: 4.121, Average Loss: 4.203, avg. samples / sec: 53306.35
Iteration:   2960, Loss function: 3.981, Average Loss: 4.223, avg. samples / sec: 53232.96
Iteration:   2960, Loss function: 3.041, Average Loss: 4.228, avg. samples / sec: 53303.75
Iteration:   2960, Loss function: 4.335, Average Loss: 4.221, avg. samples / sec: 53289.46
Iteration:   2960, Loss function: 5.490, Average Loss: 4.198, avg. samples / sec: 53334.33
Iteration:   2960, Loss function: 4.693, Average Loss: 4.211, avg. samples / sec: 53230.69
Iteration:   2960, Loss function: 4.334, Average Loss: 4.237, avg. samples / sec: 53267.75
Iteration:   2960, Loss function: 2.894, Average Loss: 4.195, avg. samples / sec: 53274.29
Iteration:   2960, Loss function: 3.787, Average Loss: 4.194, avg. samples / sec: 53291.25
Iteration:   2960, Loss function: 4.372, Average Loss: 4.213, avg. samples / sec: 53234.14
Iteration:   2960, Loss function: 3.684, Average Loss: 4.222, avg. samples / sec: 53273.67
Iteration:   2960, Loss function: 3.607, Average Loss: 4.225, avg. samples / sec: 53134.37
Iteration:   2960, Loss function: 3.645, Average Loss: 4.211, avg. samples / sec: 53263.04
Iteration:   2960, Loss function: 3.705, Average Loss: 4.235, avg. samples / sec: 53206.43
Iteration:   2960, Loss function: 3.674, Average Loss: 4.224, avg. samples / sec: 53223.81
Iteration:   2960, Loss function: 3.232, Average Loss: 4.229, avg. samples / sec: 53285.05
Iteration:   2960, Loss function: 3.489, Average Loss: 4.233, avg. samples / sec: 53272.74
Iteration:   2960, Loss function: 4.088, Average Loss: 4.215, avg. samples / sec: 53279.31
Iteration:   2960, Loss function: 3.624, Average Loss: 4.220, avg. samples / sec: 54115.67
Iteration:   2960, Loss function: 3.865, Average Loss: 4.211, avg. samples / sec: 53300.81
Iteration:   2960, Loss function: 4.293, Average Loss: 4.208, avg. samples / sec: 53260.26
Iteration:   2960, Loss function: 2.438, Average Loss: 4.233, avg. samples / sec: 53101.26
Iteration:   2960, Loss function: 3.556, Average Loss: 4.223, avg. samples / sec: 53295.47
Iteration:   2960, Loss function: 3.783, Average Loss: 4.249, avg. samples / sec: 53302.30
Iteration:   2960, Loss function: 2.608, Average Loss: 4.209, avg. samples / sec: 53080.34
Iteration:   2960, Loss function: 4.750, Average Loss: 4.244, avg. samples / sec: 54318.36
Iteration:   2960, Loss function: 4.151, Average Loss: 4.215, avg. samples / sec: 53192.39
Iteration:   2980, Loss function: 4.590, Average Loss: 4.197, avg. samples / sec: 54220.06
Iteration:   2980, Loss function: 3.222, Average Loss: 4.249, avg. samples / sec: 54215.03
Iteration:   2980, Loss function: 4.434, Average Loss: 4.199, avg. samples / sec: 54141.59
Iteration:   2980, Loss function: 3.910, Average Loss: 4.183, avg. samples / sec: 54046.81
Iteration:   2980, Loss function: 4.911, Average Loss: 4.228, avg. samples / sec: 54210.80
Iteration:   2980, Loss function: 3.804, Average Loss: 4.221, avg. samples / sec: 54272.36
Iteration:   2980, Loss function: 2.737, Average Loss: 4.226, avg. samples / sec: 54473.92
Iteration:   2980, Loss function: 4.258, Average Loss: 4.195, avg. samples / sec: 54220.64
Iteration:   2980, Loss function: 5.493, Average Loss: 4.214, avg. samples / sec: 54246.92
Iteration:   2980, Loss function: 4.243, Average Loss: 4.187, avg. samples / sec: 54218.16
Iteration:   2980, Loss function: 3.437, Average Loss: 4.195, avg. samples / sec: 54227.05
Iteration:   2980, Loss function: 4.565, Average Loss: 4.212, avg. samples / sec: 54230.91
Iteration:   2980, Loss function: 2.824, Average Loss: 4.204, avg. samples / sec: 54474.93
Iteration:   2980, Loss function: 4.208, Average Loss: 4.219, avg. samples / sec: 54160.57
Iteration:   2980, Loss function: 5.017, Average Loss: 4.213, avg. samples / sec: 54438.32
Iteration:   2980, Loss function: 4.028, Average Loss: 4.199, avg. samples / sec: 54179.72
Iteration:   2980, Loss function: 4.057, Average Loss: 4.220, avg. samples / sec: 54145.34
Iteration:   2980, Loss function: 4.799, Average Loss: 4.232, avg. samples / sec: 54149.68
Iteration:   2980, Loss function: 4.234, Average Loss: 4.228, avg. samples / sec: 54296.22
Iteration:   2980, Loss function: 3.760, Average Loss: 4.224, avg. samples / sec: 54236.65
Iteration:   2980, Loss function: 5.104, Average Loss: 4.217, avg. samples / sec: 54261.96
Iteration:   2980, Loss function: 3.775, Average Loss: 4.226, avg. samples / sec: 54241.95
Iteration:   2980, Loss function: 4.367, Average Loss: 4.208, avg. samples / sec: 54190.50
Iteration:   2980, Loss function: 2.620, Average Loss: 4.205, avg. samples / sec: 54227.55
Iteration:   2980, Loss function: 4.415, Average Loss: 4.204, avg. samples / sec: 54231.81
Iteration:   2980, Loss function: 5.029, Average Loss: 4.225, avg. samples / sec: 54191.64
Iteration:   2980, Loss function: 3.829, Average Loss: 4.209, avg. samples / sec: 54211.32
Iteration:   2980, Loss function: 3.927, Average Loss: 4.242, avg. samples / sec: 54198.29
Iteration:   2980, Loss function: 4.767, Average Loss: 4.244, avg. samples / sec: 54209.28
Iteration:   2980, Loss function: 3.007, Average Loss: 4.209, avg. samples / sec: 54220.62
Iteration:   3000, Loss function: 3.781, Average Loss: 4.243, avg. samples / sec: 53822.64
Iteration:   3000, Loss function: 3.809, Average Loss: 4.195, avg. samples / sec: 53858.82
Iteration:   3000, Loss function: 3.717, Average Loss: 4.194, avg. samples / sec: 53754.69
Iteration:   3000, Loss function: 3.624, Average Loss: 4.212, avg. samples / sec: 53940.29
Iteration:   3000, Loss function: 3.904, Average Loss: 4.206, avg. samples / sec: 53887.41
Iteration:   3000, Loss function: 4.309, Average Loss: 4.180, avg. samples / sec: 53843.93
Iteration:   3000, Loss function: 3.418, Average Loss: 4.214, avg. samples / sec: 53883.06
Iteration:   3000, Loss function: 3.386, Average Loss: 4.210, avg. samples / sec: 53863.17
Iteration:   3000, Loss function: 4.267, Average Loss: 4.186, avg. samples / sec: 53846.76
Iteration:   3000, Loss function: 4.248, Average Loss: 4.190, avg. samples / sec: 53842.92
Iteration:   3000, Loss function: 4.399, Average Loss: 4.201, avg. samples / sec: 53849.44
Iteration:   3000, Loss function: 4.341, Average Loss: 4.192, avg. samples / sec: 53829.22
Iteration:   3000, Loss function: 3.681, Average Loss: 4.213, avg. samples / sec: 53846.58
Iteration:   3000, Loss function: 2.669, Average Loss: 4.220, avg. samples / sec: 53797.64
Iteration:   3000, Loss function: 3.179, Average Loss: 4.217, avg. samples / sec: 53809.16
Iteration:   3000, Loss function: 3.546, Average Loss: 4.215, avg. samples / sec: 53793.26
Iteration:   3000, Loss function: 3.097, Average Loss: 4.225, avg. samples / sec: 53876.47
Iteration:   3000, Loss function: 3.300, Average Loss: 4.200, avg. samples / sec: 53835.27
Iteration:   3000, Loss function: 3.640, Average Loss: 4.191, avg. samples / sec: 53876.84
Iteration:   3000, Loss function: 3.786, Average Loss: 4.228, avg. samples / sec: 53754.79
Iteration:   3000, Loss function: 4.281, Average Loss: 4.222, avg. samples / sec: 53825.54
Iteration:   3000, Loss function: 3.763, Average Loss: 4.219, avg. samples / sec: 53867.45
Iteration:   3000, Loss function: 5.430, Average Loss: 4.200, avg. samples / sec: 53849.67
Iteration:   3000, Loss function: 3.690, Average Loss: 4.204, avg. samples / sec: 53866.30
Iteration:   3000, Loss function: 3.627, Average Loss: 4.216, avg. samples / sec: 53827.21
Iteration:   3000, Loss function: 4.745, Average Loss: 4.205, avg. samples / sec: 53817.34
Iteration:   3000, Loss function: 4.600, Average Loss: 4.212, avg. samples / sec: 53807.81
Iteration:   3000, Loss function: 5.032, Average Loss: 4.237, avg. samples / sec: 53865.12
Iteration:   3000, Loss function: 4.381, Average Loss: 4.238, avg. samples / sec: 53869.22
Iteration:   3000, Loss function: 3.379, Average Loss: 4.205, avg. samples / sec: 53865.99
:::MLL 1558640120.176 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558640120.176 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 3.696, Average Loss: 4.190, avg. samples / sec: 53580.73
Iteration:   3020, Loss function: 2.709, Average Loss: 4.235, avg. samples / sec: 53486.29
Iteration:   3020, Loss function: 3.660, Average Loss: 4.209, avg. samples / sec: 53485.27
Iteration:   3020, Loss function: 2.740, Average Loss: 4.218, avg. samples / sec: 53550.86
Iteration:   3020, Loss function: 3.499, Average Loss: 4.181, avg. samples / sec: 53491.30
Iteration:   3020, Loss function: 3.783, Average Loss: 4.207, avg. samples / sec: 53482.80
Iteration:   3020, Loss function: 4.057, Average Loss: 4.190, avg. samples / sec: 53514.87
Iteration:   3020, Loss function: 5.148, Average Loss: 4.215, avg. samples / sec: 53516.04
Iteration:   3020, Loss function: 3.869, Average Loss: 4.216, avg. samples / sec: 53526.37
Iteration:   3020, Loss function: 4.779, Average Loss: 4.197, avg. samples / sec: 53539.04
Iteration:   3020, Loss function: 3.849, Average Loss: 4.185, avg. samples / sec: 53500.01
Iteration:   3020, Loss function: 4.623, Average Loss: 4.184, avg. samples / sec: 53487.73
Iteration:   3020, Loss function: 3.763, Average Loss: 4.219, avg. samples / sec: 53502.68
Iteration:   3020, Loss function: 4.792, Average Loss: 4.200, avg. samples / sec: 53478.49
Iteration:   3020, Loss function: 3.048, Average Loss: 4.213, avg. samples / sec: 53479.81
Iteration:   3020, Loss function: 4.227, Average Loss: 4.209, avg. samples / sec: 53423.88
Iteration:   3020, Loss function: 3.980, Average Loss: 4.190, avg. samples / sec: 53306.90
Iteration:   3020, Loss function: 4.170, Average Loss: 4.228, avg. samples / sec: 53511.61
Iteration:   3020, Loss function: 4.068, Average Loss: 4.224, avg. samples / sec: 53514.09
Iteration:   3020, Loss function: 3.853, Average Loss: 4.216, avg. samples / sec: 53524.36
Iteration:   3020, Loss function: 4.540, Average Loss: 4.201, avg. samples / sec: 53264.75
Iteration:   3020, Loss function: 4.108, Average Loss: 4.186, avg. samples / sec: 53497.82
Iteration:   3020, Loss function: 3.258, Average Loss: 4.201, avg. samples / sec: 53499.99
Iteration:   3020, Loss function: 3.494, Average Loss: 4.215, avg. samples / sec: 53489.21
Iteration:   3020, Loss function: 4.538, Average Loss: 4.232, avg. samples / sec: 53507.57
Iteration:   3020, Loss function: 4.353, Average Loss: 4.198, avg. samples / sec: 53488.85
Iteration:   3020, Loss function: 5.181, Average Loss: 4.209, avg. samples / sec: 53468.07
Iteration:   3020, Loss function: 3.877, Average Loss: 4.235, avg. samples / sec: 53497.39
Iteration:   3020, Loss function: 4.076, Average Loss: 4.200, avg. samples / sec: 53486.78
Iteration:   3020, Loss function: 5.172, Average Loss: 4.198, avg. samples / sec: 53316.72
Iteration:   3040, Loss function: 3.624, Average Loss: 4.192, avg. samples / sec: 53718.54
Iteration:   3040, Loss function: 3.439, Average Loss: 4.211, avg. samples / sec: 53750.73
Iteration:   3040, Loss function: 4.062, Average Loss: 4.204, avg. samples / sec: 53758.52
Iteration:   3040, Loss function: 3.429, Average Loss: 4.208, avg. samples / sec: 53751.78
Iteration:   3040, Loss function: 3.893, Average Loss: 4.202, avg. samples / sec: 53705.67
Iteration:   3040, Loss function: 3.964, Average Loss: 4.211, avg. samples / sec: 53797.17
Iteration:   3040, Loss function: 4.698, Average Loss: 4.198, avg. samples / sec: 53762.95
Iteration:   3040, Loss function: 3.213, Average Loss: 4.186, avg. samples / sec: 53716.07
Iteration:   3040, Loss function: 3.576, Average Loss: 4.176, avg. samples / sec: 53702.95
Iteration:   3040, Loss function: 5.889, Average Loss: 4.217, avg. samples / sec: 53712.01
Iteration:   3040, Loss function: 3.845, Average Loss: 4.219, avg. samples / sec: 53742.53
Iteration:   3040, Loss function: 4.522, Average Loss: 4.182, avg. samples / sec: 53703.40
Iteration:   3040, Loss function: 3.858, Average Loss: 4.226, avg. samples / sec: 53520.64
Iteration:   3040, Loss function: 3.765, Average Loss: 4.207, avg. samples / sec: 53712.12
Iteration:   3040, Loss function: 4.107, Average Loss: 4.184, avg. samples / sec: 53700.31
Iteration:   3040, Loss function: 3.657, Average Loss: 4.223, avg. samples / sec: 53751.94
Iteration:   3040, Loss function: 3.614, Average Loss: 4.194, avg. samples / sec: 53736.73
Iteration:   3040, Loss function: 4.251, Average Loss: 4.203, avg. samples / sec: 53798.27
Iteration:   3040, Loss function: 3.339, Average Loss: 4.196, avg. samples / sec: 53903.77
Iteration:   3040, Loss function: 3.488, Average Loss: 4.189, avg. samples / sec: 53701.96
Iteration:   3040, Loss function: 5.798, Average Loss: 4.215, avg. samples / sec: 53697.28
Iteration:   3040, Loss function: 2.959, Average Loss: 4.222, avg. samples / sec: 53686.17
Iteration:   3040, Loss function: 4.184, Average Loss: 4.207, avg. samples / sec: 53721.70
Iteration:   3040, Loss function: 3.299, Average Loss: 4.197, avg. samples / sec: 53699.00
Iteration:   3040, Loss function: 4.553, Average Loss: 4.232, avg. samples / sec: 53722.93
Iteration:   3040, Loss function: 3.072, Average Loss: 4.197, avg. samples / sec: 53759.38
Iteration:   3040, Loss function: 3.630, Average Loss: 4.190, avg. samples / sec: 53465.55
Iteration:   3040, Loss function: 4.012, Average Loss: 4.180, avg. samples / sec: 53463.26
Iteration:   3040, Loss function: 4.629, Average Loss: 4.193, avg. samples / sec: 53710.93
Iteration:   3040, Loss function: 4.255, Average Loss: 4.230, avg. samples / sec: 53711.17
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558640121.384 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=2.74s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17160
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31581
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.16861
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.26741
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18051
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27950
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07768
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30227
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.42280
Current AP: 0.17160 AP goal: 0.23000
:::MLL 1558640125.361 eval_accuracy: {"value": 0.17159546131068976, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558640125.439 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558640125.446 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558640125.446 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 3.346, Average Loss: 4.224, avg. samples / sec: 7154.18
Iteration:   3060, Loss function: 4.126, Average Loss: 4.197, avg. samples / sec: 7150.45
Iteration:   3060, Loss function: 4.857, Average Loss: 4.189, avg. samples / sec: 7147.19
Iteration:   3060, Loss function: 3.478, Average Loss: 4.172, avg. samples / sec: 7152.11
Iteration:   3060, Loss function: 4.240, Average Loss: 4.175, avg. samples / sec: 7150.49
Iteration:   3060, Loss function: 3.860, Average Loss: 4.179, avg. samples / sec: 7150.17
Iteration:   3060, Loss function: 4.166, Average Loss: 4.195, avg. samples / sec: 7149.86
Iteration:   3060, Loss function: 2.926, Average Loss: 4.191, avg. samples / sec: 7149.64
Iteration:   3060, Loss function: 3.454, Average Loss: 4.177, avg. samples / sec: 7150.40
Iteration:   3060, Loss function: 3.044, Average Loss: 4.171, avg. samples / sec: 7154.54
Iteration:   3060, Loss function: 3.475, Average Loss: 4.188, avg. samples / sec: 7154.30
Iteration:   3060, Loss function: 4.444, Average Loss: 4.204, avg. samples / sec: 7148.97
Iteration:   3060, Loss function: 3.220, Average Loss: 4.205, avg. samples / sec: 7148.31
Iteration:   3060, Loss function: 3.405, Average Loss: 4.185, avg. samples / sec: 7153.49
Iteration:   3060, Loss function: 3.440, Average Loss: 4.202, avg. samples / sec: 7152.28
Iteration:   3060, Loss function: 2.693, Average Loss: 4.198, avg. samples / sec: 7148.32
Iteration:   3060, Loss function: 4.083, Average Loss: 4.201, avg. samples / sec: 7150.74
Iteration:   3060, Loss function: 3.981, Average Loss: 4.215, avg. samples / sec: 7149.49
Iteration:   3060, Loss function: 4.238, Average Loss: 4.194, avg. samples / sec: 7150.82
Iteration:   3060, Loss function: 5.050, Average Loss: 4.189, avg. samples / sec: 7150.35
Iteration:   3060, Loss function: 2.496, Average Loss: 4.195, avg. samples / sec: 7149.68
Iteration:   3060, Loss function: 4.872, Average Loss: 4.202, avg. samples / sec: 7150.31
Iteration:   3060, Loss function: 3.753, Average Loss: 4.192, avg. samples / sec: 7150.00
Iteration:   3060, Loss function: 3.150, Average Loss: 4.212, avg. samples / sec: 7150.19
Iteration:   3060, Loss function: 3.368, Average Loss: 4.225, avg. samples / sec: 7150.27
Iteration:   3060, Loss function: 4.024, Average Loss: 4.211, avg. samples / sec: 7145.60
Iteration:   3060, Loss function: 3.901, Average Loss: 4.202, avg. samples / sec: 7146.30
Iteration:   3060, Loss function: 3.481, Average Loss: 4.207, avg. samples / sec: 7145.47
Iteration:   3060, Loss function: 3.635, Average Loss: 4.190, avg. samples / sec: 7149.67
Iteration:   3060, Loss function: 3.276, Average Loss: 4.220, avg. samples / sec: 7149.99
:::MLL 1558640126.433 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558640126.434 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 2.999, Average Loss: 4.211, avg. samples / sec: 54158.07
Iteration:   3080, Loss function: 3.306, Average Loss: 4.175, avg. samples / sec: 54370.80
Iteration:   3080, Loss function: 4.799, Average Loss: 4.169, avg. samples / sec: 54290.30
Iteration:   3080, Loss function: 4.468, Average Loss: 4.163, avg. samples / sec: 54242.66
Iteration:   3080, Loss function: 2.410, Average Loss: 4.187, avg. samples / sec: 54152.68
Iteration:   3080, Loss function: 4.136, Average Loss: 4.191, avg. samples / sec: 54241.24
Iteration:   3080, Loss function: 2.848, Average Loss: 4.184, avg. samples / sec: 54191.66
Iteration:   3080, Loss function: 3.582, Average Loss: 4.182, avg. samples / sec: 54189.39
Iteration:   3080, Loss function: 3.573, Average Loss: 4.184, avg. samples / sec: 54116.02
Iteration:   3080, Loss function: 4.897, Average Loss: 4.190, avg. samples / sec: 54183.99
Iteration:   3080, Loss function: 2.451, Average Loss: 4.175, avg. samples / sec: 54196.87
Iteration:   3080, Loss function: 3.932, Average Loss: 4.168, avg. samples / sec: 54117.62
Iteration:   3080, Loss function: 3.603, Average Loss: 4.195, avg. samples / sec: 54181.89
Iteration:   3080, Loss function: 3.503, Average Loss: 4.166, avg. samples / sec: 54105.11
Iteration:   3080, Loss function: 3.550, Average Loss: 4.181, avg. samples / sec: 54325.11
Iteration:   3080, Loss function: 3.939, Average Loss: 4.208, avg. samples / sec: 54292.77
Iteration:   3080, Loss function: 4.645, Average Loss: 4.187, avg. samples / sec: 54160.48
Iteration:   3080, Loss function: 3.673, Average Loss: 4.191, avg. samples / sec: 54268.60
Iteration:   3080, Loss function: 2.777, Average Loss: 4.200, avg. samples / sec: 54277.42
Iteration:   3080, Loss function: 3.631, Average Loss: 4.189, avg. samples / sec: 54255.96
Iteration:   3080, Loss function: 3.215, Average Loss: 4.161, avg. samples / sec: 54012.07
Iteration:   3080, Loss function: 3.293, Average Loss: 4.211, avg. samples / sec: 54193.52
Iteration:   3080, Loss function: 3.032, Average Loss: 4.186, avg. samples / sec: 54148.81
Iteration:   3080, Loss function: 3.003, Average Loss: 4.189, avg. samples / sec: 54206.61
Iteration:   3080, Loss function: 2.629, Average Loss: 4.189, avg. samples / sec: 54137.12
Iteration:   3080, Loss function: 4.700, Average Loss: 4.175, avg. samples / sec: 54144.03
Iteration:   3080, Loss function: 4.117, Average Loss: 4.195, avg. samples / sec: 54158.97
Iteration:   3080, Loss function: 3.006, Average Loss: 4.200, avg. samples / sec: 54095.79
Iteration:   3080, Loss function: 3.951, Average Loss: 4.210, avg. samples / sec: 54135.14
Iteration:   3080, Loss function: 4.526, Average Loss: 4.178, avg. samples / sec: 54119.99
Iteration:   3100, Loss function: 3.561, Average Loss: 4.201, avg. samples / sec: 53817.24
Iteration:   3100, Loss function: 3.513, Average Loss: 4.148, avg. samples / sec: 53803.80
Iteration:   3100, Loss function: 3.501, Average Loss: 4.176, avg. samples / sec: 54031.89
Iteration:   3100, Loss function: 3.745, Average Loss: 4.160, avg. samples / sec: 53744.48
Iteration:   3100, Loss function: 4.591, Average Loss: 4.163, avg. samples / sec: 53915.69
Iteration:   3100, Loss function: 4.680, Average Loss: 4.178, avg. samples / sec: 53831.36
Iteration:   3100, Loss function: 2.920, Average Loss: 4.155, avg. samples / sec: 53930.24
Iteration:   3100, Loss function: 3.181, Average Loss: 4.173, avg. samples / sec: 53797.29
Iteration:   3100, Loss function: 2.551, Average Loss: 4.167, avg. samples / sec: 53865.64
Iteration:   3100, Loss function: 3.272, Average Loss: 4.164, avg. samples / sec: 53674.07
Iteration:   3100, Loss function: 3.682, Average Loss: 4.151, avg. samples / sec: 54006.38
Iteration:   3100, Loss function: 5.218, Average Loss: 4.157, avg. samples / sec: 53856.52
Iteration:   3100, Loss function: 3.371, Average Loss: 4.172, avg. samples / sec: 53901.14
Iteration:   3100, Loss function: 4.671, Average Loss: 4.185, avg. samples / sec: 53879.93
Iteration:   3100, Loss function: 4.561, Average Loss: 4.182, avg. samples / sec: 53773.31
Iteration:   3100, Loss function: 3.926, Average Loss: 4.171, avg. samples / sec: 53698.18
Iteration:   3100, Loss function: 3.944, Average Loss: 4.204, avg. samples / sec: 53702.84
Iteration:   3100, Loss function: 3.761, Average Loss: 4.191, avg. samples / sec: 53738.80
Iteration:   3100, Loss function: 3.276, Average Loss: 4.167, avg. samples / sec: 53857.73
Iteration:   3100, Loss function: 4.815, Average Loss: 4.177, avg. samples / sec: 53845.06
Iteration:   3100, Loss function: 3.859, Average Loss: 4.198, avg. samples / sec: 53824.94
Iteration:   3100, Loss function: 2.556, Average Loss: 4.176, avg. samples / sec: 53828.65
Iteration:   3100, Loss function: 3.550, Average Loss: 4.179, avg. samples / sec: 53721.29
Iteration:   3100, Loss function: 3.543, Average Loss: 4.175, avg. samples / sec: 53824.55
Iteration:   3100, Loss function: 2.993, Average Loss: 4.185, avg. samples / sec: 53922.96
Iteration:   3100, Loss function: 3.800, Average Loss: 4.168, avg. samples / sec: 53921.72
Iteration:   3100, Loss function: 3.102, Average Loss: 4.187, avg. samples / sec: 53863.81
Iteration:   3100, Loss function: 2.804, Average Loss: 4.200, avg. samples / sec: 53877.31
Iteration:   3100, Loss function: 3.254, Average Loss: 4.185, avg. samples / sec: 53558.00
Iteration:   3100, Loss function: 2.470, Average Loss: 4.170, avg. samples / sec: 53506.53
Iteration:   3120, Loss function: 2.839, Average Loss: 4.190, avg. samples / sec: 53886.13
Iteration:   3120, Loss function: 5.612, Average Loss: 4.155, avg. samples / sec: 53970.58
Iteration:   3120, Loss function: 3.044, Average Loss: 4.153, avg. samples / sec: 53962.83
Iteration:   3120, Loss function: 2.620, Average Loss: 4.148, avg. samples / sec: 53927.78
Iteration:   3120, Loss function: 3.629, Average Loss: 4.172, avg. samples / sec: 53948.70
Iteration:   3120, Loss function: 3.010, Average Loss: 4.163, avg. samples / sec: 53954.52
Iteration:   3120, Loss function: 3.080, Average Loss: 4.169, avg. samples / sec: 53897.28
Iteration:   3120, Loss function: 4.042, Average Loss: 4.154, avg. samples / sec: 54272.91
Iteration:   3120, Loss function: 2.783, Average Loss: 4.130, avg. samples / sec: 53879.68
Iteration:   3120, Loss function: 4.124, Average Loss: 4.173, avg. samples / sec: 54247.00
Iteration:   3120, Loss function: 3.154, Average Loss: 4.142, avg. samples / sec: 53963.82
Iteration:   3120, Loss function: 3.777, Average Loss: 4.167, avg. samples / sec: 53951.03
Iteration:   3120, Loss function: 4.939, Average Loss: 4.141, avg. samples / sec: 53914.29
Iteration:   3120, Loss function: 2.885, Average Loss: 4.156, avg. samples / sec: 53937.79
Iteration:   3120, Loss function: 4.096, Average Loss: 4.152, avg. samples / sec: 53863.76
Iteration:   3120, Loss function: 2.975, Average Loss: 4.140, avg. samples / sec: 53894.58
Iteration:   3120, Loss function: 3.534, Average Loss: 4.172, avg. samples / sec: 53914.70
Iteration:   3120, Loss function: 4.232, Average Loss: 4.167, avg. samples / sec: 53971.15
Iteration:   3120, Loss function: 4.992, Average Loss: 4.151, avg. samples / sec: 53948.28
Iteration:   3120, Loss function: 3.512, Average Loss: 4.191, avg. samples / sec: 53943.78
Iteration:   3120, Loss function: 3.385, Average Loss: 4.165, avg. samples / sec: 53954.85
Iteration:   3120, Loss function: 3.010, Average Loss: 4.162, avg. samples / sec: 53934.53
Iteration:   3120, Loss function: 3.820, Average Loss: 4.172, avg. samples / sec: 53948.32
Iteration:   3120, Loss function: 4.294, Average Loss: 4.171, avg. samples / sec: 53934.55
Iteration:   3120, Loss function: 4.179, Average Loss: 4.177, avg. samples / sec: 53904.64
Iteration:   3120, Loss function: 3.522, Average Loss: 4.155, avg. samples / sec: 53886.32
Iteration:   3120, Loss function: 3.342, Average Loss: 4.194, avg. samples / sec: 53891.37
Iteration:   3120, Loss function: 3.444, Average Loss: 4.160, avg. samples / sec: 53894.56
Iteration:   3120, Loss function: 3.772, Average Loss: 4.154, avg. samples / sec: 53894.11
Iteration:   3120, Loss function: 3.170, Average Loss: 4.184, avg. samples / sec: 53935.96
Iteration:   3140, Loss function: 4.595, Average Loss: 4.176, avg. samples / sec: 53980.89
Iteration:   3140, Loss function: 2.956, Average Loss: 4.163, avg. samples / sec: 53942.60
Iteration:   3140, Loss function: 4.167, Average Loss: 4.150, avg. samples / sec: 53947.23
Iteration:   3140, Loss function: 3.951, Average Loss: 4.118, avg. samples / sec: 53933.01
Iteration:   3140, Loss function: 3.563, Average Loss: 4.159, avg. samples / sec: 53913.38
Iteration:   3140, Loss function: 4.481, Average Loss: 4.166, avg. samples / sec: 53911.36
Iteration:   3140, Loss function: 3.159, Average Loss: 4.140, avg. samples / sec: 53945.64
Iteration:   3140, Loss function: 2.514, Average Loss: 4.137, avg. samples / sec: 53890.19
Iteration:   3140, Loss function: 3.984, Average Loss: 4.140, avg. samples / sec: 53865.66
Iteration:   3140, Loss function: 3.104, Average Loss: 4.132, avg. samples / sec: 53895.71
Iteration:   3140, Loss function: 2.284, Average Loss: 4.127, avg. samples / sec: 53940.62
Iteration:   3140, Loss function: 4.141, Average Loss: 4.145, avg. samples / sec: 53917.65
Iteration:   3140, Loss function: 3.922, Average Loss: 4.131, avg. samples / sec: 53894.00
Iteration:   3140, Loss function: 4.159, Average Loss: 4.135, avg. samples / sec: 53842.98
Iteration:   3140, Loss function: 2.896, Average Loss: 4.158, avg. samples / sec: 53911.42
Iteration:   3140, Loss function: 3.113, Average Loss: 4.150, avg. samples / sec: 53865.86
Iteration:   3140, Loss function: 4.157, Average Loss: 4.143, avg. samples / sec: 53791.29
Iteration:   3140, Loss function: 3.681, Average Loss: 4.166, avg. samples / sec: 54076.86
Iteration:   3140, Loss function: 3.780, Average Loss: 4.144, avg. samples / sec: 53955.76
Iteration:   3140, Loss function: 3.404, Average Loss: 4.157, avg. samples / sec: 53961.90
Iteration:   3140, Loss function: 2.474, Average Loss: 4.177, avg. samples / sec: 53921.88
Iteration:   3140, Loss function: 4.178, Average Loss: 4.146, avg. samples / sec: 53926.09
Iteration:   3140, Loss function: 3.599, Average Loss: 4.137, avg. samples / sec: 53908.21
Iteration:   3140, Loss function: 3.078, Average Loss: 4.159, avg. samples / sec: 53875.54
Iteration:   3140, Loss function: 3.215, Average Loss: 4.145, avg. samples / sec: 53942.67
Iteration:   3140, Loss function: 3.352, Average Loss: 4.180, avg. samples / sec: 53954.89
Iteration:   3140, Loss function: 2.881, Average Loss: 4.155, avg. samples / sec: 53923.43
Iteration:   3140, Loss function: 3.472, Average Loss: 4.148, avg. samples / sec: 53937.34
Iteration:   3140, Loss function: 1.939, Average Loss: 4.175, avg. samples / sec: 53940.11
Iteration:   3140, Loss function: 5.366, Average Loss: 4.146, avg. samples / sec: 53900.81
:::MLL 1558640128.616 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558640128.617 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 3.284, Average Loss: 4.162, avg. samples / sec: 54299.59
Iteration:   3160, Loss function: 3.180, Average Loss: 4.129, avg. samples / sec: 54468.83
Iteration:   3160, Loss function: 4.325, Average Loss: 4.124, avg. samples / sec: 54402.97
Iteration:   3160, Loss function: 3.436, Average Loss: 4.135, avg. samples / sec: 54287.94
Iteration:   3160, Loss function: 3.024, Average Loss: 4.150, avg. samples / sec: 54284.68
Iteration:   3160, Loss function: 3.117, Average Loss: 4.105, avg. samples / sec: 54318.66
Iteration:   3160, Loss function: 3.852, Average Loss: 4.122, avg. samples / sec: 54360.29
Iteration:   3160, Loss function: 3.682, Average Loss: 4.153, avg. samples / sec: 54315.06
Iteration:   3160, Loss function: 3.826, Average Loss: 4.134, avg. samples / sec: 54317.25
Iteration:   3160, Loss function: 4.310, Average Loss: 4.132, avg. samples / sec: 54324.54
Iteration:   3160, Loss function: 4.604, Average Loss: 4.128, avg. samples / sec: 54321.76
Iteration:   3160, Loss function: 4.259, Average Loss: 4.121, avg. samples / sec: 54326.17
Iteration:   3160, Loss function: 3.008, Average Loss: 4.142, avg. samples / sec: 54287.63
Iteration:   3160, Loss function: 2.286, Average Loss: 4.164, avg. samples / sec: 54550.02
Iteration:   3160, Loss function: 3.055, Average Loss: 4.119, avg. samples / sec: 54328.23
Iteration:   3160, Loss function: 3.454, Average Loss: 4.143, avg. samples / sec: 54343.41
Iteration:   3160, Loss function: 2.946, Average Loss: 4.136, avg. samples / sec: 54351.44
Iteration:   3160, Loss function: 3.539, Average Loss: 4.129, avg. samples / sec: 54276.63
Iteration:   3160, Loss function: 3.406, Average Loss: 4.164, avg. samples / sec: 54379.42
Iteration:   3160, Loss function: 3.803, Average Loss: 4.147, avg. samples / sec: 54368.93
Iteration:   3160, Loss function: 3.649, Average Loss: 4.118, avg. samples / sec: 54342.24
Iteration:   3160, Loss function: 3.818, Average Loss: 4.134, avg. samples / sec: 54327.77
Iteration:   3160, Loss function: 3.512, Average Loss: 4.132, avg. samples / sec: 54305.80
Iteration:   3160, Loss function: 2.900, Average Loss: 4.132, avg. samples / sec: 54359.39
Iteration:   3160, Loss function: 4.213, Average Loss: 4.154, avg. samples / sec: 54192.52
Iteration:   3160, Loss function: 3.276, Average Loss: 4.138, avg. samples / sec: 54334.95
Iteration:   3160, Loss function: 4.888, Average Loss: 4.133, avg. samples / sec: 54322.68
Iteration:   3160, Loss function: 3.819, Average Loss: 4.145, avg. samples / sec: 54284.24
Iteration:   3160, Loss function: 3.644, Average Loss: 4.159, avg. samples / sec: 54292.27
Iteration:   3160, Loss function: 3.514, Average Loss: 4.138, avg. samples / sec: 54322.57
Iteration:   3180, Loss function: 3.951, Average Loss: 4.150, avg. samples / sec: 54814.56
Iteration:   3180, Loss function: 3.121, Average Loss: 4.120, avg. samples / sec: 54811.45
Iteration:   3180, Loss function: 3.168, Average Loss: 4.138, avg. samples / sec: 54819.36
Iteration:   3180, Loss function: 2.789, Average Loss: 4.092, avg. samples / sec: 54797.42
Iteration:   3180, Loss function: 3.688, Average Loss: 4.109, avg. samples / sec: 54772.95
Iteration:   3180, Loss function: 3.945, Average Loss: 4.104, avg. samples / sec: 54844.04
Iteration:   3180, Loss function: 3.688, Average Loss: 4.118, avg. samples / sec: 54813.39
Iteration:   3180, Loss function: 3.606, Average Loss: 4.110, avg. samples / sec: 54806.97
Iteration:   3180, Loss function: 4.782, Average Loss: 4.121, avg. samples / sec: 54867.08
Iteration:   3180, Loss function: 3.175, Average Loss: 4.139, avg. samples / sec: 54791.71
Iteration:   3180, Loss function: 4.035, Average Loss: 4.135, avg. samples / sec: 54805.90
Iteration:   3180, Loss function: 4.672, Average Loss: 4.115, avg. samples / sec: 54752.25
Iteration:   3180, Loss function: 4.060, Average Loss: 4.115, avg. samples / sec: 54770.57
Iteration:   3180, Loss function: 3.618, Average Loss: 4.135, avg. samples / sec: 54774.19
Iteration:   3180, Loss function: 4.030, Average Loss: 4.127, avg. samples / sec: 54757.05
Iteration:   3180, Loss function: 4.743, Average Loss: 4.121, avg. samples / sec: 54853.13
Iteration:   3180, Loss function: 4.305, Average Loss: 4.149, avg. samples / sec: 54750.14
Iteration:   3180, Loss function: 3.938, Average Loss: 4.121, avg. samples / sec: 54831.47
Iteration:   3180, Loss function: 4.730, Average Loss: 4.143, avg. samples / sec: 54811.66
Iteration:   3180, Loss function: 2.030, Average Loss: 4.116, avg. samples / sec: 54801.73
Iteration:   3180, Loss function: 4.086, Average Loss: 4.137, avg. samples / sec: 54764.82
Iteration:   3180, Loss function: 3.672, Average Loss: 4.153, avg. samples / sec: 54585.88
Iteration:   3180, Loss function: 4.313, Average Loss: 4.124, avg. samples / sec: 54797.55
Iteration:   3180, Loss function: 3.494, Average Loss: 4.132, avg. samples / sec: 54814.99
Iteration:   3180, Loss function: 3.991, Average Loss: 4.123, avg. samples / sec: 54793.74
Iteration:   3180, Loss function: 2.989, Average Loss: 4.102, avg. samples / sec: 54745.38
Iteration:   3180, Loss function: 3.227, Average Loss: 4.141, avg. samples / sec: 54836.04
Iteration:   3180, Loss function: 3.163, Average Loss: 4.126, avg. samples / sec: 54491.57
Iteration:   3180, Loss function: 2.902, Average Loss: 4.129, avg. samples / sec: 54845.47
Iteration:   3180, Loss function: 5.824, Average Loss: 4.124, avg. samples / sec: 54519.17
Iteration:   3200, Loss function: 3.519, Average Loss: 4.141, avg. samples / sec: 55104.27
Iteration:   3200, Loss function: 3.046, Average Loss: 4.104, avg. samples / sec: 55080.94
Iteration:   3200, Loss function: 3.443, Average Loss: 4.102, avg. samples / sec: 55162.01
Iteration:   3200, Loss function: 3.578, Average Loss: 4.113, avg. samples / sec: 55386.91
Iteration:   3200, Loss function: 2.647, Average Loss: 4.105, avg. samples / sec: 55092.29
Iteration:   3200, Loss function: 3.657, Average Loss: 4.126, avg. samples / sec: 55138.46
Iteration:   3200, Loss function: 2.985, Average Loss: 4.103, avg. samples / sec: 55128.95
Iteration:   3200, Loss function: 3.622, Average Loss: 4.100, avg. samples / sec: 55067.47
Iteration:   3200, Loss function: 4.720, Average Loss: 4.118, avg. samples / sec: 55354.69
Iteration:   3200, Loss function: 3.833, Average Loss: 4.121, avg. samples / sec: 55007.09
Iteration:   3200, Loss function: 3.024, Average Loss: 4.097, avg. samples / sec: 55065.73
Iteration:   3200, Loss function: 2.858, Average Loss: 4.114, avg. samples / sec: 55141.18
Iteration:   3200, Loss function: 3.393, Average Loss: 4.124, avg. samples / sec: 55054.39
Iteration:   3200, Loss function: 3.706, Average Loss: 4.095, avg. samples / sec: 55024.06
Iteration:   3200, Loss function: 4.355, Average Loss: 4.124, avg. samples / sec: 55048.28
Iteration:   3200, Loss function: 3.741, Average Loss: 4.107, avg. samples / sec: 55008.96
Iteration:   3200, Loss function: 4.123, Average Loss: 4.078, avg. samples / sec: 54864.28
Iteration:   3200, Loss function: 2.476, Average Loss: 4.122, avg. samples / sec: 55096.47
Iteration:   3200, Loss function: 3.697, Average Loss: 4.110, avg. samples / sec: 55028.06
Iteration:   3200, Loss function: 2.913, Average Loss: 4.135, avg. samples / sec: 55067.94
Iteration:   3200, Loss function: 4.129, Average Loss: 4.105, avg. samples / sec: 55080.71
Iteration:   3200, Loss function: 4.058, Average Loss: 4.114, avg. samples / sec: 55062.28
Iteration:   3200, Loss function: 3.761, Average Loss: 4.131, avg. samples / sec: 55059.45
Iteration:   3200, Loss function: 3.087, Average Loss: 4.090, avg. samples / sec: 55102.89
Iteration:   3200, Loss function: 3.399, Average Loss: 4.116, avg. samples / sec: 55048.89
Iteration:   3200, Loss function: 2.882, Average Loss: 4.136, avg. samples / sec: 55042.59
Iteration:   3200, Loss function: 4.271, Average Loss: 4.122, avg. samples / sec: 55046.39
Iteration:   3200, Loss function: 2.504, Average Loss: 4.117, avg. samples / sec: 55083.05
Iteration:   3200, Loss function: 3.404, Average Loss: 4.132, avg. samples / sec: 55074.79
Iteration:   3200, Loss function: 3.924, Average Loss: 4.109, avg. samples / sec: 55042.01
:::MLL 1558640130.759 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558640130.760 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 3.446, Average Loss: 4.093, avg. samples / sec: 54912.72
Iteration:   3220, Loss function: 2.540, Average Loss: 4.130, avg. samples / sec: 54719.53
Iteration:   3220, Loss function: 3.749, Average Loss: 4.091, avg. samples / sec: 54837.25
Iteration:   3220, Loss function: 4.012, Average Loss: 4.108, avg. samples / sec: 54852.00
Iteration:   3220, Loss function: 3.584, Average Loss: 4.113, avg. samples / sec: 54789.86
Iteration:   3220, Loss function: 2.816, Average Loss: 4.063, avg. samples / sec: 54980.10
Iteration:   3220, Loss function: 2.128, Average Loss: 4.104, avg. samples / sec: 54738.59
Iteration:   3220, Loss function: 4.940, Average Loss: 4.093, avg. samples / sec: 54691.56
Iteration:   3220, Loss function: 3.994, Average Loss: 4.087, avg. samples / sec: 54736.30
Iteration:   3220, Loss function: 3.714, Average Loss: 4.108, avg. samples / sec: 54721.23
Iteration:   3220, Loss function: 4.723, Average Loss: 4.104, avg. samples / sec: 54712.50
Iteration:   3220, Loss function: 4.191, Average Loss: 4.108, avg. samples / sec: 54732.41
Iteration:   3220, Loss function: 3.134, Average Loss: 4.094, avg. samples / sec: 54732.90
Iteration:   3220, Loss function: 2.558, Average Loss: 4.083, avg. samples / sec: 54703.92
Iteration:   3220, Loss function: 2.712, Average Loss: 4.085, avg. samples / sec: 54619.37
Iteration:   3220, Loss function: 3.717, Average Loss: 4.099, avg. samples / sec: 54857.23
Iteration:   3220, Loss function: 2.957, Average Loss: 4.126, avg. samples / sec: 54830.43
Iteration:   3220, Loss function: 3.509, Average Loss: 4.106, avg. samples / sec: 54781.45
Iteration:   3220, Loss function: 3.000, Average Loss: 4.107, avg. samples / sec: 54725.27
Iteration:   3220, Loss function: 3.515, Average Loss: 4.074, avg. samples / sec: 54745.76
Iteration:   3220, Loss function: 3.306, Average Loss: 4.121, avg. samples / sec: 54768.16
Iteration:   3220, Loss function: 2.579, Average Loss: 4.092, avg. samples / sec: 54406.86
Iteration:   3220, Loss function: 4.306, Average Loss: 4.106, avg. samples / sec: 54718.25
Iteration:   3220, Loss function: 4.188, Average Loss: 4.103, avg. samples / sec: 54700.88
Iteration:   3220, Loss function: 3.027, Average Loss: 4.089, avg. samples / sec: 54556.74
Iteration:   3220, Loss function: 3.467, Average Loss: 4.113, avg. samples / sec: 54099.57
Iteration:   3220, Loss function: 3.824, Average Loss: 4.129, avg. samples / sec: 53673.51
Iteration:   3220, Loss function: 3.111, Average Loss: 4.110, avg. samples / sec: 53413.80
Iteration:   3220, Loss function: 3.548, Average Loss: 4.096, avg. samples / sec: 53587.00
Iteration:   3220, Loss function: 3.299, Average Loss: 4.117, avg. samples / sec: 53592.77
Iteration:   3240, Loss function: 3.355, Average Loss: 4.115, avg. samples / sec: 54338.57
Iteration:   3240, Loss function: 3.102, Average Loss: 4.094, avg. samples / sec: 54364.38
Iteration:   3240, Loss function: 4.007, Average Loss: 4.051, avg. samples / sec: 54388.11
Iteration:   3240, Loss function: 3.027, Average Loss: 4.103, avg. samples / sec: 54348.80
Iteration:   3240, Loss function: 3.115, Average Loss: 4.075, avg. samples / sec: 54427.51
Iteration:   3240, Loss function: 5.058, Average Loss: 4.096, avg. samples / sec: 54379.73
Iteration:   3240, Loss function: 4.263, Average Loss: 4.078, avg. samples / sec: 54289.53
Iteration:   3240, Loss function: 3.867, Average Loss: 4.094, avg. samples / sec: 54433.34
Iteration:   3240, Loss function: 2.898, Average Loss: 4.079, avg. samples / sec: 54195.66
Iteration:   3240, Loss function: 4.367, Average Loss: 4.072, avg. samples / sec: 54468.62
Iteration:   3240, Loss function: 3.301, Average Loss: 4.079, avg. samples / sec: 54454.87
Iteration:   3240, Loss function: 4.986, Average Loss: 4.074, avg. samples / sec: 54452.10
Iteration:   3240, Loss function: 4.759, Average Loss: 4.105, avg. samples / sec: 54418.16
Iteration:   3240, Loss function: 2.983, Average Loss: 4.096, avg. samples / sec: 54376.04
Iteration:   3240, Loss function: 2.221, Average Loss: 4.075, avg. samples / sec: 54478.62
Iteration:   3240, Loss function: 3.487, Average Loss: 4.105, avg. samples / sec: 55140.66
Iteration:   3240, Loss function: 1.981, Average Loss: 4.096, avg. samples / sec: 55601.26
Iteration:   3240, Loss function: 3.995, Average Loss: 4.091, avg. samples / sec: 54427.13
Iteration:   3240, Loss function: 2.563, Average Loss: 4.075, avg. samples / sec: 54598.88
Iteration:   3240, Loss function: 3.314, Average Loss: 4.114, avg. samples / sec: 54340.96
Iteration:   3240, Loss function: 3.701, Average Loss: 4.085, avg. samples / sec: 55578.89
Iteration:   3240, Loss function: 2.436, Average Loss: 4.085, avg. samples / sec: 54278.24
Iteration:   3240, Loss function: 3.232, Average Loss: 4.062, avg. samples / sec: 54384.75
Iteration:   3240, Loss function: 2.544, Average Loss: 4.094, avg. samples / sec: 54377.95
Iteration:   3240, Loss function: 3.120, Average Loss: 4.109, avg. samples / sec: 54397.05
Iteration:   3240, Loss function: 3.340, Average Loss: 4.117, avg. samples / sec: 55456.37
Iteration:   3240, Loss function: 3.343, Average Loss: 4.092, avg. samples / sec: 54468.07
Iteration:   3240, Loss function: 2.924, Average Loss: 4.103, avg. samples / sec: 55606.30
Iteration:   3240, Loss function: 3.441, Average Loss: 4.079, avg. samples / sec: 54092.01
Iteration:   3240, Loss function: 3.099, Average Loss: 4.095, avg. samples / sec: 54340.29
Iteration:   3260, Loss function: 3.078, Average Loss: 4.107, avg. samples / sec: 55000.55
Iteration:   3260, Loss function: 3.730, Average Loss: 4.042, avg. samples / sec: 55033.77
Iteration:   3260, Loss function: 4.109, Average Loss: 4.096, avg. samples / sec: 54933.23
Iteration:   3260, Loss function: 2.011, Average Loss: 4.080, avg. samples / sec: 54881.07
Iteration:   3260, Loss function: 3.785, Average Loss: 4.090, avg. samples / sec: 54941.49
Iteration:   3260, Loss function: 4.301, Average Loss: 4.066, avg. samples / sec: 54953.81
Iteration:   3260, Loss function: 2.831, Average Loss: 4.068, avg. samples / sec: 54930.08
Iteration:   3260, Loss function: 3.185, Average Loss: 4.083, avg. samples / sec: 54914.09
Iteration:   3260, Loss function: 3.714, Average Loss: 4.081, avg. samples / sec: 54968.95
Iteration:   3260, Loss function: 3.446, Average Loss: 4.068, avg. samples / sec: 55218.27
Iteration:   3260, Loss function: 3.364, Average Loss: 4.090, avg. samples / sec: 54929.40
Iteration:   3260, Loss function: 3.615, Average Loss: 4.064, avg. samples / sec: 54877.55
Iteration:   3260, Loss function: 3.682, Average Loss: 4.069, avg. samples / sec: 54910.84
Iteration:   3260, Loss function: 2.959, Average Loss: 4.062, avg. samples / sec: 54906.77
Iteration:   3260, Loss function: 3.510, Average Loss: 4.067, avg. samples / sec: 54876.65
Iteration:   3260, Loss function: 3.457, Average Loss: 4.075, avg. samples / sec: 54940.38
Iteration:   3260, Loss function: 3.014, Average Loss: 4.066, avg. samples / sec: 54887.64
Iteration:   3260, Loss function: 2.762, Average Loss: 4.087, avg. samples / sec: 54890.84
Iteration:   3260, Loss function: 3.906, Average Loss: 4.099, avg. samples / sec: 54896.32
Iteration:   3260, Loss function: 3.172, Average Loss: 4.065, avg. samples / sec: 54892.19
Iteration:   3260, Loss function: 3.798, Average Loss: 4.052, avg. samples / sec: 54926.38
Iteration:   3260, Loss function: 3.897, Average Loss: 4.106, avg. samples / sec: 54926.53
Iteration:   3260, Loss function: 3.363, Average Loss: 4.073, avg. samples / sec: 54898.54
Iteration:   3260, Loss function: 5.307, Average Loss: 4.097, avg. samples / sec: 54832.00
Iteration:   3260, Loss function: 4.964, Average Loss: 4.073, avg. samples / sec: 54893.28
Iteration:   3260, Loss function: 4.085, Average Loss: 4.100, avg. samples / sec: 54894.46
Iteration:   3260, Loss function: 4.077, Average Loss: 4.087, avg. samples / sec: 54885.20
Iteration:   3260, Loss function: 3.592, Average Loss: 4.080, avg. samples / sec: 54871.56
Iteration:   3260, Loss function: 2.858, Average Loss: 4.093, avg. samples / sec: 54864.43
Iteration:   3260, Loss function: 3.376, Average Loss: 4.083, avg. samples / sec: 54947.86
Iteration:   3280, Loss function: 3.626, Average Loss: 4.101, avg. samples / sec: 54967.19
Iteration:   3280, Loss function: 3.897, Average Loss: 4.035, avg. samples / sec: 55006.62
Iteration:   3280, Loss function: 2.295, Average Loss: 4.069, avg. samples / sec: 55037.49
Iteration:   3280, Loss function: 2.829, Average Loss: 4.055, avg. samples / sec: 55105.28
Iteration:   3280, Loss function: 3.879, Average Loss: 4.057, avg. samples / sec: 55034.95
Iteration:   3280, Loss function: 3.644, Average Loss: 4.083, avg. samples / sec: 55008.79
Iteration:   3280, Loss function: 3.830, Average Loss: 4.072, avg. samples / sec: 55048.89
Iteration:   3280, Loss function: 2.554, Average Loss: 4.054, avg. samples / sec: 55051.79
Iteration:   3280, Loss function: 5.631, Average Loss: 4.078, avg. samples / sec: 55054.78
Iteration:   3280, Loss function: 2.956, Average Loss: 4.067, avg. samples / sec: 55059.04
Iteration:   3280, Loss function: 3.279, Average Loss: 4.076, avg. samples / sec: 55001.77
Iteration:   3280, Loss function: 3.992, Average Loss: 4.070, avg. samples / sec: 55034.53
Iteration:   3280, Loss function: 4.273, Average Loss: 4.055, avg. samples / sec: 55052.13
Iteration:   3280, Loss function: 4.311, Average Loss: 4.057, avg. samples / sec: 55013.41
Iteration:   3280, Loss function: 3.889, Average Loss: 4.051, avg. samples / sec: 55030.83
Iteration:   3280, Loss function: 3.408, Average Loss: 4.056, avg. samples / sec: 55075.69
Iteration:   3280, Loss function: 4.124, Average Loss: 4.080, avg. samples / sec: 55116.34
Iteration:   3280, Loss function: 3.537, Average Loss: 4.062, avg. samples / sec: 55001.38
Iteration:   3280, Loss function: 2.215, Average Loss: 4.091, avg. samples / sec: 55065.32
Iteration:   3280, Loss function: 3.229, Average Loss: 4.038, avg. samples / sec: 55061.64
Iteration:   3280, Loss function: 3.509, Average Loss: 4.063, avg. samples / sec: 55081.42
Iteration:   3280, Loss function: 5.726, Average Loss: 4.088, avg. samples / sec: 55063.66
Iteration:   3280, Loss function: 2.111, Average Loss: 4.085, avg. samples / sec: 55028.94
Iteration:   3280, Loss function: 2.924, Average Loss: 4.065, avg. samples / sec: 55083.59
Iteration:   3280, Loss function: 2.829, Average Loss: 4.061, avg. samples / sec: 55034.22
Iteration:   3280, Loss function: 4.082, Average Loss: 4.081, avg. samples / sec: 55016.18
Iteration:   3280, Loss function: 3.457, Average Loss: 4.086, avg. samples / sec: 55052.86
Iteration:   3280, Loss function: 3.634, Average Loss: 4.078, avg. samples / sec: 55058.05
Iteration:   3280, Loss function: 3.579, Average Loss: 4.069, avg. samples / sec: 55053.57
Iteration:   3280, Loss function: 2.963, Average Loss: 4.058, avg. samples / sec: 54917.77
:::MLL 1558640132.908 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558640132.908 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 2.714, Average Loss: 4.025, avg. samples / sec: 54966.33
Iteration:   3300, Loss function: 3.516, Average Loss: 4.093, avg. samples / sec: 54919.68
Iteration:   3300, Loss function: 3.634, Average Loss: 4.070, avg. samples / sec: 54923.04
Iteration:   3300, Loss function: 3.294, Average Loss: 4.056, avg. samples / sec: 54878.53
Iteration:   3300, Loss function: 3.794, Average Loss: 4.045, avg. samples / sec: 54866.48
Iteration:   3300, Loss function: 2.942, Average Loss: 4.068, avg. samples / sec: 54888.77
Iteration:   3300, Loss function: 2.519, Average Loss: 4.044, avg. samples / sec: 54868.15
Iteration:   3300, Loss function: 3.683, Average Loss: 4.059, avg. samples / sec: 54861.38
Iteration:   3300, Loss function: 4.455, Average Loss: 4.049, avg. samples / sec: 55195.75
Iteration:   3300, Loss function: 2.409, Average Loss: 4.066, avg. samples / sec: 54853.52
Iteration:   3300, Loss function: 2.883, Average Loss: 4.047, avg. samples / sec: 54864.69
Iteration:   3300, Loss function: 3.216, Average Loss: 4.043, avg. samples / sec: 54843.80
Iteration:   3300, Loss function: 3.390, Average Loss: 4.048, avg. samples / sec: 54854.20
Iteration:   3300, Loss function: 4.176, Average Loss: 4.056, avg. samples / sec: 54845.51
Iteration:   3300, Loss function: 3.486, Average Loss: 4.058, avg. samples / sec: 54838.55
Iteration:   3300, Loss function: 2.551, Average Loss: 4.043, avg. samples / sec: 54862.19
Iteration:   3300, Loss function: 3.321, Average Loss: 4.075, avg. samples / sec: 54890.33
Iteration:   3300, Loss function: 3.501, Average Loss: 4.070, avg. samples / sec: 54907.05
Iteration:   3300, Loss function: 2.988, Average Loss: 4.050, avg. samples / sec: 54898.15
Iteration:   3300, Loss function: 3.901, Average Loss: 4.056, avg. samples / sec: 54866.59
Iteration:   3300, Loss function: 3.178, Average Loss: 4.023, avg. samples / sec: 54856.51
Iteration:   3300, Loss function: 3.233, Average Loss: 4.046, avg. samples / sec: 54831.53
Iteration:   3300, Loss function: 5.173, Average Loss: 4.081, avg. samples / sec: 54872.01
Iteration:   3300, Loss function: 3.964, Average Loss: 4.084, avg. samples / sec: 54851.17
Iteration:   3300, Loss function: 4.363, Average Loss: 4.053, avg. samples / sec: 54857.83
Iteration:   3300, Loss function: 3.192, Average Loss: 4.065, avg. samples / sec: 54820.36
Iteration:   3300, Loss function: 3.308, Average Loss: 4.066, avg. samples / sec: 54904.70
Iteration:   3300, Loss function: 2.867, Average Loss: 4.055, avg. samples / sec: 54822.81
Iteration:   3300, Loss function: 4.132, Average Loss: 4.076, avg. samples / sec: 54846.77
Iteration:   3300, Loss function: 2.999, Average Loss: 4.055, avg. samples / sec: 54907.82
Iteration:   3320, Loss function: 3.069, Average Loss: 4.080, avg. samples / sec: 54895.93
Iteration:   3320, Loss function: 4.571, Average Loss: 4.017, avg. samples / sec: 54871.61
Iteration:   3320, Loss function: 2.295, Average Loss: 4.055, avg. samples / sec: 55037.04
Iteration:   3320, Loss function: 3.847, Average Loss: 4.042, avg. samples / sec: 54999.92
Iteration:   3320, Loss function: 2.872, Average Loss: 4.031, avg. samples / sec: 55011.75
Iteration:   3320, Loss function: 3.480, Average Loss: 4.031, avg. samples / sec: 54973.77
Iteration:   3320, Loss function: 3.398, Average Loss: 4.036, avg. samples / sec: 54976.22
Iteration:   3320, Loss function: 2.162, Average Loss: 4.034, avg. samples / sec: 54925.52
Iteration:   3320, Loss function: 4.568, Average Loss: 4.047, avg. samples / sec: 54963.33
Iteration:   3320, Loss function: 3.542, Average Loss: 4.044, avg. samples / sec: 54966.31
Iteration:   3320, Loss function: 3.226, Average Loss: 4.042, avg. samples / sec: 54941.41
Iteration:   3320, Loss function: 2.831, Average Loss: 4.049, avg. samples / sec: 54921.77
Iteration:   3320, Loss function: 4.055, Average Loss: 4.064, avg. samples / sec: 54821.70
Iteration:   3320, Loss function: 3.842, Average Loss: 4.037, avg. samples / sec: 54867.74
Iteration:   3320, Loss function: 3.003, Average Loss: 4.064, avg. samples / sec: 54921.33
Iteration:   3320, Loss function: 4.409, Average Loss: 4.042, avg. samples / sec: 54729.58
Iteration:   3320, Loss function: 3.021, Average Loss: 4.046, avg. samples / sec: 54977.61
Iteration:   3320, Loss function: 2.900, Average Loss: 4.040, avg. samples / sec: 54962.09
Iteration:   3320, Loss function: 4.322, Average Loss: 4.064, avg. samples / sec: 54910.69
Iteration:   3320, Loss function: 4.103, Average Loss: 4.044, avg. samples / sec: 54907.12
Iteration:   3320, Loss function: 4.348, Average Loss: 4.044, avg. samples / sec: 54902.35
Iteration:   3320, Loss function: 3.586, Average Loss: 4.072, avg. samples / sec: 54920.32
Iteration:   3320, Loss function: 3.697, Average Loss: 4.009, avg. samples / sec: 54901.51
Iteration:   3320, Loss function: 3.426, Average Loss: 4.063, avg. samples / sec: 54929.76
Iteration:   3320, Loss function: 4.108, Average Loss: 4.032, avg. samples / sec: 54887.42
Iteration:   3320, Loss function: 3.051, Average Loss: 4.071, avg. samples / sec: 54905.98
Iteration:   3320, Loss function: 3.645, Average Loss: 4.050, avg. samples / sec: 54641.81
Iteration:   3320, Loss function: 3.329, Average Loss: 4.054, avg. samples / sec: 54899.27
Iteration:   3320, Loss function: 2.929, Average Loss: 4.055, avg. samples / sec: 54867.48
Iteration:   3320, Loss function: 2.375, Average Loss: 4.037, avg. samples / sec: 54896.70
Iteration:   3340, Loss function: 4.249, Average Loss: 4.008, avg. samples / sec: 54855.16
Iteration:   3340, Loss function: 4.218, Average Loss: 4.075, avg. samples / sec: 54791.86
Iteration:   3340, Loss function: 3.421, Average Loss: 4.031, avg. samples / sec: 54834.54
Iteration:   3340, Loss function: 2.458, Average Loss: 4.059, avg. samples / sec: 54954.20
Iteration:   3340, Loss function: 1.928, Average Loss: 4.048, avg. samples / sec: 54795.95
Iteration:   3340, Loss function: 3.645, Average Loss: 4.018, avg. samples / sec: 54882.29
Iteration:   3340, Loss function: 2.742, Average Loss: 4.039, avg. samples / sec: 55174.06
Iteration:   3340, Loss function: 3.871, Average Loss: 4.025, avg. samples / sec: 54847.41
Iteration:   3340, Loss function: 2.650, Average Loss: 4.019, avg. samples / sec: 54851.96
Iteration:   3340, Loss function: 3.105, Average Loss: 4.020, avg. samples / sec: 54920.06
Iteration:   3340, Loss function: 2.978, Average Loss: 4.021, avg. samples / sec: 54829.70
Iteration:   3340, Loss function: 3.002, Average Loss: 4.026, avg. samples / sec: 54874.66
Iteration:   3340, Loss function: 3.793, Average Loss: 4.035, avg. samples / sec: 54883.10
Iteration:   3340, Loss function: 3.123, Average Loss: 4.031, avg. samples / sec: 54852.96
Iteration:   3340, Loss function: 3.725, Average Loss: 4.034, avg. samples / sec: 54829.17
Iteration:   3340, Loss function: 2.568, Average Loss: 4.035, avg. samples / sec: 54941.37
Iteration:   3340, Loss function: 2.900, Average Loss: 4.038, avg. samples / sec: 54928.37
Iteration:   3340, Loss function: 3.221, Average Loss: 3.997, avg. samples / sec: 54937.43
Iteration:   3340, Loss function: 3.555, Average Loss: 4.047, avg. samples / sec: 54878.19
Iteration:   3340, Loss function: 3.327, Average Loss: 4.033, avg. samples / sec: 54860.20
Iteration:   3340, Loss function: 2.820, Average Loss: 4.060, avg. samples / sec: 54899.65
Iteration:   3340, Loss function: 3.414, Average Loss: 4.062, avg. samples / sec: 54922.18
Iteration:   3340, Loss function: 3.224, Average Loss: 4.026, avg. samples / sec: 54870.03
Iteration:   3340, Loss function: 4.928, Average Loss: 4.022, avg. samples / sec: 54908.72
Iteration:   3340, Loss function: 3.278, Average Loss: 4.035, avg. samples / sec: 54837.36
Iteration:   3340, Loss function: 3.748, Average Loss: 4.051, avg. samples / sec: 54889.26
Iteration:   3340, Loss function: 3.561, Average Loss: 4.045, avg. samples / sec: 54925.73
Iteration:   3340, Loss function: 4.074, Average Loss: 4.040, avg. samples / sec: 54883.77
Iteration:   3340, Loss function: 3.144, Average Loss: 4.025, avg. samples / sec: 54870.28
Iteration:   3340, Loss function: 3.430, Average Loss: 4.049, avg. samples / sec: 54716.02
:::MLL 1558640135.051 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558640135.052 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 2.815, Average Loss: 4.060, avg. samples / sec: 54762.40
Iteration:   3360, Loss function: 3.847, Average Loss: 3.998, avg. samples / sec: 54634.12
Iteration:   3360, Loss function: 4.216, Average Loss: 4.023, avg. samples / sec: 54752.08
Iteration:   3360, Loss function: 4.502, Average Loss: 4.049, avg. samples / sec: 54685.07
Iteration:   3360, Loss function: 3.806, Average Loss: 4.037, avg. samples / sec: 54665.51
Iteration:   3360, Loss function: 3.590, Average Loss: 4.021, avg. samples / sec: 54637.81
Iteration:   3360, Loss function: 2.605, Average Loss: 4.004, avg. samples / sec: 54704.04
Iteration:   3360, Loss function: 3.672, Average Loss: 4.022, avg. samples / sec: 54703.47
Iteration:   3360, Loss function: 3.676, Average Loss: 4.009, avg. samples / sec: 54617.80
Iteration:   3360, Loss function: 2.126, Average Loss: 4.018, avg. samples / sec: 54648.02
Iteration:   3360, Loss function: 3.611, Average Loss: 4.029, avg. samples / sec: 54615.98
Iteration:   3360, Loss function: 2.723, Average Loss: 4.007, avg. samples / sec: 54632.13
Iteration:   3360, Loss function: 3.932, Average Loss: 4.014, avg. samples / sec: 54619.60
Iteration:   3360, Loss function: 3.078, Average Loss: 4.020, avg. samples / sec: 54602.61
Iteration:   3360, Loss function: 3.624, Average Loss: 4.033, avg. samples / sec: 54773.36
Iteration:   3360, Loss function: 2.991, Average Loss: 4.025, avg. samples / sec: 54570.24
Iteration:   3360, Loss function: 3.229, Average Loss: 4.028, avg. samples / sec: 54720.72
Iteration:   3360, Loss function: 3.245, Average Loss: 4.047, avg. samples / sec: 54725.67
Iteration:   3360, Loss function: 4.351, Average Loss: 4.037, avg. samples / sec: 54876.84
Iteration:   3360, Loss function: 2.393, Average Loss: 4.025, avg. samples / sec: 54610.60
Iteration:   3360, Loss function: 3.013, Average Loss: 4.050, avg. samples / sec: 54643.68
Iteration:   3360, Loss function: 3.437, Average Loss: 4.022, avg. samples / sec: 54626.59
Iteration:   3360, Loss function: 3.137, Average Loss: 4.036, avg. samples / sec: 54665.57
Iteration:   3360, Loss function: 3.593, Average Loss: 4.006, avg. samples / sec: 54626.16
Iteration:   3360, Loss function: 3.633, Average Loss: 4.015, avg. samples / sec: 54609.25
Iteration:   3360, Loss function: 2.958, Average Loss: 3.988, avg. samples / sec: 54574.12
Iteration:   3360, Loss function: 3.224, Average Loss: 4.021, avg. samples / sec: 54615.62
Iteration:   3360, Loss function: 3.062, Average Loss: 4.012, avg. samples / sec: 54658.70
Iteration:   3360, Loss function: 4.722, Average Loss: 4.026, avg. samples / sec: 54592.75
Iteration:   3360, Loss function: 4.135, Average Loss: 4.033, avg. samples / sec: 54574.36
Iteration:   3380, Loss function: 3.638, Average Loss: 3.990, avg. samples / sec: 55046.28
Iteration:   3380, Loss function: 3.607, Average Loss: 4.048, avg. samples / sec: 54966.54
Iteration:   3380, Loss function: 3.109, Average Loss: 4.005, avg. samples / sec: 54977.80
Iteration:   3380, Loss function: 3.171, Average Loss: 3.993, avg. samples / sec: 55016.43
Iteration:   3380, Loss function: 4.674, Average Loss: 4.023, avg. samples / sec: 54932.84
Iteration:   3380, Loss function: 2.376, Average Loss: 4.014, avg. samples / sec: 54965.94
Iteration:   3380, Loss function: 3.616, Average Loss: 4.040, avg. samples / sec: 54904.96
Iteration:   3380, Loss function: 3.577, Average Loss: 3.990, avg. samples / sec: 54923.74
Iteration:   3380, Loss function: 4.313, Average Loss: 4.005, avg. samples / sec: 55009.35
Iteration:   3380, Loss function: 3.097, Average Loss: 4.013, avg. samples / sec: 55034.16
Iteration:   3380, Loss function: 2.876, Average Loss: 4.019, avg. samples / sec: 54963.07
Iteration:   3380, Loss function: 3.043, Average Loss: 4.011, avg. samples / sec: 54832.67
Iteration:   3380, Loss function: 3.934, Average Loss: 4.011, avg. samples / sec: 54996.96
Iteration:   3380, Loss function: 2.846, Average Loss: 4.013, avg. samples / sec: 55180.09
Iteration:   3380, Loss function: 2.978, Average Loss: 4.004, avg. samples / sec: 54935.80
Iteration:   3380, Loss function: 3.020, Average Loss: 4.013, avg. samples / sec: 54991.49
Iteration:   3380, Loss function: 2.101, Average Loss: 4.017, avg. samples / sec: 54844.53
Iteration:   3380, Loss function: 3.487, Average Loss: 3.979, avg. samples / sec: 55039.83
Iteration:   3380, Loss function: 3.062, Average Loss: 4.013, avg. samples / sec: 54880.03
Iteration:   3380, Loss function: 3.521, Average Loss: 4.034, avg. samples / sec: 54884.17
Iteration:   3380, Loss function: 2.686, Average Loss: 4.025, avg. samples / sec: 54885.86
Iteration:   3380, Loss function: 4.030, Average Loss: 4.005, avg. samples / sec: 54985.44
Iteration:   3380, Loss function: 2.882, Average Loss: 4.023, avg. samples / sec: 54955.57
Iteration:   3380, Loss function: 4.057, Average Loss: 4.034, avg. samples / sec: 54942.48
Iteration:   3380, Loss function: 3.166, Average Loss: 4.020, avg. samples / sec: 55042.61
Iteration:   3380, Loss function: 2.368, Average Loss: 3.993, avg. samples / sec: 54962.69
Iteration:   3380, Loss function: 3.724, Average Loss: 4.013, avg. samples / sec: 55035.90
Iteration:   3380, Loss function: 2.577, Average Loss: 4.016, avg. samples / sec: 54980.29
Iteration:   3380, Loss function: 4.551, Average Loss: 4.003, avg. samples / sec: 54659.72
Iteration:   3380, Loss function: 2.137, Average Loss: 4.003, avg. samples / sec: 54946.14
Iteration:   3400, Loss function: 3.956, Average Loss: 3.982, avg. samples / sec: 54677.01
Iteration:   3400, Loss function: 4.386, Average Loss: 4.038, avg. samples / sec: 54649.04
Iteration:   3400, Loss function: 4.374, Average Loss: 4.029, avg. samples / sec: 54796.23
Iteration:   3400, Loss function: 3.347, Average Loss: 3.993, avg. samples / sec: 54690.33
Iteration:   3400, Loss function: 3.761, Average Loss: 3.979, avg. samples / sec: 54703.47
Iteration:   3400, Loss function: 3.015, Average Loss: 3.992, avg. samples / sec: 55004.67
Iteration:   3400, Loss function: 3.633, Average Loss: 4.004, avg. samples / sec: 54733.70
Iteration:   3400, Loss function: 4.264, Average Loss: 3.983, avg. samples / sec: 54673.21
Iteration:   3400, Loss function: 3.275, Average Loss: 3.994, avg. samples / sec: 54727.65
Iteration:   3400, Loss function: 3.298, Average Loss: 4.008, avg. samples / sec: 54709.78
Iteration:   3400, Loss function: 2.445, Average Loss: 3.991, avg. samples / sec: 54678.83
Iteration:   3400, Loss function: 3.760, Average Loss: 4.012, avg. samples / sec: 54650.01
Iteration:   3400, Loss function: 3.337, Average Loss: 4.002, avg. samples / sec: 54639.27
Iteration:   3400, Loss function: 3.872, Average Loss: 4.002, avg. samples / sec: 54684.24
Iteration:   3400, Loss function: 2.167, Average Loss: 3.997, avg. samples / sec: 54638.70
Iteration:   3400, Loss function: 3.029, Average Loss: 4.002, avg. samples / sec: 54521.78
Iteration:   3400, Loss function: 4.444, Average Loss: 4.004, avg. samples / sec: 54664.87
Iteration:   3400, Loss function: 3.787, Average Loss: 4.012, avg. samples / sec: 54713.41
Iteration:   3400, Loss function: 3.789, Average Loss: 3.999, avg. samples / sec: 54671.98
Iteration:   3400, Loss function: 3.993, Average Loss: 4.021, avg. samples / sec: 54693.30
Iteration:   3400, Loss function: 3.814, Average Loss: 4.000, avg. samples / sec: 54646.86
Iteration:   3400, Loss function: 2.609, Average Loss: 3.981, avg. samples / sec: 54696.42
Iteration:   3400, Loss function: 3.688, Average Loss: 4.005, avg. samples / sec: 54694.62
Iteration:   3400, Loss function: 3.734, Average Loss: 4.009, avg. samples / sec: 54666.89
Iteration:   3400, Loss function: 4.374, Average Loss: 3.999, avg. samples / sec: 54669.37
Iteration:   3400, Loss function: 4.151, Average Loss: 4.011, avg. samples / sec: 54684.30
Iteration:   3400, Loss function: 4.046, Average Loss: 3.970, avg. samples / sec: 54590.30
Iteration:   3400, Loss function: 3.876, Average Loss: 3.992, avg. samples / sec: 54723.50
Iteration:   3400, Loss function: 4.310, Average Loss: 4.026, avg. samples / sec: 54643.97
Iteration:   3400, Loss function: 2.801, Average Loss: 4.003, avg. samples / sec: 54655.44
Iteration:   3420, Loss function: 2.620, Average Loss: 3.972, avg. samples / sec: 54846.92
Iteration:   3420, Loss function: 2.924, Average Loss: 4.024, avg. samples / sec: 54833.11
Iteration:   3420, Loss function: 3.446, Average Loss: 3.981, avg. samples / sec: 54899.18
Iteration:   3420, Loss function: 2.556, Average Loss: 4.013, avg. samples / sec: 54834.05
Iteration:   3420, Loss function: 2.358, Average Loss: 3.970, avg. samples / sec: 54934.68
Iteration:   3420, Loss function: 3.455, Average Loss: 3.969, avg. samples / sec: 54904.72
Iteration:   3420, Loss function: 4.298, Average Loss: 3.983, avg. samples / sec: 54898.26
Iteration:   3420, Loss function: 3.254, Average Loss: 3.997, avg. samples / sec: 54918.82
Iteration:   3420, Loss function: 3.663, Average Loss: 3.982, avg. samples / sec: 54903.93
Iteration:   3420, Loss function: 3.240, Average Loss: 3.991, avg. samples / sec: 54885.45
Iteration:   3420, Loss function: 3.044, Average Loss: 3.982, avg. samples / sec: 54898.20
Iteration:   3420, Loss function: 2.577, Average Loss: 3.997, avg. samples / sec: 54863.32
Iteration:   3420, Loss function: 3.879, Average Loss: 3.993, avg. samples / sec: 54887.72
Iteration:   3420, Loss function: 2.518, Average Loss: 3.986, avg. samples / sec: 54906.07
Iteration:   3420, Loss function: 3.116, Average Loss: 3.991, avg. samples / sec: 54840.28
Iteration:   3420, Loss function: 3.053, Average Loss: 3.995, avg. samples / sec: 54926.14
Iteration:   3420, Loss function: 3.876, Average Loss: 3.992, avg. samples / sec: 54931.58
Iteration:   3420, Loss function: 3.855, Average Loss: 4.008, avg. samples / sec: 54914.18
Iteration:   3420, Loss function: 3.281, Average Loss: 3.961, avg. samples / sec: 54978.87
Iteration:   3420, Loss function: 2.412, Average Loss: 4.002, avg. samples / sec: 54890.97
Iteration:   3420, Loss function: 2.929, Average Loss: 3.992, avg. samples / sec: 54889.11
Iteration:   3420, Loss function: 3.679, Average Loss: 3.992, avg. samples / sec: 54905.83
Iteration:   3420, Loss function: 3.785, Average Loss: 3.999, avg. samples / sec: 54926.98
Iteration:   3420, Loss function: 3.758, Average Loss: 4.014, avg. samples / sec: 54956.75
Iteration:   3420, Loss function: 2.286, Average Loss: 3.973, avg. samples / sec: 54904.59
Iteration:   3420, Loss function: 3.921, Average Loss: 3.989, avg. samples / sec: 54911.76
Iteration:   3420, Loss function: 2.422, Average Loss: 3.988, avg. samples / sec: 54931.49
Iteration:   3420, Loss function: 3.794, Average Loss: 4.000, avg. samples / sec: 54882.61
Iteration:   3420, Loss function: 2.826, Average Loss: 3.989, avg. samples / sec: 54877.80
Iteration:   3420, Loss function: 2.900, Average Loss: 3.987, avg. samples / sec: 54902.18
:::MLL 1558640137.179 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=2.52s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22134
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38084
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22778
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05726
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23360
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09751
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.35959
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52129
Current AP: 0.22134 AP goal: 0.23000
:::MLL 1558640140.938 eval_accuracy: {"value": 0.22133697960361523, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558640141.005 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558640141.011 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558640141.012 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558640141.043 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558640141.044 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.977, Average Loss: 4.008, avg. samples / sec: 7529.69
Iteration:   3440, Loss function: 4.399, Average Loss: 4.005, avg. samples / sec: 7528.43
Iteration:   3440, Loss function: 5.234, Average Loss: 3.977, avg. samples / sec: 7534.58
Iteration:   3440, Loss function: 2.125, Average Loss: 3.967, avg. samples / sec: 7527.93
Iteration:   3440, Loss function: 3.008, Average Loss: 3.977, avg. samples / sec: 7528.53
Iteration:   3440, Loss function: 3.519, Average Loss: 3.988, avg. samples / sec: 7528.93
Iteration:   3440, Loss function: 2.578, Average Loss: 3.983, avg. samples / sec: 7528.79
Iteration:   3440, Loss function: 3.445, Average Loss: 3.980, avg. samples / sec: 7529.35
Iteration:   3440, Loss function: 3.812, Average Loss: 3.971, avg. samples / sec: 7529.77
Iteration:   3440, Loss function: 3.735, Average Loss: 3.958, avg. samples / sec: 7527.95
Iteration:   3440, Loss function: 2.924, Average Loss: 3.979, avg. samples / sec: 7529.81
Iteration:   3440, Loss function: 3.488, Average Loss: 3.977, avg. samples / sec: 7528.37
Iteration:   3440, Loss function: 3.021, Average Loss: 3.978, avg. samples / sec: 7528.54
Iteration:   3440, Loss function: 5.190, Average Loss: 3.974, avg. samples / sec: 7524.79
Iteration:   3440, Loss function: 3.771, Average Loss: 3.949, avg. samples / sec: 7528.98
Iteration:   3440, Loss function: 4.521, Average Loss: 3.979, avg. samples / sec: 7528.79
Iteration:   3440, Loss function: 4.050, Average Loss: 3.983, avg. samples / sec: 7527.85
Iteration:   3440, Loss function: 2.810, Average Loss: 3.990, avg. samples / sec: 7528.56
Iteration:   3440, Loss function: 2.347, Average Loss: 3.957, avg. samples / sec: 7521.59
Iteration:   3440, Loss function: 3.719, Average Loss: 3.982, avg. samples / sec: 7528.47
Iteration:   3440, Loss function: 3.708, Average Loss: 4.005, avg. samples / sec: 7528.94
Iteration:   3440, Loss function: 3.532, Average Loss: 3.997, avg. samples / sec: 7528.53
Iteration:   3440, Loss function: 4.934, Average Loss: 3.986, avg. samples / sec: 7528.61
Iteration:   3440, Loss function: 4.511, Average Loss: 3.960, avg. samples / sec: 7522.97
Iteration:   3440, Loss function: 2.738, Average Loss: 3.962, avg. samples / sec: 7528.58
Iteration:   3440, Loss function: 3.310, Average Loss: 3.981, avg. samples / sec: 7528.49
Iteration:   3440, Loss function: 2.855, Average Loss: 3.977, avg. samples / sec: 7528.60
Iteration:   3440, Loss function: 3.206, Average Loss: 3.975, avg. samples / sec: 7528.64
Iteration:   3440, Loss function: 3.196, Average Loss: 3.967, avg. samples / sec: 7522.77
Iteration:   3440, Loss function: 3.709, Average Loss: 3.992, avg. samples / sec: 7528.34
Iteration:   3460, Loss function: 3.894, Average Loss: 3.992, avg. samples / sec: 54772.70
Iteration:   3460, Loss function: 3.848, Average Loss: 3.976, avg. samples / sec: 54705.76
Iteration:   3460, Loss function: 2.635, Average Loss: 3.955, avg. samples / sec: 54621.50
Iteration:   3460, Loss function: 3.205, Average Loss: 3.948, avg. samples / sec: 54664.77
Iteration:   3460, Loss function: 3.225, Average Loss: 3.966, avg. samples / sec: 54696.70
Iteration:   3460, Loss function: 3.056, Average Loss: 3.968, avg. samples / sec: 54643.95
Iteration:   3460, Loss function: 2.281, Average Loss: 3.969, avg. samples / sec: 54585.52
Iteration:   3460, Loss function: 3.741, Average Loss: 3.971, avg. samples / sec: 54575.73
Iteration:   3460, Loss function: 4.657, Average Loss: 3.961, avg. samples / sec: 54591.14
Iteration:   3460, Loss function: 2.413, Average Loss: 4.002, avg. samples / sec: 54384.29
Iteration:   3460, Loss function: 3.850, Average Loss: 3.968, avg. samples / sec: 54655.16
Iteration:   3460, Loss function: 2.947, Average Loss: 3.972, avg. samples / sec: 54676.92
Iteration:   3460, Loss function: 4.220, Average Loss: 3.969, avg. samples / sec: 54653.21
Iteration:   3460, Loss function: 2.574, Average Loss: 3.971, avg. samples / sec: 54647.26
Iteration:   3460, Loss function: 3.773, Average Loss: 3.938, avg. samples / sec: 54626.03
Iteration:   3460, Loss function: 3.550, Average Loss: 3.943, avg. samples / sec: 54631.20
Iteration:   3460, Loss function: 3.885, Average Loss: 3.995, avg. samples / sec: 54645.35
Iteration:   3460, Loss function: 3.662, Average Loss: 3.983, avg. samples / sec: 54641.77
Iteration:   3460, Loss function: 3.063, Average Loss: 3.971, avg. samples / sec: 54362.68
Iteration:   3460, Loss function: 4.179, Average Loss: 3.965, avg. samples / sec: 54602.99
Iteration:   3460, Loss function: 3.989, Average Loss: 3.944, avg. samples / sec: 54635.44
Iteration:   3460, Loss function: 3.326, Average Loss: 3.978, avg. samples / sec: 54641.20
Iteration:   3460, Loss function: 2.990, Average Loss: 3.967, avg. samples / sec: 54663.01
Iteration:   3460, Loss function: 3.630, Average Loss: 3.979, avg. samples / sec: 54582.98
Iteration:   3460, Loss function: 3.701, Average Loss: 3.951, avg. samples / sec: 54601.59
Iteration:   3460, Loss function: 4.994, Average Loss: 3.979, avg. samples / sec: 54667.55
Iteration:   3460, Loss function: 4.369, Average Loss: 3.980, avg. samples / sec: 54586.36
Iteration:   3460, Loss function: 3.197, Average Loss: 3.970, avg. samples / sec: 54636.64
Iteration:   3460, Loss function: 3.812, Average Loss: 3.972, avg. samples / sec: 54324.27
Iteration:   3460, Loss function: 3.591, Average Loss: 3.958, avg. samples / sec: 54617.57
Iteration:   3480, Loss function: 3.152, Average Loss: 3.981, avg. samples / sec: 55009.50
Iteration:   3480, Loss function: 2.589, Average Loss: 3.991, avg. samples / sec: 55298.65
Iteration:   3480, Loss function: 2.811, Average Loss: 3.963, avg. samples / sec: 55357.10
Iteration:   3480, Loss function: 2.811, Average Loss: 3.944, avg. samples / sec: 55002.05
Iteration:   3480, Loss function: 4.319, Average Loss: 3.963, avg. samples / sec: 54934.19
Iteration:   3480, Loss function: 3.200, Average Loss: 3.952, avg. samples / sec: 55056.41
Iteration:   3480, Loss function: 4.072, Average Loss: 3.958, avg. samples / sec: 55031.62
Iteration:   3480, Loss function: 4.765, Average Loss: 3.942, avg. samples / sec: 54961.44
Iteration:   3480, Loss function: 3.164, Average Loss: 3.958, avg. samples / sec: 54999.28
Iteration:   3480, Loss function: 3.506, Average Loss: 3.958, avg. samples / sec: 54946.44
Iteration:   3480, Loss function: 3.774, Average Loss: 3.971, avg. samples / sec: 55207.21
Iteration:   3480, Loss function: 4.576, Average Loss: 3.953, avg. samples / sec: 54913.11
Iteration:   3480, Loss function: 3.042, Average Loss: 3.970, avg. samples / sec: 55209.85
Iteration:   3480, Loss function: 4.345, Average Loss: 3.959, avg. samples / sec: 55027.39
Iteration:   3480, Loss function: 3.306, Average Loss: 3.970, avg. samples / sec: 55020.34
Iteration:   3480, Loss function: 4.229, Average Loss: 3.963, avg. samples / sec: 54976.49
Iteration:   3480, Loss function: 4.458, Average Loss: 3.930, avg. samples / sec: 55010.85
Iteration:   3480, Loss function: 3.142, Average Loss: 3.955, avg. samples / sec: 54960.74
Iteration:   3480, Loss function: 3.207, Average Loss: 3.957, avg. samples / sec: 54963.31
Iteration:   3480, Loss function: 1.878, Average Loss: 3.927, avg. samples / sec: 54980.87
Iteration:   3480, Loss function: 3.192, Average Loss: 3.958, avg. samples / sec: 54997.03
Iteration:   3480, Loss function: 2.544, Average Loss: 3.989, avg. samples / sec: 54972.93
Iteration:   3480, Loss function: 2.914, Average Loss: 3.940, avg. samples / sec: 55027.37
Iteration:   3480, Loss function: 5.244, Average Loss: 3.969, avg. samples / sec: 54986.36
Iteration:   3480, Loss function: 3.938, Average Loss: 3.954, avg. samples / sec: 54971.80
Iteration:   3480, Loss function: 2.843, Average Loss: 3.963, avg. samples / sec: 54991.25
Iteration:   3480, Loss function: 3.594, Average Loss: 3.951, avg. samples / sec: 55045.98
Iteration:   3480, Loss function: 3.570, Average Loss: 3.935, avg. samples / sec: 54963.01
Iteration:   3480, Loss function: 3.492, Average Loss: 3.970, avg. samples / sec: 54965.54
Iteration:   3480, Loss function: 3.146, Average Loss: 3.957, avg. samples / sec: 54984.97
:::MLL 1558640143.191 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558640143.192 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 3.938, Average Loss: 3.983, avg. samples / sec: 54756.59
Iteration:   3500, Loss function: 4.634, Average Loss: 3.974, avg. samples / sec: 54758.48
Iteration:   3500, Loss function: 3.799, Average Loss: 3.948, avg. samples / sec: 54943.36
Iteration:   3500, Loss function: 2.620, Average Loss: 3.954, avg. samples / sec: 54863.60
Iteration:   3500, Loss function: 3.056, Average Loss: 3.936, avg. samples / sec: 54831.00
Iteration:   3500, Loss function: 4.110, Average Loss: 3.947, avg. samples / sec: 54918.18
Iteration:   3500, Loss function: 3.982, Average Loss: 3.952, avg. samples / sec: 54781.11
Iteration:   3500, Loss function: 3.304, Average Loss: 3.933, avg. samples / sec: 54827.48
Iteration:   3500, Loss function: 2.759, Average Loss: 3.951, avg. samples / sec: 54846.32
Iteration:   3500, Loss function: 3.384, Average Loss: 3.946, avg. samples / sec: 54785.83
Iteration:   3500, Loss function: 4.319, Average Loss: 3.941, avg. samples / sec: 54842.40
Iteration:   3500, Loss function: 4.606, Average Loss: 3.953, avg. samples / sec: 54943.32
Iteration:   3500, Loss function: 4.390, Average Loss: 3.961, avg. samples / sec: 54797.27
Iteration:   3500, Loss function: 3.440, Average Loss: 3.922, avg. samples / sec: 54941.37
Iteration:   3500, Loss function: 4.254, Average Loss: 3.950, avg. samples / sec: 54966.03
Iteration:   3500, Loss function: 3.464, Average Loss: 3.956, avg. samples / sec: 54920.92
Iteration:   3500, Loss function: 2.948, Average Loss: 3.944, avg. samples / sec: 54918.78
Iteration:   3500, Loss function: 4.256, Average Loss: 3.934, avg. samples / sec: 54917.24
Iteration:   3500, Loss function: 3.686, Average Loss: 3.938, avg. samples / sec: 54904.53
Iteration:   3500, Loss function: 4.392, Average Loss: 3.923, avg. samples / sec: 54901.77
Iteration:   3500, Loss function: 2.785, Average Loss: 3.920, avg. samples / sec: 54827.87
Iteration:   3500, Loss function: 3.125, Average Loss: 3.957, avg. samples / sec: 54661.25
Iteration:   3500, Loss function: 3.529, Average Loss: 3.960, avg. samples / sec: 54840.33
Iteration:   3500, Loss function: 3.150, Average Loss: 3.980, avg. samples / sec: 54812.53
Iteration:   3500, Loss function: 5.426, Average Loss: 3.952, avg. samples / sec: 54798.59
Iteration:   3500, Loss function: 2.776, Average Loss: 3.944, avg. samples / sec: 54828.04
Iteration:   3500, Loss function: 3.603, Average Loss: 3.948, avg. samples / sec: 54735.34
Iteration:   3500, Loss function: 2.639, Average Loss: 3.941, avg. samples / sec: 54854.18
Iteration:   3500, Loss function: 3.069, Average Loss: 3.956, avg. samples / sec: 54801.75
Iteration:   3500, Loss function: 3.730, Average Loss: 3.957, avg. samples / sec: 54793.27
Iteration:   3520, Loss function: 3.449, Average Loss: 3.960, avg. samples / sec: 55203.04
Iteration:   3520, Loss function: 3.424, Average Loss: 3.970, avg. samples / sec: 55179.37
Iteration:   3520, Loss function: 2.516, Average Loss: 3.921, avg. samples / sec: 55146.70
Iteration:   3520, Loss function: 3.813, Average Loss: 3.944, avg. samples / sec: 55183.35
Iteration:   3520, Loss function: 3.983, Average Loss: 3.948, avg. samples / sec: 55111.08
Iteration:   3520, Loss function: 3.781, Average Loss: 3.935, avg. samples / sec: 55051.04
Iteration:   3520, Loss function: 2.953, Average Loss: 3.938, avg. samples / sec: 55174.49
Iteration:   3520, Loss function: 2.858, Average Loss: 3.940, avg. samples / sec: 55107.52
Iteration:   3520, Loss function: 4.333, Average Loss: 3.925, avg. samples / sec: 55137.99
Iteration:   3520, Loss function: 2.395, Average Loss: 3.936, avg. samples / sec: 55192.90
Iteration:   3520, Loss function: 2.434, Average Loss: 3.938, avg. samples / sec: 55217.40
Iteration:   3520, Loss function: 3.467, Average Loss: 3.942, avg. samples / sec: 55192.45
Iteration:   3520, Loss function: 3.619, Average Loss: 3.914, avg. samples / sec: 55027.28
Iteration:   3520, Loss function: 5.348, Average Loss: 3.946, avg. samples / sec: 55020.62
Iteration:   3520, Loss function: 3.061, Average Loss: 3.942, avg. samples / sec: 55010.27
Iteration:   3520, Loss function: 2.243, Average Loss: 3.947, avg. samples / sec: 55012.46
Iteration:   3520, Loss function: 3.452, Average Loss: 3.933, avg. samples / sec: 55169.31
Iteration:   3520, Loss function: 3.648, Average Loss: 3.911, avg. samples / sec: 55129.53
Iteration:   3520, Loss function: 2.798, Average Loss: 3.913, avg. samples / sec: 55107.97
Iteration:   3520, Loss function: 3.271, Average Loss: 3.935, avg. samples / sec: 55007.03
Iteration:   3520, Loss function: 3.805, Average Loss: 3.940, avg. samples / sec: 54999.52
Iteration:   3520, Loss function: 2.193, Average Loss: 3.967, avg. samples / sec: 55146.19
Iteration:   3520, Loss function: 3.903, Average Loss: 3.949, avg. samples / sec: 55133.20
Iteration:   3520, Loss function: 3.578, Average Loss: 3.944, avg. samples / sec: 55164.71
Iteration:   3520, Loss function: 2.817, Average Loss: 3.945, avg. samples / sec: 55106.10
Iteration:   3520, Loss function: 3.420, Average Loss: 3.931, avg. samples / sec: 55048.28
Iteration:   3520, Loss function: 3.493, Average Loss: 3.927, avg. samples / sec: 55015.77
Iteration:   3520, Loss function: 4.056, Average Loss: 3.945, avg. samples / sec: 54857.42
Iteration:   3520, Loss function: 2.566, Average Loss: 3.931, avg. samples / sec: 55095.00
Iteration:   3520, Loss function: 3.049, Average Loss: 3.947, avg. samples / sec: 55149.68
Iteration:   3540, Loss function: 3.072, Average Loss: 3.963, avg. samples / sec: 55225.62
Iteration:   3540, Loss function: 4.076, Average Loss: 3.951, avg. samples / sec: 55178.96
Iteration:   3540, Loss function: 3.432, Average Loss: 3.935, avg. samples / sec: 55215.22
Iteration:   3540, Loss function: 2.402, Average Loss: 3.917, avg. samples / sec: 55204.94
Iteration:   3540, Loss function: 2.236, Average Loss: 3.932, avg. samples / sec: 55543.47
Iteration:   3540, Loss function: 2.832, Average Loss: 3.937, avg. samples / sec: 55186.22
Iteration:   3540, Loss function: 2.418, Average Loss: 3.925, avg. samples / sec: 55190.91
Iteration:   3540, Loss function: 3.291, Average Loss: 3.923, avg. samples / sec: 55219.83
Iteration:   3540, Loss function: 4.467, Average Loss: 3.926, avg. samples / sec: 55193.18
Iteration:   3540, Loss function: 2.808, Average Loss: 3.926, avg. samples / sec: 55182.05
Iteration:   3540, Loss function: 3.835, Average Loss: 3.929, avg. samples / sec: 55234.69
Iteration:   3540, Loss function: 2.216, Average Loss: 3.934, avg. samples / sec: 55252.19
Iteration:   3540, Loss function: 2.426, Average Loss: 3.908, avg. samples / sec: 55224.69
Iteration:   3540, Loss function: 3.472, Average Loss: 3.932, avg. samples / sec: 55220.13
Iteration:   3540, Loss function: 2.288, Average Loss: 3.925, avg. samples / sec: 55268.92
Iteration:   3540, Loss function: 5.906, Average Loss: 3.936, avg. samples / sec: 55234.61
Iteration:   3540, Loss function: 3.705, Average Loss: 3.930, avg. samples / sec: 55249.94
Iteration:   3540, Loss function: 2.735, Average Loss: 3.900, avg. samples / sec: 55233.03
Iteration:   3540, Loss function: 3.500, Average Loss: 3.930, avg. samples / sec: 55207.30
Iteration:   3540, Loss function: 3.116, Average Loss: 3.916, avg. samples / sec: 54987.99
Iteration:   3540, Loss function: 3.201, Average Loss: 3.902, avg. samples / sec: 55221.82
Iteration:   3540, Loss function: 3.045, Average Loss: 3.937, avg. samples / sec: 55234.15
Iteration:   3540, Loss function: 2.816, Average Loss: 3.955, avg. samples / sec: 55224.74
Iteration:   3540, Loss function: 3.393, Average Loss: 3.936, avg. samples / sec: 55291.93
Iteration:   3540, Loss function: 4.690, Average Loss: 3.934, avg. samples / sec: 55235.15
Iteration:   3540, Loss function: 2.682, Average Loss: 3.925, avg. samples / sec: 55188.95
Iteration:   3540, Loss function: 2.815, Average Loss: 3.934, avg. samples / sec: 55219.80
Iteration:   3540, Loss function: 4.109, Average Loss: 3.922, avg. samples / sec: 55228.91
Iteration:   3540, Loss function: 3.597, Average Loss: 3.925, avg. samples / sec: 55270.44
Iteration:   3540, Loss function: 3.864, Average Loss: 3.914, avg. samples / sec: 55229.93
:::MLL 1558640145.030 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558640145.030 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 2.647, Average Loss: 3.939, avg. samples / sec: 54189.89
Iteration:   3560, Loss function: 4.568, Average Loss: 3.945, avg. samples / sec: 54134.29
Iteration:   3560, Loss function: 3.339, Average Loss: 3.911, avg. samples / sec: 54260.93
Iteration:   3560, Loss function: 4.158, Average Loss: 3.929, avg. samples / sec: 54220.77
Iteration:   3560, Loss function: 4.482, Average Loss: 3.918, avg. samples / sec: 54201.85
Iteration:   3560, Loss function: 4.324, Average Loss: 3.923, avg. samples / sec: 54128.26
Iteration:   3560, Loss function: 3.725, Average Loss: 3.919, avg. samples / sec: 54132.19
Iteration:   3560, Loss function: 2.318, Average Loss: 3.911, avg. samples / sec: 54135.08
Iteration:   3560, Loss function: 3.229, Average Loss: 3.909, avg. samples / sec: 54124.21
Iteration:   3560, Loss function: 3.761, Average Loss: 3.920, avg. samples / sec: 54345.82
Iteration:   3560, Loss function: 3.255, Average Loss: 3.899, avg. samples / sec: 54301.16
Iteration:   3560, Loss function: 3.080, Average Loss: 3.924, avg. samples / sec: 54286.50
Iteration:   3560, Loss function: 2.760, Average Loss: 3.906, avg. samples / sec: 54282.98
Iteration:   3560, Loss function: 2.734, Average Loss: 3.917, avg. samples / sec: 54244.14
Iteration:   3560, Loss function: 2.836, Average Loss: 3.929, avg. samples / sec: 54216.16
Iteration:   3560, Loss function: 2.423, Average Loss: 3.921, avg. samples / sec: 54231.99
Iteration:   3560, Loss function: 3.169, Average Loss: 3.902, avg. samples / sec: 54280.64
Iteration:   3560, Loss function: 3.640, Average Loss: 3.901, avg. samples / sec: 53920.50
Iteration:   3560, Loss function: 2.497, Average Loss: 3.924, avg. samples / sec: 54157.07
Iteration:   3560, Loss function: 3.515, Average Loss: 3.892, avg. samples / sec: 54174.91
Iteration:   3560, Loss function: 3.299, Average Loss: 3.892, avg. samples / sec: 54166.81
Iteration:   3560, Loss function: 2.674, Average Loss: 3.922, avg. samples / sec: 54178.75
Iteration:   3560, Loss function: 3.256, Average Loss: 3.912, avg. samples / sec: 54194.12
Iteration:   3560, Loss function: 3.197, Average Loss: 3.928, avg. samples / sec: 54184.02
Iteration:   3560, Loss function: 4.228, Average Loss: 3.929, avg. samples / sec: 54154.59
Iteration:   3560, Loss function: 3.191, Average Loss: 3.918, avg. samples / sec: 54092.09
Iteration:   3560, Loss function: 3.110, Average Loss: 3.945, avg. samples / sec: 54149.35
Iteration:   3560, Loss function: 3.419, Average Loss: 3.918, avg. samples / sec: 54144.82
Iteration:   3560, Loss function: 3.712, Average Loss: 3.912, avg. samples / sec: 54140.57
Iteration:   3560, Loss function: 3.540, Average Loss: 3.918, avg. samples / sec: 54091.47
Iteration:   3580, Loss function: 3.044, Average Loss: 3.930, avg. samples / sec: 54571.23
Iteration:   3580, Loss function: 3.391, Average Loss: 3.935, avg. samples / sec: 54577.89
Iteration:   3580, Loss function: 3.128, Average Loss: 3.908, avg. samples / sec: 54645.22
Iteration:   3580, Loss function: 2.953, Average Loss: 3.916, avg. samples / sec: 54556.59
Iteration:   3580, Loss function: 4.879, Average Loss: 3.914, avg. samples / sec: 54611.05
Iteration:   3580, Loss function: 2.880, Average Loss: 3.907, avg. samples / sec: 54589.60
Iteration:   3580, Loss function: 2.461, Average Loss: 3.895, avg. samples / sec: 54638.15
Iteration:   3580, Loss function: 3.994, Average Loss: 3.903, avg. samples / sec: 54479.31
Iteration:   3580, Loss function: 3.249, Average Loss: 3.898, avg. samples / sec: 54605.12
Iteration:   3580, Loss function: 4.208, Average Loss: 3.910, avg. samples / sec: 54466.32
Iteration:   3580, Loss function: 3.460, Average Loss: 3.908, avg. samples / sec: 54626.59
Iteration:   3580, Loss function: 3.529, Average Loss: 3.901, avg. samples / sec: 54517.65
Iteration:   3580, Loss function: 3.662, Average Loss: 3.905, avg. samples / sec: 54658.00
Iteration:   3580, Loss function: 4.423, Average Loss: 3.884, avg. samples / sec: 54611.05
Iteration:   3580, Loss function: 3.568, Average Loss: 3.893, avg. samples / sec: 54592.83
Iteration:   3580, Loss function: 3.960, Average Loss: 3.910, avg. samples / sec: 54506.52
Iteration:   3580, Loss function: 3.597, Average Loss: 3.917, avg. samples / sec: 54632.94
Iteration:   3580, Loss function: 4.049, Average Loss: 3.917, avg. samples / sec: 54480.98
Iteration:   3580, Loss function: 4.100, Average Loss: 3.919, avg. samples / sec: 54494.63
Iteration:   3580, Loss function: 3.866, Average Loss: 3.888, avg. samples / sec: 54432.60
Iteration:   3580, Loss function: 3.608, Average Loss: 3.913, avg. samples / sec: 54501.29
Iteration:   3580, Loss function: 3.522, Average Loss: 3.883, avg. samples / sec: 54587.59
Iteration:   3580, Loss function: 2.207, Average Loss: 3.890, avg. samples / sec: 54508.37
Iteration:   3580, Loss function: 4.571, Average Loss: 3.909, avg. samples / sec: 54634.38
Iteration:   3580, Loss function: 4.577, Average Loss: 3.932, avg. samples / sec: 54599.96
Iteration:   3580, Loss function: 3.374, Average Loss: 3.902, avg. samples / sec: 54563.41
Iteration:   3580, Loss function: 3.294, Average Loss: 3.918, avg. samples / sec: 54562.59
Iteration:   3580, Loss function: 2.624, Average Loss: 3.907, avg. samples / sec: 54642.49
Iteration:   3580, Loss function: 3.676, Average Loss: 3.917, avg. samples / sec: 54543.29
Iteration:   3580, Loss function: 3.594, Average Loss: 3.905, avg. samples / sec: 54563.41
Iteration:   3600, Loss function: 2.218, Average Loss: 3.917, avg. samples / sec: 55073.39
Iteration:   3600, Loss function: 3.590, Average Loss: 3.907, avg. samples / sec: 55119.10
Iteration:   3600, Loss function: 2.700, Average Loss: 3.888, avg. samples / sec: 55134.21
Iteration:   3600, Loss function: 2.821, Average Loss: 3.899, avg. samples / sec: 55068.52
Iteration:   3600, Loss function: 2.844, Average Loss: 3.891, avg. samples / sec: 55100.15
Iteration:   3600, Loss function: 3.308, Average Loss: 3.883, avg. samples / sec: 55045.29
Iteration:   3600, Loss function: 2.922, Average Loss: 3.889, avg. samples / sec: 55021.85
Iteration:   3600, Loss function: 3.200, Average Loss: 3.925, avg. samples / sec: 54846.90
Iteration:   3600, Loss function: 3.240, Average Loss: 3.908, avg. samples / sec: 55108.21
Iteration:   3600, Loss function: 3.257, Average Loss: 3.875, avg. samples / sec: 55085.96
Iteration:   3600, Loss function: 3.514, Average Loss: 3.908, avg. samples / sec: 55052.05
Iteration:   3600, Loss function: 3.361, Average Loss: 3.906, avg. samples / sec: 55104.48
Iteration:   3600, Loss function: 4.378, Average Loss: 3.879, avg. samples / sec: 55084.84
Iteration:   3600, Loss function: 2.301, Average Loss: 3.900, avg. samples / sec: 55050.37
Iteration:   3600, Loss function: 3.740, Average Loss: 3.878, avg. samples / sec: 55109.48
Iteration:   3600, Loss function: 3.702, Average Loss: 3.907, avg. samples / sec: 55093.39
Iteration:   3600, Loss function: 3.481, Average Loss: 3.903, avg. samples / sec: 55100.00
Iteration:   3600, Loss function: 3.178, Average Loss: 3.905, avg. samples / sec: 55125.26
Iteration:   3600, Loss function: 3.228, Average Loss: 3.897, avg. samples / sec: 55038.69
Iteration:   3600, Loss function: 4.262, Average Loss: 3.895, avg. samples / sec: 55118.66
Iteration:   3600, Loss function: 3.221, Average Loss: 3.908, avg. samples / sec: 55036.89
Iteration:   3600, Loss function: 3.027, Average Loss: 3.911, avg. samples / sec: 55117.48
Iteration:   3600, Loss function: 4.126, Average Loss: 3.876, avg. samples / sec: 55051.40
Iteration:   3600, Loss function: 3.520, Average Loss: 3.896, avg. samples / sec: 55096.81
Iteration:   3600, Loss function: 3.393, Average Loss: 3.893, avg. samples / sec: 54996.43
Iteration:   3600, Loss function: 3.380, Average Loss: 3.893, avg. samples / sec: 55143.10
Iteration:   3600, Loss function: 3.555, Average Loss: 3.905, avg. samples / sec: 54772.78
Iteration:   3600, Loss function: 3.407, Average Loss: 3.880, avg. samples / sec: 55018.78
Iteration:   3600, Loss function: 3.576, Average Loss: 3.923, avg. samples / sec: 54334.32
Iteration:   3600, Loss function: 3.314, Average Loss: 3.898, avg. samples / sec: 54175.91
Iteration:   3620, Loss function: 2.674, Average Loss: 3.911, avg. samples / sec: 55041.36
Iteration:   3620, Loss function: 2.807, Average Loss: 3.913, avg. samples / sec: 55266.34
Iteration:   3620, Loss function: 4.279, Average Loss: 3.897, avg. samples / sec: 55332.17
Iteration:   3620, Loss function: 3.245, Average Loss: 3.899, avg. samples / sec: 54969.48
Iteration:   3620, Loss function: 3.984, Average Loss: 3.884, avg. samples / sec: 55048.26
Iteration:   3620, Loss function: 3.309, Average Loss: 3.874, avg. samples / sec: 55039.08
Iteration:   3620, Loss function: 4.190, Average Loss: 3.875, avg. samples / sec: 54957.05
Iteration:   3620, Loss function: 4.343, Average Loss: 3.891, avg. samples / sec: 54958.14
Iteration:   3620, Loss function: 2.843, Average Loss: 3.881, avg. samples / sec: 55035.90
Iteration:   3620, Loss function: 2.389, Average Loss: 3.881, avg. samples / sec: 55129.53
Iteration:   3620, Loss function: 2.573, Average Loss: 3.872, avg. samples / sec: 55052.93
Iteration:   3620, Loss function: 3.184, Average Loss: 3.897, avg. samples / sec: 55045.02
Iteration:   3620, Loss function: 2.976, Average Loss: 3.888, avg. samples / sec: 55980.08
Iteration:   3620, Loss function: 2.811, Average Loss: 3.900, avg. samples / sec: 55018.82
Iteration:   3620, Loss function: 3.313, Average Loss: 3.864, avg. samples / sec: 55073.11
Iteration:   3620, Loss function: 3.715, Average Loss: 3.887, avg. samples / sec: 55050.52
Iteration:   3620, Loss function: 3.598, Average Loss: 3.896, avg. samples / sec: 55018.71
Iteration:   3620, Loss function: 3.251, Average Loss: 3.867, avg. samples / sec: 55013.66
Iteration:   3620, Loss function: 2.181, Average Loss: 3.888, avg. samples / sec: 55015.38
Iteration:   3620, Loss function: 3.545, Average Loss: 3.894, avg. samples / sec: 55022.96
Iteration:   3620, Loss function: 3.520, Average Loss: 3.895, avg. samples / sec: 55009.97
Iteration:   3620, Loss function: 3.078, Average Loss: 3.913, avg. samples / sec: 55801.27
Iteration:   3620, Loss function: 2.269, Average Loss: 3.866, avg. samples / sec: 54982.01
Iteration:   3620, Loss function: 3.205, Average Loss: 3.898, avg. samples / sec: 55002.74
Iteration:   3620, Loss function: 3.882, Average Loss: 3.900, avg. samples / sec: 55026.23
Iteration:   3620, Loss function: 2.825, Average Loss: 3.873, avg. samples / sec: 55057.36
Iteration:   3620, Loss function: 3.474, Average Loss: 3.884, avg. samples / sec: 55015.47
Iteration:   3620, Loss function: 3.193, Average Loss: 3.899, avg. samples / sec: 55010.66
Iteration:   3620, Loss function: 3.295, Average Loss: 3.885, avg. samples / sec: 55002.86
Iteration:   3620, Loss function: 3.027, Average Loss: 3.887, avg. samples / sec: 54965.60
:::MLL 1558640147.174 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558640147.175 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 4.170, Average Loss: 3.904, avg. samples / sec: 54832.84
Iteration:   3640, Loss function: 2.773, Average Loss: 3.903, avg. samples / sec: 54803.45
Iteration:   3640, Loss function: 2.723, Average Loss: 3.888, avg. samples / sec: 54915.03
Iteration:   3640, Loss function: 3.486, Average Loss: 3.866, avg. samples / sec: 54901.68
Iteration:   3640, Loss function: 3.339, Average Loss: 3.879, avg. samples / sec: 54897.98
Iteration:   3640, Loss function: 3.749, Average Loss: 3.887, avg. samples / sec: 54844.15
Iteration:   3640, Loss function: 4.316, Average Loss: 3.861, avg. samples / sec: 55028.87
Iteration:   3640, Loss function: 3.390, Average Loss: 3.864, avg. samples / sec: 54854.61
Iteration:   3640, Loss function: 4.097, Average Loss: 3.875, avg. samples / sec: 54781.87
Iteration:   3640, Loss function: 5.304, Average Loss: 3.871, avg. samples / sec: 54838.87
Iteration:   3640, Loss function: 3.095, Average Loss: 3.857, avg. samples / sec: 54894.90
Iteration:   3640, Loss function: 3.462, Average Loss: 3.877, avg. samples / sec: 54882.08
Iteration:   3640, Loss function: 4.362, Average Loss: 3.887, avg. samples / sec: 54839.71
Iteration:   3640, Loss function: 4.194, Average Loss: 3.884, avg. samples / sec: 54844.04
Iteration:   3640, Loss function: 2.796, Average Loss: 3.872, avg. samples / sec: 54806.18
Iteration:   3640, Loss function: 2.827, Average Loss: 3.859, avg. samples / sec: 54884.39
Iteration:   3640, Loss function: 4.267, Average Loss: 3.909, avg. samples / sec: 54878.96
Iteration:   3640, Loss function: 2.162, Average Loss: 3.877, avg. samples / sec: 54826.05
Iteration:   3640, Loss function: 3.251, Average Loss: 3.857, avg. samples / sec: 54818.70
Iteration:   3640, Loss function: 2.662, Average Loss: 3.886, avg. samples / sec: 54839.60
Iteration:   3640, Loss function: 2.937, Average Loss: 3.887, avg. samples / sec: 54860.16
Iteration:   3640, Loss function: 2.656, Average Loss: 3.884, avg. samples / sec: 54840.41
Iteration:   3640, Loss function: 4.431, Average Loss: 3.893, avg. samples / sec: 54790.99
Iteration:   3640, Loss function: 4.437, Average Loss: 3.892, avg. samples / sec: 54873.08
Iteration:   3640, Loss function: 2.870, Average Loss: 3.889, avg. samples / sec: 54804.80
Iteration:   3640, Loss function: 3.865, Average Loss: 3.874, avg. samples / sec: 54851.23
Iteration:   3640, Loss function: 4.420, Average Loss: 3.864, avg. samples / sec: 54846.52
Iteration:   3640, Loss function: 4.327, Average Loss: 3.882, avg. samples / sec: 54860.09
Iteration:   3640, Loss function: 3.746, Average Loss: 3.888, avg. samples / sec: 54810.44
Iteration:   3640, Loss function: 2.665, Average Loss: 3.877, avg. samples / sec: 54852.79
Iteration:   3660, Loss function: 3.101, Average Loss: 3.892, avg. samples / sec: 54881.91
Iteration:   3660, Loss function: 2.862, Average Loss: 3.893, avg. samples / sec: 54881.76
Iteration:   3660, Loss function: 3.583, Average Loss: 3.884, avg. samples / sec: 54843.44
Iteration:   3660, Loss function: 3.956, Average Loss: 3.879, avg. samples / sec: 54894.41
Iteration:   3660, Loss function: 2.300, Average Loss: 3.854, avg. samples / sec: 54877.44
Iteration:   3660, Loss function: 3.132, Average Loss: 3.852, avg. samples / sec: 54899.65
Iteration:   3660, Loss function: 3.080, Average Loss: 3.870, avg. samples / sec: 54907.10
Iteration:   3660, Loss function: 3.485, Average Loss: 3.859, avg. samples / sec: 54907.46
Iteration:   3660, Loss function: 3.169, Average Loss: 3.861, avg. samples / sec: 54867.53
Iteration:   3660, Loss function: 3.510, Average Loss: 3.864, avg. samples / sec: 55029.84
Iteration:   3660, Loss function: 2.637, Average Loss: 3.847, avg. samples / sec: 54864.30
Iteration:   3660, Loss function: 2.811, Average Loss: 3.868, avg. samples / sec: 54859.52
Iteration:   3660, Loss function: 3.394, Average Loss: 3.875, avg. samples / sec: 54921.80
Iteration:   3660, Loss function: 4.496, Average Loss: 3.871, avg. samples / sec: 54902.80
Iteration:   3660, Loss function: 2.573, Average Loss: 3.848, avg. samples / sec: 54871.20
Iteration:   3660, Loss function: 2.901, Average Loss: 3.873, avg. samples / sec: 54890.84
Iteration:   3660, Loss function: 3.833, Average Loss: 3.876, avg. samples / sec: 54845.79
Iteration:   3660, Loss function: 4.176, Average Loss: 3.851, avg. samples / sec: 54872.12
Iteration:   3660, Loss function: 3.603, Average Loss: 3.881, avg. samples / sec: 54878.42
Iteration:   3660, Loss function: 3.503, Average Loss: 3.862, avg. samples / sec: 54903.22
Iteration:   3660, Loss function: 4.022, Average Loss: 3.885, avg. samples / sec: 54873.72
Iteration:   3660, Loss function: 4.290, Average Loss: 3.877, avg. samples / sec: 54858.68
Iteration:   3660, Loss function: 3.842, Average Loss: 3.866, avg. samples / sec: 54877.48
Iteration:   3660, Loss function: 3.132, Average Loss: 3.884, avg. samples / sec: 54849.35
Iteration:   3660, Loss function: 2.233, Average Loss: 3.873, avg. samples / sec: 54791.37
Iteration:   3660, Loss function: 2.523, Average Loss: 3.895, avg. samples / sec: 54806.71
Iteration:   3660, Loss function: 2.650, Average Loss: 3.875, avg. samples / sec: 54880.28
Iteration:   3660, Loss function: 4.552, Average Loss: 3.871, avg. samples / sec: 54874.11
Iteration:   3660, Loss function: 3.534, Average Loss: 3.875, avg. samples / sec: 54854.18
Iteration:   3660, Loss function: 3.639, Average Loss: 3.869, avg. samples / sec: 54511.43
Iteration:   3680, Loss function: 3.036, Average Loss: 3.884, avg. samples / sec: 55143.55
Iteration:   3680, Loss function: 3.386, Average Loss: 3.882, avg. samples / sec: 55175.85
Iteration:   3680, Loss function: 3.220, Average Loss: 3.869, avg. samples / sec: 55125.09
Iteration:   3680, Loss function: 3.450, Average Loss: 3.872, avg. samples / sec: 55096.08
Iteration:   3680, Loss function: 2.989, Average Loss: 3.840, avg. samples / sec: 55116.49
Iteration:   3680, Loss function: 3.741, Average Loss: 3.852, avg. samples / sec: 55147.87
Iteration:   3680, Loss function: 3.929, Average Loss: 3.857, avg. samples / sec: 55145.47
Iteration:   3680, Loss function: 4.682, Average Loss: 3.877, avg. samples / sec: 55374.74
Iteration:   3680, Loss function: 3.034, Average Loss: 3.857, avg. samples / sec: 55125.13
Iteration:   3680, Loss function: 4.046, Average Loss: 3.855, avg. samples / sec: 55446.55
Iteration:   3680, Loss function: 2.301, Average Loss: 3.845, avg. samples / sec: 55058.41
Iteration:   3680, Loss function: 2.712, Average Loss: 3.838, avg. samples / sec: 55130.78
Iteration:   3680, Loss function: 4.537, Average Loss: 3.855, avg. samples / sec: 54992.24
Iteration:   3680, Loss function: 3.936, Average Loss: 3.867, avg. samples / sec: 55207.91
Iteration:   3680, Loss function: 3.555, Average Loss: 3.890, avg. samples / sec: 55207.99
Iteration:   3680, Loss function: 4.225, Average Loss: 3.859, avg. samples / sec: 55140.86
Iteration:   3680, Loss function: 4.433, Average Loss: 3.861, avg. samples / sec: 55119.96
Iteration:   3680, Loss function: 3.747, Average Loss: 3.874, avg. samples / sec: 55183.69
Iteration:   3680, Loss function: 2.903, Average Loss: 3.871, avg. samples / sec: 55150.33
Iteration:   3680, Loss function: 3.396, Average Loss: 3.862, avg. samples / sec: 55107.76
Iteration:   3680, Loss function: 3.182, Average Loss: 3.852, avg. samples / sec: 55142.65
Iteration:   3680, Loss function: 3.112, Average Loss: 3.843, avg. samples / sec: 55130.39
Iteration:   3680, Loss function: 3.618, Average Loss: 3.869, avg. samples / sec: 55144.65
Iteration:   3680, Loss function: 3.708, Average Loss: 3.862, avg. samples / sec: 55088.13
Iteration:   3680, Loss function: 2.796, Average Loss: 3.866, avg. samples / sec: 55106.42
Iteration:   3680, Loss function: 3.174, Average Loss: 3.838, avg. samples / sec: 55093.28
Iteration:   3680, Loss function: 4.416, Average Loss: 3.870, avg. samples / sec: 55152.12
Iteration:   3680, Loss function: 3.396, Average Loss: 3.864, avg. samples / sec: 55151.93
Iteration:   3680, Loss function: 3.653, Average Loss: 3.864, avg. samples / sec: 55154.28
Iteration:   3680, Loss function: 3.325, Average Loss: 3.853, avg. samples / sec: 55099.23
:::MLL 1558640149.315 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558640149.316 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 4.037, Average Loss: 3.872, avg. samples / sec: 54642.96
Iteration:   3700, Loss function: 2.346, Average Loss: 3.868, avg. samples / sec: 54621.53
Iteration:   3700, Loss function: 3.216, Average Loss: 3.838, avg. samples / sec: 54822.60
Iteration:   3700, Loss function: 2.365, Average Loss: 3.855, avg. samples / sec: 54656.61
Iteration:   3700, Loss function: 3.014, Average Loss: 3.844, avg. samples / sec: 54658.68
Iteration:   3700, Loss function: 3.492, Average Loss: 3.842, avg. samples / sec: 54692.54
Iteration:   3700, Loss function: 1.954, Average Loss: 3.853, avg. samples / sec: 54898.28
Iteration:   3700, Loss function: 3.179, Average Loss: 3.844, avg. samples / sec: 54651.86
Iteration:   3700, Loss function: 2.382, Average Loss: 3.828, avg. samples / sec: 54613.16
Iteration:   3700, Loss function: 3.754, Average Loss: 3.849, avg. samples / sec: 54615.30
Iteration:   3700, Loss function: 3.882, Average Loss: 3.862, avg. samples / sec: 54576.43
Iteration:   3700, Loss function: 3.748, Average Loss: 3.860, avg. samples / sec: 54802.79
Iteration:   3700, Loss function: 3.461, Average Loss: 3.868, avg. samples / sec: 54597.32
Iteration:   3700, Loss function: 3.429, Average Loss: 3.831, avg. samples / sec: 54736.08
Iteration:   3700, Loss function: 3.201, Average Loss: 3.854, avg. samples / sec: 54762.18
Iteration:   3700, Loss function: 2.654, Average Loss: 3.852, avg. samples / sec: 54751.57
Iteration:   3700, Loss function: 4.308, Average Loss: 3.864, avg. samples / sec: 54748.27
Iteration:   3700, Loss function: 3.713, Average Loss: 3.838, avg. samples / sec: 54745.33
Iteration:   3700, Loss function: 3.344, Average Loss: 3.846, avg. samples / sec: 54767.61
Iteration:   3700, Loss function: 2.607, Average Loss: 3.850, avg. samples / sec: 54661.10
Iteration:   3700, Loss function: 3.427, Average Loss: 3.829, avg. samples / sec: 54685.94
Iteration:   3700, Loss function: 2.659, Average Loss: 3.861, avg. samples / sec: 54650.29
Iteration:   3700, Loss function: 4.507, Average Loss: 3.838, avg. samples / sec: 54661.86
Iteration:   3700, Loss function: 3.614, Average Loss: 3.856, avg. samples / sec: 54674.88
Iteration:   3700, Loss function: 2.739, Average Loss: 3.864, avg. samples / sec: 54638.85
Iteration:   3700, Loss function: 3.048, Average Loss: 3.842, avg. samples / sec: 54578.82
Iteration:   3700, Loss function: 4.128, Average Loss: 3.878, avg. samples / sec: 54572.81
Iteration:   3700, Loss function: 2.095, Average Loss: 3.855, avg. samples / sec: 54614.50
Iteration:   3700, Loss function: 3.169, Average Loss: 3.863, avg. samples / sec: 54620.36
Iteration:   3700, Loss function: 3.321, Average Loss: 3.850, avg. samples / sec: 54618.03
Iteration:   3720, Loss function: 3.137, Average Loss: 3.853, avg. samples / sec: 55263.63
Iteration:   3720, Loss function: 3.294, Average Loss: 3.861, avg. samples / sec: 55201.85
Iteration:   3720, Loss function: 3.227, Average Loss: 3.861, avg. samples / sec: 55348.63
Iteration:   3720, Loss function: 3.729, Average Loss: 3.845, avg. samples / sec: 55239.52
Iteration:   3720, Loss function: 3.178, Average Loss: 3.819, avg. samples / sec: 55303.66
Iteration:   3720, Loss function: 3.964, Average Loss: 3.829, avg. samples / sec: 55101.27
Iteration:   3720, Loss function: 3.830, Average Loss: 3.834, avg. samples / sec: 55237.83
Iteration:   3720, Loss function: 3.535, Average Loss: 3.859, avg. samples / sec: 55276.22
Iteration:   3720, Loss function: 3.251, Average Loss: 3.843, avg. samples / sec: 55240.24
Iteration:   3720, Loss function: 4.366, Average Loss: 3.837, avg. samples / sec: 55190.83
Iteration:   3720, Loss function: 2.538, Average Loss: 3.834, avg. samples / sec: 55153.01
Iteration:   3720, Loss function: 4.197, Average Loss: 3.834, avg. samples / sec: 55296.29
Iteration:   3720, Loss function: 4.089, Average Loss: 3.825, avg. samples / sec: 55106.03
Iteration:   3720, Loss function: 3.927, Average Loss: 3.870, avg. samples / sec: 55302.91
Iteration:   3720, Loss function: 2.930, Average Loss: 3.844, avg. samples / sec: 55219.26
Iteration:   3720, Loss function: 3.206, Average Loss: 3.850, avg. samples / sec: 55134.13
Iteration:   3720, Loss function: 3.484, Average Loss: 3.848, avg. samples / sec: 55113.43
Iteration:   3720, Loss function: 3.443, Average Loss: 3.853, avg. samples / sec: 55050.97
Iteration:   3720, Loss function: 3.692, Average Loss: 3.852, avg. samples / sec: 55222.59
Iteration:   3720, Loss function: 4.230, Average Loss: 3.822, avg. samples / sec: 55222.53
Iteration:   3720, Loss function: 3.141, Average Loss: 3.845, avg. samples / sec: 54989.28
Iteration:   3720, Loss function: 2.981, Average Loss: 3.829, avg. samples / sec: 55220.95
Iteration:   3720, Loss function: 4.066, Average Loss: 3.844, avg. samples / sec: 55099.49
Iteration:   3720, Loss function: 3.981, Average Loss: 3.847, avg. samples / sec: 55229.82
Iteration:   3720, Loss function: 3.267, Average Loss: 3.847, avg. samples / sec: 55258.02
Iteration:   3720, Loss function: 3.185, Average Loss: 3.831, avg. samples / sec: 55100.84
Iteration:   3720, Loss function: 3.657, Average Loss: 3.830, avg. samples / sec: 55137.51
Iteration:   3720, Loss function: 3.687, Average Loss: 3.851, avg. samples / sec: 55251.09
Iteration:   3720, Loss function: 3.308, Average Loss: 3.854, avg. samples / sec: 55199.95
Iteration:   3720, Loss function: 4.505, Average Loss: 3.847, avg. samples / sec: 55234.63
Iteration:   3740, Loss function: 4.254, Average Loss: 3.850, avg. samples / sec: 54544.72
Iteration:   3740, Loss function: 3.732, Average Loss: 3.832, avg. samples / sec: 54620.72
Iteration:   3740, Loss function: 4.109, Average Loss: 3.857, avg. samples / sec: 54506.03
Iteration:   3740, Loss function: 2.543, Average Loss: 3.823, avg. samples / sec: 54584.46
Iteration:   3740, Loss function: 3.888, Average Loss: 3.833, avg. samples / sec: 54611.03
Iteration:   3740, Loss function: 2.324, Average Loss: 3.821, avg. samples / sec: 54570.07
Iteration:   3740, Loss function: 5.285, Average Loss: 3.846, avg. samples / sec: 54307.69
Iteration:   3740, Loss function: 3.077, Average Loss: 3.838, avg. samples / sec: 54587.00
Iteration:   3740, Loss function: 3.974, Average Loss: 3.843, avg. samples / sec: 54581.31
Iteration:   3740, Loss function: 2.674, Average Loss: 3.827, avg. samples / sec: 54549.34
Iteration:   3740, Loss function: 3.134, Average Loss: 3.845, avg. samples / sec: 54564.68
Iteration:   3740, Loss function: 2.957, Average Loss: 3.822, avg. samples / sec: 54584.69
Iteration:   3740, Loss function: 3.402, Average Loss: 3.834, avg. samples / sec: 54550.02
Iteration:   3740, Loss function: 3.947, Average Loss: 3.849, avg. samples / sec: 54547.70
Iteration:   3740, Loss function: 2.975, Average Loss: 3.835, avg. samples / sec: 54572.35
Iteration:   3740, Loss function: 2.787, Average Loss: 3.812, avg. samples / sec: 54539.09
Iteration:   3740, Loss function: 3.293, Average Loss: 3.838, avg. samples / sec: 54546.77
Iteration:   3740, Loss function: 3.508, Average Loss: 3.822, avg. samples / sec: 54575.65
Iteration:   3740, Loss function: 3.603, Average Loss: 3.862, avg. samples / sec: 54511.41
Iteration:   3740, Loss function: 3.996, Average Loss: 3.843, avg. samples / sec: 54548.20
Iteration:   3740, Loss function: 4.237, Average Loss: 3.848, avg. samples / sec: 54574.74
Iteration:   3740, Loss function: 3.211, Average Loss: 3.825, avg. samples / sec: 54271.26
Iteration:   3740, Loss function: 4.809, Average Loss: 3.845, avg. samples / sec: 54561.09
Iteration:   3740, Loss function: 2.832, Average Loss: 3.818, avg. samples / sec: 54475.50
Iteration:   3740, Loss function: 3.999, Average Loss: 3.842, avg. samples / sec: 54519.21
Iteration:   3740, Loss function: 2.285, Average Loss: 3.836, avg. samples / sec: 54207.75
Iteration:   3740, Loss function: 3.398, Average Loss: 3.812, avg. samples / sec: 54208.78
Iteration:   3740, Loss function: 2.928, Average Loss: 3.818, avg. samples / sec: 54521.55
Iteration:   3740, Loss function: 2.324, Average Loss: 3.837, avg. samples / sec: 54557.50
Iteration:   3740, Loss function: 4.132, Average Loss: 3.853, avg. samples / sec: 54253.23
Iteration:   3760, Loss function: 3.416, Average Loss: 3.840, avg. samples / sec: 53898.50
Iteration:   3760, Loss function: 3.623, Average Loss: 3.833, avg. samples / sec: 54111.93
Iteration:   3760, Loss function: 3.337, Average Loss: 3.799, avg. samples / sec: 54269.19
Iteration:   3760, Loss function: 4.075, Average Loss: 3.829, avg. samples / sec: 54245.79
Iteration:   3760, Loss function: 3.739, Average Loss: 3.847, avg. samples / sec: 53888.05
Iteration:   3760, Loss function: 3.735, Average Loss: 3.850, avg. samples / sec: 54225.90
Iteration:   3760, Loss function: 2.134, Average Loss: 3.816, avg. samples / sec: 54145.42
Iteration:   3760, Loss function: 3.680, Average Loss: 3.822, avg. samples / sec: 53849.85
Iteration:   3760, Loss function: 3.427, Average Loss: 3.815, avg. samples / sec: 53841.75
Iteration:   3760, Loss function: 3.397, Average Loss: 3.813, avg. samples / sec: 53870.27
Iteration:   3760, Loss function: 3.893, Average Loss: 3.824, avg. samples / sec: 53784.33
Iteration:   3760, Loss function: 3.946, Average Loss: 3.804, avg. samples / sec: 53992.80
Iteration:   3760, Loss function: 3.396, Average Loss: 3.819, avg. samples / sec: 53915.84
Iteration:   3760, Loss function: 2.724, Average Loss: 3.824, avg. samples / sec: 53922.40
Iteration:   3760, Loss function: 2.314, Average Loss: 3.828, avg. samples / sec: 53887.41
Iteration:   3760, Loss function: 2.994, Average Loss: 3.842, avg. samples / sec: 53917.57
Iteration:   3760, Loss function: 3.157, Average Loss: 3.831, avg. samples / sec: 53881.19
Iteration:   3760, Loss function: 3.267, Average Loss: 3.817, avg. samples / sec: 53912.60
Iteration:   3760, Loss function: 4.308, Average Loss: 3.813, avg. samples / sec: 53972.31
Iteration:   3760, Loss function: 3.578, Average Loss: 3.799, avg. samples / sec: 53898.33
Iteration:   3760, Loss function: 4.329, Average Loss: 3.851, avg. samples / sec: 53904.89
Iteration:   3760, Loss function: 2.748, Average Loss: 3.834, avg. samples / sec: 53918.93
Iteration:   3760, Loss function: 3.380, Average Loss: 3.812, avg. samples / sec: 53859.46
Iteration:   3760, Loss function: 2.227, Average Loss: 3.830, avg. samples / sec: 53922.54
Iteration:   3760, Loss function: 2.827, Average Loss: 3.816, avg. samples / sec: 53878.24
Iteration:   3760, Loss function: 3.991, Average Loss: 3.829, avg. samples / sec: 53887.18
Iteration:   3760, Loss function: 3.775, Average Loss: 3.827, avg. samples / sec: 53881.00
Iteration:   3760, Loss function: 3.915, Average Loss: 3.835, avg. samples / sec: 53829.55
Iteration:   3760, Loss function: 2.915, Average Loss: 3.832, avg. samples / sec: 53874.41
Iteration:   3760, Loss function: 4.089, Average Loss: 3.835, avg. samples / sec: 53884.26
:::MLL 1558640151.479 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558640151.480 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 3.772, Average Loss: 3.828, avg. samples / sec: 53086.54
Iteration:   3780, Loss function: 4.009, Average Loss: 3.832, avg. samples / sec: 53038.71
Iteration:   3780, Loss function: 3.863, Average Loss: 3.841, avg. samples / sec: 53057.32
Iteration:   3780, Loss function: 3.301, Average Loss: 3.810, avg. samples / sec: 53072.88
Iteration:   3780, Loss function: 3.291, Average Loss: 3.792, avg. samples / sec: 52986.10
Iteration:   3780, Loss function: 2.776, Average Loss: 3.804, avg. samples / sec: 53085.34
Iteration:   3780, Loss function: 3.049, Average Loss: 3.837, avg. samples / sec: 53015.74
Iteration:   3780, Loss function: 3.136, Average Loss: 3.814, avg. samples / sec: 53063.07
Iteration:   3780, Loss function: 3.042, Average Loss: 3.800, avg. samples / sec: 53100.26
Iteration:   3780, Loss function: 4.240, Average Loss: 3.819, avg. samples / sec: 52972.64
Iteration:   3780, Loss function: 3.894, Average Loss: 3.812, avg. samples / sec: 53084.40
Iteration:   3780, Loss function: 4.537, Average Loss: 3.797, avg. samples / sec: 53043.82
Iteration:   3780, Loss function: 2.628, Average Loss: 3.811, avg. samples / sec: 53038.31
Iteration:   3780, Loss function: 3.046, Average Loss: 3.829, avg. samples / sec: 53045.63
Iteration:   3780, Loss function: 3.522, Average Loss: 3.815, avg. samples / sec: 53035.25
Iteration:   3780, Loss function: 3.163, Average Loss: 3.818, avg. samples / sec: 53024.14
Iteration:   3780, Loss function: 3.552, Average Loss: 3.803, avg. samples / sec: 53079.56
Iteration:   3780, Loss function: 3.281, Average Loss: 3.807, avg. samples / sec: 53042.20
Iteration:   3780, Loss function: 4.242, Average Loss: 3.823, avg. samples / sec: 53036.47
Iteration:   3780, Loss function: 4.267, Average Loss: 3.844, avg. samples / sec: 53064.65
Iteration:   3780, Loss function: 4.015, Average Loss: 3.791, avg. samples / sec: 53045.35
Iteration:   3780, Loss function: 3.918, Average Loss: 3.823, avg. samples / sec: 53061.71
Iteration:   3780, Loss function: 3.379, Average Loss: 3.832, avg. samples / sec: 53045.71
Iteration:   3780, Loss function: 3.629, Average Loss: 3.823, avg. samples / sec: 53078.76
Iteration:   3780, Loss function: 2.418, Average Loss: 3.817, avg. samples / sec: 53044.34
Iteration:   3780, Loss function: 3.509, Average Loss: 3.820, avg. samples / sec: 53046.31
Iteration:   3780, Loss function: 3.707, Average Loss: 3.804, avg. samples / sec: 52981.02
Iteration:   3780, Loss function: 3.211, Average Loss: 3.818, avg. samples / sec: 53015.56
Iteration:   3780, Loss function: 3.684, Average Loss: 3.807, avg. samples / sec: 53014.54
Iteration:   3780, Loss function: 2.801, Average Loss: 3.825, avg. samples / sec: 53032.78
Iteration:   3800, Loss function: 3.697, Average Loss: 3.823, avg. samples / sec: 53826.82
Iteration:   3800, Loss function: 3.078, Average Loss: 3.819, avg. samples / sec: 53743.60
Iteration:   3800, Loss function: 5.273, Average Loss: 3.811, avg. samples / sec: 53947.13
Iteration:   3800, Loss function: 3.655, Average Loss: 3.806, avg. samples / sec: 54100.83
Iteration:   3800, Loss function: 3.898, Average Loss: 3.833, avg. samples / sec: 53865.14
Iteration:   3800, Loss function: 2.987, Average Loss: 3.787, avg. samples / sec: 53863.41
Iteration:   3800, Loss function: 5.583, Average Loss: 3.804, avg. samples / sec: 53857.34
Iteration:   3800, Loss function: 3.307, Average Loss: 3.829, avg. samples / sec: 53872.52
Iteration:   3800, Loss function: 4.608, Average Loss: 3.794, avg. samples / sec: 53874.00
Iteration:   3800, Loss function: 3.416, Average Loss: 3.802, avg. samples / sec: 53862.76
Iteration:   3800, Loss function: 3.284, Average Loss: 3.795, avg. samples / sec: 53773.29
Iteration:   3800, Loss function: 2.954, Average Loss: 3.805, avg. samples / sec: 53875.79
Iteration:   3800, Loss function: 3.066, Average Loss: 3.809, avg. samples / sec: 53854.79
Iteration:   3800, Loss function: 3.336, Average Loss: 3.815, avg. samples / sec: 53889.16
Iteration:   3800, Loss function: 4.500, Average Loss: 3.810, avg. samples / sec: 53863.00
Iteration:   3800, Loss function: 3.185, Average Loss: 3.810, avg. samples / sec: 53931.99
Iteration:   3800, Loss function: 5.775, Average Loss: 3.782, avg. samples / sec: 53870.68
Iteration:   3800, Loss function: 3.429, Average Loss: 3.789, avg. samples / sec: 53822.17
Iteration:   3800, Loss function: 3.423, Average Loss: 3.791, avg. samples / sec: 53898.79
Iteration:   3800, Loss function: 2.492, Average Loss: 3.828, avg. samples / sec: 53860.06
Iteration:   3800, Loss function: 3.635, Average Loss: 3.813, avg. samples / sec: 53831.69
Iteration:   3800, Loss function: 2.809, Average Loss: 3.822, avg. samples / sec: 53812.08
Iteration:   3800, Loss function: 3.895, Average Loss: 3.798, avg. samples / sec: 53823.16
Iteration:   3800, Loss function: 2.338, Average Loss: 3.810, avg. samples / sec: 53867.59
Iteration:   3800, Loss function: 2.446, Average Loss: 3.796, avg. samples / sec: 53889.28
Iteration:   3800, Loss function: 1.914, Average Loss: 3.818, avg. samples / sec: 53838.68
Iteration:   3800, Loss function: 2.901, Average Loss: 3.814, avg. samples / sec: 53858.33
Iteration:   3800, Loss function: 4.078, Average Loss: 3.835, avg. samples / sec: 53778.30
Iteration:   3800, Loss function: 3.908, Average Loss: 3.816, avg. samples / sec: 53848.66
Iteration:   3800, Loss function: 3.586, Average Loss: 3.806, avg. samples / sec: 53522.10
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558640152.745 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.52s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22687
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38697
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05810
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23860
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21994
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09829
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52478
Current AP: 0.22687 AP goal: 0.23000
:::MLL 1558640156.577 eval_accuracy: {"value": 0.22687471957976008, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558640156.644 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558640156.651 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558640156.651 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 2.352, Average Loss: 3.819, avg. samples / sec: 7393.46
Iteration:   3820, Loss function: 3.145, Average Loss: 3.812, avg. samples / sec: 7391.31
Iteration:   3820, Loss function: 2.540, Average Loss: 3.813, avg. samples / sec: 7390.99
Iteration:   3820, Loss function: 4.556, Average Loss: 3.804, avg. samples / sec: 7389.72
Iteration:   3820, Loss function: 4.083, Average Loss: 3.784, avg. samples / sec: 7390.59
Iteration:   3820, Loss function: 3.325, Average Loss: 3.809, avg. samples / sec: 7395.82
Iteration:   3820, Loss function: 4.109, Average Loss: 3.802, avg. samples / sec: 7395.47
Iteration:   3820, Loss function: 3.062, Average Loss: 3.796, avg. samples / sec: 7397.01
Iteration:   3820, Loss function: 3.597, Average Loss: 3.798, avg. samples / sec: 7394.45
Iteration:   3820, Loss function: 2.832, Average Loss: 3.785, avg. samples / sec: 7391.70
Iteration:   3820, Loss function: 3.957, Average Loss: 3.794, avg. samples / sec: 7389.82
Iteration:   3820, Loss function: 3.797, Average Loss: 3.802, avg. samples / sec: 7391.43
Iteration:   3820, Loss function: 1.551, Average Loss: 3.812, avg. samples / sec: 7391.61
Iteration:   3820, Loss function: 3.567, Average Loss: 3.799, avg. samples / sec: 7385.90
Iteration:   3820, Loss function: 3.657, Average Loss: 3.782, avg. samples / sec: 7390.80
Iteration:   3820, Loss function: 3.250, Average Loss: 3.828, avg. samples / sec: 7385.73
Iteration:   3820, Loss function: 3.985, Average Loss: 3.808, avg. samples / sec: 7391.10
Iteration:   3820, Loss function: 4.391, Average Loss: 3.797, avg. samples / sec: 7386.81
Iteration:   3820, Loss function: 3.940, Average Loss: 3.790, avg. samples / sec: 7391.25
Iteration:   3820, Loss function: 4.278, Average Loss: 3.806, avg. samples / sec: 7390.19
Iteration:   3820, Loss function: 4.329, Average Loss: 3.774, avg. samples / sec: 7385.75
Iteration:   3820, Loss function: 2.726, Average Loss: 3.775, avg. samples / sec: 7390.37
Iteration:   3820, Loss function: 3.560, Average Loss: 3.790, avg. samples / sec: 7390.81
Iteration:   3820, Loss function: 3.000, Average Loss: 3.816, avg. samples / sec: 7390.54
Iteration:   3820, Loss function: 2.716, Average Loss: 3.824, avg. samples / sec: 7391.64
Iteration:   3820, Loss function: 5.029, Average Loss: 3.798, avg. samples / sec: 7389.54
Iteration:   3820, Loss function: 3.032, Average Loss: 3.810, avg. samples / sec: 7390.80
Iteration:   3820, Loss function: 3.044, Average Loss: 3.799, avg. samples / sec: 7389.65
Iteration:   3820, Loss function: 3.245, Average Loss: 3.785, avg. samples / sec: 7390.00
Iteration:   3820, Loss function: 4.235, Average Loss: 3.808, avg. samples / sec: 7391.03
:::MLL 1558640157.602 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558640157.602 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 3.901, Average Loss: 3.804, avg. samples / sec: 53012.81
Iteration:   3840, Loss function: 4.484, Average Loss: 3.815, avg. samples / sec: 53003.14
Iteration:   3840, Loss function: 3.405, Average Loss: 3.808, avg. samples / sec: 53011.97
Iteration:   3840, Loss function: 4.028, Average Loss: 3.776, avg. samples / sec: 53010.42
Iteration:   3840, Loss function: 4.323, Average Loss: 3.796, avg. samples / sec: 53010.89
Iteration:   3840, Loss function: 4.175, Average Loss: 3.800, avg. samples / sec: 52994.03
Iteration:   3840, Loss function: 3.956, Average Loss: 3.778, avg. samples / sec: 53006.83
Iteration:   3840, Loss function: 2.827, Average Loss: 3.784, avg. samples / sec: 52976.08
Iteration:   3840, Loss function: 4.004, Average Loss: 3.794, avg. samples / sec: 52944.83
Iteration:   3840, Loss function: 3.423, Average Loss: 3.785, avg. samples / sec: 52992.42
Iteration:   3840, Loss function: 3.507, Average Loss: 3.792, avg. samples / sec: 52956.53
Iteration:   3840, Loss function: 2.907, Average Loss: 3.774, avg. samples / sec: 53112.93
Iteration:   3840, Loss function: 3.526, Average Loss: 3.803, avg. samples / sec: 53069.90
Iteration:   3840, Loss function: 4.680, Average Loss: 3.799, avg. samples / sec: 53093.24
Iteration:   3840, Loss function: 2.236, Average Loss: 3.793, avg. samples / sec: 53135.83
Iteration:   3840, Loss function: 4.160, Average Loss: 3.778, avg. samples / sec: 53108.66
Iteration:   3840, Loss function: 3.622, Average Loss: 3.781, avg. samples / sec: 53131.47
Iteration:   3840, Loss function: 3.952, Average Loss: 3.792, avg. samples / sec: 53077.58
Iteration:   3840, Loss function: 3.373, Average Loss: 3.792, avg. samples / sec: 53102.74
Iteration:   3840, Loss function: 3.711, Average Loss: 3.816, avg. samples / sec: 53053.02
Iteration:   3840, Loss function: 2.961, Average Loss: 3.762, avg. samples / sec: 53045.17
Iteration:   3840, Loss function: 3.413, Average Loss: 3.814, avg. samples / sec: 53023.70
Iteration:   3840, Loss function: 3.268, Average Loss: 3.796, avg. samples / sec: 52941.51
Iteration:   3840, Loss function: 3.638, Average Loss: 3.781, avg. samples / sec: 52985.42
Iteration:   3840, Loss function: 4.417, Average Loss: 3.771, avg. samples / sec: 52978.35
Iteration:   3840, Loss function: 2.638, Average Loss: 3.799, avg. samples / sec: 52971.42
Iteration:   3840, Loss function: 3.591, Average Loss: 3.802, avg. samples / sec: 53038.15
Iteration:   3840, Loss function: 3.368, Average Loss: 3.789, avg. samples / sec: 52918.83
Iteration:   3840, Loss function: 3.327, Average Loss: 3.804, avg. samples / sec: 52974.03
Iteration:   3840, Loss function: 3.461, Average Loss: 3.805, avg. samples / sec: 52951.24
Iteration:   3860, Loss function: 3.111, Average Loss: 3.796, avg. samples / sec: 53616.22
Iteration:   3860, Loss function: 4.004, Average Loss: 3.810, avg. samples / sec: 53510.82
Iteration:   3860, Loss function: 3.113, Average Loss: 3.795, avg. samples / sec: 53541.34
Iteration:   3860, Loss function: 2.678, Average Loss: 3.785, avg. samples / sec: 53669.28
Iteration:   3860, Loss function: 4.293, Average Loss: 3.771, avg. samples / sec: 53605.92
Iteration:   3860, Loss function: 3.755, Average Loss: 3.789, avg. samples / sec: 53612.32
Iteration:   3860, Loss function: 3.039, Average Loss: 3.777, avg. samples / sec: 53615.48
Iteration:   3860, Loss function: 3.718, Average Loss: 3.783, avg. samples / sec: 53573.23
Iteration:   3860, Loss function: 3.604, Average Loss: 3.770, avg. samples / sec: 53587.51
Iteration:   3860, Loss function: 2.987, Average Loss: 3.775, avg. samples / sec: 53601.90
Iteration:   3860, Loss function: 3.511, Average Loss: 3.784, avg. samples / sec: 53601.49
Iteration:   3860, Loss function: 2.497, Average Loss: 3.765, avg. samples / sec: 53522.41
Iteration:   3860, Loss function: 3.173, Average Loss: 3.788, avg. samples / sec: 53525.45
Iteration:   3860, Loss function: 2.942, Average Loss: 3.781, avg. samples / sec: 53677.15
Iteration:   3860, Loss function: 4.206, Average Loss: 3.788, avg. samples / sec: 53529.24
Iteration:   3860, Loss function: 2.526, Average Loss: 3.765, avg. samples / sec: 53637.62
Iteration:   3860, Loss function: 3.864, Average Loss: 3.792, avg. samples / sec: 53607.10
Iteration:   3860, Loss function: 4.242, Average Loss: 3.797, avg. samples / sec: 53656.10
Iteration:   3860, Loss function: 3.980, Average Loss: 3.793, avg. samples / sec: 53479.83
Iteration:   3860, Loss function: 3.543, Average Loss: 3.774, avg. samples / sec: 53607.36
Iteration:   3860, Loss function: 3.294, Average Loss: 3.784, avg. samples / sec: 53491.93
Iteration:   3860, Loss function: 3.150, Average Loss: 3.809, avg. samples / sec: 53581.91
Iteration:   3860, Loss function: 2.783, Average Loss: 3.774, avg. samples / sec: 53486.49
Iteration:   3860, Loss function: 3.336, Average Loss: 3.795, avg. samples / sec: 53606.02
Iteration:   3860, Loss function: 3.675, Average Loss: 3.788, avg. samples / sec: 53507.94
Iteration:   3860, Loss function: 3.934, Average Loss: 3.756, avg. samples / sec: 53526.49
Iteration:   3860, Loss function: 2.906, Average Loss: 3.793, avg. samples / sec: 53640.24
Iteration:   3860, Loss function: 2.946, Average Loss: 3.807, avg. samples / sec: 53514.54
Iteration:   3860, Loss function: 3.543, Average Loss: 3.780, avg. samples / sec: 53481.17
Iteration:   3860, Loss function: 3.824, Average Loss: 3.794, avg. samples / sec: 53576.41
Iteration:   3880, Loss function: 3.555, Average Loss: 3.785, avg. samples / sec: 53671.35
Iteration:   3880, Loss function: 3.492, Average Loss: 3.778, avg. samples / sec: 53711.11
Iteration:   3880, Loss function: 5.223, Average Loss: 3.763, avg. samples / sec: 53647.24
Iteration:   3880, Loss function: 3.167, Average Loss: 3.759, avg. samples / sec: 53677.62
Iteration:   3880, Loss function: 3.046, Average Loss: 3.767, avg. samples / sec: 53653.84
Iteration:   3880, Loss function: 2.765, Average Loss: 3.798, avg. samples / sec: 53564.98
Iteration:   3880, Loss function: 3.256, Average Loss: 3.782, avg. samples / sec: 53616.56
Iteration:   3880, Loss function: 2.957, Average Loss: 3.770, avg. samples / sec: 53668.98
Iteration:   3880, Loss function: 2.955, Average Loss: 3.788, avg. samples / sec: 53556.62
Iteration:   3880, Loss function: 2.835, Average Loss: 3.783, avg. samples / sec: 53716.80
Iteration:   3880, Loss function: 2.847, Average Loss: 3.785, avg. samples / sec: 53704.11
Iteration:   3880, Loss function: 1.916, Average Loss: 3.768, avg. samples / sec: 53673.49
Iteration:   3880, Loss function: 3.534, Average Loss: 3.761, avg. samples / sec: 53645.48
Iteration:   3880, Loss function: 3.382, Average Loss: 3.782, avg. samples / sec: 53661.52
Iteration:   3880, Loss function: 2.590, Average Loss: 3.802, avg. samples / sec: 53700.51
Iteration:   3880, Loss function: 3.530, Average Loss: 3.775, avg. samples / sec: 53684.04
Iteration:   3880, Loss function: 1.906, Average Loss: 3.780, avg. samples / sec: 53675.70
Iteration:   3880, Loss function: 3.402, Average Loss: 3.762, avg. samples / sec: 53671.55
Iteration:   3880, Loss function: 3.147, Average Loss: 3.789, avg. samples / sec: 53653.71
Iteration:   3880, Loss function: 2.682, Average Loss: 3.783, avg. samples / sec: 53666.20
Iteration:   3880, Loss function: 4.200, Average Loss: 3.784, avg. samples / sec: 53626.93
Iteration:   3880, Loss function: 3.704, Average Loss: 3.757, avg. samples / sec: 53621.95
Iteration:   3880, Loss function: 3.827, Average Loss: 3.782, avg. samples / sec: 53706.67
Iteration:   3880, Loss function: 3.675, Average Loss: 3.762, avg. samples / sec: 53643.64
Iteration:   3880, Loss function: 3.801, Average Loss: 3.753, avg. samples / sec: 53654.92
Iteration:   3880, Loss function: 2.633, Average Loss: 3.781, avg. samples / sec: 53647.77
Iteration:   3880, Loss function: 3.596, Average Loss: 3.798, avg. samples / sec: 53641.77
Iteration:   3880, Loss function: 3.287, Average Loss: 3.776, avg. samples / sec: 53329.35
Iteration:   3880, Loss function: 3.793, Average Loss: 3.773, avg. samples / sec: 53410.23
Iteration:   3880, Loss function: 3.113, Average Loss: 3.775, avg. samples / sec: 53632.09
Iteration:   3900, Loss function: 2.413, Average Loss: 3.781, avg. samples / sec: 54156.20
Iteration:   3900, Loss function: 3.678, Average Loss: 3.776, avg. samples / sec: 53903.01
Iteration:   3900, Loss function: 3.657, Average Loss: 3.785, avg. samples / sec: 54080.01
Iteration:   3900, Loss function: 4.024, Average Loss: 3.765, avg. samples / sec: 54255.04
Iteration:   3900, Loss function: 2.635, Average Loss: 3.760, avg. samples / sec: 53954.21
Iteration:   3900, Loss function: 3.702, Average Loss: 3.771, avg. samples / sec: 53881.95
Iteration:   3900, Loss function: 2.244, Average Loss: 3.753, avg. samples / sec: 53908.29
Iteration:   3900, Loss function: 3.095, Average Loss: 3.776, avg. samples / sec: 53942.03
Iteration:   3900, Loss function: 2.972, Average Loss: 3.761, avg. samples / sec: 53954.07
Iteration:   3900, Loss function: 3.836, Average Loss: 3.766, avg. samples / sec: 54201.83
Iteration:   3900, Loss function: 2.426, Average Loss: 3.775, avg. samples / sec: 53908.58
Iteration:   3900, Loss function: 3.144, Average Loss: 3.782, avg. samples / sec: 53977.96
Iteration:   3900, Loss function: 4.008, Average Loss: 3.763, avg. samples / sec: 53914.39
Iteration:   3900, Loss function: 3.383, Average Loss: 3.774, avg. samples / sec: 53885.45
Iteration:   3900, Loss function: 3.048, Average Loss: 3.755, avg. samples / sec: 53900.21
Iteration:   3900, Loss function: 2.397, Average Loss: 3.775, avg. samples / sec: 53903.26
Iteration:   3900, Loss function: 4.036, Average Loss: 3.767, avg. samples / sec: 53908.54
Iteration:   3900, Loss function: 3.217, Average Loss: 3.757, avg. samples / sec: 53681.04
Iteration:   3900, Loss function: 3.144, Average Loss: 3.749, avg. samples / sec: 53937.84
Iteration:   3900, Loss function: 2.570, Average Loss: 3.755, avg. samples / sec: 53907.09
Iteration:   3900, Loss function: 3.466, Average Loss: 3.774, avg. samples / sec: 53912.58
Iteration:   3900, Loss function: 3.792, Average Loss: 3.797, avg. samples / sec: 53865.74
Iteration:   3900, Loss function: 2.490, Average Loss: 3.779, avg. samples / sec: 53896.77
Iteration:   3900, Loss function: 4.523, Average Loss: 3.759, avg. samples / sec: 53918.93
Iteration:   3900, Loss function: 1.649, Average Loss: 3.769, avg. samples / sec: 53879.52
Iteration:   3900, Loss function: 2.142, Average Loss: 3.774, avg. samples / sec: 53908.43
Iteration:   3900, Loss function: 3.160, Average Loss: 3.793, avg. samples / sec: 53909.94
Iteration:   3900, Loss function: 3.348, Average Loss: 3.773, avg. samples / sec: 53879.09
Iteration:   3900, Loss function: 3.178, Average Loss: 3.769, avg. samples / sec: 53910.29
Iteration:   3900, Loss function: 2.275, Average Loss: 3.747, avg. samples / sec: 53779.10
:::MLL 1558640159.799 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558640159.799 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 2.859, Average Loss: 3.765, avg. samples / sec: 53078.44
Iteration:   3920, Loss function: 4.050, Average Loss: 3.776, avg. samples / sec: 53085.88
Iteration:   3920, Loss function: 2.371, Average Loss: 3.769, avg. samples / sec: 53043.70
Iteration:   3920, Loss function: 3.124, Average Loss: 3.759, avg. samples / sec: 53083.12
Iteration:   3920, Loss function: 3.041, Average Loss: 3.764, avg. samples / sec: 53090.86
Iteration:   3920, Loss function: 3.219, Average Loss: 3.748, avg. samples / sec: 53089.98
Iteration:   3920, Loss function: 3.980, Average Loss: 3.754, avg. samples / sec: 53050.96
Iteration:   3920, Loss function: 3.228, Average Loss: 3.766, avg. samples / sec: 53066.09
Iteration:   3920, Loss function: 3.477, Average Loss: 3.756, avg. samples / sec: 53052.60
Iteration:   3920, Loss function: 3.306, Average Loss: 3.754, avg. samples / sec: 53045.25
Iteration:   3920, Loss function: 2.982, Average Loss: 3.747, avg. samples / sec: 53104.74
Iteration:   3920, Loss function: 2.030, Average Loss: 3.751, avg. samples / sec: 53086.32
Iteration:   3920, Loss function: 3.493, Average Loss: 3.740, avg. samples / sec: 53259.39
Iteration:   3920, Loss function: 4.373, Average Loss: 3.776, avg. samples / sec: 53061.57
Iteration:   3920, Loss function: 2.902, Average Loss: 3.769, avg. samples / sec: 53076.32
Iteration:   3920, Loss function: 3.577, Average Loss: 3.760, avg. samples / sec: 53090.84
Iteration:   3920, Loss function: 3.347, Average Loss: 3.770, avg. samples / sec: 53045.77
Iteration:   3920, Loss function: 2.507, Average Loss: 3.751, avg. samples / sec: 53113.33
Iteration:   3920, Loss function: 2.774, Average Loss: 3.761, avg. samples / sec: 53068.24
Iteration:   3920, Loss function: 4.350, Average Loss: 3.794, avg. samples / sec: 53098.50
Iteration:   3920, Loss function: 2.153, Average Loss: 3.755, avg. samples / sec: 53115.89
Iteration:   3920, Loss function: 4.783, Average Loss: 3.791, avg. samples / sec: 53103.92
Iteration:   3920, Loss function: 2.736, Average Loss: 3.748, avg. samples / sec: 53070.16
Iteration:   3920, Loss function: 3.376, Average Loss: 3.764, avg. samples / sec: 53102.08
Iteration:   3920, Loss function: 2.013, Average Loss: 3.771, avg. samples / sec: 53079.46
Iteration:   3920, Loss function: 4.274, Average Loss: 3.743, avg. samples / sec: 53058.89
Iteration:   3920, Loss function: 4.655, Average Loss: 3.767, avg. samples / sec: 53060.45
Iteration:   3920, Loss function: 2.743, Average Loss: 3.758, avg. samples / sec: 53104.22
Iteration:   3920, Loss function: 3.113, Average Loss: 3.769, avg. samples / sec: 53079.96
Iteration:   3920, Loss function: 2.646, Average Loss: 3.754, avg. samples / sec: 53017.97
Iteration:   3940, Loss function: 2.326, Average Loss: 3.760, avg. samples / sec: 54009.48
Iteration:   3940, Loss function: 3.519, Average Loss: 3.763, avg. samples / sec: 54018.20
Iteration:   3940, Loss function: 3.896, Average Loss: 3.771, avg. samples / sec: 53943.37
Iteration:   3940, Loss function: 2.873, Average Loss: 3.753, avg. samples / sec: 54027.23
Iteration:   3940, Loss function: 2.952, Average Loss: 3.745, avg. samples / sec: 54068.72
Iteration:   3940, Loss function: 3.106, Average Loss: 3.759, avg. samples / sec: 54009.01
Iteration:   3940, Loss function: 2.979, Average Loss: 3.744, avg. samples / sec: 54036.53
Iteration:   3940, Loss function: 2.957, Average Loss: 3.752, avg. samples / sec: 53952.31
Iteration:   3940, Loss function: 2.521, Average Loss: 3.739, avg. samples / sec: 53801.54
Iteration:   3940, Loss function: 2.498, Average Loss: 3.745, avg. samples / sec: 53992.89
Iteration:   3940, Loss function: 3.795, Average Loss: 3.747, avg. samples / sec: 54000.89
Iteration:   3940, Loss function: 2.502, Average Loss: 3.755, avg. samples / sec: 54003.65
Iteration:   3940, Loss function: 3.754, Average Loss: 3.748, avg. samples / sec: 54018.34
Iteration:   3940, Loss function: 2.890, Average Loss: 3.783, avg. samples / sec: 54030.25
Iteration:   3940, Loss function: 3.216, Average Loss: 3.732, avg. samples / sec: 54046.41
Iteration:   3940, Loss function: 3.759, Average Loss: 3.761, avg. samples / sec: 53998.97
Iteration:   3940, Loss function: 3.413, Average Loss: 3.763, avg. samples / sec: 53993.47
Iteration:   3940, Loss function: 3.113, Average Loss: 3.730, avg. samples / sec: 53981.20
Iteration:   3940, Loss function: 2.658, Average Loss: 3.770, avg. samples / sec: 53987.78
Iteration:   3940, Loss function: 3.633, Average Loss: 3.745, avg. samples / sec: 53995.74
Iteration:   3940, Loss function: 3.039, Average Loss: 3.789, avg. samples / sec: 54001.60
Iteration:   3940, Loss function: 4.482, Average Loss: 3.748, avg. samples / sec: 54038.33
Iteration:   3940, Loss function: 2.699, Average Loss: 3.758, avg. samples / sec: 54030.23
Iteration:   3940, Loss function: 2.271, Average Loss: 3.748, avg. samples / sec: 53979.57
Iteration:   3940, Loss function: 2.709, Average Loss: 3.748, avg. samples / sec: 54045.69
Iteration:   3940, Loss function: 2.112, Average Loss: 3.760, avg. samples / sec: 54002.92
Iteration:   3940, Loss function: 3.755, Average Loss: 3.754, avg. samples / sec: 53990.40
Iteration:   3940, Loss function: 2.731, Average Loss: 3.738, avg. samples / sec: 53987.47
Iteration:   3940, Loss function: 3.209, Average Loss: 3.748, avg. samples / sec: 53698.71
Iteration:   3940, Loss function: 3.735, Average Loss: 3.759, avg. samples / sec: 53970.99
Iteration:   3960, Loss function: 3.504, Average Loss: 3.761, avg. samples / sec: 53840.49
Iteration:   3960, Loss function: 3.659, Average Loss: 3.747, avg. samples / sec: 53802.75
Iteration:   3960, Loss function: 3.994, Average Loss: 3.759, avg. samples / sec: 53804.48
Iteration:   3960, Loss function: 3.449, Average Loss: 3.741, avg. samples / sec: 53881.58
Iteration:   3960, Loss function: 3.472, Average Loss: 3.744, avg. samples / sec: 53776.58
Iteration:   3960, Loss function: 3.171, Average Loss: 3.737, avg. samples / sec: 53769.78
Iteration:   3960, Loss function: 4.614, Average Loss: 3.745, avg. samples / sec: 53718.16
Iteration:   3960, Loss function: 4.541, Average Loss: 3.742, avg. samples / sec: 54093.54
Iteration:   3960, Loss function: 2.973, Average Loss: 3.735, avg. samples / sec: 53776.97
Iteration:   3960, Loss function: 3.837, Average Loss: 3.738, avg. samples / sec: 53832.26
Iteration:   3960, Loss function: 2.461, Average Loss: 3.738, avg. samples / sec: 53822.23
Iteration:   3960, Loss function: 2.754, Average Loss: 3.756, avg. samples / sec: 53853.27
Iteration:   3960, Loss function: 2.808, Average Loss: 3.711, avg. samples / sec: 53837.98
Iteration:   3960, Loss function: 2.867, Average Loss: 3.747, avg. samples / sec: 53827.68
Iteration:   3960, Loss function: 3.255, Average Loss: 3.731, avg. samples / sec: 53777.05
Iteration:   3960, Loss function: 3.270, Average Loss: 3.741, avg. samples / sec: 53821.72
Iteration:   3960, Loss function: 4.459, Average Loss: 3.763, avg. samples / sec: 53822.42
Iteration:   3960, Loss function: 2.736, Average Loss: 3.739, avg. samples / sec: 53821.43
Iteration:   3960, Loss function: 2.428, Average Loss: 3.738, avg. samples / sec: 53842.61
Iteration:   3960, Loss function: 2.759, Average Loss: 3.725, avg. samples / sec: 53812.26
Iteration:   3960, Loss function: 3.264, Average Loss: 3.777, avg. samples / sec: 53804.11
Iteration:   3960, Loss function: 3.848, Average Loss: 3.740, avg. samples / sec: 53794.45
Iteration:   3960, Loss function: 3.879, Average Loss: 3.749, avg. samples / sec: 53808.54
Iteration:   3960, Loss function: 3.087, Average Loss: 3.730, avg. samples / sec: 53836.32
Iteration:   3960, Loss function: 2.848, Average Loss: 3.738, avg. samples / sec: 53817.38
Iteration:   3960, Loss function: 3.079, Average Loss: 3.745, avg. samples / sec: 53826.65
Iteration:   3960, Loss function: 3.277, Average Loss: 3.777, avg. samples / sec: 53765.62
Iteration:   3960, Loss function: 4.617, Average Loss: 3.755, avg. samples / sec: 53776.23
Iteration:   3960, Loss function: 3.289, Average Loss: 3.743, avg. samples / sec: 53756.04
Iteration:   3960, Loss function: 3.798, Average Loss: 3.753, avg. samples / sec: 53804.91
:::MLL 1558640161.985 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558640161.986 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.918, Average Loss: 3.740, avg. samples / sec: 53509.72
Iteration:   3980, Loss function: 4.353, Average Loss: 3.755, avg. samples / sec: 53584.37
Iteration:   3980, Loss function: 3.772, Average Loss: 3.750, avg. samples / sec: 53470.93
Iteration:   3980, Loss function: 2.827, Average Loss: 3.742, avg. samples / sec: 53596.07
Iteration:   3980, Loss function: 2.492, Average Loss: 3.739, avg. samples / sec: 53542.92
Iteration:   3980, Loss function: 3.317, Average Loss: 3.727, avg. samples / sec: 53536.98
Iteration:   3980, Loss function: 2.925, Average Loss: 3.735, avg. samples / sec: 53520.98
Iteration:   3980, Loss function: 2.590, Average Loss: 3.724, avg. samples / sec: 53497.76
Iteration:   3980, Loss function: 3.479, Average Loss: 3.723, avg. samples / sec: 53676.17
Iteration:   3980, Loss function: 3.730, Average Loss: 3.737, avg. samples / sec: 53470.44
Iteration:   3980, Loss function: 3.195, Average Loss: 3.718, avg. samples / sec: 53668.00
Iteration:   3980, Loss function: 3.367, Average Loss: 3.737, avg. samples / sec: 53650.61
Iteration:   3980, Loss function: 2.995, Average Loss: 3.754, avg. samples / sec: 53626.40
Iteration:   3980, Loss function: 2.755, Average Loss: 3.725, avg. samples / sec: 53616.17
Iteration:   3980, Loss function: 5.102, Average Loss: 3.734, avg. samples / sec: 53608.14
Iteration:   3980, Loss function: 4.071, Average Loss: 3.731, avg. samples / sec: 53617.68
Iteration:   3980, Loss function: 2.363, Average Loss: 3.768, avg. samples / sec: 53594.54
Iteration:   3980, Loss function: 3.387, Average Loss: 3.723, avg. samples / sec: 53610.48
Iteration:   3980, Loss function: 4.004, Average Loss: 3.736, avg. samples / sec: 53579.65
Iteration:   3980, Loss function: 3.644, Average Loss: 3.744, avg. samples / sec: 53603.53
Iteration:   3980, Loss function: 3.493, Average Loss: 3.705, avg. samples / sec: 53538.61
Iteration:   3980, Loss function: 3.905, Average Loss: 3.733, avg. samples / sec: 53618.81
Iteration:   3980, Loss function: 3.880, Average Loss: 3.748, avg. samples / sec: 53494.88
Iteration:   3980, Loss function: 3.117, Average Loss: 3.731, avg. samples / sec: 53476.22
Iteration:   3980, Loss function: 3.327, Average Loss: 3.763, avg. samples / sec: 53572.19
Iteration:   3980, Loss function: 3.185, Average Loss: 3.735, avg. samples / sec: 53539.08
Iteration:   3980, Loss function: 3.601, Average Loss: 3.748, avg. samples / sec: 53565.33
Iteration:   3980, Loss function: 4.429, Average Loss: 3.739, avg. samples / sec: 53525.27
Iteration:   3980, Loss function: 3.803, Average Loss: 3.733, avg. samples / sec: 53480.56
Iteration:   3980, Loss function: 3.146, Average Loss: 3.747, avg. samples / sec: 53584.74
Iteration:   4000, Loss function: 3.123, Average Loss: 3.744, avg. samples / sec: 53953.41
Iteration:   4000, Loss function: 3.300, Average Loss: 3.740, avg. samples / sec: 53900.19
Iteration:   4000, Loss function: 4.818, Average Loss: 3.749, avg. samples / sec: 53883.02
Iteration:   4000, Loss function: 3.916, Average Loss: 3.734, avg. samples / sec: 53872.58
Iteration:   4000, Loss function: 2.821, Average Loss: 3.719, avg. samples / sec: 53914.58
Iteration:   4000, Loss function: 3.236, Average Loss: 3.730, avg. samples / sec: 53881.29
Iteration:   4000, Loss function: 2.913, Average Loss: 3.716, avg. samples / sec: 53895.94
Iteration:   4000, Loss function: 3.517, Average Loss: 3.724, avg. samples / sec: 53864.96
Iteration:   4000, Loss function: 3.333, Average Loss: 3.729, avg. samples / sec: 53881.39
Iteration:   4000, Loss function: 2.612, Average Loss: 3.716, avg. samples / sec: 53733.84
Iteration:   4000, Loss function: 3.129, Average Loss: 3.729, avg. samples / sec: 53780.02
Iteration:   4000, Loss function: 3.245, Average Loss: 3.725, avg. samples / sec: 53915.82
Iteration:   4000, Loss function: 3.452, Average Loss: 3.739, avg. samples / sec: 53846.66
Iteration:   4000, Loss function: 3.764, Average Loss: 3.717, avg. samples / sec: 53846.89
Iteration:   4000, Loss function: 3.270, Average Loss: 3.738, avg. samples / sec: 53884.36
Iteration:   4000, Loss function: 3.589, Average Loss: 3.728, avg. samples / sec: 53831.75
Iteration:   4000, Loss function: 3.492, Average Loss: 3.748, avg. samples / sec: 53903.61
Iteration:   4000, Loss function: 3.514, Average Loss: 3.718, avg. samples / sec: 53778.96
Iteration:   4000, Loss function: 3.170, Average Loss: 3.748, avg. samples / sec: 53770.77
Iteration:   4000, Loss function: 2.593, Average Loss: 3.724, avg. samples / sec: 53790.72
Iteration:   4000, Loss function: 3.555, Average Loss: 3.702, avg. samples / sec: 53832.88
Iteration:   4000, Loss function: 2.706, Average Loss: 3.760, avg. samples / sec: 53806.10
Iteration:   4000, Loss function: 3.624, Average Loss: 3.742, avg. samples / sec: 53901.18
Iteration:   4000, Loss function: 4.219, Average Loss: 3.733, avg. samples / sec: 53778.77
Iteration:   4000, Loss function: 3.839, Average Loss: 3.723, avg. samples / sec: 53900.50
Iteration:   4000, Loss function: 4.172, Average Loss: 3.715, avg. samples / sec: 53707.84
Iteration:   4000, Loss function: 3.699, Average Loss: 3.732, avg. samples / sec: 53884.85
Iteration:   4000, Loss function: 4.051, Average Loss: 3.732, avg. samples / sec: 53866.87
Iteration:   4000, Loss function: 3.073, Average Loss: 3.727, avg. samples / sec: 53806.90
Iteration:   4000, Loss function: 3.116, Average Loss: 3.746, avg. samples / sec: 53851.62
Iteration:   4020, Loss function: 2.589, Average Loss: 3.727, avg. samples / sec: 53451.29
Iteration:   4020, Loss function: 3.886, Average Loss: 3.725, avg. samples / sec: 53486.96
Iteration:   4020, Loss function: 3.183, Average Loss: 3.722, avg. samples / sec: 53534.99
Iteration:   4020, Loss function: 3.672, Average Loss: 3.722, avg. samples / sec: 53487.10
Iteration:   4020, Loss function: 3.430, Average Loss: 3.737, avg. samples / sec: 53287.83
Iteration:   4020, Loss function: 2.394, Average Loss: 3.710, avg. samples / sec: 53404.16
Iteration:   4020, Loss function: 4.150, Average Loss: 3.733, avg. samples / sec: 53155.44
Iteration:   4020, Loss function: 2.922, Average Loss: 3.729, avg. samples / sec: 53496.38
Iteration:   4020, Loss function: 2.453, Average Loss: 3.724, avg. samples / sec: 53458.84
Iteration:   4020, Loss function: 2.973, Average Loss: 3.708, avg. samples / sec: 53429.06
Iteration:   4020, Loss function: 4.130, Average Loss: 3.733, avg. samples / sec: 53474.58
Iteration:   4020, Loss function: 3.937, Average Loss: 3.713, avg. samples / sec: 53443.41
Iteration:   4020, Loss function: 2.275, Average Loss: 3.715, avg. samples / sec: 53455.19
Iteration:   4020, Loss function: 3.898, Average Loss: 3.718, avg. samples / sec: 53425.80
Iteration:   4020, Loss function: 3.702, Average Loss: 3.743, avg. samples / sec: 53444.12
Iteration:   4020, Loss function: 3.325, Average Loss: 3.722, avg. samples / sec: 53463.40
Iteration:   4020, Loss function: 3.358, Average Loss: 3.717, avg. samples / sec: 53468.96
Iteration:   4020, Loss function: 3.788, Average Loss: 3.729, avg. samples / sec: 53158.20
Iteration:   4020, Loss function: 3.621, Average Loss: 3.719, avg. samples / sec: 53424.51
Iteration:   4020, Loss function: 4.270, Average Loss: 3.757, avg. samples / sec: 53446.73
Iteration:   4020, Loss function: 4.494, Average Loss: 3.710, avg. samples / sec: 53463.30
Iteration:   4020, Loss function: 4.563, Average Loss: 3.732, avg. samples / sec: 53454.92
Iteration:   4020, Loss function: 3.628, Average Loss: 3.742, avg. samples / sec: 53438.18
Iteration:   4020, Loss function: 3.729, Average Loss: 3.733, avg. samples / sec: 53404.08
Iteration:   4020, Loss function: 3.762, Average Loss: 3.693, avg. samples / sec: 53437.01
Iteration:   4020, Loss function: 3.908, Average Loss: 3.724, avg. samples / sec: 53450.50
Iteration:   4020, Loss function: 3.073, Average Loss: 3.710, avg. samples / sec: 53207.11
Iteration:   4020, Loss function: 3.939, Average Loss: 3.721, avg. samples / sec: 53472.49
Iteration:   4020, Loss function: 3.213, Average Loss: 3.725, avg. samples / sec: 53438.34
Iteration:   4020, Loss function: 3.472, Average Loss: 3.741, avg. samples / sec: 53441.59
Iteration:   4040, Loss function: 2.853, Average Loss: 3.730, avg. samples / sec: 53929.81
Iteration:   4040, Loss function: 2.680, Average Loss: 3.717, avg. samples / sec: 53691.67
Iteration:   4040, Loss function: 3.179, Average Loss: 3.721, avg. samples / sec: 54068.60
Iteration:   4040, Loss function: 2.743, Average Loss: 3.716, avg. samples / sec: 53759.49
Iteration:   4040, Loss function: 2.581, Average Loss: 3.727, avg. samples / sec: 53852.05
Iteration:   4040, Loss function: 3.886, Average Loss: 3.705, avg. samples / sec: 54041.33
Iteration:   4040, Loss function: 3.396, Average Loss: 3.721, avg. samples / sec: 53759.69
Iteration:   4040, Loss function: 4.068, Average Loss: 3.707, avg. samples / sec: 53772.55
Iteration:   4040, Loss function: 2.277, Average Loss: 3.712, avg. samples / sec: 53680.77
Iteration:   4040, Loss function: 3.913, Average Loss: 3.707, avg. samples / sec: 53797.60
Iteration:   4040, Loss function: 4.283, Average Loss: 3.710, avg. samples / sec: 53796.59
Iteration:   4040, Loss function: 3.730, Average Loss: 3.721, avg. samples / sec: 53752.76
Iteration:   4040, Loss function: 3.162, Average Loss: 3.704, avg. samples / sec: 53778.63
Iteration:   4040, Loss function: 3.381, Average Loss: 3.722, avg. samples / sec: 53731.63
Iteration:   4040, Loss function: 3.153, Average Loss: 3.710, avg. samples / sec: 53784.76
Iteration:   4040, Loss function: 3.671, Average Loss: 3.729, avg. samples / sec: 53795.15
Iteration:   4040, Loss function: 4.219, Average Loss: 3.735, avg. samples / sec: 53781.44
Iteration:   4040, Loss function: 3.392, Average Loss: 3.718, avg. samples / sec: 53770.73
Iteration:   4040, Loss function: 2.864, Average Loss: 3.687, avg. samples / sec: 53792.98
Iteration:   4040, Loss function: 2.814, Average Loss: 3.703, avg. samples / sec: 53775.16
Iteration:   4040, Loss function: 4.314, Average Loss: 3.728, avg. samples / sec: 53746.57
Iteration:   4040, Loss function: 2.971, Average Loss: 3.714, avg. samples / sec: 53801.52
Iteration:   4040, Loss function: 3.064, Average Loss: 3.711, avg. samples / sec: 53771.90
Iteration:   4040, Loss function: 4.851, Average Loss: 3.724, avg. samples / sec: 53771.86
Iteration:   4040, Loss function: 3.113, Average Loss: 3.729, avg. samples / sec: 53771.01
Iteration:   4040, Loss function: 2.587, Average Loss: 3.749, avg. samples / sec: 53759.57
Iteration:   4040, Loss function: 3.186, Average Loss: 3.716, avg. samples / sec: 53773.25
Iteration:   4040, Loss function: 2.833, Average Loss: 3.701, avg. samples / sec: 53724.91
Iteration:   4040, Loss function: 2.488, Average Loss: 3.710, avg. samples / sec: 53761.33
Iteration:   4040, Loss function: 3.341, Average Loss: 3.732, avg. samples / sec: 53771.40
:::MLL 1558640164.179 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558640164.180 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 4.326, Average Loss: 3.712, avg. samples / sec: 53514.54
Iteration:   4060, Loss function: 3.797, Average Loss: 3.725, avg. samples / sec: 53483.16
Iteration:   4060, Loss function: 3.796, Average Loss: 3.716, avg. samples / sec: 53468.39
Iteration:   4060, Loss function: 2.918, Average Loss: 3.721, avg. samples / sec: 53474.88
Iteration:   4060, Loss function: 2.895, Average Loss: 3.702, avg. samples / sec: 53495.30
Iteration:   4060, Loss function: 3.568, Average Loss: 3.699, avg. samples / sec: 53458.68
Iteration:   4060, Loss function: 3.388, Average Loss: 3.714, avg. samples / sec: 53422.40
Iteration:   4060, Loss function: 3.779, Average Loss: 3.719, avg. samples / sec: 53456.77
Iteration:   4060, Loss function: 3.046, Average Loss: 3.707, avg. samples / sec: 53470.44
Iteration:   4060, Loss function: 3.599, Average Loss: 3.699, avg. samples / sec: 53484.26
Iteration:   4060, Loss function: 1.851, Average Loss: 3.704, avg. samples / sec: 53475.13
Iteration:   4060, Loss function: 3.445, Average Loss: 3.716, avg. samples / sec: 53473.77
Iteration:   4060, Loss function: 3.712, Average Loss: 3.710, avg. samples / sec: 53489.58
Iteration:   4060, Loss function: 3.375, Average Loss: 3.711, avg. samples / sec: 53477.28
Iteration:   4060, Loss function: 1.681, Average Loss: 3.724, avg. samples / sec: 53506.62
Iteration:   4060, Loss function: 3.941, Average Loss: 3.723, avg. samples / sec: 53493.60
Iteration:   4060, Loss function: 2.370, Average Loss: 3.724, avg. samples / sec: 53468.96
Iteration:   4060, Loss function: 3.232, Average Loss: 3.697, avg. samples / sec: 53435.57
Iteration:   4060, Loss function: 3.402, Average Loss: 3.703, avg. samples / sec: 53475.61
Iteration:   4060, Loss function: 3.112, Average Loss: 3.695, avg. samples / sec: 53474.92
Iteration:   4060, Loss function: 3.100, Average Loss: 3.680, avg. samples / sec: 53463.54
Iteration:   4060, Loss function: 2.440, Average Loss: 3.728, avg. samples / sec: 53448.27
Iteration:   4060, Loss function: 3.486, Average Loss: 3.738, avg. samples / sec: 53479.33
Iteration:   4060, Loss function: 3.627, Average Loss: 3.724, avg. samples / sec: 53461.64
Iteration:   4060, Loss function: 4.020, Average Loss: 3.707, avg. samples / sec: 53465.94
Iteration:   4060, Loss function: 3.364, Average Loss: 3.700, avg. samples / sec: 53425.38
Iteration:   4060, Loss function: 3.980, Average Loss: 3.692, avg. samples / sec: 53457.19
Iteration:   4060, Loss function: 2.817, Average Loss: 3.703, avg. samples / sec: 53432.43
Iteration:   4060, Loss function: 3.023, Average Loss: 3.725, avg. samples / sec: 53500.36
Iteration:   4060, Loss function: 4.285, Average Loss: 3.709, avg. samples / sec: 53474.27
Iteration:   4080, Loss function: 3.321, Average Loss: 3.708, avg. samples / sec: 53956.26
Iteration:   4080, Loss function: 2.517, Average Loss: 3.717, avg. samples / sec: 53877.85
Iteration:   4080, Loss function: 5.517, Average Loss: 3.700, avg. samples / sec: 53934.86
Iteration:   4080, Loss function: 4.278, Average Loss: 3.709, avg. samples / sec: 53867.74
Iteration:   4080, Loss function: 3.531, Average Loss: 3.689, avg. samples / sec: 53906.39
Iteration:   4080, Loss function: 3.388, Average Loss: 3.708, avg. samples / sec: 53888.54
Iteration:   4080, Loss function: 2.332, Average Loss: 3.709, avg. samples / sec: 53867.10
Iteration:   4080, Loss function: 4.062, Average Loss: 3.704, avg. samples / sec: 53847.32
Iteration:   4080, Loss function: 3.543, Average Loss: 3.696, avg. samples / sec: 53905.22
Iteration:   4080, Loss function: 2.773, Average Loss: 3.691, avg. samples / sec: 53935.63
Iteration:   4080, Loss function: 3.439, Average Loss: 3.690, avg. samples / sec: 53881.10
Iteration:   4080, Loss function: 2.628, Average Loss: 3.716, avg. samples / sec: 53914.46
Iteration:   4080, Loss function: 4.413, Average Loss: 3.731, avg. samples / sec: 53926.17
Iteration:   4080, Loss function: 4.048, Average Loss: 3.702, avg. samples / sec: 53945.39
Iteration:   4080, Loss function: 1.791, Average Loss: 3.718, avg. samples / sec: 53903.61
Iteration:   4080, Loss function: 3.105, Average Loss: 3.690, avg. samples / sec: 53941.41
Iteration:   4080, Loss function: 2.921, Average Loss: 3.715, avg. samples / sec: 53879.62
Iteration:   4080, Loss function: 3.488, Average Loss: 3.710, avg. samples / sec: 53859.83
Iteration:   4080, Loss function: 2.186, Average Loss: 3.685, avg. samples / sec: 53936.02
Iteration:   4080, Loss function: 3.436, Average Loss: 3.714, avg. samples / sec: 53902.33
Iteration:   4080, Loss function: 2.393, Average Loss: 3.698, avg. samples / sec: 53927.31
Iteration:   4080, Loss function: 3.339, Average Loss: 3.694, avg. samples / sec: 53885.97
Iteration:   4080, Loss function: 2.819, Average Loss: 3.703, avg. samples / sec: 53857.71
Iteration:   4080, Loss function: 2.854, Average Loss: 3.691, avg. samples / sec: 53876.70
Iteration:   4080, Loss function: 3.655, Average Loss: 3.725, avg. samples / sec: 53883.99
Iteration:   4080, Loss function: 3.494, Average Loss: 3.677, avg. samples / sec: 53873.57
Iteration:   4080, Loss function: 2.605, Average Loss: 3.701, avg. samples / sec: 53832.72
Iteration:   4080, Loss function: 3.255, Average Loss: 3.696, avg. samples / sec: 53902.08
Iteration:   4080, Loss function: 2.768, Average Loss: 3.712, avg. samples / sec: 53623.21
Iteration:   4080, Loss function: 3.501, Average Loss: 3.717, avg. samples / sec: 53849.85
Iteration:   4100, Loss function: 2.727, Average Loss: 3.697, avg. samples / sec: 53783.66
Iteration:   4100, Loss function: 3.698, Average Loss: 3.710, avg. samples / sec: 53833.91
Iteration:   4100, Loss function: 3.555, Average Loss: 3.705, avg. samples / sec: 54174.27
Iteration:   4100, Loss function: 3.446, Average Loss: 3.702, avg. samples / sec: 53967.70
Iteration:   4100, Loss function: 2.730, Average Loss: 3.701, avg. samples / sec: 53861.19
Iteration:   4100, Loss function: 3.881, Average Loss: 3.696, avg. samples / sec: 53808.20
Iteration:   4100, Loss function: 3.137, Average Loss: 3.680, avg. samples / sec: 53834.67
Iteration:   4100, Loss function: 3.730, Average Loss: 3.705, avg. samples / sec: 53827.21
Iteration:   4100, Loss function: 3.497, Average Loss: 3.704, avg. samples / sec: 53773.62
Iteration:   4100, Loss function: 3.730, Average Loss: 3.712, avg. samples / sec: 53851.87
Iteration:   4100, Loss function: 4.073, Average Loss: 3.684, avg. samples / sec: 53850.08
Iteration:   4100, Loss function: 3.265, Average Loss: 3.673, avg. samples / sec: 53894.60
Iteration:   4100, Loss function: 3.381, Average Loss: 3.724, avg. samples / sec: 53850.47
Iteration:   4100, Loss function: 3.436, Average Loss: 3.702, avg. samples / sec: 53875.79
Iteration:   4100, Loss function: 4.022, Average Loss: 3.697, avg. samples / sec: 53882.61
Iteration:   4100, Loss function: 2.616, Average Loss: 3.686, avg. samples / sec: 53821.43
Iteration:   4100, Loss function: 2.917, Average Loss: 3.723, avg. samples / sec: 53881.93
Iteration:   4100, Loss function: 3.048, Average Loss: 3.691, avg. samples / sec: 53884.63
Iteration:   4100, Loss function: 3.585, Average Loss: 3.694, avg. samples / sec: 53880.88
Iteration:   4100, Loss function: 3.906, Average Loss: 3.686, avg. samples / sec: 53861.66
Iteration:   4100, Loss function: 2.636, Average Loss: 3.674, avg. samples / sec: 53832.98
Iteration:   4100, Loss function: 3.810, Average Loss: 3.685, avg. samples / sec: 53846.54
Iteration:   4100, Loss function: 2.486, Average Loss: 3.711, avg. samples / sec: 53809.06
Iteration:   4100, Loss function: 2.789, Average Loss: 3.697, avg. samples / sec: 53819.23
Iteration:   4100, Loss function: 4.070, Average Loss: 3.707, avg. samples / sec: 53815.59
Iteration:   4100, Loss function: 4.026, Average Loss: 3.696, avg. samples / sec: 53794.82
Iteration:   4100, Loss function: 3.732, Average Loss: 3.686, avg. samples / sec: 53797.53
Iteration:   4100, Loss function: 4.322, Average Loss: 3.695, avg. samples / sec: 53806.84
Iteration:   4100, Loss function: 3.682, Average Loss: 3.714, avg. samples / sec: 53868.03
Iteration:   4100, Loss function: 2.856, Average Loss: 3.686, avg. samples / sec: 53673.02
:::MLL 1558640166.367 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558640166.368 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 3.027, Average Loss: 3.690, avg. samples / sec: 53513.77
Iteration:   4120, Loss function: 3.184, Average Loss: 3.702, avg. samples / sec: 53484.06
Iteration:   4120, Loss function: 3.414, Average Loss: 3.695, avg. samples / sec: 53497.46
Iteration:   4120, Loss function: 3.472, Average Loss: 3.697, avg. samples / sec: 53536.25
Iteration:   4120, Loss function: 2.740, Average Loss: 3.696, avg. samples / sec: 53512.53
Iteration:   4120, Loss function: 4.433, Average Loss: 3.700, avg. samples / sec: 53421.55
Iteration:   4120, Loss function: 3.668, Average Loss: 3.673, avg. samples / sec: 53459.79
Iteration:   4120, Loss function: 2.698, Average Loss: 3.679, avg. samples / sec: 53607.04
Iteration:   4120, Loss function: 3.351, Average Loss: 3.689, avg. samples / sec: 53406.91
Iteration:   4120, Loss function: 3.977, Average Loss: 3.696, avg. samples / sec: 53352.97
Iteration:   4120, Loss function: 2.340, Average Loss: 3.688, avg. samples / sec: 53630.09
Iteration:   4120, Loss function: 2.988, Average Loss: 3.702, avg. samples / sec: 53555.93
Iteration:   4120, Loss function: 3.540, Average Loss: 3.675, avg. samples / sec: 53562.05
Iteration:   4120, Loss function: 2.854, Average Loss: 3.703, avg. samples / sec: 53592.89
Iteration:   4120, Loss function: 4.326, Average Loss: 3.686, avg. samples / sec: 53560.14
Iteration:   4120, Loss function: 4.866, Average Loss: 3.704, avg. samples / sec: 53574.19
Iteration:   4120, Loss function: 3.392, Average Loss: 3.671, avg. samples / sec: 53565.90
Iteration:   4120, Loss function: 2.857, Average Loss: 3.677, avg. samples / sec: 53547.20
Iteration:   4120, Loss function: 4.035, Average Loss: 3.718, avg. samples / sec: 53502.96
Iteration:   4120, Loss function: 3.256, Average Loss: 3.682, avg. samples / sec: 53520.90
Iteration:   4120, Loss function: 3.263, Average Loss: 3.693, avg. samples / sec: 53559.59
Iteration:   4120, Loss function: 3.126, Average Loss: 3.688, avg. samples / sec: 53472.83
Iteration:   4120, Loss function: 2.490, Average Loss: 3.682, avg. samples / sec: 53604.94
Iteration:   4120, Loss function: 3.048, Average Loss: 3.670, avg. samples / sec: 53456.49
Iteration:   4120, Loss function: 3.078, Average Loss: 3.676, avg. samples / sec: 53500.64
Iteration:   4120, Loss function: 4.399, Average Loss: 3.683, avg. samples / sec: 53478.66
Iteration:   4120, Loss function: 2.643, Average Loss: 3.718, avg. samples / sec: 53443.77
Iteration:   4120, Loss function: 2.904, Average Loss: 3.690, avg. samples / sec: 53481.76
Iteration:   4120, Loss function: 2.629, Average Loss: 3.697, avg. samples / sec: 53415.92
Iteration:   4120, Loss function: 2.395, Average Loss: 3.707, avg. samples / sec: 53491.02
Iteration:   4140, Loss function: 3.047, Average Loss: 3.692, avg. samples / sec: 53164.42
Iteration:   4140, Loss function: 2.520, Average Loss: 3.682, avg. samples / sec: 53086.22
Iteration:   4140, Loss function: 2.605, Average Loss: 3.691, avg. samples / sec: 53141.75
Iteration:   4140, Loss function: 4.891, Average Loss: 3.689, avg. samples / sec: 53130.43
Iteration:   4140, Loss function: 2.767, Average Loss: 3.694, avg. samples / sec: 53155.66
Iteration:   4140, Loss function: 4.142, Average Loss: 3.692, avg. samples / sec: 53098.54
Iteration:   4140, Loss function: 2.278, Average Loss: 3.676, avg. samples / sec: 53157.16
Iteration:   4140, Loss function: 2.764, Average Loss: 3.663, avg. samples / sec: 53097.10
Iteration:   4140, Loss function: 3.304, Average Loss: 3.685, avg. samples / sec: 53123.38
Iteration:   4140, Loss function: 3.541, Average Loss: 3.676, avg. samples / sec: 53162.41
Iteration:   4140, Loss function: 2.319, Average Loss: 3.679, avg. samples / sec: 53020.87
Iteration:   4140, Loss function: 3.947, Average Loss: 3.687, avg. samples / sec: 53133.15
Iteration:   4140, Loss function: 3.057, Average Loss: 3.696, avg. samples / sec: 53052.20
Iteration:   4140, Loss function: 3.462, Average Loss: 3.659, avg. samples / sec: 53135.69
Iteration:   4140, Loss function: 3.231, Average Loss: 3.675, avg. samples / sec: 52976.18
Iteration:   4140, Loss function: 3.150, Average Loss: 3.674, avg. samples / sec: 53097.36
Iteration:   4140, Loss function: 2.908, Average Loss: 3.677, avg. samples / sec: 53043.50
Iteration:   4140, Loss function: 2.550, Average Loss: 3.716, avg. samples / sec: 53079.50
Iteration:   4140, Loss function: 3.449, Average Loss: 3.668, avg. samples / sec: 53132.41
Iteration:   4140, Loss function: 3.763, Average Loss: 3.672, avg. samples / sec: 53015.56
Iteration:   4140, Loss function: 4.369, Average Loss: 3.695, avg. samples / sec: 53009.68
Iteration:   4140, Loss function: 2.955, Average Loss: 3.697, avg. samples / sec: 53040.72
Iteration:   4140, Loss function: 4.178, Average Loss: 3.680, avg. samples / sec: 53147.12
Iteration:   4140, Loss function: 3.447, Average Loss: 3.694, avg. samples / sec: 53146.39
Iteration:   4140, Loss function: 4.121, Average Loss: 3.661, avg. samples / sec: 53020.51
Iteration:   4140, Loss function: 3.665, Average Loss: 3.670, avg. samples / sec: 53034.77
Iteration:   4140, Loss function: 2.909, Average Loss: 3.709, avg. samples / sec: 53111.56
Iteration:   4140, Loss function: 2.433, Average Loss: 3.683, avg. samples / sec: 53057.78
Iteration:   4140, Loss function: 2.800, Average Loss: 3.676, avg. samples / sec: 53076.02
Iteration:   4140, Loss function: 4.116, Average Loss: 3.705, avg. samples / sec: 53110.42
Iteration:   4160, Loss function: 2.549, Average Loss: 3.674, avg. samples / sec: 53969.00
Iteration:   4160, Loss function: 2.254, Average Loss: 3.683, avg. samples / sec: 53893.57
Iteration:   4160, Loss function: 3.255, Average Loss: 3.677, avg. samples / sec: 53964.85
Iteration:   4160, Loss function: 3.508, Average Loss: 3.689, avg. samples / sec: 53953.43
Iteration:   4160, Loss function: 3.648, Average Loss: 3.679, avg. samples / sec: 54040.80
Iteration:   4160, Loss function: 3.371, Average Loss: 3.688, avg. samples / sec: 53967.00
Iteration:   4160, Loss function: 3.501, Average Loss: 3.673, avg. samples / sec: 53948.63
Iteration:   4160, Loss function: 2.520, Average Loss: 3.676, avg. samples / sec: 53995.45
Iteration:   4160, Loss function: 3.116, Average Loss: 3.672, avg. samples / sec: 53978.27
Iteration:   4160, Loss function: 3.435, Average Loss: 3.668, avg. samples / sec: 53965.16
Iteration:   4160, Loss function: 4.616, Average Loss: 3.670, avg. samples / sec: 54026.85
Iteration:   4160, Loss function: 3.537, Average Loss: 3.661, avg. samples / sec: 53989.89
Iteration:   4160, Loss function: 3.537, Average Loss: 3.681, avg. samples / sec: 53938.17
Iteration:   4160, Loss function: 4.542, Average Loss: 3.660, avg. samples / sec: 53955.20
Iteration:   4160, Loss function: 3.999, Average Loss: 3.703, avg. samples / sec: 53988.44
Iteration:   4160, Loss function: 4.479, Average Loss: 3.688, avg. samples / sec: 53954.71
Iteration:   4160, Loss function: 3.025, Average Loss: 3.667, avg. samples / sec: 53917.84
Iteration:   4160, Loss function: 2.934, Average Loss: 3.653, avg. samples / sec: 53738.80
Iteration:   4160, Loss function: 3.930, Average Loss: 3.692, avg. samples / sec: 53903.44
Iteration:   4160, Loss function: 3.021, Average Loss: 3.692, avg. samples / sec: 53929.85
Iteration:   4160, Loss function: 3.775, Average Loss: 3.654, avg. samples / sec: 53904.27
Iteration:   4160, Loss function: 3.573, Average Loss: 3.688, avg. samples / sec: 53919.39
Iteration:   4160, Loss function: 4.635, Average Loss: 3.666, avg. samples / sec: 53906.02
Iteration:   4160, Loss function: 3.205, Average Loss: 3.663, avg. samples / sec: 53942.60
Iteration:   4160, Loss function: 3.442, Average Loss: 3.683, avg. samples / sec: 53631.62
Iteration:   4160, Loss function: 3.237, Average Loss: 3.710, avg. samples / sec: 53908.41
Iteration:   4160, Loss function: 2.680, Average Loss: 3.662, avg. samples / sec: 53920.50
Iteration:   4160, Loss function: 2.821, Average Loss: 3.695, avg. samples / sec: 53971.96
Iteration:   4160, Loss function: 2.918, Average Loss: 3.676, avg. samples / sec: 53903.88
Iteration:   4160, Loss function: 2.891, Average Loss: 3.677, avg. samples / sec: 53924.54
Iteration:   4180, Loss function: 2.611, Average Loss: 3.665, avg. samples / sec: 53907.57
Iteration:   4180, Loss function: 3.445, Average Loss: 3.679, avg. samples / sec: 53940.66
Iteration:   4180, Loss function: 3.341, Average Loss: 3.675, avg. samples / sec: 54244.71
Iteration:   4180, Loss function: 3.685, Average Loss: 3.678, avg. samples / sec: 53864.75
Iteration:   4180, Loss function: 4.077, Average Loss: 3.683, avg. samples / sec: 53876.78
Iteration:   4180, Loss function: 3.193, Average Loss: 3.668, avg. samples / sec: 53910.06
Iteration:   4180, Loss function: 3.563, Average Loss: 3.670, avg. samples / sec: 53825.52
Iteration:   4180, Loss function: 2.891, Average Loss: 3.652, avg. samples / sec: 54116.02
Iteration:   4180, Loss function: 3.547, Average Loss: 3.675, avg. samples / sec: 53840.72
Iteration:   4180, Loss function: 2.642, Average Loss: 3.664, avg. samples / sec: 53893.20
Iteration:   4180, Loss function: 3.608, Average Loss: 3.662, avg. samples / sec: 53842.07
Iteration:   4180, Loss function: 3.908, Average Loss: 3.648, avg. samples / sec: 53930.92
Iteration:   4180, Loss function: 3.861, Average Loss: 3.654, avg. samples / sec: 53891.24
Iteration:   4180, Loss function: 4.554, Average Loss: 3.689, avg. samples / sec: 53922.48
Iteration:   4180, Loss function: 2.990, Average Loss: 3.688, avg. samples / sec: 53919.61
Iteration:   4180, Loss function: 2.925, Average Loss: 3.669, avg. samples / sec: 53820.09
Iteration:   4180, Loss function: 3.608, Average Loss: 3.655, avg. samples / sec: 53926.94
Iteration:   4180, Loss function: 4.274, Average Loss: 3.656, avg. samples / sec: 53878.10
Iteration:   4180, Loss function: 2.427, Average Loss: 3.654, avg. samples / sec: 53926.67
Iteration:   4180, Loss function: 4.513, Average Loss: 3.661, avg. samples / sec: 53910.35
Iteration:   4180, Loss function: 3.039, Average Loss: 3.664, avg. samples / sec: 53860.57
Iteration:   4180, Loss function: 3.820, Average Loss: 3.704, avg. samples / sec: 53871.09
Iteration:   4180, Loss function: 3.364, Average Loss: 3.681, avg. samples / sec: 53883.60
Iteration:   4180, Loss function: 3.426, Average Loss: 3.668, avg. samples / sec: 53925.66
Iteration:   4180, Loss function: 3.561, Average Loss: 3.706, avg. samples / sec: 53905.24
Iteration:   4180, Loss function: 3.920, Average Loss: 3.663, avg. samples / sec: 53884.11
Iteration:   4180, Loss function: 2.231, Average Loss: 3.671, avg. samples / sec: 53844.46
Iteration:   4180, Loss function: 2.538, Average Loss: 3.684, avg. samples / sec: 53890.69
Iteration:   4180, Loss function: 2.778, Average Loss: 3.670, avg. samples / sec: 53894.77
Iteration:   4180, Loss function: 4.709, Average Loss: 3.693, avg. samples / sec: 53870.97
:::MLL 1558640168.561 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558640168.562 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558640168.631 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=2.49s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23041
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39114
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23612
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05980
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24229
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32256
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33953
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36755
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53101
Current AP: 0.23041 AP goal: 0.23000
:::MLL 1558640172.408 eval_accuracy: {"value": 0.23040504682767693, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558640172.461 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558640172.468 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558640173.019 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 07:36:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:09 PM
ENDING TIMING RUN AT 2019-05-23 07:36:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:19 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:07 PM
ENDING TIMING RUN AT 2019-05-23 07:36:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:33:04 PM
ENDING TIMING RUN AT 2019-05-23 07:36:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:10 PM
ENDING TIMING RUN AT 2019-05-23 07:36:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:33:11 PM
ENDING TIMING RUN AT 2019-05-23 07:36:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:10 PM
ENDING TIMING RUN AT 2019-05-23 07:36:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:06 PM
ENDING TIMING RUN AT 2019-05-23 07:36:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:12 PM
ENDING TIMING RUN AT 2019-05-23 07:36:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 07:33:07 PM
ENDING TIMING RUN AT 2019-05-23 07:36:19 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:07 PM
ENDING TIMING RUN AT 2019-05-23 07:36:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:04 PM
ENDING TIMING RUN AT 2019-05-23 07:36:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:03 PM
ENDING TIMING RUN AT 2019-05-23 07:36:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:12 PM
ENDING TIMING RUN AT 2019-05-23 07:36:20 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:08 PM
ENDING TIMING RUN AT 2019-05-23 07:36:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:06 PM
ENDING TIMING RUN AT 2019-05-23 07:36:19 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:07 PM
ENDING TIMING RUN AT 2019-05-23 07:36:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:06 PM
ENDING TIMING RUN AT 2019-05-23 07:36:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:10 PM
ENDING TIMING RUN AT 2019-05-23 07:36:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:03 PM
ENDING TIMING RUN AT 2019-05-23 07:36:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:10 PM
ENDING TIMING RUN AT 2019-05-23 07:36:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:05 PM
ENDING TIMING RUN AT 2019-05-23 07:36:18 PM
RESULT,SINGLE_STAGE_DETECTOR,,192,nvidia,2019-05-23 07:33:06 PM
