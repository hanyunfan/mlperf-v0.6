Beginning trial 5 of 5
Gathering sys log on sc-sdgx-407
:::MLL 1558641008.435 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558641008.436 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558641008.437 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558641008.438 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558641008.438 submission_platform: {"value": "30xDGX-1 with V100", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558641008.439 submission_entry: {"value": "{'hardware': 'DGX-1 with V100', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.2 LTS / NVIDIA DGX Server 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz', 'num_cores': '40', 'num_vcpus': '80', 'accelerator': 'Tesla V100-SXM2-16GB', 'num_accelerators': '8', 'sys_mem_size': '503 GB', 'sys_storage_type': 'SATA SSD', 'sys_storage_size': '1x 7T + 1x 446.6G', 'cpu_accel_interconnect': 'QPI', 'network_card': 'Mellanox Technologies MT27700 Family [ConnectX-4]', 'num_network_cards': '4', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558641008.440 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558641008.441 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558641054.511 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641061.072 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641065.036 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641053.263 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641053.174 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641060.689 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641054.920 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641052.776 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641056.091 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641056.317 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641053.398 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641057.726 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641051.622 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641054.956 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641055.522 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641055.684 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641053.991 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641053.333 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641058.049 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641053.207 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641053.502 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641052.659 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641058.340 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641052.899 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641051.490 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641054.343 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641055.635 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641055.301 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641057.826 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558641051.362 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node sc-sdgx-407
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-408
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-414
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-407
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-415
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-408
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-407 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-416
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-414
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-408 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-415
Launching on node sc-sdgx-417
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-414 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-418
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-415 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-416
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-423
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-417
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-416 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-418
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-424
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-417 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-418 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-425
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-423
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-426
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-424
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-423 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-425
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-427
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-424 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-433
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-425 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-426
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-434
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-427
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-426 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
Launching on node sc-sdgx-435
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-433
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-427 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-434
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-436
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-433 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-434 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ set +x
Launching on node sc-sdgx-441
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-435
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-442
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-435 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-436
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-443
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-441
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-436 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-444
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-441 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-442
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-628
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-443
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-442 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
Launching on node sc-sdgx-629
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-444
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-443 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-630
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-628
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-444 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node sc-sdgx-631
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-629
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-628 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-629 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-630
Launching on node sc-sdgx-632
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-630 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ set +x
Launching on node sc-sdgx-638
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-631
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-632
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-639
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-631 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-632 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-640
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-638
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-639
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-638 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
Launching on node sc-sdgx-641
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-639 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node sc-sdgx-646
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-640
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-640 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-641
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-646
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-641 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-646 docker exec -e DGXSYSTEM=DGX1_multi_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154' -e SLURM_JOB_ID=326639 -e SLURM_NTASKS_PER_NODE=8 cont_326639 ./run_and_time.sh
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:50:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:50:58 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:51:02 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:51 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:50:56 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:54 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:50:53 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:50:55 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 326639 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154
STARTING TIMING RUN AT 2019-05-23 07:51:01 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:54 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:50:55 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:51 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:55 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:56 PM
STARTING TIMING RUN AT 2019-05-23 07:50:58 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:50:54 PM
running benchmark
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:54 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:53 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:50:54 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:54 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:50:52 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:50:53 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 07:50:57 PM
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:57 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 07:50:58 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2019-05-23 07:51:06 PM
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:58 PM
running benchmark
+ NUMEPOCHS=80
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 07:50:55 PM
+ echo 'running benchmark'
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 07:50:53 PM
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 07:50:56 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=172.22.0.208 --master_port=5154 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558641059.305 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.305 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.305 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.305 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.306 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.306 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.306 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.307 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641059.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.474 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.474 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.474 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.534 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.535 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.535 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.535 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.536 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.536 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.536 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.536 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.048 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.048 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.049 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.049 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.049 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.049 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.050 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558641058.051 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641062.051 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.051 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.051 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.052 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.053 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.053 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.053 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.053 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641057.238 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.238 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.238 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.240 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.240 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.240 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.240 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.240 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641061.171 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.171 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.172 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.172 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.172 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.172 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.173 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.173 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641057.990 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.990 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.990 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.991 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.992 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641056.320 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641056.320 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641056.321 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641056.322 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641056.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641056.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641056.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641056.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641062.503 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.503 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.503 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.503 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.503 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.503 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.504 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.505 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.237 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.238 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.238 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558641058.239 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.239 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.239 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.239 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558641058.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641057.779 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.779 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.780 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.629 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.629 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.629 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.780 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.780 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.781 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.781 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.630 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.630 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.630 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.781 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641062.630 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641062.633 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558641055.959 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.959 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.959 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.959 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.960 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.960 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.960 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.961 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641066.307 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641066.307 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641066.307 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641066.308 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641066.308 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641066.308 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641066.308 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641061.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641066.309 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641060.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.093 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.093 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.093 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.094 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641060.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.259 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641060.260 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.260 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.261 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.261 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558641055.765 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.765 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.765 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.766 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.766 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641055.767 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641055.767 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641055.768 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641059.741 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.741 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.741 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.741 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.741 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.741 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.742 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641059.742 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641057.295 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.295 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.295 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.296 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.296 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.297 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641057.297 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641057.297 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641070.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641070.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641070.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641070.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641070.337 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641070.337 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641070.337 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641070.339 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641065.852 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641065.852 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641065.853 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641065.853 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641065.853 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641065.853 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641065.854 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641065.854 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641063.004 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641063.004 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641063.004 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641063.005 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641063.005 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641063.005 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641063.005 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641063.006 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.106 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.106 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.106 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.109 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.864 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.864 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.864 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.865 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.866 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.866 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.866 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.867 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641060.591 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.591 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.592 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.592 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.592 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.592 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.593 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.593 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.679 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.680 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.680 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.681 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.682 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.682 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.682 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.682 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.098 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.098 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.098 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.099 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.099 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.099 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641058.099 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641058.101 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558641060.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558641060.406 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
5 Using seed = 1389992210
1 Using seed = 1389992206
0 Using seed = 1389992205
:::MLL 1558641075.627 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
7 Using seed = 1389992212
6 Using seed = 1389992211
3 Using seed = 1389992208
4 Using seed = 1389992209
13 Using seed = 1389992218
15 Using seed = 1389992220
12 Using seed = 1389992217
14 Using seed = 1389992219
9 Using seed = 1389992214
11 Using seed = 1389992216
10 Using seed = 1389992215
8 Using seed = 1389992213
18 Using seed = 1389992223
17 Using seed = 1389992222
16 Using seed = 1389992221
21 Using seed = 1389992226
19 Using seed = 1389992224
22 Using seed = 1389992227
23 Using seed = 1389992228
20 Using seed = 1389992225
24 Using seed = 1389992229
25 Using seed = 1389992230
26 Using seed = 1389992231
29 Using seed = 1389992234
27 Using seed = 1389992232
31 Using seed = 1389992236
30 Using seed = 1389992235
28 Using seed = 1389992233
39 Using seed = 1389992244
37 Using seed = 1389992242
36 Using seed = 1389992241
38 Using seed = 1389992243
33 Using seed = 1389992238
35 Using seed = 1389992240
34 Using seed = 1389992239
32 Using seed = 1389992237
46 Using seed = 1389992251
44 Using seed = 1389992249
45 Using seed = 1389992250
47 Using seed = 1389992252
41 Using seed = 1389992246
42 Using seed = 1389992247
40 Using seed = 1389992245
43 Using seed = 1389992248
49 Using seed = 1389992254
48 Using seed = 1389992253
50 Using seed = 1389992255
53 Using seed = 1389992258
51 Using seed = 1389992256
55 Using seed = 1389992260
54 Using seed = 1389992259
52 Using seed = 1389992257
57 Using seed = 1389992262
58 Using seed = 1389992263
56 Using seed = 1389992261
61 Using seed = 1389992266
63 Using seed = 1389992268
62 Using seed = 1389992267
59 Using seed = 1389992264
60 Using seed = 1389992265
64 Using seed = 1389992269
66 Using seed = 1389992271
65 Using seed = 1389992270
67 Using seed = 1389992272
69 Using seed = 1389992274
71 Using seed = 1389992276
70 Using seed = 1389992275
68 Using seed = 1389992273
79 Using seed = 1389992284
77 Using seed = 1389992282
76 Using seed = 1389992281
74 Using seed = 1389992279
75 Using seed = 1389992280
72 Using seed = 1389992277
73 Using seed = 1389992278
78 Using seed = 1389992283
87 Using seed = 1389992292
84 Using seed = 1389992289
85 Using seed = 1389992290
86 Using seed = 1389992291
82 Using seed = 1389992287
81 Using seed = 1389992286
80 Using seed = 1389992285
83 Using seed = 1389992288
89 Using seed = 1389992294
88 Using seed = 1389992293
90 Using seed = 1389992295
93 Using seed = 1389992298
91 Using seed = 1389992296
94 Using seed = 1389992299
95 Using seed = 1389992300
92 Using seed = 1389992297
100 Using seed = 1389992305
101 Using seed = 1389992306
102 Using seed = 1389992307
103 Using seed = 1389992308
98 Using seed = 1389992303
99 Using seed = 1389992304
97 Using seed = 1389992302
96 Using seed = 1389992301
104 Using seed = 1389992309
105 Using seed = 1389992310
106 Using seed = 1389992311
109 Using seed = 1389992314
110 Using seed = 1389992315
111 Using seed = 1389992316
107 Using seed = 1389992312
108 Using seed = 1389992313
115 Using seed = 1389992320
113 Using seed = 1389992318
112 Using seed = 1389992317
114 Using seed = 1389992319
119 Using seed = 1389992324
118 Using seed = 1389992323
116 Using seed = 1389992321
117 Using seed = 1389992322
121 Using seed = 1389992326
122 Using seed = 1389992327
123 Using seed = 1389992328
120 Using seed = 1389992325
127 Using seed = 1389992332
125 Using seed = 1389992330
126 Using seed = 1389992331
124 Using seed = 1389992329
130 Using seed = 1389992335
131 Using seed = 1389992336
129 Using seed = 1389992334
128 Using seed = 1389992333
135 Using seed = 1389992340
134 Using seed = 1389992339
132 Using seed = 1389992337
133 Using seed = 1389992338
142 Using seed = 1389992347
143 Using seed = 1389992348
140 Using seed = 1389992345
141 Using seed = 1389992346
139 Using seed = 1389992344
136 Using seed = 1389992341
137 Using seed = 1389992342
138 Using seed = 1389992343
145 Using seed = 1389992350
147 Using seed = 1389992352
146 Using seed = 1389992351
144 Using seed = 1389992349
151 Using seed = 1389992356
150 Using seed = 1389992355
149 Using seed = 1389992354
148 Using seed = 1389992353
157 Using seed = 1389992362
158 Using seed = 1389992363
159 Using seed = 1389992364
156 Using seed = 1389992361
152 Using seed = 1389992357
155 Using seed = 1389992360
153 Using seed = 1389992358
154 Using seed = 1389992359
166 Using seed = 1389992371
165 Using seed = 1389992370
164 Using seed = 1389992369
167 Using seed = 1389992372
161 Using seed = 1389992366
160 Using seed = 1389992365
162 Using seed = 1389992367
163 Using seed = 1389992368
174 Using seed = 1389992379
173 Using seed = 1389992378
175 Using seed = 1389992380
172 Using seed = 1389992377
169 Using seed = 1389992374
171 Using seed = 1389992376
168 Using seed = 1389992373
170 Using seed = 1389992375
179 Using seed = 1389992384
178 Using seed = 1389992383
176 Using seed = 1389992381
177 Using seed = 1389992382
181 Using seed = 1389992386
182 Using seed = 1389992387
180 Using seed = 1389992385
183 Using seed = 1389992388
186 Using seed = 1389992391
184 Using seed = 1389992389
185 Using seed = 1389992390
189 Using seed = 1389992394
187 Using seed = 1389992392
191 Using seed = 1389992396
190 Using seed = 1389992395
188 Using seed = 1389992393
199 Using seed = 1389992404
198 Using seed = 1389992403
196 Using seed = 1389992401
197 Using seed = 1389992402
195 Using seed = 1389992400
192 Using seed = 1389992397
194 Using seed = 1389992399
193 Using seed = 1389992398
200 Using seed = 1389992405
202 Using seed = 1389992407
203 Using seed = 1389992408
201 Using seed = 1389992406
206 Using seed = 1389992411
205 Using seed = 1389992410
207 Using seed = 1389992412
204 Using seed = 1389992409
214 Using seed = 1389992419
212 Using seed = 1389992417
215 Using seed = 1389992420
213 Using seed = 1389992418
211 Using seed = 1389992416
208 Using seed = 1389992413
210 Using seed = 1389992415
209 Using seed = 1389992414
221 Using seed = 1389992426
222 Using seed = 1389992427
220 Using seed = 1389992425
223 Using seed = 1389992428
217 Using seed = 1389992422
219 Using seed = 1389992424
218 Using seed = 1389992423
216 Using seed = 1389992421
229 Using seed = 1389992434
230 Using seed = 1389992435
231 Using seed = 1389992436
228 Using seed = 1389992433
224 Using seed = 1389992429
225 Using seed = 1389992430
227 Using seed = 1389992432
226 Using seed = 1389992431
234 Using seed = 1389992439
233 Using seed = 1389992438
232 Using seed = 1389992437
235 Using seed = 1389992440
239 Using seed = 1389992444
236 Using seed = 1389992441
237 Using seed = 1389992442
238 Using seed = 1389992443
2 Using seed = 1389992207
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558641080.532 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558641080.532 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
:::MLL 1558641080.539 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558641080.539 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
Delaying allreduces to the end of backward()
:::MLL 1558641080.540 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
Delaying allreduces to the end of backward()
:::MLL 1558641080.540 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558641089.495 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558641089.495 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
Done (t=0.48s)
creating index...
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
Done (t=0.49s)
creating index...
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
Done (t=0.50s)
creating index...
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
Done (t=0.50s)
creating index...
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.54s)
creating index...
Done (t=0.54s)
creating index...
time_check a: 1558641081.319569349
time_check a: 1558641088.462990046
time_check a: 1558641083.874835253
time_check a: 1558641085.985136747
time_check a: 1558641084.038561106
time_check a: 1558641083.558547735
time_check a: 1558641086.680668831
time_check a: 1558641081.977364779
time_check a: 1558641085.675757408
time_check a: 1558641083.402453661
time_check a: 1558641085.835890293
time_check a: 1558641085.306164265
time_check a: 1558641088.259536028
time_check a: 1558641086.879164934
time_check a: 1558641084.430005550
time_check a: 1558641091.344740391
time_check a: 1558641095.841420174
time_check a: 1558641082.847801924
time_check a: 1558641081.580787659
time_check a: 1558641083.413408279
time_check a: 1558641085.312634945
time_check a: 1558641084.296766043
time_check a: 1558641091.916103601
time_check a: 1558641087.841100216
time_check a: 1558641083.013406038
time_check a: 1558641088.185121059
time_check a: 1558641083.716104031
time_check a: 1558641085.579792976
time_check a: 1558641083.930930853
time_check a: 1558641085.500689983
time_check b: 1558641087.547879457
time_check b: 1558641089.499218941
time_check b: 1558641085.027059317
time_check b: 1558641085.258896589
time_check b: 1558641090.567189217
time_check b: 1558641087.754045486
time_check b: 1558641087.275370598
time_check b: 1558641091.969795942
time_check b: 1558641087.131790161
time_check b: 1558641087.630355597
time_check b: 1558641091.555628777
time_check b: 1558641088.015018702
time_check b: 1558641086.569122791
time_check b: 1558641088.156015873
time_check b: 1558641092.214720249
time_check b: 1558641091.892968416
time_check b: 1558641089.289828062
time_check b: 1558641087.147959948
time_check b: 1558641085.726962805
time_check b: 1558641087.440385342
time_check b: 1558641089.200280666
time_check b: 1558641089.443911076
time_check b: 1558641089.760412931
time_check b: 1558641095.106631279
time_check b: 1558641089.078948021
time_check b: 1558641090.473954916
time_check b: 1558641099.622409105
time_check b: 1558641095.696331739
time_check b: 1558641086.794643879
time_check b: 1558641089.138395548
:::MLL 1558641096.223 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558641096.224 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 23.357, Average Loss: 0.023, avg. samples / sec: 132.66
Iteration:      0, Loss function: 22.025, Average Loss: 0.022, avg. samples / sec: 132.95
Iteration:      0, Loss function: 22.641, Average Loss: 0.023, avg. samples / sec: 135.45
Iteration:      0, Loss function: 22.668, Average Loss: 0.023, avg. samples / sec: 133.21
Iteration:      0, Loss function: 22.575, Average Loss: 0.023, avg. samples / sec: 133.23
Iteration:      0, Loss function: 22.269, Average Loss: 0.022, avg. samples / sec: 133.99
Iteration:      0, Loss function: 22.583, Average Loss: 0.023, avg. samples / sec: 134.80
Iteration:      0, Loss function: 22.214, Average Loss: 0.022, avg. samples / sec: 154.30
Iteration:      0, Loss function: 23.236, Average Loss: 0.023, avg. samples / sec: 131.92
Iteration:      0, Loss function: 22.729, Average Loss: 0.023, avg. samples / sec: 131.01
Iteration:      0, Loss function: 22.682, Average Loss: 0.023, avg. samples / sec: 131.36
Iteration:      0, Loss function: 22.620, Average Loss: 0.023, avg. samples / sec: 168.13
Iteration:      0, Loss function: 23.163, Average Loss: 0.023, avg. samples / sec: 131.50
Iteration:      0, Loss function: 22.965, Average Loss: 0.023, avg. samples / sec: 132.45
Iteration:      0, Loss function: 22.271, Average Loss: 0.022, avg. samples / sec: 132.88
Iteration:      0, Loss function: 22.684, Average Loss: 0.023, avg. samples / sec: 132.04
Iteration:      0, Loss function: 22.807, Average Loss: 0.023, avg. samples / sec: 133.94
Iteration:      0, Loss function: 22.635, Average Loss: 0.023, avg. samples / sec: 156.39
Iteration:      0, Loss function: 22.181, Average Loss: 0.022, avg. samples / sec: 132.36
Iteration:      0, Loss function: 22.171, Average Loss: 0.022, avg. samples / sec: 133.54
Iteration:      0, Loss function: 22.431, Average Loss: 0.022, avg. samples / sec: 132.90
Iteration:      0, Loss function: 22.971, Average Loss: 0.023, avg. samples / sec: 134.14
Iteration:      0, Loss function: 22.470, Average Loss: 0.022, avg. samples / sec: 131.09
Iteration:      0, Loss function: 22.513, Average Loss: 0.023, avg. samples / sec: 131.81
Iteration:      0, Loss function: 21.967, Average Loss: 0.022, avg. samples / sec: 134.77
Iteration:      0, Loss function: 22.716, Average Loss: 0.023, avg. samples / sec: 131.22
Iteration:      0, Loss function: 22.362, Average Loss: 0.022, avg. samples / sec: 134.49
Iteration:      0, Loss function: 22.499, Average Loss: 0.022, avg. samples / sec: 130.64
Iteration:      0, Loss function: 23.821, Average Loss: 0.024, avg. samples / sec: 132.71
Iteration:      0, Loss function: 22.251, Average Loss: 0.022, avg. samples / sec: 130.39
Iteration:     20, Loss function: 21.112, Average Loss: 0.445, avg. samples / sec: 33335.32
Iteration:     20, Loss function: 20.335, Average Loss: 0.445, avg. samples / sec: 32312.74
Iteration:     20, Loss function: 20.676, Average Loss: 0.446, avg. samples / sec: 31550.66
Iteration:     20, Loss function: 20.175, Average Loss: 0.443, avg. samples / sec: 32278.52
Iteration:     20, Loss function: 20.987, Average Loss: 0.442, avg. samples / sec: 36772.26
Iteration:     20, Loss function: 20.509, Average Loss: 0.444, avg. samples / sec: 32027.73
Iteration:     20, Loss function: 21.002, Average Loss: 0.441, avg. samples / sec: 31138.12
Iteration:     20, Loss function: 20.816, Average Loss: 0.439, avg. samples / sec: 32596.49
Iteration:     20, Loss function: 20.527, Average Loss: 0.446, avg. samples / sec: 31141.95
Iteration:     20, Loss function: 20.298, Average Loss: 0.446, avg. samples / sec: 32252.35
Iteration:     20, Loss function: 20.251, Average Loss: 0.443, avg. samples / sec: 31126.66
Iteration:     20, Loss function: 20.121, Average Loss: 0.442, avg. samples / sec: 32716.28
Iteration:     20, Loss function: 22.632, Average Loss: 0.446, avg. samples / sec: 31150.63
Iteration:     20, Loss function: 21.261, Average Loss: 0.445, avg. samples / sec: 31627.62
Iteration:     20, Loss function: 20.211, Average Loss: 0.443, avg. samples / sec: 32943.56
Iteration:     20, Loss function: 20.321, Average Loss: 0.441, avg. samples / sec: 32967.79
Iteration:     20, Loss function: 20.593, Average Loss: 0.440, avg. samples / sec: 32965.35
Iteration:     20, Loss function: 20.788, Average Loss: 0.443, avg. samples / sec: 31694.51
Iteration:     20, Loss function: 20.781, Average Loss: 0.448, avg. samples / sec: 30993.73
Iteration:     20, Loss function: 20.668, Average Loss: 0.444, avg. samples / sec: 31918.81
Iteration:     20, Loss function: 20.332, Average Loss: 0.446, avg. samples / sec: 32396.18
Iteration:     20, Loss function: 21.079, Average Loss: 0.443, avg. samples / sec: 32224.75
Iteration:     20, Loss function: 20.944, Average Loss: 0.443, avg. samples / sec: 32390.29
Iteration:     20, Loss function: 20.568, Average Loss: 0.443, avg. samples / sec: 32502.41
Iteration:     20, Loss function: 21.659, Average Loss: 0.445, avg. samples / sec: 32737.00
Iteration:     20, Loss function: 20.254, Average Loss: 0.443, avg. samples / sec: 32317.27
Iteration:     20, Loss function: 20.605, Average Loss: 0.444, avg. samples / sec: 32620.27
Iteration:     20, Loss function: 20.699, Average Loss: 0.446, avg. samples / sec: 33558.72
Iteration:     20, Loss function: 20.678, Average Loss: 0.443, avg. samples / sec: 32529.11
Iteration:     20, Loss function: 20.282, Average Loss: 0.450, avg. samples / sec: 31566.94
Iteration:     40, Loss function: 19.260, Average Loss: 0.835, avg. samples / sec: 48379.23
Iteration:     40, Loss function: 19.692, Average Loss: 0.833, avg. samples / sec: 48143.95
Iteration:     40, Loss function: 19.306, Average Loss: 0.833, avg. samples / sec: 48024.86
Iteration:     40, Loss function: 19.189, Average Loss: 0.833, avg. samples / sec: 48380.65
Iteration:     40, Loss function: 19.416, Average Loss: 0.835, avg. samples / sec: 48035.47
Iteration:     40, Loss function: 19.628, Average Loss: 0.838, avg. samples / sec: 48225.80
Iteration:     40, Loss function: 19.140, Average Loss: 0.832, avg. samples / sec: 48280.97
Iteration:     40, Loss function: 18.600, Average Loss: 0.832, avg. samples / sec: 48486.99
Iteration:     40, Loss function: 18.225, Average Loss: 0.828, avg. samples / sec: 47932.80
Iteration:     40, Loss function: 18.702, Average Loss: 0.841, avg. samples / sec: 48660.39
Iteration:     40, Loss function: 19.916, Average Loss: 0.840, avg. samples / sec: 47935.51
Iteration:     40, Loss function: 18.689, Average Loss: 0.839, avg. samples / sec: 48200.33
Iteration:     40, Loss function: 19.093, Average Loss: 0.832, avg. samples / sec: 47857.78
Iteration:     40, Loss function: 18.665, Average Loss: 0.836, avg. samples / sec: 48339.79
Iteration:     40, Loss function: 18.938, Average Loss: 0.836, avg. samples / sec: 47902.64
Iteration:     40, Loss function: 19.064, Average Loss: 0.828, avg. samples / sec: 48058.61
Iteration:     40, Loss function: 18.740, Average Loss: 0.833, avg. samples / sec: 47812.88
Iteration:     40, Loss function: 18.998, Average Loss: 0.835, avg. samples / sec: 47860.21
Iteration:     40, Loss function: 18.977, Average Loss: 0.835, avg. samples / sec: 47935.98
Iteration:     40, Loss function: 18.692, Average Loss: 0.837, avg. samples / sec: 47893.36
Iteration:     40, Loss function: 18.868, Average Loss: 0.834, avg. samples / sec: 48272.09
Iteration:     40, Loss function: 18.342, Average Loss: 0.838, avg. samples / sec: 47777.27
Iteration:     40, Loss function: 19.167, Average Loss: 0.834, avg. samples / sec: 47911.84
Iteration:     40, Loss function: 18.658, Average Loss: 0.833, avg. samples / sec: 47796.60
Iteration:     40, Loss function: 18.868, Average Loss: 0.832, avg. samples / sec: 48175.86
Iteration:     40, Loss function: 20.045, Average Loss: 0.839, avg. samples / sec: 47488.69
Iteration:     40, Loss function: 19.979, Average Loss: 0.836, avg. samples / sec: 47735.37
Iteration:     40, Loss function: 18.920, Average Loss: 0.838, avg. samples / sec: 47238.20
Iteration:     40, Loss function: 20.800, Average Loss: 0.837, avg. samples / sec: 47387.40
Iteration:     40, Loss function: 18.725, Average Loss: 0.831, avg. samples / sec: 47043.62
Iteration:     60, Loss function: 14.493, Average Loss: 1.096, avg. samples / sec: 51119.44
Iteration:     60, Loss function: 12.166, Average Loss: 1.101, avg. samples / sec: 51476.20
Iteration:     60, Loss function: 12.433, Average Loss: 1.101, avg. samples / sec: 52077.59
Iteration:     60, Loss function: 12.792, Average Loss: 1.095, avg. samples / sec: 51297.75
Iteration:     60, Loss function: 14.228, Average Loss: 1.105, avg. samples / sec: 51304.38
Iteration:     60, Loss function: 12.581, Average Loss: 1.094, avg. samples / sec: 51295.12
Iteration:     60, Loss function: 12.432, Average Loss: 1.100, avg. samples / sec: 51294.71
Iteration:     60, Loss function: 11.217, Average Loss: 1.095, avg. samples / sec: 52033.21
Iteration:     60, Loss function: 12.544, Average Loss: 1.099, avg. samples / sec: 51125.09
Iteration:     60, Loss function: 11.570, Average Loss: 1.101, avg. samples / sec: 51328.41
Iteration:     60, Loss function: 11.720, Average Loss: 1.100, avg. samples / sec: 51146.86
Iteration:     60, Loss function: 13.122, Average Loss: 1.102, avg. samples / sec: 50917.58
Iteration:     60, Loss function: 11.405, Average Loss: 1.101, avg. samples / sec: 51344.90
Iteration:     60, Loss function: 12.051, Average Loss: 1.104, avg. samples / sec: 51254.00
Iteration:     60, Loss function: 11.697, Average Loss: 1.092, avg. samples / sec: 51411.08
Iteration:     60, Loss function: 11.974, Average Loss: 1.103, avg. samples / sec: 51168.17
Iteration:     60, Loss function: 11.676, Average Loss: 1.092, avg. samples / sec: 51067.90
Iteration:     60, Loss function: 13.362, Average Loss: 1.102, avg. samples / sec: 51139.75
Iteration:     60, Loss function: 12.308, Average Loss: 1.097, avg. samples / sec: 51243.79
Iteration:     60, Loss function: 11.792, Average Loss: 1.087, avg. samples / sec: 51115.78
Iteration:     60, Loss function: 11.367, Average Loss: 1.097, avg. samples / sec: 51019.11
Iteration:     60, Loss function: 11.027, Average Loss: 1.099, avg. samples / sec: 51099.44
Iteration:     60, Loss function: 12.833, Average Loss: 1.107, avg. samples / sec: 51155.99
Iteration:     60, Loss function: 11.059, Average Loss: 1.089, avg. samples / sec: 52218.28
Iteration:     60, Loss function: 12.377, Average Loss: 1.100, avg. samples / sec: 51188.60
Iteration:     60, Loss function: 12.553, Average Loss: 1.101, avg. samples / sec: 51953.79
Iteration:     60, Loss function: 13.966, Average Loss: 1.102, avg. samples / sec: 51714.53
Iteration:     60, Loss function: 11.660, Average Loss: 1.098, avg. samples / sec: 51084.77
Iteration:     60, Loss function: 12.196, Average Loss: 1.101, avg. samples / sec: 50955.10
Iteration:     60, Loss function: 12.558, Average Loss: 1.090, avg. samples / sec: 50865.22
:::MLL 1558641099.822 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558641099.823 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 9.953, Average Loss: 1.296, avg. samples / sec: 52434.03
Iteration:     80, Loss function: 10.487, Average Loss: 1.300, avg. samples / sec: 52164.39
Iteration:     80, Loss function: 10.267, Average Loss: 1.290, avg. samples / sec: 52640.14
Iteration:     80, Loss function: 10.591, Average Loss: 1.296, avg. samples / sec: 52079.59
Iteration:     80, Loss function: 10.301, Average Loss: 1.301, avg. samples / sec: 52147.67
Iteration:     80, Loss function: 9.243, Average Loss: 1.298, avg. samples / sec: 52137.06
Iteration:     80, Loss function: 9.839, Average Loss: 1.290, avg. samples / sec: 51978.05
Iteration:     80, Loss function: 10.002, Average Loss: 1.293, avg. samples / sec: 51929.44
Iteration:     80, Loss function: 9.367, Average Loss: 1.280, avg. samples / sec: 52098.46
Iteration:     80, Loss function: 11.251, Average Loss: 1.299, avg. samples / sec: 51860.38
Iteration:     80, Loss function: 11.028, Average Loss: 1.298, avg. samples / sec: 51938.88
Iteration:     80, Loss function: 10.119, Average Loss: 1.299, avg. samples / sec: 51887.99
Iteration:     80, Loss function: 10.097, Average Loss: 1.295, avg. samples / sec: 51897.22
Iteration:     80, Loss function: 10.186, Average Loss: 1.301, avg. samples / sec: 51854.31
Iteration:     80, Loss function: 9.196, Average Loss: 1.285, avg. samples / sec: 52138.16
Iteration:     80, Loss function: 9.782, Average Loss: 1.287, avg. samples / sec: 51980.22
Iteration:     80, Loss function: 9.945, Average Loss: 1.289, avg. samples / sec: 51799.82
Iteration:     80, Loss function: 9.831, Average Loss: 1.298, avg. samples / sec: 52179.70
Iteration:     80, Loss function: 10.391, Average Loss: 1.304, avg. samples / sec: 51848.74
Iteration:     80, Loss function: 9.418, Average Loss: 1.296, avg. samples / sec: 52072.16
Iteration:     80, Loss function: 9.079, Average Loss: 1.290, avg. samples / sec: 51936.18
Iteration:     80, Loss function: 10.148, Average Loss: 1.298, avg. samples / sec: 51959.41
Iteration:     80, Loss function: 11.101, Average Loss: 1.299, avg. samples / sec: 52005.35
Iteration:     80, Loss function: 9.730, Average Loss: 1.289, avg. samples / sec: 51571.90
Iteration:     80, Loss function: 10.248, Average Loss: 1.297, avg. samples / sec: 51595.95
Iteration:     80, Loss function: 10.313, Average Loss: 1.294, avg. samples / sec: 51726.93
Iteration:     80, Loss function: 9.656, Average Loss: 1.304, avg. samples / sec: 51844.30
Iteration:     80, Loss function: 10.768, Average Loss: 1.284, avg. samples / sec: 51396.98
Iteration:     80, Loss function: 10.467, Average Loss: 1.300, avg. samples / sec: 51668.53
Iteration:     80, Loss function: 11.340, Average Loss: 1.301, avg. samples / sec: 50540.00
Iteration:    100, Loss function: 10.076, Average Loss: 1.466, avg. samples / sec: 51038.86
Iteration:    100, Loss function: 10.123, Average Loss: 1.467, avg. samples / sec: 51190.14
Iteration:    100, Loss function: 9.544, Average Loss: 1.467, avg. samples / sec: 51570.09
Iteration:    100, Loss function: 9.173, Average Loss: 1.468, avg. samples / sec: 51106.14
Iteration:    100, Loss function: 8.403, Average Loss: 1.466, avg. samples / sec: 51646.76
Iteration:    100, Loss function: 9.179, Average Loss: 1.461, avg. samples / sec: 50999.45
Iteration:    100, Loss function: 8.473, Average Loss: 1.459, avg. samples / sec: 52399.85
Iteration:    100, Loss function: 9.447, Average Loss: 1.459, avg. samples / sec: 51292.84
Iteration:    100, Loss function: 9.427, Average Loss: 1.454, avg. samples / sec: 50849.18
Iteration:    100, Loss function: 9.040, Average Loss: 1.462, avg. samples / sec: 50869.63
Iteration:    100, Loss function: 8.683, Average Loss: 1.443, avg. samples / sec: 50788.84
Iteration:    100, Loss function: 8.857, Average Loss: 1.448, avg. samples / sec: 50766.85
Iteration:    100, Loss function: 9.242, Average Loss: 1.455, avg. samples / sec: 50806.53
Iteration:    100, Loss function: 9.102, Average Loss: 1.461, avg. samples / sec: 50494.46
Iteration:    100, Loss function: 9.386, Average Loss: 1.461, avg. samples / sec: 50306.28
Iteration:    100, Loss function: 9.863, Average Loss: 1.455, avg. samples / sec: 50603.04
Iteration:    100, Loss function: 9.370, Average Loss: 1.465, avg. samples / sec: 50672.42
Iteration:    100, Loss function: 9.315, Average Loss: 1.461, avg. samples / sec: 50943.87
Iteration:    100, Loss function: 9.078, Average Loss: 1.454, avg. samples / sec: 50633.06
Iteration:    100, Loss function: 9.465, Average Loss: 1.461, avg. samples / sec: 50741.82
Iteration:    100, Loss function: 8.619, Average Loss: 1.459, avg. samples / sec: 50643.29
Iteration:    100, Loss function: 9.234, Average Loss: 1.448, avg. samples / sec: 51026.93
Iteration:    100, Loss function: 9.772, Average Loss: 1.445, avg. samples / sec: 50480.31
Iteration:    100, Loss function: 10.084, Average Loss: 1.463, avg. samples / sec: 50376.48
Iteration:    100, Loss function: 9.520, Average Loss: 1.469, avg. samples / sec: 50329.08
Iteration:    100, Loss function: 7.868, Average Loss: 1.459, avg. samples / sec: 50235.48
Iteration:    100, Loss function: 9.419, Average Loss: 1.456, avg. samples / sec: 50160.62
Iteration:    100, Loss function: 8.324, Average Loss: 1.450, avg. samples / sec: 50332.37
Iteration:    100, Loss function: 8.767, Average Loss: 1.460, avg. samples / sec: 50233.64
Iteration:    100, Loss function: 9.764, Average Loss: 1.453, avg. samples / sec: 49728.04
Iteration:    120, Loss function: 8.920, Average Loss: 1.612, avg. samples / sec: 52318.03
Iteration:    120, Loss function: 9.853, Average Loss: 1.610, avg. samples / sec: 52689.39
Iteration:    120, Loss function: 8.625, Average Loss: 1.598, avg. samples / sec: 51902.95
Iteration:    120, Loss function: 9.428, Average Loss: 1.619, avg. samples / sec: 51562.09
Iteration:    120, Loss function: 8.749, Average Loss: 1.626, avg. samples / sec: 52355.68
Iteration:    120, Loss function: 8.960, Average Loss: 1.618, avg. samples / sec: 51901.50
Iteration:    120, Loss function: 9.743, Average Loss: 1.612, avg. samples / sec: 52147.83
Iteration:    120, Loss function: 8.512, Average Loss: 1.603, avg. samples / sec: 52171.59
Iteration:    120, Loss function: 9.480, Average Loss: 1.604, avg. samples / sec: 52643.11
Iteration:    120, Loss function: 8.295, Average Loss: 1.597, avg. samples / sec: 52248.24
Iteration:    120, Loss function: 8.569, Average Loss: 1.613, avg. samples / sec: 52272.86
Iteration:    120, Loss function: 9.465, Average Loss: 1.607, avg. samples / sec: 51734.50
Iteration:    120, Loss function: 9.095, Average Loss: 1.600, avg. samples / sec: 51968.97
Iteration:    120, Loss function: 9.177, Average Loss: 1.607, avg. samples / sec: 52465.48
Iteration:    120, Loss function: 8.367, Average Loss: 1.610, avg. samples / sec: 52171.42
Iteration:    120, Loss function: 9.652, Average Loss: 1.610, avg. samples / sec: 52068.45
Iteration:    120, Loss function: 9.326, Average Loss: 1.616, avg. samples / sec: 51602.64
Iteration:    120, Loss function: 9.839, Average Loss: 1.620, avg. samples / sec: 51371.97
Iteration:    120, Loss function: 9.125, Average Loss: 1.612, avg. samples / sec: 52019.42
Iteration:    120, Loss function: 8.949, Average Loss: 1.618, avg. samples / sec: 51504.59
Iteration:    120, Loss function: 9.047, Average Loss: 1.604, avg. samples / sec: 51779.38
Iteration:    120, Loss function: 8.771, Average Loss: 1.611, avg. samples / sec: 51456.11
Iteration:    120, Loss function: 9.834, Average Loss: 1.602, avg. samples / sec: 52241.89
Iteration:    120, Loss function: 9.289, Average Loss: 1.608, avg. samples / sec: 52018.27
Iteration:    120, Loss function: 8.803, Average Loss: 1.614, avg. samples / sec: 50721.72
Iteration:    120, Loss function: 8.773, Average Loss: 1.606, avg. samples / sec: 51464.44
Iteration:    120, Loss function: 9.094, Average Loss: 1.613, avg. samples / sec: 50881.20
Iteration:    120, Loss function: 9.236, Average Loss: 1.597, avg. samples / sec: 51402.70
Iteration:    120, Loss function: 9.531, Average Loss: 1.594, avg. samples / sec: 51006.50
Iteration:    120, Loss function: 9.408, Average Loss: 1.614, avg. samples / sec: 51246.08
:::MLL 1558641102.097 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558641102.097 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 7.875, Average Loss: 1.748, avg. samples / sec: 52236.62
Iteration:    140, Loss function: 9.259, Average Loss: 1.752, avg. samples / sec: 52969.19
Iteration:    140, Loss function: 9.035, Average Loss: 1.760, avg. samples / sec: 52148.10
Iteration:    140, Loss function: 8.489, Average Loss: 1.750, avg. samples / sec: 52215.22
Iteration:    140, Loss function: 8.593, Average Loss: 1.735, avg. samples / sec: 53114.29
Iteration:    140, Loss function: 9.269, Average Loss: 1.748, avg. samples / sec: 52183.65
Iteration:    140, Loss function: 8.769, Average Loss: 1.754, avg. samples / sec: 51965.73
Iteration:    140, Loss function: 9.681, Average Loss: 1.748, avg. samples / sec: 52734.91
Iteration:    140, Loss function: 8.646, Average Loss: 1.756, avg. samples / sec: 52163.11
Iteration:    140, Loss function: 10.367, Average Loss: 1.741, avg. samples / sec: 52156.26
Iteration:    140, Loss function: 8.866, Average Loss: 1.759, avg. samples / sec: 52218.89
Iteration:    140, Loss function: 8.485, Average Loss: 1.742, avg. samples / sec: 52084.26
Iteration:    140, Loss function: 8.989, Average Loss: 1.744, avg. samples / sec: 52366.79
Iteration:    140, Loss function: 8.475, Average Loss: 1.755, avg. samples / sec: 52308.21
Iteration:    140, Loss function: 9.417, Average Loss: 1.755, avg. samples / sec: 52178.27
Iteration:    140, Loss function: 9.150, Average Loss: 1.752, avg. samples / sec: 52165.86
Iteration:    140, Loss function: 8.954, Average Loss: 1.745, avg. samples / sec: 52129.12
Iteration:    140, Loss function: 8.009, Average Loss: 1.754, avg. samples / sec: 52376.77
Iteration:    140, Loss function: 9.226, Average Loss: 1.754, avg. samples / sec: 52255.18
Iteration:    140, Loss function: 8.934, Average Loss: 1.769, avg. samples / sec: 51994.70
Iteration:    140, Loss function: 8.302, Average Loss: 1.756, avg. samples / sec: 51985.24
Iteration:    140, Loss function: 9.026, Average Loss: 1.761, avg. samples / sec: 52092.76
Iteration:    140, Loss function: 8.638, Average Loss: 1.752, avg. samples / sec: 52520.89
Iteration:    140, Loss function: 8.510, Average Loss: 1.757, avg. samples / sec: 52788.97
Iteration:    140, Loss function: 8.770, Average Loss: 1.743, avg. samples / sec: 52747.62
Iteration:    140, Loss function: 8.169, Average Loss: 1.757, avg. samples / sec: 52525.90
Iteration:    140, Loss function: 9.098, Average Loss: 1.743, avg. samples / sec: 51437.93
Iteration:    140, Loss function: 9.460, Average Loss: 1.752, avg. samples / sec: 51612.66
Iteration:    140, Loss function: 8.408, Average Loss: 1.755, avg. samples / sec: 51422.02
Iteration:    140, Loss function: 8.154, Average Loss: 1.761, avg. samples / sec: 51934.82
Iteration:    160, Loss function: 8.488, Average Loss: 1.915, avg. samples / sec: 52178.68
Iteration:    160, Loss function: 7.964, Average Loss: 1.903, avg. samples / sec: 52930.74
Iteration:    160, Loss function: 8.548, Average Loss: 1.888, avg. samples / sec: 51979.49
Iteration:    160, Loss function: 9.114, Average Loss: 1.894, avg. samples / sec: 52685.92
Iteration:    160, Loss function: 9.180, Average Loss: 1.889, avg. samples / sec: 51927.26
Iteration:    160, Loss function: 9.637, Average Loss: 1.886, avg. samples / sec: 51957.57
Iteration:    160, Loss function: 9.045, Average Loss: 1.885, avg. samples / sec: 51699.64
Iteration:    160, Loss function: 8.355, Average Loss: 1.896, avg. samples / sec: 52037.57
Iteration:    160, Loss function: 8.915, Average Loss: 1.884, avg. samples / sec: 51944.35
Iteration:    160, Loss function: 8.823, Average Loss: 1.885, avg. samples / sec: 51880.60
Iteration:    160, Loss function: 8.573, Average Loss: 1.886, avg. samples / sec: 52500.13
Iteration:    160, Loss function: 8.418, Average Loss: 1.884, avg. samples / sec: 51929.90
Iteration:    160, Loss function: 8.896, Average Loss: 1.892, avg. samples / sec: 51764.01
Iteration:    160, Loss function: 8.589, Average Loss: 1.896, avg. samples / sec: 51861.07
Iteration:    160, Loss function: 8.685, Average Loss: 1.875, avg. samples / sec: 51750.54
Iteration:    160, Loss function: 7.435, Average Loss: 1.895, avg. samples / sec: 51733.34
Iteration:    160, Loss function: 9.590, Average Loss: 1.890, avg. samples / sec: 52414.55
Iteration:    160, Loss function: 8.439, Average Loss: 1.893, avg. samples / sec: 52271.71
Iteration:    160, Loss function: 9.539, Average Loss: 1.893, avg. samples / sec: 51828.93
Iteration:    160, Loss function: 9.361, Average Loss: 1.882, avg. samples / sec: 51995.77
Iteration:    160, Loss function: 9.428, Average Loss: 1.900, avg. samples / sec: 51899.34
Iteration:    160, Loss function: 9.759, Average Loss: 1.897, avg. samples / sec: 51930.51
Iteration:    160, Loss function: 9.329, Average Loss: 1.896, avg. samples / sec: 51709.65
Iteration:    160, Loss function: 8.492, Average Loss: 1.895, avg. samples / sec: 51685.87
Iteration:    160, Loss function: 8.416, Average Loss: 1.898, avg. samples / sec: 51640.93
Iteration:    160, Loss function: 7.923, Average Loss: 1.895, avg. samples / sec: 51811.74
Iteration:    160, Loss function: 8.252, Average Loss: 1.881, avg. samples / sec: 51515.10
Iteration:    160, Loss function: 8.832, Average Loss: 1.894, avg. samples / sec: 51535.42
Iteration:    160, Loss function: 8.103, Average Loss: 1.883, avg. samples / sec: 51427.53
Iteration:    160, Loss function: 8.282, Average Loss: 1.888, avg. samples / sec: 50818.62
Iteration:    180, Loss function: 7.680, Average Loss: 2.017, avg. samples / sec: 51860.15
Iteration:    180, Loss function: 8.211, Average Loss: 2.016, avg. samples / sec: 51903.53
Iteration:    180, Loss function: 8.661, Average Loss: 2.032, avg. samples / sec: 51687.94
Iteration:    180, Loss function: 8.182, Average Loss: 2.011, avg. samples / sec: 51776.93
Iteration:    180, Loss function: 7.282, Average Loss: 2.004, avg. samples / sec: 51874.43
Iteration:    180, Loss function: 8.490, Average Loss: 2.018, avg. samples / sec: 52944.50
Iteration:    180, Loss function: 8.262, Average Loss: 2.018, avg. samples / sec: 51755.71
Iteration:    180, Loss function: 8.431, Average Loss: 2.015, avg. samples / sec: 51770.21
Iteration:    180, Loss function: 7.360, Average Loss: 2.011, avg. samples / sec: 52170.47
Iteration:    180, Loss function: 8.410, Average Loss: 2.033, avg. samples / sec: 51924.16
Iteration:    180, Loss function: 8.677, Average Loss: 2.028, avg. samples / sec: 51786.92
Iteration:    180, Loss function: 8.182, Average Loss: 2.022, avg. samples / sec: 51700.74
Iteration:    180, Loss function: 8.227, Average Loss: 2.027, avg. samples / sec: 51648.69
Iteration:    180, Loss function: 8.678, Average Loss: 2.018, avg. samples / sec: 51563.61
Iteration:    180, Loss function: 9.114, Average Loss: 2.026, avg. samples / sec: 51713.98
Iteration:    180, Loss function: 7.774, Average Loss: 2.024, avg. samples / sec: 51817.23
Iteration:    180, Loss function: 9.159, Average Loss: 2.025, avg. samples / sec: 51815.82
Iteration:    180, Loss function: 8.035, Average Loss: 2.020, avg. samples / sec: 51479.93
Iteration:    180, Loss function: 8.477, Average Loss: 2.029, avg. samples / sec: 51818.98
Iteration:    180, Loss function: 7.703, Average Loss: 2.028, avg. samples / sec: 51511.50
Iteration:    180, Loss function: 9.066, Average Loss: 2.049, avg. samples / sec: 51346.40
Iteration:    180, Loss function: 8.140, Average Loss: 2.023, avg. samples / sec: 51951.15
Iteration:    180, Loss function: 8.347, Average Loss: 2.026, avg. samples / sec: 51429.37
Iteration:    180, Loss function: 8.596, Average Loss: 2.024, avg. samples / sec: 51866.03
Iteration:    180, Loss function: 8.590, Average Loss: 2.016, avg. samples / sec: 51631.43
Iteration:    180, Loss function: 7.842, Average Loss: 2.029, avg. samples / sec: 51569.12
Iteration:    180, Loss function: 8.262, Average Loss: 2.021, avg. samples / sec: 51423.50
Iteration:    180, Loss function: 8.917, Average Loss: 2.015, avg. samples / sec: 51219.17
Iteration:    180, Loss function: 8.210, Average Loss: 2.014, avg. samples / sec: 50936.89
Iteration:    180, Loss function: 9.428, Average Loss: 2.026, avg. samples / sec: 50015.89
Iteration:    200, Loss function: 8.341, Average Loss: 2.136, avg. samples / sec: 52175.96
Iteration:    200, Loss function: 8.342, Average Loss: 2.159, avg. samples / sec: 52277.72
Iteration:    200, Loss function: 9.706, Average Loss: 2.137, avg. samples / sec: 52446.11
Iteration:    200, Loss function: 8.622, Average Loss: 2.137, avg. samples / sec: 53538.14
Iteration:    200, Loss function: 8.375, Average Loss: 2.136, avg. samples / sec: 52539.18
Iteration:    200, Loss function: 8.137, Average Loss: 2.128, avg. samples / sec: 52176.77
Iteration:    200, Loss function: 8.423, Average Loss: 2.142, avg. samples / sec: 52283.23
Iteration:    200, Loss function: 8.797, Average Loss: 2.133, avg. samples / sec: 52203.48
Iteration:    200, Loss function: 8.640, Average Loss: 2.142, avg. samples / sec: 52389.04
Iteration:    200, Loss function: 8.778, Average Loss: 2.153, avg. samples / sec: 52600.99
Iteration:    200, Loss function: 8.580, Average Loss: 2.140, avg. samples / sec: 52175.67
Iteration:    200, Loss function: 8.827, Average Loss: 2.149, avg. samples / sec: 52221.41
Iteration:    200, Loss function: 9.011, Average Loss: 2.128, avg. samples / sec: 52055.06
Iteration:    200, Loss function: 8.009, Average Loss: 2.149, avg. samples / sec: 52243.21
Iteration:    200, Loss function: 8.964, Average Loss: 2.148, avg. samples / sec: 54068.74
Iteration:    200, Loss function: 7.914, Average Loss: 2.150, avg. samples / sec: 52207.60
Iteration:    200, Loss function: 8.387, Average Loss: 2.148, avg. samples / sec: 52244.64
Iteration:    200, Loss function: 8.160, Average Loss: 2.141, avg. samples / sec: 52459.09
Iteration:    200, Loss function: 8.931, Average Loss: 2.173, avg. samples / sec: 52233.70
Iteration:    200, Loss function: 8.446, Average Loss: 2.154, avg. samples / sec: 52036.36
Iteration:    200, Loss function: 8.432, Average Loss: 2.150, avg. samples / sec: 52241.85
Iteration:    200, Loss function: 7.276, Average Loss: 2.144, avg. samples / sec: 52225.26
Iteration:    200, Loss function: 9.280, Average Loss: 2.148, avg. samples / sec: 52142.13
Iteration:    200, Loss function: 8.576, Average Loss: 2.143, avg. samples / sec: 52170.80
Iteration:    200, Loss function: 7.668, Average Loss: 2.135, avg. samples / sec: 51712.61
Iteration:    200, Loss function: 7.735, Average Loss: 2.137, avg. samples / sec: 52397.75
Iteration:    200, Loss function: 8.984, Average Loss: 2.151, avg. samples / sec: 52119.09
Iteration:    200, Loss function: 9.904, Average Loss: 2.152, avg. samples / sec: 51831.20
Iteration:    200, Loss function: 7.864, Average Loss: 2.132, avg. samples / sec: 51553.05
Iteration:    200, Loss function: 7.755, Average Loss: 2.139, avg. samples / sec: 51201.02
:::MLL 1558641104.357 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558641104.357 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 8.411, Average Loss: 2.258, avg. samples / sec: 52527.23
Iteration:    220, Loss function: 7.859, Average Loss: 2.262, avg. samples / sec: 52190.53
Iteration:    220, Loss function: 8.479, Average Loss: 2.271, avg. samples / sec: 52361.15
Iteration:    220, Loss function: 8.351, Average Loss: 2.284, avg. samples / sec: 52108.05
Iteration:    220, Loss function: 8.406, Average Loss: 2.263, avg. samples / sec: 52535.67
Iteration:    220, Loss function: 7.406, Average Loss: 2.262, avg. samples / sec: 52195.74
Iteration:    220, Loss function: 8.186, Average Loss: 2.277, avg. samples / sec: 52370.12
Iteration:    220, Loss function: 8.348, Average Loss: 2.255, avg. samples / sec: 52195.78
Iteration:    220, Loss function: 8.130, Average Loss: 2.259, avg. samples / sec: 52200.87
Iteration:    220, Loss function: 8.156, Average Loss: 2.265, avg. samples / sec: 52128.44
Iteration:    220, Loss function: 8.415, Average Loss: 2.268, avg. samples / sec: 52178.16
Iteration:    220, Loss function: 8.182, Average Loss: 2.266, avg. samples / sec: 52128.27
Iteration:    220, Loss function: 7.946, Average Loss: 2.272, avg. samples / sec: 52375.55
Iteration:    220, Loss function: 8.407, Average Loss: 2.259, avg. samples / sec: 52373.27
Iteration:    220, Loss function: 9.193, Average Loss: 2.273, avg. samples / sec: 52243.34
Iteration:    220, Loss function: 7.853, Average Loss: 2.259, avg. samples / sec: 52762.02
Iteration:    220, Loss function: 8.584, Average Loss: 2.270, avg. samples / sec: 52259.50
Iteration:    220, Loss function: 7.861, Average Loss: 2.272, avg. samples / sec: 52276.73
Iteration:    220, Loss function: 8.459, Average Loss: 2.276, avg. samples / sec: 52164.10
Iteration:    220, Loss function: 8.737, Average Loss: 2.302, avg. samples / sec: 52174.53
Iteration:    220, Loss function: 8.039, Average Loss: 2.280, avg. samples / sec: 51988.77
Iteration:    220, Loss function: 8.685, Average Loss: 2.267, avg. samples / sec: 52191.36
Iteration:    220, Loss function: 8.556, Average Loss: 2.267, avg. samples / sec: 52980.26
Iteration:    220, Loss function: 8.265, Average Loss: 2.275, avg. samples / sec: 52132.74
Iteration:    220, Loss function: 8.341, Average Loss: 2.275, avg. samples / sec: 52153.60
Iteration:    220, Loss function: 8.369, Average Loss: 2.278, avg. samples / sec: 52059.87
Iteration:    220, Loss function: 8.937, Average Loss: 2.275, avg. samples / sec: 52121.64
Iteration:    220, Loss function: 8.278, Average Loss: 2.274, avg. samples / sec: 52016.44
Iteration:    220, Loss function: 8.089, Average Loss: 2.261, avg. samples / sec: 51479.04
Iteration:    220, Loss function: 7.510, Average Loss: 2.273, avg. samples / sec: 51300.68
Iteration:    240, Loss function: 7.735, Average Loss: 2.377, avg. samples / sec: 53671.16
Iteration:    240, Loss function: 8.137, Average Loss: 2.383, avg. samples / sec: 53256.05
Iteration:    240, Loss function: 8.252, Average Loss: 2.374, avg. samples / sec: 53196.31
Iteration:    240, Loss function: 8.046, Average Loss: 2.389, avg. samples / sec: 53380.15
Iteration:    240, Loss function: 8.044, Average Loss: 2.366, avg. samples / sec: 53045.25
Iteration:    240, Loss function: 8.673, Average Loss: 2.376, avg. samples / sec: 53214.93
Iteration:    240, Loss function: 7.198, Average Loss: 2.385, avg. samples / sec: 53217.36
Iteration:    240, Loss function: 7.635, Average Loss: 2.371, avg. samples / sec: 53365.11
Iteration:    240, Loss function: 7.372, Average Loss: 2.368, avg. samples / sec: 53220.17
Iteration:    240, Loss function: 8.693, Average Loss: 2.384, avg. samples / sec: 53227.49
Iteration:    240, Loss function: 8.181, Average Loss: 2.380, avg. samples / sec: 53256.47
Iteration:    240, Loss function: 8.102, Average Loss: 2.377, avg. samples / sec: 53208.80
Iteration:    240, Loss function: 7.449, Average Loss: 2.374, avg. samples / sec: 53103.86
Iteration:    240, Loss function: 6.820, Average Loss: 2.386, avg. samples / sec: 53869.71
Iteration:    240, Loss function: 8.087, Average Loss: 2.378, avg. samples / sec: 53283.23
Iteration:    240, Loss function: 7.609, Average Loss: 2.377, avg. samples / sec: 53301.78
Iteration:    240, Loss function: 8.176, Average Loss: 2.382, avg. samples / sec: 53429.77
Iteration:    240, Loss function: 6.572, Average Loss: 2.407, avg. samples / sec: 53253.38
Iteration:    240, Loss function: 7.709, Average Loss: 2.366, avg. samples / sec: 53118.49
Iteration:    240, Loss function: 6.945, Average Loss: 2.384, avg. samples / sec: 53260.52
Iteration:    240, Loss function: 6.915, Average Loss: 2.371, avg. samples / sec: 53759.04
Iteration:    240, Loss function: 7.098, Average Loss: 2.381, avg. samples / sec: 53088.78
Iteration:    240, Loss function: 7.887, Average Loss: 2.388, avg. samples / sec: 53367.27
Iteration:    240, Loss function: 7.266, Average Loss: 2.388, avg. samples / sec: 53223.21
Iteration:    240, Loss function: 7.365, Average Loss: 2.380, avg. samples / sec: 53108.74
Iteration:    240, Loss function: 7.716, Average Loss: 2.387, avg. samples / sec: 53238.57
Iteration:    240, Loss function: 7.170, Average Loss: 2.381, avg. samples / sec: 53977.07
Iteration:    240, Loss function: 8.377, Average Loss: 2.364, avg. samples / sec: 52402.33
Iteration:    240, Loss function: 7.277, Average Loss: 2.394, avg. samples / sec: 52257.58
Iteration:    240, Loss function: 7.148, Average Loss: 2.385, avg. samples / sec: 52429.29
Iteration:    260, Loss function: 7.248, Average Loss: 2.469, avg. samples / sec: 53697.24
Iteration:    260, Loss function: 7.335, Average Loss: 2.470, avg. samples / sec: 54280.25
Iteration:    260, Loss function: 6.704, Average Loss: 2.492, avg. samples / sec: 54335.49
Iteration:    260, Loss function: 8.364, Average Loss: 2.484, avg. samples / sec: 53405.13
Iteration:    260, Loss function: 7.719, Average Loss: 2.481, avg. samples / sec: 53416.63
Iteration:    260, Loss function: 6.860, Average Loss: 2.484, avg. samples / sec: 53138.54
Iteration:    260, Loss function: 7.174, Average Loss: 2.473, avg. samples / sec: 53252.39
Iteration:    260, Loss function: 7.098, Average Loss: 2.488, avg. samples / sec: 53257.28
Iteration:    260, Loss function: 7.490, Average Loss: 2.475, avg. samples / sec: 53318.76
Iteration:    260, Loss function: 7.272, Average Loss: 2.469, avg. samples / sec: 53101.72
Iteration:    260, Loss function: 8.085, Average Loss: 2.472, avg. samples / sec: 53213.00
Iteration:    260, Loss function: 7.070, Average Loss: 2.471, avg. samples / sec: 53232.13
Iteration:    260, Loss function: 8.271, Average Loss: 2.488, avg. samples / sec: 53187.21
Iteration:    260, Loss function: 7.084, Average Loss: 2.477, avg. samples / sec: 53414.67
Iteration:    260, Loss function: 7.524, Average Loss: 2.490, avg. samples / sec: 53127.48
Iteration:    260, Loss function: 7.831, Average Loss: 2.492, avg. samples / sec: 53248.39
Iteration:    260, Loss function: 7.915, Average Loss: 2.486, avg. samples / sec: 54124.50
Iteration:    260, Loss function: 6.952, Average Loss: 2.478, avg. samples / sec: 52869.16
Iteration:    260, Loss function: 7.080, Average Loss: 2.503, avg. samples / sec: 53262.45
Iteration:    260, Loss function: 7.781, Average Loss: 2.481, avg. samples / sec: 53135.17
Iteration:    260, Loss function: 6.945, Average Loss: 2.490, avg. samples / sec: 53238.79
Iteration:    260, Loss function: 7.168, Average Loss: 2.488, avg. samples / sec: 53244.62
Iteration:    260, Loss function: 6.884, Average Loss: 2.480, avg. samples / sec: 53197.03
Iteration:    260, Loss function: 7.960, Average Loss: 2.483, avg. samples / sec: 53254.36
Iteration:    260, Loss function: 7.439, Average Loss: 2.483, avg. samples / sec: 53217.00
Iteration:    260, Loss function: 8.411, Average Loss: 2.484, avg. samples / sec: 53119.83
Iteration:    260, Loss function: 8.324, Average Loss: 2.481, avg. samples / sec: 52777.96
Iteration:    260, Loss function: 7.204, Average Loss: 2.491, avg. samples / sec: 52813.68
Iteration:    260, Loss function: 7.129, Average Loss: 2.487, avg. samples / sec: 52463.95
Iteration:    260, Loss function: 6.190, Average Loss: 2.464, avg. samples / sec: 52210.32
:::MLL 1558641106.593 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558641106.594 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 7.884, Average Loss: 2.589, avg. samples / sec: 51659.33
Iteration:    280, Loss function: 8.214, Average Loss: 2.588, avg. samples / sec: 51785.76
Iteration:    280, Loss function: 9.303, Average Loss: 2.613, avg. samples / sec: 51718.33
Iteration:    280, Loss function: 8.368, Average Loss: 2.582, avg. samples / sec: 51571.63
Iteration:    280, Loss function: 7.817, Average Loss: 2.594, avg. samples / sec: 51544.96
Iteration:    280, Loss function: 7.815, Average Loss: 2.575, avg. samples / sec: 51452.99
Iteration:    280, Loss function: 9.720, Average Loss: 2.575, avg. samples / sec: 51225.79
Iteration:    280, Loss function: 7.764, Average Loss: 2.585, avg. samples / sec: 51258.87
Iteration:    280, Loss function: 9.872, Average Loss: 2.583, avg. samples / sec: 51346.70
Iteration:    280, Loss function: 8.271, Average Loss: 2.592, avg. samples / sec: 51381.24
Iteration:    280, Loss function: 7.285, Average Loss: 2.592, avg. samples / sec: 51530.69
Iteration:    280, Loss function: 8.159, Average Loss: 2.589, avg. samples / sec: 51155.40
Iteration:    280, Loss function: 7.474, Average Loss: 2.597, avg. samples / sec: 51055.54
Iteration:    280, Loss function: 6.879, Average Loss: 2.590, avg. samples / sec: 51489.57
Iteration:    280, Loss function: 7.363, Average Loss: 2.582, avg. samples / sec: 51297.47
Iteration:    280, Loss function: 7.340, Average Loss: 2.582, avg. samples / sec: 51361.65
Iteration:    280, Loss function: 7.786, Average Loss: 2.583, avg. samples / sec: 51674.86
Iteration:    280, Loss function: 7.519, Average Loss: 2.571, avg. samples / sec: 51064.55
Iteration:    280, Loss function: 7.630, Average Loss: 2.592, avg. samples / sec: 51172.21
Iteration:    280, Loss function: 8.101, Average Loss: 2.585, avg. samples / sec: 51205.43
Iteration:    280, Loss function: 8.134, Average Loss: 2.598, avg. samples / sec: 51549.26
Iteration:    280, Loss function: 7.472, Average Loss: 2.573, avg. samples / sec: 50704.12
Iteration:    280, Loss function: 6.939, Average Loss: 2.591, avg. samples / sec: 51092.56
Iteration:    280, Loss function: 6.536, Average Loss: 2.574, avg. samples / sec: 50763.85
Iteration:    280, Loss function: 7.742, Average Loss: 2.587, avg. samples / sec: 50948.56
Iteration:    280, Loss function: 7.478, Average Loss: 2.593, avg. samples / sec: 50694.73
Iteration:    280, Loss function: 7.474, Average Loss: 2.572, avg. samples / sec: 51600.22
Iteration:    280, Loss function: 8.085, Average Loss: 2.595, avg. samples / sec: 50701.64
Iteration:    280, Loss function: 8.765, Average Loss: 2.579, avg. samples / sec: 50484.60
Iteration:    280, Loss function: 7.877, Average Loss: 2.589, avg. samples / sec: 51271.53
Iteration:    300, Loss function: 8.751, Average Loss: 2.674, avg. samples / sec: 53374.63
Iteration:    300, Loss function: 6.366, Average Loss: 2.670, avg. samples / sec: 53739.54
Iteration:    300, Loss function: 7.407, Average Loss: 2.680, avg. samples / sec: 53367.29
Iteration:    300, Loss function: 6.907, Average Loss: 2.672, avg. samples / sec: 54075.24
Iteration:    300, Loss function: 7.919, Average Loss: 2.696, avg. samples / sec: 54105.20
Iteration:    300, Loss function: 8.482, Average Loss: 2.681, avg. samples / sec: 54272.51
Iteration:    300, Loss function: 7.653, Average Loss: 2.675, avg. samples / sec: 53118.97
Iteration:    300, Loss function: 6.740, Average Loss: 2.684, avg. samples / sec: 53011.57
Iteration:    300, Loss function: 8.528, Average Loss: 2.687, avg. samples / sec: 53907.67
Iteration:    300, Loss function: 7.644, Average Loss: 2.681, avg. samples / sec: 53234.33
Iteration:    300, Loss function: 7.578, Average Loss: 2.687, avg. samples / sec: 53342.29
Iteration:    300, Loss function: 7.295, Average Loss: 2.683, avg. samples / sec: 53418.72
Iteration:    300, Loss function: 6.976, Average Loss: 2.680, avg. samples / sec: 53439.38
Iteration:    300, Loss function: 7.209, Average Loss: 2.689, avg. samples / sec: 53364.63
Iteration:    300, Loss function: 8.099, Average Loss: 2.675, avg. samples / sec: 53846.33
Iteration:    300, Loss function: 7.069, Average Loss: 2.689, avg. samples / sec: 53885.66
Iteration:    300, Loss function: 7.939, Average Loss: 2.688, avg. samples / sec: 53214.10
Iteration:    300, Loss function: 6.577, Average Loss: 2.691, avg. samples / sec: 53162.51
Iteration:    300, Loss function: 8.001, Average Loss: 2.691, avg. samples / sec: 53387.07
Iteration:    300, Loss function: 7.284, Average Loss: 2.686, avg. samples / sec: 54133.31
Iteration:    300, Loss function: 7.212, Average Loss: 2.711, avg. samples / sec: 52796.07
Iteration:    300, Loss function: 6.720, Average Loss: 2.682, avg. samples / sec: 52812.87
Iteration:    300, Loss function: 6.887, Average Loss: 2.691, avg. samples / sec: 53492.74
Iteration:    300, Loss function: 8.657, Average Loss: 2.681, avg. samples / sec: 53257.44
Iteration:    300, Loss function: 7.221, Average Loss: 2.681, avg. samples / sec: 53344.89
Iteration:    300, Loss function: 8.010, Average Loss: 2.696, avg. samples / sec: 52620.04
Iteration:    300, Loss function: 6.446, Average Loss: 2.694, avg. samples / sec: 53240.82
Iteration:    300, Loss function: 7.334, Average Loss: 2.685, avg. samples / sec: 52092.50
Iteration:    300, Loss function: 7.885, Average Loss: 2.675, avg. samples / sec: 52912.45
Iteration:    300, Loss function: 7.407, Average Loss: 2.679, avg. samples / sec: 52621.02
Iteration:    320, Loss function: 7.668, Average Loss: 2.773, avg. samples / sec: 54320.31
Iteration:    320, Loss function: 8.493, Average Loss: 2.780, avg. samples / sec: 53393.09
Iteration:    320, Loss function: 8.210, Average Loss: 2.783, avg. samples / sec: 53299.30
Iteration:    320, Loss function: 6.375, Average Loss: 2.759, avg. samples / sec: 53162.09
Iteration:    320, Loss function: 8.008, Average Loss: 2.767, avg. samples / sec: 53198.98
Iteration:    320, Loss function: 7.445, Average Loss: 2.783, avg. samples / sec: 53772.27
Iteration:    320, Loss function: 6.615, Average Loss: 2.775, avg. samples / sec: 53285.79
Iteration:    320, Loss function: 8.002, Average Loss: 2.760, avg. samples / sec: 53193.74
Iteration:    320, Loss function: 6.705, Average Loss: 2.772, avg. samples / sec: 53972.68
Iteration:    320, Loss function: 6.789, Average Loss: 2.772, avg. samples / sec: 53270.89
Iteration:    320, Loss function: 7.544, Average Loss: 2.767, avg. samples / sec: 53214.35
Iteration:    320, Loss function: 6.772, Average Loss: 2.780, avg. samples / sec: 53280.21
Iteration:    320, Loss function: 6.685, Average Loss: 2.767, avg. samples / sec: 53259.37
Iteration:    320, Loss function: 7.569, Average Loss: 2.768, avg. samples / sec: 53183.18
Iteration:    320, Loss function: 6.423, Average Loss: 2.770, avg. samples / sec: 53223.93
Iteration:    320, Loss function: 6.242, Average Loss: 2.769, avg. samples / sec: 53495.24
Iteration:    320, Loss function: 7.473, Average Loss: 2.803, avg. samples / sec: 53437.49
Iteration:    320, Loss function: 7.141, Average Loss: 2.768, avg. samples / sec: 53240.54
Iteration:    320, Loss function: 5.453, Average Loss: 2.777, avg. samples / sec: 53333.08
Iteration:    320, Loss function: 7.789, Average Loss: 2.784, avg. samples / sec: 53556.54
Iteration:    320, Loss function: 6.789, Average Loss: 2.767, avg. samples / sec: 53056.74
Iteration:    320, Loss function: 7.823, Average Loss: 2.772, avg. samples / sec: 53316.92
Iteration:    320, Loss function: 6.987, Average Loss: 2.771, avg. samples / sec: 53146.31
Iteration:    320, Loss function: 8.027, Average Loss: 2.762, avg. samples / sec: 52791.39
Iteration:    320, Loss function: 7.850, Average Loss: 2.780, avg. samples / sec: 53244.26
Iteration:    320, Loss function: 7.014, Average Loss: 2.772, avg. samples / sec: 53263.00
Iteration:    320, Loss function: 6.846, Average Loss: 2.781, avg. samples / sec: 53164.84
Iteration:    320, Loss function: 6.603, Average Loss: 2.783, avg. samples / sec: 52751.29
Iteration:    320, Loss function: 6.672, Average Loss: 2.781, avg. samples / sec: 52718.26
Iteration:    320, Loss function: 7.302, Average Loss: 2.764, avg. samples / sec: 53261.93
Iteration:    340, Loss function: 7.177, Average Loss: 2.851, avg. samples / sec: 53343.01
Iteration:    340, Loss function: 7.663, Average Loss: 2.856, avg. samples / sec: 53398.17
Iteration:    340, Loss function: 6.875, Average Loss: 2.869, avg. samples / sec: 53215.87
Iteration:    340, Loss function: 7.566, Average Loss: 2.855, avg. samples / sec: 53522.71
Iteration:    340, Loss function: 6.743, Average Loss: 2.862, avg. samples / sec: 53133.83
Iteration:    340, Loss function: 6.724, Average Loss: 2.854, avg. samples / sec: 53351.64
Iteration:    340, Loss function: 6.845, Average Loss: 2.851, avg. samples / sec: 54150.85
Iteration:    340, Loss function: 8.418, Average Loss: 2.853, avg. samples / sec: 53307.42
Iteration:    340, Loss function: 7.287, Average Loss: 2.857, avg. samples / sec: 53323.21
Iteration:    340, Loss function: 6.847, Average Loss: 2.856, avg. samples / sec: 53352.02
Iteration:    340, Loss function: 8.555, Average Loss: 2.854, avg. samples / sec: 53276.99
Iteration:    340, Loss function: 6.744, Average Loss: 2.860, avg. samples / sec: 53296.07
Iteration:    340, Loss function: 9.743, Average Loss: 2.871, avg. samples / sec: 53932.45
Iteration:    340, Loss function: 7.792, Average Loss: 2.870, avg. samples / sec: 53826.28
Iteration:    340, Loss function: 7.141, Average Loss: 2.861, avg. samples / sec: 53471.23
Iteration:    340, Loss function: 7.186, Average Loss: 2.869, avg. samples / sec: 53214.89
Iteration:    340, Loss function: 7.314, Average Loss: 2.855, avg. samples / sec: 53056.62
Iteration:    340, Loss function: 6.887, Average Loss: 2.857, avg. samples / sec: 53315.27
Iteration:    340, Loss function: 8.185, Average Loss: 2.871, avg. samples / sec: 53406.37
Iteration:    340, Loss function: 7.203, Average Loss: 2.859, avg. samples / sec: 53110.68
Iteration:    340, Loss function: 7.170, Average Loss: 2.893, avg. samples / sec: 53110.34
Iteration:    340, Loss function: 6.814, Average Loss: 2.866, avg. samples / sec: 53008.88
Iteration:    340, Loss function: 7.070, Average Loss: 2.865, avg. samples / sec: 53160.71
Iteration:    340, Loss function: 8.043, Average Loss: 2.855, avg. samples / sec: 53211.41
Iteration:    340, Loss function: 7.305, Average Loss: 2.868, avg. samples / sec: 53065.97
Iteration:    340, Loss function: 6.648, Average Loss: 2.870, avg. samples / sec: 52608.55
Iteration:    340, Loss function: 8.027, Average Loss: 2.860, avg. samples / sec: 52640.83
Iteration:    340, Loss function: 7.505, Average Loss: 2.865, avg. samples / sec: 52519.34
Iteration:    340, Loss function: 7.460, Average Loss: 2.866, avg. samples / sec: 52764.94
Iteration:    340, Loss function: 7.677, Average Loss: 2.863, avg. samples / sec: 52445.21
:::MLL 1558641108.808 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558641108.809 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 7.924, Average Loss: 2.948, avg. samples / sec: 53398.98
Iteration:    360, Loss function: 6.829, Average Loss: 2.935, avg. samples / sec: 53228.47
Iteration:    360, Loss function: 6.702, Average Loss: 2.958, avg. samples / sec: 53429.79
Iteration:    360, Loss function: 7.216, Average Loss: 2.943, avg. samples / sec: 53293.99
Iteration:    360, Loss function: 6.631, Average Loss: 2.942, avg. samples / sec: 53310.28
Iteration:    360, Loss function: 6.334, Average Loss: 2.937, avg. samples / sec: 53296.78
Iteration:    360, Loss function: 5.959, Average Loss: 2.944, avg. samples / sec: 53497.64
Iteration:    360, Loss function: 6.968, Average Loss: 2.936, avg. samples / sec: 53261.47
Iteration:    360, Loss function: 7.748, Average Loss: 2.952, avg. samples / sec: 54031.64
Iteration:    360, Loss function: 5.524, Average Loss: 2.951, avg. samples / sec: 53838.52
Iteration:    360, Loss function: 6.285, Average Loss: 2.948, avg. samples / sec: 53304.03
Iteration:    360, Loss function: 6.496, Average Loss: 2.940, avg. samples / sec: 53232.31
Iteration:    360, Loss function: 7.716, Average Loss: 2.960, avg. samples / sec: 53291.56
Iteration:    360, Loss function: 7.183, Average Loss: 2.961, avg. samples / sec: 53255.33
Iteration:    360, Loss function: 6.855, Average Loss: 2.941, avg. samples / sec: 53379.28
Iteration:    360, Loss function: 5.076, Average Loss: 2.946, avg. samples / sec: 53892.27
Iteration:    360, Loss function: 7.541, Average Loss: 2.942, avg. samples / sec: 53113.93
Iteration:    360, Loss function: 5.915, Average Loss: 2.946, avg. samples / sec: 53414.81
Iteration:    360, Loss function: 7.184, Average Loss: 2.951, avg. samples / sec: 53389.39
Iteration:    360, Loss function: 6.664, Average Loss: 2.943, avg. samples / sec: 53024.04
Iteration:    360, Loss function: 6.107, Average Loss: 2.948, avg. samples / sec: 53058.15
Iteration:    360, Loss function: 6.686, Average Loss: 2.955, avg. samples / sec: 53288.88
Iteration:    360, Loss function: 8.024, Average Loss: 2.956, avg. samples / sec: 53332.05
Iteration:    360, Loss function: 7.258, Average Loss: 2.953, avg. samples / sec: 53813.54
Iteration:    360, Loss function: 7.493, Average Loss: 2.955, avg. samples / sec: 54122.63
Iteration:    360, Loss function: 7.108, Average Loss: 2.983, avg. samples / sec: 53276.65
Iteration:    360, Loss function: 6.863, Average Loss: 2.952, avg. samples / sec: 53407.80
Iteration:    360, Loss function: 7.132, Average Loss: 2.940, avg. samples / sec: 53334.17
Iteration:    360, Loss function: 8.262, Average Loss: 2.960, avg. samples / sec: 52688.68
Iteration:    360, Loss function: 6.972, Average Loss: 2.939, avg. samples / sec: 52598.69
Iteration:    380, Loss function: 7.227, Average Loss: 3.017, avg. samples / sec: 54167.75
Iteration:    380, Loss function: 8.039, Average Loss: 3.018, avg. samples / sec: 54396.84
Iteration:    380, Loss function: 7.601, Average Loss: 3.013, avg. samples / sec: 53696.97
Iteration:    380, Loss function: 6.995, Average Loss: 3.034, avg. samples / sec: 53909.94
Iteration:    380, Loss function: 5.674, Average Loss: 3.033, avg. samples / sec: 53909.69
Iteration:    380, Loss function: 7.300, Average Loss: 3.025, avg. samples / sec: 53513.65
Iteration:    380, Loss function: 7.040, Average Loss: 3.027, avg. samples / sec: 53649.67
Iteration:    380, Loss function: 7.083, Average Loss: 3.009, avg. samples / sec: 53635.78
Iteration:    380, Loss function: 6.378, Average Loss: 3.029, avg. samples / sec: 53689.89
Iteration:    380, Loss function: 7.384, Average Loss: 3.040, avg. samples / sec: 53677.62
Iteration:    380, Loss function: 6.390, Average Loss: 3.016, avg. samples / sec: 53534.26
Iteration:    380, Loss function: 5.984, Average Loss: 3.019, avg. samples / sec: 53678.34
Iteration:    380, Loss function: 6.760, Average Loss: 3.018, avg. samples / sec: 53715.82
Iteration:    380, Loss function: 5.919, Average Loss: 3.037, avg. samples / sec: 53656.57
Iteration:    380, Loss function: 6.261, Average Loss: 3.026, avg. samples / sec: 53623.01
Iteration:    380, Loss function: 7.150, Average Loss: 3.037, avg. samples / sec: 53825.40
Iteration:    380, Loss function: 6.593, Average Loss: 3.021, avg. samples / sec: 53654.39
Iteration:    380, Loss function: 6.423, Average Loss: 3.038, avg. samples / sec: 53518.50
Iteration:    380, Loss function: 6.742, Average Loss: 3.021, avg. samples / sec: 53601.45
Iteration:    380, Loss function: 6.321, Average Loss: 3.026, avg. samples / sec: 53703.46
Iteration:    380, Loss function: 6.146, Average Loss: 3.035, avg. samples / sec: 54050.66
Iteration:    380, Loss function: 7.196, Average Loss: 3.032, avg. samples / sec: 53700.43
Iteration:    380, Loss function: 5.810, Average Loss: 3.023, avg. samples / sec: 53606.65
Iteration:    380, Loss function: 6.540, Average Loss: 3.024, avg. samples / sec: 53404.65
Iteration:    380, Loss function: 6.616, Average Loss: 3.060, avg. samples / sec: 53699.86
Iteration:    380, Loss function: 6.513, Average Loss: 3.030, avg. samples / sec: 53463.70
Iteration:    380, Loss function: 6.498, Average Loss: 3.032, avg. samples / sec: 53680.40
Iteration:    380, Loss function: 6.061, Average Loss: 3.023, avg. samples / sec: 53515.21
Iteration:    380, Loss function: 7.190, Average Loss: 3.024, avg. samples / sec: 53615.58
Iteration:    380, Loss function: 6.415, Average Loss: 3.020, avg. samples / sec: 52325.38
Iteration:    400, Loss function: 6.167, Average Loss: 3.097, avg. samples / sec: 53737.20
Iteration:    400, Loss function: 7.154, Average Loss: 3.102, avg. samples / sec: 53758.63
Iteration:    400, Loss function: 7.144, Average Loss: 3.094, avg. samples / sec: 53717.54
Iteration:    400, Loss function: 7.378, Average Loss: 3.096, avg. samples / sec: 53389.05
Iteration:    400, Loss function: 7.942, Average Loss: 3.102, avg. samples / sec: 53684.11
Iteration:    400, Loss function: 6.526, Average Loss: 3.088, avg. samples / sec: 53581.74
Iteration:    400, Loss function: 5.879, Average Loss: 3.111, avg. samples / sec: 53572.25
Iteration:    400, Loss function: 6.770, Average Loss: 3.102, avg. samples / sec: 53773.68
Iteration:    400, Loss function: 6.325, Average Loss: 3.113, avg. samples / sec: 53606.96
Iteration:    400, Loss function: 6.420, Average Loss: 3.092, avg. samples / sec: 53518.30
Iteration:    400, Loss function: 7.437, Average Loss: 3.101, avg. samples / sec: 53574.47
Iteration:    400, Loss function: 6.412, Average Loss: 3.120, avg. samples / sec: 53608.08
Iteration:    400, Loss function: 6.219, Average Loss: 3.102, avg. samples / sec: 53572.37
Iteration:    400, Loss function: 6.946, Average Loss: 3.099, avg. samples / sec: 53578.99
Iteration:    400, Loss function: 7.936, Average Loss: 3.112, avg. samples / sec: 53698.87
Iteration:    400, Loss function: 7.163, Average Loss: 3.123, avg. samples / sec: 53533.81
Iteration:    400, Loss function: 7.657, Average Loss: 3.099, avg. samples / sec: 53762.69
Iteration:    400, Loss function: 6.896, Average Loss: 3.095, avg. samples / sec: 53531.13
Iteration:    400, Loss function: 6.634, Average Loss: 3.142, avg. samples / sec: 53698.24
Iteration:    400, Loss function: 7.721, Average Loss: 3.103, avg. samples / sec: 53688.13
Iteration:    400, Loss function: 7.697, Average Loss: 3.106, avg. samples / sec: 53378.45
Iteration:    400, Loss function: 7.244, Average Loss: 3.113, avg. samples / sec: 53321.18
Iteration:    400, Loss function: 8.388, Average Loss: 3.103, avg. samples / sec: 53570.89
Iteration:    400, Loss function: 6.193, Average Loss: 3.111, avg. samples / sec: 53564.58
Iteration:    400, Loss function: 6.446, Average Loss: 3.109, avg. samples / sec: 53522.08
Iteration:    400, Loss function: 7.368, Average Loss: 3.104, avg. samples / sec: 53495.14
Iteration:    400, Loss function: 8.008, Average Loss: 3.099, avg. samples / sec: 53512.71
Iteration:    400, Loss function: 6.817, Average Loss: 3.112, avg. samples / sec: 53358.79
Iteration:    400, Loss function: 5.927, Average Loss: 3.110, avg. samples / sec: 52686.25
Iteration:    400, Loss function: 7.322, Average Loss: 3.100, avg. samples / sec: 53904.17
:::MLL 1558641111.002 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558641111.002 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 8.406, Average Loss: 3.171, avg. samples / sec: 53555.80
Iteration:    420, Loss function: 6.880, Average Loss: 3.169, avg. samples / sec: 53628.42
Iteration:    420, Loss function: 7.123, Average Loss: 3.174, avg. samples / sec: 53746.08
Iteration:    420, Loss function: 6.279, Average Loss: 3.176, avg. samples / sec: 54683.26
Iteration:    420, Loss function: 6.661, Average Loss: 3.190, avg. samples / sec: 53645.09
Iteration:    420, Loss function: 6.308, Average Loss: 3.172, avg. samples / sec: 53673.43
Iteration:    420, Loss function: 6.269, Average Loss: 3.190, avg. samples / sec: 53643.26
Iteration:    420, Loss function: 5.709, Average Loss: 3.173, avg. samples / sec: 53669.28
Iteration:    420, Loss function: 6.786, Average Loss: 3.181, avg. samples / sec: 53809.72
Iteration:    420, Loss function: 6.186, Average Loss: 3.198, avg. samples / sec: 53661.82
Iteration:    420, Loss function: 6.478, Average Loss: 3.187, avg. samples / sec: 53674.15
Iteration:    420, Loss function: 6.680, Average Loss: 3.162, avg. samples / sec: 53593.89
Iteration:    420, Loss function: 6.972, Average Loss: 3.195, avg. samples / sec: 53603.88
Iteration:    420, Loss function: 5.494, Average Loss: 3.171, avg. samples / sec: 53605.59
Iteration:    420, Loss function: 6.861, Average Loss: 3.175, avg. samples / sec: 53502.63
Iteration:    420, Loss function: 7.740, Average Loss: 3.166, avg. samples / sec: 53544.63
Iteration:    420, Loss function: 5.738, Average Loss: 3.176, avg. samples / sec: 53511.63
Iteration:    420, Loss function: 6.483, Average Loss: 3.187, avg. samples / sec: 53742.61
Iteration:    420, Loss function: 6.054, Average Loss: 3.175, avg. samples / sec: 53747.33
Iteration:    420, Loss function: 6.957, Average Loss: 3.176, avg. samples / sec: 53230.32
Iteration:    420, Loss function: 6.184, Average Loss: 3.186, avg. samples / sec: 53696.56
Iteration:    420, Loss function: 7.021, Average Loss: 3.183, avg. samples / sec: 54308.97
Iteration:    420, Loss function: 7.419, Average Loss: 3.183, avg. samples / sec: 53666.28
Iteration:    420, Loss function: 5.872, Average Loss: 3.181, avg. samples / sec: 53631.54
Iteration:    420, Loss function: 7.695, Average Loss: 3.175, avg. samples / sec: 53534.85
Iteration:    420, Loss function: 5.603, Average Loss: 3.174, avg. samples / sec: 53436.66
Iteration:    420, Loss function: 6.564, Average Loss: 3.177, avg. samples / sec: 53566.37
Iteration:    420, Loss function: 5.634, Average Loss: 3.218, avg. samples / sec: 53406.85
Iteration:    420, Loss function: 7.275, Average Loss: 3.175, avg. samples / sec: 53536.35
Iteration:    420, Loss function: 6.409, Average Loss: 3.169, avg. samples / sec: 53213.08
Iteration:    440, Loss function: 5.266, Average Loss: 3.236, avg. samples / sec: 54488.33
Iteration:    440, Loss function: 7.154, Average Loss: 3.236, avg. samples / sec: 53948.30
Iteration:    440, Loss function: 6.303, Average Loss: 3.238, avg. samples / sec: 53954.91
Iteration:    440, Loss function: 7.059, Average Loss: 3.256, avg. samples / sec: 53996.98
Iteration:    440, Loss function: 6.561, Average Loss: 3.246, avg. samples / sec: 54130.90
Iteration:    440, Loss function: 5.395, Average Loss: 3.240, avg. samples / sec: 53952.62
Iteration:    440, Loss function: 7.376, Average Loss: 3.227, avg. samples / sec: 54001.06
Iteration:    440, Loss function: 5.935, Average Loss: 3.235, avg. samples / sec: 53987.30
Iteration:    440, Loss function: 6.161, Average Loss: 3.233, avg. samples / sec: 54089.27
Iteration:    440, Loss function: 6.992, Average Loss: 3.247, avg. samples / sec: 54100.77
Iteration:    440, Loss function: 6.043, Average Loss: 3.239, avg. samples / sec: 54083.60
Iteration:    440, Loss function: 6.562, Average Loss: 3.238, avg. samples / sec: 54226.86
Iteration:    440, Loss function: 6.121, Average Loss: 3.243, avg. samples / sec: 53935.50
Iteration:    440, Loss function: 6.557, Average Loss: 3.264, avg. samples / sec: 53947.46
Iteration:    440, Loss function: 6.467, Average Loss: 3.255, avg. samples / sec: 54155.74
Iteration:    440, Loss function: 5.902, Average Loss: 3.263, avg. samples / sec: 53929.97
Iteration:    440, Loss function: 6.825, Average Loss: 3.244, avg. samples / sec: 53869.65
Iteration:    440, Loss function: 5.759, Average Loss: 3.250, avg. samples / sec: 53915.73
Iteration:    440, Loss function: 6.412, Average Loss: 3.235, avg. samples / sec: 54014.08
Iteration:    440, Loss function: 6.512, Average Loss: 3.251, avg. samples / sec: 54072.46
Iteration:    440, Loss function: 6.376, Average Loss: 3.236, avg. samples / sec: 54059.27
Iteration:    440, Loss function: 6.497, Average Loss: 3.256, avg. samples / sec: 53863.56
Iteration:    440, Loss function: 5.312, Average Loss: 3.245, avg. samples / sec: 53950.62
Iteration:    440, Loss function: 6.208, Average Loss: 3.288, avg. samples / sec: 54027.50
Iteration:    440, Loss function: 6.233, Average Loss: 3.259, avg. samples / sec: 53663.50
Iteration:    440, Loss function: 5.794, Average Loss: 3.263, avg. samples / sec: 53770.01
Iteration:    440, Loss function: 7.710, Average Loss: 3.256, avg. samples / sec: 53801.66
Iteration:    440, Loss function: 8.449, Average Loss: 3.252, avg. samples / sec: 53803.78
Iteration:    440, Loss function: 5.059, Average Loss: 3.242, avg. samples / sec: 53889.02
Iteration:    440, Loss function: 7.846, Average Loss: 3.243, avg. samples / sec: 53519.74
Iteration:    460, Loss function: 7.088, Average Loss: 3.301, avg. samples / sec: 53641.32
Iteration:    460, Loss function: 6.688, Average Loss: 3.303, avg. samples / sec: 53626.21
Iteration:    460, Loss function: 5.828, Average Loss: 3.330, avg. samples / sec: 53595.13
Iteration:    460, Loss function: 7.520, Average Loss: 3.314, avg. samples / sec: 53601.17
Iteration:    460, Loss function: 6.225, Average Loss: 3.312, avg. samples / sec: 53568.22
Iteration:    460, Loss function: 6.314, Average Loss: 3.304, avg. samples / sec: 53498.37
Iteration:    460, Loss function: 6.834, Average Loss: 3.290, avg. samples / sec: 53500.38
Iteration:    460, Loss function: 7.063, Average Loss: 3.315, avg. samples / sec: 53506.45
Iteration:    460, Loss function: 7.062, Average Loss: 3.314, avg. samples / sec: 53509.28
Iteration:    460, Loss function: 6.749, Average Loss: 3.303, avg. samples / sec: 53605.02
Iteration:    460, Loss function: 6.577, Average Loss: 3.322, avg. samples / sec: 53763.34
Iteration:    460, Loss function: 5.993, Average Loss: 3.305, avg. samples / sec: 53772.16
Iteration:    460, Loss function: 5.754, Average Loss: 3.318, avg. samples / sec: 53308.17
Iteration:    460, Loss function: 6.983, Average Loss: 3.304, avg. samples / sec: 53324.79
Iteration:    460, Loss function: 7.080, Average Loss: 3.295, avg. samples / sec: 53266.94
Iteration:    460, Loss function: 6.568, Average Loss: 3.302, avg. samples / sec: 53077.20
Iteration:    460, Loss function: 6.909, Average Loss: 3.330, avg. samples / sec: 53469.02
Iteration:    460, Loss function: 5.998, Average Loss: 3.317, avg. samples / sec: 53197.47
Iteration:    460, Loss function: 6.794, Average Loss: 3.303, avg. samples / sec: 53151.21
Iteration:    460, Loss function: 6.802, Average Loss: 3.319, avg. samples / sec: 53103.00
Iteration:    460, Loss function: 6.299, Average Loss: 3.312, avg. samples / sec: 53108.24
Iteration:    460, Loss function: 5.711, Average Loss: 3.325, avg. samples / sec: 53229.34
Iteration:    460, Loss function: 8.860, Average Loss: 3.318, avg. samples / sec: 53103.46
Iteration:    460, Loss function: 6.322, Average Loss: 3.330, avg. samples / sec: 52804.01
Iteration:    460, Loss function: 6.980, Average Loss: 3.301, avg. samples / sec: 52626.25
Iteration:    460, Loss function: 6.939, Average Loss: 3.306, avg. samples / sec: 52695.47
Iteration:    460, Loss function: 6.499, Average Loss: 3.313, avg. samples / sec: 53312.38
Iteration:    460, Loss function: 6.343, Average Loss: 3.355, avg. samples / sec: 52647.66
Iteration:    460, Loss function: 5.725, Average Loss: 3.317, avg. samples / sec: 52614.46
Iteration:    460, Loss function: 6.501, Average Loss: 3.318, avg. samples / sec: 52634.80
Iteration:    480, Loss function: 6.629, Average Loss: 3.373, avg. samples / sec: 54154.41
Iteration:    480, Loss function: 6.787, Average Loss: 3.386, avg. samples / sec: 53915.20
Iteration:    480, Loss function: 7.730, Average Loss: 3.378, avg. samples / sec: 53627.15
Iteration:    480, Loss function: 6.657, Average Loss: 3.392, avg. samples / sec: 54226.53
Iteration:    480, Loss function: 6.243, Average Loss: 3.368, avg. samples / sec: 53420.01
Iteration:    480, Loss function: 7.192, Average Loss: 3.382, avg. samples / sec: 54981.77
Iteration:    480, Loss function: 7.628, Average Loss: 3.368, avg. samples / sec: 53996.13
Iteration:    480, Loss function: 6.202, Average Loss: 3.354, avg. samples / sec: 53630.99
Iteration:    480, Loss function: 7.132, Average Loss: 3.382, avg. samples / sec: 54298.90
Iteration:    480, Loss function: 5.743, Average Loss: 3.374, avg. samples / sec: 54477.48
Iteration:    480, Loss function: 7.239, Average Loss: 3.360, avg. samples / sec: 53876.06
Iteration:    480, Loss function: 6.042, Average Loss: 3.393, avg. samples / sec: 53569.44
Iteration:    480, Loss function: 6.479, Average Loss: 3.380, avg. samples / sec: 54777.25
Iteration:    480, Loss function: 5.724, Average Loss: 3.376, avg. samples / sec: 53587.96
Iteration:    480, Loss function: 6.221, Average Loss: 3.377, avg. samples / sec: 53633.50
Iteration:    480, Loss function: 6.102, Average Loss: 3.370, avg. samples / sec: 53981.93
Iteration:    480, Loss function: 5.970, Average Loss: 3.417, avg. samples / sec: 54704.19
Iteration:    480, Loss function: 5.941, Average Loss: 3.364, avg. samples / sec: 54314.05
Iteration:    480, Loss function: 6.087, Average Loss: 3.378, avg. samples / sec: 53639.01
Iteration:    480, Loss function: 6.018, Average Loss: 3.370, avg. samples / sec: 53691.43
Iteration:    480, Loss function: 6.373, Average Loss: 3.392, avg. samples / sec: 54242.16
Iteration:    480, Loss function: 7.226, Average Loss: 3.370, avg. samples / sec: 53556.29
Iteration:    480, Loss function: 7.601, Average Loss: 3.386, avg. samples / sec: 53810.68
Iteration:    480, Loss function: 6.918, Average Loss: 3.372, avg. samples / sec: 53580.01
Iteration:    480, Loss function: 6.080, Average Loss: 3.363, avg. samples / sec: 53333.40
Iteration:    480, Loss function: 6.756, Average Loss: 3.384, avg. samples / sec: 53736.45
Iteration:    480, Loss function: 7.003, Average Loss: 3.383, avg. samples / sec: 53520.03
Iteration:    480, Loss function: 7.154, Average Loss: 3.381, avg. samples / sec: 54269.73
Iteration:    480, Loss function: 5.510, Average Loss: 3.368, avg. samples / sec: 53225.88
Iteration:    480, Loss function: 7.072, Average Loss: 3.399, avg. samples / sec: 53557.17
:::MLL 1558641113.194 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558641113.195 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 7.238, Average Loss: 3.432, avg. samples / sec: 53934.95
Iteration:    500, Loss function: 6.843, Average Loss: 3.441, avg. samples / sec: 53922.81
Iteration:    500, Loss function: 5.469, Average Loss: 3.450, avg. samples / sec: 53973.78
Iteration:    500, Loss function: 6.411, Average Loss: 3.433, avg. samples / sec: 53983.70
Iteration:    500, Loss function: 6.214, Average Loss: 3.432, avg. samples / sec: 53936.41
Iteration:    500, Loss function: 6.517, Average Loss: 3.435, avg. samples / sec: 53948.14
Iteration:    500, Loss function: 6.136, Average Loss: 3.434, avg. samples / sec: 54051.95
Iteration:    500, Loss function: 5.936, Average Loss: 3.451, avg. samples / sec: 53920.89
Iteration:    500, Loss function: 6.106, Average Loss: 3.409, avg. samples / sec: 53906.54
Iteration:    500, Loss function: 7.347, Average Loss: 3.427, avg. samples / sec: 54311.60
Iteration:    500, Loss function: 6.370, Average Loss: 3.430, avg. samples / sec: 53885.00
Iteration:    500, Loss function: 5.665, Average Loss: 3.418, avg. samples / sec: 54142.69
Iteration:    500, Loss function: 6.051, Average Loss: 3.452, avg. samples / sec: 54046.18
Iteration:    500, Loss function: 6.437, Average Loss: 3.429, avg. samples / sec: 53920.17
Iteration:    500, Loss function: 5.440, Average Loss: 3.426, avg. samples / sec: 53859.71
Iteration:    500, Loss function: 6.248, Average Loss: 3.429, avg. samples / sec: 53862.80
Iteration:    500, Loss function: 6.333, Average Loss: 3.440, avg. samples / sec: 53768.94
Iteration:    500, Loss function: 6.455, Average Loss: 3.440, avg. samples / sec: 54001.24
Iteration:    500, Loss function: 6.935, Average Loss: 3.418, avg. samples / sec: 53813.23
Iteration:    500, Loss function: 5.076, Average Loss: 3.433, avg. samples / sec: 53952.08
Iteration:    500, Loss function: 6.046, Average Loss: 3.428, avg. samples / sec: 53908.00
Iteration:    500, Loss function: 6.387, Average Loss: 3.443, avg. samples / sec: 53929.04
Iteration:    500, Loss function: 5.639, Average Loss: 3.476, avg. samples / sec: 53769.70
Iteration:    500, Loss function: 6.108, Average Loss: 3.453, avg. samples / sec: 54079.62
Iteration:    500, Loss function: 6.397, Average Loss: 3.443, avg. samples / sec: 53905.40
Iteration:    500, Loss function: 6.733, Average Loss: 3.436, avg. samples / sec: 53649.67
Iteration:    500, Loss function: 5.226, Average Loss: 3.441, avg. samples / sec: 53792.03
Iteration:    500, Loss function: 6.469, Average Loss: 3.436, avg. samples / sec: 53577.87
Iteration:    500, Loss function: 5.755, Average Loss: 3.412, avg. samples / sec: 53448.21
Iteration:    500, Loss function: 7.055, Average Loss: 3.438, avg. samples / sec: 53401.43
Iteration:    520, Loss function: 5.904, Average Loss: 3.489, avg. samples / sec: 53471.17
Iteration:    520, Loss function: 6.841, Average Loss: 3.492, avg. samples / sec: 54168.50
Iteration:    520, Loss function: 6.399, Average Loss: 3.486, avg. samples / sec: 53770.03
Iteration:    520, Loss function: 6.593, Average Loss: 3.505, avg. samples / sec: 53489.82
Iteration:    520, Loss function: 6.468, Average Loss: 3.490, avg. samples / sec: 53474.01
Iteration:    520, Loss function: 6.206, Average Loss: 3.459, avg. samples / sec: 53475.21
Iteration:    520, Loss function: 6.211, Average Loss: 3.485, avg. samples / sec: 53480.42
Iteration:    520, Loss function: 6.024, Average Loss: 3.466, avg. samples / sec: 53924.15
Iteration:    520, Loss function: 6.485, Average Loss: 3.502, avg. samples / sec: 53549.51
Iteration:    520, Loss function: 7.332, Average Loss: 3.487, avg. samples / sec: 53430.60
Iteration:    520, Loss function: 7.109, Average Loss: 3.476, avg. samples / sec: 53406.97
Iteration:    520, Loss function: 6.688, Average Loss: 3.491, avg. samples / sec: 53338.69
Iteration:    520, Loss function: 7.174, Average Loss: 3.506, avg. samples / sec: 53395.02
Iteration:    520, Loss function: 5.938, Average Loss: 3.489, avg. samples / sec: 53352.22
Iteration:    520, Loss function: 7.032, Average Loss: 3.482, avg. samples / sec: 53378.15
Iteration:    520, Loss function: 6.955, Average Loss: 3.487, avg. samples / sec: 53342.02
Iteration:    520, Loss function: 6.554, Average Loss: 3.499, avg. samples / sec: 53525.84
Iteration:    520, Loss function: 7.198, Average Loss: 3.493, avg. samples / sec: 53434.41
Iteration:    520, Loss function: 7.028, Average Loss: 3.497, avg. samples / sec: 53481.56
Iteration:    520, Loss function: 6.592, Average Loss: 3.494, avg. samples / sec: 53173.59
Iteration:    520, Loss function: 6.035, Average Loss: 3.524, avg. samples / sec: 53509.16
Iteration:    520, Loss function: 6.441, Average Loss: 3.508, avg. samples / sec: 53182.01
Iteration:    520, Loss function: 6.495, Average Loss: 3.489, avg. samples / sec: 53470.95
Iteration:    520, Loss function: 7.255, Average Loss: 3.512, avg. samples / sec: 53492.40
Iteration:    520, Loss function: 5.639, Average Loss: 3.486, avg. samples / sec: 53444.71
Iteration:    520, Loss function: 6.209, Average Loss: 3.484, avg. samples / sec: 53200.95
Iteration:    520, Loss function: 5.967, Average Loss: 3.497, avg. samples / sec: 53464.96
Iteration:    520, Loss function: 5.465, Average Loss: 3.471, avg. samples / sec: 53391.74
Iteration:    520, Loss function: 6.738, Average Loss: 3.498, avg. samples / sec: 53318.25
Iteration:    520, Loss function: 6.913, Average Loss: 3.493, avg. samples / sec: 52896.15
Iteration:    540, Loss function: 5.664, Average Loss: 3.552, avg. samples / sec: 54445.05
Iteration:    540, Loss function: 6.832, Average Loss: 3.542, avg. samples / sec: 54427.60
Iteration:    540, Loss function: 6.125, Average Loss: 3.571, avg. samples / sec: 54648.98
Iteration:    540, Loss function: 5.868, Average Loss: 3.546, avg. samples / sec: 54637.66
Iteration:    540, Loss function: 5.945, Average Loss: 3.539, avg. samples / sec: 54265.93
Iteration:    540, Loss function: 6.232, Average Loss: 3.544, avg. samples / sec: 54411.88
Iteration:    540, Loss function: 6.687, Average Loss: 3.535, avg. samples / sec: 54478.49
Iteration:    540, Loss function: 5.303, Average Loss: 3.542, avg. samples / sec: 54515.69
Iteration:    540, Loss function: 6.834, Average Loss: 3.546, avg. samples / sec: 54531.70
Iteration:    540, Loss function: 6.942, Average Loss: 3.548, avg. samples / sec: 54487.47
Iteration:    540, Loss function: 5.724, Average Loss: 3.552, avg. samples / sec: 54634.93
Iteration:    540, Loss function: 5.761, Average Loss: 3.547, avg. samples / sec: 54622.73
Iteration:    540, Loss function: 7.179, Average Loss: 3.555, avg. samples / sec: 54937.98
Iteration:    540, Loss function: 5.413, Average Loss: 3.549, avg. samples / sec: 54564.42
Iteration:    540, Loss function: 5.943, Average Loss: 3.545, avg. samples / sec: 54434.37
Iteration:    540, Loss function: 6.462, Average Loss: 3.551, avg. samples / sec: 55394.12
Iteration:    540, Loss function: 8.032, Average Loss: 3.572, avg. samples / sec: 54549.79
Iteration:    540, Loss function: 6.975, Average Loss: 3.515, avg. samples / sec: 54290.70
Iteration:    540, Loss function: 6.101, Average Loss: 3.560, avg. samples / sec: 54348.44
Iteration:    540, Loss function: 5.267, Average Loss: 3.546, avg. samples / sec: 54436.32
Iteration:    540, Loss function: 6.076, Average Loss: 3.524, avg. samples / sec: 54470.05
Iteration:    540, Loss function: 5.599, Average Loss: 3.553, avg. samples / sec: 54396.32
Iteration:    540, Loss function: 6.033, Average Loss: 3.561, avg. samples / sec: 54383.80
Iteration:    540, Loss function: 5.006, Average Loss: 3.577, avg. samples / sec: 54380.89
Iteration:    540, Loss function: 6.604, Average Loss: 3.549, avg. samples / sec: 54170.35
Iteration:    540, Loss function: 6.544, Average Loss: 3.525, avg. samples / sec: 54175.48
Iteration:    540, Loss function: 6.874, Average Loss: 3.549, avg. samples / sec: 54378.29
Iteration:    540, Loss function: 5.891, Average Loss: 3.567, avg. samples / sec: 54372.56
Iteration:    540, Loss function: 6.706, Average Loss: 3.549, avg. samples / sec: 54066.69
Iteration:    540, Loss function: 4.841, Average Loss: 3.562, avg. samples / sec: 53837.92
:::MLL 1558641115.374 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558641115.375 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 6.171, Average Loss: 3.601, avg. samples / sec: 53598.78
Iteration:    560, Loss function: 5.795, Average Loss: 3.595, avg. samples / sec: 53784.68
Iteration:    560, Loss function: 4.994, Average Loss: 3.603, avg. samples / sec: 54277.28
Iteration:    560, Loss function: 5.447, Average Loss: 3.598, avg. samples / sec: 53757.13
Iteration:    560, Loss function: 6.339, Average Loss: 3.567, avg. samples / sec: 53823.49
Iteration:    560, Loss function: 5.076, Average Loss: 3.585, avg. samples / sec: 53717.93
Iteration:    560, Loss function: 6.819, Average Loss: 3.594, avg. samples / sec: 53728.52
Iteration:    560, Loss function: 4.775, Average Loss: 3.588, avg. samples / sec: 53634.52
Iteration:    560, Loss function: 5.253, Average Loss: 3.591, avg. samples / sec: 53707.59
Iteration:    560, Loss function: 5.686, Average Loss: 3.601, avg. samples / sec: 53545.14
Iteration:    560, Loss function: 6.270, Average Loss: 3.620, avg. samples / sec: 53534.10
Iteration:    560, Loss function: 5.014, Average Loss: 3.591, avg. samples / sec: 53425.48
Iteration:    560, Loss function: 7.433, Average Loss: 3.578, avg. samples / sec: 53892.19
Iteration:    560, Loss function: 7.142, Average Loss: 3.600, avg. samples / sec: 53708.19
Iteration:    560, Loss function: 6.331, Average Loss: 3.609, avg. samples / sec: 53692.82
Iteration:    560, Loss function: 6.294, Average Loss: 3.598, avg. samples / sec: 53723.28
Iteration:    560, Loss function: 6.767, Average Loss: 3.604, avg. samples / sec: 53633.34
Iteration:    560, Loss function: 5.735, Average Loss: 3.600, avg. samples / sec: 53635.34
Iteration:    560, Loss function: 5.491, Average Loss: 3.612, avg. samples / sec: 53816.85
Iteration:    560, Loss function: 5.323, Average Loss: 3.595, avg. samples / sec: 53631.46
Iteration:    560, Loss function: 4.734, Average Loss: 3.596, avg. samples / sec: 53804.17
Iteration:    560, Loss function: 5.983, Average Loss: 3.613, avg. samples / sec: 53795.11
Iteration:    560, Loss function: 6.957, Average Loss: 3.605, avg. samples / sec: 53609.18
Iteration:    560, Loss function: 5.589, Average Loss: 3.623, avg. samples / sec: 53532.33
Iteration:    560, Loss function: 5.849, Average Loss: 3.623, avg. samples / sec: 53600.04
Iteration:    560, Loss function: 5.915, Average Loss: 3.575, avg. samples / sec: 53564.56
Iteration:    560, Loss function: 5.842, Average Loss: 3.598, avg. samples / sec: 53571.76
Iteration:    560, Loss function: 5.907, Average Loss: 3.596, avg. samples / sec: 53521.80
Iteration:    560, Loss function: 5.415, Average Loss: 3.598, avg. samples / sec: 53415.40
Iteration:    560, Loss function: 6.154, Average Loss: 3.613, avg. samples / sec: 53551.75
Iteration:    580, Loss function: 5.504, Average Loss: 3.644, avg. samples / sec: 53325.07
Iteration:    580, Loss function: 6.013, Average Loss: 3.637, avg. samples / sec: 53400.38
Iteration:    580, Loss function: 5.675, Average Loss: 3.643, avg. samples / sec: 53706.43
Iteration:    580, Loss function: 6.555, Average Loss: 3.618, avg. samples / sec: 53242.65
Iteration:    580, Loss function: 5.836, Average Loss: 3.648, avg. samples / sec: 53346.26
Iteration:    580, Loss function: 6.472, Average Loss: 3.651, avg. samples / sec: 53204.54
Iteration:    580, Loss function: 5.383, Average Loss: 3.629, avg. samples / sec: 53279.04
Iteration:    580, Loss function: 6.364, Average Loss: 3.648, avg. samples / sec: 53257.98
Iteration:    580, Loss function: 5.740, Average Loss: 3.649, avg. samples / sec: 53320.79
Iteration:    580, Loss function: 5.520, Average Loss: 3.648, avg. samples / sec: 53120.61
Iteration:    580, Loss function: 5.928, Average Loss: 3.629, avg. samples / sec: 53194.30
Iteration:    580, Loss function: 4.963, Average Loss: 3.671, avg. samples / sec: 53227.11
Iteration:    580, Loss function: 5.572, Average Loss: 3.663, avg. samples / sec: 53881.45
Iteration:    580, Loss function: 5.978, Average Loss: 3.640, avg. samples / sec: 53192.11
Iteration:    580, Loss function: 5.329, Average Loss: 3.648, avg. samples / sec: 53206.95
Iteration:    580, Loss function: 6.441, Average Loss: 3.651, avg. samples / sec: 53118.45
Iteration:    580, Loss function: 6.191, Average Loss: 3.629, avg. samples / sec: 53489.60
Iteration:    580, Loss function: 6.444, Average Loss: 3.673, avg. samples / sec: 53341.32
Iteration:    580, Loss function: 6.262, Average Loss: 3.655, avg. samples / sec: 53221.04
Iteration:    580, Loss function: 6.757, Average Loss: 3.643, avg. samples / sec: 53128.04
Iteration:    580, Loss function: 4.950, Average Loss: 3.647, avg. samples / sec: 53498.27
Iteration:    580, Loss function: 6.275, Average Loss: 3.648, avg. samples / sec: 53337.26
Iteration:    580, Loss function: 6.380, Average Loss: 3.660, avg. samples / sec: 53086.64
Iteration:    580, Loss function: 5.985, Average Loss: 3.649, avg. samples / sec: 53114.13
Iteration:    580, Loss function: 6.113, Average Loss: 3.671, avg. samples / sec: 53210.29
Iteration:    580, Loss function: 6.061, Average Loss: 3.642, avg. samples / sec: 52948.77
Iteration:    580, Loss function: 6.848, Average Loss: 3.648, avg. samples / sec: 52988.71
Iteration:    580, Loss function: 5.531, Average Loss: 3.656, avg. samples / sec: 52997.76
Iteration:    580, Loss function: 5.517, Average Loss: 3.661, avg. samples / sec: 52887.75
Iteration:    580, Loss function: 5.213, Average Loss: 3.638, avg. samples / sec: 52292.82
Iteration:    600, Loss function: 5.904, Average Loss: 3.691, avg. samples / sec: 54145.34
Iteration:    600, Loss function: 5.919, Average Loss: 3.679, avg. samples / sec: 53679.61
Iteration:    600, Loss function: 5.899, Average Loss: 3.693, avg. samples / sec: 53570.66
Iteration:    600, Loss function: 5.292, Average Loss: 3.692, avg. samples / sec: 53811.38
Iteration:    600, Loss function: 5.903, Average Loss: 3.700, avg. samples / sec: 53704.62
Iteration:    600, Loss function: 6.427, Average Loss: 3.669, avg. samples / sec: 53646.24
Iteration:    600, Loss function: 6.134, Average Loss: 3.675, avg. samples / sec: 53656.61
Iteration:    600, Loss function: 6.884, Average Loss: 3.695, avg. samples / sec: 53911.98
Iteration:    600, Loss function: 5.757, Average Loss: 3.694, avg. samples / sec: 53658.80
Iteration:    600, Loss function: 5.614, Average Loss: 3.691, avg. samples / sec: 53681.49
Iteration:    600, Loss function: 5.881, Average Loss: 3.686, avg. samples / sec: 53664.83
Iteration:    600, Loss function: 5.501, Average Loss: 3.706, avg. samples / sec: 53666.18
Iteration:    600, Loss function: 4.327, Average Loss: 3.691, avg. samples / sec: 53640.75
Iteration:    600, Loss function: 5.414, Average Loss: 3.684, avg. samples / sec: 53921.26
Iteration:    600, Loss function: 6.786, Average Loss: 3.696, avg. samples / sec: 53598.31
Iteration:    600, Loss function: 6.544, Average Loss: 3.685, avg. samples / sec: 53823.61
Iteration:    600, Loss function: 6.077, Average Loss: 3.715, avg. samples / sec: 53620.97
Iteration:    600, Loss function: 6.630, Average Loss: 3.698, avg. samples / sec: 53643.79
Iteration:    600, Loss function: 5.412, Average Loss: 3.682, avg. samples / sec: 53566.86
Iteration:    600, Loss function: 6.700, Average Loss: 3.691, avg. samples / sec: 53675.03
Iteration:    600, Loss function: 6.299, Average Loss: 3.716, avg. samples / sec: 53726.65
Iteration:    600, Loss function: 5.853, Average Loss: 3.688, avg. samples / sec: 53337.68
Iteration:    600, Loss function: 5.541, Average Loss: 3.708, avg. samples / sec: 53801.68
Iteration:    600, Loss function: 5.500, Average Loss: 3.718, avg. samples / sec: 53616.91
Iteration:    600, Loss function: 7.325, Average Loss: 3.700, avg. samples / sec: 53646.05
Iteration:    600, Loss function: 6.022, Average Loss: 3.709, avg. samples / sec: 53639.75
Iteration:    600, Loss function: 5.949, Average Loss: 3.700, avg. samples / sec: 53776.06
Iteration:    600, Loss function: 4.409, Average Loss: 3.669, avg. samples / sec: 53461.92
Iteration:    600, Loss function: 5.495, Average Loss: 3.686, avg. samples / sec: 53473.28
Iteration:    600, Loss function: 6.701, Average Loss: 3.707, avg. samples / sec: 52607.41
Iteration:    620, Loss function: 5.809, Average Loss: 3.720, avg. samples / sec: 53410.82
Iteration:    620, Loss function: 5.863, Average Loss: 3.725, avg. samples / sec: 53520.37
Iteration:    620, Loss function: 7.324, Average Loss: 3.714, avg. samples / sec: 53474.35
Iteration:    620, Loss function: 5.736, Average Loss: 3.737, avg. samples / sec: 53464.23
Iteration:    620, Loss function: 5.282, Average Loss: 3.747, avg. samples / sec: 53719.20
Iteration:    620, Loss function: 6.454, Average Loss: 3.746, avg. samples / sec: 53456.38
Iteration:    620, Loss function: 5.496, Average Loss: 3.732, avg. samples / sec: 53651.94
Iteration:    620, Loss function: 5.146, Average Loss: 3.719, avg. samples / sec: 53413.13
Iteration:    620, Loss function: 6.163, Average Loss: 3.730, avg. samples / sec: 54570.55
Iteration:    620, Loss function: 5.733, Average Loss: 3.728, avg. samples / sec: 53507.53
Iteration:    620, Loss function: 5.001, Average Loss: 3.729, avg. samples / sec: 53418.11
Iteration:    620, Loss function: 5.654, Average Loss: 3.738, avg. samples / sec: 53426.17
Iteration:    620, Loss function: 6.033, Average Loss: 3.757, avg. samples / sec: 53443.63
Iteration:    620, Loss function: 6.038, Average Loss: 3.743, avg. samples / sec: 53477.60
Iteration:    620, Loss function: 6.843, Average Loss: 3.743, avg. samples / sec: 53354.26
Iteration:    620, Loss function: 6.799, Average Loss: 3.734, avg. samples / sec: 53360.22
Iteration:    620, Loss function: 6.152, Average Loss: 3.732, avg. samples / sec: 53160.41
Iteration:    620, Loss function: 7.773, Average Loss: 3.763, avg. samples / sec: 53477.97
Iteration:    620, Loss function: 6.153, Average Loss: 3.749, avg. samples / sec: 54503.19
Iteration:    620, Loss function: 6.882, Average Loss: 3.733, avg. samples / sec: 53403.07
Iteration:    620, Loss function: 6.164, Average Loss: 3.758, avg. samples / sec: 53403.84
Iteration:    620, Loss function: 7.467, Average Loss: 3.746, avg. samples / sec: 53436.40
Iteration:    620, Loss function: 5.761, Average Loss: 3.726, avg. samples / sec: 53235.83
Iteration:    620, Loss function: 6.376, Average Loss: 3.755, avg. samples / sec: 53431.01
Iteration:    620, Loss function: 6.225, Average Loss: 3.735, avg. samples / sec: 53016.62
Iteration:    620, Loss function: 5.189, Average Loss: 3.750, avg. samples / sec: 53420.36
Iteration:    620, Loss function: 5.997, Average Loss: 3.738, avg. samples / sec: 53180.85
Iteration:    620, Loss function: 5.293, Average Loss: 3.733, avg. samples / sec: 53004.99
Iteration:    620, Loss function: 6.210, Average Loss: 3.711, avg. samples / sec: 53415.17
Iteration:    620, Loss function: 5.531, Average Loss: 3.743, avg. samples / sec: 53041.06
:::MLL 1558641117.576 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558641117.577 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 5.067, Average Loss: 3.771, avg. samples / sec: 53908.45
Iteration:    640, Loss function: 5.793, Average Loss: 3.761, avg. samples / sec: 53811.57
Iteration:    640, Loss function: 5.667, Average Loss: 3.770, avg. samples / sec: 54057.15
Iteration:    640, Loss function: 5.980, Average Loss: 3.782, avg. samples / sec: 54275.79
Iteration:    640, Loss function: 5.199, Average Loss: 3.777, avg. samples / sec: 54195.87
Iteration:    640, Loss function: 5.698, Average Loss: 3.792, avg. samples / sec: 54143.65
Iteration:    640, Loss function: 5.660, Average Loss: 3.787, avg. samples / sec: 54082.92
Iteration:    640, Loss function: 5.810, Average Loss: 3.760, avg. samples / sec: 53789.12
Iteration:    640, Loss function: 5.238, Average Loss: 3.781, avg. samples / sec: 54126.12
Iteration:    640, Loss function: 6.304, Average Loss: 3.790, avg. samples / sec: 53825.89
Iteration:    640, Loss function: 6.649, Average Loss: 3.774, avg. samples / sec: 53834.20
Iteration:    640, Loss function: 6.066, Average Loss: 3.759, avg. samples / sec: 53820.03
Iteration:    640, Loss function: 7.445, Average Loss: 3.778, avg. samples / sec: 53761.83
Iteration:    640, Loss function: 6.337, Average Loss: 3.776, avg. samples / sec: 53822.81
Iteration:    640, Loss function: 5.753, Average Loss: 3.784, avg. samples / sec: 53828.40
Iteration:    640, Loss function: 5.677, Average Loss: 3.775, avg. samples / sec: 53773.97
Iteration:    640, Loss function: 5.071, Average Loss: 3.766, avg. samples / sec: 54012.71
Iteration:    640, Loss function: 4.665, Average Loss: 3.794, avg. samples / sec: 53811.54
Iteration:    640, Loss function: 6.114, Average Loss: 3.775, avg. samples / sec: 53849.46
Iteration:    640, Loss function: 6.901, Average Loss: 3.778, avg. samples / sec: 53770.19
Iteration:    640, Loss function: 5.368, Average Loss: 3.772, avg. samples / sec: 53946.88
Iteration:    640, Loss function: 5.260, Average Loss: 3.798, avg. samples / sec: 53894.44
Iteration:    640, Loss function: 5.750, Average Loss: 3.775, avg. samples / sec: 53668.42
Iteration:    640, Loss function: 5.550, Average Loss: 3.801, avg. samples / sec: 53827.45
Iteration:    640, Loss function: 4.929, Average Loss: 3.787, avg. samples / sec: 53850.18
Iteration:    640, Loss function: 4.743, Average Loss: 3.782, avg. samples / sec: 53556.33
Iteration:    640, Loss function: 5.094, Average Loss: 3.778, avg. samples / sec: 53827.72
Iteration:    640, Loss function: 4.969, Average Loss: 3.785, avg. samples / sec: 53646.03
Iteration:    640, Loss function: 5.896, Average Loss: 3.749, avg. samples / sec: 53842.30
Iteration:    640, Loss function: 5.079, Average Loss: 3.800, avg. samples / sec: 53781.83
Iteration:    660, Loss function: 5.158, Average Loss: 3.800, avg. samples / sec: 53750.34
Iteration:    660, Loss function: 5.898, Average Loss: 3.797, avg. samples / sec: 53745.07
Iteration:    660, Loss function: 7.038, Average Loss: 3.818, avg. samples / sec: 53899.90
Iteration:    660, Loss function: 5.663, Average Loss: 3.832, avg. samples / sec: 53713.55
Iteration:    660, Loss function: 5.591, Average Loss: 3.814, avg. samples / sec: 53736.82
Iteration:    660, Loss function: 5.907, Average Loss: 3.826, avg. samples / sec: 53924.79
Iteration:    660, Loss function: 6.708, Average Loss: 3.824, avg. samples / sec: 53675.60
Iteration:    660, Loss function: 6.177, Average Loss: 3.833, avg. samples / sec: 53746.47
Iteration:    660, Loss function: 5.135, Average Loss: 3.793, avg. samples / sec: 53634.21
Iteration:    660, Loss function: 5.748, Average Loss: 3.826, avg. samples / sec: 53696.01
Iteration:    660, Loss function: 5.967, Average Loss: 3.814, avg. samples / sec: 53693.49
Iteration:    660, Loss function: 6.514, Average Loss: 3.817, avg. samples / sec: 53729.38
Iteration:    660, Loss function: 5.287, Average Loss: 3.815, avg. samples / sec: 53551.06
Iteration:    660, Loss function: 5.170, Average Loss: 3.833, avg. samples / sec: 53813.93
Iteration:    660, Loss function: 5.369, Average Loss: 3.827, avg. samples / sec: 53575.19
Iteration:    660, Loss function: 5.577, Average Loss: 3.818, avg. samples / sec: 53569.69
Iteration:    660, Loss function: 5.130, Average Loss: 3.809, avg. samples / sec: 53570.56
Iteration:    660, Loss function: 6.902, Average Loss: 3.821, avg. samples / sec: 53741.28
Iteration:    660, Loss function: 5.318, Average Loss: 3.813, avg. samples / sec: 53603.67
Iteration:    660, Loss function: 5.674, Average Loss: 3.812, avg. samples / sec: 53520.17
Iteration:    660, Loss function: 5.548, Average Loss: 3.817, avg. samples / sec: 53721.68
Iteration:    660, Loss function: 6.164, Average Loss: 3.841, avg. samples / sec: 53652.79
Iteration:    660, Loss function: 5.808, Average Loss: 3.833, avg. samples / sec: 53746.82
Iteration:    660, Loss function: 4.734, Average Loss: 3.825, avg. samples / sec: 53710.50
Iteration:    660, Loss function: 5.411, Average Loss: 3.823, avg. samples / sec: 53317.16
Iteration:    660, Loss function: 5.101, Average Loss: 3.830, avg. samples / sec: 53389.61
Iteration:    660, Loss function: 6.571, Average Loss: 3.819, avg. samples / sec: 53282.39
Iteration:    660, Loss function: 7.397, Average Loss: 3.793, avg. samples / sec: 53574.37
Iteration:    660, Loss function: 5.245, Average Loss: 3.804, avg. samples / sec: 53144.49
Iteration:    660, Loss function: 5.409, Average Loss: 3.813, avg. samples / sec: 53139.80
Iteration:    680, Loss function: 5.505, Average Loss: 3.843, avg. samples / sec: 53835.25
Iteration:    680, Loss function: 5.584, Average Loss: 3.853, avg. samples / sec: 54108.52
Iteration:    680, Loss function: 5.304, Average Loss: 3.853, avg. samples / sec: 53910.19
Iteration:    680, Loss function: 6.526, Average Loss: 3.857, avg. samples / sec: 54041.00
Iteration:    680, Loss function: 5.752, Average Loss: 3.842, avg. samples / sec: 54249.13
Iteration:    680, Loss function: 5.024, Average Loss: 3.874, avg. samples / sec: 53910.58
Iteration:    680, Loss function: 4.491, Average Loss: 3.851, avg. samples / sec: 54019.61
Iteration:    680, Loss function: 4.402, Average Loss: 3.832, avg. samples / sec: 53812.24
Iteration:    680, Loss function: 4.949, Average Loss: 3.851, avg. samples / sec: 54352.57
Iteration:    680, Loss function: 7.539, Average Loss: 3.858, avg. samples / sec: 53838.97
Iteration:    680, Loss function: 5.995, Average Loss: 3.858, avg. samples / sec: 53747.53
Iteration:    680, Loss function: 6.071, Average Loss: 3.867, avg. samples / sec: 53805.71
Iteration:    680, Loss function: 6.642, Average Loss: 3.846, avg. samples / sec: 53818.45
Iteration:    680, Loss function: 4.833, Average Loss: 3.857, avg. samples / sec: 53764.43
Iteration:    680, Loss function: 6.059, Average Loss: 3.855, avg. samples / sec: 53751.55
Iteration:    680, Loss function: 5.289, Average Loss: 3.863, avg. samples / sec: 53977.29
Iteration:    680, Loss function: 7.776, Average Loss: 3.871, avg. samples / sec: 53698.38
Iteration:    680, Loss function: 5.298, Average Loss: 3.873, avg. samples / sec: 53920.83
Iteration:    680, Loss function: 5.916, Average Loss: 3.844, avg. samples / sec: 53856.11
Iteration:    680, Loss function: 6.040, Average Loss: 3.854, avg. samples / sec: 53864.16
Iteration:    680, Loss function: 5.580, Average Loss: 3.864, avg. samples / sec: 53683.33
Iteration:    680, Loss function: 4.817, Average Loss: 3.848, avg. samples / sec: 53798.87
Iteration:    680, Loss function: 6.100, Average Loss: 3.855, avg. samples / sec: 53781.01
Iteration:    680, Loss function: 6.128, Average Loss: 3.882, avg. samples / sec: 53799.57
Iteration:    680, Loss function: 5.152, Average Loss: 3.859, avg. samples / sec: 53574.37
Iteration:    680, Loss function: 7.049, Average Loss: 3.867, avg. samples / sec: 53800.94
Iteration:    680, Loss function: 5.279, Average Loss: 3.833, avg. samples / sec: 53955.39
Iteration:    680, Loss function: 6.131, Average Loss: 3.869, avg. samples / sec: 53396.94
Iteration:    680, Loss function: 5.197, Average Loss: 3.834, avg. samples / sec: 53099.68
Iteration:    680, Loss function: 5.157, Average Loss: 3.867, avg. samples / sec: 53063.13
:::MLL 1558641119.764 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558641119.764 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 4.900, Average Loss: 3.892, avg. samples / sec: 53638.01
Iteration:    700, Loss function: 5.670, Average Loss: 3.859, avg. samples / sec: 53552.08
Iteration:    700, Loss function: 5.059, Average Loss: 3.888, avg. samples / sec: 53484.85
Iteration:    700, Loss function: 5.031, Average Loss: 3.894, avg. samples / sec: 53523.48
Iteration:    700, Loss function: 4.945, Average Loss: 3.878, avg. samples / sec: 53257.42
Iteration:    700, Loss function: 6.418, Average Loss: 3.900, avg. samples / sec: 53882.48
Iteration:    700, Loss function: 4.836, Average Loss: 3.886, avg. samples / sec: 53506.21
Iteration:    700, Loss function: 5.308, Average Loss: 3.886, avg. samples / sec: 53603.02
Iteration:    700, Loss function: 5.544, Average Loss: 3.910, avg. samples / sec: 53662.64
Iteration:    700, Loss function: 5.815, Average Loss: 3.892, avg. samples / sec: 53449.79
Iteration:    700, Loss function: 6.170, Average Loss: 3.906, avg. samples / sec: 53524.89
Iteration:    700, Loss function: 5.073, Average Loss: 3.872, avg. samples / sec: 53391.78
Iteration:    700, Loss function: 5.534, Average Loss: 3.867, avg. samples / sec: 54082.44
Iteration:    700, Loss function: 6.209, Average Loss: 3.888, avg. samples / sec: 53457.54
Iteration:    700, Loss function: 6.306, Average Loss: 3.896, avg. samples / sec: 53591.08
Iteration:    700, Loss function: 3.729, Average Loss: 3.906, avg. samples / sec: 53361.98
Iteration:    700, Loss function: 5.471, Average Loss: 3.894, avg. samples / sec: 53461.35
Iteration:    700, Loss function: 5.902, Average Loss: 3.882, avg. samples / sec: 53351.82
Iteration:    700, Loss function: 4.962, Average Loss: 3.884, avg. samples / sec: 53559.77
Iteration:    700, Loss function: 6.070, Average Loss: 3.893, avg. samples / sec: 53304.82
Iteration:    700, Loss function: 6.023, Average Loss: 3.896, avg. samples / sec: 54317.17
Iteration:    700, Loss function: 5.643, Average Loss: 3.876, avg. samples / sec: 53415.44
Iteration:    700, Loss function: 5.677, Average Loss: 3.870, avg. samples / sec: 53527.18
Iteration:    700, Loss function: 6.177, Average Loss: 3.899, avg. samples / sec: 53495.69
Iteration:    700, Loss function: 6.515, Average Loss: 3.897, avg. samples / sec: 53465.33
Iteration:    700, Loss function: 5.538, Average Loss: 3.881, avg. samples / sec: 53220.39
Iteration:    700, Loss function: 5.391, Average Loss: 3.906, avg. samples / sec: 53277.76
Iteration:    700, Loss function: 4.845, Average Loss: 3.894, avg. samples / sec: 53290.04
Iteration:    700, Loss function: 5.691, Average Loss: 3.898, avg. samples / sec: 53017.58
Iteration:    700, Loss function: 5.474, Average Loss: 3.884, avg. samples / sec: 52525.17
Iteration:    720, Loss function: 4.547, Average Loss: 3.912, avg. samples / sec: 54313.09
Iteration:    720, Loss function: 5.382, Average Loss: 3.904, avg. samples / sec: 54341.00
Iteration:    720, Loss function: 5.564, Average Loss: 3.934, avg. samples / sec: 54276.94
Iteration:    720, Loss function: 4.578, Average Loss: 3.889, avg. samples / sec: 54101.69
Iteration:    720, Loss function: 5.522, Average Loss: 3.915, avg. samples / sec: 54443.22
Iteration:    720, Loss function: 5.658, Average Loss: 3.913, avg. samples / sec: 55084.41
Iteration:    720, Loss function: 3.673, Average Loss: 3.924, avg. samples / sec: 54094.15
Iteration:    720, Loss function: 5.499, Average Loss: 3.924, avg. samples / sec: 54066.05
Iteration:    720, Loss function: 5.288, Average Loss: 3.916, avg. samples / sec: 54227.17
Iteration:    720, Loss function: 5.324, Average Loss: 3.921, avg. samples / sec: 53984.45
Iteration:    720, Loss function: 5.964, Average Loss: 3.923, avg. samples / sec: 54145.50
Iteration:    720, Loss function: 6.802, Average Loss: 3.924, avg. samples / sec: 54070.51
Iteration:    720, Loss function: 4.797, Average Loss: 3.930, avg. samples / sec: 54025.63
Iteration:    720, Loss function: 6.223, Average Loss: 3.943, avg. samples / sec: 54081.34
Iteration:    720, Loss function: 6.252, Average Loss: 3.939, avg. samples / sec: 54039.03
Iteration:    720, Loss function: 5.863, Average Loss: 3.919, avg. samples / sec: 53974.28
Iteration:    720, Loss function: 5.749, Average Loss: 3.931, avg. samples / sec: 54444.23
Iteration:    720, Loss function: 4.646, Average Loss: 3.926, avg. samples / sec: 54009.73
Iteration:    720, Loss function: 5.931, Average Loss: 3.940, avg. samples / sec: 54096.16
Iteration:    720, Loss function: 5.496, Average Loss: 3.921, avg. samples / sec: 53971.65
Iteration:    720, Loss function: 4.216, Average Loss: 3.941, avg. samples / sec: 54229.70
Iteration:    720, Loss function: 5.936, Average Loss: 3.913, avg. samples / sec: 54102.41
Iteration:    720, Loss function: 6.000, Average Loss: 3.919, avg. samples / sec: 54024.06
Iteration:    720, Loss function: 5.830, Average Loss: 3.924, avg. samples / sec: 54038.68
Iteration:    720, Loss function: 4.913, Average Loss: 3.924, avg. samples / sec: 54282.54
Iteration:    720, Loss function: 5.799, Average Loss: 3.930, avg. samples / sec: 54111.05
Iteration:    720, Loss function: 5.916, Average Loss: 3.937, avg. samples / sec: 54098.15
Iteration:    720, Loss function: 5.469, Average Loss: 3.940, avg. samples / sec: 53907.20
Iteration:    720, Loss function: 5.803, Average Loss: 3.904, avg. samples / sec: 54061.67
Iteration:    720, Loss function: 5.112, Average Loss: 3.899, avg. samples / sec: 53863.00
Iteration:    740, Loss function: 6.055, Average Loss: 3.972, avg. samples / sec: 54151.14
Iteration:    740, Loss function: 5.847, Average Loss: 3.955, avg. samples / sec: 53868.77
Iteration:    740, Loss function: 5.227, Average Loss: 3.929, avg. samples / sec: 54085.34
Iteration:    740, Loss function: 5.894, Average Loss: 3.919, avg. samples / sec: 53660.07
Iteration:    740, Loss function: 5.699, Average Loss: 3.955, avg. samples / sec: 53871.36
Iteration:    740, Loss function: 5.785, Average Loss: 3.970, avg. samples / sec: 53834.16
Iteration:    740, Loss function: 4.961, Average Loss: 3.948, avg. samples / sec: 53811.05
Iteration:    740, Loss function: 5.347, Average Loss: 3.959, avg. samples / sec: 53569.12
Iteration:    740, Loss function: 5.291, Average Loss: 3.938, avg. samples / sec: 53397.30
Iteration:    740, Loss function: 6.040, Average Loss: 3.949, avg. samples / sec: 53736.20
Iteration:    740, Loss function: 4.737, Average Loss: 3.962, avg. samples / sec: 53698.94
Iteration:    740, Loss function: 6.164, Average Loss: 3.945, avg. samples / sec: 53507.75
Iteration:    740, Loss function: 5.320, Average Loss: 3.973, avg. samples / sec: 53438.02
Iteration:    740, Loss function: 6.657, Average Loss: 3.956, avg. samples / sec: 53485.80
Iteration:    740, Loss function: 5.841, Average Loss: 3.943, avg. samples / sec: 52948.10
Iteration:    740, Loss function: 5.362, Average Loss: 3.945, avg. samples / sec: 53134.49
Iteration:    740, Loss function: 5.057, Average Loss: 3.941, avg. samples / sec: 53327.33
Iteration:    740, Loss function: 4.479, Average Loss: 3.961, avg. samples / sec: 53038.03
Iteration:    740, Loss function: 4.957, Average Loss: 3.960, avg. samples / sec: 53128.88
Iteration:    740, Loss function: 5.686, Average Loss: 3.966, avg. samples / sec: 53234.87
Iteration:    740, Loss function: 5.112, Average Loss: 3.948, avg. samples / sec: 53231.93
Iteration:    740, Loss function: 5.752, Average Loss: 3.956, avg. samples / sec: 53079.50
Iteration:    740, Loss function: 6.560, Average Loss: 3.974, avg. samples / sec: 53144.01
Iteration:    740, Loss function: 6.418, Average Loss: 3.963, avg. samples / sec: 53202.15
Iteration:    740, Loss function: 5.124, Average Loss: 3.966, avg. samples / sec: 53010.40
Iteration:    740, Loss function: 6.185, Average Loss: 3.935, avg. samples / sec: 53016.46
Iteration:    740, Loss function: 4.757, Average Loss: 3.953, avg. samples / sec: 52754.12
Iteration:    740, Loss function: 5.647, Average Loss: 3.949, avg. samples / sec: 52883.34
Iteration:    740, Loss function: 6.420, Average Loss: 3.948, avg. samples / sec: 52482.79
Iteration:    740, Loss function: 4.944, Average Loss: 3.964, avg. samples / sec: 52717.94
Iteration:    760, Loss function: 6.087, Average Loss: 3.974, avg. samples / sec: 54858.39
Iteration:    760, Loss function: 5.928, Average Loss: 3.975, avg. samples / sec: 54350.73
Iteration:    760, Loss function: 5.273, Average Loss: 3.987, avg. samples / sec: 53950.78
Iteration:    760, Loss function: 5.290, Average Loss: 3.981, avg. samples / sec: 54701.35
Iteration:    760, Loss function: 4.787, Average Loss: 3.997, avg. samples / sec: 54181.39
Iteration:    760, Loss function: 4.890, Average Loss: 3.975, avg. samples / sec: 54288.23
Iteration:    760, Loss function: 5.327, Average Loss: 3.986, avg. samples / sec: 54130.99
Iteration:    760, Loss function: 4.025, Average Loss: 3.988, avg. samples / sec: 54756.29
Iteration:    760, Loss function: 5.621, Average Loss: 3.981, avg. samples / sec: 54174.31
Iteration:    760, Loss function: 5.177, Average Loss: 3.998, avg. samples / sec: 54720.06
Iteration:    760, Loss function: 4.297, Average Loss: 3.988, avg. samples / sec: 54696.53
Iteration:    760, Loss function: 5.678, Average Loss: 3.995, avg. samples / sec: 54826.05
Iteration:    760, Loss function: 5.715, Average Loss: 3.995, avg. samples / sec: 54650.93
Iteration:    760, Loss function: 6.040, Average Loss: 3.985, avg. samples / sec: 54470.30
Iteration:    760, Loss function: 6.208, Average Loss: 3.997, avg. samples / sec: 54186.72
Iteration:    760, Loss function: 5.940, Average Loss: 3.983, avg. samples / sec: 54909.94
Iteration:    760, Loss function: 5.222, Average Loss: 3.988, avg. samples / sec: 54005.78
Iteration:    760, Loss function: 7.031, Average Loss: 4.006, avg. samples / sec: 54639.19
Iteration:    760, Loss function: 6.113, Average Loss: 3.978, avg. samples / sec: 55127.91
Iteration:    760, Loss function: 5.308, Average Loss: 4.002, avg. samples / sec: 53659.17
Iteration:    760, Loss function: 5.237, Average Loss: 3.972, avg. samples / sec: 54463.52
Iteration:    760, Loss function: 6.151, Average Loss: 3.992, avg. samples / sec: 55130.33
Iteration:    760, Loss function: 4.777, Average Loss: 3.982, avg. samples / sec: 54500.61
Iteration:    760, Loss function: 5.589, Average Loss: 3.974, avg. samples / sec: 54905.96
Iteration:    760, Loss function: 5.443, Average Loss: 3.954, avg. samples / sec: 53816.72
Iteration:    760, Loss function: 4.525, Average Loss: 3.995, avg. samples / sec: 54597.70
Iteration:    760, Loss function: 6.098, Average Loss: 3.967, avg. samples / sec: 54784.11
Iteration:    760, Loss function: 5.680, Average Loss: 3.960, avg. samples / sec: 53732.49
Iteration:    760, Loss function: 5.781, Average Loss: 4.000, avg. samples / sec: 54121.84
Iteration:    760, Loss function: 5.720, Average Loss: 3.966, avg. samples / sec: 53291.92
:::MLL 1558641121.946 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558641121.947 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 4.627, Average Loss: 3.989, avg. samples / sec: 55077.99
Iteration:    780, Loss function: 5.797, Average Loss: 4.009, avg. samples / sec: 53941.16
Iteration:    780, Loss function: 6.153, Average Loss: 4.015, avg. samples / sec: 53986.18
Iteration:    780, Loss function: 5.604, Average Loss: 4.031, avg. samples / sec: 54005.65
Iteration:    780, Loss function: 4.632, Average Loss: 4.031, avg. samples / sec: 54213.43
Iteration:    780, Loss function: 6.664, Average Loss: 4.015, avg. samples / sec: 53997.38
Iteration:    780, Loss function: 4.406, Average Loss: 4.000, avg. samples / sec: 53768.00
Iteration:    780, Loss function: 6.119, Average Loss: 4.011, avg. samples / sec: 53931.46
Iteration:    780, Loss function: 5.432, Average Loss: 4.003, avg. samples / sec: 53912.74
Iteration:    780, Loss function: 5.824, Average Loss: 3.984, avg. samples / sec: 54198.64
Iteration:    780, Loss function: 5.347, Average Loss: 4.006, avg. samples / sec: 53930.98
Iteration:    780, Loss function: 7.011, Average Loss: 4.016, avg. samples / sec: 54089.35
Iteration:    780, Loss function: 6.524, Average Loss: 4.032, avg. samples / sec: 53959.73
Iteration:    780, Loss function: 4.999, Average Loss: 4.016, avg. samples / sec: 53977.42
Iteration:    780, Loss function: 4.471, Average Loss: 4.001, avg. samples / sec: 53823.69
Iteration:    780, Loss function: 4.869, Average Loss: 4.020, avg. samples / sec: 53921.80
Iteration:    780, Loss function: 4.425, Average Loss: 4.000, avg. samples / sec: 54051.26
Iteration:    780, Loss function: 5.021, Average Loss: 4.024, avg. samples / sec: 54109.68
Iteration:    780, Loss function: 6.260, Average Loss: 4.019, avg. samples / sec: 53971.69
Iteration:    780, Loss function: 5.396, Average Loss: 4.004, avg. samples / sec: 53979.42
Iteration:    780, Loss function: 5.979, Average Loss: 4.006, avg. samples / sec: 53972.66
Iteration:    780, Loss function: 4.341, Average Loss: 4.011, avg. samples / sec: 53993.30
Iteration:    780, Loss function: 5.871, Average Loss: 4.035, avg. samples / sec: 53964.31
Iteration:    780, Loss function: 5.265, Average Loss: 4.010, avg. samples / sec: 53704.05
Iteration:    780, Loss function: 5.199, Average Loss: 4.024, avg. samples / sec: 53695.95
Iteration:    780, Loss function: 6.402, Average Loss: 4.027, avg. samples / sec: 53959.27
Iteration:    780, Loss function: 6.249, Average Loss: 4.021, avg. samples / sec: 53762.65
Iteration:    780, Loss function: 5.289, Average Loss: 3.998, avg. samples / sec: 53972.91
Iteration:    780, Loss function: 5.128, Average Loss: 3.986, avg. samples / sec: 53940.58
Iteration:    780, Loss function: 4.887, Average Loss: 4.020, avg. samples / sec: 53305.55
Iteration:    800, Loss function: 6.120, Average Loss: 4.060, avg. samples / sec: 53808.11
Iteration:    800, Loss function: 5.512, Average Loss: 4.040, avg. samples / sec: 53826.32
Iteration:    800, Loss function: 5.329, Average Loss: 4.044, avg. samples / sec: 53893.36
Iteration:    800, Loss function: 5.090, Average Loss: 4.040, avg. samples / sec: 53863.13
Iteration:    800, Loss function: 5.398, Average Loss: 4.063, avg. samples / sec: 53846.76
Iteration:    800, Loss function: 5.551, Average Loss: 4.049, avg. samples / sec: 53788.93
Iteration:    800, Loss function: 6.035, Average Loss: 4.030, avg. samples / sec: 53792.46
Iteration:    800, Loss function: 4.251, Average Loss: 4.012, avg. samples / sec: 53809.49
Iteration:    800, Loss function: 5.597, Average Loss: 4.037, avg. samples / sec: 53988.09
Iteration:    800, Loss function: 6.768, Average Loss: 4.021, avg. samples / sec: 53607.36
Iteration:    800, Loss function: 5.002, Average Loss: 4.039, avg. samples / sec: 53699.71
Iteration:    800, Loss function: 5.032, Average Loss: 4.050, avg. samples / sec: 54627.33
Iteration:    800, Loss function: 5.689, Average Loss: 4.050, avg. samples / sec: 53843.74
Iteration:    800, Loss function: 4.326, Average Loss: 4.038, avg. samples / sec: 53706.10
Iteration:    800, Loss function: 5.353, Average Loss: 4.044, avg. samples / sec: 53705.77
Iteration:    800, Loss function: 7.089, Average Loss: 4.029, avg. samples / sec: 53810.37
Iteration:    800, Loss function: 5.407, Average Loss: 4.060, avg. samples / sec: 53614.11
Iteration:    800, Loss function: 5.346, Average Loss: 4.048, avg. samples / sec: 53887.72
Iteration:    800, Loss function: 4.859, Average Loss: 4.051, avg. samples / sec: 53800.68
Iteration:    800, Loss function: 4.573, Average Loss: 4.039, avg. samples / sec: 53824.10
Iteration:    800, Loss function: 5.382, Average Loss: 4.036, avg. samples / sec: 53782.65
Iteration:    800, Loss function: 5.850, Average Loss: 4.040, avg. samples / sec: 53520.47
Iteration:    800, Loss function: 5.179, Average Loss: 4.028, avg. samples / sec: 53669.34
Iteration:    800, Loss function: 6.309, Average Loss: 4.063, avg. samples / sec: 53767.94
Iteration:    800, Loss function: 5.548, Average Loss: 4.031, avg. samples / sec: 53794.68
Iteration:    800, Loss function: 4.580, Average Loss: 4.054, avg. samples / sec: 53780.00
Iteration:    800, Loss function: 5.418, Average Loss: 4.016, avg. samples / sec: 53832.28
Iteration:    800, Loss function: 5.584, Average Loss: 4.055, avg. samples / sec: 53687.62
Iteration:    800, Loss function: 4.084, Average Loss: 4.048, avg. samples / sec: 53767.73
Iteration:    800, Loss function: 5.326, Average Loss: 4.038, avg. samples / sec: 53681.90
Iteration:    820, Loss function: 5.561, Average Loss: 4.035, avg. samples / sec: 54699.14
Iteration:    820, Loss function: 5.300, Average Loss: 4.071, avg. samples / sec: 54542.17
Iteration:    820, Loss function: 5.285, Average Loss: 4.061, avg. samples / sec: 54694.92
Iteration:    820, Loss function: 5.022, Average Loss: 4.063, avg. samples / sec: 54629.17
Iteration:    820, Loss function: 5.567, Average Loss: 4.048, avg. samples / sec: 54554.92
Iteration:    820, Loss function: 5.199, Average Loss: 4.059, avg. samples / sec: 54477.19
Iteration:    820, Loss function: 5.761, Average Loss: 4.063, avg. samples / sec: 54497.39
Iteration:    820, Loss function: 5.153, Average Loss: 4.062, avg. samples / sec: 54511.34
Iteration:    820, Loss function: 5.284, Average Loss: 4.065, avg. samples / sec: 54557.03
Iteration:    820, Loss function: 4.483, Average Loss: 4.072, avg. samples / sec: 54442.57
Iteration:    820, Loss function: 5.570, Average Loss: 4.069, avg. samples / sec: 54712.07
Iteration:    820, Loss function: 5.136, Average Loss: 4.086, avg. samples / sec: 54421.82
Iteration:    820, Loss function: 4.260, Average Loss: 4.066, avg. samples / sec: 54627.52
Iteration:    820, Loss function: 5.767, Average Loss: 4.069, avg. samples / sec: 54584.16
Iteration:    820, Loss function: 5.238, Average Loss: 4.091, avg. samples / sec: 54424.76
Iteration:    820, Loss function: 5.154, Average Loss: 4.077, avg. samples / sec: 54686.87
Iteration:    820, Loss function: 3.672, Average Loss: 4.055, avg. samples / sec: 54651.33
Iteration:    820, Loss function: 5.665, Average Loss: 4.076, avg. samples / sec: 54325.36
Iteration:    820, Loss function: 6.322, Average Loss: 4.053, avg. samples / sec: 54577.38
Iteration:    820, Loss function: 4.940, Average Loss: 4.066, avg. samples / sec: 54531.95
Iteration:    820, Loss function: 6.496, Average Loss: 4.076, avg. samples / sec: 54496.31
Iteration:    820, Loss function: 4.996, Average Loss: 4.067, avg. samples / sec: 54620.93
Iteration:    820, Loss function: 5.718, Average Loss: 4.087, avg. samples / sec: 54531.17
Iteration:    820, Loss function: 5.288, Average Loss: 4.062, avg. samples / sec: 54490.50
Iteration:    820, Loss function: 4.972, Average Loss: 4.074, avg. samples / sec: 54555.53
Iteration:    820, Loss function: 5.927, Average Loss: 4.090, avg. samples / sec: 54422.76
Iteration:    820, Loss function: 4.884, Average Loss: 4.081, avg. samples / sec: 54546.58
Iteration:    820, Loss function: 4.888, Average Loss: 4.073, avg. samples / sec: 54322.43
Iteration:    820, Loss function: 4.681, Average Loss: 4.038, avg. samples / sec: 54514.28
Iteration:    820, Loss function: 5.296, Average Loss: 4.077, avg. samples / sec: 53958.61
:::MLL 1558641124.129 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558641124.130 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 5.212, Average Loss: 4.094, avg. samples / sec: 53229.60
Iteration:    840, Loss function: 5.023, Average Loss: 4.054, avg. samples / sec: 52949.05
Iteration:    840, Loss function: 5.738, Average Loss: 4.089, avg. samples / sec: 53072.34
Iteration:    840, Loss function: 4.840, Average Loss: 4.111, avg. samples / sec: 53182.94
Iteration:    840, Loss function: 5.026, Average Loss: 4.090, avg. samples / sec: 53092.82
Iteration:    840, Loss function: 4.678, Average Loss: 4.086, avg. samples / sec: 53059.51
Iteration:    840, Loss function: 6.077, Average Loss: 4.093, avg. samples / sec: 53649.26
Iteration:    840, Loss function: 5.290, Average Loss: 4.089, avg. samples / sec: 53055.48
Iteration:    840, Loss function: 5.721, Average Loss: 4.088, avg. samples / sec: 53019.97
Iteration:    840, Loss function: 4.913, Average Loss: 4.079, avg. samples / sec: 53013.73
Iteration:    840, Loss function: 5.457, Average Loss: 4.097, avg. samples / sec: 53237.66
Iteration:    840, Loss function: 5.478, Average Loss: 4.105, avg. samples / sec: 53162.61
Iteration:    840, Loss function: 6.491, Average Loss: 4.113, avg. samples / sec: 52978.45
Iteration:    840, Loss function: 5.618, Average Loss: 4.089, avg. samples / sec: 52937.83
Iteration:    840, Loss function: 5.091, Average Loss: 4.096, avg. samples / sec: 52968.56
Iteration:    840, Loss function: 5.771, Average Loss: 4.069, avg. samples / sec: 52906.99
Iteration:    840, Loss function: 4.569, Average Loss: 4.092, avg. samples / sec: 52948.57
Iteration:    840, Loss function: 5.269, Average Loss: 4.085, avg. samples / sec: 53137.38
Iteration:    840, Loss function: 4.544, Average Loss: 4.090, avg. samples / sec: 52852.07
Iteration:    840, Loss function: 4.730, Average Loss: 4.078, avg. samples / sec: 53062.07
Iteration:    840, Loss function: 6.093, Average Loss: 4.090, avg. samples / sec: 53043.54
Iteration:    840, Loss function: 5.241, Average Loss: 4.109, avg. samples / sec: 53078.82
Iteration:    840, Loss function: 5.002, Average Loss: 4.079, avg. samples / sec: 52933.62
Iteration:    840, Loss function: 4.744, Average Loss: 4.097, avg. samples / sec: 52901.15
Iteration:    840, Loss function: 3.792, Average Loss: 4.102, avg. samples / sec: 53029.51
Iteration:    840, Loss function: 5.005, Average Loss: 4.059, avg. samples / sec: 53047.39
Iteration:    840, Loss function: 4.477, Average Loss: 4.100, avg. samples / sec: 52919.57
Iteration:    840, Loss function: 5.804, Average Loss: 4.094, avg. samples / sec: 53000.31
Iteration:    840, Loss function: 5.558, Average Loss: 4.085, avg. samples / sec: 52930.32
Iteration:    840, Loss function: 4.315, Average Loss: 4.111, avg. samples / sec: 52949.09
Iteration:    860, Loss function: 4.929, Average Loss: 4.114, avg. samples / sec: 54072.48
Iteration:    860, Loss function: 5.627, Average Loss: 4.124, avg. samples / sec: 54317.32
Iteration:    860, Loss function: 5.541, Average Loss: 4.113, avg. samples / sec: 53862.39
Iteration:    860, Loss function: 6.264, Average Loss: 4.118, avg. samples / sec: 54136.97
Iteration:    860, Loss function: 4.922, Average Loss: 4.114, avg. samples / sec: 54210.80
Iteration:    860, Loss function: 3.772, Average Loss: 4.121, avg. samples / sec: 54162.36
Iteration:    860, Loss function: 5.382, Average Loss: 4.087, avg. samples / sec: 54150.89
Iteration:    860, Loss function: 4.551, Average Loss: 4.101, avg. samples / sec: 54032.14
Iteration:    860, Loss function: 5.148, Average Loss: 4.113, avg. samples / sec: 53953.98
Iteration:    860, Loss function: 4.830, Average Loss: 4.102, avg. samples / sec: 53999.49
Iteration:    860, Loss function: 4.153, Average Loss: 4.115, avg. samples / sec: 54123.29
Iteration:    860, Loss function: 5.051, Average Loss: 4.116, avg. samples / sec: 54236.00
Iteration:    860, Loss function: 5.720, Average Loss: 4.077, avg. samples / sec: 53904.81
Iteration:    860, Loss function: 5.454, Average Loss: 4.131, avg. samples / sec: 53901.92
Iteration:    860, Loss function: 5.617, Average Loss: 4.113, avg. samples / sec: 53957.21
Iteration:    860, Loss function: 4.829, Average Loss: 4.099, avg. samples / sec: 54079.06
Iteration:    860, Loss function: 5.598, Average Loss: 4.131, avg. samples / sec: 54005.80
Iteration:    860, Loss function: 5.068, Average Loss: 4.108, avg. samples / sec: 54149.93
Iteration:    860, Loss function: 4.150, Average Loss: 4.105, avg. samples / sec: 53951.53
Iteration:    860, Loss function: 5.820, Average Loss: 4.114, avg. samples / sec: 54090.41
Iteration:    860, Loss function: 4.159, Average Loss: 4.127, avg. samples / sec: 53873.87
Iteration:    860, Loss function: 5.382, Average Loss: 4.103, avg. samples / sec: 53951.40
Iteration:    860, Loss function: 6.203, Average Loss: 4.128, avg. samples / sec: 54131.01
Iteration:    860, Loss function: 5.662, Average Loss: 4.117, avg. samples / sec: 53940.99
Iteration:    860, Loss function: 4.771, Average Loss: 4.108, avg. samples / sec: 53792.67
Iteration:    860, Loss function: 4.727, Average Loss: 4.127, avg. samples / sec: 54028.80
Iteration:    860, Loss function: 6.004, Average Loss: 4.121, avg. samples / sec: 53822.64
Iteration:    860, Loss function: 4.082, Average Loss: 4.075, avg. samples / sec: 54017.99
Iteration:    860, Loss function: 5.070, Average Loss: 4.135, avg. samples / sec: 53838.50
Iteration:    860, Loss function: 5.025, Average Loss: 4.110, avg. samples / sec: 53365.11
Iteration:    880, Loss function: 5.303, Average Loss: 4.129, avg. samples / sec: 54767.91
Iteration:    880, Loss function: 5.904, Average Loss: 4.140, avg. samples / sec: 54583.02
Iteration:    880, Loss function: 5.200, Average Loss: 4.139, avg. samples / sec: 54635.25
Iteration:    880, Loss function: 5.875, Average Loss: 4.132, avg. samples / sec: 54604.64
Iteration:    880, Loss function: 4.527, Average Loss: 4.136, avg. samples / sec: 54828.55
Iteration:    880, Loss function: 4.340, Average Loss: 4.141, avg. samples / sec: 54519.25
Iteration:    880, Loss function: 4.474, Average Loss: 4.152, avg. samples / sec: 54580.30
Iteration:    880, Loss function: 5.432, Average Loss: 4.126, avg. samples / sec: 54508.50
Iteration:    880, Loss function: 5.582, Average Loss: 4.143, avg. samples / sec: 54495.18
Iteration:    880, Loss function: 5.219, Average Loss: 4.157, avg. samples / sec: 54792.99
Iteration:    880, Loss function: 4.599, Average Loss: 4.135, avg. samples / sec: 55180.30
Iteration:    880, Loss function: 5.436, Average Loss: 4.116, avg. samples / sec: 54485.23
Iteration:    880, Loss function: 5.435, Average Loss: 4.101, avg. samples / sec: 54508.33
Iteration:    880, Loss function: 4.666, Average Loss: 4.134, avg. samples / sec: 54492.29
Iteration:    880, Loss function: 6.083, Average Loss: 4.137, avg. samples / sec: 54517.82
Iteration:    880, Loss function: 4.349, Average Loss: 4.143, avg. samples / sec: 54422.95
Iteration:    880, Loss function: 4.185, Average Loss: 4.133, avg. samples / sec: 54581.71
Iteration:    880, Loss function: 5.497, Average Loss: 4.153, avg. samples / sec: 54583.83
Iteration:    880, Loss function: 5.721, Average Loss: 4.154, avg. samples / sec: 54558.85
Iteration:    880, Loss function: 5.226, Average Loss: 4.146, avg. samples / sec: 54563.81
Iteration:    880, Loss function: 4.643, Average Loss: 4.138, avg. samples / sec: 54319.01
Iteration:    880, Loss function: 4.912, Average Loss: 4.137, avg. samples / sec: 54519.34
Iteration:    880, Loss function: 4.379, Average Loss: 4.146, avg. samples / sec: 54277.36
Iteration:    880, Loss function: 5.407, Average Loss: 4.127, avg. samples / sec: 54520.03
Iteration:    880, Loss function: 4.214, Average Loss: 4.099, avg. samples / sec: 54545.04
Iteration:    880, Loss function: 4.228, Average Loss: 4.143, avg. samples / sec: 54483.80
Iteration:    880, Loss function: 4.727, Average Loss: 4.124, avg. samples / sec: 54442.29
Iteration:    880, Loss function: 4.839, Average Loss: 4.142, avg. samples / sec: 54491.66
Iteration:    880, Loss function: 5.863, Average Loss: 4.150, avg. samples / sec: 54480.11
Iteration:    880, Loss function: 5.908, Average Loss: 4.156, avg. samples / sec: 54277.84
Iteration:    900, Loss function: 4.785, Average Loss: 4.159, avg. samples / sec: 53927.33
Iteration:    900, Loss function: 4.944, Average Loss: 4.152, avg. samples / sec: 53805.73
Iteration:    900, Loss function: 5.284, Average Loss: 4.148, avg. samples / sec: 53932.67
Iteration:    900, Loss function: 3.733, Average Loss: 4.159, avg. samples / sec: 53901.09
Iteration:    900, Loss function: 5.697, Average Loss: 4.178, avg. samples / sec: 54408.64
Iteration:    900, Loss function: 3.814, Average Loss: 4.166, avg. samples / sec: 54160.94
Iteration:    900, Loss function: 5.670, Average Loss: 4.136, avg. samples / sec: 53986.50
Iteration:    900, Loss function: 5.657, Average Loss: 4.162, avg. samples / sec: 53974.54
Iteration:    900, Loss function: 5.083, Average Loss: 4.120, avg. samples / sec: 53965.35
Iteration:    900, Loss function: 3.980, Average Loss: 4.146, avg. samples / sec: 53944.01
Iteration:    900, Loss function: 5.283, Average Loss: 4.173, avg. samples / sec: 53899.69
Iteration:    900, Loss function: 5.085, Average Loss: 4.161, avg. samples / sec: 53821.61
Iteration:    900, Loss function: 3.721, Average Loss: 4.162, avg. samples / sec: 53915.40
Iteration:    900, Loss function: 5.918, Average Loss: 4.176, avg. samples / sec: 53916.48
Iteration:    900, Loss function: 5.383, Average Loss: 4.164, avg. samples / sec: 53869.74
Iteration:    900, Loss function: 4.225, Average Loss: 4.161, avg. samples / sec: 53940.99
Iteration:    900, Loss function: 5.132, Average Loss: 4.151, avg. samples / sec: 53923.51
Iteration:    900, Loss function: 5.490, Average Loss: 4.167, avg. samples / sec: 53970.58
Iteration:    900, Loss function: 5.275, Average Loss: 4.145, avg. samples / sec: 54003.02
Iteration:    900, Loss function: 5.659, Average Loss: 4.157, avg. samples / sec: 53942.71
Iteration:    900, Loss function: 5.916, Average Loss: 4.168, avg. samples / sec: 53935.96
Iteration:    900, Loss function: 5.482, Average Loss: 4.151, avg. samples / sec: 53937.36
Iteration:    900, Loss function: 4.778, Average Loss: 4.170, avg. samples / sec: 53913.96
Iteration:    900, Loss function: 5.523, Average Loss: 4.165, avg. samples / sec: 53972.21
Iteration:    900, Loss function: 5.342, Average Loss: 4.163, avg. samples / sec: 53987.30
Iteration:    900, Loss function: 4.640, Average Loss: 4.140, avg. samples / sec: 53936.02
Iteration:    900, Loss function: 4.932, Average Loss: 4.179, avg. samples / sec: 53837.57
Iteration:    900, Loss function: 5.827, Average Loss: 4.116, avg. samples / sec: 53891.22
Iteration:    900, Loss function: 4.717, Average Loss: 4.169, avg. samples / sec: 53909.03
Iteration:    900, Loss function: 5.005, Average Loss: 4.155, avg. samples / sec: 53394.69
:::MLL 1558641126.306 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558641126.306 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 5.622, Average Loss: 4.157, avg. samples / sec: 52572.36
Iteration:    920, Loss function: 4.473, Average Loss: 4.196, avg. samples / sec: 52590.05
Iteration:    920, Loss function: 5.002, Average Loss: 4.181, avg. samples / sec: 52361.07
Iteration:    920, Loss function: 5.027, Average Loss: 4.171, avg. samples / sec: 52536.86
Iteration:    920, Loss function: 5.184, Average Loss: 4.175, avg. samples / sec: 52576.69
Iteration:    920, Loss function: 5.652, Average Loss: 4.176, avg. samples / sec: 52363.33
Iteration:    920, Loss function: 4.483, Average Loss: 4.195, avg. samples / sec: 52466.26
Iteration:    920, Loss function: 6.355, Average Loss: 4.196, avg. samples / sec: 52585.40
Iteration:    920, Loss function: 5.300, Average Loss: 4.182, avg. samples / sec: 52429.62
Iteration:    920, Loss function: 5.939, Average Loss: 4.183, avg. samples / sec: 52352.16
Iteration:    920, Loss function: 4.465, Average Loss: 4.189, avg. samples / sec: 52553.30
Iteration:    920, Loss function: 5.303, Average Loss: 4.186, avg. samples / sec: 52318.50
Iteration:    920, Loss function: 3.439, Average Loss: 4.186, avg. samples / sec: 52618.56
Iteration:    920, Loss function: 4.885, Average Loss: 4.190, avg. samples / sec: 52355.45
Iteration:    920, Loss function: 3.742, Average Loss: 4.175, avg. samples / sec: 52488.38
Iteration:    920, Loss function: 5.215, Average Loss: 4.179, avg. samples / sec: 52467.98
Iteration:    920, Loss function: 4.910, Average Loss: 4.189, avg. samples / sec: 52470.44
Iteration:    920, Loss function: 6.021, Average Loss: 4.151, avg. samples / sec: 52273.03
Iteration:    920, Loss function: 5.512, Average Loss: 4.182, avg. samples / sec: 52256.81
Iteration:    920, Loss function: 5.824, Average Loss: 4.178, avg. samples / sec: 52888.78
Iteration:    920, Loss function: 4.113, Average Loss: 4.193, avg. samples / sec: 52454.15
Iteration:    920, Loss function: 4.890, Average Loss: 4.169, avg. samples / sec: 52114.16
Iteration:    920, Loss function: 5.229, Average Loss: 4.170, avg. samples / sec: 52325.26
Iteration:    920, Loss function: 5.556, Average Loss: 4.138, avg. samples / sec: 52408.00
Iteration:    920, Loss function: 4.523, Average Loss: 4.188, avg. samples / sec: 52113.77
Iteration:    920, Loss function: 4.513, Average Loss: 4.188, avg. samples / sec: 52320.34
Iteration:    920, Loss function: 5.096, Average Loss: 4.183, avg. samples / sec: 52145.51
Iteration:    920, Loss function: 4.969, Average Loss: 4.193, avg. samples / sec: 52148.41
Iteration:    920, Loss function: 4.453, Average Loss: 4.165, avg. samples / sec: 52273.86
Iteration:    920, Loss function: 5.144, Average Loss: 4.202, avg. samples / sec: 51996.89
Iteration:    940, Loss function: 6.156, Average Loss: 4.207, avg. samples / sec: 52868.88
Iteration:    940, Loss function: 4.437, Average Loss: 4.214, avg. samples / sec: 52720.71
Iteration:    940, Loss function: 4.775, Average Loss: 4.168, avg. samples / sec: 52895.49
Iteration:    940, Loss function: 4.099, Average Loss: 4.193, avg. samples / sec: 52926.16
Iteration:    940, Loss function: 5.049, Average Loss: 4.201, avg. samples / sec: 52762.02
Iteration:    940, Loss function: 5.418, Average Loss: 4.194, avg. samples / sec: 52693.01
Iteration:    940, Loss function: 4.615, Average Loss: 4.194, avg. samples / sec: 52622.93
Iteration:    940, Loss function: 5.742, Average Loss: 4.196, avg. samples / sec: 52601.14
Iteration:    940, Loss function: 5.588, Average Loss: 4.189, avg. samples / sec: 52613.38
Iteration:    940, Loss function: 4.897, Average Loss: 4.174, avg. samples / sec: 52547.52
Iteration:    940, Loss function: 6.426, Average Loss: 4.218, avg. samples / sec: 52588.64
Iteration:    940, Loss function: 5.406, Average Loss: 4.213, avg. samples / sec: 52928.81
Iteration:    940, Loss function: 5.129, Average Loss: 4.201, avg. samples / sec: 52791.72
Iteration:    940, Loss function: 5.322, Average Loss: 4.198, avg. samples / sec: 53017.73
Iteration:    940, Loss function: 4.624, Average Loss: 4.218, avg. samples / sec: 52698.82
Iteration:    940, Loss function: 5.089, Average Loss: 4.204, avg. samples / sec: 52973.99
Iteration:    940, Loss function: 5.906, Average Loss: 4.209, avg. samples / sec: 52710.45
Iteration:    940, Loss function: 5.770, Average Loss: 4.199, avg. samples / sec: 52585.38
Iteration:    940, Loss function: 3.884, Average Loss: 4.185, avg. samples / sec: 52793.23
Iteration:    940, Loss function: 5.793, Average Loss: 4.210, avg. samples / sec: 52863.11
Iteration:    940, Loss function: 4.502, Average Loss: 4.219, avg. samples / sec: 52933.06
Iteration:    940, Loss function: 4.690, Average Loss: 4.190, avg. samples / sec: 52647.60
Iteration:    940, Loss function: 5.335, Average Loss: 4.198, avg. samples / sec: 52715.22
Iteration:    940, Loss function: 5.156, Average Loss: 4.198, avg. samples / sec: 52642.37
Iteration:    940, Loss function: 4.103, Average Loss: 4.189, avg. samples / sec: 52747.84
Iteration:    940, Loss function: 5.113, Average Loss: 4.189, avg. samples / sec: 52887.63
Iteration:    940, Loss function: 4.526, Average Loss: 4.205, avg. samples / sec: 52814.48
Iteration:    940, Loss function: 6.254, Average Loss: 4.157, avg. samples / sec: 52764.92
Iteration:    940, Loss function: 5.864, Average Loss: 4.201, avg. samples / sec: 52563.24
Iteration:    940, Loss function: 4.602, Average Loss: 4.211, avg. samples / sec: 52529.07
Iteration:    960, Loss function: 4.971, Average Loss: 4.211, avg. samples / sec: 53419.57
Iteration:    960, Loss function: 5.947, Average Loss: 4.190, avg. samples / sec: 53373.74
Iteration:    960, Loss function: 4.821, Average Loss: 4.212, avg. samples / sec: 53353.78
Iteration:    960, Loss function: 4.806, Average Loss: 4.211, avg. samples / sec: 53536.37
Iteration:    960, Loss function: 5.416, Average Loss: 4.236, avg. samples / sec: 53549.27
Iteration:    960, Loss function: 4.878, Average Loss: 4.222, avg. samples / sec: 53318.03
Iteration:    960, Loss function: 4.761, Average Loss: 4.226, avg. samples / sec: 53376.92
Iteration:    960, Loss function: 6.216, Average Loss: 4.215, avg. samples / sec: 53322.81
Iteration:    960, Loss function: 5.056, Average Loss: 4.182, avg. samples / sec: 53309.22
Iteration:    960, Loss function: 5.513, Average Loss: 4.207, avg. samples / sec: 53549.03
Iteration:    960, Loss function: 5.262, Average Loss: 4.223, avg. samples / sec: 53267.53
Iteration:    960, Loss function: 4.882, Average Loss: 4.220, avg. samples / sec: 53316.88
Iteration:    960, Loss function: 6.011, Average Loss: 4.234, avg. samples / sec: 53327.59
Iteration:    960, Loss function: 4.615, Average Loss: 4.224, avg. samples / sec: 53483.43
Iteration:    960, Loss function: 5.866, Average Loss: 4.210, avg. samples / sec: 53274.07
Iteration:    960, Loss function: 4.079, Average Loss: 4.229, avg. samples / sec: 53251.04
Iteration:    960, Loss function: 4.404, Average Loss: 4.232, avg. samples / sec: 53276.16
Iteration:    960, Loss function: 5.326, Average Loss: 4.210, avg. samples / sec: 53229.44
Iteration:    960, Loss function: 3.507, Average Loss: 4.203, avg. samples / sec: 53399.77
Iteration:    960, Loss function: 4.635, Average Loss: 4.206, avg. samples / sec: 53342.53
Iteration:    960, Loss function: 5.723, Average Loss: 4.214, avg. samples / sec: 53330.94
Iteration:    960, Loss function: 4.687, Average Loss: 4.232, avg. samples / sec: 53391.92
Iteration:    960, Loss function: 4.661, Average Loss: 4.220, avg. samples / sec: 53344.77
Iteration:    960, Loss function: 3.984, Average Loss: 4.211, avg. samples / sec: 53301.73
Iteration:    960, Loss function: 6.314, Average Loss: 4.232, avg. samples / sec: 53113.41
Iteration:    960, Loss function: 6.279, Average Loss: 4.205, avg. samples / sec: 53329.83
Iteration:    960, Loss function: 3.959, Average Loss: 4.217, avg. samples / sec: 53348.00
Iteration:    960, Loss function: 3.529, Average Loss: 4.222, avg. samples / sec: 53245.93
Iteration:    960, Loss function: 5.750, Average Loss: 4.176, avg. samples / sec: 53300.20
Iteration:    960, Loss function: 4.771, Average Loss: 4.217, avg. samples / sec: 53038.81
:::MLL 1558641128.533 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558641128.534 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 5.762, Average Loss: 4.201, avg. samples / sec: 53154.45
Iteration:    980, Loss function: 3.932, Average Loss: 4.226, avg. samples / sec: 53121.01
Iteration:    980, Loss function: 4.350, Average Loss: 4.239, avg. samples / sec: 53120.37
Iteration:    980, Loss function: 4.322, Average Loss: 4.246, avg. samples / sec: 53133.97
Iteration:    980, Loss function: 5.005, Average Loss: 4.223, avg. samples / sec: 52989.09
Iteration:    980, Loss function: 5.610, Average Loss: 4.241, avg. samples / sec: 53054.28
Iteration:    980, Loss function: 4.681, Average Loss: 4.227, avg. samples / sec: 53019.27
Iteration:    980, Loss function: 4.478, Average Loss: 4.253, avg. samples / sec: 53080.62
Iteration:    980, Loss function: 5.762, Average Loss: 4.239, avg. samples / sec: 53350.30
Iteration:    980, Loss function: 5.077, Average Loss: 4.248, avg. samples / sec: 52959.44
Iteration:    980, Loss function: 5.479, Average Loss: 4.225, avg. samples / sec: 53024.86
Iteration:    980, Loss function: 5.779, Average Loss: 4.239, avg. samples / sec: 52944.48
Iteration:    980, Loss function: 4.221, Average Loss: 4.227, avg. samples / sec: 52913.92
Iteration:    980, Loss function: 5.110, Average Loss: 4.232, avg. samples / sec: 52888.56
Iteration:    980, Loss function: 4.955, Average Loss: 4.208, avg. samples / sec: 52840.46
Iteration:    980, Loss function: 4.489, Average Loss: 4.237, avg. samples / sec: 52911.70
Iteration:    980, Loss function: 5.149, Average Loss: 4.241, avg. samples / sec: 52928.51
Iteration:    980, Loss function: 3.855, Average Loss: 4.235, avg. samples / sec: 53071.96
Iteration:    980, Loss function: 5.818, Average Loss: 4.227, avg. samples / sec: 52937.18
Iteration:    980, Loss function: 6.288, Average Loss: 4.218, avg. samples / sec: 52959.38
Iteration:    980, Loss function: 6.443, Average Loss: 4.238, avg. samples / sec: 53091.20
Iteration:    980, Loss function: 3.745, Average Loss: 4.223, avg. samples / sec: 53014.68
Iteration:    980, Loss function: 4.873, Average Loss: 4.230, avg. samples / sec: 53027.07
Iteration:    980, Loss function: 5.368, Average Loss: 4.220, avg. samples / sec: 53007.96
Iteration:    980, Loss function: 5.442, Average Loss: 4.192, avg. samples / sec: 53032.38
Iteration:    980, Loss function: 4.519, Average Loss: 4.229, avg. samples / sec: 52982.08
Iteration:    980, Loss function: 5.068, Average Loss: 4.249, avg. samples / sec: 52966.56
Iteration:    980, Loss function: 4.166, Average Loss: 4.235, avg. samples / sec: 52944.48
Iteration:    980, Loss function: 4.360, Average Loss: 4.237, avg. samples / sec: 52743.26
Iteration:    980, Loss function: 4.391, Average Loss: 4.247, avg. samples / sec: 52876.72
Iteration:   1000, Loss function: 4.957, Average Loss: 4.257, avg. samples / sec: 52854.65
Iteration:   1000, Loss function: 6.029, Average Loss: 4.260, avg. samples / sec: 52915.49
Iteration:   1000, Loss function: 5.131, Average Loss: 4.250, avg. samples / sec: 52867.67
Iteration:   1000, Loss function: 4.029, Average Loss: 4.239, avg. samples / sec: 52665.23
Iteration:   1000, Loss function: 4.385, Average Loss: 4.239, avg. samples / sec: 52996.52
Iteration:   1000, Loss function: 4.835, Average Loss: 4.257, avg. samples / sec: 52659.70
Iteration:   1000, Loss function: 5.415, Average Loss: 4.260, avg. samples / sec: 52729.88
Iteration:   1000, Loss function: 5.499, Average Loss: 4.259, avg. samples / sec: 52879.42
Iteration:   1000, Loss function: 5.704, Average Loss: 4.264, avg. samples / sec: 52766.05
Iteration:   1000, Loss function: 4.889, Average Loss: 4.240, avg. samples / sec: 52661.27
Iteration:   1000, Loss function: 5.287, Average Loss: 4.224, avg. samples / sec: 52861.49
Iteration:   1000, Loss function: 4.978, Average Loss: 4.243, avg. samples / sec: 52810.95
Iteration:   1000, Loss function: 5.033, Average Loss: 4.219, avg. samples / sec: 52575.97
Iteration:   1000, Loss function: 4.855, Average Loss: 4.242, avg. samples / sec: 52849.97
Iteration:   1000, Loss function: 4.467, Average Loss: 4.244, avg. samples / sec: 52720.23
Iteration:   1000, Loss function: 5.395, Average Loss: 4.263, avg. samples / sec: 52623.95
Iteration:   1000, Loss function: 5.054, Average Loss: 4.260, avg. samples / sec: 52642.39
Iteration:   1000, Loss function: 4.201, Average Loss: 4.250, avg. samples / sec: 52625.28
Iteration:   1000, Loss function: 6.064, Average Loss: 4.207, avg. samples / sec: 52884.95
Iteration:   1000, Loss function: 5.990, Average Loss: 4.270, avg. samples / sec: 52603.85
Iteration:   1000, Loss function: 4.430, Average Loss: 4.249, avg. samples / sec: 52884.83
Iteration:   1000, Loss function: 5.912, Average Loss: 4.240, avg. samples / sec: 52722.42
Iteration:   1000, Loss function: 3.918, Average Loss: 4.232, avg. samples / sec: 52711.22
Iteration:   1000, Loss function: 4.706, Average Loss: 4.247, avg. samples / sec: 52672.41
Iteration:   1000, Loss function: 4.783, Average Loss: 4.248, avg. samples / sec: 52681.57
Iteration:   1000, Loss function: 4.902, Average Loss: 4.248, avg. samples / sec: 52705.62
Iteration:   1000, Loss function: 5.768, Average Loss: 4.263, avg. samples / sec: 52757.42
Iteration:   1000, Loss function: 3.934, Average Loss: 4.252, avg. samples / sec: 52801.63
Iteration:   1000, Loss function: 5.651, Average Loss: 4.265, avg. samples / sec: 52851.26
Iteration:   1000, Loss function: 4.833, Average Loss: 4.254, avg. samples / sec: 52185.23
Iteration:   1020, Loss function: 5.141, Average Loss: 4.252, avg. samples / sec: 53272.82
Iteration:   1020, Loss function: 4.528, Average Loss: 4.269, avg. samples / sec: 53159.73
Iteration:   1020, Loss function: 5.297, Average Loss: 4.234, avg. samples / sec: 53188.24
Iteration:   1020, Loss function: 4.723, Average Loss: 4.272, avg. samples / sec: 53127.18
Iteration:   1020, Loss function: 5.356, Average Loss: 4.275, avg. samples / sec: 53201.37
Iteration:   1020, Loss function: 4.771, Average Loss: 4.268, avg. samples / sec: 53231.75
Iteration:   1020, Loss function: 5.505, Average Loss: 4.280, avg. samples / sec: 53117.35
Iteration:   1020, Loss function: 4.361, Average Loss: 4.271, avg. samples / sec: 53052.44
Iteration:   1020, Loss function: 5.413, Average Loss: 4.239, avg. samples / sec: 53118.93
Iteration:   1020, Loss function: 5.635, Average Loss: 4.260, avg. samples / sec: 53063.99
Iteration:   1020, Loss function: 4.939, Average Loss: 4.278, avg. samples / sec: 53340.27
Iteration:   1020, Loss function: 4.918, Average Loss: 4.259, avg. samples / sec: 53100.86
Iteration:   1020, Loss function: 3.277, Average Loss: 4.272, avg. samples / sec: 53137.38
Iteration:   1020, Loss function: 4.267, Average Loss: 4.253, avg. samples / sec: 53130.05
Iteration:   1020, Loss function: 4.376, Average Loss: 4.251, avg. samples / sec: 53278.26
Iteration:   1020, Loss function: 4.390, Average Loss: 4.286, avg. samples / sec: 53182.36
Iteration:   1020, Loss function: 5.276, Average Loss: 4.278, avg. samples / sec: 53067.61
Iteration:   1020, Loss function: 4.138, Average Loss: 4.276, avg. samples / sec: 52983.55
Iteration:   1020, Loss function: 5.306, Average Loss: 4.245, avg. samples / sec: 53131.87
Iteration:   1020, Loss function: 4.720, Average Loss: 4.259, avg. samples / sec: 53026.29
Iteration:   1020, Loss function: 5.435, Average Loss: 4.264, avg. samples / sec: 53131.35
Iteration:   1020, Loss function: 5.349, Average Loss: 4.260, avg. samples / sec: 53120.03
Iteration:   1020, Loss function: 4.866, Average Loss: 4.281, avg. samples / sec: 53153.39
Iteration:   1020, Loss function: 5.265, Average Loss: 4.260, avg. samples / sec: 52937.73
Iteration:   1020, Loss function: 6.864, Average Loss: 4.272, avg. samples / sec: 53127.08
Iteration:   1020, Loss function: 6.055, Average Loss: 4.249, avg. samples / sec: 52845.98
Iteration:   1020, Loss function: 4.029, Average Loss: 4.264, avg. samples / sec: 53104.04
Iteration:   1020, Loss function: 5.194, Average Loss: 4.267, avg. samples / sec: 53728.62
Iteration:   1020, Loss function: 5.688, Average Loss: 4.219, avg. samples / sec: 52922.86
Iteration:   1020, Loss function: 4.407, Average Loss: 4.259, avg. samples / sec: 52705.92
Iteration:   1040, Loss function: 4.833, Average Loss: 4.285, avg. samples / sec: 52901.77
Iteration:   1040, Loss function: 7.085, Average Loss: 4.282, avg. samples / sec: 52899.74
Iteration:   1040, Loss function: 4.652, Average Loss: 4.260, avg. samples / sec: 52832.95
Iteration:   1040, Loss function: 4.495, Average Loss: 4.292, avg. samples / sec: 52879.30
Iteration:   1040, Loss function: 5.786, Average Loss: 4.259, avg. samples / sec: 52884.24
Iteration:   1040, Loss function: 6.491, Average Loss: 4.294, avg. samples / sec: 52826.83
Iteration:   1040, Loss function: 6.207, Average Loss: 4.273, avg. samples / sec: 52883.86
Iteration:   1040, Loss function: 4.256, Average Loss: 4.298, avg. samples / sec: 52975.54
Iteration:   1040, Loss function: 6.065, Average Loss: 4.280, avg. samples / sec: 53257.84
Iteration:   1040, Loss function: 5.305, Average Loss: 4.271, avg. samples / sec: 52833.50
Iteration:   1040, Loss function: 4.994, Average Loss: 4.293, avg. samples / sec: 52762.67
Iteration:   1040, Loss function: 4.195, Average Loss: 4.286, avg. samples / sec: 52806.36
Iteration:   1040, Loss function: 4.908, Average Loss: 4.290, avg. samples / sec: 52766.19
Iteration:   1040, Loss function: 3.851, Average Loss: 4.286, avg. samples / sec: 52800.66
Iteration:   1040, Loss function: 5.642, Average Loss: 4.298, avg. samples / sec: 52800.62
Iteration:   1040, Loss function: 4.735, Average Loss: 4.277, avg. samples / sec: 53003.24
Iteration:   1040, Loss function: 4.606, Average Loss: 4.264, avg. samples / sec: 52851.08
Iteration:   1040, Loss function: 5.520, Average Loss: 4.269, avg. samples / sec: 52690.70
Iteration:   1040, Loss function: 4.528, Average Loss: 4.277, avg. samples / sec: 52863.37
Iteration:   1040, Loss function: 5.791, Average Loss: 4.300, avg. samples / sec: 52665.36
Iteration:   1040, Loss function: 4.481, Average Loss: 4.301, avg. samples / sec: 52859.96
Iteration:   1040, Loss function: 5.877, Average Loss: 4.277, avg. samples / sec: 52826.73
Iteration:   1040, Loss function: 3.732, Average Loss: 4.274, avg. samples / sec: 52434.26
Iteration:   1040, Loss function: 5.843, Average Loss: 4.288, avg. samples / sec: 52839.37
Iteration:   1040, Loss function: 5.155, Average Loss: 4.271, avg. samples / sec: 52841.21
Iteration:   1040, Loss function: 4.815, Average Loss: 4.280, avg. samples / sec: 52816.59
Iteration:   1040, Loss function: 5.846, Average Loss: 4.238, avg. samples / sec: 52862.77
Iteration:   1040, Loss function: 5.667, Average Loss: 4.286, avg. samples / sec: 52803.39
Iteration:   1040, Loss function: 5.419, Average Loss: 4.281, avg. samples / sec: 52483.92
Iteration:   1040, Loss function: 5.059, Average Loss: 4.296, avg. samples / sec: 52229.15
:::MLL 1558641130.759 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558641130.760 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 4.220, Average Loss: 4.284, avg. samples / sec: 53134.73
Iteration:   1060, Loss function: 5.277, Average Loss: 4.298, avg. samples / sec: 52778.77
Iteration:   1060, Loss function: 4.738, Average Loss: 4.311, avg. samples / sec: 52845.51
Iteration:   1060, Loss function: 4.037, Average Loss: 4.314, avg. samples / sec: 52848.22
Iteration:   1060, Loss function: 4.803, Average Loss: 4.308, avg. samples / sec: 52806.36
Iteration:   1060, Loss function: 3.902, Average Loss: 4.308, avg. samples / sec: 52890.09
Iteration:   1060, Loss function: 4.892, Average Loss: 4.288, avg. samples / sec: 52869.36
Iteration:   1060, Loss function: 5.360, Average Loss: 4.302, avg. samples / sec: 52891.11
Iteration:   1060, Loss function: 5.043, Average Loss: 4.283, avg. samples / sec: 52794.29
Iteration:   1060, Loss function: 5.407, Average Loss: 4.315, avg. samples / sec: 52887.87
Iteration:   1060, Loss function: 4.908, Average Loss: 4.302, avg. samples / sec: 52844.74
Iteration:   1060, Loss function: 3.509, Average Loss: 4.279, avg. samples / sec: 52980.18
Iteration:   1060, Loss function: 4.982, Average Loss: 4.305, avg. samples / sec: 52833.62
Iteration:   1060, Loss function: 5.420, Average Loss: 4.267, avg. samples / sec: 52752.89
Iteration:   1060, Loss function: 4.247, Average Loss: 4.277, avg. samples / sec: 52743.50
Iteration:   1060, Loss function: 4.984, Average Loss: 4.306, avg. samples / sec: 53448.64
Iteration:   1060, Loss function: 4.809, Average Loss: 4.278, avg. samples / sec: 52858.91
Iteration:   1060, Loss function: 4.122, Average Loss: 4.302, avg. samples / sec: 53226.73
Iteration:   1060, Loss function: 5.021, Average Loss: 4.290, avg. samples / sec: 52841.07
Iteration:   1060, Loss function: 5.368, Average Loss: 4.311, avg. samples / sec: 52824.27
Iteration:   1060, Loss function: 4.511, Average Loss: 4.291, avg. samples / sec: 52577.71
Iteration:   1060, Loss function: 5.650, Average Loss: 4.306, avg. samples / sec: 52841.55
Iteration:   1060, Loss function: 4.508, Average Loss: 4.318, avg. samples / sec: 52803.91
Iteration:   1060, Loss function: 4.398, Average Loss: 4.285, avg. samples / sec: 52850.56
Iteration:   1060, Loss function: 4.934, Average Loss: 4.295, avg. samples / sec: 52902.68
Iteration:   1060, Loss function: 5.579, Average Loss: 4.286, avg. samples / sec: 52838.00
Iteration:   1060, Loss function: 4.050, Average Loss: 4.288, avg. samples / sec: 52648.95
Iteration:   1060, Loss function: 4.122, Average Loss: 4.249, avg. samples / sec: 52643.13
Iteration:   1060, Loss function: 5.759, Average Loss: 4.292, avg. samples / sec: 52172.21
Iteration:   1060, Loss function: 5.264, Average Loss: 4.289, avg. samples / sec: 51894.95
Iteration:   1080, Loss function: 4.079, Average Loss: 4.306, avg. samples / sec: 52990.74
Iteration:   1080, Loss function: 4.998, Average Loss: 4.304, avg. samples / sec: 53030.30
Iteration:   1080, Loss function: 5.745, Average Loss: 4.289, avg. samples / sec: 53056.66
Iteration:   1080, Loss function: 5.476, Average Loss: 4.318, avg. samples / sec: 53008.46
Iteration:   1080, Loss function: 4.798, Average Loss: 4.329, avg. samples / sec: 52998.61
Iteration:   1080, Loss function: 4.667, Average Loss: 4.312, avg. samples / sec: 53045.41
Iteration:   1080, Loss function: 4.545, Average Loss: 4.277, avg. samples / sec: 53039.58
Iteration:   1080, Loss function: 4.554, Average Loss: 4.290, avg. samples / sec: 53030.04
Iteration:   1080, Loss function: 4.738, Average Loss: 4.315, avg. samples / sec: 52997.50
Iteration:   1080, Loss function: 5.999, Average Loss: 4.316, avg. samples / sec: 53033.94
Iteration:   1080, Loss function: 4.918, Average Loss: 4.315, avg. samples / sec: 53020.37
Iteration:   1080, Loss function: 4.836, Average Loss: 4.313, avg. samples / sec: 52964.59
Iteration:   1080, Loss function: 6.656, Average Loss: 4.328, avg. samples / sec: 53002.60
Iteration:   1080, Loss function: 4.388, Average Loss: 4.301, avg. samples / sec: 53658.98
Iteration:   1080, Loss function: 4.040, Average Loss: 4.320, avg. samples / sec: 53169.25
Iteration:   1080, Loss function: 4.985, Average Loss: 4.318, avg. samples / sec: 52896.86
Iteration:   1080, Loss function: 5.250, Average Loss: 4.315, avg. samples / sec: 53009.80
Iteration:   1080, Loss function: 5.271, Average Loss: 4.294, avg. samples / sec: 52853.77
Iteration:   1080, Loss function: 4.294, Average Loss: 4.291, avg. samples / sec: 52956.75
Iteration:   1080, Loss function: 3.292, Average Loss: 4.298, avg. samples / sec: 53070.54
Iteration:   1080, Loss function: 4.873, Average Loss: 4.297, avg. samples / sec: 52985.52
Iteration:   1080, Loss function: 4.719, Average Loss: 4.332, avg. samples / sec: 53021.25
Iteration:   1080, Loss function: 5.407, Average Loss: 4.304, avg. samples / sec: 53002.84
Iteration:   1080, Loss function: 4.226, Average Loss: 4.297, avg. samples / sec: 52705.82
Iteration:   1080, Loss function: 4.246, Average Loss: 4.300, avg. samples / sec: 52994.81
Iteration:   1080, Loss function: 4.715, Average Loss: 4.299, avg. samples / sec: 52977.00
Iteration:   1080, Loss function: 5.198, Average Loss: 4.325, avg. samples / sec: 52975.34
Iteration:   1080, Loss function: 5.422, Average Loss: 4.305, avg. samples / sec: 52967.80
Iteration:   1080, Loss function: 4.377, Average Loss: 4.258, avg. samples / sec: 53183.76
Iteration:   1080, Loss function: 3.832, Average Loss: 4.298, avg. samples / sec: 53872.97
Iteration:   1100, Loss function: 4.926, Average Loss: 4.340, avg. samples / sec: 53305.22
Iteration:   1100, Loss function: 5.032, Average Loss: 4.332, avg. samples / sec: 53293.81
Iteration:   1100, Loss function: 5.275, Average Loss: 4.307, avg. samples / sec: 53275.02
Iteration:   1100, Loss function: 5.610, Average Loss: 4.330, avg. samples / sec: 53326.26
Iteration:   1100, Loss function: 6.284, Average Loss: 4.330, avg. samples / sec: 53318.17
Iteration:   1100, Loss function: 4.369, Average Loss: 4.324, avg. samples / sec: 53259.47
Iteration:   1100, Loss function: 4.610, Average Loss: 4.320, avg. samples / sec: 53250.56
Iteration:   1100, Loss function: 4.412, Average Loss: 4.328, avg. samples / sec: 53333.06
Iteration:   1100, Loss function: 4.890, Average Loss: 4.318, avg. samples / sec: 53311.17
Iteration:   1100, Loss function: 4.432, Average Loss: 4.325, avg. samples / sec: 53250.92
Iteration:   1100, Loss function: 4.810, Average Loss: 4.294, avg. samples / sec: 53273.18
Iteration:   1100, Loss function: 5.894, Average Loss: 4.333, avg. samples / sec: 53279.21
Iteration:   1100, Loss function: 5.146, Average Loss: 4.337, avg. samples / sec: 53272.08
Iteration:   1100, Loss function: 4.900, Average Loss: 4.301, avg. samples / sec: 53266.44
Iteration:   1100, Loss function: 5.651, Average Loss: 4.310, avg. samples / sec: 53454.07
Iteration:   1100, Loss function: 3.690, Average Loss: 4.335, avg. samples / sec: 53255.77
Iteration:   1100, Loss function: 4.248, Average Loss: 4.322, avg. samples / sec: 53376.13
Iteration:   1100, Loss function: 4.645, Average Loss: 4.311, avg. samples / sec: 53306.65
Iteration:   1100, Loss function: 5.434, Average Loss: 4.311, avg. samples / sec: 53324.57
Iteration:   1100, Loss function: 5.448, Average Loss: 4.305, avg. samples / sec: 53286.28
Iteration:   1100, Loss function: 4.680, Average Loss: 4.323, avg. samples / sec: 53271.69
Iteration:   1100, Loss function: 3.726, Average Loss: 4.300, avg. samples / sec: 53275.48
Iteration:   1100, Loss function: 5.611, Average Loss: 4.310, avg. samples / sec: 53333.79
Iteration:   1100, Loss function: 5.217, Average Loss: 4.306, avg. samples / sec: 53401.89
Iteration:   1100, Loss function: 4.079, Average Loss: 4.311, avg. samples / sec: 53320.59
Iteration:   1100, Loss function: 4.557, Average Loss: 4.340, avg. samples / sec: 53312.44
Iteration:   1100, Loss function: 4.102, Average Loss: 4.317, avg. samples / sec: 53317.85
Iteration:   1100, Loss function: 4.975, Average Loss: 4.347, avg. samples / sec: 53127.88
Iteration:   1100, Loss function: 4.569, Average Loss: 4.331, avg. samples / sec: 52895.81
Iteration:   1100, Loss function: 4.960, Average Loss: 4.270, avg. samples / sec: 52859.56
:::MLL 1558641132.976 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558641132.977 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 4.740, Average Loss: 4.342, avg. samples / sec: 52876.04
Iteration:   1120, Loss function: 5.526, Average Loss: 4.336, avg. samples / sec: 52851.93
Iteration:   1120, Loss function: 5.763, Average Loss: 4.340, avg. samples / sec: 52840.38
Iteration:   1120, Loss function: 6.341, Average Loss: 4.325, avg. samples / sec: 52889.72
Iteration:   1120, Loss function: 5.399, Average Loss: 4.337, avg. samples / sec: 52928.55
Iteration:   1120, Loss function: 4.575, Average Loss: 4.314, avg. samples / sec: 52835.25
Iteration:   1120, Loss function: 4.454, Average Loss: 4.345, avg. samples / sec: 52785.71
Iteration:   1120, Loss function: 3.244, Average Loss: 4.335, avg. samples / sec: 52749.34
Iteration:   1120, Loss function: 5.256, Average Loss: 4.344, avg. samples / sec: 52783.22
Iteration:   1120, Loss function: 5.424, Average Loss: 4.347, avg. samples / sec: 52811.63
Iteration:   1120, Loss function: 4.500, Average Loss: 4.351, avg. samples / sec: 52667.71
Iteration:   1120, Loss function: 4.125, Average Loss: 4.332, avg. samples / sec: 52718.54
Iteration:   1120, Loss function: 3.740, Average Loss: 4.318, avg. samples / sec: 52904.31
Iteration:   1120, Loss function: 4.259, Average Loss: 4.346, avg. samples / sec: 52656.43
Iteration:   1120, Loss function: 5.105, Average Loss: 4.338, avg. samples / sec: 52665.70
Iteration:   1120, Loss function: 5.982, Average Loss: 4.338, avg. samples / sec: 52683.32
Iteration:   1120, Loss function: 4.635, Average Loss: 4.317, avg. samples / sec: 52635.96
Iteration:   1120, Loss function: 4.735, Average Loss: 4.309, avg. samples / sec: 52814.14
Iteration:   1120, Loss function: 4.559, Average Loss: 4.303, avg. samples / sec: 52622.20
Iteration:   1120, Loss function: 4.616, Average Loss: 4.327, avg. samples / sec: 52784.41
Iteration:   1120, Loss function: 3.803, Average Loss: 4.322, avg. samples / sec: 52773.14
Iteration:   1120, Loss function: 5.488, Average Loss: 4.326, avg. samples / sec: 52791.03
Iteration:   1120, Loss function: 4.228, Average Loss: 4.321, avg. samples / sec: 52769.31
Iteration:   1120, Loss function: 5.094, Average Loss: 4.281, avg. samples / sec: 53254.30
Iteration:   1120, Loss function: 5.294, Average Loss: 4.314, avg. samples / sec: 52661.23
Iteration:   1120, Loss function: 4.301, Average Loss: 4.326, avg. samples / sec: 52645.93
Iteration:   1120, Loss function: 5.144, Average Loss: 4.352, avg. samples / sec: 52691.36
Iteration:   1120, Loss function: 3.969, Average Loss: 4.360, avg. samples / sec: 52816.89
Iteration:   1120, Loss function: 3.645, Average Loss: 4.328, avg. samples / sec: 52677.19
Iteration:   1120, Loss function: 4.939, Average Loss: 4.342, avg. samples / sec: 52863.98
Iteration:   1140, Loss function: 4.970, Average Loss: 4.346, avg. samples / sec: 53265.37
Iteration:   1140, Loss function: 4.290, Average Loss: 4.333, avg. samples / sec: 53116.69
Iteration:   1140, Loss function: 4.115, Average Loss: 4.352, avg. samples / sec: 53186.81
Iteration:   1140, Loss function: 5.412, Average Loss: 4.337, avg. samples / sec: 53271.33
Iteration:   1140, Loss function: 6.114, Average Loss: 4.350, avg. samples / sec: 52964.41
Iteration:   1140, Loss function: 4.694, Average Loss: 4.349, avg. samples / sec: 52961.75
Iteration:   1140, Loss function: 4.844, Average Loss: 4.323, avg. samples / sec: 53023.40
Iteration:   1140, Loss function: 4.761, Average Loss: 4.348, avg. samples / sec: 53024.20
Iteration:   1140, Loss function: 5.941, Average Loss: 4.350, avg. samples / sec: 53056.38
Iteration:   1140, Loss function: 4.394, Average Loss: 4.339, avg. samples / sec: 53362.71
Iteration:   1140, Loss function: 4.924, Average Loss: 4.346, avg. samples / sec: 52939.62
Iteration:   1140, Loss function: 4.835, Average Loss: 4.314, avg. samples / sec: 53201.95
Iteration:   1140, Loss function: 5.507, Average Loss: 4.360, avg. samples / sec: 53090.54
Iteration:   1140, Loss function: 4.756, Average Loss: 4.347, avg. samples / sec: 53122.74
Iteration:   1140, Loss function: 5.482, Average Loss: 4.359, avg. samples / sec: 53025.85
Iteration:   1140, Loss function: 4.342, Average Loss: 4.355, avg. samples / sec: 53020.85
Iteration:   1140, Loss function: 5.831, Average Loss: 4.328, avg. samples / sec: 53114.51
Iteration:   1140, Loss function: 4.932, Average Loss: 4.326, avg. samples / sec: 53197.89
Iteration:   1140, Loss function: 4.453, Average Loss: 4.329, avg. samples / sec: 53080.12
Iteration:   1140, Loss function: 4.932, Average Loss: 4.348, avg. samples / sec: 52966.92
Iteration:   1140, Loss function: 5.429, Average Loss: 4.320, avg. samples / sec: 53039.48
Iteration:   1140, Loss function: 5.906, Average Loss: 4.348, avg. samples / sec: 52942.73
Iteration:   1140, Loss function: 7.028, Average Loss: 4.331, avg. samples / sec: 52943.58
Iteration:   1140, Loss function: 4.420, Average Loss: 4.374, avg. samples / sec: 53191.01
Iteration:   1140, Loss function: 5.047, Average Loss: 4.330, avg. samples / sec: 53062.07
Iteration:   1140, Loss function: 4.580, Average Loss: 4.332, avg. samples / sec: 53023.12
Iteration:   1140, Loss function: 4.943, Average Loss: 4.363, avg. samples / sec: 53138.94
Iteration:   1140, Loss function: 4.353, Average Loss: 4.338, avg. samples / sec: 53158.82
Iteration:   1140, Loss function: 3.468, Average Loss: 4.352, avg. samples / sec: 53165.10
Iteration:   1140, Loss function: 6.100, Average Loss: 4.291, avg. samples / sec: 53025.55
Iteration:   1160, Loss function: 4.598, Average Loss: 4.354, avg. samples / sec: 53356.85
Iteration:   1160, Loss function: 3.971, Average Loss: 4.353, avg. samples / sec: 53698.69
Iteration:   1160, Loss function: 5.029, Average Loss: 4.361, avg. samples / sec: 53509.64
Iteration:   1160, Loss function: 5.140, Average Loss: 4.363, avg. samples / sec: 53425.01
Iteration:   1160, Loss function: 5.746, Average Loss: 4.372, avg. samples / sec: 53509.97
Iteration:   1160, Loss function: 5.313, Average Loss: 4.338, avg. samples / sec: 53520.92
Iteration:   1160, Loss function: 4.623, Average Loss: 4.358, avg. samples / sec: 53462.85
Iteration:   1160, Loss function: 4.767, Average Loss: 4.323, avg. samples / sec: 53483.83
Iteration:   1160, Loss function: 4.313, Average Loss: 4.356, avg. samples / sec: 53481.80
Iteration:   1160, Loss function: 4.799, Average Loss: 4.358, avg. samples / sec: 53471.23
Iteration:   1160, Loss function: 5.530, Average Loss: 4.336, avg. samples / sec: 53446.57
Iteration:   1160, Loss function: 5.197, Average Loss: 4.356, avg. samples / sec: 53619.56
Iteration:   1160, Loss function: 5.020, Average Loss: 4.362, avg. samples / sec: 53479.37
Iteration:   1160, Loss function: 3.927, Average Loss: 4.354, avg. samples / sec: 53480.75
Iteration:   1160, Loss function: 5.529, Average Loss: 4.359, avg. samples / sec: 53432.71
Iteration:   1160, Loss function: 4.421, Average Loss: 4.371, avg. samples / sec: 53463.44
Iteration:   1160, Loss function: 5.245, Average Loss: 4.345, avg. samples / sec: 53244.24
Iteration:   1160, Loss function: 3.832, Average Loss: 4.345, avg. samples / sec: 53323.05
Iteration:   1160, Loss function: 3.414, Average Loss: 4.334, avg. samples / sec: 53466.04
Iteration:   1160, Loss function: 4.663, Average Loss: 4.333, avg. samples / sec: 53489.96
Iteration:   1160, Loss function: 4.625, Average Loss: 4.343, avg. samples / sec: 53515.76
Iteration:   1160, Loss function: 4.624, Average Loss: 4.340, avg. samples / sec: 53412.76
Iteration:   1160, Loss function: 5.953, Average Loss: 4.340, avg. samples / sec: 53469.75
Iteration:   1160, Loss function: 3.998, Average Loss: 4.347, avg. samples / sec: 53178.32
Iteration:   1160, Loss function: 4.938, Average Loss: 4.339, avg. samples / sec: 53415.98
Iteration:   1160, Loss function: 4.970, Average Loss: 4.388, avg. samples / sec: 53408.86
Iteration:   1160, Loss function: 5.060, Average Loss: 4.366, avg. samples / sec: 53444.02
Iteration:   1160, Loss function: 4.194, Average Loss: 4.307, avg. samples / sec: 53464.39
Iteration:   1160, Loss function: 3.279, Average Loss: 4.351, avg. samples / sec: 53427.18
Iteration:   1160, Loss function: 5.207, Average Loss: 4.370, avg. samples / sec: 53173.23
Iteration:   1180, Loss function: 3.959, Average Loss: 4.369, avg. samples / sec: 53304.84
Iteration:   1180, Loss function: 5.138, Average Loss: 4.370, avg. samples / sec: 53269.00
Iteration:   1180, Loss function: 4.869, Average Loss: 4.374, avg. samples / sec: 53529.28
Iteration:   1180, Loss function: 6.785, Average Loss: 4.366, avg. samples / sec: 53250.14
Iteration:   1180, Loss function: 5.966, Average Loss: 4.360, avg. samples / sec: 53191.73
Iteration:   1180, Loss function: 4.723, Average Loss: 4.366, avg. samples / sec: 53259.65
Iteration:   1180, Loss function: 5.489, Average Loss: 4.384, avg. samples / sec: 53220.78
Iteration:   1180, Loss function: 5.435, Average Loss: 4.344, avg. samples / sec: 53240.52
Iteration:   1180, Loss function: 5.823, Average Loss: 4.377, avg. samples / sec: 53269.86
Iteration:   1180, Loss function: 5.537, Average Loss: 4.394, avg. samples / sec: 53471.13
Iteration:   1180, Loss function: 4.406, Average Loss: 4.348, avg. samples / sec: 53198.60
Iteration:   1180, Loss function: 3.592, Average Loss: 4.366, avg. samples / sec: 53209.88
Iteration:   1180, Loss function: 7.261, Average Loss: 4.334, avg. samples / sec: 53204.04
Iteration:   1180, Loss function: 6.543, Average Loss: 4.370, avg. samples / sec: 53214.59
Iteration:   1180, Loss function: 4.585, Average Loss: 4.362, avg. samples / sec: 53194.02
Iteration:   1180, Loss function: 6.082, Average Loss: 4.369, avg. samples / sec: 53158.02
Iteration:   1180, Loss function: 5.541, Average Loss: 4.368, avg. samples / sec: 53067.21
Iteration:   1180, Loss function: 4.683, Average Loss: 4.349, avg. samples / sec: 53232.58
Iteration:   1180, Loss function: 3.350, Average Loss: 4.337, avg. samples / sec: 53259.27
Iteration:   1180, Loss function: 4.190, Average Loss: 4.369, avg. samples / sec: 53098.78
Iteration:   1180, Loss function: 4.234, Average Loss: 4.353, avg. samples / sec: 53187.27
Iteration:   1180, Loss function: 4.718, Average Loss: 4.356, avg. samples / sec: 53269.74
Iteration:   1180, Loss function: 5.109, Average Loss: 4.348, avg. samples / sec: 53199.36
Iteration:   1180, Loss function: 4.678, Average Loss: 4.342, avg. samples / sec: 53170.40
Iteration:   1180, Loss function: 5.216, Average Loss: 4.348, avg. samples / sec: 53241.24
Iteration:   1180, Loss function: 4.362, Average Loss: 4.350, avg. samples / sec: 53205.55
Iteration:   1180, Loss function: 4.760, Average Loss: 4.348, avg. samples / sec: 53197.73
Iteration:   1180, Loss function: 4.607, Average Loss: 4.377, avg. samples / sec: 53495.71
Iteration:   1180, Loss function: 4.824, Average Loss: 4.362, avg. samples / sec: 53228.33
Iteration:   1180, Loss function: 4.738, Average Loss: 4.319, avg. samples / sec: 53201.55
:::MLL 1558641135.187 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558641135.188 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 4.997, Average Loss: 4.381, avg. samples / sec: 52935.89
Iteration:   1200, Loss function: 4.913, Average Loss: 4.398, avg. samples / sec: 52914.10
Iteration:   1200, Loss function: 4.905, Average Loss: 4.361, avg. samples / sec: 53100.12
Iteration:   1200, Loss function: 4.908, Average Loss: 4.375, avg. samples / sec: 52869.62
Iteration:   1200, Loss function: 4.573, Average Loss: 4.369, avg. samples / sec: 52781.56
Iteration:   1200, Loss function: 4.966, Average Loss: 4.359, avg. samples / sec: 52751.19
Iteration:   1200, Loss function: 4.377, Average Loss: 4.387, avg. samples / sec: 52953.19
Iteration:   1200, Loss function: 3.779, Average Loss: 4.383, avg. samples / sec: 52852.72
Iteration:   1200, Loss function: 5.290, Average Loss: 4.380, avg. samples / sec: 52673.06
Iteration:   1200, Loss function: 5.359, Average Loss: 4.390, avg. samples / sec: 52667.94
Iteration:   1200, Loss function: 5.571, Average Loss: 4.346, avg. samples / sec: 52683.83
Iteration:   1200, Loss function: 5.193, Average Loss: 4.364, avg. samples / sec: 52669.44
Iteration:   1200, Loss function: 4.469, Average Loss: 4.376, avg. samples / sec: 52695.65
Iteration:   1200, Loss function: 4.534, Average Loss: 4.335, avg. samples / sec: 52924.00
Iteration:   1200, Loss function: 5.320, Average Loss: 4.364, avg. samples / sec: 52804.90
Iteration:   1200, Loss function: 5.618, Average Loss: 4.355, avg. samples / sec: 52766.17
Iteration:   1200, Loss function: 4.044, Average Loss: 4.359, avg. samples / sec: 52789.59
Iteration:   1200, Loss function: 4.819, Average Loss: 4.360, avg. samples / sec: 52759.43
Iteration:   1200, Loss function: 5.220, Average Loss: 4.374, avg. samples / sec: 52784.49
Iteration:   1200, Loss function: 5.816, Average Loss: 4.363, avg. samples / sec: 52718.28
Iteration:   1200, Loss function: 5.045, Average Loss: 4.381, avg. samples / sec: 52538.71
Iteration:   1200, Loss function: 4.767, Average Loss: 4.364, avg. samples / sec: 52496.57
Iteration:   1200, Loss function: 3.534, Average Loss: 4.377, avg. samples / sec: 52380.75
Iteration:   1200, Loss function: 5.829, Average Loss: 4.385, avg. samples / sec: 52413.73
Iteration:   1200, Loss function: 3.997, Average Loss: 4.353, avg. samples / sec: 52453.50
Iteration:   1200, Loss function: 3.750, Average Loss: 4.403, avg. samples / sec: 52346.91
Iteration:   1200, Loss function: 5.478, Average Loss: 4.382, avg. samples / sec: 52348.47
Iteration:   1200, Loss function: 5.276, Average Loss: 4.384, avg. samples / sec: 52163.21
Iteration:   1200, Loss function: 5.489, Average Loss: 4.386, avg. samples / sec: 52221.55
Iteration:   1200, Loss function: 4.610, Average Loss: 4.371, avg. samples / sec: 52459.48
Iteration:   1220, Loss function: 5.266, Average Loss: 4.394, avg. samples / sec: 53678.44
Iteration:   1220, Loss function: 4.837, Average Loss: 4.356, avg. samples / sec: 53617.09
Iteration:   1220, Loss function: 3.138, Average Loss: 4.390, avg. samples / sec: 53974.46
Iteration:   1220, Loss function: 4.491, Average Loss: 4.381, avg. samples / sec: 53598.11
Iteration:   1220, Loss function: 5.731, Average Loss: 4.385, avg. samples / sec: 53414.34
Iteration:   1220, Loss function: 5.330, Average Loss: 4.392, avg. samples / sec: 53954.56
Iteration:   1220, Loss function: 7.524, Average Loss: 4.374, avg. samples / sec: 53454.80
Iteration:   1220, Loss function: 3.576, Average Loss: 4.396, avg. samples / sec: 53519.78
Iteration:   1220, Loss function: 4.898, Average Loss: 4.377, avg. samples / sec: 53773.89
Iteration:   1220, Loss function: 4.145, Average Loss: 4.362, avg. samples / sec: 53873.59
Iteration:   1220, Loss function: 4.448, Average Loss: 4.369, avg. samples / sec: 53544.06
Iteration:   1220, Loss function: 4.617, Average Loss: 4.384, avg. samples / sec: 53238.21
Iteration:   1220, Loss function: 4.732, Average Loss: 4.390, avg. samples / sec: 53711.65
Iteration:   1220, Loss function: 5.357, Average Loss: 4.395, avg. samples / sec: 53819.07
Iteration:   1220, Loss function: 4.900, Average Loss: 4.381, avg. samples / sec: 53299.94
Iteration:   1220, Loss function: 3.376, Average Loss: 4.412, avg. samples / sec: 53217.06
Iteration:   1220, Loss function: 5.701, Average Loss: 4.374, avg. samples / sec: 53498.57
Iteration:   1220, Loss function: 4.402, Average Loss: 4.399, avg. samples / sec: 53413.63
Iteration:   1220, Loss function: 5.284, Average Loss: 4.376, avg. samples / sec: 53781.30
Iteration:   1220, Loss function: 4.598, Average Loss: 4.366, avg. samples / sec: 53452.86
Iteration:   1220, Loss function: 5.854, Average Loss: 4.369, avg. samples / sec: 53476.89
Iteration:   1220, Loss function: 5.451, Average Loss: 4.384, avg. samples / sec: 53571.11
Iteration:   1220, Loss function: 6.982, Average Loss: 4.374, avg. samples / sec: 53480.89
Iteration:   1220, Loss function: 6.702, Average Loss: 4.394, avg. samples / sec: 53737.08
Iteration:   1220, Loss function: 4.748, Average Loss: 4.414, avg. samples / sec: 53651.24
Iteration:   1220, Loss function: 5.710, Average Loss: 4.400, avg. samples / sec: 53299.90
Iteration:   1220, Loss function: 5.729, Average Loss: 4.374, avg. samples / sec: 53098.16
Iteration:   1220, Loss function: 3.254, Average Loss: 4.343, avg. samples / sec: 53296.01
Iteration:   1220, Loss function: 5.316, Average Loss: 4.368, avg. samples / sec: 53379.34
Iteration:   1220, Loss function: 4.300, Average Loss: 4.389, avg. samples / sec: 53389.21
Iteration:   1240, Loss function: 5.954, Average Loss: 4.382, avg. samples / sec: 53197.43
Iteration:   1240, Loss function: 4.429, Average Loss: 4.405, avg. samples / sec: 53001.90
Iteration:   1240, Loss function: 4.791, Average Loss: 4.391, avg. samples / sec: 53142.61
Iteration:   1240, Loss function: 3.950, Average Loss: 4.373, avg. samples / sec: 53077.46
Iteration:   1240, Loss function: 5.717, Average Loss: 4.406, avg. samples / sec: 53165.16
Iteration:   1240, Loss function: 6.379, Average Loss: 4.396, avg. samples / sec: 53134.93
Iteration:   1240, Loss function: 4.850, Average Loss: 4.397, avg. samples / sec: 53332.92
Iteration:   1240, Loss function: 5.385, Average Loss: 4.389, avg. samples / sec: 53211.75
Iteration:   1240, Loss function: 5.080, Average Loss: 4.390, avg. samples / sec: 53120.85
Iteration:   1240, Loss function: 5.667, Average Loss: 4.425, avg. samples / sec: 53178.22
Iteration:   1240, Loss function: 4.945, Average Loss: 4.396, avg. samples / sec: 53118.85
Iteration:   1240, Loss function: 5.538, Average Loss: 4.391, avg. samples / sec: 53143.91
Iteration:   1240, Loss function: 6.053, Average Loss: 4.407, avg. samples / sec: 53035.87
Iteration:   1240, Loss function: 5.358, Average Loss: 4.405, avg. samples / sec: 53072.40
Iteration:   1240, Loss function: 5.252, Average Loss: 4.411, avg. samples / sec: 53066.51
Iteration:   1240, Loss function: 5.622, Average Loss: 4.413, avg. samples / sec: 53296.76
Iteration:   1240, Loss function: 4.635, Average Loss: 4.404, avg. samples / sec: 53072.62
Iteration:   1240, Loss function: 3.913, Average Loss: 4.398, avg. samples / sec: 52968.71
Iteration:   1240, Loss function: 5.640, Average Loss: 4.376, avg. samples / sec: 52992.22
Iteration:   1240, Loss function: 5.080, Average Loss: 4.391, avg. samples / sec: 53158.10
Iteration:   1240, Loss function: 5.151, Average Loss: 4.387, avg. samples / sec: 53131.31
Iteration:   1240, Loss function: 5.315, Average Loss: 4.377, avg. samples / sec: 53112.46
Iteration:   1240, Loss function: 4.819, Average Loss: 4.385, avg. samples / sec: 53137.90
Iteration:   1240, Loss function: 5.126, Average Loss: 4.392, avg. samples / sec: 53142.43
Iteration:   1240, Loss function: 5.615, Average Loss: 4.431, avg. samples / sec: 53141.73
Iteration:   1240, Loss function: 4.737, Average Loss: 4.381, avg. samples / sec: 53182.32
Iteration:   1240, Loss function: 5.014, Average Loss: 4.395, avg. samples / sec: 53201.79
Iteration:   1240, Loss function: 6.211, Average Loss: 4.418, avg. samples / sec: 52978.31
Iteration:   1240, Loss function: 4.808, Average Loss: 4.399, avg. samples / sec: 53096.30
Iteration:   1240, Loss function: 5.310, Average Loss: 4.345, avg. samples / sec: 53124.80
:::MLL 1558641137.401 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558641137.402 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 3.307, Average Loss: 4.404, avg. samples / sec: 53065.19
Iteration:   1260, Loss function: 4.468, Average Loss: 4.412, avg. samples / sec: 53030.30
Iteration:   1260, Loss function: 3.771, Average Loss: 4.418, avg. samples / sec: 53126.36
Iteration:   1260, Loss function: 3.855, Average Loss: 4.409, avg. samples / sec: 53058.91
Iteration:   1260, Loss function: 5.074, Average Loss: 4.420, avg. samples / sec: 53109.08
Iteration:   1260, Loss function: 4.266, Average Loss: 4.401, avg. samples / sec: 53021.66
Iteration:   1260, Loss function: 5.261, Average Loss: 4.410, avg. samples / sec: 52986.54
Iteration:   1260, Loss function: 4.700, Average Loss: 4.401, avg. samples / sec: 53026.25
Iteration:   1260, Loss function: 4.202, Average Loss: 4.403, avg. samples / sec: 52949.69
Iteration:   1260, Loss function: 3.643, Average Loss: 4.395, avg. samples / sec: 52964.10
Iteration:   1260, Loss function: 4.302, Average Loss: 4.431, avg. samples / sec: 52960.45
Iteration:   1260, Loss function: 3.766, Average Loss: 4.405, avg. samples / sec: 53051.74
Iteration:   1260, Loss function: 4.204, Average Loss: 4.399, avg. samples / sec: 52918.51
Iteration:   1260, Loss function: 3.537, Average Loss: 4.381, avg. samples / sec: 52890.25
Iteration:   1260, Loss function: 4.987, Average Loss: 4.414, avg. samples / sec: 52987.85
Iteration:   1260, Loss function: 3.688, Average Loss: 4.403, avg. samples / sec: 52918.35
Iteration:   1260, Loss function: 4.112, Average Loss: 4.395, avg. samples / sec: 53074.68
Iteration:   1260, Loss function: 7.146, Average Loss: 4.394, avg. samples / sec: 52806.80
Iteration:   1260, Loss function: 5.658, Average Loss: 4.394, avg. samples / sec: 53092.34
Iteration:   1260, Loss function: 4.346, Average Loss: 4.378, avg. samples / sec: 53010.54
Iteration:   1260, Loss function: 4.035, Average Loss: 4.435, avg. samples / sec: 53055.20
Iteration:   1260, Loss function: 4.859, Average Loss: 4.397, avg. samples / sec: 52936.52
Iteration:   1260, Loss function: 4.889, Average Loss: 4.401, avg. samples / sec: 52988.31
Iteration:   1260, Loss function: 4.225, Average Loss: 4.385, avg. samples / sec: 52958.56
Iteration:   1260, Loss function: 4.365, Average Loss: 4.394, avg. samples / sec: 52954.72
Iteration:   1260, Loss function: 4.304, Average Loss: 4.397, avg. samples / sec: 52949.69
Iteration:   1260, Loss function: 5.443, Average Loss: 4.348, avg. samples / sec: 52971.30
Iteration:   1260, Loss function: 5.220, Average Loss: 4.401, avg. samples / sec: 52952.00
Iteration:   1260, Loss function: 5.208, Average Loss: 4.428, avg. samples / sec: 52910.31
Iteration:   1260, Loss function: 3.590, Average Loss: 4.407, avg. samples / sec: 52495.96
Iteration:   1280, Loss function: 4.819, Average Loss: 4.413, avg. samples / sec: 53532.29
Iteration:   1280, Loss function: 3.926, Average Loss: 4.411, avg. samples / sec: 53349.50
Iteration:   1280, Loss function: 4.643, Average Loss: 4.435, avg. samples / sec: 53452.65
Iteration:   1280, Loss function: 5.855, Average Loss: 4.407, avg. samples / sec: 53483.53
Iteration:   1280, Loss function: 4.244, Average Loss: 4.404, avg. samples / sec: 53460.62
Iteration:   1280, Loss function: 4.617, Average Loss: 4.384, avg. samples / sec: 53457.19
Iteration:   1280, Loss function: 5.024, Average Loss: 4.410, avg. samples / sec: 53279.37
Iteration:   1280, Loss function: 4.807, Average Loss: 4.404, avg. samples / sec: 53370.61
Iteration:   1280, Loss function: 4.892, Average Loss: 4.418, avg. samples / sec: 53384.70
Iteration:   1280, Loss function: 4.855, Average Loss: 4.412, avg. samples / sec: 53434.51
Iteration:   1280, Loss function: 4.884, Average Loss: 4.415, avg. samples / sec: 53276.95
Iteration:   1280, Loss function: 4.078, Average Loss: 4.414, avg. samples / sec: 53440.19
Iteration:   1280, Loss function: 3.623, Average Loss: 4.399, avg. samples / sec: 53482.68
Iteration:   1280, Loss function: 4.871, Average Loss: 4.414, avg. samples / sec: 53894.13
Iteration:   1280, Loss function: 4.410, Average Loss: 4.403, avg. samples / sec: 53351.96
Iteration:   1280, Loss function: 6.255, Average Loss: 4.400, avg. samples / sec: 53362.57
Iteration:   1280, Loss function: 4.015, Average Loss: 4.420, avg. samples / sec: 53251.69
Iteration:   1280, Loss function: 4.930, Average Loss: 4.411, avg. samples / sec: 53459.22
Iteration:   1280, Loss function: 4.868, Average Loss: 4.398, avg. samples / sec: 53342.13
Iteration:   1280, Loss function: 4.182, Average Loss: 4.388, avg. samples / sec: 53469.95
Iteration:   1280, Loss function: 5.947, Average Loss: 4.386, avg. samples / sec: 53329.53
Iteration:   1280, Loss function: 5.554, Average Loss: 4.398, avg. samples / sec: 53440.86
Iteration:   1280, Loss function: 4.854, Average Loss: 4.437, avg. samples / sec: 53337.50
Iteration:   1280, Loss function: 3.623, Average Loss: 4.434, avg. samples / sec: 53473.52
Iteration:   1280, Loss function: 4.254, Average Loss: 4.400, avg. samples / sec: 53270.20
Iteration:   1280, Loss function: 5.568, Average Loss: 4.426, avg. samples / sec: 53047.31
Iteration:   1280, Loss function: 4.428, Average Loss: 4.352, avg. samples / sec: 53432.16
Iteration:   1280, Loss function: 3.837, Average Loss: 4.399, avg. samples / sec: 53359.51
Iteration:   1280, Loss function: 3.922, Average Loss: 4.397, avg. samples / sec: 53394.02
Iteration:   1280, Loss function: 4.985, Average Loss: 4.413, avg. samples / sec: 53422.08
Iteration:   1300, Loss function: 5.677, Average Loss: 4.421, avg. samples / sec: 53434.96
Iteration:   1300, Loss function: 4.941, Average Loss: 4.421, avg. samples / sec: 53518.42
Iteration:   1300, Loss function: 3.854, Average Loss: 4.421, avg. samples / sec: 53444.34
Iteration:   1300, Loss function: 4.793, Average Loss: 4.438, avg. samples / sec: 53408.80
Iteration:   1300, Loss function: 3.872, Average Loss: 4.419, avg. samples / sec: 53446.25
Iteration:   1300, Loss function: 5.173, Average Loss: 4.420, avg. samples / sec: 53457.66
Iteration:   1300, Loss function: 3.480, Average Loss: 4.412, avg. samples / sec: 53428.27
Iteration:   1300, Loss function: 4.672, Average Loss: 4.414, avg. samples / sec: 53418.72
Iteration:   1300, Loss function: 5.294, Average Loss: 4.406, avg. samples / sec: 53395.26
Iteration:   1300, Loss function: 3.824, Average Loss: 4.415, avg. samples / sec: 53386.05
Iteration:   1300, Loss function: 4.779, Average Loss: 4.393, avg. samples / sec: 53399.41
Iteration:   1300, Loss function: 4.136, Average Loss: 4.418, avg. samples / sec: 53336.43
Iteration:   1300, Loss function: 4.707, Average Loss: 4.430, avg. samples / sec: 53619.15
Iteration:   1300, Loss function: 3.629, Average Loss: 4.404, avg. samples / sec: 53415.60
Iteration:   1300, Loss function: 5.784, Average Loss: 4.414, avg. samples / sec: 53627.64
Iteration:   1300, Loss function: 4.326, Average Loss: 4.401, avg. samples / sec: 53590.49
Iteration:   1300, Loss function: 4.695, Average Loss: 4.405, avg. samples / sec: 53355.29
Iteration:   1300, Loss function: 4.878, Average Loss: 4.419, avg. samples / sec: 53350.65
Iteration:   1300, Loss function: 4.706, Average Loss: 4.406, avg. samples / sec: 53339.08
Iteration:   1300, Loss function: 5.436, Average Loss: 4.448, avg. samples / sec: 53499.87
Iteration:   1300, Loss function: 4.446, Average Loss: 4.402, avg. samples / sec: 53297.97
Iteration:   1300, Loss function: 4.432, Average Loss: 4.396, avg. samples / sec: 53380.96
Iteration:   1300, Loss function: 4.293, Average Loss: 4.404, avg. samples / sec: 53363.27
Iteration:   1300, Loss function: 3.998, Average Loss: 4.403, avg. samples / sec: 53440.21
Iteration:   1300, Loss function: 4.015, Average Loss: 4.406, avg. samples / sec: 53382.84
Iteration:   1300, Loss function: 5.271, Average Loss: 4.393, avg. samples / sec: 53369.70
Iteration:   1300, Loss function: 3.504, Average Loss: 4.419, avg. samples / sec: 53316.94
Iteration:   1300, Loss function: 5.699, Average Loss: 4.435, avg. samples / sec: 53401.06
Iteration:   1300, Loss function: 3.927, Average Loss: 4.401, avg. samples / sec: 53414.20
Iteration:   1300, Loss function: 4.443, Average Loss: 4.357, avg. samples / sec: 53394.89
Iteration:   1320, Loss function: 5.233, Average Loss: 4.408, avg. samples / sec: 53634.36
Iteration:   1320, Loss function: 4.260, Average Loss: 4.426, avg. samples / sec: 53222.18
Iteration:   1320, Loss function: 4.414, Average Loss: 4.425, avg. samples / sec: 53289.48
Iteration:   1320, Loss function: 5.532, Average Loss: 4.409, avg. samples / sec: 53300.63
Iteration:   1320, Loss function: 4.222, Average Loss: 4.419, avg. samples / sec: 53272.90
Iteration:   1320, Loss function: 4.995, Average Loss: 4.399, avg. samples / sec: 53294.86
Iteration:   1320, Loss function: 3.421, Average Loss: 4.413, avg. samples / sec: 53359.35
Iteration:   1320, Loss function: 5.367, Average Loss: 4.424, avg. samples / sec: 53342.02
Iteration:   1320, Loss function: 4.197, Average Loss: 4.428, avg. samples / sec: 53234.08
Iteration:   1320, Loss function: 4.267, Average Loss: 4.422, avg. samples / sec: 53280.56
Iteration:   1320, Loss function: 5.401, Average Loss: 4.442, avg. samples / sec: 53234.73
Iteration:   1320, Loss function: 4.555, Average Loss: 4.431, avg. samples / sec: 53294.96
Iteration:   1320, Loss function: 2.956, Average Loss: 4.409, avg. samples / sec: 53298.49
Iteration:   1320, Loss function: 4.173, Average Loss: 4.413, avg. samples / sec: 53245.71
Iteration:   1320, Loss function: 3.763, Average Loss: 4.427, avg. samples / sec: 53244.02
Iteration:   1320, Loss function: 3.633, Average Loss: 4.415, avg. samples / sec: 53257.12
Iteration:   1320, Loss function: 4.789, Average Loss: 4.426, avg. samples / sec: 53193.15
Iteration:   1320, Loss function: 5.372, Average Loss: 4.409, avg. samples / sec: 53292.60
Iteration:   1320, Loss function: 5.038, Average Loss: 4.406, avg. samples / sec: 53295.65
Iteration:   1320, Loss function: 4.116, Average Loss: 4.420, avg. samples / sec: 53322.83
Iteration:   1320, Loss function: 4.632, Average Loss: 4.410, avg. samples / sec: 53313.59
Iteration:   1320, Loss function: 5.514, Average Loss: 4.411, avg. samples / sec: 53150.99
Iteration:   1320, Loss function: 4.282, Average Loss: 4.438, avg. samples / sec: 53300.42
Iteration:   1320, Loss function: 3.505, Average Loss: 4.405, avg. samples / sec: 53258.57
Iteration:   1320, Loss function: 4.533, Average Loss: 4.417, avg. samples / sec: 53094.22
Iteration:   1320, Loss function: 4.765, Average Loss: 4.395, avg. samples / sec: 53272.44
Iteration:   1320, Loss function: 6.335, Average Loss: 4.408, avg. samples / sec: 53277.15
Iteration:   1320, Loss function: 4.003, Average Loss: 4.415, avg. samples / sec: 53232.19
Iteration:   1320, Loss function: 5.722, Average Loss: 4.451, avg. samples / sec: 53147.14
Iteration:   1320, Loss function: 4.382, Average Loss: 4.368, avg. samples / sec: 53251.79
:::MLL 1558641139.610 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558641139.611 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 4.609, Average Loss: 4.408, avg. samples / sec: 52831.25
Iteration:   1340, Loss function: 4.225, Average Loss: 4.432, avg. samples / sec: 52843.43
Iteration:   1340, Loss function: 4.786, Average Loss: 4.431, avg. samples / sec: 52843.45
Iteration:   1340, Loss function: 4.309, Average Loss: 4.428, avg. samples / sec: 52845.67
Iteration:   1340, Loss function: 4.483, Average Loss: 4.412, avg. samples / sec: 52809.55
Iteration:   1340, Loss function: 2.728, Average Loss: 4.415, avg. samples / sec: 52812.16
Iteration:   1340, Loss function: 4.337, Average Loss: 4.439, avg. samples / sec: 52828.41
Iteration:   1340, Loss function: 4.444, Average Loss: 4.427, avg. samples / sec: 52786.38
Iteration:   1340, Loss function: 3.814, Average Loss: 4.412, avg. samples / sec: 52851.69
Iteration:   1340, Loss function: 4.053, Average Loss: 4.446, avg. samples / sec: 52806.68
Iteration:   1340, Loss function: 5.535, Average Loss: 4.413, avg. samples / sec: 52809.78
Iteration:   1340, Loss function: 5.250, Average Loss: 4.406, avg. samples / sec: 52783.08
Iteration:   1340, Loss function: 5.036, Average Loss: 4.433, avg. samples / sec: 52798.15
Iteration:   1340, Loss function: 5.570, Average Loss: 4.423, avg. samples / sec: 52807.13
Iteration:   1340, Loss function: 4.881, Average Loss: 4.433, avg. samples / sec: 52805.31
Iteration:   1340, Loss function: 3.907, Average Loss: 4.417, avg. samples / sec: 52807.11
Iteration:   1340, Loss function: 4.385, Average Loss: 4.432, avg. samples / sec: 52811.23
Iteration:   1340, Loss function: 6.072, Average Loss: 4.425, avg. samples / sec: 52740.40
Iteration:   1340, Loss function: 4.421, Average Loss: 4.404, avg. samples / sec: 52866.70
Iteration:   1340, Loss function: 5.015, Average Loss: 4.412, avg. samples / sec: 52798.29
Iteration:   1340, Loss function: 3.911, Average Loss: 4.443, avg. samples / sec: 52845.91
Iteration:   1340, Loss function: 4.797, Average Loss: 4.413, avg. samples / sec: 52837.09
Iteration:   1340, Loss function: 4.563, Average Loss: 4.421, avg. samples / sec: 52806.30
Iteration:   1340, Loss function: 3.388, Average Loss: 4.410, avg. samples / sec: 52774.21
Iteration:   1340, Loss function: 4.915, Average Loss: 4.424, avg. samples / sec: 52820.04
Iteration:   1340, Loss function: 4.341, Average Loss: 4.427, avg. samples / sec: 52760.42
Iteration:   1340, Loss function: 4.036, Average Loss: 4.454, avg. samples / sec: 52831.36
Iteration:   1340, Loss function: 5.230, Average Loss: 4.371, avg. samples / sec: 52848.82
Iteration:   1340, Loss function: 5.205, Average Loss: 4.418, avg. samples / sec: 52811.53
Iteration:   1340, Loss function: 5.617, Average Loss: 4.418, avg. samples / sec: 52776.64
Iteration:   1360, Loss function: 4.676, Average Loss: 4.438, avg. samples / sec: 52524.80
Iteration:   1360, Loss function: 4.141, Average Loss: 4.432, avg. samples / sec: 52659.66
Iteration:   1360, Loss function: 4.727, Average Loss: 4.410, avg. samples / sec: 52666.98
Iteration:   1360, Loss function: 4.965, Average Loss: 4.416, avg. samples / sec: 52638.63
Iteration:   1360, Loss function: 5.989, Average Loss: 4.430, avg. samples / sec: 52668.39
Iteration:   1360, Loss function: 4.217, Average Loss: 4.439, avg. samples / sec: 52658.22
Iteration:   1360, Loss function: 5.512, Average Loss: 4.434, avg. samples / sec: 52606.80
Iteration:   1360, Loss function: 3.934, Average Loss: 4.447, avg. samples / sec: 52637.53
Iteration:   1360, Loss function: 3.908, Average Loss: 4.417, avg. samples / sec: 52596.65
Iteration:   1360, Loss function: 4.631, Average Loss: 4.442, avg. samples / sec: 52651.49
Iteration:   1360, Loss function: 4.012, Average Loss: 4.426, avg. samples / sec: 52651.37
Iteration:   1360, Loss function: 5.121, Average Loss: 4.421, avg. samples / sec: 52627.56
Iteration:   1360, Loss function: 4.404, Average Loss: 4.421, avg. samples / sec: 52614.24
Iteration:   1360, Loss function: 4.645, Average Loss: 4.411, avg. samples / sec: 52382.71
Iteration:   1360, Loss function: 4.515, Average Loss: 4.442, avg. samples / sec: 52585.79
Iteration:   1360, Loss function: 4.804, Average Loss: 4.416, avg. samples / sec: 52597.31
Iteration:   1360, Loss function: 4.700, Average Loss: 4.436, avg. samples / sec: 52596.12
Iteration:   1360, Loss function: 6.142, Average Loss: 4.432, avg. samples / sec: 52708.50
Iteration:   1360, Loss function: 4.238, Average Loss: 4.409, avg. samples / sec: 52651.67
Iteration:   1360, Loss function: 4.748, Average Loss: 4.434, avg. samples / sec: 52653.97
Iteration:   1360, Loss function: 4.203, Average Loss: 4.435, avg. samples / sec: 52393.89
Iteration:   1360, Loss function: 5.080, Average Loss: 4.423, avg. samples / sec: 52580.60
Iteration:   1360, Loss function: 4.538, Average Loss: 4.415, avg. samples / sec: 52587.07
Iteration:   1360, Loss function: 4.414, Average Loss: 4.406, avg. samples / sec: 52569.96
Iteration:   1360, Loss function: 5.060, Average Loss: 4.458, avg. samples / sec: 52613.87
Iteration:   1360, Loss function: 3.780, Average Loss: 4.421, avg. samples / sec: 52574.30
Iteration:   1360, Loss function: 4.283, Average Loss: 4.443, avg. samples / sec: 52550.17
Iteration:   1360, Loss function: 4.302, Average Loss: 4.376, avg. samples / sec: 52601.48
Iteration:   1360, Loss function: 4.687, Average Loss: 4.429, avg. samples / sec: 52600.89
Iteration:   1360, Loss function: 4.359, Average Loss: 4.424, avg. samples / sec: 52627.72
Iteration:   1380, Loss function: 4.475, Average Loss: 4.443, avg. samples / sec: 53349.27
Iteration:   1380, Loss function: 5.947, Average Loss: 4.425, avg. samples / sec: 53325.37
Iteration:   1380, Loss function: 4.730, Average Loss: 4.454, avg. samples / sec: 53294.14
Iteration:   1380, Loss function: 3.895, Average Loss: 4.439, avg. samples / sec: 53263.88
Iteration:   1380, Loss function: 5.698, Average Loss: 4.437, avg. samples / sec: 53243.34
Iteration:   1380, Loss function: 4.899, Average Loss: 4.442, avg. samples / sec: 53258.87
Iteration:   1380, Loss function: 3.640, Average Loss: 4.449, avg. samples / sec: 53242.63
Iteration:   1380, Loss function: 4.784, Average Loss: 4.448, avg. samples / sec: 53263.10
Iteration:   1380, Loss function: 4.500, Average Loss: 4.427, avg. samples / sec: 53255.99
Iteration:   1380, Loss function: 4.617, Average Loss: 4.425, avg. samples / sec: 53486.17
Iteration:   1380, Loss function: 3.354, Average Loss: 4.440, avg. samples / sec: 53248.08
Iteration:   1380, Loss function: 5.380, Average Loss: 4.429, avg. samples / sec: 53206.77
Iteration:   1380, Loss function: 5.725, Average Loss: 4.425, avg. samples / sec: 53154.03
Iteration:   1380, Loss function: 4.693, Average Loss: 4.460, avg. samples / sec: 53344.00
Iteration:   1380, Loss function: 4.603, Average Loss: 4.427, avg. samples / sec: 53127.52
Iteration:   1380, Loss function: 4.372, Average Loss: 4.420, avg. samples / sec: 53128.82
Iteration:   1380, Loss function: 4.349, Average Loss: 4.426, avg. samples / sec: 53294.98
Iteration:   1380, Loss function: 5.056, Average Loss: 4.433, avg. samples / sec: 53274.33
Iteration:   1380, Loss function: 4.766, Average Loss: 4.447, avg. samples / sec: 53301.94
Iteration:   1380, Loss function: 5.565, Average Loss: 4.417, avg. samples / sec: 53222.00
Iteration:   1380, Loss function: 4.969, Average Loss: 4.426, avg. samples / sec: 53305.06
Iteration:   1380, Loss function: 5.155, Average Loss: 4.411, avg. samples / sec: 52989.91
Iteration:   1380, Loss function: 4.316, Average Loss: 4.433, avg. samples / sec: 53290.73
Iteration:   1380, Loss function: 4.163, Average Loss: 4.436, avg. samples / sec: 53131.13
Iteration:   1380, Loss function: 4.295, Average Loss: 4.382, avg. samples / sec: 53212.64
Iteration:   1380, Loss function: 4.472, Average Loss: 4.415, avg. samples / sec: 53067.69
Iteration:   1380, Loss function: 5.547, Average Loss: 4.437, avg. samples / sec: 53049.87
Iteration:   1380, Loss function: 3.524, Average Loss: 4.441, avg. samples / sec: 52857.24
Iteration:   1380, Loss function: 4.644, Average Loss: 4.423, avg. samples / sec: 52797.38
Iteration:   1380, Loss function: 4.156, Average Loss: 4.439, avg. samples / sec: 52726.72
:::MLL 1558641141.833 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558641141.833 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 4.912, Average Loss: 4.445, avg. samples / sec: 52896.27
Iteration:   1400, Loss function: 3.559, Average Loss: 4.443, avg. samples / sec: 53018.75
Iteration:   1400, Loss function: 3.809, Average Loss: 4.438, avg. samples / sec: 52914.76
Iteration:   1400, Loss function: 3.224, Average Loss: 4.437, avg. samples / sec: 53356.52
Iteration:   1400, Loss function: 5.396, Average Loss: 4.447, avg. samples / sec: 52901.55
Iteration:   1400, Loss function: 4.864, Average Loss: 4.435, avg. samples / sec: 52859.17
Iteration:   1400, Loss function: 3.796, Average Loss: 4.455, avg. samples / sec: 52825.66
Iteration:   1400, Loss function: 4.615, Average Loss: 4.453, avg. samples / sec: 52847.65
Iteration:   1400, Loss function: 5.180, Average Loss: 4.452, avg. samples / sec: 52856.19
Iteration:   1400, Loss function: 4.627, Average Loss: 4.439, avg. samples / sec: 53233.56
Iteration:   1400, Loss function: 4.987, Average Loss: 4.427, avg. samples / sec: 52896.33
Iteration:   1400, Loss function: 4.561, Average Loss: 4.424, avg. samples / sec: 52971.28
Iteration:   1400, Loss function: 4.860, Average Loss: 4.460, avg. samples / sec: 52964.91
Iteration:   1400, Loss function: 5.029, Average Loss: 4.430, avg. samples / sec: 52826.29
Iteration:   1400, Loss function: 4.092, Average Loss: 4.413, avg. samples / sec: 53036.59
Iteration:   1400, Loss function: 4.200, Average Loss: 4.431, avg. samples / sec: 52725.56
Iteration:   1400, Loss function: 4.137, Average Loss: 4.435, avg. samples / sec: 52843.33
Iteration:   1400, Loss function: 3.956, Average Loss: 4.427, avg. samples / sec: 53228.25
Iteration:   1400, Loss function: 3.900, Average Loss: 4.429, avg. samples / sec: 52881.36
Iteration:   1400, Loss function: 6.557, Average Loss: 4.442, avg. samples / sec: 53429.39
Iteration:   1400, Loss function: 4.318, Average Loss: 4.415, avg. samples / sec: 53110.38
Iteration:   1400, Loss function: 2.929, Average Loss: 4.382, avg. samples / sec: 53008.64
Iteration:   1400, Loss function: 4.496, Average Loss: 4.428, avg. samples / sec: 52828.02
Iteration:   1400, Loss function: 3.979, Average Loss: 4.437, avg. samples / sec: 52879.38
Iteration:   1400, Loss function: 5.027, Average Loss: 4.438, avg. samples / sec: 52823.13
Iteration:   1400, Loss function: 4.123, Average Loss: 4.422, avg. samples / sec: 52624.73
Iteration:   1400, Loss function: 5.065, Average Loss: 4.419, avg. samples / sec: 52805.93
Iteration:   1400, Loss function: 4.270, Average Loss: 4.437, avg. samples / sec: 52797.60
Iteration:   1400, Loss function: 4.030, Average Loss: 4.426, avg. samples / sec: 52759.67
Iteration:   1400, Loss function: 4.863, Average Loss: 4.455, avg. samples / sec: 52734.55
Iteration:   1420, Loss function: 4.691, Average Loss: 4.445, avg. samples / sec: 53267.53
Iteration:   1420, Loss function: 5.551, Average Loss: 4.444, avg. samples / sec: 53226.46
Iteration:   1420, Loss function: 4.096, Average Loss: 4.438, avg. samples / sec: 53140.18
Iteration:   1420, Loss function: 4.225, Average Loss: 4.445, avg. samples / sec: 53261.33
Iteration:   1420, Loss function: 4.211, Average Loss: 4.437, avg. samples / sec: 53350.24
Iteration:   1420, Loss function: 5.459, Average Loss: 4.436, avg. samples / sec: 53255.05
Iteration:   1420, Loss function: 3.890, Average Loss: 4.420, avg. samples / sec: 53254.14
Iteration:   1420, Loss function: 4.451, Average Loss: 4.436, avg. samples / sec: 53415.05
Iteration:   1420, Loss function: 4.812, Average Loss: 4.463, avg. samples / sec: 53232.33
Iteration:   1420, Loss function: 5.351, Average Loss: 4.449, avg. samples / sec: 53066.95
Iteration:   1420, Loss function: 3.989, Average Loss: 4.435, avg. samples / sec: 53265.51
Iteration:   1420, Loss function: 3.965, Average Loss: 4.453, avg. samples / sec: 53119.79
Iteration:   1420, Loss function: 3.258, Average Loss: 4.441, avg. samples / sec: 53093.22
Iteration:   1420, Loss function: 4.591, Average Loss: 4.440, avg. samples / sec: 53484.60
Iteration:   1420, Loss function: 4.451, Average Loss: 4.457, avg. samples / sec: 53169.67
Iteration:   1420, Loss function: 3.820, Average Loss: 4.460, avg. samples / sec: 53165.92
Iteration:   1420, Loss function: 4.517, Average Loss: 4.431, avg. samples / sec: 53228.90
Iteration:   1420, Loss function: 4.344, Average Loss: 4.456, avg. samples / sec: 53143.51
Iteration:   1420, Loss function: 4.471, Average Loss: 4.427, avg. samples / sec: 53195.24
Iteration:   1420, Loss function: 4.871, Average Loss: 4.459, avg. samples / sec: 53486.82
Iteration:   1420, Loss function: 4.386, Average Loss: 4.428, avg. samples / sec: 53260.72
Iteration:   1420, Loss function: 4.042, Average Loss: 4.420, avg. samples / sec: 53211.41
Iteration:   1420, Loss function: 5.529, Average Loss: 4.446, avg. samples / sec: 53171.92
Iteration:   1420, Loss function: 4.992, Average Loss: 4.426, avg. samples / sec: 53270.22
Iteration:   1420, Loss function: 3.650, Average Loss: 4.415, avg. samples / sec: 53281.97
Iteration:   1420, Loss function: 4.725, Average Loss: 4.442, avg. samples / sec: 53212.62
Iteration:   1420, Loss function: 3.708, Average Loss: 4.436, avg. samples / sec: 53172.00
Iteration:   1420, Loss function: 4.648, Average Loss: 4.390, avg. samples / sec: 53105.42
Iteration:   1420, Loss function: 4.915, Average Loss: 4.424, avg. samples / sec: 53267.57
Iteration:   1420, Loss function: 5.180, Average Loss: 4.433, avg. samples / sec: 52953.43
Iteration:   1440, Loss function: 3.680, Average Loss: 4.446, avg. samples / sec: 53006.83
Iteration:   1440, Loss function: 5.430, Average Loss: 4.439, avg. samples / sec: 53467.70
Iteration:   1440, Loss function: 4.609, Average Loss: 4.447, avg. samples / sec: 53103.36
Iteration:   1440, Loss function: 4.213, Average Loss: 4.445, avg. samples / sec: 53093.50
Iteration:   1440, Loss function: 4.176, Average Loss: 4.447, avg. samples / sec: 53069.70
Iteration:   1440, Loss function: 5.405, Average Loss: 4.441, avg. samples / sec: 53082.44
Iteration:   1440, Loss function: 5.048, Average Loss: 4.436, avg. samples / sec: 53142.99
Iteration:   1440, Loss function: 4.050, Average Loss: 4.432, avg. samples / sec: 53156.46
Iteration:   1440, Loss function: 4.539, Average Loss: 4.427, avg. samples / sec: 53083.14
Iteration:   1440, Loss function: 3.894, Average Loss: 4.438, avg. samples / sec: 53059.29
Iteration:   1440, Loss function: 3.898, Average Loss: 4.456, avg. samples / sec: 53121.49
Iteration:   1440, Loss function: 4.596, Average Loss: 4.439, avg. samples / sec: 53084.48
Iteration:   1440, Loss function: 4.206, Average Loss: 4.440, avg. samples / sec: 53106.18
Iteration:   1440, Loss function: 4.670, Average Loss: 4.459, avg. samples / sec: 53079.04
Iteration:   1440, Loss function: 4.195, Average Loss: 4.436, avg. samples / sec: 53064.09
Iteration:   1440, Loss function: 5.545, Average Loss: 4.428, avg. samples / sec: 53111.78
Iteration:   1440, Loss function: 4.139, Average Loss: 4.464, avg. samples / sec: 53091.88
Iteration:   1440, Loss function: 5.646, Average Loss: 4.454, avg. samples / sec: 53055.64
Iteration:   1440, Loss function: 3.621, Average Loss: 4.462, avg. samples / sec: 53044.73
Iteration:   1440, Loss function: 5.626, Average Loss: 4.463, avg. samples / sec: 53025.97
Iteration:   1440, Loss function: 3.582, Average Loss: 4.440, avg. samples / sec: 53154.65
Iteration:   1440, Loss function: 5.121, Average Loss: 4.449, avg. samples / sec: 53092.38
Iteration:   1440, Loss function: 5.108, Average Loss: 4.419, avg. samples / sec: 53059.25
Iteration:   1440, Loss function: 4.108, Average Loss: 4.443, avg. samples / sec: 52936.96
Iteration:   1440, Loss function: 3.126, Average Loss: 4.412, avg. samples / sec: 53087.54
Iteration:   1440, Loss function: 4.083, Average Loss: 4.458, avg. samples / sec: 52932.86
Iteration:   1440, Loss function: 4.471, Average Loss: 4.433, avg. samples / sec: 53066.85
Iteration:   1440, Loss function: 3.254, Average Loss: 4.400, avg. samples / sec: 53104.62
Iteration:   1440, Loss function: 4.941, Average Loss: 4.423, avg. samples / sec: 53094.22
Iteration:   1440, Loss function: 6.000, Average Loss: 4.444, avg. samples / sec: 53078.96
Iteration:   1460, Loss function: 4.775, Average Loss: 4.443, avg. samples / sec: 53213.08
Iteration:   1460, Loss function: 4.015, Average Loss: 4.450, avg. samples / sec: 53193.15
Iteration:   1460, Loss function: 4.674, Average Loss: 4.444, avg. samples / sec: 53205.38
Iteration:   1460, Loss function: 3.510, Average Loss: 4.440, avg. samples / sec: 53417.91
Iteration:   1460, Loss function: 4.514, Average Loss: 4.433, avg. samples / sec: 53205.91
Iteration:   1460, Loss function: 4.346, Average Loss: 4.461, avg. samples / sec: 53277.70
Iteration:   1460, Loss function: 4.061, Average Loss: 4.446, avg. samples / sec: 53169.73
Iteration:   1460, Loss function: 4.550, Average Loss: 4.461, avg. samples / sec: 53246.98
Iteration:   1460, Loss function: 3.886, Average Loss: 4.454, avg. samples / sec: 53212.03
Iteration:   1460, Loss function: 4.847, Average Loss: 4.441, avg. samples / sec: 53032.26
Iteration:   1460, Loss function: 5.080, Average Loss: 4.438, avg. samples / sec: 53206.73
Iteration:   1460, Loss function: 4.612, Average Loss: 4.443, avg. samples / sec: 53101.14
Iteration:   1460, Loss function: 5.260, Average Loss: 4.444, avg. samples / sec: 53185.97
Iteration:   1460, Loss function: 3.589, Average Loss: 4.451, avg. samples / sec: 53229.32
Iteration:   1460, Loss function: 4.688, Average Loss: 4.428, avg. samples / sec: 53180.65
Iteration:   1460, Loss function: 3.940, Average Loss: 4.433, avg. samples / sec: 53161.31
Iteration:   1460, Loss function: 4.474, Average Loss: 4.461, avg. samples / sec: 53193.21
Iteration:   1460, Loss function: 3.289, Average Loss: 4.435, avg. samples / sec: 53190.46
Iteration:   1460, Loss function: 4.098, Average Loss: 4.439, avg. samples / sec: 53188.32
Iteration:   1460, Loss function: 3.335, Average Loss: 4.426, avg. samples / sec: 53308.43
Iteration:   1460, Loss function: 5.094, Average Loss: 4.446, avg. samples / sec: 53136.36
Iteration:   1460, Loss function: 4.247, Average Loss: 4.461, avg. samples / sec: 53203.98
Iteration:   1460, Loss function: 3.888, Average Loss: 4.437, avg. samples / sec: 53172.78
Iteration:   1460, Loss function: 3.257, Average Loss: 4.450, avg. samples / sec: 53175.29
Iteration:   1460, Loss function: 3.995, Average Loss: 4.416, avg. samples / sec: 53194.06
Iteration:   1460, Loss function: 3.439, Average Loss: 4.447, avg. samples / sec: 53245.93
Iteration:   1460, Loss function: 5.518, Average Loss: 4.465, avg. samples / sec: 53187.37
Iteration:   1460, Loss function: 4.218, Average Loss: 4.437, avg. samples / sec: 53167.51
Iteration:   1460, Loss function: 4.266, Average Loss: 4.403, avg. samples / sec: 53176.62
Iteration:   1460, Loss function: 4.294, Average Loss: 4.421, avg. samples / sec: 53189.30
:::MLL 1558641144.048 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558641144.048 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 3.394, Average Loss: 4.435, avg. samples / sec: 53007.44
Iteration:   1480, Loss function: 5.943, Average Loss: 4.451, avg. samples / sec: 52904.45
Iteration:   1480, Loss function: 4.730, Average Loss: 4.442, avg. samples / sec: 52841.07
Iteration:   1480, Loss function: 4.439, Average Loss: 4.441, avg. samples / sec: 52850.50
Iteration:   1480, Loss function: 3.819, Average Loss: 4.449, avg. samples / sec: 52929.13
Iteration:   1480, Loss function: 3.912, Average Loss: 4.434, avg. samples / sec: 52872.63
Iteration:   1480, Loss function: 5.002, Average Loss: 4.452, avg. samples / sec: 52803.47
Iteration:   1480, Loss function: 4.017, Average Loss: 4.459, avg. samples / sec: 52841.15
Iteration:   1480, Loss function: 3.383, Average Loss: 4.441, avg. samples / sec: 52776.62
Iteration:   1480, Loss function: 5.211, Average Loss: 4.446, avg. samples / sec: 52851.53
Iteration:   1480, Loss function: 4.549, Average Loss: 4.432, avg. samples / sec: 52850.70
Iteration:   1480, Loss function: 5.325, Average Loss: 4.463, avg. samples / sec: 52852.72
Iteration:   1480, Loss function: 4.208, Average Loss: 4.456, avg. samples / sec: 52917.00
Iteration:   1480, Loss function: 5.437, Average Loss: 4.468, avg. samples / sec: 52813.43
Iteration:   1480, Loss function: 4.071, Average Loss: 4.460, avg. samples / sec: 52799.24
Iteration:   1480, Loss function: 4.311, Average Loss: 4.435, avg. samples / sec: 52790.87
Iteration:   1480, Loss function: 3.620, Average Loss: 4.450, avg. samples / sec: 52832.83
Iteration:   1480, Loss function: 4.268, Average Loss: 4.445, avg. samples / sec: 52769.78
Iteration:   1480, Loss function: 5.012, Average Loss: 4.440, avg. samples / sec: 52816.51
Iteration:   1480, Loss function: 4.401, Average Loss: 4.428, avg. samples / sec: 52804.90
Iteration:   1480, Loss function: 3.808, Average Loss: 4.426, avg. samples / sec: 52830.27
Iteration:   1480, Loss function: 5.300, Average Loss: 4.441, avg. samples / sec: 52843.45
Iteration:   1480, Loss function: 3.888, Average Loss: 4.453, avg. samples / sec: 52850.62
Iteration:   1480, Loss function: 4.553, Average Loss: 4.435, avg. samples / sec: 52886.96
Iteration:   1480, Loss function: 4.595, Average Loss: 4.420, avg. samples / sec: 52826.71
Iteration:   1480, Loss function: 4.902, Average Loss: 4.466, avg. samples / sec: 52838.85
Iteration:   1480, Loss function: 4.510, Average Loss: 4.449, avg. samples / sec: 52806.62
Iteration:   1480, Loss function: 3.563, Average Loss: 4.424, avg. samples / sec: 52850.90
Iteration:   1480, Loss function: 3.697, Average Loss: 4.435, avg. samples / sec: 52543.50
Iteration:   1480, Loss function: 3.427, Average Loss: 4.398, avg. samples / sec: 52817.42
Iteration:   1500, Loss function: 5.092, Average Loss: 4.441, avg. samples / sec: 53658.76
Iteration:   1500, Loss function: 8.740, Average Loss: 4.454, avg. samples / sec: 53437.25
Iteration:   1500, Loss function: 4.406, Average Loss: 4.454, avg. samples / sec: 53474.07
Iteration:   1500, Loss function: 4.301, Average Loss: 4.442, avg. samples / sec: 53449.00
Iteration:   1500, Loss function: 5.906, Average Loss: 4.446, avg. samples / sec: 53461.43
Iteration:   1500, Loss function: 4.420, Average Loss: 4.468, avg. samples / sec: 53462.02
Iteration:   1500, Loss function: 4.591, Average Loss: 4.449, avg. samples / sec: 53493.15
Iteration:   1500, Loss function: 3.984, Average Loss: 4.446, avg. samples / sec: 53427.36
Iteration:   1500, Loss function: 5.459, Average Loss: 4.459, avg. samples / sec: 53453.24
Iteration:   1500, Loss function: 3.519, Average Loss: 4.465, avg. samples / sec: 53425.46
Iteration:   1500, Loss function: 5.115, Average Loss: 4.466, avg. samples / sec: 53434.98
Iteration:   1500, Loss function: 4.744, Average Loss: 4.440, avg. samples / sec: 53412.28
Iteration:   1500, Loss function: 4.936, Average Loss: 4.455, avg. samples / sec: 53441.20
Iteration:   1500, Loss function: 4.586, Average Loss: 4.436, avg. samples / sec: 53425.26
Iteration:   1500, Loss function: 4.754, Average Loss: 4.433, avg. samples / sec: 53453.71
Iteration:   1500, Loss function: 4.861, Average Loss: 4.437, avg. samples / sec: 53237.20
Iteration:   1500, Loss function: 4.328, Average Loss: 4.450, avg. samples / sec: 53402.18
Iteration:   1500, Loss function: 4.587, Average Loss: 4.457, avg. samples / sec: 53374.73
Iteration:   1500, Loss function: 4.675, Average Loss: 4.450, avg. samples / sec: 53354.04
Iteration:   1500, Loss function: 4.890, Average Loss: 4.425, avg. samples / sec: 53321.50
Iteration:   1500, Loss function: 4.677, Average Loss: 4.440, avg. samples / sec: 53407.26
Iteration:   1500, Loss function: 4.543, Average Loss: 4.450, avg. samples / sec: 53405.96
Iteration:   1500, Loss function: 5.105, Average Loss: 4.469, avg. samples / sec: 53429.85
Iteration:   1500, Loss function: 4.501, Average Loss: 4.438, avg. samples / sec: 53474.19
Iteration:   1500, Loss function: 4.778, Average Loss: 4.419, avg. samples / sec: 53408.27
Iteration:   1500, Loss function: 5.137, Average Loss: 4.443, avg. samples / sec: 53167.09
Iteration:   1500, Loss function: 4.475, Average Loss: 4.424, avg. samples / sec: 53413.92
Iteration:   1500, Loss function: 4.271, Average Loss: 4.403, avg. samples / sec: 53428.80
Iteration:   1500, Loss function: 4.008, Average Loss: 4.444, avg. samples / sec: 53339.36
Iteration:   1500, Loss function: 4.254, Average Loss: 4.454, avg. samples / sec: 53381.48
Iteration:   1520, Loss function: 2.994, Average Loss: 4.438, avg. samples / sec: 53547.97
Iteration:   1520, Loss function: 5.141, Average Loss: 4.455, avg. samples / sec: 53646.97
Iteration:   1520, Loss function: 4.466, Average Loss: 4.450, avg. samples / sec: 53758.34
Iteration:   1520, Loss function: 4.379, Average Loss: 4.439, avg. samples / sec: 53690.77
Iteration:   1520, Loss function: 4.794, Average Loss: 4.465, avg. samples / sec: 53687.68
Iteration:   1520, Loss function: 4.104, Average Loss: 4.447, avg. samples / sec: 53765.21
Iteration:   1520, Loss function: 3.354, Average Loss: 4.457, avg. samples / sec: 53667.16
Iteration:   1520, Loss function: 4.277, Average Loss: 4.448, avg. samples / sec: 53637.54
Iteration:   1520, Loss function: 4.909, Average Loss: 4.450, avg. samples / sec: 53657.06
Iteration:   1520, Loss function: 5.986, Average Loss: 4.440, avg. samples / sec: 53680.71
Iteration:   1520, Loss function: 5.098, Average Loss: 4.444, avg. samples / sec: 53915.40
Iteration:   1520, Loss function: 5.051, Average Loss: 4.446, avg. samples / sec: 53631.91
Iteration:   1520, Loss function: 4.407, Average Loss: 4.442, avg. samples / sec: 53695.95
Iteration:   1520, Loss function: 3.169, Average Loss: 4.458, avg. samples / sec: 53663.34
Iteration:   1520, Loss function: 3.242, Average Loss: 4.453, avg. samples / sec: 53711.58
Iteration:   1520, Loss function: 4.838, Average Loss: 4.467, avg. samples / sec: 53623.76
Iteration:   1520, Loss function: 4.771, Average Loss: 4.466, avg. samples / sec: 53605.53
Iteration:   1520, Loss function: 4.521, Average Loss: 4.452, avg. samples / sec: 53600.29
Iteration:   1520, Loss function: 4.311, Average Loss: 4.459, avg. samples / sec: 53460.97
Iteration:   1520, Loss function: 5.476, Average Loss: 4.432, avg. samples / sec: 53692.43
Iteration:   1520, Loss function: 5.307, Average Loss: 4.442, avg. samples / sec: 53699.45
Iteration:   1520, Loss function: 5.891, Average Loss: 4.447, avg. samples / sec: 53764.78
Iteration:   1520, Loss function: 5.831, Average Loss: 4.424, avg. samples / sec: 53706.47
Iteration:   1520, Loss function: 3.951, Average Loss: 4.438, avg. samples / sec: 53687.66
Iteration:   1520, Loss function: 2.915, Average Loss: 4.453, avg. samples / sec: 53752.62
Iteration:   1520, Loss function: 3.488, Average Loss: 4.424, avg. samples / sec: 53720.86
Iteration:   1520, Loss function: 4.400, Average Loss: 4.454, avg. samples / sec: 53655.63
Iteration:   1520, Loss function: 5.264, Average Loss: 4.462, avg. samples / sec: 53648.53
Iteration:   1520, Loss function: 3.696, Average Loss: 4.400, avg. samples / sec: 53698.49
Iteration:   1520, Loss function: 5.321, Average Loss: 4.436, avg. samples / sec: 53400.84
:::MLL 1558641146.257 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558641146.258 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.364, Average Loss: 4.454, avg. samples / sec: 52865.93
Iteration:   1540, Loss function: 4.114, Average Loss: 4.441, avg. samples / sec: 52897.34
Iteration:   1540, Loss function: 4.009, Average Loss: 4.451, avg. samples / sec: 52819.38
Iteration:   1540, Loss function: 5.737, Average Loss: 4.453, avg. samples / sec: 52800.29
Iteration:   1540, Loss function: 5.946, Average Loss: 4.464, avg. samples / sec: 52787.04
Iteration:   1540, Loss function: 5.355, Average Loss: 4.451, avg. samples / sec: 52797.08
Iteration:   1540, Loss function: 4.756, Average Loss: 4.435, avg. samples / sec: 52947.34
Iteration:   1540, Loss function: 4.286, Average Loss: 4.450, avg. samples / sec: 52744.48
Iteration:   1540, Loss function: 4.714, Average Loss: 4.453, avg. samples / sec: 52766.21
Iteration:   1540, Loss function: 4.733, Average Loss: 4.454, avg. samples / sec: 52789.94
Iteration:   1540, Loss function: 4.666, Average Loss: 4.439, avg. samples / sec: 52713.13
Iteration:   1540, Loss function: 4.261, Average Loss: 4.466, avg. samples / sec: 52769.78
Iteration:   1540, Loss function: 4.126, Average Loss: 4.439, avg. samples / sec: 52627.21
Iteration:   1540, Loss function: 4.717, Average Loss: 4.449, avg. samples / sec: 52712.42
Iteration:   1540, Loss function: 4.639, Average Loss: 4.453, avg. samples / sec: 52716.70
Iteration:   1540, Loss function: 4.398, Average Loss: 4.442, avg. samples / sec: 52685.76
Iteration:   1540, Loss function: 4.242, Average Loss: 4.459, avg. samples / sec: 52819.05
Iteration:   1540, Loss function: 4.084, Average Loss: 4.459, avg. samples / sec: 52663.57
Iteration:   1540, Loss function: 4.292, Average Loss: 4.465, avg. samples / sec: 52702.59
Iteration:   1540, Loss function: 3.542, Average Loss: 4.441, avg. samples / sec: 52651.79
Iteration:   1540, Loss function: 4.767, Average Loss: 4.455, avg. samples / sec: 52870.93
Iteration:   1540, Loss function: 4.736, Average Loss: 4.430, avg. samples / sec: 52787.23
Iteration:   1540, Loss function: 4.374, Average Loss: 4.451, avg. samples / sec: 52797.62
Iteration:   1540, Loss function: 4.359, Average Loss: 4.422, avg. samples / sec: 52798.92
Iteration:   1540, Loss function: 5.191, Average Loss: 4.404, avg. samples / sec: 52821.92
Iteration:   1540, Loss function: 4.395, Average Loss: 4.419, avg. samples / sec: 52743.10
Iteration:   1540, Loss function: 4.235, Average Loss: 4.463, avg. samples / sec: 52773.69
Iteration:   1540, Loss function: 3.447, Average Loss: 4.450, avg. samples / sec: 52716.15
Iteration:   1540, Loss function: 4.592, Average Loss: 4.434, avg. samples / sec: 52713.23
Iteration:   1540, Loss function: 3.692, Average Loss: 4.434, avg. samples / sec: 52780.32
Iteration:   1560, Loss function: 4.474, Average Loss: 4.443, avg. samples / sec: 52719.36
Iteration:   1560, Loss function: 4.486, Average Loss: 4.455, avg. samples / sec: 52625.36
Iteration:   1560, Loss function: 5.460, Average Loss: 4.456, avg. samples / sec: 52647.50
Iteration:   1560, Loss function: 3.476, Average Loss: 4.459, avg. samples / sec: 52730.59
Iteration:   1560, Loss function: 3.293, Average Loss: 4.436, avg. samples / sec: 52675.80
Iteration:   1560, Loss function: 5.130, Average Loss: 4.456, avg. samples / sec: 52600.73
Iteration:   1560, Loss function: 4.206, Average Loss: 4.445, avg. samples / sec: 52507.25
Iteration:   1560, Loss function: 4.508, Average Loss: 4.467, avg. samples / sec: 52721.73
Iteration:   1560, Loss function: 5.221, Average Loss: 4.455, avg. samples / sec: 52655.11
Iteration:   1560, Loss function: 3.792, Average Loss: 4.453, avg. samples / sec: 52495.47
Iteration:   1560, Loss function: 4.778, Average Loss: 4.464, avg. samples / sec: 52602.30
Iteration:   1560, Loss function: 5.529, Average Loss: 4.466, avg. samples / sec: 52650.92
Iteration:   1560, Loss function: 4.799, Average Loss: 4.465, avg. samples / sec: 52719.23
Iteration:   1560, Loss function: 4.389, Average Loss: 4.458, avg. samples / sec: 52625.46
Iteration:   1560, Loss function: 4.321, Average Loss: 4.449, avg. samples / sec: 52656.96
Iteration:   1560, Loss function: 5.209, Average Loss: 4.450, avg. samples / sec: 52520.59
Iteration:   1560, Loss function: 4.512, Average Loss: 4.452, avg. samples / sec: 52633.30
Iteration:   1560, Loss function: 3.660, Average Loss: 4.438, avg. samples / sec: 52668.08
Iteration:   1560, Loss function: 3.121, Average Loss: 4.449, avg. samples / sec: 52698.47
Iteration:   1560, Loss function: 4.959, Average Loss: 4.438, avg. samples / sec: 52559.83
Iteration:   1560, Loss function: 3.628, Average Loss: 4.454, avg. samples / sec: 52557.32
Iteration:   1560, Loss function: 3.555, Average Loss: 4.436, avg. samples / sec: 52405.97
Iteration:   1560, Loss function: 4.542, Average Loss: 4.450, avg. samples / sec: 52681.72
Iteration:   1560, Loss function: 3.395, Average Loss: 4.436, avg. samples / sec: 52672.80
Iteration:   1560, Loss function: 5.989, Average Loss: 4.421, avg. samples / sec: 52638.59
Iteration:   1560, Loss function: 4.857, Average Loss: 4.466, avg. samples / sec: 52622.14
Iteration:   1560, Loss function: 4.971, Average Loss: 4.409, avg. samples / sec: 52561.69
Iteration:   1560, Loss function: 5.090, Average Loss: 4.432, avg. samples / sec: 52495.42
Iteration:   1560, Loss function: 5.214, Average Loss: 4.438, avg. samples / sec: 52627.41
Iteration:   1560, Loss function: 4.529, Average Loss: 4.424, avg. samples / sec: 52168.58
Iteration:   1580, Loss function: 4.526, Average Loss: 4.440, avg. samples / sec: 53225.28
Iteration:   1580, Loss function: 5.068, Average Loss: 4.454, avg. samples / sec: 53219.31
Iteration:   1580, Loss function: 3.981, Average Loss: 4.458, avg. samples / sec: 53202.47
Iteration:   1580, Loss function: 3.805, Average Loss: 4.470, avg. samples / sec: 53214.83
Iteration:   1580, Loss function: 5.010, Average Loss: 4.446, avg. samples / sec: 53192.61
Iteration:   1580, Loss function: 5.055, Average Loss: 4.451, avg. samples / sec: 53189.66
Iteration:   1580, Loss function: 5.829, Average Loss: 4.470, avg. samples / sec: 53206.11
Iteration:   1580, Loss function: 5.322, Average Loss: 4.459, avg. samples / sec: 53229.22
Iteration:   1580, Loss function: 5.336, Average Loss: 4.467, avg. samples / sec: 53213.86
Iteration:   1580, Loss function: 5.222, Average Loss: 4.435, avg. samples / sec: 53407.60
Iteration:   1580, Loss function: 4.276, Average Loss: 4.460, avg. samples / sec: 53206.87
Iteration:   1580, Loss function: 5.264, Average Loss: 4.441, avg. samples / sec: 53314.38
Iteration:   1580, Loss function: 4.161, Average Loss: 4.451, avg. samples / sec: 53218.18
Iteration:   1580, Loss function: 3.467, Average Loss: 4.449, avg. samples / sec: 53230.28
Iteration:   1580, Loss function: 3.275, Average Loss: 4.457, avg. samples / sec: 53148.50
Iteration:   1580, Loss function: 4.117, Average Loss: 4.449, avg. samples / sec: 53226.61
Iteration:   1580, Loss function: 4.353, Average Loss: 4.458, avg. samples / sec: 53154.17
Iteration:   1580, Loss function: 3.388, Average Loss: 4.442, avg. samples / sec: 53155.58
Iteration:   1580, Loss function: 4.337, Average Loss: 4.453, avg. samples / sec: 53112.36
Iteration:   1580, Loss function: 4.606, Average Loss: 4.437, avg. samples / sec: 53184.26
Iteration:   1580, Loss function: 4.227, Average Loss: 4.429, avg. samples / sec: 53265.09
Iteration:   1580, Loss function: 4.253, Average Loss: 4.457, avg. samples / sec: 53086.38
Iteration:   1580, Loss function: 3.442, Average Loss: 4.438, avg. samples / sec: 53191.61
Iteration:   1580, Loss function: 5.115, Average Loss: 4.429, avg. samples / sec: 53189.10
Iteration:   1580, Loss function: 3.546, Average Loss: 4.437, avg. samples / sec: 53246.94
Iteration:   1580, Loss function: 4.094, Average Loss: 4.463, avg. samples / sec: 53195.34
Iteration:   1580, Loss function: 4.278, Average Loss: 4.450, avg. samples / sec: 53165.74
Iteration:   1580, Loss function: 4.198, Average Loss: 4.457, avg. samples / sec: 53136.82
Iteration:   1580, Loss function: 4.627, Average Loss: 4.421, avg. samples / sec: 53596.62
Iteration:   1580, Loss function: 5.379, Average Loss: 4.403, avg. samples / sec: 53183.74
Iteration:   1600, Loss function: 3.524, Average Loss: 4.449, avg. samples / sec: 53224.78
Iteration:   1600, Loss function: 3.893, Average Loss: 4.439, avg. samples / sec: 53276.51
Iteration:   1600, Loss function: 4.240, Average Loss: 4.452, avg. samples / sec: 53148.88
Iteration:   1600, Loss function: 4.006, Average Loss: 4.469, avg. samples / sec: 53155.38
Iteration:   1600, Loss function: 4.245, Average Loss: 4.448, avg. samples / sec: 53136.20
Iteration:   1600, Loss function: 4.519, Average Loss: 4.441, avg. samples / sec: 53148.50
Iteration:   1600, Loss function: 3.886, Average Loss: 4.462, avg. samples / sec: 53147.46
Iteration:   1600, Loss function: 5.048, Average Loss: 4.449, avg. samples / sec: 53131.13
Iteration:   1600, Loss function: 4.982, Average Loss: 4.462, avg. samples / sec: 53111.00
Iteration:   1600, Loss function: 4.917, Average Loss: 4.455, avg. samples / sec: 53159.79
Iteration:   1600, Loss function: 4.015, Average Loss: 4.452, avg. samples / sec: 53139.98
Iteration:   1600, Loss function: 4.095, Average Loss: 4.448, avg. samples / sec: 53150.12
Iteration:   1600, Loss function: 3.277, Average Loss: 4.464, avg. samples / sec: 53102.80
Iteration:   1600, Loss function: 3.943, Average Loss: 4.437, avg. samples / sec: 53067.09
Iteration:   1600, Loss function: 5.293, Average Loss: 4.462, avg. samples / sec: 53103.70
Iteration:   1600, Loss function: 3.826, Average Loss: 4.473, avg. samples / sec: 53103.30
Iteration:   1600, Loss function: 3.607, Average Loss: 4.457, avg. samples / sec: 53117.33
Iteration:   1600, Loss function: 5.070, Average Loss: 4.454, avg. samples / sec: 53158.28
Iteration:   1600, Loss function: 4.162, Average Loss: 4.439, avg. samples / sec: 53105.56
Iteration:   1600, Loss function: 3.703, Average Loss: 4.430, avg. samples / sec: 53180.55
Iteration:   1600, Loss function: 4.657, Average Loss: 4.425, avg. samples / sec: 53234.00
Iteration:   1600, Loss function: 3.434, Average Loss: 4.440, avg. samples / sec: 52936.58
Iteration:   1600, Loss function: 4.480, Average Loss: 4.450, avg. samples / sec: 53179.04
Iteration:   1600, Loss function: 3.862, Average Loss: 4.429, avg. samples / sec: 53153.75
Iteration:   1600, Loss function: 4.152, Average Loss: 4.435, avg. samples / sec: 53138.88
Iteration:   1600, Loss function: 5.749, Average Loss: 4.459, avg. samples / sec: 53113.25
Iteration:   1600, Loss function: 4.496, Average Loss: 4.458, avg. samples / sec: 53141.57
Iteration:   1600, Loss function: 4.418, Average Loss: 4.407, avg. samples / sec: 53163.64
Iteration:   1600, Loss function: 5.272, Average Loss: 4.432, avg. samples / sec: 53102.08
Iteration:   1600, Loss function: 4.295, Average Loss: 4.470, avg. samples / sec: 53100.10
:::MLL 1558641148.478 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558641148.479 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 4.160, Average Loss: 4.447, avg. samples / sec: 52854.63
Iteration:   1620, Loss function: 4.724, Average Loss: 4.451, avg. samples / sec: 52888.11
Iteration:   1620, Loss function: 4.506, Average Loss: 4.450, avg. samples / sec: 52775.26
Iteration:   1620, Loss function: 4.779, Average Loss: 4.431, avg. samples / sec: 53079.88
Iteration:   1620, Loss function: 4.331, Average Loss: 4.442, avg. samples / sec: 52802.35
Iteration:   1620, Loss function: 5.829, Average Loss: 4.437, avg. samples / sec: 52835.09
Iteration:   1620, Loss function: 4.654, Average Loss: 4.453, avg. samples / sec: 52813.72
Iteration:   1620, Loss function: 3.396, Average Loss: 4.445, avg. samples / sec: 52792.99
Iteration:   1620, Loss function: 4.311, Average Loss: 4.446, avg. samples / sec: 52806.96
Iteration:   1620, Loss function: 3.970, Average Loss: 4.456, avg. samples / sec: 52795.66
Iteration:   1620, Loss function: 3.905, Average Loss: 4.471, avg. samples / sec: 52821.17
Iteration:   1620, Loss function: 5.174, Average Loss: 4.464, avg. samples / sec: 52782.51
Iteration:   1620, Loss function: 4.959, Average Loss: 4.460, avg. samples / sec: 52789.25
Iteration:   1620, Loss function: 4.188, Average Loss: 4.462, avg. samples / sec: 52756.86
Iteration:   1620, Loss function: 5.078, Average Loss: 4.451, avg. samples / sec: 52760.48
Iteration:   1620, Loss function: 3.925, Average Loss: 4.456, avg. samples / sec: 52804.28
Iteration:   1620, Loss function: 4.495, Average Loss: 4.465, avg. samples / sec: 52783.97
Iteration:   1620, Loss function: 4.591, Average Loss: 4.442, avg. samples / sec: 52716.45
Iteration:   1620, Loss function: 3.932, Average Loss: 4.452, avg. samples / sec: 52822.93
Iteration:   1620, Loss function: 5.628, Average Loss: 4.436, avg. samples / sec: 52804.05
Iteration:   1620, Loss function: 3.771, Average Loss: 4.439, avg. samples / sec: 52818.30
Iteration:   1620, Loss function: 4.223, Average Loss: 4.432, avg. samples / sec: 52758.34
Iteration:   1620, Loss function: 5.504, Average Loss: 4.468, avg. samples / sec: 52869.20
Iteration:   1620, Loss function: 3.401, Average Loss: 4.467, avg. samples / sec: 52819.34
Iteration:   1620, Loss function: 3.733, Average Loss: 4.456, avg. samples / sec: 52815.11
Iteration:   1620, Loss function: 5.597, Average Loss: 4.431, avg. samples / sec: 52778.93
Iteration:   1620, Loss function: 3.873, Average Loss: 4.447, avg. samples / sec: 52745.29
Iteration:   1620, Loss function: 4.161, Average Loss: 4.435, avg. samples / sec: 52758.86
Iteration:   1620, Loss function: 3.671, Average Loss: 4.429, avg. samples / sec: 52677.80
Iteration:   1620, Loss function: 4.327, Average Loss: 4.407, avg. samples / sec: 52756.98
Iteration:   1640, Loss function: 4.409, Average Loss: 4.448, avg. samples / sec: 53144.57
Iteration:   1640, Loss function: 4.374, Average Loss: 4.445, avg. samples / sec: 53173.45
Iteration:   1640, Loss function: 4.676, Average Loss: 4.442, avg. samples / sec: 53124.28
Iteration:   1640, Loss function: 5.860, Average Loss: 4.455, avg. samples / sec: 53143.71
Iteration:   1640, Loss function: 4.423, Average Loss: 4.452, avg. samples / sec: 53115.93
Iteration:   1640, Loss function: 4.021, Average Loss: 4.443, avg. samples / sec: 53109.22
Iteration:   1640, Loss function: 3.841, Average Loss: 4.459, avg. samples / sec: 53117.21
Iteration:   1640, Loss function: 4.989, Average Loss: 4.464, avg. samples / sec: 53097.94
Iteration:   1640, Loss function: 4.577, Average Loss: 4.459, avg. samples / sec: 53106.08
Iteration:   1640, Loss function: 3.807, Average Loss: 4.446, avg. samples / sec: 52978.83
Iteration:   1640, Loss function: 6.944, Average Loss: 4.470, avg. samples / sec: 53088.02
Iteration:   1640, Loss function: 3.492, Average Loss: 4.457, avg. samples / sec: 53067.55
Iteration:   1640, Loss function: 5.755, Average Loss: 4.435, avg. samples / sec: 53056.58
Iteration:   1640, Loss function: 4.819, Average Loss: 4.435, avg. samples / sec: 53120.71
Iteration:   1640, Loss function: 3.270, Average Loss: 4.452, avg. samples / sec: 53026.41
Iteration:   1640, Loss function: 4.309, Average Loss: 4.453, avg. samples / sec: 53070.90
Iteration:   1640, Loss function: 4.708, Average Loss: 4.452, avg. samples / sec: 53019.91
Iteration:   1640, Loss function: 4.715, Average Loss: 4.448, avg. samples / sec: 53031.82
Iteration:   1640, Loss function: 3.839, Average Loss: 4.458, avg. samples / sec: 53111.42
Iteration:   1640, Loss function: 5.366, Average Loss: 4.444, avg. samples / sec: 53058.41
Iteration:   1640, Loss function: 3.125, Average Loss: 4.432, avg. samples / sec: 53078.78
Iteration:   1640, Loss function: 4.607, Average Loss: 4.431, avg. samples / sec: 53098.96
Iteration:   1640, Loss function: 3.909, Average Loss: 4.447, avg. samples / sec: 53125.84
Iteration:   1640, Loss function: 3.473, Average Loss: 4.468, avg. samples / sec: 53064.07
Iteration:   1640, Loss function: 4.953, Average Loss: 4.458, avg. samples / sec: 52885.79
Iteration:   1640, Loss function: 5.396, Average Loss: 4.436, avg. samples / sec: 53100.24
Iteration:   1640, Loss function: 3.775, Average Loss: 4.430, avg. samples / sec: 52819.50
Iteration:   1640, Loss function: 3.830, Average Loss: 4.431, avg. samples / sec: 53119.31
Iteration:   1640, Loss function: 5.725, Average Loss: 4.465, avg. samples / sec: 53034.63
Iteration:   1640, Loss function: 7.250, Average Loss: 4.415, avg. samples / sec: 53109.68
Iteration:   1660, Loss function: 4.572, Average Loss: 4.449, avg. samples / sec: 53238.69
Iteration:   1660, Loss function: 4.912, Average Loss: 4.456, avg. samples / sec: 53208.28
Iteration:   1660, Loss function: 3.632, Average Loss: 4.458, avg. samples / sec: 53177.18
Iteration:   1660, Loss function: 5.000, Average Loss: 4.435, avg. samples / sec: 53146.82
Iteration:   1660, Loss function: 4.362, Average Loss: 4.453, avg. samples / sec: 53087.56
Iteration:   1660, Loss function: 4.066, Average Loss: 4.461, avg. samples / sec: 53129.89
Iteration:   1660, Loss function: 3.734, Average Loss: 4.433, avg. samples / sec: 53151.67
Iteration:   1660, Loss function: 6.160, Average Loss: 4.456, avg. samples / sec: 53086.14
Iteration:   1660, Loss function: 3.619, Average Loss: 4.440, avg. samples / sec: 53145.47
Iteration:   1660, Loss function: 4.578, Average Loss: 4.455, avg. samples / sec: 53169.37
Iteration:   1660, Loss function: 3.082, Average Loss: 4.460, avg. samples / sec: 53098.68
Iteration:   1660, Loss function: 5.335, Average Loss: 4.469, avg. samples / sec: 53127.18
Iteration:   1660, Loss function: 3.927, Average Loss: 4.443, avg. samples / sec: 53065.57
Iteration:   1660, Loss function: 3.816, Average Loss: 4.451, avg. samples / sec: 53075.04
Iteration:   1660, Loss function: 4.553, Average Loss: 4.434, avg. samples / sec: 53357.55
Iteration:   1660, Loss function: 3.754, Average Loss: 4.458, avg. samples / sec: 53152.07
Iteration:   1660, Loss function: 4.915, Average Loss: 4.451, avg. samples / sec: 53114.15
Iteration:   1660, Loss function: 3.894, Average Loss: 4.450, avg. samples / sec: 53144.03
Iteration:   1660, Loss function: 4.865, Average Loss: 4.447, avg. samples / sec: 52994.47
Iteration:   1660, Loss function: 3.761, Average Loss: 4.433, avg. samples / sec: 53176.15
Iteration:   1660, Loss function: 3.321, Average Loss: 4.438, avg. samples / sec: 53165.68
Iteration:   1660, Loss function: 4.382, Average Loss: 4.470, avg. samples / sec: 53143.01
Iteration:   1660, Loss function: 4.204, Average Loss: 4.433, avg. samples / sec: 53130.19
Iteration:   1660, Loss function: 5.189, Average Loss: 4.453, avg. samples / sec: 53098.74
Iteration:   1660, Loss function: 4.682, Average Loss: 4.408, avg. samples / sec: 53161.47
Iteration:   1660, Loss function: 5.047, Average Loss: 4.463, avg. samples / sec: 53155.48
Iteration:   1660, Loss function: 4.065, Average Loss: 4.454, avg. samples / sec: 53118.07
Iteration:   1660, Loss function: 4.313, Average Loss: 4.437, avg. samples / sec: 53134.01
Iteration:   1660, Loss function: 3.629, Average Loss: 4.447, avg. samples / sec: 53103.84
Iteration:   1660, Loss function: 3.597, Average Loss: 4.432, avg. samples / sec: 53130.71
:::MLL 1558641150.696 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558641150.697 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 3.096, Average Loss: 4.449, avg. samples / sec: 53069.48
Iteration:   1680, Loss function: 4.384, Average Loss: 4.431, avg. samples / sec: 53040.40
Iteration:   1680, Loss function: 4.077, Average Loss: 4.443, avg. samples / sec: 52963.44
Iteration:   1680, Loss function: 3.892, Average Loss: 4.461, avg. samples / sec: 53001.05
Iteration:   1680, Loss function: 3.364, Average Loss: 4.448, avg. samples / sec: 53046.57
Iteration:   1680, Loss function: 3.738, Average Loss: 4.457, avg. samples / sec: 53015.50
Iteration:   1680, Loss function: 3.497, Average Loss: 4.453, avg. samples / sec: 52956.71
Iteration:   1680, Loss function: 4.304, Average Loss: 4.450, avg. samples / sec: 52982.91
Iteration:   1680, Loss function: 4.575, Average Loss: 4.457, avg. samples / sec: 52934.16
Iteration:   1680, Loss function: 3.819, Average Loss: 4.438, avg. samples / sec: 52932.15
Iteration:   1680, Loss function: 4.644, Average Loss: 4.458, avg. samples / sec: 52861.51
Iteration:   1680, Loss function: 4.398, Average Loss: 4.463, avg. samples / sec: 52910.55
Iteration:   1680, Loss function: 4.138, Average Loss: 4.433, avg. samples / sec: 53078.08
Iteration:   1680, Loss function: 3.664, Average Loss: 4.429, avg. samples / sec: 52901.09
Iteration:   1680, Loss function: 3.964, Average Loss: 4.436, avg. samples / sec: 52899.72
Iteration:   1680, Loss function: 2.903, Average Loss: 4.455, avg. samples / sec: 52898.21
Iteration:   1680, Loss function: 4.997, Average Loss: 4.446, avg. samples / sec: 52934.61
Iteration:   1680, Loss function: 4.641, Average Loss: 4.468, avg. samples / sec: 52884.63
Iteration:   1680, Loss function: 4.821, Average Loss: 4.432, avg. samples / sec: 53036.59
Iteration:   1680, Loss function: 5.369, Average Loss: 4.445, avg. samples / sec: 52932.07
Iteration:   1680, Loss function: 2.574, Average Loss: 4.445, avg. samples / sec: 53071.80
Iteration:   1680, Loss function: 5.412, Average Loss: 4.403, avg. samples / sec: 53054.74
Iteration:   1680, Loss function: 3.214, Average Loss: 4.449, avg. samples / sec: 53041.48
Iteration:   1680, Loss function: 4.241, Average Loss: 4.430, avg. samples / sec: 52916.21
Iteration:   1680, Loss function: 3.656, Average Loss: 4.447, avg. samples / sec: 52942.69
Iteration:   1680, Loss function: 4.195, Average Loss: 4.436, avg. samples / sec: 52929.88
Iteration:   1680, Loss function: 4.186, Average Loss: 4.471, avg. samples / sec: 52886.00
Iteration:   1680, Loss function: 4.846, Average Loss: 4.435, avg. samples / sec: 52694.94
Iteration:   1680, Loss function: 5.886, Average Loss: 4.433, avg. samples / sec: 52902.26
Iteration:   1680, Loss function: 3.374, Average Loss: 4.465, avg. samples / sec: 52860.57
Iteration:   1700, Loss function: 3.949, Average Loss: 4.441, avg. samples / sec: 53236.01
Iteration:   1700, Loss function: 4.428, Average Loss: 4.454, avg. samples / sec: 53275.76
Iteration:   1700, Loss function: 5.072, Average Loss: 4.434, avg. samples / sec: 53108.02
Iteration:   1700, Loss function: 4.279, Average Loss: 4.460, avg. samples / sec: 53212.88
Iteration:   1700, Loss function: 6.060, Average Loss: 4.468, avg. samples / sec: 53273.32
Iteration:   1700, Loss function: 3.879, Average Loss: 4.449, avg. samples / sec: 53380.74
Iteration:   1700, Loss function: 5.284, Average Loss: 4.447, avg. samples / sec: 53065.03
Iteration:   1700, Loss function: 4.399, Average Loss: 4.431, avg. samples / sec: 53268.13
Iteration:   1700, Loss function: 4.671, Average Loss: 4.443, avg. samples / sec: 53285.77
Iteration:   1700, Loss function: 3.920, Average Loss: 4.456, avg. samples / sec: 53234.77
Iteration:   1700, Loss function: 3.433, Average Loss: 4.456, avg. samples / sec: 53098.26
Iteration:   1700, Loss function: 4.237, Average Loss: 4.438, avg. samples / sec: 53254.54
Iteration:   1700, Loss function: 4.813, Average Loss: 4.452, avg. samples / sec: 53257.74
Iteration:   1700, Loss function: 3.759, Average Loss: 4.449, avg. samples / sec: 53121.39
Iteration:   1700, Loss function: 3.417, Average Loss: 4.435, avg. samples / sec: 53219.93
Iteration:   1700, Loss function: 3.833, Average Loss: 4.449, avg. samples / sec: 53187.15
Iteration:   1700, Loss function: 3.233, Average Loss: 4.457, avg. samples / sec: 53166.79
Iteration:   1700, Loss function: 3.732, Average Loss: 4.469, avg. samples / sec: 53237.16
Iteration:   1700, Loss function: 4.151, Average Loss: 4.429, avg. samples / sec: 53422.02
Iteration:   1700, Loss function: 4.068, Average Loss: 4.460, avg. samples / sec: 53485.92
Iteration:   1700, Loss function: 5.800, Average Loss: 4.445, avg. samples / sec: 53220.05
Iteration:   1700, Loss function: 4.373, Average Loss: 4.474, avg. samples / sec: 53318.88
Iteration:   1700, Loss function: 3.901, Average Loss: 4.430, avg. samples / sec: 53075.92
Iteration:   1700, Loss function: 4.527, Average Loss: 4.433, avg. samples / sec: 53088.68
Iteration:   1700, Loss function: 4.846, Average Loss: 4.445, avg. samples / sec: 53117.07
Iteration:   1700, Loss function: 3.839, Average Loss: 4.433, avg. samples / sec: 53287.99
Iteration:   1700, Loss function: 3.325, Average Loss: 4.446, avg. samples / sec: 53249.71
Iteration:   1700, Loss function: 5.345, Average Loss: 4.430, avg. samples / sec: 53239.41
Iteration:   1700, Loss function: 4.406, Average Loss: 4.432, avg. samples / sec: 53265.69
Iteration:   1700, Loss function: 3.004, Average Loss: 4.402, avg. samples / sec: 53084.34
Iteration:   1720, Loss function: 4.403, Average Loss: 4.435, avg. samples / sec: 53340.81
Iteration:   1720, Loss function: 4.810, Average Loss: 4.470, avg. samples / sec: 53273.69
Iteration:   1720, Loss function: 3.469, Average Loss: 4.457, avg. samples / sec: 53284.99
Iteration:   1720, Loss function: 3.961, Average Loss: 4.451, avg. samples / sec: 53282.43
Iteration:   1720, Loss function: 5.352, Average Loss: 4.447, avg. samples / sec: 53284.52
Iteration:   1720, Loss function: 4.207, Average Loss: 4.444, avg. samples / sec: 53257.98
Iteration:   1720, Loss function: 4.156, Average Loss: 4.454, avg. samples / sec: 53221.92
Iteration:   1720, Loss function: 4.076, Average Loss: 4.436, avg. samples / sec: 53271.98
Iteration:   1720, Loss function: 3.198, Average Loss: 4.453, avg. samples / sec: 53269.30
Iteration:   1720, Loss function: 3.994, Average Loss: 4.456, avg. samples / sec: 53295.28
Iteration:   1720, Loss function: 3.627, Average Loss: 4.430, avg. samples / sec: 53205.53
Iteration:   1720, Loss function: 4.202, Average Loss: 4.445, avg. samples / sec: 53238.29
Iteration:   1720, Loss function: 3.423, Average Loss: 4.443, avg. samples / sec: 53274.33
Iteration:   1720, Loss function: 4.364, Average Loss: 4.445, avg. samples / sec: 53068.50
Iteration:   1720, Loss function: 4.304, Average Loss: 4.468, avg. samples / sec: 53274.55
Iteration:   1720, Loss function: 4.583, Average Loss: 4.444, avg. samples / sec: 53303.79
Iteration:   1720, Loss function: 4.108, Average Loss: 4.459, avg. samples / sec: 53182.86
Iteration:   1720, Loss function: 4.691, Average Loss: 4.447, avg. samples / sec: 53201.33
Iteration:   1720, Loss function: 4.784, Average Loss: 4.429, avg. samples / sec: 53197.87
Iteration:   1720, Loss function: 4.905, Average Loss: 4.434, avg. samples / sec: 53285.41
Iteration:   1720, Loss function: 3.605, Average Loss: 4.430, avg. samples / sec: 53249.31
Iteration:   1720, Loss function: 3.664, Average Loss: 4.447, avg. samples / sec: 53279.79
Iteration:   1720, Loss function: 4.203, Average Loss: 4.429, avg. samples / sec: 53290.67
Iteration:   1720, Loss function: 4.465, Average Loss: 4.476, avg. samples / sec: 53222.24
Iteration:   1720, Loss function: 4.019, Average Loss: 4.428, avg. samples / sec: 53284.52
Iteration:   1720, Loss function: 4.355, Average Loss: 4.425, avg. samples / sec: 53077.30
Iteration:   1720, Loss function: 4.881, Average Loss: 4.434, avg. samples / sec: 53248.24
Iteration:   1720, Loss function: 5.018, Average Loss: 4.410, avg. samples / sec: 53271.39
Iteration:   1720, Loss function: 2.765, Average Loss: 4.454, avg. samples / sec: 53075.86
Iteration:   1720, Loss function: 3.898, Average Loss: 4.446, avg. samples / sec: 53217.00
Iteration:   1740, Loss function: 3.283, Average Loss: 4.441, avg. samples / sec: 52766.44
Iteration:   1740, Loss function: 3.569, Average Loss: 4.428, avg. samples / sec: 52728.67
Iteration:   1740, Loss function: 5.501, Average Loss: 4.441, avg. samples / sec: 52646.99
Iteration:   1740, Loss function: 5.261, Average Loss: 4.439, avg. samples / sec: 52707.67
Iteration:   1740, Loss function: 5.279, Average Loss: 4.452, avg. samples / sec: 52720.00
Iteration:   1740, Loss function: 3.889, Average Loss: 4.445, avg. samples / sec: 52690.69
Iteration:   1740, Loss function: 3.700, Average Loss: 4.470, avg. samples / sec: 52663.47
Iteration:   1740, Loss function: 4.407, Average Loss: 4.453, avg. samples / sec: 52681.78
Iteration:   1740, Loss function: 3.020, Average Loss: 4.452, avg. samples / sec: 52698.49
Iteration:   1740, Loss function: 4.971, Average Loss: 4.457, avg. samples / sec: 52723.01
Iteration:   1740, Loss function: 3.402, Average Loss: 4.444, avg. samples / sec: 52719.50
Iteration:   1740, Loss function: 4.674, Average Loss: 4.467, avg. samples / sec: 52717.16
Iteration:   1740, Loss function: 3.447, Average Loss: 4.456, avg. samples / sec: 52685.54
Iteration:   1740, Loss function: 4.925, Average Loss: 4.426, avg. samples / sec: 52718.69
Iteration:   1740, Loss function: 4.359, Average Loss: 4.452, avg. samples / sec: 52644.33
Iteration:   1740, Loss function: 5.015, Average Loss: 4.442, avg. samples / sec: 52693.40
Iteration:   1740, Loss function: 5.445, Average Loss: 4.453, avg. samples / sec: 52653.16
Iteration:   1740, Loss function: 4.117, Average Loss: 4.441, avg. samples / sec: 52661.25
Iteration:   1740, Loss function: 5.252, Average Loss: 4.446, avg. samples / sec: 52611.49
Iteration:   1740, Loss function: 3.019, Average Loss: 4.430, avg. samples / sec: 52737.73
Iteration:   1740, Loss function: 3.719, Average Loss: 4.432, avg. samples / sec: 52695.83
Iteration:   1740, Loss function: 4.452, Average Loss: 4.446, avg. samples / sec: 52683.32
Iteration:   1740, Loss function: 4.441, Average Loss: 4.423, avg. samples / sec: 52706.73
Iteration:   1740, Loss function: 4.883, Average Loss: 4.435, avg. samples / sec: 52694.70
Iteration:   1740, Loss function: 3.904, Average Loss: 4.444, avg. samples / sec: 52709.68
Iteration:   1740, Loss function: 3.647, Average Loss: 4.429, avg. samples / sec: 52655.37
Iteration:   1740, Loss function: 5.986, Average Loss: 4.452, avg. samples / sec: 52684.50
Iteration:   1740, Loss function: 3.737, Average Loss: 4.411, avg. samples / sec: 52676.11
Iteration:   1740, Loss function: 5.112, Average Loss: 4.428, avg. samples / sec: 52638.24
Iteration:   1740, Loss function: 3.719, Average Loss: 4.472, avg. samples / sec: 52535.96
:::MLL 1558641152.916 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558641152.917 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 3.735, Average Loss: 4.436, avg. samples / sec: 52734.14
Iteration:   1760, Loss function: 4.044, Average Loss: 4.440, avg. samples / sec: 52738.96
Iteration:   1760, Loss function: 3.998, Average Loss: 4.432, avg. samples / sec: 52732.34
Iteration:   1760, Loss function: 4.617, Average Loss: 4.444, avg. samples / sec: 52780.93
Iteration:   1760, Loss function: 3.959, Average Loss: 4.449, avg. samples / sec: 52810.64
Iteration:   1760, Loss function: 4.862, Average Loss: 4.451, avg. samples / sec: 52725.14
Iteration:   1760, Loss function: 4.729, Average Loss: 4.443, avg. samples / sec: 52738.03
Iteration:   1760, Loss function: 4.649, Average Loss: 4.446, avg. samples / sec: 52759.19
Iteration:   1760, Loss function: 4.724, Average Loss: 4.463, avg. samples / sec: 52713.90
Iteration:   1760, Loss function: 3.467, Average Loss: 4.449, avg. samples / sec: 52701.56
Iteration:   1760, Loss function: 4.062, Average Loss: 4.451, avg. samples / sec: 52715.80
Iteration:   1760, Loss function: 4.547, Average Loss: 4.443, avg. samples / sec: 52749.81
Iteration:   1760, Loss function: 3.423, Average Loss: 4.442, avg. samples / sec: 52689.90
Iteration:   1760, Loss function: 5.331, Average Loss: 4.428, avg. samples / sec: 52715.80
Iteration:   1760, Loss function: 4.159, Average Loss: 4.464, avg. samples / sec: 52706.13
Iteration:   1760, Loss function: 4.373, Average Loss: 4.451, avg. samples / sec: 52718.16
Iteration:   1760, Loss function: 4.846, Average Loss: 4.427, avg. samples / sec: 52654.68
Iteration:   1760, Loss function: 4.379, Average Loss: 4.430, avg. samples / sec: 52840.79
Iteration:   1760, Loss function: 4.100, Average Loss: 4.454, avg. samples / sec: 52659.64
Iteration:   1760, Loss function: 4.222, Average Loss: 4.432, avg. samples / sec: 52892.16
Iteration:   1760, Loss function: 4.737, Average Loss: 4.425, avg. samples / sec: 52703.06
Iteration:   1760, Loss function: 4.304, Average Loss: 4.440, avg. samples / sec: 52730.61
Iteration:   1760, Loss function: 4.462, Average Loss: 4.446, avg. samples / sec: 52517.81
Iteration:   1760, Loss function: 3.918, Average Loss: 4.422, avg. samples / sec: 52784.05
Iteration:   1760, Loss function: 4.129, Average Loss: 4.421, avg. samples / sec: 52725.12
Iteration:   1760, Loss function: 4.929, Average Loss: 4.428, avg. samples / sec: 52722.89
Iteration:   1760, Loss function: 3.605, Average Loss: 4.450, avg. samples / sec: 52731.83
Iteration:   1760, Loss function: 4.326, Average Loss: 4.441, avg. samples / sec: 52713.51
Iteration:   1760, Loss function: 4.524, Average Loss: 4.413, avg. samples / sec: 52734.71
Iteration:   1760, Loss function: 4.839, Average Loss: 4.475, avg. samples / sec: 52838.65
Iteration:   1780, Loss function: 4.523, Average Loss: 4.437, avg. samples / sec: 53214.91
Iteration:   1780, Loss function: 3.657, Average Loss: 4.454, avg. samples / sec: 53220.66
Iteration:   1780, Loss function: 3.458, Average Loss: 4.426, avg. samples / sec: 53256.41
Iteration:   1780, Loss function: 4.246, Average Loss: 4.443, avg. samples / sec: 53209.22
Iteration:   1780, Loss function: 3.668, Average Loss: 4.448, avg. samples / sec: 53239.47
Iteration:   1780, Loss function: 3.923, Average Loss: 4.441, avg. samples / sec: 53184.84
Iteration:   1780, Loss function: 4.121, Average Loss: 4.433, avg. samples / sec: 53164.10
Iteration:   1780, Loss function: 3.905, Average Loss: 4.419, avg. samples / sec: 53170.28
Iteration:   1780, Loss function: 3.221, Average Loss: 4.424, avg. samples / sec: 53243.58
Iteration:   1780, Loss function: 4.129, Average Loss: 4.458, avg. samples / sec: 53193.76
Iteration:   1780, Loss function: 4.932, Average Loss: 4.452, avg. samples / sec: 53271.55
Iteration:   1780, Loss function: 4.054, Average Loss: 4.440, avg. samples / sec: 53216.86
Iteration:   1780, Loss function: 4.776, Average Loss: 4.447, avg. samples / sec: 53189.34
Iteration:   1780, Loss function: 4.236, Average Loss: 4.439, avg. samples / sec: 53181.85
Iteration:   1780, Loss function: 3.228, Average Loss: 4.450, avg. samples / sec: 53201.49
Iteration:   1780, Loss function: 4.346, Average Loss: 4.463, avg. samples / sec: 53211.95
Iteration:   1780, Loss function: 3.699, Average Loss: 4.438, avg. samples / sec: 53173.14
Iteration:   1780, Loss function: 3.835, Average Loss: 4.424, avg. samples / sec: 53096.52
Iteration:   1780, Loss function: 5.122, Average Loss: 4.442, avg. samples / sec: 53008.26
Iteration:   1780, Loss function: 3.114, Average Loss: 4.420, avg. samples / sec: 53154.01
Iteration:   1780, Loss function: 3.286, Average Loss: 4.438, avg. samples / sec: 53175.41
Iteration:   1780, Loss function: 6.589, Average Loss: 4.436, avg. samples / sec: 53163.22
Iteration:   1780, Loss function: 5.034, Average Loss: 4.471, avg. samples / sec: 53234.16
Iteration:   1780, Loss function: 3.963, Average Loss: 4.418, avg. samples / sec: 53177.88
Iteration:   1780, Loss function: 3.608, Average Loss: 4.431, avg. samples / sec: 53034.61
Iteration:   1780, Loss function: 3.998, Average Loss: 4.428, avg. samples / sec: 53174.99
Iteration:   1780, Loss function: 4.143, Average Loss: 4.449, avg. samples / sec: 53189.08
Iteration:   1780, Loss function: 4.553, Average Loss: 4.442, avg. samples / sec: 53180.07
Iteration:   1780, Loss function: 4.817, Average Loss: 4.421, avg. samples / sec: 53131.35
Iteration:   1780, Loss function: 4.158, Average Loss: 4.411, avg. samples / sec: 53156.86
Iteration:   1800, Loss function: 3.740, Average Loss: 4.433, avg. samples / sec: 53464.09
Iteration:   1800, Loss function: 5.392, Average Loss: 4.421, avg. samples / sec: 53384.78
Iteration:   1800, Loss function: 4.110, Average Loss: 4.455, avg. samples / sec: 53331.69
Iteration:   1800, Loss function: 4.986, Average Loss: 4.438, avg. samples / sec: 53318.51
Iteration:   1800, Loss function: 4.479, Average Loss: 4.415, avg. samples / sec: 53358.12
Iteration:   1800, Loss function: 3.952, Average Loss: 4.436, avg. samples / sec: 53355.64
Iteration:   1800, Loss function: 4.277, Average Loss: 4.455, avg. samples / sec: 53355.92
Iteration:   1800, Loss function: 4.266, Average Loss: 4.448, avg. samples / sec: 53343.42
Iteration:   1800, Loss function: 4.443, Average Loss: 4.438, avg. samples / sec: 53325.55
Iteration:   1800, Loss function: 4.760, Average Loss: 4.447, avg. samples / sec: 53342.99
Iteration:   1800, Loss function: 4.272, Average Loss: 4.450, avg. samples / sec: 53318.71
Iteration:   1800, Loss function: 4.110, Average Loss: 4.442, avg. samples / sec: 53535.13
Iteration:   1800, Loss function: 4.160, Average Loss: 4.440, avg. samples / sec: 53375.64
Iteration:   1800, Loss function: 4.248, Average Loss: 4.448, avg. samples / sec: 53296.90
Iteration:   1800, Loss function: 3.510, Average Loss: 4.458, avg. samples / sec: 53311.68
Iteration:   1800, Loss function: 4.329, Average Loss: 4.453, avg. samples / sec: 53313.71
Iteration:   1800, Loss function: 5.256, Average Loss: 4.433, avg. samples / sec: 53301.98
Iteration:   1800, Loss function: 4.388, Average Loss: 4.424, avg. samples / sec: 53239.07
Iteration:   1800, Loss function: 3.115, Average Loss: 4.435, avg. samples / sec: 53377.62
Iteration:   1800, Loss function: 4.442, Average Loss: 4.420, avg. samples / sec: 53358.42
Iteration:   1800, Loss function: 4.523, Average Loss: 4.433, avg. samples / sec: 53369.07
Iteration:   1800, Loss function: 3.853, Average Loss: 4.425, avg. samples / sec: 53295.89
Iteration:   1800, Loss function: 3.829, Average Loss: 4.472, avg. samples / sec: 53363.07
Iteration:   1800, Loss function: 4.861, Average Loss: 4.435, avg. samples / sec: 53365.78
Iteration:   1800, Loss function: 3.763, Average Loss: 4.425, avg. samples / sec: 53367.29
Iteration:   1800, Loss function: 4.067, Average Loss: 4.443, avg. samples / sec: 53374.69
Iteration:   1800, Loss function: 4.522, Average Loss: 4.414, avg. samples / sec: 53344.25
Iteration:   1800, Loss function: 5.083, Average Loss: 4.418, avg. samples / sec: 53387.07
Iteration:   1800, Loss function: 3.337, Average Loss: 4.433, avg. samples / sec: 53368.45
Iteration:   1800, Loss function: 4.205, Average Loss: 4.406, avg. samples / sec: 53387.55
:::MLL 1558641155.128 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558641155.129 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 3.839, Average Loss: 4.435, avg. samples / sec: 53136.86
Iteration:   1820, Loss function: 4.527, Average Loss: 4.422, avg. samples / sec: 53158.56
Iteration:   1820, Loss function: 5.430, Average Loss: 4.437, avg. samples / sec: 53167.31
Iteration:   1820, Loss function: 4.700, Average Loss: 4.441, avg. samples / sec: 53168.27
Iteration:   1820, Loss function: 5.209, Average Loss: 4.448, avg. samples / sec: 53146.29
Iteration:   1820, Loss function: 5.028, Average Loss: 4.453, avg. samples / sec: 53150.20
Iteration:   1820, Loss function: 4.199, Average Loss: 4.442, avg. samples / sec: 53082.80
Iteration:   1820, Loss function: 4.147, Average Loss: 4.462, avg. samples / sec: 53101.10
Iteration:   1820, Loss function: 5.126, Average Loss: 4.463, avg. samples / sec: 53031.98
Iteration:   1820, Loss function: 5.250, Average Loss: 4.443, avg. samples / sec: 53012.31
Iteration:   1820, Loss function: 4.599, Average Loss: 4.442, avg. samples / sec: 53041.10
Iteration:   1820, Loss function: 4.576, Average Loss: 4.449, avg. samples / sec: 53047.89
Iteration:   1820, Loss function: 4.046, Average Loss: 4.413, avg. samples / sec: 53005.99
Iteration:   1820, Loss function: 7.292, Average Loss: 4.442, avg. samples / sec: 53067.49
Iteration:   1820, Loss function: 3.943, Average Loss: 4.431, avg. samples / sec: 53222.71
Iteration:   1820, Loss function: 5.097, Average Loss: 4.449, avg. samples / sec: 53011.29
Iteration:   1820, Loss function: 3.868, Average Loss: 4.435, avg. samples / sec: 53245.01
Iteration:   1820, Loss function: 5.353, Average Loss: 4.426, avg. samples / sec: 53060.51
Iteration:   1820, Loss function: 3.620, Average Loss: 4.447, avg. samples / sec: 53031.90
Iteration:   1820, Loss function: 4.475, Average Loss: 4.460, avg. samples / sec: 52975.58
Iteration:   1820, Loss function: 4.416, Average Loss: 4.412, avg. samples / sec: 53215.47
Iteration:   1820, Loss function: 4.587, Average Loss: 4.430, avg. samples / sec: 53163.06
Iteration:   1820, Loss function: 4.208, Average Loss: 4.439, avg. samples / sec: 53117.07
Iteration:   1820, Loss function: 4.736, Average Loss: 4.423, avg. samples / sec: 53046.61
Iteration:   1820, Loss function: 4.604, Average Loss: 4.429, avg. samples / sec: 53046.53
Iteration:   1820, Loss function: 4.586, Average Loss: 4.446, avg. samples / sec: 53014.68
Iteration:   1820, Loss function: 5.014, Average Loss: 4.439, avg. samples / sec: 53001.92
Iteration:   1820, Loss function: 3.577, Average Loss: 4.421, avg. samples / sec: 53018.55
Iteration:   1820, Loss function: 3.664, Average Loss: 4.416, avg. samples / sec: 53018.61
Iteration:   1820, Loss function: 4.783, Average Loss: 4.471, avg. samples / sec: 52962.34
Iteration:   1840, Loss function: 3.874, Average Loss: 4.460, avg. samples / sec: 53291.60
Iteration:   1840, Loss function: 3.848, Average Loss: 4.420, avg. samples / sec: 53116.85
Iteration:   1840, Loss function: 4.851, Average Loss: 4.448, avg. samples / sec: 53289.22
Iteration:   1840, Loss function: 4.791, Average Loss: 4.447, avg. samples / sec: 53314.46
Iteration:   1840, Loss function: 4.749, Average Loss: 4.441, avg. samples / sec: 53281.08
Iteration:   1840, Loss function: 5.095, Average Loss: 4.456, avg. samples / sec: 53173.43
Iteration:   1840, Loss function: 5.318, Average Loss: 4.409, avg. samples / sec: 53293.65
Iteration:   1840, Loss function: 4.347, Average Loss: 4.437, avg. samples / sec: 53274.94
Iteration:   1840, Loss function: 4.303, Average Loss: 4.440, avg. samples / sec: 53225.84
Iteration:   1840, Loss function: 5.005, Average Loss: 4.457, avg. samples / sec: 53232.96
Iteration:   1840, Loss function: 5.147, Average Loss: 4.434, avg. samples / sec: 53025.20
Iteration:   1840, Loss function: 4.687, Average Loss: 4.424, avg. samples / sec: 53283.42
Iteration:   1840, Loss function: 4.406, Average Loss: 4.446, avg. samples / sec: 53115.21
Iteration:   1840, Loss function: 2.945, Average Loss: 4.459, avg. samples / sec: 53290.43
Iteration:   1840, Loss function: 3.851, Average Loss: 4.438, avg. samples / sec: 53232.80
Iteration:   1840, Loss function: 3.785, Average Loss: 4.432, avg. samples / sec: 53090.44
Iteration:   1840, Loss function: 3.820, Average Loss: 4.431, avg. samples / sec: 53012.61
Iteration:   1840, Loss function: 3.395, Average Loss: 4.427, avg. samples / sec: 53173.10
Iteration:   1840, Loss function: 4.093, Average Loss: 4.432, avg. samples / sec: 53091.12
Iteration:   1840, Loss function: 4.384, Average Loss: 4.439, avg. samples / sec: 53173.35
Iteration:   1840, Loss function: 4.521, Average Loss: 4.454, avg. samples / sec: 53101.72
Iteration:   1840, Loss function: 4.663, Average Loss: 4.420, avg. samples / sec: 53309.01
Iteration:   1840, Loss function: 4.924, Average Loss: 4.428, avg. samples / sec: 53255.45
Iteration:   1840, Loss function: 4.078, Average Loss: 4.431, avg. samples / sec: 53084.60
Iteration:   1840, Loss function: 3.992, Average Loss: 4.437, avg. samples / sec: 53294.30
Iteration:   1840, Loss function: 3.683, Average Loss: 4.420, avg. samples / sec: 53209.20
Iteration:   1840, Loss function: 3.729, Average Loss: 4.419, avg. samples / sec: 53294.12
Iteration:   1840, Loss function: 3.431, Average Loss: 4.464, avg. samples / sec: 53313.61
Iteration:   1840, Loss function: 4.005, Average Loss: 4.411, avg. samples / sec: 53076.66
Iteration:   1840, Loss function: 5.471, Average Loss: 4.447, avg. samples / sec: 53019.07
Iteration:   1860, Loss function: 4.863, Average Loss: 4.425, avg. samples / sec: 53208.20
Iteration:   1860, Loss function: 4.320, Average Loss: 4.416, avg. samples / sec: 53066.57
Iteration:   1860, Loss function: 4.685, Average Loss: 4.424, avg. samples / sec: 53130.81
Iteration:   1860, Loss function: 4.142, Average Loss: 4.450, avg. samples / sec: 53060.51
Iteration:   1860, Loss function: 5.505, Average Loss: 4.441, avg. samples / sec: 53043.98
Iteration:   1860, Loss function: 4.463, Average Loss: 4.431, avg. samples / sec: 53045.43
Iteration:   1860, Loss function: 4.304, Average Loss: 4.438, avg. samples / sec: 53050.41
Iteration:   1860, Loss function: 4.295, Average Loss: 4.456, avg. samples / sec: 53001.62
Iteration:   1860, Loss function: 4.603, Average Loss: 4.453, avg. samples / sec: 53251.10
Iteration:   1860, Loss function: 3.169, Average Loss: 4.453, avg. samples / sec: 53078.76
Iteration:   1860, Loss function: 4.534, Average Loss: 4.445, avg. samples / sec: 53019.37
Iteration:   1860, Loss function: 3.459, Average Loss: 4.425, avg. samples / sec: 53048.97
Iteration:   1860, Loss function: 3.436, Average Loss: 4.428, avg. samples / sec: 53029.56
Iteration:   1860, Loss function: 4.937, Average Loss: 4.435, avg. samples / sec: 53004.02
Iteration:   1860, Loss function: 3.963, Average Loss: 4.433, avg. samples / sec: 53036.85
Iteration:   1860, Loss function: 4.995, Average Loss: 4.447, avg. samples / sec: 53011.73
Iteration:   1860, Loss function: 2.825, Average Loss: 4.450, avg. samples / sec: 52927.38
Iteration:   1860, Loss function: 2.913, Average Loss: 4.408, avg. samples / sec: 52899.01
Iteration:   1860, Loss function: 4.997, Average Loss: 4.420, avg. samples / sec: 53126.94
Iteration:   1860, Loss function: 4.869, Average Loss: 4.421, avg. samples / sec: 53023.84
Iteration:   1860, Loss function: 4.528, Average Loss: 4.431, avg. samples / sec: 53020.43
Iteration:   1860, Loss function: 4.250, Average Loss: 4.432, avg. samples / sec: 53020.35
Iteration:   1860, Loss function: 6.741, Average Loss: 4.424, avg. samples / sec: 53051.50
Iteration:   1860, Loss function: 3.420, Average Loss: 4.436, avg. samples / sec: 53053.98
Iteration:   1860, Loss function: 3.644, Average Loss: 4.431, avg. samples / sec: 53052.14
Iteration:   1860, Loss function: 4.299, Average Loss: 4.463, avg. samples / sec: 53060.27
Iteration:   1860, Loss function: 6.658, Average Loss: 4.441, avg. samples / sec: 53315.14
Iteration:   1860, Loss function: 5.285, Average Loss: 4.419, avg. samples / sec: 53032.04
Iteration:   1860, Loss function: 3.403, Average Loss: 4.418, avg. samples / sec: 53049.07
Iteration:   1860, Loss function: 5.394, Average Loss: 4.410, avg. samples / sec: 53047.69
Iteration:   1880, Loss function: 4.542, Average Loss: 4.406, avg. samples / sec: 53454.44
Iteration:   1880, Loss function: 3.665, Average Loss: 4.444, avg. samples / sec: 53315.43
Iteration:   1880, Loss function: 4.560, Average Loss: 4.443, avg. samples / sec: 53407.10
Iteration:   1880, Loss function: 3.756, Average Loss: 4.422, avg. samples / sec: 53321.54
Iteration:   1880, Loss function: 4.617, Average Loss: 4.456, avg. samples / sec: 53296.13
Iteration:   1880, Loss function: 4.692, Average Loss: 4.447, avg. samples / sec: 53272.06
Iteration:   1880, Loss function: 3.929, Average Loss: 4.435, avg. samples / sec: 53268.87
Iteration:   1880, Loss function: 4.469, Average Loss: 4.432, avg. samples / sec: 53303.95
Iteration:   1880, Loss function: 3.725, Average Loss: 4.422, avg. samples / sec: 53294.54
Iteration:   1880, Loss function: 3.995, Average Loss: 4.449, avg. samples / sec: 53264.20
Iteration:   1880, Loss function: 4.838, Average Loss: 4.416, avg. samples / sec: 53217.86
Iteration:   1880, Loss function: 4.113, Average Loss: 4.415, avg. samples / sec: 53455.57
Iteration:   1880, Loss function: 4.793, Average Loss: 4.452, avg. samples / sec: 53253.03
Iteration:   1880, Loss function: 5.298, Average Loss: 4.446, avg. samples / sec: 53319.44
Iteration:   1880, Loss function: 4.898, Average Loss: 4.427, avg. samples / sec: 53299.38
Iteration:   1880, Loss function: 4.929, Average Loss: 4.423, avg. samples / sec: 53221.08
Iteration:   1880, Loss function: 4.636, Average Loss: 4.416, avg. samples / sec: 53187.67
Iteration:   1880, Loss function: 4.273, Average Loss: 4.428, avg. samples / sec: 53459.85
Iteration:   1880, Loss function: 3.566, Average Loss: 4.430, avg. samples / sec: 53196.45
Iteration:   1880, Loss function: 4.989, Average Loss: 4.415, avg. samples / sec: 53355.62
Iteration:   1880, Loss function: 4.527, Average Loss: 4.434, avg. samples / sec: 53189.30
Iteration:   1880, Loss function: 3.344, Average Loss: 4.426, avg. samples / sec: 53302.10
Iteration:   1880, Loss function: 3.893, Average Loss: 4.431, avg. samples / sec: 53299.92
Iteration:   1880, Loss function: 4.315, Average Loss: 4.440, avg. samples / sec: 53288.61
Iteration:   1880, Loss function: 4.065, Average Loss: 4.414, avg. samples / sec: 53289.16
Iteration:   1880, Loss function: 4.809, Average Loss: 4.415, avg. samples / sec: 53267.57
Iteration:   1880, Loss function: 4.240, Average Loss: 4.414, avg. samples / sec: 53267.22
Iteration:   1880, Loss function: 2.948, Average Loss: 4.405, avg. samples / sec: 53291.60
Iteration:   1880, Loss function: 4.665, Average Loss: 4.457, avg. samples / sec: 53236.40
Iteration:   1880, Loss function: 3.416, Average Loss: 4.422, avg. samples / sec: 53234.51
:::MLL 1558641157.343 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558641157.344 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 4.322, Average Loss: 4.447, avg. samples / sec: 52884.42
Iteration:   1900, Loss function: 4.455, Average Loss: 4.408, avg. samples / sec: 52839.35
Iteration:   1900, Loss function: 4.226, Average Loss: 4.439, avg. samples / sec: 52818.61
Iteration:   1900, Loss function: 4.705, Average Loss: 4.438, avg. samples / sec: 52796.00
Iteration:   1900, Loss function: 4.082, Average Loss: 4.443, avg. samples / sec: 52847.83
Iteration:   1900, Loss function: 4.533, Average Loss: 4.419, avg. samples / sec: 52846.02
Iteration:   1900, Loss function: 4.527, Average Loss: 4.420, avg. samples / sec: 52793.44
Iteration:   1900, Loss function: 3.847, Average Loss: 4.445, avg. samples / sec: 52783.50
Iteration:   1900, Loss function: 5.043, Average Loss: 4.427, avg. samples / sec: 52808.58
Iteration:   1900, Loss function: 4.057, Average Loss: 4.400, avg. samples / sec: 52757.02
Iteration:   1900, Loss function: 5.673, Average Loss: 4.429, avg. samples / sec: 52877.07
Iteration:   1900, Loss function: 3.872, Average Loss: 4.454, avg. samples / sec: 52781.94
Iteration:   1900, Loss function: 4.882, Average Loss: 4.407, avg. samples / sec: 52831.50
Iteration:   1900, Loss function: 4.241, Average Loss: 4.430, avg. samples / sec: 52784.76
Iteration:   1900, Loss function: 3.576, Average Loss: 4.426, avg. samples / sec: 52843.77
Iteration:   1900, Loss function: 5.016, Average Loss: 4.418, avg. samples / sec: 52805.25
Iteration:   1900, Loss function: 3.168, Average Loss: 4.412, avg. samples / sec: 52761.94
Iteration:   1900, Loss function: 2.793, Average Loss: 4.442, avg. samples / sec: 52717.79
Iteration:   1900, Loss function: 4.121, Average Loss: 4.419, avg. samples / sec: 52827.13
Iteration:   1900, Loss function: 3.992, Average Loss: 4.414, avg. samples / sec: 52635.66
Iteration:   1900, Loss function: 4.209, Average Loss: 4.455, avg. samples / sec: 52869.77
Iteration:   1900, Loss function: 4.826, Average Loss: 4.426, avg. samples / sec: 52803.24
Iteration:   1900, Loss function: 3.260, Average Loss: 4.413, avg. samples / sec: 52680.70
Iteration:   1900, Loss function: 3.173, Average Loss: 4.410, avg. samples / sec: 52828.53
Iteration:   1900, Loss function: 5.158, Average Loss: 4.440, avg. samples / sec: 52815.01
Iteration:   1900, Loss function: 4.692, Average Loss: 4.408, avg. samples / sec: 52826.81
Iteration:   1900, Loss function: 3.635, Average Loss: 4.404, avg. samples / sec: 52824.39
Iteration:   1900, Loss function: 3.123, Average Loss: 4.424, avg. samples / sec: 52624.01
Iteration:   1900, Loss function: 3.868, Average Loss: 4.412, avg. samples / sec: 52811.25
Iteration:   1900, Loss function: 3.290, Average Loss: 4.418, avg. samples / sec: 52804.32
Iteration:   1920, Loss function: 4.576, Average Loss: 4.400, avg. samples / sec: 53276.51
Iteration:   1920, Loss function: 5.306, Average Loss: 4.419, avg. samples / sec: 53252.01
Iteration:   1920, Loss function: 6.563, Average Loss: 4.402, avg. samples / sec: 53259.23
Iteration:   1920, Loss function: 4.963, Average Loss: 4.427, avg. samples / sec: 53228.37
Iteration:   1920, Loss function: 4.022, Average Loss: 4.405, avg. samples / sec: 53209.14
Iteration:   1920, Loss function: 4.914, Average Loss: 4.433, avg. samples / sec: 53198.28
Iteration:   1920, Loss function: 5.104, Average Loss: 4.415, avg. samples / sec: 53200.48
Iteration:   1920, Loss function: 5.831, Average Loss: 4.444, avg. samples / sec: 53205.43
Iteration:   1920, Loss function: 3.874, Average Loss: 4.424, avg. samples / sec: 53230.91
Iteration:   1920, Loss function: 3.517, Average Loss: 4.439, avg. samples / sec: 53174.41
Iteration:   1920, Loss function: 4.119, Average Loss: 4.428, avg. samples / sec: 53193.34
Iteration:   1920, Loss function: 3.374, Average Loss: 4.409, avg. samples / sec: 53240.44
Iteration:   1920, Loss function: 5.938, Average Loss: 4.417, avg. samples / sec: 53211.33
Iteration:   1920, Loss function: 3.440, Average Loss: 4.441, avg. samples / sec: 53160.17
Iteration:   1920, Loss function: 4.730, Average Loss: 4.443, avg. samples / sec: 53051.30
Iteration:   1920, Loss function: 5.388, Average Loss: 4.408, avg. samples / sec: 53255.51
Iteration:   1920, Loss function: 2.807, Average Loss: 4.409, avg. samples / sec: 53241.04
Iteration:   1920, Loss function: 4.078, Average Loss: 4.429, avg. samples / sec: 53052.98
Iteration:   1920, Loss function: 3.750, Average Loss: 4.405, avg. samples / sec: 53226.95
Iteration:   1920, Loss function: 4.950, Average Loss: 4.425, avg. samples / sec: 53234.99
Iteration:   1920, Loss function: 4.919, Average Loss: 4.422, avg. samples / sec: 53203.44
Iteration:   1920, Loss function: 3.129, Average Loss: 4.405, avg. samples / sec: 53236.84
Iteration:   1920, Loss function: 4.399, Average Loss: 4.451, avg. samples / sec: 53202.57
Iteration:   1920, Loss function: 4.413, Average Loss: 4.448, avg. samples / sec: 52999.35
Iteration:   1920, Loss function: 3.903, Average Loss: 4.438, avg. samples / sec: 53088.14
Iteration:   1920, Loss function: 3.357, Average Loss: 4.414, avg. samples / sec: 53243.80
Iteration:   1920, Loss function: 3.915, Average Loss: 4.402, avg. samples / sec: 53193.98
Iteration:   1920, Loss function: 3.794, Average Loss: 4.413, avg. samples / sec: 53141.14
Iteration:   1920, Loss function: 4.109, Average Loss: 4.436, avg. samples / sec: 53159.49
Iteration:   1920, Loss function: 4.327, Average Loss: 4.402, avg. samples / sec: 53146.58
Iteration:   1940, Loss function: 5.113, Average Loss: 4.417, avg. samples / sec: 53139.26
Iteration:   1940, Loss function: 3.702, Average Loss: 4.424, avg. samples / sec: 53362.26
Iteration:   1940, Loss function: 4.989, Average Loss: 4.402, avg. samples / sec: 53138.42
Iteration:   1940, Loss function: 4.902, Average Loss: 4.445, avg. samples / sec: 53175.21
Iteration:   1940, Loss function: 4.462, Average Loss: 4.425, avg. samples / sec: 53150.88
Iteration:   1940, Loss function: 3.714, Average Loss: 4.429, avg. samples / sec: 53146.84
Iteration:   1940, Loss function: 3.853, Average Loss: 4.401, avg. samples / sec: 53088.20
Iteration:   1940, Loss function: 4.633, Average Loss: 4.440, avg. samples / sec: 53165.10
Iteration:   1940, Loss function: 3.468, Average Loss: 4.419, avg. samples / sec: 53146.88
Iteration:   1940, Loss function: 4.626, Average Loss: 4.447, avg. samples / sec: 53361.25
Iteration:   1940, Loss function: 3.901, Average Loss: 4.438, avg. samples / sec: 53232.40
Iteration:   1940, Loss function: 4.189, Average Loss: 4.427, avg. samples / sec: 53160.03
Iteration:   1940, Loss function: 3.730, Average Loss: 4.406, avg. samples / sec: 53113.47
Iteration:   1940, Loss function: 5.695, Average Loss: 4.417, avg. samples / sec: 53149.72
Iteration:   1940, Loss function: 4.502, Average Loss: 4.408, avg. samples / sec: 53140.22
Iteration:   1940, Loss function: 4.592, Average Loss: 4.438, avg. samples / sec: 53152.67
Iteration:   1940, Loss function: 4.491, Average Loss: 4.412, avg. samples / sec: 53097.54
Iteration:   1940, Loss function: 4.802, Average Loss: 4.410, avg. samples / sec: 53179.89
Iteration:   1940, Loss function: 4.758, Average Loss: 4.409, avg. samples / sec: 53130.17
Iteration:   1940, Loss function: 3.903, Average Loss: 4.411, avg. samples / sec: 53120.51
Iteration:   1940, Loss function: 3.866, Average Loss: 4.417, avg. samples / sec: 53163.72
Iteration:   1940, Loss function: 4.303, Average Loss: 4.409, avg. samples / sec: 53201.23
Iteration:   1940, Loss function: 3.940, Average Loss: 4.436, avg. samples / sec: 53159.65
Iteration:   1940, Loss function: 4.011, Average Loss: 4.431, avg. samples / sec: 53202.83
Iteration:   1940, Loss function: 3.387, Average Loss: 4.408, avg. samples / sec: 53158.06
Iteration:   1940, Loss function: 5.293, Average Loss: 4.402, avg. samples / sec: 53125.58
Iteration:   1940, Loss function: 3.676, Average Loss: 4.409, avg. samples / sec: 53152.87
Iteration:   1940, Loss function: 3.677, Average Loss: 4.421, avg. samples / sec: 53120.25
Iteration:   1940, Loss function: 5.814, Average Loss: 4.455, avg. samples / sec: 53116.49
Iteration:   1940, Loss function: 5.095, Average Loss: 4.402, avg. samples / sec: 53160.73
:::MLL 1558641159.556 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558641159.557 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.708, Average Loss: 4.397, avg. samples / sec: 53277.82
Iteration:   1960, Loss function: 5.095, Average Loss: 4.404, avg. samples / sec: 53267.97
Iteration:   1960, Loss function: 4.284, Average Loss: 4.412, avg. samples / sec: 53173.65
Iteration:   1960, Loss function: 4.261, Average Loss: 4.433, avg. samples / sec: 53247.68
Iteration:   1960, Loss function: 3.677, Average Loss: 4.408, avg. samples / sec: 53232.96
Iteration:   1960, Loss function: 5.446, Average Loss: 4.422, avg. samples / sec: 53188.50
Iteration:   1960, Loss function: 3.711, Average Loss: 4.431, avg. samples / sec: 53187.94
Iteration:   1960, Loss function: 4.063, Average Loss: 4.421, avg. samples / sec: 53100.80
Iteration:   1960, Loss function: 2.858, Average Loss: 4.423, avg. samples / sec: 53112.81
Iteration:   1960, Loss function: 4.883, Average Loss: 4.412, avg. samples / sec: 53125.94
Iteration:   1960, Loss function: 4.184, Average Loss: 4.411, avg. samples / sec: 53155.34
Iteration:   1960, Loss function: 4.244, Average Loss: 4.435, avg. samples / sec: 53094.92
Iteration:   1960, Loss function: 3.964, Average Loss: 4.396, avg. samples / sec: 53093.70
Iteration:   1960, Loss function: 4.121, Average Loss: 4.402, avg. samples / sec: 53121.77
Iteration:   1960, Loss function: 4.271, Average Loss: 4.440, avg. samples / sec: 53089.82
Iteration:   1960, Loss function: 3.644, Average Loss: 4.421, avg. samples / sec: 53029.35
Iteration:   1960, Loss function: 3.807, Average Loss: 4.439, avg. samples / sec: 53029.70
Iteration:   1960, Loss function: 3.745, Average Loss: 4.408, avg. samples / sec: 53285.43
Iteration:   1960, Loss function: 4.170, Average Loss: 4.427, avg. samples / sec: 53255.95
Iteration:   1960, Loss function: 3.345, Average Loss: 4.400, avg. samples / sec: 53313.37
Iteration:   1960, Loss function: 4.355, Average Loss: 4.420, avg. samples / sec: 53254.10
Iteration:   1960, Loss function: 4.679, Average Loss: 4.416, avg. samples / sec: 53210.75
Iteration:   1960, Loss function: 4.810, Average Loss: 4.408, avg. samples / sec: 53193.03
Iteration:   1960, Loss function: 4.591, Average Loss: 4.412, avg. samples / sec: 53060.33
Iteration:   1960, Loss function: 4.105, Average Loss: 4.403, avg. samples / sec: 53065.61
Iteration:   1960, Loss function: 5.690, Average Loss: 4.402, avg. samples / sec: 53092.30
Iteration:   1960, Loss function: 5.424, Average Loss: 4.455, avg. samples / sec: 53103.10
Iteration:   1960, Loss function: 3.474, Average Loss: 4.407, avg. samples / sec: 53047.31
Iteration:   1960, Loss function: 3.648, Average Loss: 4.425, avg. samples / sec: 53072.34
Iteration:   1960, Loss function: 4.418, Average Loss: 4.405, avg. samples / sec: 53066.17
Iteration:   1980, Loss function: 4.181, Average Loss: 4.397, avg. samples / sec: 53065.27
Iteration:   1980, Loss function: 4.502, Average Loss: 4.407, avg. samples / sec: 53084.28
Iteration:   1980, Loss function: 3.172, Average Loss: 4.429, avg. samples / sec: 53206.03
Iteration:   1980, Loss function: 4.707, Average Loss: 4.389, avg. samples / sec: 53191.87
Iteration:   1980, Loss function: 3.890, Average Loss: 4.407, avg. samples / sec: 53171.78
Iteration:   1980, Loss function: 4.176, Average Loss: 4.416, avg. samples / sec: 53265.71
Iteration:   1980, Loss function: 4.737, Average Loss: 4.422, avg. samples / sec: 53153.79
Iteration:   1980, Loss function: 4.264, Average Loss: 4.415, avg. samples / sec: 53152.99
Iteration:   1980, Loss function: 3.481, Average Loss: 4.435, avg. samples / sec: 53220.01
Iteration:   1980, Loss function: 4.423, Average Loss: 4.431, avg. samples / sec: 53094.96
Iteration:   1980, Loss function: 5.218, Average Loss: 4.408, avg. samples / sec: 53145.05
Iteration:   1980, Loss function: 3.310, Average Loss: 4.397, avg. samples / sec: 52942.73
Iteration:   1980, Loss function: 4.100, Average Loss: 4.437, avg. samples / sec: 53153.71
Iteration:   1980, Loss function: 4.291, Average Loss: 4.416, avg. samples / sec: 53060.53
Iteration:   1980, Loss function: 5.257, Average Loss: 4.429, avg. samples / sec: 53026.91
Iteration:   1980, Loss function: 5.026, Average Loss: 4.399, avg. samples / sec: 53143.55
Iteration:   1980, Loss function: 4.282, Average Loss: 4.414, avg. samples / sec: 53128.96
Iteration:   1980, Loss function: 3.656, Average Loss: 4.403, avg. samples / sec: 52992.93
Iteration:   1980, Loss function: 4.115, Average Loss: 4.409, avg. samples / sec: 53177.16
Iteration:   1980, Loss function: 4.501, Average Loss: 4.409, avg. samples / sec: 53217.56
Iteration:   1980, Loss function: 3.688, Average Loss: 4.452, avg. samples / sec: 53196.85
Iteration:   1980, Loss function: 5.718, Average Loss: 4.413, avg. samples / sec: 53033.56
Iteration:   1980, Loss function: 4.110, Average Loss: 4.400, avg. samples / sec: 53188.40
Iteration:   1980, Loss function: 4.045, Average Loss: 4.405, avg. samples / sec: 53036.29
Iteration:   1980, Loss function: 4.601, Average Loss: 4.421, avg. samples / sec: 53003.82
Iteration:   1980, Loss function: 3.714, Average Loss: 4.421, avg. samples / sec: 53171.00
Iteration:   1980, Loss function: 3.992, Average Loss: 4.398, avg. samples / sec: 52987.77
Iteration:   1980, Loss function: 4.972, Average Loss: 4.406, avg. samples / sec: 52956.47
Iteration:   1980, Loss function: 4.902, Average Loss: 4.404, avg. samples / sec: 53183.08
Iteration:   1980, Loss function: 4.060, Average Loss: 4.400, avg. samples / sec: 53140.68
Iteration:   2000, Loss function: 4.675, Average Loss: 4.389, avg. samples / sec: 53107.48
Iteration:   2000, Loss function: 5.192, Average Loss: 4.429, avg. samples / sec: 53134.99
Iteration:   2000, Loss function: 4.965, Average Loss: 4.432, avg. samples / sec: 53116.25
Iteration:   2000, Loss function: 4.489, Average Loss: 4.411, avg. samples / sec: 53113.69
Iteration:   2000, Loss function: 3.762, Average Loss: 4.387, avg. samples / sec: 53092.28
Iteration:   2000, Loss function: 3.593, Average Loss: 4.404, avg. samples / sec: 53088.76
Iteration:   2000, Loss function: 3.712, Average Loss: 4.417, avg. samples / sec: 53090.60
Iteration:   2000, Loss function: 4.977, Average Loss: 4.395, avg. samples / sec: 53142.19
Iteration:   2000, Loss function: 4.769, Average Loss: 4.404, avg. samples / sec: 53065.47
Iteration:   2000, Loss function: 3.907, Average Loss: 4.400, avg. samples / sec: 53173.45
Iteration:   2000, Loss function: 4.604, Average Loss: 4.425, avg. samples / sec: 53062.77
Iteration:   2000, Loss function: 3.348, Average Loss: 4.407, avg. samples / sec: 53125.84
Iteration:   2000, Loss function: 3.799, Average Loss: 4.425, avg. samples / sec: 53119.41
Iteration:   2000, Loss function: 3.412, Average Loss: 4.422, avg. samples / sec: 53072.36
Iteration:   2000, Loss function: 3.520, Average Loss: 4.413, avg. samples / sec: 53158.88
Iteration:   2000, Loss function: 5.180, Average Loss: 4.432, avg. samples / sec: 53084.48
Iteration:   2000, Loss function: 4.270, Average Loss: 4.399, avg. samples / sec: 53063.23
Iteration:   2000, Loss function: 4.602, Average Loss: 4.392, avg. samples / sec: 53267.85
Iteration:   2000, Loss function: 3.998, Average Loss: 4.396, avg. samples / sec: 53051.42
Iteration:   2000, Loss function: 3.855, Average Loss: 4.404, avg. samples / sec: 53178.30
Iteration:   2000, Loss function: 3.642, Average Loss: 4.407, avg. samples / sec: 53125.56
Iteration:   2000, Loss function: 5.683, Average Loss: 4.412, avg. samples / sec: 53137.18
Iteration:   2000, Loss function: 4.867, Average Loss: 4.407, avg. samples / sec: 53087.88
Iteration:   2000, Loss function: 2.627, Average Loss: 4.414, avg. samples / sec: 53116.07
Iteration:   2000, Loss function: 5.617, Average Loss: 4.418, avg. samples / sec: 53134.83
Iteration:   2000, Loss function: 3.481, Average Loss: 4.447, avg. samples / sec: 53090.68
Iteration:   2000, Loss function: 3.174, Average Loss: 4.400, avg. samples / sec: 53128.70
Iteration:   2000, Loss function: 3.484, Average Loss: 4.403, avg. samples / sec: 53113.79
Iteration:   2000, Loss function: 5.457, Average Loss: 4.398, avg. samples / sec: 53114.23
Iteration:   2000, Loss function: 3.257, Average Loss: 4.391, avg. samples / sec: 53072.56
Iteration:   2020, Loss function: 5.316, Average Loss: 4.381, avg. samples / sec: 53314.24
Iteration:   2020, Loss function: 5.106, Average Loss: 4.425, avg. samples / sec: 53311.90
Iteration:   2020, Loss function: 4.095, Average Loss: 4.405, avg. samples / sec: 53341.56
Iteration:   2020, Loss function: 4.597, Average Loss: 4.406, avg. samples / sec: 53306.69
Iteration:   2020, Loss function: 4.171, Average Loss: 4.419, avg. samples / sec: 53346.26
Iteration:   2020, Loss function: 2.978, Average Loss: 4.396, avg. samples / sec: 53372.69
Iteration:   2020, Loss function: 3.964, Average Loss: 4.395, avg. samples / sec: 53388.85
Iteration:   2020, Loss function: 3.402, Average Loss: 4.425, avg. samples / sec: 53314.50
Iteration:   2020, Loss function: 4.865, Average Loss: 4.425, avg. samples / sec: 53276.08
Iteration:   2020, Loss function: 3.758, Average Loss: 4.401, avg. samples / sec: 53298.43
Iteration:   2020, Loss function: 3.770, Average Loss: 4.413, avg. samples / sec: 53306.03
Iteration:   2020, Loss function: 3.064, Average Loss: 4.402, avg. samples / sec: 53297.68
Iteration:   2020, Loss function: 3.147, Average Loss: 4.397, avg. samples / sec: 53275.22
Iteration:   2020, Loss function: 4.560, Average Loss: 4.412, avg. samples / sec: 53294.40
Iteration:   2020, Loss function: 4.567, Average Loss: 4.381, avg. samples / sec: 53265.09
Iteration:   2020, Loss function: 3.826, Average Loss: 4.428, avg. samples / sec: 53322.27
Iteration:   2020, Loss function: 3.924, Average Loss: 4.415, avg. samples / sec: 53265.94
Iteration:   2020, Loss function: 5.918, Average Loss: 4.398, avg. samples / sec: 53259.29
Iteration:   2020, Loss function: 3.793, Average Loss: 4.405, avg. samples / sec: 53308.57
Iteration:   2020, Loss function: 5.154, Average Loss: 4.404, avg. samples / sec: 53301.90
Iteration:   2020, Loss function: 4.267, Average Loss: 4.398, avg. samples / sec: 53381.67
Iteration:   2020, Loss function: 4.408, Average Loss: 4.412, avg. samples / sec: 53327.25
Iteration:   2020, Loss function: 4.805, Average Loss: 4.442, avg. samples / sec: 53321.96
Iteration:   2020, Loss function: 4.381, Average Loss: 4.412, avg. samples / sec: 53312.72
Iteration:   2020, Loss function: 4.837, Average Loss: 4.387, avg. samples / sec: 53147.82
Iteration:   2020, Loss function: 4.481, Average Loss: 4.397, avg. samples / sec: 53303.61
Iteration:   2020, Loss function: 4.671, Average Loss: 4.405, avg. samples / sec: 53274.77
Iteration:   2020, Loss function: 4.547, Average Loss: 4.393, avg. samples / sec: 53318.47
Iteration:   2020, Loss function: 4.891, Average Loss: 4.390, avg. samples / sec: 53366.10
Iteration:   2020, Loss function: 4.573, Average Loss: 4.402, avg. samples / sec: 53312.44
:::MLL 1558641161.771 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558641161.772 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 4.216, Average Loss: 4.389, avg. samples / sec: 53038.49
Iteration:   2040, Loss function: 4.760, Average Loss: 4.398, avg. samples / sec: 52890.55
Iteration:   2040, Loss function: 4.771, Average Loss: 4.422, avg. samples / sec: 52880.53
Iteration:   2040, Loss function: 4.570, Average Loss: 4.392, avg. samples / sec: 52959.02
Iteration:   2040, Loss function: 4.928, Average Loss: 4.411, avg. samples / sec: 52881.04
Iteration:   2040, Loss function: 4.223, Average Loss: 4.399, avg. samples / sec: 52902.64
Iteration:   2040, Loss function: 3.294, Average Loss: 4.377, avg. samples / sec: 52921.95
Iteration:   2040, Loss function: 5.001, Average Loss: 4.383, avg. samples / sec: 52822.20
Iteration:   2040, Loss function: 4.964, Average Loss: 4.423, avg. samples / sec: 52872.75
Iteration:   2040, Loss function: 4.577, Average Loss: 4.391, avg. samples / sec: 52859.80
Iteration:   2040, Loss function: 4.901, Average Loss: 4.405, avg. samples / sec: 52901.13
Iteration:   2040, Loss function: 2.741, Average Loss: 4.421, avg. samples / sec: 52899.90
Iteration:   2040, Loss function: 3.788, Average Loss: 4.405, avg. samples / sec: 52842.62
Iteration:   2040, Loss function: 3.523, Average Loss: 4.419, avg. samples / sec: 52862.20
Iteration:   2040, Loss function: 4.441, Average Loss: 4.405, avg. samples / sec: 52872.81
Iteration:   2040, Loss function: 4.619, Average Loss: 4.403, avg. samples / sec: 52852.13
Iteration:   2040, Loss function: 2.998, Average Loss: 4.412, avg. samples / sec: 52831.72
Iteration:   2040, Loss function: 4.257, Average Loss: 4.392, avg. samples / sec: 52771.90
Iteration:   2040, Loss function: 4.194, Average Loss: 4.395, avg. samples / sec: 52886.18
Iteration:   2040, Loss function: 4.806, Average Loss: 4.397, avg. samples / sec: 52891.72
Iteration:   2040, Loss function: 4.669, Average Loss: 4.401, avg. samples / sec: 52816.99
Iteration:   2040, Loss function: 5.030, Average Loss: 4.384, avg. samples / sec: 52887.18
Iteration:   2040, Loss function: 4.339, Average Loss: 4.408, avg. samples / sec: 52844.60
Iteration:   2040, Loss function: 4.935, Average Loss: 4.406, avg. samples / sec: 52866.17
Iteration:   2040, Loss function: 4.731, Average Loss: 4.398, avg. samples / sec: 52887.65
Iteration:   2040, Loss function: 3.417, Average Loss: 4.390, avg. samples / sec: 52822.81
Iteration:   2040, Loss function: 4.792, Average Loss: 4.390, avg. samples / sec: 52858.19
Iteration:   2040, Loss function: 4.910, Average Loss: 4.440, avg. samples / sec: 52845.57
Iteration:   2040, Loss function: 4.089, Average Loss: 4.390, avg. samples / sec: 52839.03
Iteration:   2040, Loss function: 3.372, Average Loss: 4.383, avg. samples / sec: 52804.88
Iteration:   2060, Loss function: 3.057, Average Loss: 4.418, avg. samples / sec: 53282.57
Iteration:   2060, Loss function: 3.977, Average Loss: 4.380, avg. samples / sec: 53309.07
Iteration:   2060, Loss function: 3.568, Average Loss: 4.393, avg. samples / sec: 53390.93
Iteration:   2060, Loss function: 4.239, Average Loss: 4.391, avg. samples / sec: 53242.17
Iteration:   2060, Loss function: 3.798, Average Loss: 4.375, avg. samples / sec: 53270.53
Iteration:   2060, Loss function: 3.995, Average Loss: 4.390, avg. samples / sec: 53129.06
Iteration:   2060, Loss function: 4.324, Average Loss: 4.415, avg. samples / sec: 53289.14
Iteration:   2060, Loss function: 3.785, Average Loss: 4.402, avg. samples / sec: 53278.32
Iteration:   2060, Loss function: 4.614, Average Loss: 4.383, avg. samples / sec: 53258.77
Iteration:   2060, Loss function: 3.720, Average Loss: 4.394, avg. samples / sec: 53238.79
Iteration:   2060, Loss function: 5.474, Average Loss: 4.426, avg. samples / sec: 53249.53
Iteration:   2060, Loss function: 3.411, Average Loss: 4.390, avg. samples / sec: 53186.35
Iteration:   2060, Loss function: 3.839, Average Loss: 4.400, avg. samples / sec: 53247.68
Iteration:   2060, Loss function: 3.614, Average Loss: 4.398, avg. samples / sec: 53219.93
Iteration:   2060, Loss function: 4.090, Average Loss: 4.408, avg. samples / sec: 53164.22
Iteration:   2060, Loss function: 4.664, Average Loss: 4.403, avg. samples / sec: 53240.12
Iteration:   2060, Loss function: 4.586, Average Loss: 4.414, avg. samples / sec: 53076.78
Iteration:   2060, Loss function: 4.885, Average Loss: 4.392, avg. samples / sec: 53271.94
Iteration:   2060, Loss function: 5.021, Average Loss: 4.403, avg. samples / sec: 53093.16
Iteration:   2060, Loss function: 4.222, Average Loss: 4.379, avg. samples / sec: 53268.29
Iteration:   2060, Loss function: 4.841, Average Loss: 4.387, avg. samples / sec: 53327.67
Iteration:   2060, Loss function: 4.627, Average Loss: 4.388, avg. samples / sec: 53287.18
Iteration:   2060, Loss function: 3.726, Average Loss: 4.397, avg. samples / sec: 53253.50
Iteration:   2060, Loss function: 5.898, Average Loss: 4.407, avg. samples / sec: 53266.34
Iteration:   2060, Loss function: 4.022, Average Loss: 4.390, avg. samples / sec: 53204.54
Iteration:   2060, Loss function: 6.095, Average Loss: 4.393, avg. samples / sec: 53266.26
Iteration:   2060, Loss function: 3.886, Average Loss: 4.396, avg. samples / sec: 53267.14
Iteration:   2060, Loss function: 3.674, Average Loss: 4.400, avg. samples / sec: 53248.67
Iteration:   2060, Loss function: 3.423, Average Loss: 4.433, avg. samples / sec: 53227.91
Iteration:   2060, Loss function: 4.393, Average Loss: 4.382, avg. samples / sec: 53274.61
Iteration:   2080, Loss function: 4.130, Average Loss: 4.383, avg. samples / sec: 53359.76
Iteration:   2080, Loss function: 4.589, Average Loss: 4.412, avg. samples / sec: 53309.01
Iteration:   2080, Loss function: 3.938, Average Loss: 4.401, avg. samples / sec: 53435.85
Iteration:   2080, Loss function: 3.523, Average Loss: 4.395, avg. samples / sec: 53412.90
Iteration:   2080, Loss function: 2.921, Average Loss: 4.408, avg. samples / sec: 53351.64
Iteration:   2080, Loss function: 4.098, Average Loss: 4.401, avg. samples / sec: 53413.17
Iteration:   2080, Loss function: 3.942, Average Loss: 4.367, avg. samples / sec: 53329.51
Iteration:   2080, Loss function: 4.295, Average Loss: 4.396, avg. samples / sec: 53315.04
Iteration:   2080, Loss function: 4.143, Average Loss: 4.422, avg. samples / sec: 53362.69
Iteration:   2080, Loss function: 3.927, Average Loss: 4.399, avg. samples / sec: 53350.91
Iteration:   2080, Loss function: 3.805, Average Loss: 4.387, avg. samples / sec: 53378.25
Iteration:   2080, Loss function: 4.252, Average Loss: 4.387, avg. samples / sec: 53332.11
Iteration:   2080, Loss function: 4.620, Average Loss: 4.375, avg. samples / sec: 53276.06
Iteration:   2080, Loss function: 3.874, Average Loss: 4.399, avg. samples / sec: 53407.58
Iteration:   2080, Loss function: 4.185, Average Loss: 4.378, avg. samples / sec: 53338.87
Iteration:   2080, Loss function: 4.878, Average Loss: 4.403, avg. samples / sec: 53524.66
Iteration:   2080, Loss function: 3.778, Average Loss: 4.407, avg. samples / sec: 53513.00
Iteration:   2080, Loss function: 4.328, Average Loss: 4.393, avg. samples / sec: 53307.62
Iteration:   2080, Loss function: 2.641, Average Loss: 4.387, avg. samples / sec: 53405.82
Iteration:   2080, Loss function: 5.154, Average Loss: 4.391, avg. samples / sec: 53389.80
Iteration:   2080, Loss function: 5.415, Average Loss: 4.402, avg. samples / sec: 53404.44
Iteration:   2080, Loss function: 4.702, Average Loss: 4.396, avg. samples / sec: 53371.90
Iteration:   2080, Loss function: 3.697, Average Loss: 4.386, avg. samples / sec: 53344.29
Iteration:   2080, Loss function: 3.515, Average Loss: 4.405, avg. samples / sec: 53368.65
Iteration:   2080, Loss function: 4.218, Average Loss: 4.386, avg. samples / sec: 53357.47
Iteration:   2080, Loss function: 4.796, Average Loss: 4.378, avg. samples / sec: 53336.21
Iteration:   2080, Loss function: 6.089, Average Loss: 4.390, avg. samples / sec: 53325.96
Iteration:   2080, Loss function: 3.662, Average Loss: 4.391, avg. samples / sec: 53345.44
Iteration:   2080, Loss function: 3.935, Average Loss: 4.434, avg. samples / sec: 53383.85
Iteration:   2080, Loss function: 3.983, Average Loss: 4.380, avg. samples / sec: 53376.43
:::MLL 1558641163.976 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558641163.977 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 3.413, Average Loss: 4.376, avg. samples / sec: 53703.17
Iteration:   2100, Loss function: 3.743, Average Loss: 4.396, avg. samples / sec: 53661.99
Iteration:   2100, Loss function: 4.247, Average Loss: 4.390, avg. samples / sec: 53647.52
Iteration:   2100, Loss function: 3.572, Average Loss: 4.384, avg. samples / sec: 53687.23
Iteration:   2100, Loss function: 3.992, Average Loss: 4.405, avg. samples / sec: 53616.71
Iteration:   2100, Loss function: 3.523, Average Loss: 4.370, avg. samples / sec: 53640.77
Iteration:   2100, Loss function: 3.384, Average Loss: 4.402, avg. samples / sec: 53582.21
Iteration:   2100, Loss function: 3.246, Average Loss: 4.389, avg. samples / sec: 53546.61
Iteration:   2100, Loss function: 4.065, Average Loss: 4.414, avg. samples / sec: 53526.27
Iteration:   2100, Loss function: 4.811, Average Loss: 4.381, avg. samples / sec: 53481.15
Iteration:   2100, Loss function: 4.120, Average Loss: 4.399, avg. samples / sec: 53540.87
Iteration:   2100, Loss function: 3.482, Average Loss: 4.408, avg. samples / sec: 53487.87
Iteration:   2100, Loss function: 4.364, Average Loss: 4.383, avg. samples / sec: 53506.47
Iteration:   2100, Loss function: 4.492, Average Loss: 4.368, avg. samples / sec: 53490.43
Iteration:   2100, Loss function: 4.407, Average Loss: 4.390, avg. samples / sec: 53486.73
Iteration:   2100, Loss function: 4.774, Average Loss: 4.388, avg. samples / sec: 53713.26
Iteration:   2100, Loss function: 3.836, Average Loss: 4.430, avg. samples / sec: 53721.19
Iteration:   2100, Loss function: 3.680, Average Loss: 4.397, avg. samples / sec: 53499.65
Iteration:   2100, Loss function: 4.285, Average Loss: 4.378, avg. samples / sec: 53474.33
Iteration:   2100, Loss function: 4.301, Average Loss: 4.385, avg. samples / sec: 53426.07
Iteration:   2100, Loss function: 5.036, Average Loss: 4.390, avg. samples / sec: 53635.38
Iteration:   2100, Loss function: 5.852, Average Loss: 4.388, avg. samples / sec: 53640.32
Iteration:   2100, Loss function: 3.821, Average Loss: 4.395, avg. samples / sec: 53621.76
Iteration:   2100, Loss function: 3.842, Average Loss: 4.371, avg. samples / sec: 53627.40
Iteration:   2100, Loss function: 3.764, Average Loss: 4.379, avg. samples / sec: 53504.81
Iteration:   2100, Loss function: 5.034, Average Loss: 4.382, avg. samples / sec: 53517.36
Iteration:   2100, Loss function: 3.886, Average Loss: 4.402, avg. samples / sec: 53483.95
Iteration:   2100, Loss function: 2.614, Average Loss: 4.383, avg. samples / sec: 53467.17
Iteration:   2100, Loss function: 4.242, Average Loss: 4.372, avg. samples / sec: 53466.91
Iteration:   2100, Loss function: 4.418, Average Loss: 4.389, avg. samples / sec: 53474.84
Iteration:   2120, Loss function: 4.766, Average Loss: 4.408, avg. samples / sec: 53546.50
Iteration:   2120, Loss function: 4.007, Average Loss: 4.374, avg. samples / sec: 53528.79
Iteration:   2120, Loss function: 4.823, Average Loss: 4.414, avg. samples / sec: 53497.70
Iteration:   2120, Loss function: 4.865, Average Loss: 4.362, avg. samples / sec: 53509.34
Iteration:   2120, Loss function: 4.119, Average Loss: 4.382, avg. samples / sec: 53567.35
Iteration:   2120, Loss function: 4.415, Average Loss: 4.389, avg. samples / sec: 53329.59
Iteration:   2120, Loss function: 4.963, Average Loss: 4.405, avg. samples / sec: 53374.13
Iteration:   2120, Loss function: 5.126, Average Loss: 4.385, avg. samples / sec: 53448.66
Iteration:   2120, Loss function: 3.853, Average Loss: 4.372, avg. samples / sec: 53307.64
Iteration:   2120, Loss function: 4.576, Average Loss: 4.394, avg. samples / sec: 53473.91
Iteration:   2120, Loss function: 4.839, Average Loss: 4.399, avg. samples / sec: 53390.08
Iteration:   2120, Loss function: 4.845, Average Loss: 4.384, avg. samples / sec: 53491.20
Iteration:   2120, Loss function: 4.152, Average Loss: 4.383, avg. samples / sec: 53353.72
Iteration:   2120, Loss function: 3.645, Average Loss: 4.372, avg. samples / sec: 53354.24
Iteration:   2120, Loss function: 4.318, Average Loss: 4.372, avg. samples / sec: 53515.29
Iteration:   2120, Loss function: 4.627, Average Loss: 4.373, avg. samples / sec: 53338.27
Iteration:   2120, Loss function: 3.664, Average Loss: 4.392, avg. samples / sec: 53480.06
Iteration:   2120, Loss function: 4.437, Average Loss: 4.381, avg. samples / sec: 53346.37
Iteration:   2120, Loss function: 5.225, Average Loss: 4.389, avg. samples / sec: 53401.79
Iteration:   2120, Loss function: 3.944, Average Loss: 4.372, avg. samples / sec: 53491.95
Iteration:   2120, Loss function: 4.207, Average Loss: 4.378, avg. samples / sec: 53542.70
Iteration:   2120, Loss function: 4.550, Average Loss: 4.387, avg. samples / sec: 53362.79
Iteration:   2120, Loss function: 3.257, Average Loss: 4.377, avg. samples / sec: 53489.25
Iteration:   2120, Loss function: 4.155, Average Loss: 4.400, avg. samples / sec: 53483.04
Iteration:   2120, Loss function: 3.914, Average Loss: 4.384, avg. samples / sec: 53519.91
Iteration:   2120, Loss function: 3.437, Average Loss: 4.395, avg. samples / sec: 53349.98
Iteration:   2120, Loss function: 4.341, Average Loss: 4.370, avg. samples / sec: 53518.99
Iteration:   2120, Loss function: 4.838, Average Loss: 4.425, avg. samples / sec: 53287.12
Iteration:   2120, Loss function: 5.013, Average Loss: 4.361, avg. samples / sec: 53389.29
Iteration:   2120, Loss function: 4.020, Average Loss: 4.384, avg. samples / sec: 53252.73
Iteration:   2140, Loss function: 4.004, Average Loss: 4.387, avg. samples / sec: 53745.36
Iteration:   2140, Loss function: 3.843, Average Loss: 4.405, avg. samples / sec: 53609.30
Iteration:   2140, Loss function: 2.990, Average Loss: 4.407, avg. samples / sec: 53634.40
Iteration:   2140, Loss function: 3.889, Average Loss: 4.359, avg. samples / sec: 53647.30
Iteration:   2140, Loss function: 5.678, Average Loss: 4.392, avg. samples / sec: 53660.21
Iteration:   2140, Loss function: 3.698, Average Loss: 4.365, avg. samples / sec: 53655.63
Iteration:   2140, Loss function: 2.842, Average Loss: 4.370, avg. samples / sec: 53567.30
Iteration:   2140, Loss function: 4.198, Average Loss: 4.405, avg. samples / sec: 53619.48
Iteration:   2140, Loss function: 3.588, Average Loss: 4.393, avg. samples / sec: 53631.44
Iteration:   2140, Loss function: 4.513, Average Loss: 4.385, avg. samples / sec: 53666.12
Iteration:   2140, Loss function: 3.892, Average Loss: 4.374, avg. samples / sec: 53771.53
Iteration:   2140, Loss function: 3.875, Average Loss: 4.374, avg. samples / sec: 53631.80
Iteration:   2140, Loss function: 4.684, Average Loss: 4.365, avg. samples / sec: 53645.71
Iteration:   2140, Loss function: 4.703, Average Loss: 4.382, avg. samples / sec: 53612.71
Iteration:   2140, Loss function: 3.088, Average Loss: 4.380, avg. samples / sec: 53586.72
Iteration:   2140, Loss function: 4.003, Average Loss: 4.383, avg. samples / sec: 53756.27
Iteration:   2140, Loss function: 4.785, Average Loss: 4.380, avg. samples / sec: 53587.45
Iteration:   2140, Loss function: 3.976, Average Loss: 4.372, avg. samples / sec: 53559.87
Iteration:   2140, Loss function: 4.092, Average Loss: 4.381, avg. samples / sec: 53549.47
Iteration:   2140, Loss function: 4.660, Average Loss: 4.380, avg. samples / sec: 53673.98
Iteration:   2140, Loss function: 5.841, Average Loss: 4.368, avg. samples / sec: 53603.71
Iteration:   2140, Loss function: 4.376, Average Loss: 4.385, avg. samples / sec: 53610.79
Iteration:   2140, Loss function: 4.539, Average Loss: 4.374, avg. samples / sec: 53683.43
Iteration:   2140, Loss function: 4.215, Average Loss: 4.386, avg. samples / sec: 53648.93
Iteration:   2140, Loss function: 3.965, Average Loss: 4.366, avg. samples / sec: 53643.91
Iteration:   2140, Loss function: 4.397, Average Loss: 4.373, avg. samples / sec: 53572.46
Iteration:   2140, Loss function: 5.109, Average Loss: 4.370, avg. samples / sec: 53571.58
Iteration:   2140, Loss function: 5.499, Average Loss: 4.396, avg. samples / sec: 53590.30
Iteration:   2140, Loss function: 4.458, Average Loss: 4.422, avg. samples / sec: 53599.96
Iteration:   2140, Loss function: 4.676, Average Loss: 4.361, avg. samples / sec: 53598.66
Iteration:   2160, Loss function: 3.900, Average Loss: 4.387, avg. samples / sec: 53766.79
Iteration:   2160, Loss function: 2.633, Average Loss: 4.353, avg. samples / sec: 53737.47
Iteration:   2160, Loss function: 4.356, Average Loss: 4.405, avg. samples / sec: 53704.22
Iteration:   2160, Loss function: 4.265, Average Loss: 4.363, avg. samples / sec: 53733.19
Iteration:   2160, Loss function: 3.881, Average Loss: 4.370, avg. samples / sec: 53811.54
Iteration:   2160, Loss function: 4.429, Average Loss: 4.377, avg. samples / sec: 53813.25
Iteration:   2160, Loss function: 4.969, Average Loss: 4.364, avg. samples / sec: 53720.84
Iteration:   2160, Loss function: 4.475, Average Loss: 4.401, avg. samples / sec: 53727.78
Iteration:   2160, Loss function: 5.211, Average Loss: 4.390, avg. samples / sec: 53697.18
Iteration:   2160, Loss function: 3.817, Average Loss: 4.374, avg. samples / sec: 53728.21
Iteration:   2160, Loss function: 4.267, Average Loss: 4.376, avg. samples / sec: 53771.49
Iteration:   2160, Loss function: 3.875, Average Loss: 4.368, avg. samples / sec: 53722.80
Iteration:   2160, Loss function: 3.216, Average Loss: 4.360, avg. samples / sec: 53716.68
Iteration:   2160, Loss function: 4.504, Average Loss: 4.380, avg. samples / sec: 53711.05
Iteration:   2160, Loss function: 3.706, Average Loss: 4.381, avg. samples / sec: 53712.05
Iteration:   2160, Loss function: 3.637, Average Loss: 4.387, avg. samples / sec: 53686.07
Iteration:   2160, Loss function: 3.910, Average Loss: 4.382, avg. samples / sec: 53681.84
Iteration:   2160, Loss function: 3.303, Average Loss: 4.401, avg. samples / sec: 53621.13
Iteration:   2160, Loss function: 3.662, Average Loss: 4.381, avg. samples / sec: 53601.27
Iteration:   2160, Loss function: 4.186, Average Loss: 4.362, avg. samples / sec: 53742.90
Iteration:   2160, Loss function: 3.738, Average Loss: 4.383, avg. samples / sec: 53745.20
Iteration:   2160, Loss function: 4.065, Average Loss: 4.388, avg. samples / sec: 53737.06
Iteration:   2160, Loss function: 4.845, Average Loss: 4.373, avg. samples / sec: 53746.53
Iteration:   2160, Loss function: 6.476, Average Loss: 4.364, avg. samples / sec: 53729.30
Iteration:   2160, Loss function: 3.898, Average Loss: 4.361, avg. samples / sec: 53787.49
Iteration:   2160, Loss function: 2.182, Average Loss: 4.379, avg. samples / sec: 53695.58
Iteration:   2160, Loss function: 3.856, Average Loss: 4.422, avg. samples / sec: 53775.39
Iteration:   2160, Loss function: 4.663, Average Loss: 4.370, avg. samples / sec: 53712.24
Iteration:   2160, Loss function: 4.845, Average Loss: 4.397, avg. samples / sec: 53755.24
Iteration:   2160, Loss function: 4.146, Average Loss: 4.372, avg. samples / sec: 53751.22
:::MLL 1558641166.176 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558641166.177 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 3.028, Average Loss: 4.383, avg. samples / sec: 52879.44
Iteration:   2180, Loss function: 3.639, Average Loss: 4.397, avg. samples / sec: 52974.31
Iteration:   2180, Loss function: 3.663, Average Loss: 4.389, avg. samples / sec: 52969.59
Iteration:   2180, Loss function: 3.020, Average Loss: 4.362, avg. samples / sec: 52971.78
Iteration:   2180, Loss function: 4.915, Average Loss: 4.361, avg. samples / sec: 52965.57
Iteration:   2180, Loss function: 3.330, Average Loss: 4.379, avg. samples / sec: 52996.68
Iteration:   2180, Loss function: 5.193, Average Loss: 4.347, avg. samples / sec: 52909.29
Iteration:   2180, Loss function: 4.495, Average Loss: 4.380, avg. samples / sec: 52992.87
Iteration:   2180, Loss function: 5.458, Average Loss: 4.393, avg. samples / sec: 53001.98
Iteration:   2180, Loss function: 5.670, Average Loss: 4.380, avg. samples / sec: 52950.13
Iteration:   2180, Loss function: 4.024, Average Loss: 4.375, avg. samples / sec: 53127.62
Iteration:   2180, Loss function: 4.738, Average Loss: 4.369, avg. samples / sec: 52941.22
Iteration:   2180, Loss function: 3.694, Average Loss: 4.377, avg. samples / sec: 53079.42
Iteration:   2180, Loss function: 3.398, Average Loss: 4.372, avg. samples / sec: 52938.79
Iteration:   2180, Loss function: 4.559, Average Loss: 4.368, avg. samples / sec: 52907.55
Iteration:   2180, Loss function: 3.514, Average Loss: 4.375, avg. samples / sec: 52972.92
Iteration:   2180, Loss function: 4.455, Average Loss: 4.399, avg. samples / sec: 52830.27
Iteration:   2180, Loss function: 4.507, Average Loss: 4.366, avg. samples / sec: 52855.56
Iteration:   2180, Loss function: 4.158, Average Loss: 4.363, avg. samples / sec: 52964.00
Iteration:   2180, Loss function: 3.865, Average Loss: 4.370, avg. samples / sec: 52979.49
Iteration:   2180, Loss function: 5.422, Average Loss: 4.366, avg. samples / sec: 52738.74
Iteration:   2180, Loss function: 3.980, Average Loss: 4.383, avg. samples / sec: 52961.05
Iteration:   2180, Loss function: 4.884, Average Loss: 4.368, avg. samples / sec: 52985.96
Iteration:   2180, Loss function: 3.798, Average Loss: 4.354, avg. samples / sec: 52942.03
Iteration:   2180, Loss function: 3.844, Average Loss: 4.376, avg. samples / sec: 52944.72
Iteration:   2180, Loss function: 4.847, Average Loss: 4.393, avg. samples / sec: 52953.13
Iteration:   2180, Loss function: 3.738, Average Loss: 4.413, avg. samples / sec: 52927.64
Iteration:   2180, Loss function: 3.951, Average Loss: 4.350, avg. samples / sec: 52721.69
Iteration:   2180, Loss function: 4.831, Average Loss: 4.366, avg. samples / sec: 52907.49
Iteration:   2180, Loss function: 2.998, Average Loss: 4.358, avg. samples / sec: 52857.44
Iteration:   2200, Loss function: 3.489, Average Loss: 4.378, avg. samples / sec: 53072.20
Iteration:   2200, Loss function: 3.446, Average Loss: 4.362, avg. samples / sec: 53172.62
Iteration:   2200, Loss function: 3.174, Average Loss: 4.391, avg. samples / sec: 53238.45
Iteration:   2200, Loss function: 3.983, Average Loss: 4.391, avg. samples / sec: 53107.76
Iteration:   2200, Loss function: 3.651, Average Loss: 4.374, avg. samples / sec: 53126.28
Iteration:   2200, Loss function: 5.160, Average Loss: 4.370, avg. samples / sec: 53137.84
Iteration:   2200, Loss function: 3.729, Average Loss: 4.366, avg. samples / sec: 53140.92
Iteration:   2200, Loss function: 4.875, Average Loss: 4.388, avg. samples / sec: 53124.42
Iteration:   2200, Loss function: 2.852, Average Loss: 4.368, avg. samples / sec: 53131.05
Iteration:   2200, Loss function: 5.209, Average Loss: 4.356, avg. samples / sec: 53093.06
Iteration:   2200, Loss function: 4.189, Average Loss: 4.345, avg. samples / sec: 53087.62
Iteration:   2200, Loss function: 4.793, Average Loss: 4.359, avg. samples / sec: 53175.85
Iteration:   2200, Loss function: 3.863, Average Loss: 4.365, avg. samples / sec: 53271.27
Iteration:   2200, Loss function: 4.478, Average Loss: 4.369, avg. samples / sec: 53086.86
Iteration:   2200, Loss function: 3.463, Average Loss: 4.378, avg. samples / sec: 53044.89
Iteration:   2200, Loss function: 3.669, Average Loss: 4.354, avg. samples / sec: 53040.90
Iteration:   2200, Loss function: 3.726, Average Loss: 4.380, avg. samples / sec: 52948.36
Iteration:   2200, Loss function: 4.990, Average Loss: 4.375, avg. samples / sec: 52923.66
Iteration:   2200, Loss function: 4.946, Average Loss: 4.353, avg. samples / sec: 53104.64
Iteration:   2200, Loss function: 4.409, Average Loss: 4.383, avg. samples / sec: 52869.46
Iteration:   2200, Loss function: 5.033, Average Loss: 4.356, avg. samples / sec: 53043.48
Iteration:   2200, Loss function: 3.898, Average Loss: 4.360, avg. samples / sec: 53059.37
Iteration:   2200, Loss function: 3.771, Average Loss: 4.375, avg. samples / sec: 53063.45
Iteration:   2200, Loss function: 4.463, Average Loss: 4.360, avg. samples / sec: 53063.71
Iteration:   2200, Loss function: 3.339, Average Loss: 4.405, avg. samples / sec: 53088.94
Iteration:   2200, Loss function: 3.745, Average Loss: 4.346, avg. samples / sec: 53093.24
Iteration:   2200, Loss function: 3.264, Average Loss: 4.374, avg. samples / sec: 53065.03
Iteration:   2200, Loss function: 5.257, Average Loss: 4.368, avg. samples / sec: 53102.70
Iteration:   2200, Loss function: 4.065, Average Loss: 4.354, avg. samples / sec: 53140.54
Iteration:   2200, Loss function: 4.336, Average Loss: 4.387, avg. samples / sec: 53051.14
Iteration:   2220, Loss function: 4.567, Average Loss: 4.349, avg. samples / sec: 53262.17
Iteration:   2220, Loss function: 3.978, Average Loss: 4.380, avg. samples / sec: 53153.15
Iteration:   2220, Loss function: 3.237, Average Loss: 4.346, avg. samples / sec: 53198.60
Iteration:   2220, Loss function: 4.186, Average Loss: 4.385, avg. samples / sec: 53094.90
Iteration:   2220, Loss function: 5.849, Average Loss: 4.361, avg. samples / sec: 53099.18
Iteration:   2220, Loss function: 3.657, Average Loss: 4.356, avg. samples / sec: 53064.45
Iteration:   2220, Loss function: 4.743, Average Loss: 4.355, avg. samples / sec: 53134.09
Iteration:   2220, Loss function: 4.857, Average Loss: 4.368, avg. samples / sec: 53093.24
Iteration:   2220, Loss function: 5.396, Average Loss: 4.378, avg. samples / sec: 53280.92
Iteration:   2220, Loss function: 4.076, Average Loss: 4.374, avg. samples / sec: 53154.97
Iteration:   2220, Loss function: 4.439, Average Loss: 4.341, avg. samples / sec: 53112.52
Iteration:   2220, Loss function: 4.506, Average Loss: 4.385, avg. samples / sec: 53059.09
Iteration:   2220, Loss function: 3.068, Average Loss: 4.371, avg. samples / sec: 53082.84
Iteration:   2220, Loss function: 3.557, Average Loss: 4.361, avg. samples / sec: 53135.79
Iteration:   2220, Loss function: 3.810, Average Loss: 4.367, avg. samples / sec: 53075.06
Iteration:   2220, Loss function: 4.886, Average Loss: 4.359, avg. samples / sec: 53099.60
Iteration:   2220, Loss function: 3.793, Average Loss: 4.375, avg. samples / sec: 53283.88
Iteration:   2220, Loss function: 4.279, Average Loss: 4.386, avg. samples / sec: 53048.97
Iteration:   2220, Loss function: 4.690, Average Loss: 4.359, avg. samples / sec: 53161.23
Iteration:   2220, Loss function: 5.071, Average Loss: 4.373, avg. samples / sec: 53117.91
Iteration:   2220, Loss function: 2.714, Average Loss: 4.356, avg. samples / sec: 53135.29
Iteration:   2220, Loss function: 4.130, Average Loss: 4.354, avg. samples / sec: 53140.18
Iteration:   2220, Loss function: 4.211, Average Loss: 4.341, avg. samples / sec: 53157.90
Iteration:   2220, Loss function: 3.847, Average Loss: 4.401, avg. samples / sec: 53136.76
Iteration:   2220, Loss function: 4.057, Average Loss: 4.381, avg. samples / sec: 53165.90
Iteration:   2220, Loss function: 3.596, Average Loss: 4.365, avg. samples / sec: 53114.39
Iteration:   2220, Loss function: 5.350, Average Loss: 4.368, avg. samples / sec: 53138.30
Iteration:   2220, Loss function: 4.715, Average Loss: 4.348, avg. samples / sec: 53089.22
Iteration:   2220, Loss function: 4.332, Average Loss: 4.366, avg. samples / sec: 53119.03
Iteration:   2220, Loss function: 2.424, Average Loss: 4.350, avg. samples / sec: 53116.29
:::MLL 1558641168.390 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558641168.391 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 4.041, Average Loss: 4.353, avg. samples / sec: 53185.00
Iteration:   2240, Loss function: 3.741, Average Loss: 4.381, avg. samples / sec: 53161.33
Iteration:   2240, Loss function: 4.020, Average Loss: 4.357, avg. samples / sec: 53141.95
Iteration:   2240, Loss function: 2.850, Average Loss: 4.360, avg. samples / sec: 53153.93
Iteration:   2240, Loss function: 4.116, Average Loss: 4.352, avg. samples / sec: 53122.17
Iteration:   2240, Loss function: 3.829, Average Loss: 4.376, avg. samples / sec: 52997.64
Iteration:   2240, Loss function: 4.250, Average Loss: 4.351, avg. samples / sec: 53089.70
Iteration:   2240, Loss function: 4.282, Average Loss: 4.376, avg. samples / sec: 53111.82
Iteration:   2240, Loss function: 5.547, Average Loss: 4.369, avg. samples / sec: 53057.98
Iteration:   2240, Loss function: 3.523, Average Loss: 4.335, avg. samples / sec: 53007.84
Iteration:   2240, Loss function: 4.614, Average Loss: 4.378, avg. samples / sec: 53049.45
Iteration:   2240, Loss function: 4.175, Average Loss: 4.350, avg. samples / sec: 53024.26
Iteration:   2240, Loss function: 5.071, Average Loss: 4.344, avg. samples / sec: 52867.49
Iteration:   2240, Loss function: 3.803, Average Loss: 4.377, avg. samples / sec: 53011.21
Iteration:   2240, Loss function: 3.975, Average Loss: 4.333, avg. samples / sec: 53008.10
Iteration:   2240, Loss function: 4.712, Average Loss: 4.366, avg. samples / sec: 52998.85
Iteration:   2240, Loss function: 4.235, Average Loss: 4.371, avg. samples / sec: 53040.64
Iteration:   2240, Loss function: 4.600, Average Loss: 4.350, avg. samples / sec: 53190.52
Iteration:   2240, Loss function: 4.939, Average Loss: 4.364, avg. samples / sec: 53213.16
Iteration:   2240, Loss function: 4.182, Average Loss: 4.370, avg. samples / sec: 53169.55
Iteration:   2240, Loss function: 3.944, Average Loss: 4.369, avg. samples / sec: 52972.34
Iteration:   2240, Loss function: 3.681, Average Loss: 4.393, avg. samples / sec: 53103.30
Iteration:   2240, Loss function: 4.988, Average Loss: 4.340, avg. samples / sec: 53070.32
Iteration:   2240, Loss function: 4.633, Average Loss: 4.357, avg. samples / sec: 53020.71
Iteration:   2240, Loss function: 3.643, Average Loss: 4.359, avg. samples / sec: 53080.02
Iteration:   2240, Loss function: 5.526, Average Loss: 4.353, avg. samples / sec: 53042.18
Iteration:   2240, Loss function: 4.792, Average Loss: 4.367, avg. samples / sec: 53082.62
Iteration:   2240, Loss function: 3.540, Average Loss: 4.344, avg. samples / sec: 53046.57
Iteration:   2240, Loss function: 3.089, Average Loss: 4.374, avg. samples / sec: 53015.10
Iteration:   2240, Loss function: 4.242, Average Loss: 4.345, avg. samples / sec: 53048.51
Iteration:   2260, Loss function: 4.318, Average Loss: 4.372, avg. samples / sec: 53095.96
Iteration:   2260, Loss function: 5.295, Average Loss: 4.368, avg. samples / sec: 53084.92
Iteration:   2260, Loss function: 5.621, Average Loss: 4.349, avg. samples / sec: 52930.66
Iteration:   2260, Loss function: 3.090, Average Loss: 4.370, avg. samples / sec: 53113.09
Iteration:   2260, Loss function: 4.373, Average Loss: 4.382, avg. samples / sec: 52930.38
Iteration:   2260, Loss function: 4.493, Average Loss: 4.359, avg. samples / sec: 52978.91
Iteration:   2260, Loss function: 4.660, Average Loss: 4.339, avg. samples / sec: 53082.20
Iteration:   2260, Loss function: 3.982, Average Loss: 4.334, avg. samples / sec: 53098.28
Iteration:   2260, Loss function: 3.937, Average Loss: 4.361, avg. samples / sec: 53124.02
Iteration:   2260, Loss function: 4.086, Average Loss: 4.375, avg. samples / sec: 53076.66
Iteration:   2260, Loss function: 3.848, Average Loss: 4.372, avg. samples / sec: 53020.17
Iteration:   2260, Loss function: 3.731, Average Loss: 4.357, avg. samples / sec: 53014.52
Iteration:   2260, Loss function: 4.678, Average Loss: 4.366, avg. samples / sec: 53019.45
Iteration:   2260, Loss function: 4.779, Average Loss: 4.330, avg. samples / sec: 53026.81
Iteration:   2260, Loss function: 4.333, Average Loss: 4.365, avg. samples / sec: 53066.87
Iteration:   2260, Loss function: 4.641, Average Loss: 4.353, avg. samples / sec: 52918.23
Iteration:   2260, Loss function: 4.887, Average Loss: 4.344, avg. samples / sec: 53028.09
Iteration:   2260, Loss function: 3.631, Average Loss: 4.342, avg. samples / sec: 52878.92
Iteration:   2260, Loss function: 4.792, Average Loss: 4.358, avg. samples / sec: 53090.84
Iteration:   2260, Loss function: 3.426, Average Loss: 4.371, avg. samples / sec: 52943.74
Iteration:   2260, Loss function: 3.983, Average Loss: 4.349, avg. samples / sec: 52914.26
Iteration:   2260, Loss function: 5.089, Average Loss: 4.351, avg. samples / sec: 53047.67
Iteration:   2260, Loss function: 3.641, Average Loss: 4.368, avg. samples / sec: 53087.56
Iteration:   2260, Loss function: 4.132, Average Loss: 4.367, avg. samples / sec: 53042.16
Iteration:   2260, Loss function: 3.852, Average Loss: 4.338, avg. samples / sec: 53008.52
Iteration:   2260, Loss function: 3.973, Average Loss: 4.363, avg. samples / sec: 52876.38
Iteration:   2260, Loss function: 4.142, Average Loss: 4.391, avg. samples / sec: 52976.26
Iteration:   2260, Loss function: 4.000, Average Loss: 4.343, avg. samples / sec: 53046.89
Iteration:   2260, Loss function: 4.357, Average Loss: 4.356, avg. samples / sec: 53001.68
Iteration:   2260, Loss function: 2.588, Average Loss: 4.341, avg. samples / sec: 53014.12
Iteration:   2280, Loss function: 5.007, Average Loss: 4.367, avg. samples / sec: 53277.78
Iteration:   2280, Loss function: 3.707, Average Loss: 4.363, avg. samples / sec: 53349.98
Iteration:   2280, Loss function: 3.721, Average Loss: 4.357, avg. samples / sec: 53270.81
Iteration:   2280, Loss function: 4.439, Average Loss: 4.325, avg. samples / sec: 53248.71
Iteration:   2280, Loss function: 4.860, Average Loss: 4.354, avg. samples / sec: 53242.41
Iteration:   2280, Loss function: 4.936, Average Loss: 4.366, avg. samples / sec: 53174.45
Iteration:   2280, Loss function: 3.168, Average Loss: 4.338, avg. samples / sec: 53315.57
Iteration:   2280, Loss function: 4.584, Average Loss: 4.355, avg. samples / sec: 53205.49
Iteration:   2280, Loss function: 5.035, Average Loss: 4.364, avg. samples / sec: 53218.14
Iteration:   2280, Loss function: 4.367, Average Loss: 4.356, avg. samples / sec: 53189.82
Iteration:   2280, Loss function: 2.807, Average Loss: 4.368, avg. samples / sec: 53202.97
Iteration:   2280, Loss function: 3.903, Average Loss: 4.365, avg. samples / sec: 53169.69
Iteration:   2280, Loss function: 4.203, Average Loss: 4.330, avg. samples / sec: 53184.76
Iteration:   2280, Loss function: 4.371, Average Loss: 4.345, avg. samples / sec: 53160.81
Iteration:   2280, Loss function: 4.089, Average Loss: 4.332, avg. samples / sec: 53177.84
Iteration:   2280, Loss function: 4.573, Average Loss: 4.379, avg. samples / sec: 53172.54
Iteration:   2280, Loss function: 4.685, Average Loss: 4.350, avg. samples / sec: 53363.07
Iteration:   2280, Loss function: 2.935, Average Loss: 4.363, avg. samples / sec: 53175.03
Iteration:   2280, Loss function: 2.781, Average Loss: 4.339, avg. samples / sec: 53191.67
Iteration:   2280, Loss function: 4.945, Average Loss: 4.357, avg. samples / sec: 53184.22
Iteration:   2280, Loss function: 4.234, Average Loss: 4.365, avg. samples / sec: 53175.81
Iteration:   2280, Loss function: 3.908, Average Loss: 4.344, avg. samples / sec: 53204.78
Iteration:   2280, Loss function: 4.104, Average Loss: 4.370, avg. samples / sec: 53206.75
Iteration:   2280, Loss function: 4.756, Average Loss: 4.343, avg. samples / sec: 53223.93
Iteration:   2280, Loss function: 5.557, Average Loss: 4.382, avg. samples / sec: 53221.16
Iteration:   2280, Loss function: 3.882, Average Loss: 4.363, avg. samples / sec: 53211.55
Iteration:   2280, Loss function: 3.900, Average Loss: 4.339, avg. samples / sec: 53205.53
Iteration:   2280, Loss function: 3.805, Average Loss: 4.350, avg. samples / sec: 53225.72
Iteration:   2280, Loss function: 4.799, Average Loss: 4.358, avg. samples / sec: 53186.77
Iteration:   2280, Loss function: 3.852, Average Loss: 4.336, avg. samples / sec: 53251.38
:::MLL 1558641169.870 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 1.10 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.56s)
DONE (t=0.59s)
DONE (t=2.73s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.15918
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.29979
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.15642
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03817
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.16332
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.25838
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.17322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.25578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26933
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06996
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.28108
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.42207
Current AP: 0.15918 AP goal: 0.23000
:::MLL 1558641174.258 eval_accuracy: {"value": 0.15918096640253898, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558641174.368 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558641174.374 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558641174.374 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 4.182, Average Loss: 4.357, avg. samples / sec: 6494.05
Iteration:   2300, Loss function: 3.537, Average Loss: 4.327, avg. samples / sec: 6491.84
Iteration:   2300, Loss function: 3.906, Average Loss: 4.344, avg. samples / sec: 6493.98
Iteration:   2300, Loss function: 4.073, Average Loss: 4.357, avg. samples / sec: 6489.25
Iteration:   2300, Loss function: 3.635, Average Loss: 4.355, avg. samples / sec: 6488.85
Iteration:   2300, Loss function: 4.248, Average Loss: 4.356, avg. samples / sec: 6488.70
Iteration:   2300, Loss function: 3.475, Average Loss: 4.354, avg. samples / sec: 6488.31
Iteration:   2300, Loss function: 3.945, Average Loss: 4.355, avg. samples / sec: 6488.73
Iteration:   2300, Loss function: 4.424, Average Loss: 4.339, avg. samples / sec: 6488.63
Iteration:   2300, Loss function: 3.746, Average Loss: 4.362, avg. samples / sec: 6489.06
Iteration:   2300, Loss function: 3.269, Average Loss: 4.329, avg. samples / sec: 6488.20
Iteration:   2300, Loss function: 3.379, Average Loss: 4.363, avg. samples / sec: 6485.49
Iteration:   2300, Loss function: 3.835, Average Loss: 4.322, avg. samples / sec: 6487.82
Iteration:   2300, Loss function: 4.510, Average Loss: 4.351, avg. samples / sec: 6487.79
Iteration:   2300, Loss function: 4.912, Average Loss: 4.362, avg. samples / sec: 6491.17
Iteration:   2300, Loss function: 5.035, Average Loss: 4.356, avg. samples / sec: 6487.59
Iteration:   2300, Loss function: 3.692, Average Loss: 4.365, avg. samples / sec: 6485.44
Iteration:   2300, Loss function: 3.380, Average Loss: 4.364, avg. samples / sec: 6490.37
Iteration:   2300, Loss function: 5.634, Average Loss: 4.340, avg. samples / sec: 6488.89
Iteration:   2300, Loss function: 4.074, Average Loss: 4.359, avg. samples / sec: 6488.09
Iteration:   2300, Loss function: 4.777, Average Loss: 4.348, avg. samples / sec: 6485.44
Iteration:   2300, Loss function: 3.943, Average Loss: 4.335, avg. samples / sec: 6488.34
Iteration:   2300, Loss function: 4.154, Average Loss: 4.365, avg. samples / sec: 6485.02
Iteration:   2300, Loss function: 3.793, Average Loss: 4.324, avg. samples / sec: 6484.92
Iteration:   2300, Loss function: 4.367, Average Loss: 4.375, avg. samples / sec: 6484.91
Iteration:   2300, Loss function: 4.484, Average Loss: 4.329, avg. samples / sec: 6484.48
Iteration:   2300, Loss function: 3.735, Average Loss: 4.378, avg. samples / sec: 6487.62
Iteration:   2300, Loss function: 3.205, Average Loss: 4.347, avg. samples / sec: 6487.64
Iteration:   2300, Loss function: 3.588, Average Loss: 4.346, avg. samples / sec: 6487.18
Iteration:   2300, Loss function: 3.504, Average Loss: 4.333, avg. samples / sec: 6487.15
:::MLL 1558641175.151 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558641175.152 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 3.910, Average Loss: 4.357, avg. samples / sec: 53354.32
Iteration:   2320, Loss function: 4.547, Average Loss: 4.320, avg. samples / sec: 53367.23
Iteration:   2320, Loss function: 3.885, Average Loss: 4.338, avg. samples / sec: 53375.46
Iteration:   2320, Loss function: 4.941, Average Loss: 4.342, avg. samples / sec: 53416.85
Iteration:   2320, Loss function: 4.541, Average Loss: 4.354, avg. samples / sec: 53382.70
Iteration:   2320, Loss function: 3.691, Average Loss: 4.344, avg. samples / sec: 53390.00
Iteration:   2320, Loss function: 4.979, Average Loss: 4.313, avg. samples / sec: 53387.45
Iteration:   2320, Loss function: 5.241, Average Loss: 4.349, avg. samples / sec: 53435.59
Iteration:   2320, Loss function: 4.407, Average Loss: 4.353, avg. samples / sec: 53367.76
Iteration:   2320, Loss function: 4.733, Average Loss: 4.356, avg. samples / sec: 53369.84
Iteration:   2320, Loss function: 4.652, Average Loss: 4.359, avg. samples / sec: 53328.56
Iteration:   2320, Loss function: 4.563, Average Loss: 4.348, avg. samples / sec: 53400.80
Iteration:   2320, Loss function: 5.878, Average Loss: 4.362, avg. samples / sec: 53445.86
Iteration:   2320, Loss function: 3.637, Average Loss: 4.325, avg. samples / sec: 53360.18
Iteration:   2320, Loss function: 3.912, Average Loss: 4.361, avg. samples / sec: 53422.44
Iteration:   2320, Loss function: 3.308, Average Loss: 4.365, avg. samples / sec: 53357.23
Iteration:   2320, Loss function: 3.623, Average Loss: 4.355, avg. samples / sec: 53394.17
Iteration:   2320, Loss function: 3.956, Average Loss: 4.350, avg. samples / sec: 53217.04
Iteration:   2320, Loss function: 4.837, Average Loss: 4.324, avg. samples / sec: 53415.90
Iteration:   2320, Loss function: 4.907, Average Loss: 4.343, avg. samples / sec: 53399.30
Iteration:   2320, Loss function: 4.066, Average Loss: 4.369, avg. samples / sec: 53417.26
Iteration:   2320, Loss function: 3.854, Average Loss: 4.332, avg. samples / sec: 53386.52
Iteration:   2320, Loss function: 5.660, Average Loss: 4.336, avg. samples / sec: 53466.77
Iteration:   2320, Loss function: 4.467, Average Loss: 4.376, avg. samples / sec: 53407.44
Iteration:   2320, Loss function: 4.473, Average Loss: 4.321, avg. samples / sec: 53402.87
Iteration:   2320, Loss function: 3.976, Average Loss: 4.341, avg. samples / sec: 53441.36
Iteration:   2320, Loss function: 4.430, Average Loss: 4.353, avg. samples / sec: 53341.96
Iteration:   2320, Loss function: 4.513, Average Loss: 4.359, avg. samples / sec: 53355.25
Iteration:   2320, Loss function: 4.514, Average Loss: 4.335, avg. samples / sec: 53298.69
Iteration:   2320, Loss function: 4.057, Average Loss: 4.339, avg. samples / sec: 53382.27
Iteration:   2340, Loss function: 5.193, Average Loss: 4.322, avg. samples / sec: 53992.66
Iteration:   2340, Loss function: 3.504, Average Loss: 4.335, avg. samples / sec: 54002.49
Iteration:   2340, Loss function: 3.048, Average Loss: 4.347, avg. samples / sec: 53966.32
Iteration:   2340, Loss function: 3.430, Average Loss: 4.338, avg. samples / sec: 53983.91
Iteration:   2340, Loss function: 3.417, Average Loss: 4.355, avg. samples / sec: 54005.18
Iteration:   2340, Loss function: 3.562, Average Loss: 4.344, avg. samples / sec: 53970.91
Iteration:   2340, Loss function: 5.048, Average Loss: 4.368, avg. samples / sec: 54023.44
Iteration:   2340, Loss function: 4.160, Average Loss: 4.308, avg. samples / sec: 53979.57
Iteration:   2340, Loss function: 3.311, Average Loss: 4.345, avg. samples / sec: 53927.97
Iteration:   2340, Loss function: 3.483, Average Loss: 4.319, avg. samples / sec: 53963.14
Iteration:   2340, Loss function: 3.819, Average Loss: 4.358, avg. samples / sec: 53964.46
Iteration:   2340, Loss function: 4.214, Average Loss: 4.350, avg. samples / sec: 53932.18
Iteration:   2340, Loss function: 3.766, Average Loss: 4.350, avg. samples / sec: 53952.62
Iteration:   2340, Loss function: 4.902, Average Loss: 4.343, avg. samples / sec: 53923.78
Iteration:   2340, Loss function: 4.212, Average Loss: 4.357, avg. samples / sec: 53925.76
Iteration:   2340, Loss function: 4.712, Average Loss: 4.345, avg. samples / sec: 53888.81
Iteration:   2340, Loss function: 3.409, Average Loss: 4.348, avg. samples / sec: 54039.64
Iteration:   2340, Loss function: 4.814, Average Loss: 4.318, avg. samples / sec: 53967.58
Iteration:   2340, Loss function: 3.949, Average Loss: 4.355, avg. samples / sec: 54012.55
Iteration:   2340, Loss function: 4.237, Average Loss: 4.319, avg. samples / sec: 53983.62
Iteration:   2340, Loss function: 3.728, Average Loss: 4.373, avg. samples / sec: 53977.15
Iteration:   2340, Loss function: 3.409, Average Loss: 4.331, avg. samples / sec: 53955.10
Iteration:   2340, Loss function: 3.852, Average Loss: 4.335, avg. samples / sec: 53990.47
Iteration:   2340, Loss function: 5.831, Average Loss: 4.344, avg. samples / sec: 53926.11
Iteration:   2340, Loss function: 3.695, Average Loss: 4.350, avg. samples / sec: 53679.50
Iteration:   2340, Loss function: 4.627, Average Loss: 4.365, avg. samples / sec: 53905.16
Iteration:   2340, Loss function: 3.100, Average Loss: 4.335, avg. samples / sec: 53940.60
Iteration:   2340, Loss function: 4.581, Average Loss: 4.339, avg. samples / sec: 53972.21
Iteration:   2340, Loss function: 3.815, Average Loss: 4.342, avg. samples / sec: 53646.36
Iteration:   2340, Loss function: 4.483, Average Loss: 4.335, avg. samples / sec: 53884.87
Iteration:   2360, Loss function: 4.296, Average Loss: 4.336, avg. samples / sec: 53886.69
Iteration:   2360, Loss function: 3.378, Average Loss: 4.316, avg. samples / sec: 53858.72
Iteration:   2360, Loss function: 3.329, Average Loss: 4.333, avg. samples / sec: 53804.74
Iteration:   2360, Loss function: 3.087, Average Loss: 4.340, avg. samples / sec: 54091.24
Iteration:   2360, Loss function: 4.320, Average Loss: 4.305, avg. samples / sec: 53885.68
Iteration:   2360, Loss function: 5.167, Average Loss: 4.348, avg. samples / sec: 54178.95
Iteration:   2360, Loss function: 3.869, Average Loss: 4.334, avg. samples / sec: 54205.09
Iteration:   2360, Loss function: 4.013, Average Loss: 4.350, avg. samples / sec: 53858.37
Iteration:   2360, Loss function: 4.522, Average Loss: 4.339, avg. samples / sec: 53850.55
Iteration:   2360, Loss function: 4.668, Average Loss: 4.336, avg. samples / sec: 53803.66
Iteration:   2360, Loss function: 4.057, Average Loss: 4.355, avg. samples / sec: 53910.93
Iteration:   2360, Loss function: 4.530, Average Loss: 4.358, avg. samples / sec: 53825.13
Iteration:   2360, Loss function: 3.447, Average Loss: 4.315, avg. samples / sec: 53872.74
Iteration:   2360, Loss function: 3.377, Average Loss: 4.340, avg. samples / sec: 53852.51
Iteration:   2360, Loss function: 3.486, Average Loss: 4.342, avg. samples / sec: 53875.52
Iteration:   2360, Loss function: 3.510, Average Loss: 4.344, avg. samples / sec: 53865.45
Iteration:   2360, Loss function: 3.852, Average Loss: 4.351, avg. samples / sec: 53832.37
Iteration:   2360, Loss function: 5.613, Average Loss: 4.343, avg. samples / sec: 53877.73
Iteration:   2360, Loss function: 3.892, Average Loss: 4.335, avg. samples / sec: 53935.28
Iteration:   2360, Loss function: 4.503, Average Loss: 4.313, avg. samples / sec: 53867.49
Iteration:   2360, Loss function: 3.284, Average Loss: 4.337, avg. samples / sec: 53707.41
Iteration:   2360, Loss function: 4.682, Average Loss: 4.361, avg. samples / sec: 53939.40
Iteration:   2360, Loss function: 4.849, Average Loss: 4.331, avg. samples / sec: 53903.40
Iteration:   2360, Loss function: 3.513, Average Loss: 4.350, avg. samples / sec: 53863.72
Iteration:   2360, Loss function: 4.314, Average Loss: 4.330, avg. samples / sec: 53945.25
Iteration:   2360, Loss function: 5.006, Average Loss: 4.336, avg. samples / sec: 53906.74
Iteration:   2360, Loss function: 4.099, Average Loss: 4.317, avg. samples / sec: 53848.08
Iteration:   2360, Loss function: 3.729, Average Loss: 4.331, avg. samples / sec: 53890.17
Iteration:   2360, Loss function: 4.080, Average Loss: 4.329, avg. samples / sec: 53844.38
Iteration:   2360, Loss function: 3.533, Average Loss: 4.366, avg. samples / sec: 53829.61
:::MLL 1558641177.338 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558641177.339 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 3.557, Average Loss: 4.311, avg. samples / sec: 53483.87
Iteration:   2380, Loss function: 4.960, Average Loss: 4.328, avg. samples / sec: 53445.21
Iteration:   2380, Loss function: 3.769, Average Loss: 4.327, avg. samples / sec: 53470.68
Iteration:   2380, Loss function: 3.492, Average Loss: 4.337, avg. samples / sec: 53580.07
Iteration:   2380, Loss function: 4.075, Average Loss: 4.312, avg. samples / sec: 53593.22
Iteration:   2380, Loss function: 3.399, Average Loss: 4.355, avg. samples / sec: 53581.74
Iteration:   2380, Loss function: 4.062, Average Loss: 4.336, avg. samples / sec: 53594.64
Iteration:   2380, Loss function: 4.102, Average Loss: 4.335, avg. samples / sec: 53413.84
Iteration:   2380, Loss function: 3.862, Average Loss: 4.332, avg. samples / sec: 53454.90
Iteration:   2380, Loss function: 3.176, Average Loss: 4.329, avg. samples / sec: 53489.29
Iteration:   2380, Loss function: 3.859, Average Loss: 4.343, avg. samples / sec: 53427.65
Iteration:   2380, Loss function: 4.618, Average Loss: 4.341, avg. samples / sec: 53422.75
Iteration:   2380, Loss function: 3.430, Average Loss: 4.306, avg. samples / sec: 53403.94
Iteration:   2380, Loss function: 3.552, Average Loss: 4.337, avg. samples / sec: 53478.31
Iteration:   2380, Loss function: 4.183, Average Loss: 4.332, avg. samples / sec: 53393.07
Iteration:   2380, Loss function: 4.365, Average Loss: 4.346, avg. samples / sec: 53467.09
Iteration:   2380, Loss function: 3.787, Average Loss: 4.344, avg. samples / sec: 53400.28
Iteration:   2380, Loss function: 3.525, Average Loss: 4.309, avg. samples / sec: 53555.17
Iteration:   2380, Loss function: 4.864, Average Loss: 4.348, avg. samples / sec: 53554.66
Iteration:   2380, Loss function: 3.668, Average Loss: 4.351, avg. samples / sec: 53529.15
Iteration:   2380, Loss function: 4.331, Average Loss: 4.316, avg. samples / sec: 53574.13
Iteration:   2380, Loss function: 3.840, Average Loss: 4.340, avg. samples / sec: 53495.28
Iteration:   2380, Loss function: 3.729, Average Loss: 4.323, avg. samples / sec: 53556.01
Iteration:   2380, Loss function: 4.392, Average Loss: 4.327, avg. samples / sec: 53546.79
Iteration:   2380, Loss function: 4.361, Average Loss: 4.330, avg. samples / sec: 53406.65
Iteration:   2380, Loss function: 2.792, Average Loss: 4.325, avg. samples / sec: 53431.27
Iteration:   2380, Loss function: 4.154, Average Loss: 4.328, avg. samples / sec: 53438.51
Iteration:   2380, Loss function: 4.924, Average Loss: 4.334, avg. samples / sec: 53374.81
Iteration:   2380, Loss function: 5.068, Average Loss: 4.322, avg. samples / sec: 53402.93
Iteration:   2380, Loss function: 4.616, Average Loss: 4.355, avg. samples / sec: 53382.31
Iteration:   2400, Loss function: 4.432, Average Loss: 4.330, avg. samples / sec: 53853.37
Iteration:   2400, Loss function: 2.624, Average Loss: 4.310, avg. samples / sec: 53804.62
Iteration:   2400, Loss function: 3.118, Average Loss: 4.317, avg. samples / sec: 53873.61
Iteration:   2400, Loss function: 4.511, Average Loss: 4.304, avg. samples / sec: 53746.16
Iteration:   2400, Loss function: 4.571, Average Loss: 4.330, avg. samples / sec: 53741.34
Iteration:   2400, Loss function: 4.318, Average Loss: 4.337, avg. samples / sec: 53921.74
Iteration:   2400, Loss function: 4.020, Average Loss: 4.329, avg. samples / sec: 53728.44
Iteration:   2400, Loss function: 4.963, Average Loss: 4.329, avg. samples / sec: 53842.14
Iteration:   2400, Loss function: 3.398, Average Loss: 4.321, avg. samples / sec: 53827.62
Iteration:   2400, Loss function: 3.657, Average Loss: 4.337, avg. samples / sec: 53843.23
Iteration:   2400, Loss function: 3.686, Average Loss: 4.347, avg. samples / sec: 53717.03
Iteration:   2400, Loss function: 4.915, Average Loss: 4.334, avg. samples / sec: 53844.15
Iteration:   2400, Loss function: 3.506, Average Loss: 4.303, avg. samples / sec: 53838.21
Iteration:   2400, Loss function: 4.386, Average Loss: 4.323, avg. samples / sec: 53847.18
Iteration:   2400, Loss function: 4.427, Average Loss: 4.344, avg. samples / sec: 53848.53
Iteration:   2400, Loss function: 3.774, Average Loss: 4.330, avg. samples / sec: 53711.30
Iteration:   2400, Loss function: 3.523, Average Loss: 4.334, avg. samples / sec: 53899.38
Iteration:   2400, Loss function: 3.224, Average Loss: 4.340, avg. samples / sec: 53794.00
Iteration:   2400, Loss function: 4.068, Average Loss: 4.311, avg. samples / sec: 53751.92
Iteration:   2400, Loss function: 3.051, Average Loss: 4.341, avg. samples / sec: 53635.01
Iteration:   2400, Loss function: 5.442, Average Loss: 4.330, avg. samples / sec: 53871.11
Iteration:   2400, Loss function: 5.982, Average Loss: 4.331, avg. samples / sec: 53908.99
Iteration:   2400, Loss function: 4.109, Average Loss: 4.348, avg. samples / sec: 53762.30
Iteration:   2400, Loss function: 4.872, Average Loss: 4.310, avg. samples / sec: 53755.61
Iteration:   2400, Loss function: 3.442, Average Loss: 4.318, avg. samples / sec: 53761.78
Iteration:   2400, Loss function: 2.993, Average Loss: 4.350, avg. samples / sec: 53953.69
Iteration:   2400, Loss function: 3.582, Average Loss: 4.320, avg. samples / sec: 53842.20
Iteration:   2400, Loss function: 3.481, Average Loss: 4.320, avg. samples / sec: 53749.22
Iteration:   2400, Loss function: 3.894, Average Loss: 4.324, avg. samples / sec: 53873.50
Iteration:   2400, Loss function: 2.658, Average Loss: 4.323, avg. samples / sec: 53835.29
Iteration:   2420, Loss function: 3.968, Average Loss: 4.316, avg. samples / sec: 53872.33
Iteration:   2420, Loss function: 5.121, Average Loss: 4.328, avg. samples / sec: 53832.41
Iteration:   2420, Loss function: 4.483, Average Loss: 4.329, avg. samples / sec: 54051.33
Iteration:   2420, Loss function: 3.821, Average Loss: 4.313, avg. samples / sec: 53765.52
Iteration:   2420, Loss function: 3.783, Average Loss: 4.327, avg. samples / sec: 53885.99
Iteration:   2420, Loss function: 3.816, Average Loss: 4.320, avg. samples / sec: 53905.26
Iteration:   2420, Loss function: 4.703, Average Loss: 4.299, avg. samples / sec: 53904.45
Iteration:   2420, Loss function: 3.895, Average Loss: 4.325, avg. samples / sec: 53865.35
Iteration:   2420, Loss function: 3.940, Average Loss: 4.319, avg. samples / sec: 53909.36
Iteration:   2420, Loss function: 4.241, Average Loss: 4.330, avg. samples / sec: 53877.85
Iteration:   2420, Loss function: 5.117, Average Loss: 4.330, avg. samples / sec: 53856.77
Iteration:   2420, Loss function: 4.282, Average Loss: 4.301, avg. samples / sec: 53832.47
Iteration:   2420, Loss function: 4.450, Average Loss: 4.342, avg. samples / sec: 54061.53
Iteration:   2420, Loss function: 3.649, Average Loss: 4.326, avg. samples / sec: 53861.27
Iteration:   2420, Loss function: 3.799, Average Loss: 4.332, avg. samples / sec: 53833.27
Iteration:   2420, Loss function: 4.036, Average Loss: 4.343, avg. samples / sec: 53849.97
Iteration:   2420, Loss function: 4.408, Average Loss: 4.349, avg. samples / sec: 53809.86
Iteration:   2420, Loss function: 3.730, Average Loss: 4.345, avg. samples / sec: 53997.46
Iteration:   2420, Loss function: 3.783, Average Loss: 4.307, avg. samples / sec: 53868.87
Iteration:   2420, Loss function: 4.399, Average Loss: 4.332, avg. samples / sec: 53866.44
Iteration:   2420, Loss function: 5.238, Average Loss: 4.329, avg. samples / sec: 53857.24
Iteration:   2420, Loss function: 5.442, Average Loss: 4.333, avg. samples / sec: 53725.28
Iteration:   2420, Loss function: 3.979, Average Loss: 4.311, avg. samples / sec: 53885.66
Iteration:   2420, Loss function: 5.222, Average Loss: 4.348, avg. samples / sec: 53876.18
Iteration:   2420, Loss function: 4.405, Average Loss: 4.340, avg. samples / sec: 53803.47
Iteration:   2420, Loss function: 4.058, Average Loss: 4.303, avg. samples / sec: 53825.23
Iteration:   2420, Loss function: 3.557, Average Loss: 4.318, avg. samples / sec: 53884.26
Iteration:   2420, Loss function: 4.364, Average Loss: 4.312, avg. samples / sec: 53872.19
Iteration:   2420, Loss function: 3.879, Average Loss: 4.317, avg. samples / sec: 53821.43
Iteration:   2420, Loss function: 4.511, Average Loss: 4.327, avg. samples / sec: 53783.25
Iteration:   2440, Loss function: 5.066, Average Loss: 4.309, avg. samples / sec: 53961.57
Iteration:   2440, Loss function: 4.644, Average Loss: 4.324, avg. samples / sec: 53845.06
Iteration:   2440, Loss function: 4.453, Average Loss: 4.313, avg. samples / sec: 53805.32
Iteration:   2440, Loss function: 3.374, Average Loss: 4.325, avg. samples / sec: 53840.96
Iteration:   2440, Loss function: 3.940, Average Loss: 4.322, avg. samples / sec: 53855.16
Iteration:   2440, Loss function: 4.840, Average Loss: 4.299, avg. samples / sec: 53861.21
Iteration:   2440, Loss function: 4.577, Average Loss: 4.322, avg. samples / sec: 53867.78
Iteration:   2440, Loss function: 4.638, Average Loss: 4.296, avg. samples / sec: 53882.55
Iteration:   2440, Loss function: 4.628, Average Loss: 4.319, avg. samples / sec: 53823.90
Iteration:   2440, Loss function: 4.969, Average Loss: 4.345, avg. samples / sec: 53911.65
Iteration:   2440, Loss function: 4.606, Average Loss: 4.324, avg. samples / sec: 53838.04
Iteration:   2440, Loss function: 5.061, Average Loss: 4.341, avg. samples / sec: 53896.74
Iteration:   2440, Loss function: 4.346, Average Loss: 4.320, avg. samples / sec: 53821.66
Iteration:   2440, Loss function: 3.934, Average Loss: 4.325, avg. samples / sec: 53855.86
Iteration:   2440, Loss function: 4.631, Average Loss: 4.339, avg. samples / sec: 53838.87
Iteration:   2440, Loss function: 4.645, Average Loss: 4.316, avg. samples / sec: 53801.36
Iteration:   2440, Loss function: 5.005, Average Loss: 4.324, avg. samples / sec: 53812.22
Iteration:   2440, Loss function: 4.101, Average Loss: 4.326, avg. samples / sec: 53867.14
Iteration:   2440, Loss function: 4.132, Average Loss: 4.340, avg. samples / sec: 53887.90
Iteration:   2440, Loss function: 4.164, Average Loss: 4.320, avg. samples / sec: 53866.54
Iteration:   2440, Loss function: 4.192, Average Loss: 4.312, avg. samples / sec: 53870.19
Iteration:   2440, Loss function: 3.328, Average Loss: 4.327, avg. samples / sec: 53866.26
Iteration:   2440, Loss function: 4.914, Average Loss: 4.341, avg. samples / sec: 53710.05
Iteration:   2440, Loss function: 3.457, Average Loss: 4.301, avg. samples / sec: 53848.70
Iteration:   2440, Loss function: 4.633, Average Loss: 4.301, avg. samples / sec: 53829.30
Iteration:   2440, Loss function: 3.768, Average Loss: 4.346, avg. samples / sec: 53837.32
Iteration:   2440, Loss function: 2.101, Average Loss: 4.317, avg. samples / sec: 53841.05
Iteration:   2440, Loss function: 3.979, Average Loss: 4.308, avg. samples / sec: 53845.90
Iteration:   2440, Loss function: 4.189, Average Loss: 4.314, avg. samples / sec: 53855.18
Iteration:   2440, Loss function: 3.779, Average Loss: 4.319, avg. samples / sec: 53912.21
:::MLL 1558641179.528 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558641179.529 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.858, Average Loss: 4.308, avg. samples / sec: 53355.23
Iteration:   2460, Loss function: 4.487, Average Loss: 4.307, avg. samples / sec: 53366.34
Iteration:   2460, Loss function: 3.197, Average Loss: 4.316, avg. samples / sec: 53403.25
Iteration:   2460, Loss function: 2.907, Average Loss: 4.319, avg. samples / sec: 53268.69
Iteration:   2460, Loss function: 3.617, Average Loss: 4.331, avg. samples / sec: 53390.65
Iteration:   2460, Loss function: 5.882, Average Loss: 4.317, avg. samples / sec: 53366.20
Iteration:   2460, Loss function: 4.246, Average Loss: 4.291, avg. samples / sec: 53309.82
Iteration:   2460, Loss function: 3.946, Average Loss: 4.317, avg. samples / sec: 53300.55
Iteration:   2460, Loss function: 5.915, Average Loss: 4.318, avg. samples / sec: 53346.20
Iteration:   2460, Loss function: 3.982, Average Loss: 4.307, avg. samples / sec: 53366.04
Iteration:   2460, Loss function: 5.203, Average Loss: 4.314, avg. samples / sec: 53312.10
Iteration:   2460, Loss function: 3.172, Average Loss: 4.318, avg. samples / sec: 53376.53
Iteration:   2460, Loss function: 4.185, Average Loss: 4.319, avg. samples / sec: 53285.73
Iteration:   2460, Loss function: 4.644, Average Loss: 4.292, avg. samples / sec: 53287.36
Iteration:   2460, Loss function: 3.192, Average Loss: 4.339, avg. samples / sec: 53310.51
Iteration:   2460, Loss function: 3.822, Average Loss: 4.318, avg. samples / sec: 53308.85
Iteration:   2460, Loss function: 3.772, Average Loss: 4.335, avg. samples / sec: 53292.50
Iteration:   2460, Loss function: 3.615, Average Loss: 4.325, avg. samples / sec: 53479.35
Iteration:   2460, Loss function: 3.783, Average Loss: 4.318, avg. samples / sec: 53326.64
Iteration:   2460, Loss function: 4.700, Average Loss: 4.320, avg. samples / sec: 53327.89
Iteration:   2460, Loss function: 4.466, Average Loss: 4.299, avg. samples / sec: 53347.03
Iteration:   2460, Loss function: 5.968, Average Loss: 4.336, avg. samples / sec: 53309.22
Iteration:   2460, Loss function: 4.765, Average Loss: 4.335, avg. samples / sec: 53320.55
Iteration:   2460, Loss function: 4.209, Average Loss: 4.311, avg. samples / sec: 53283.40
Iteration:   2460, Loss function: 5.697, Average Loss: 4.311, avg. samples / sec: 53352.24
Iteration:   2460, Loss function: 4.570, Average Loss: 4.300, avg. samples / sec: 53312.62
Iteration:   2460, Loss function: 5.384, Average Loss: 4.340, avg. samples / sec: 53320.45
Iteration:   2460, Loss function: 4.847, Average Loss: 4.305, avg. samples / sec: 53332.56
Iteration:   2460, Loss function: 4.115, Average Loss: 4.316, avg. samples / sec: 53325.11
Iteration:   2460, Loss function: 4.680, Average Loss: 4.315, avg. samples / sec: 53343.76
Iteration:   2480, Loss function: 3.817, Average Loss: 4.303, avg. samples / sec: 53647.08
Iteration:   2480, Loss function: 3.903, Average Loss: 4.304, avg. samples / sec: 53603.29
Iteration:   2480, Loss function: 3.973, Average Loss: 4.316, avg. samples / sec: 53680.38
Iteration:   2480, Loss function: 2.903, Average Loss: 4.306, avg. samples / sec: 53605.55
Iteration:   2480, Loss function: 3.822, Average Loss: 4.306, avg. samples / sec: 53690.71
Iteration:   2480, Loss function: 4.121, Average Loss: 4.286, avg. samples / sec: 53653.16
Iteration:   2480, Loss function: 4.741, Average Loss: 4.309, avg. samples / sec: 53648.91
Iteration:   2480, Loss function: 4.769, Average Loss: 4.317, avg. samples / sec: 53665.03
Iteration:   2480, Loss function: 3.880, Average Loss: 4.331, avg. samples / sec: 53686.60
Iteration:   2480, Loss function: 4.368, Average Loss: 4.314, avg. samples / sec: 53634.29
Iteration:   2480, Loss function: 3.711, Average Loss: 4.313, avg. samples / sec: 53607.45
Iteration:   2480, Loss function: 4.161, Average Loss: 4.285, avg. samples / sec: 53624.48
Iteration:   2480, Loss function: 5.162, Average Loss: 4.310, avg. samples / sec: 53597.90
Iteration:   2480, Loss function: 4.122, Average Loss: 4.334, avg. samples / sec: 53627.64
Iteration:   2480, Loss function: 4.345, Average Loss: 4.316, avg. samples / sec: 53634.07
Iteration:   2480, Loss function: 3.414, Average Loss: 4.324, avg. samples / sec: 53432.20
Iteration:   2480, Loss function: 4.701, Average Loss: 4.308, avg. samples / sec: 53652.08
Iteration:   2480, Loss function: 3.678, Average Loss: 4.302, avg. samples / sec: 53693.90
Iteration:   2480, Loss function: 4.764, Average Loss: 4.333, avg. samples / sec: 53672.88
Iteration:   2480, Loss function: 3.600, Average Loss: 4.336, avg. samples / sec: 53644.65
Iteration:   2480, Loss function: 4.941, Average Loss: 4.308, avg. samples / sec: 53663.27
Iteration:   2480, Loss function: 4.218, Average Loss: 4.317, avg. samples / sec: 53620.15
Iteration:   2480, Loss function: 4.346, Average Loss: 4.325, avg. samples / sec: 53450.32
Iteration:   2480, Loss function: 4.829, Average Loss: 4.293, avg. samples / sec: 53620.34
Iteration:   2480, Loss function: 4.445, Average Loss: 4.298, avg. samples / sec: 53650.30
Iteration:   2480, Loss function: 4.947, Average Loss: 4.302, avg. samples / sec: 53664.24
Iteration:   2480, Loss function: 3.018, Average Loss: 4.308, avg. samples / sec: 53661.05
Iteration:   2480, Loss function: 3.166, Average Loss: 4.334, avg. samples / sec: 53621.13
Iteration:   2480, Loss function: 4.155, Average Loss: 4.299, avg. samples / sec: 53627.05
Iteration:   2480, Loss function: 4.277, Average Loss: 4.305, avg. samples / sec: 53341.28
Iteration:   2500, Loss function: 3.261, Average Loss: 4.309, avg. samples / sec: 53784.03
Iteration:   2500, Loss function: 3.716, Average Loss: 4.299, avg. samples / sec: 53692.41
Iteration:   2500, Loss function: 4.474, Average Loss: 4.306, avg. samples / sec: 53869.16
Iteration:   2500, Loss function: 3.765, Average Loss: 4.296, avg. samples / sec: 53699.75
Iteration:   2500, Loss function: 3.790, Average Loss: 4.304, avg. samples / sec: 53638.66
Iteration:   2500, Loss function: 3.477, Average Loss: 4.300, avg. samples / sec: 53725.61
Iteration:   2500, Loss function: 3.834, Average Loss: 4.282, avg. samples / sec: 53725.02
Iteration:   2500, Loss function: 3.878, Average Loss: 4.314, avg. samples / sec: 53743.00
Iteration:   2500, Loss function: 3.848, Average Loss: 4.300, avg. samples / sec: 54051.28
Iteration:   2500, Loss function: 2.758, Average Loss: 4.301, avg. samples / sec: 53714.59
Iteration:   2500, Loss function: 4.356, Average Loss: 4.313, avg. samples / sec: 53774.36
Iteration:   2500, Loss function: 3.916, Average Loss: 4.329, avg. samples / sec: 53777.21
Iteration:   2500, Loss function: 3.968, Average Loss: 4.306, avg. samples / sec: 54001.49
Iteration:   2500, Loss function: 4.058, Average Loss: 4.309, avg. samples / sec: 53737.43
Iteration:   2500, Loss function: 3.519, Average Loss: 4.312, avg. samples / sec: 53762.09
Iteration:   2500, Loss function: 2.950, Average Loss: 4.275, avg. samples / sec: 53731.49
Iteration:   2500, Loss function: 4.093, Average Loss: 4.325, avg. samples / sec: 53697.85
Iteration:   2500, Loss function: 3.708, Average Loss: 4.315, avg. samples / sec: 53727.70
Iteration:   2500, Loss function: 5.610, Average Loss: 4.291, avg. samples / sec: 53790.25
Iteration:   2500, Loss function: 3.471, Average Loss: 4.296, avg. samples / sec: 53742.16
Iteration:   2500, Loss function: 5.128, Average Loss: 4.301, avg. samples / sec: 53729.93
Iteration:   2500, Loss function: 3.939, Average Loss: 4.306, avg. samples / sec: 53769.39
Iteration:   2500, Loss function: 3.849, Average Loss: 4.328, avg. samples / sec: 53738.72
Iteration:   2500, Loss function: 2.904, Average Loss: 4.323, avg. samples / sec: 53760.31
Iteration:   2500, Loss function: 4.205, Average Loss: 4.298, avg. samples / sec: 53769.97
Iteration:   2500, Loss function: 2.447, Average Loss: 4.331, avg. samples / sec: 53792.20
Iteration:   2500, Loss function: 3.934, Average Loss: 4.305, avg. samples / sec: 53756.60
Iteration:   2500, Loss function: 5.048, Average Loss: 4.309, avg. samples / sec: 53725.77
Iteration:   2500, Loss function: 4.332, Average Loss: 4.331, avg. samples / sec: 53711.03
Iteration:   2500, Loss function: 4.081, Average Loss: 4.295, avg. samples / sec: 53761.85
:::MLL 1558641181.722 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558641181.723 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 3.201, Average Loss: 4.298, avg. samples / sec: 53488.28
Iteration:   2520, Loss function: 4.113, Average Loss: 4.300, avg. samples / sec: 53331.71
Iteration:   2520, Loss function: 3.369, Average Loss: 4.290, avg. samples / sec: 53358.04
Iteration:   2520, Loss function: 3.719, Average Loss: 4.294, avg. samples / sec: 53402.16
Iteration:   2520, Loss function: 4.102, Average Loss: 4.310, avg. samples / sec: 53438.00
Iteration:   2520, Loss function: 4.742, Average Loss: 4.305, avg. samples / sec: 53340.85
Iteration:   2520, Loss function: 3.600, Average Loss: 4.326, avg. samples / sec: 53366.00
Iteration:   2520, Loss function: 3.276, Average Loss: 4.295, avg. samples / sec: 53324.79
Iteration:   2520, Loss function: 3.039, Average Loss: 4.292, avg. samples / sec: 53349.05
Iteration:   2520, Loss function: 5.073, Average Loss: 4.322, avg. samples / sec: 53383.08
Iteration:   2520, Loss function: 4.987, Average Loss: 4.317, avg. samples / sec: 53559.08
Iteration:   2520, Loss function: 4.672, Average Loss: 4.306, avg. samples / sec: 53315.00
Iteration:   2520, Loss function: 4.207, Average Loss: 4.276, avg. samples / sec: 53351.15
Iteration:   2520, Loss function: 5.216, Average Loss: 4.305, avg. samples / sec: 53312.99
Iteration:   2520, Loss function: 3.613, Average Loss: 4.296, avg. samples / sec: 53305.32
Iteration:   2520, Loss function: 4.536, Average Loss: 4.304, avg. samples / sec: 53312.87
Iteration:   2520, Loss function: 3.310, Average Loss: 4.289, avg. samples / sec: 53563.58
Iteration:   2520, Loss function: 2.955, Average Loss: 4.280, avg. samples / sec: 53254.70
Iteration:   2520, Loss function: 4.073, Average Loss: 4.300, avg. samples / sec: 53263.48
Iteration:   2520, Loss function: 3.867, Average Loss: 4.285, avg. samples / sec: 53439.36
Iteration:   2520, Loss function: 3.858, Average Loss: 4.288, avg. samples / sec: 53442.70
Iteration:   2520, Loss function: 3.872, Average Loss: 4.325, avg. samples / sec: 53428.29
Iteration:   2520, Loss function: 4.713, Average Loss: 4.301, avg. samples / sec: 53400.84
Iteration:   2520, Loss function: 4.890, Average Loss: 4.303, avg. samples / sec: 53427.30
Iteration:   2520, Loss function: 3.576, Average Loss: 4.325, avg. samples / sec: 53405.19
Iteration:   2520, Loss function: 3.984, Average Loss: 4.309, avg. samples / sec: 53324.85
Iteration:   2520, Loss function: 4.359, Average Loss: 4.293, avg. samples / sec: 53336.96
Iteration:   2520, Loss function: 3.380, Average Loss: 4.323, avg. samples / sec: 53342.27
Iteration:   2520, Loss function: 5.001, Average Loss: 4.291, avg. samples / sec: 53315.71
Iteration:   2520, Loss function: 4.391, Average Loss: 4.299, avg. samples / sec: 53319.72
Iteration:   2540, Loss function: 4.075, Average Loss: 4.295, avg. samples / sec: 53572.13
Iteration:   2540, Loss function: 3.638, Average Loss: 4.296, avg. samples / sec: 53609.71
Iteration:   2540, Loss function: 3.706, Average Loss: 4.290, avg. samples / sec: 53597.29
Iteration:   2540, Loss function: 4.014, Average Loss: 4.303, avg. samples / sec: 53553.95
Iteration:   2540, Loss function: 3.031, Average Loss: 4.291, avg. samples / sec: 53622.03
Iteration:   2540, Loss function: 4.054, Average Loss: 4.307, avg. samples / sec: 53521.88
Iteration:   2540, Loss function: 3.563, Average Loss: 4.294, avg. samples / sec: 53683.63
Iteration:   2540, Loss function: 3.880, Average Loss: 4.320, avg. samples / sec: 53598.78
Iteration:   2540, Loss function: 3.809, Average Loss: 4.269, avg. samples / sec: 53629.19
Iteration:   2540, Loss function: 4.290, Average Loss: 4.286, avg. samples / sec: 53648.06
Iteration:   2540, Loss function: 3.307, Average Loss: 4.294, avg. samples / sec: 53583.21
Iteration:   2540, Loss function: 3.333, Average Loss: 4.277, avg. samples / sec: 53660.17
Iteration:   2540, Loss function: 3.662, Average Loss: 4.301, avg. samples / sec: 53638.25
Iteration:   2540, Loss function: 4.337, Average Loss: 4.301, avg. samples / sec: 53599.72
Iteration:   2540, Loss function: 2.608, Average Loss: 4.295, avg. samples / sec: 53629.80
Iteration:   2540, Loss function: 3.469, Average Loss: 4.320, avg. samples / sec: 53541.15
Iteration:   2540, Loss function: 4.230, Average Loss: 4.296, avg. samples / sec: 53355.03
Iteration:   2540, Loss function: 2.866, Average Loss: 4.290, avg. samples / sec: 53581.89
Iteration:   2540, Loss function: 4.388, Average Loss: 4.280, avg. samples / sec: 53515.56
Iteration:   2540, Loss function: 3.948, Average Loss: 4.301, avg. samples / sec: 53606.55
Iteration:   2540, Loss function: 5.149, Average Loss: 4.324, avg. samples / sec: 53617.40
Iteration:   2540, Loss function: 4.905, Average Loss: 4.294, avg. samples / sec: 53540.83
Iteration:   2540, Loss function: 4.326, Average Loss: 4.290, avg. samples / sec: 53586.88
Iteration:   2540, Loss function: 4.897, Average Loss: 4.323, avg. samples / sec: 53559.26
Iteration:   2540, Loss function: 4.725, Average Loss: 4.315, avg. samples / sec: 53364.02
Iteration:   2540, Loss function: 4.648, Average Loss: 4.288, avg. samples / sec: 53475.19
Iteration:   2540, Loss function: 3.662, Average Loss: 4.317, avg. samples / sec: 53491.20
Iteration:   2540, Loss function: 4.411, Average Loss: 4.294, avg. samples / sec: 53597.27
Iteration:   2540, Loss function: 3.162, Average Loss: 4.287, avg. samples / sec: 53552.06
Iteration:   2540, Loss function: 4.468, Average Loss: 4.294, avg. samples / sec: 53360.73
Iteration:   2560, Loss function: 4.848, Average Loss: 4.293, avg. samples / sec: 53552.34
Iteration:   2560, Loss function: 4.227, Average Loss: 4.290, avg. samples / sec: 53508.20
Iteration:   2560, Loss function: 3.702, Average Loss: 4.297, avg. samples / sec: 53574.47
Iteration:   2560, Loss function: 3.764, Average Loss: 4.289, avg. samples / sec: 53626.95
Iteration:   2560, Loss function: 3.379, Average Loss: 4.289, avg. samples / sec: 53582.23
Iteration:   2560, Loss function: 4.383, Average Loss: 4.292, avg. samples / sec: 53633.74
Iteration:   2560, Loss function: 5.628, Average Loss: 4.305, avg. samples / sec: 53564.35
Iteration:   2560, Loss function: 4.088, Average Loss: 4.291, avg. samples / sec: 53577.10
Iteration:   2560, Loss function: 4.200, Average Loss: 4.285, avg. samples / sec: 53868.52
Iteration:   2560, Loss function: 4.918, Average Loss: 4.280, avg. samples / sec: 53575.57
Iteration:   2560, Loss function: 3.486, Average Loss: 4.268, avg. samples / sec: 53586.49
Iteration:   2560, Loss function: 4.590, Average Loss: 4.262, avg. samples / sec: 53566.49
Iteration:   2560, Loss function: 4.625, Average Loss: 4.324, avg. samples / sec: 53800.51
Iteration:   2560, Loss function: 4.092, Average Loss: 4.311, avg. samples / sec: 53592.28
Iteration:   2560, Loss function: 3.738, Average Loss: 4.309, avg. samples / sec: 53550.19
Iteration:   2560, Loss function: 3.156, Average Loss: 4.290, avg. samples / sec: 53563.17
Iteration:   2560, Loss function: 3.764, Average Loss: 4.288, avg. samples / sec: 53553.95
Iteration:   2560, Loss function: 4.550, Average Loss: 4.292, avg. samples / sec: 53619.40
Iteration:   2560, Loss function: 5.299, Average Loss: 4.309, avg. samples / sec: 53625.29
Iteration:   2560, Loss function: 5.645, Average Loss: 4.276, avg. samples / sec: 53570.07
Iteration:   2560, Loss function: 3.575, Average Loss: 4.285, avg. samples / sec: 53224.98
Iteration:   2560, Loss function: 4.271, Average Loss: 4.296, avg. samples / sec: 53574.37
Iteration:   2560, Loss function: 4.724, Average Loss: 4.284, avg. samples / sec: 53538.69
Iteration:   2560, Loss function: 4.563, Average Loss: 4.284, avg. samples / sec: 53579.30
Iteration:   2560, Loss function: 4.919, Average Loss: 4.315, avg. samples / sec: 53592.79
Iteration:   2560, Loss function: 3.126, Average Loss: 4.281, avg. samples / sec: 53579.16
Iteration:   2560, Loss function: 3.065, Average Loss: 4.315, avg. samples / sec: 53552.40
Iteration:   2560, Loss function: 4.420, Average Loss: 4.278, avg. samples / sec: 53608.87
Iteration:   2560, Loss function: 3.931, Average Loss: 4.292, avg. samples / sec: 53571.34
Iteration:   2560, Loss function: 3.282, Average Loss: 4.288, avg. samples / sec: 53460.84
Iteration:   2580, Loss function: 3.920, Average Loss: 4.287, avg. samples / sec: 53619.15
Iteration:   2580, Loss function: 3.368, Average Loss: 4.287, avg. samples / sec: 53542.88
Iteration:   2580, Loss function: 3.378, Average Loss: 4.282, avg. samples / sec: 53765.66
Iteration:   2580, Loss function: 2.859, Average Loss: 4.290, avg. samples / sec: 53573.56
Iteration:   2580, Loss function: 3.163, Average Loss: 4.303, avg. samples / sec: 53599.29
Iteration:   2580, Loss function: 4.073, Average Loss: 4.280, avg. samples / sec: 53533.00
Iteration:   2580, Loss function: 4.499, Average Loss: 4.280, avg. samples / sec: 53529.36
Iteration:   2580, Loss function: 4.106, Average Loss: 4.297, avg. samples / sec: 53550.17
Iteration:   2580, Loss function: 4.213, Average Loss: 4.320, avg. samples / sec: 53580.44
Iteration:   2580, Loss function: 4.236, Average Loss: 4.284, avg. samples / sec: 53555.01
Iteration:   2580, Loss function: 3.896, Average Loss: 4.263, avg. samples / sec: 53568.38
Iteration:   2580, Loss function: 4.789, Average Loss: 4.292, avg. samples / sec: 53594.42
Iteration:   2580, Loss function: 4.059, Average Loss: 4.305, avg. samples / sec: 53578.55
Iteration:   2580, Loss function: 2.672, Average Loss: 4.291, avg. samples / sec: 53502.17
Iteration:   2580, Loss function: 4.107, Average Loss: 4.287, avg. samples / sec: 53523.22
Iteration:   2580, Loss function: 4.679, Average Loss: 4.272, avg. samples / sec: 53548.21
Iteration:   2580, Loss function: 4.186, Average Loss: 4.285, avg. samples / sec: 53577.61
Iteration:   2580, Loss function: 4.272, Average Loss: 4.261, avg. samples / sec: 53531.70
Iteration:   2580, Loss function: 4.046, Average Loss: 4.281, avg. samples / sec: 53594.52
Iteration:   2580, Loss function: 4.115, Average Loss: 4.303, avg. samples / sec: 53567.77
Iteration:   2580, Loss function: 3.935, Average Loss: 4.283, avg. samples / sec: 53562.09
Iteration:   2580, Loss function: 3.973, Average Loss: 4.276, avg. samples / sec: 53546.97
Iteration:   2580, Loss function: 3.350, Average Loss: 4.276, avg. samples / sec: 53583.29
Iteration:   2580, Loss function: 4.873, Average Loss: 4.293, avg. samples / sec: 53544.63
Iteration:   2580, Loss function: 3.930, Average Loss: 4.283, avg. samples / sec: 53689.87
Iteration:   2580, Loss function: 3.535, Average Loss: 4.312, avg. samples / sec: 53568.99
Iteration:   2580, Loss function: 4.114, Average Loss: 4.273, avg. samples / sec: 53589.67
Iteration:   2580, Loss function: 3.156, Average Loss: 4.275, avg. samples / sec: 53576.88
Iteration:   2580, Loss function: 3.561, Average Loss: 4.293, avg. samples / sec: 53570.89
Iteration:   2580, Loss function: 2.343, Average Loss: 4.310, avg. samples / sec: 53399.53
:::MLL 1558641183.920 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558641183.921 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 4.706, Average Loss: 4.283, avg. samples / sec: 53371.21
Iteration:   2600, Loss function: 5.177, Average Loss: 4.284, avg. samples / sec: 53249.95
Iteration:   2600, Loss function: 3.712, Average Loss: 4.273, avg. samples / sec: 53257.02
Iteration:   2600, Loss function: 3.878, Average Loss: 4.285, avg. samples / sec: 53367.58
Iteration:   2600, Loss function: 3.889, Average Loss: 4.284, avg. samples / sec: 53372.12
Iteration:   2600, Loss function: 3.168, Average Loss: 4.257, avg. samples / sec: 53398.41
Iteration:   2600, Loss function: 2.972, Average Loss: 4.283, avg. samples / sec: 53350.77
Iteration:   2600, Loss function: 4.804, Average Loss: 4.277, avg. samples / sec: 53342.17
Iteration:   2600, Loss function: 4.773, Average Loss: 4.254, avg. samples / sec: 53338.27
Iteration:   2600, Loss function: 4.168, Average Loss: 4.300, avg. samples / sec: 53317.85
Iteration:   2600, Loss function: 4.190, Average Loss: 4.273, avg. samples / sec: 53322.93
Iteration:   2600, Loss function: 2.974, Average Loss: 4.263, avg. samples / sec: 53338.35
Iteration:   2600, Loss function: 4.726, Average Loss: 4.320, avg. samples / sec: 53312.56
Iteration:   2600, Loss function: 2.839, Average Loss: 4.274, avg. samples / sec: 53292.34
Iteration:   2600, Loss function: 3.870, Average Loss: 4.279, avg. samples / sec: 53304.38
Iteration:   2600, Loss function: 4.014, Average Loss: 4.282, avg. samples / sec: 53297.88
Iteration:   2600, Loss function: 3.071, Average Loss: 4.296, avg. samples / sec: 53299.13
Iteration:   2600, Loss function: 3.136, Average Loss: 4.274, avg. samples / sec: 53313.95
Iteration:   2600, Loss function: 3.814, Average Loss: 4.270, avg. samples / sec: 53375.48
Iteration:   2600, Loss function: 4.308, Average Loss: 4.292, avg. samples / sec: 53344.35
Iteration:   2600, Loss function: 3.660, Average Loss: 4.280, avg. samples / sec: 53333.30
Iteration:   2600, Loss function: 3.820, Average Loss: 4.287, avg. samples / sec: 53366.04
Iteration:   2600, Loss function: 3.373, Average Loss: 4.274, avg. samples / sec: 53361.09
Iteration:   2600, Loss function: 5.110, Average Loss: 4.282, avg. samples / sec: 53344.59
Iteration:   2600, Loss function: 3.453, Average Loss: 4.303, avg. samples / sec: 53527.02
Iteration:   2600, Loss function: 4.438, Average Loss: 4.271, avg. samples / sec: 53345.66
Iteration:   2600, Loss function: 3.635, Average Loss: 4.310, avg. samples / sec: 53343.90
Iteration:   2600, Loss function: 4.622, Average Loss: 4.277, avg. samples / sec: 53311.84
Iteration:   2600, Loss function: 2.729, Average Loss: 4.283, avg. samples / sec: 53336.55
Iteration:   2600, Loss function: 3.655, Average Loss: 4.276, avg. samples / sec: 53219.97
Iteration:   2620, Loss function: 2.558, Average Loss: 4.282, avg. samples / sec: 53426.71
Iteration:   2620, Loss function: 5.343, Average Loss: 4.277, avg. samples / sec: 53509.34
Iteration:   2620, Loss function: 5.065, Average Loss: 4.279, avg. samples / sec: 53455.80
Iteration:   2620, Loss function: 4.689, Average Loss: 4.269, avg. samples / sec: 53482.82
Iteration:   2620, Loss function: 5.098, Average Loss: 4.274, avg. samples / sec: 53450.04
Iteration:   2620, Loss function: 3.411, Average Loss: 4.271, avg. samples / sec: 53494.94
Iteration:   2620, Loss function: 4.320, Average Loss: 4.256, avg. samples / sec: 53425.62
Iteration:   2620, Loss function: 4.981, Average Loss: 4.279, avg. samples / sec: 53475.76
Iteration:   2620, Loss function: 3.645, Average Loss: 4.249, avg. samples / sec: 53430.46
Iteration:   2620, Loss function: 4.386, Average Loss: 4.270, avg. samples / sec: 53475.19
Iteration:   2620, Loss function: 3.963, Average Loss: 4.264, avg. samples / sec: 53327.13
Iteration:   2620, Loss function: 4.392, Average Loss: 4.260, avg. samples / sec: 53426.21
Iteration:   2620, Loss function: 3.477, Average Loss: 4.292, avg. samples / sec: 53402.14
Iteration:   2620, Loss function: 3.645, Average Loss: 4.280, avg. samples / sec: 53352.04
Iteration:   2620, Loss function: 3.471, Average Loss: 4.285, avg. samples / sec: 53426.65
Iteration:   2620, Loss function: 3.629, Average Loss: 4.316, avg. samples / sec: 53399.32
Iteration:   2620, Loss function: 3.184, Average Loss: 4.278, avg. samples / sec: 53314.08
Iteration:   2620, Loss function: 4.222, Average Loss: 4.282, avg. samples / sec: 53444.79
Iteration:   2620, Loss function: 3.974, Average Loss: 4.279, avg. samples / sec: 53419.81
Iteration:   2620, Loss function: 3.595, Average Loss: 4.272, avg. samples / sec: 53408.63
Iteration:   2620, Loss function: 4.414, Average Loss: 4.273, avg. samples / sec: 53399.73
Iteration:   2620, Loss function: 4.824, Average Loss: 4.270, avg. samples / sec: 53368.30
Iteration:   2620, Loss function: 3.900, Average Loss: 4.305, avg. samples / sec: 53405.74
Iteration:   2620, Loss function: 3.141, Average Loss: 4.278, avg. samples / sec: 53452.57
Iteration:   2620, Loss function: 5.331, Average Loss: 4.293, avg. samples / sec: 53359.43
Iteration:   2620, Loss function: 4.610, Average Loss: 4.274, avg. samples / sec: 53516.59
Iteration:   2620, Loss function: 3.821, Average Loss: 4.272, avg. samples / sec: 53399.57
Iteration:   2620, Loss function: 5.118, Average Loss: 4.268, avg. samples / sec: 53363.98
Iteration:   2620, Loss function: 4.427, Average Loss: 4.273, avg. samples / sec: 53170.36
Iteration:   2620, Loss function: 4.384, Average Loss: 4.293, avg. samples / sec: 53349.17
Iteration:   2640, Loss function: 3.931, Average Loss: 4.279, avg. samples / sec: 53720.90
Iteration:   2640, Loss function: 3.151, Average Loss: 4.270, avg. samples / sec: 53530.80
Iteration:   2640, Loss function: 4.390, Average Loss: 4.276, avg. samples / sec: 53504.77
Iteration:   2640, Loss function: 3.462, Average Loss: 4.262, avg. samples / sec: 53710.33
Iteration:   2640, Loss function: 4.394, Average Loss: 4.279, avg. samples / sec: 53598.54
Iteration:   2640, Loss function: 4.411, Average Loss: 4.313, avg. samples / sec: 53608.10
Iteration:   2640, Loss function: 4.775, Average Loss: 4.268, avg. samples / sec: 53851.21
Iteration:   2640, Loss function: 3.897, Average Loss: 4.268, avg. samples / sec: 53502.78
Iteration:   2640, Loss function: 4.732, Average Loss: 4.260, avg. samples / sec: 53528.14
Iteration:   2640, Loss function: 3.471, Average Loss: 4.285, avg. samples / sec: 53591.61
Iteration:   2640, Loss function: 4.317, Average Loss: 4.273, avg. samples / sec: 53636.66
Iteration:   2640, Loss function: 3.775, Average Loss: 4.255, avg. samples / sec: 53507.83
Iteration:   2640, Loss function: 3.385, Average Loss: 4.256, avg. samples / sec: 53540.30
Iteration:   2640, Loss function: 3.656, Average Loss: 4.288, avg. samples / sec: 53537.94
Iteration:   2640, Loss function: 4.342, Average Loss: 4.265, avg. samples / sec: 53504.89
Iteration:   2640, Loss function: 3.821, Average Loss: 4.268, avg. samples / sec: 53477.68
Iteration:   2640, Loss function: 4.600, Average Loss: 4.272, avg. samples / sec: 53446.43
Iteration:   2640, Loss function: 3.388, Average Loss: 4.248, avg. samples / sec: 53489.19
Iteration:   2640, Loss function: 4.478, Average Loss: 4.278, avg. samples / sec: 53689.87
Iteration:   2640, Loss function: 4.104, Average Loss: 4.277, avg. samples / sec: 53536.82
Iteration:   2640, Loss function: 3.977, Average Loss: 4.268, avg. samples / sec: 53559.93
Iteration:   2640, Loss function: 3.307, Average Loss: 4.295, avg. samples / sec: 53596.91
Iteration:   2640, Loss function: 3.426, Average Loss: 4.270, avg. samples / sec: 53555.05
Iteration:   2640, Loss function: 4.556, Average Loss: 4.274, avg. samples / sec: 53534.97
Iteration:   2640, Loss function: 4.254, Average Loss: 4.265, avg. samples / sec: 53552.65
Iteration:   2640, Loss function: 3.999, Average Loss: 4.270, avg. samples / sec: 53575.53
Iteration:   2640, Loss function: 3.618, Average Loss: 4.301, avg. samples / sec: 53535.76
Iteration:   2640, Loss function: 4.651, Average Loss: 4.292, avg. samples / sec: 53581.91
Iteration:   2640, Loss function: 4.056, Average Loss: 4.266, avg. samples / sec: 53549.37
Iteration:   2640, Loss function: 3.162, Average Loss: 4.258, avg. samples / sec: 53539.44
:::MLL 1558641186.121 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558641186.121 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 4.068, Average Loss: 4.263, avg. samples / sec: 53322.18
Iteration:   2660, Loss function: 2.844, Average Loss: 4.275, avg. samples / sec: 53328.48
Iteration:   2660, Loss function: 3.833, Average Loss: 4.265, avg. samples / sec: 53410.80
Iteration:   2660, Loss function: 4.608, Average Loss: 4.272, avg. samples / sec: 53455.05
Iteration:   2660, Loss function: 4.076, Average Loss: 4.259, avg. samples / sec: 53244.80
Iteration:   2660, Loss function: 3.222, Average Loss: 4.281, avg. samples / sec: 53387.15
Iteration:   2660, Loss function: 3.951, Average Loss: 4.264, avg. samples / sec: 53314.50
Iteration:   2660, Loss function: 4.096, Average Loss: 4.261, avg. samples / sec: 53298.69
Iteration:   2660, Loss function: 4.431, Average Loss: 4.253, avg. samples / sec: 53297.72
Iteration:   2660, Loss function: 4.664, Average Loss: 4.259, avg. samples / sec: 53310.04
Iteration:   2660, Loss function: 2.687, Average Loss: 4.271, avg. samples / sec: 53226.54
Iteration:   2660, Loss function: 4.444, Average Loss: 4.244, avg. samples / sec: 53301.53
Iteration:   2660, Loss function: 3.201, Average Loss: 4.271, avg. samples / sec: 53072.22
Iteration:   2660, Loss function: 3.436, Average Loss: 4.307, avg. samples / sec: 53230.65
Iteration:   2660, Loss function: 3.811, Average Loss: 4.263, avg. samples / sec: 53284.18
Iteration:   2660, Loss function: 4.591, Average Loss: 4.248, avg. samples / sec: 53259.27
Iteration:   2660, Loss function: 4.654, Average Loss: 4.271, avg. samples / sec: 53219.99
Iteration:   2660, Loss function: 4.270, Average Loss: 4.255, avg. samples / sec: 53196.41
Iteration:   2660, Loss function: 4.181, Average Loss: 4.297, avg. samples / sec: 53436.20
Iteration:   2660, Loss function: 4.031, Average Loss: 4.258, avg. samples / sec: 53360.00
Iteration:   2660, Loss function: 4.847, Average Loss: 4.270, avg. samples / sec: 53264.12
Iteration:   2660, Loss function: 3.756, Average Loss: 4.273, avg. samples / sec: 53285.11
Iteration:   2660, Loss function: 4.657, Average Loss: 4.266, avg. samples / sec: 53273.79
Iteration:   2660, Loss function: 2.756, Average Loss: 4.250, avg. samples / sec: 53350.59
Iteration:   2660, Loss function: 5.072, Average Loss: 4.287, avg. samples / sec: 53225.28
Iteration:   2660, Loss function: 4.288, Average Loss: 4.274, avg. samples / sec: 53126.52
Iteration:   2660, Loss function: 4.137, Average Loss: 4.289, avg. samples / sec: 53272.58
Iteration:   2660, Loss function: 4.007, Average Loss: 4.262, avg. samples / sec: 53245.07
Iteration:   2660, Loss function: 4.189, Average Loss: 4.268, avg. samples / sec: 53265.51
Iteration:   2660, Loss function: 4.508, Average Loss: 4.259, avg. samples / sec: 53098.10
Iteration:   2680, Loss function: 4.598, Average Loss: 4.269, avg. samples / sec: 53617.42
Iteration:   2680, Loss function: 3.784, Average Loss: 4.258, avg. samples / sec: 53557.00
Iteration:   2680, Loss function: 3.025, Average Loss: 4.257, avg. samples / sec: 53621.64
Iteration:   2680, Loss function: 3.902, Average Loss: 4.257, avg. samples / sec: 53522.38
Iteration:   2680, Loss function: 4.428, Average Loss: 4.270, avg. samples / sec: 53505.99
Iteration:   2680, Loss function: 3.068, Average Loss: 4.258, avg. samples / sec: 53657.02
Iteration:   2680, Loss function: 5.011, Average Loss: 4.266, avg. samples / sec: 53654.76
Iteration:   2680, Loss function: 4.700, Average Loss: 4.267, avg. samples / sec: 53683.55
Iteration:   2680, Loss function: 4.212, Average Loss: 4.260, avg. samples / sec: 53598.17
Iteration:   2680, Loss function: 3.691, Average Loss: 4.246, avg. samples / sec: 53617.75
Iteration:   2680, Loss function: 4.189, Average Loss: 4.276, avg. samples / sec: 53541.52
Iteration:   2680, Loss function: 4.202, Average Loss: 4.254, avg. samples / sec: 53598.72
Iteration:   2680, Loss function: 4.068, Average Loss: 4.247, avg. samples / sec: 53623.50
Iteration:   2680, Loss function: 4.605, Average Loss: 4.296, avg. samples / sec: 53600.13
Iteration:   2680, Loss function: 3.174, Average Loss: 4.252, avg. samples / sec: 53597.60
Iteration:   2680, Loss function: 4.581, Average Loss: 4.251, avg. samples / sec: 53623.46
Iteration:   2680, Loss function: 3.661, Average Loss: 4.256, avg. samples / sec: 53427.67
Iteration:   2680, Loss function: 4.887, Average Loss: 4.278, avg. samples / sec: 53734.81
Iteration:   2680, Loss function: 4.867, Average Loss: 4.261, avg. samples / sec: 53638.79
Iteration:   2680, Loss function: 3.948, Average Loss: 4.254, avg. samples / sec: 53556.11
Iteration:   2680, Loss function: 4.179, Average Loss: 4.272, avg. samples / sec: 53615.99
Iteration:   2680, Loss function: 3.509, Average Loss: 4.294, avg. samples / sec: 53500.91
Iteration:   2680, Loss function: 4.706, Average Loss: 4.240, avg. samples / sec: 53421.49
Iteration:   2680, Loss function: 4.161, Average Loss: 4.245, avg. samples / sec: 53623.07
Iteration:   2680, Loss function: 3.488, Average Loss: 4.259, avg. samples / sec: 53604.63
Iteration:   2680, Loss function: 3.361, Average Loss: 4.256, avg. samples / sec: 53764.00
Iteration:   2680, Loss function: 5.270, Average Loss: 4.281, avg. samples / sec: 53653.49
Iteration:   2680, Loss function: 3.462, Average Loss: 4.255, avg. samples / sec: 53640.13
Iteration:   2680, Loss function: 3.094, Average Loss: 4.260, avg. samples / sec: 53631.27
Iteration:   2680, Loss function: 4.663, Average Loss: 4.263, avg. samples / sec: 53644.46
Iteration:   2700, Loss function: 4.741, Average Loss: 4.270, avg. samples / sec: 53327.83
Iteration:   2700, Loss function: 3.829, Average Loss: 4.249, avg. samples / sec: 53339.38
Iteration:   2700, Loss function: 4.550, Average Loss: 4.267, avg. samples / sec: 53351.64
Iteration:   2700, Loss function: 3.478, Average Loss: 4.253, avg. samples / sec: 53355.98
Iteration:   2700, Loss function: 3.882, Average Loss: 4.253, avg. samples / sec: 53299.74
Iteration:   2700, Loss function: 3.798, Average Loss: 4.265, avg. samples / sec: 53335.38
Iteration:   2700, Loss function: 3.313, Average Loss: 4.253, avg. samples / sec: 53333.53
Iteration:   2700, Loss function: 5.137, Average Loss: 4.239, avg. samples / sec: 53325.25
Iteration:   2700, Loss function: 4.904, Average Loss: 4.241, avg. samples / sec: 53547.15
Iteration:   2700, Loss function: 4.403, Average Loss: 4.252, avg. samples / sec: 53379.30
Iteration:   2700, Loss function: 2.810, Average Loss: 4.247, avg. samples / sec: 53346.85
Iteration:   2700, Loss function: 3.891, Average Loss: 4.287, avg. samples / sec: 53359.35
Iteration:   2700, Loss function: 4.876, Average Loss: 4.267, avg. samples / sec: 53305.51
Iteration:   2700, Loss function: 4.749, Average Loss: 4.244, avg. samples / sec: 53375.34
Iteration:   2700, Loss function: 3.769, Average Loss: 4.258, avg. samples / sec: 53254.28
Iteration:   2700, Loss function: 4.069, Average Loss: 4.243, avg. samples / sec: 53313.89
Iteration:   2700, Loss function: 3.545, Average Loss: 4.264, avg. samples / sec: 53267.04
Iteration:   2700, Loss function: 3.709, Average Loss: 4.257, avg. samples / sec: 53353.41
Iteration:   2700, Loss function: 3.193, Average Loss: 4.246, avg. samples / sec: 53370.24
Iteration:   2700, Loss function: 3.744, Average Loss: 4.247, avg. samples / sec: 53234.12
Iteration:   2700, Loss function: 4.053, Average Loss: 4.255, avg. samples / sec: 53386.01
Iteration:   2700, Loss function: 4.566, Average Loss: 4.268, avg. samples / sec: 53330.64
Iteration:   2700, Loss function: 3.080, Average Loss: 4.263, avg. samples / sec: 53340.37
Iteration:   2700, Loss function: 3.490, Average Loss: 4.270, avg. samples / sec: 53239.90
Iteration:   2700, Loss function: 3.257, Average Loss: 4.289, avg. samples / sec: 53326.08
Iteration:   2700, Loss function: 3.428, Average Loss: 4.257, avg. samples / sec: 53351.17
Iteration:   2700, Loss function: 3.993, Average Loss: 4.250, avg. samples / sec: 53344.43
Iteration:   2700, Loss function: 3.959, Average Loss: 4.249, avg. samples / sec: 53309.22
Iteration:   2700, Loss function: 3.614, Average Loss: 4.279, avg. samples / sec: 53319.24
Iteration:   2700, Loss function: 4.286, Average Loss: 4.256, avg. samples / sec: 53320.79
Iteration:   2720, Loss function: 4.581, Average Loss: 4.247, avg. samples / sec: 53723.73
Iteration:   2720, Loss function: 3.381, Average Loss: 4.257, avg. samples / sec: 53808.94
Iteration:   2720, Loss function: 4.727, Average Loss: 4.263, avg. samples / sec: 53587.04
Iteration:   2720, Loss function: 3.710, Average Loss: 4.254, avg. samples / sec: 53690.53
Iteration:   2720, Loss function: 4.415, Average Loss: 4.262, avg. samples / sec: 53677.44
Iteration:   2720, Loss function: 4.313, Average Loss: 4.246, avg. samples / sec: 53726.90
Iteration:   2720, Loss function: 4.127, Average Loss: 4.239, avg. samples / sec: 53691.94
Iteration:   2720, Loss function: 3.429, Average Loss: 4.249, avg. samples / sec: 53680.83
Iteration:   2720, Loss function: 4.447, Average Loss: 4.247, avg. samples / sec: 53669.81
Iteration:   2720, Loss function: 2.824, Average Loss: 4.238, avg. samples / sec: 53719.51
Iteration:   2720, Loss function: 3.886, Average Loss: 4.262, avg. samples / sec: 53690.34
Iteration:   2720, Loss function: 4.479, Average Loss: 4.256, avg. samples / sec: 53691.28
Iteration:   2720, Loss function: 3.871, Average Loss: 4.240, avg. samples / sec: 53682.16
Iteration:   2720, Loss function: 4.160, Average Loss: 4.244, avg. samples / sec: 53659.62
Iteration:   2720, Loss function: 4.296, Average Loss: 4.284, avg. samples / sec: 53670.63
Iteration:   2720, Loss function: 3.458, Average Loss: 4.259, avg. samples / sec: 53703.15
Iteration:   2720, Loss function: 3.570, Average Loss: 4.236, avg. samples / sec: 53531.74
Iteration:   2720, Loss function: 4.400, Average Loss: 4.265, avg. samples / sec: 53745.96
Iteration:   2720, Loss function: 5.378, Average Loss: 4.255, avg. samples / sec: 53666.26
Iteration:   2720, Loss function: 2.876, Average Loss: 4.235, avg. samples / sec: 53663.13
Iteration:   2720, Loss function: 4.317, Average Loss: 4.286, avg. samples / sec: 53718.73
Iteration:   2720, Loss function: 4.327, Average Loss: 4.264, avg. samples / sec: 53695.03
Iteration:   2720, Loss function: 3.811, Average Loss: 4.260, avg. samples / sec: 53682.39
Iteration:   2720, Loss function: 3.786, Average Loss: 4.249, avg. samples / sec: 53627.89
Iteration:   2720, Loss function: 2.818, Average Loss: 4.238, avg. samples / sec: 53616.15
Iteration:   2720, Loss function: 4.080, Average Loss: 4.274, avg. samples / sec: 53679.48
Iteration:   2720, Loss function: 4.294, Average Loss: 4.243, avg. samples / sec: 53676.05
Iteration:   2720, Loss function: 2.797, Average Loss: 4.241, avg. samples / sec: 53667.61
Iteration:   2720, Loss function: 2.902, Average Loss: 4.248, avg. samples / sec: 53682.59
Iteration:   2720, Loss function: 2.894, Average Loss: 4.247, avg. samples / sec: 53555.15
:::MLL 1558641188.326 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558641188.327 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 3.872, Average Loss: 4.263, avg. samples / sec: 53100.58
Iteration:   2740, Loss function: 3.747, Average Loss: 4.241, avg. samples / sec: 52931.73
Iteration:   2740, Loss function: 3.631, Average Loss: 4.238, avg. samples / sec: 53041.24
Iteration:   2740, Loss function: 4.256, Average Loss: 4.258, avg. samples / sec: 52977.12
Iteration:   2740, Loss function: 3.460, Average Loss: 4.250, avg. samples / sec: 52952.06
Iteration:   2740, Loss function: 5.180, Average Loss: 4.248, avg. samples / sec: 52861.37
Iteration:   2740, Loss function: 3.242, Average Loss: 4.242, avg. samples / sec: 53024.56
Iteration:   2740, Loss function: 4.820, Average Loss: 4.249, avg. samples / sec: 53004.39
Iteration:   2740, Loss function: 4.511, Average Loss: 4.235, avg. samples / sec: 52968.63
Iteration:   2740, Loss function: 3.898, Average Loss: 4.236, avg. samples / sec: 52999.79
Iteration:   2740, Loss function: 3.411, Average Loss: 4.232, avg. samples / sec: 52954.62
Iteration:   2740, Loss function: 4.050, Average Loss: 4.255, avg. samples / sec: 52987.91
Iteration:   2740, Loss function: 4.320, Average Loss: 4.278, avg. samples / sec: 52981.86
Iteration:   2740, Loss function: 3.911, Average Loss: 4.242, avg. samples / sec: 52911.86
Iteration:   2740, Loss function: 3.892, Average Loss: 4.233, avg. samples / sec: 53082.00
Iteration:   2740, Loss function: 4.314, Average Loss: 4.251, avg. samples / sec: 52944.50
Iteration:   2740, Loss function: 3.722, Average Loss: 4.225, avg. samples / sec: 52936.18
Iteration:   2740, Loss function: 3.666, Average Loss: 4.252, avg. samples / sec: 53080.00
Iteration:   2740, Loss function: 4.084, Average Loss: 4.228, avg. samples / sec: 52998.41
Iteration:   2740, Loss function: 4.248, Average Loss: 4.260, avg. samples / sec: 52965.97
Iteration:   2740, Loss function: 3.957, Average Loss: 4.258, avg. samples / sec: 52976.68
Iteration:   2740, Loss function: 3.610, Average Loss: 4.233, avg. samples / sec: 53020.49
Iteration:   2740, Loss function: 2.805, Average Loss: 4.261, avg. samples / sec: 52984.85
Iteration:   2740, Loss function: 3.767, Average Loss: 4.239, avg. samples / sec: 53004.29
Iteration:   2740, Loss function: 3.759, Average Loss: 4.243, avg. samples / sec: 53008.76
Iteration:   2740, Loss function: 5.491, Average Loss: 4.284, avg. samples / sec: 52941.93
Iteration:   2740, Loss function: 4.024, Average Loss: 4.243, avg. samples / sec: 53092.10
Iteration:   2740, Loss function: 4.623, Average Loss: 4.270, avg. samples / sec: 52973.93
Iteration:   2740, Loss function: 3.820, Average Loss: 4.240, avg. samples / sec: 52980.24
Iteration:   2740, Loss function: 3.706, Average Loss: 4.232, avg. samples / sec: 52947.80
Iteration:   2760, Loss function: 3.237, Average Loss: 4.236, avg. samples / sec: 53858.43
Iteration:   2760, Loss function: 3.496, Average Loss: 4.261, avg. samples / sec: 53743.54
Iteration:   2760, Loss function: 3.561, Average Loss: 4.255, avg. samples / sec: 53849.89
Iteration:   2760, Loss function: 4.487, Average Loss: 4.241, avg. samples / sec: 53832.39
Iteration:   2760, Loss function: 3.731, Average Loss: 4.234, avg. samples / sec: 53780.66
Iteration:   2760, Loss function: 3.284, Average Loss: 4.227, avg. samples / sec: 53852.30
Iteration:   2760, Loss function: 4.296, Average Loss: 4.250, avg. samples / sec: 53846.72
Iteration:   2760, Loss function: 5.065, Average Loss: 4.238, avg. samples / sec: 53806.20
Iteration:   2760, Loss function: 3.691, Average Loss: 4.244, avg. samples / sec: 53783.80
Iteration:   2760, Loss function: 3.475, Average Loss: 4.245, avg. samples / sec: 53852.77
Iteration:   2760, Loss function: 3.825, Average Loss: 4.234, avg. samples / sec: 53848.37
Iteration:   2760, Loss function: 3.673, Average Loss: 4.267, avg. samples / sec: 53827.37
Iteration:   2760, Loss function: 4.193, Average Loss: 4.232, avg. samples / sec: 53782.30
Iteration:   2760, Loss function: 3.183, Average Loss: 4.221, avg. samples / sec: 53835.12
Iteration:   2760, Loss function: 3.929, Average Loss: 4.238, avg. samples / sec: 53809.22
Iteration:   2760, Loss function: 3.470, Average Loss: 4.246, avg. samples / sec: 53754.52
Iteration:   2760, Loss function: 3.544, Average Loss: 4.258, avg. samples / sec: 53834.34
Iteration:   2760, Loss function: 4.103, Average Loss: 4.232, avg. samples / sec: 53848.58
Iteration:   2760, Loss function: 3.614, Average Loss: 4.257, avg. samples / sec: 53824.41
Iteration:   2760, Loss function: 3.713, Average Loss: 4.280, avg. samples / sec: 53850.88
Iteration:   2760, Loss function: 3.149, Average Loss: 4.223, avg. samples / sec: 53773.72
Iteration:   2760, Loss function: 5.038, Average Loss: 4.239, avg. samples / sec: 53808.85
Iteration:   2760, Loss function: 4.001, Average Loss: 4.235, avg. samples / sec: 53819.76
Iteration:   2760, Loss function: 3.470, Average Loss: 4.238, avg. samples / sec: 53843.66
Iteration:   2760, Loss function: 3.681, Average Loss: 4.249, avg. samples / sec: 53694.11
Iteration:   2760, Loss function: 3.650, Average Loss: 4.263, avg. samples / sec: 53738.21
Iteration:   2760, Loss function: 3.242, Average Loss: 4.242, avg. samples / sec: 53810.31
Iteration:   2760, Loss function: 3.763, Average Loss: 4.230, avg. samples / sec: 53842.49
Iteration:   2760, Loss function: 5.329, Average Loss: 4.260, avg. samples / sec: 53801.13
Iteration:   2760, Loss function: 3.687, Average Loss: 4.236, avg. samples / sec: 53540.52
Iteration:   2780, Loss function: 5.398, Average Loss: 4.233, avg. samples / sec: 53955.04
Iteration:   2780, Loss function: 4.070, Average Loss: 4.262, avg. samples / sec: 53980.95
Iteration:   2780, Loss function: 4.715, Average Loss: 4.233, avg. samples / sec: 53951.32
Iteration:   2780, Loss function: 3.763, Average Loss: 4.241, avg. samples / sec: 53969.42
Iteration:   2780, Loss function: 3.369, Average Loss: 4.229, avg. samples / sec: 53937.84
Iteration:   2780, Loss function: 3.838, Average Loss: 4.235, avg. samples / sec: 53989.10
Iteration:   2780, Loss function: 5.161, Average Loss: 4.239, avg. samples / sec: 53966.42
Iteration:   2780, Loss function: 3.203, Average Loss: 4.237, avg. samples / sec: 53907.79
Iteration:   2780, Loss function: 4.908, Average Loss: 4.251, avg. samples / sec: 53871.28
Iteration:   2780, Loss function: 6.494, Average Loss: 4.246, avg. samples / sec: 53939.59
Iteration:   2780, Loss function: 4.045, Average Loss: 4.241, avg. samples / sec: 53970.89
Iteration:   2780, Loss function: 3.788, Average Loss: 4.270, avg. samples / sec: 53936.89
Iteration:   2780, Loss function: 4.917, Average Loss: 4.247, avg. samples / sec: 53897.82
Iteration:   2780, Loss function: 5.057, Average Loss: 4.232, avg. samples / sec: 54191.10
Iteration:   2780, Loss function: 3.364, Average Loss: 4.235, avg. samples / sec: 53921.59
Iteration:   2780, Loss function: 3.467, Average Loss: 4.215, avg. samples / sec: 53908.83
Iteration:   2780, Loss function: 5.067, Average Loss: 4.240, avg. samples / sec: 53858.39
Iteration:   2780, Loss function: 4.500, Average Loss: 4.230, avg. samples / sec: 53912.89
Iteration:   2780, Loss function: 5.100, Average Loss: 4.259, avg. samples / sec: 53905.01
Iteration:   2780, Loss function: 4.285, Average Loss: 4.251, avg. samples / sec: 54014.68
Iteration:   2780, Loss function: 2.998, Average Loss: 4.232, avg. samples / sec: 53948.86
Iteration:   2780, Loss function: 3.612, Average Loss: 4.280, avg. samples / sec: 53933.19
Iteration:   2780, Loss function: 4.093, Average Loss: 4.260, avg. samples / sec: 53971.65
Iteration:   2780, Loss function: 3.447, Average Loss: 4.255, avg. samples / sec: 53913.51
Iteration:   2780, Loss function: 4.176, Average Loss: 4.232, avg. samples / sec: 53928.51
Iteration:   2780, Loss function: 4.881, Average Loss: 4.220, avg. samples / sec: 53927.16
Iteration:   2780, Loss function: 3.863, Average Loss: 4.249, avg. samples / sec: 53936.76
Iteration:   2780, Loss function: 3.297, Average Loss: 4.233, avg. samples / sec: 53904.76
Iteration:   2780, Loss function: 3.932, Average Loss: 4.240, avg. samples / sec: 53927.95
Iteration:   2780, Loss function: 4.430, Average Loss: 4.233, avg. samples / sec: 53933.21
:::MLL 1558641190.517 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558641190.517 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 4.678, Average Loss: 4.256, avg. samples / sec: 53282.99
Iteration:   2800, Loss function: 4.287, Average Loss: 4.233, avg. samples / sec: 53201.67
Iteration:   2800, Loss function: 4.462, Average Loss: 4.241, avg. samples / sec: 53392.81
Iteration:   2800, Loss function: 4.639, Average Loss: 4.241, avg. samples / sec: 53358.52
Iteration:   2800, Loss function: 4.767, Average Loss: 4.237, avg. samples / sec: 53345.98
Iteration:   2800, Loss function: 3.370, Average Loss: 4.230, avg. samples / sec: 53285.49
Iteration:   2800, Loss function: 3.894, Average Loss: 4.227, avg. samples / sec: 53202.43
Iteration:   2800, Loss function: 4.637, Average Loss: 4.255, avg. samples / sec: 53438.34
Iteration:   2800, Loss function: 2.522, Average Loss: 4.236, avg. samples / sec: 53209.56
Iteration:   2800, Loss function: 4.014, Average Loss: 4.227, avg. samples / sec: 53199.72
Iteration:   2800, Loss function: 4.069, Average Loss: 4.238, avg. samples / sec: 53212.92
Iteration:   2800, Loss function: 3.943, Average Loss: 4.247, avg. samples / sec: 53244.14
Iteration:   2800, Loss function: 3.265, Average Loss: 4.235, avg. samples / sec: 53242.09
Iteration:   2800, Loss function: 2.470, Average Loss: 4.224, avg. samples / sec: 53259.94
Iteration:   2800, Loss function: 3.391, Average Loss: 4.210, avg. samples / sec: 53264.34
Iteration:   2800, Loss function: 4.962, Average Loss: 4.267, avg. samples / sec: 53212.62
Iteration:   2800, Loss function: 2.822, Average Loss: 4.229, avg. samples / sec: 53171.54
Iteration:   2800, Loss function: 5.609, Average Loss: 4.276, avg. samples / sec: 53367.23
Iteration:   2800, Loss function: 2.949, Average Loss: 4.216, avg. samples / sec: 53374.02
Iteration:   2800, Loss function: 4.410, Average Loss: 4.236, avg. samples / sec: 53216.48
Iteration:   2800, Loss function: 2.770, Average Loss: 4.226, avg. samples / sec: 53317.46
Iteration:   2800, Loss function: 2.956, Average Loss: 4.230, avg. samples / sec: 53329.57
Iteration:   2800, Loss function: 3.951, Average Loss: 4.249, avg. samples / sec: 53276.83
Iteration:   2800, Loss function: 3.516, Average Loss: 4.246, avg. samples / sec: 53255.95
Iteration:   2800, Loss function: 4.121, Average Loss: 4.233, avg. samples / sec: 53218.73
Iteration:   2800, Loss function: 4.926, Average Loss: 4.251, avg. samples / sec: 53180.73
Iteration:   2800, Loss function: 4.541, Average Loss: 4.229, avg. samples / sec: 53236.08
Iteration:   2800, Loss function: 5.624, Average Loss: 4.231, avg. samples / sec: 53235.69
Iteration:   2800, Loss function: 4.172, Average Loss: 4.243, avg. samples / sec: 53225.30
Iteration:   2800, Loss function: 3.572, Average Loss: 4.252, avg. samples / sec: 53166.30
Iteration:   2820, Loss function: 5.795, Average Loss: 4.250, avg. samples / sec: 53694.78
Iteration:   2820, Loss function: 4.604, Average Loss: 4.227, avg. samples / sec: 53748.44
Iteration:   2820, Loss function: 2.965, Average Loss: 4.231, avg. samples / sec: 53815.96
Iteration:   2820, Loss function: 4.115, Average Loss: 4.242, avg. samples / sec: 53644.85
Iteration:   2820, Loss function: 4.275, Average Loss: 4.220, avg. samples / sec: 53788.44
Iteration:   2820, Loss function: 2.791, Average Loss: 4.259, avg. samples / sec: 53828.97
Iteration:   2820, Loss function: 2.083, Average Loss: 4.228, avg. samples / sec: 53687.36
Iteration:   2820, Loss function: 3.477, Average Loss: 4.206, avg. samples / sec: 53818.14
Iteration:   2820, Loss function: 4.504, Average Loss: 4.247, avg. samples / sec: 53657.78
Iteration:   2820, Loss function: 4.858, Average Loss: 4.230, avg. samples / sec: 53795.44
Iteration:   2820, Loss function: 4.122, Average Loss: 4.244, avg. samples / sec: 53790.33
Iteration:   2820, Loss function: 2.633, Average Loss: 4.219, avg. samples / sec: 53793.47
Iteration:   2820, Loss function: 4.146, Average Loss: 4.229, avg. samples / sec: 53679.42
Iteration:   2820, Loss function: 3.989, Average Loss: 4.234, avg. samples / sec: 53737.41
Iteration:   2820, Loss function: 4.638, Average Loss: 4.226, avg. samples / sec: 53768.43
Iteration:   2820, Loss function: 3.760, Average Loss: 4.229, avg. samples / sec: 53792.09
Iteration:   2820, Loss function: 4.348, Average Loss: 4.249, avg. samples / sec: 53590.24
Iteration:   2820, Loss function: 4.607, Average Loss: 4.247, avg. samples / sec: 53767.06
Iteration:   2820, Loss function: 4.154, Average Loss: 4.247, avg. samples / sec: 53866.03
Iteration:   2820, Loss function: 4.100, Average Loss: 4.222, avg. samples / sec: 53672.82
Iteration:   2820, Loss function: 3.506, Average Loss: 4.221, avg. samples / sec: 53802.59
Iteration:   2820, Loss function: 3.306, Average Loss: 4.242, avg. samples / sec: 53776.04
Iteration:   2820, Loss function: 4.460, Average Loss: 4.247, avg. samples / sec: 53804.83
Iteration:   2820, Loss function: 4.440, Average Loss: 4.225, avg. samples / sec: 53657.45
Iteration:   2820, Loss function: 3.773, Average Loss: 4.226, avg. samples / sec: 53553.54
Iteration:   2820, Loss function: 4.576, Average Loss: 4.237, avg. samples / sec: 53830.43
Iteration:   2820, Loss function: 3.464, Average Loss: 4.275, avg. samples / sec: 53598.56
Iteration:   2820, Loss function: 4.191, Average Loss: 4.225, avg. samples / sec: 53781.73
Iteration:   2820, Loss function: 3.488, Average Loss: 4.217, avg. samples / sec: 53586.82
Iteration:   2820, Loss function: 3.863, Average Loss: 4.226, avg. samples / sec: 53777.70
Iteration:   2840, Loss function: 3.368, Average Loss: 4.240, avg. samples / sec: 53852.05
Iteration:   2840, Loss function: 2.975, Average Loss: 4.222, avg. samples / sec: 53839.56
Iteration:   2840, Loss function: 3.661, Average Loss: 4.213, avg. samples / sec: 53862.43
Iteration:   2840, Loss function: 5.617, Average Loss: 4.228, avg. samples / sec: 53861.71
Iteration:   2840, Loss function: 3.815, Average Loss: 4.231, avg. samples / sec: 53834.09
Iteration:   2840, Loss function: 4.363, Average Loss: 4.224, avg. samples / sec: 54100.50
Iteration:   2840, Loss function: 4.425, Average Loss: 4.229, avg. samples / sec: 53852.73
Iteration:   2840, Loss function: 3.836, Average Loss: 4.223, avg. samples / sec: 53812.22
Iteration:   2840, Loss function: 4.183, Average Loss: 4.221, avg. samples / sec: 53895.45
Iteration:   2840, Loss function: 4.053, Average Loss: 4.228, avg. samples / sec: 53888.13
Iteration:   2840, Loss function: 5.761, Average Loss: 4.245, avg. samples / sec: 53825.13
Iteration:   2840, Loss function: 5.251, Average Loss: 4.218, avg. samples / sec: 53826.57
Iteration:   2840, Loss function: 2.386, Average Loss: 4.245, avg. samples / sec: 53990.90
Iteration:   2840, Loss function: 3.849, Average Loss: 4.252, avg. samples / sec: 53792.18
Iteration:   2840, Loss function: 3.811, Average Loss: 4.195, avg. samples / sec: 53782.42
Iteration:   2840, Loss function: 3.263, Average Loss: 4.222, avg. samples / sec: 53859.42
Iteration:   2840, Loss function: 4.618, Average Loss: 4.221, avg. samples / sec: 53815.70
Iteration:   2840, Loss function: 5.419, Average Loss: 4.243, avg. samples / sec: 53769.99
Iteration:   2840, Loss function: 3.792, Average Loss: 4.238, avg. samples / sec: 53871.82
Iteration:   2840, Loss function: 3.438, Average Loss: 4.219, avg. samples / sec: 53856.02
Iteration:   2840, Loss function: 3.735, Average Loss: 4.242, avg. samples / sec: 53839.71
Iteration:   2840, Loss function: 4.874, Average Loss: 4.217, avg. samples / sec: 53854.32
Iteration:   2840, Loss function: 4.129, Average Loss: 4.210, avg. samples / sec: 53900.87
Iteration:   2840, Loss function: 2.493, Average Loss: 4.216, avg. samples / sec: 53881.72
Iteration:   2840, Loss function: 4.391, Average Loss: 4.239, avg. samples / sec: 53807.81
Iteration:   2840, Loss function: 3.101, Average Loss: 4.242, avg. samples / sec: 53827.51
Iteration:   2840, Loss function: 4.193, Average Loss: 4.264, avg. samples / sec: 53849.48
Iteration:   2840, Loss function: 5.125, Average Loss: 4.219, avg. samples / sec: 53810.41
Iteration:   2840, Loss function: 4.536, Average Loss: 4.233, avg. samples / sec: 53809.61
Iteration:   2840, Loss function: 3.662, Average Loss: 4.218, avg. samples / sec: 53795.89
Iteration:   2860, Loss function: 3.608, Average Loss: 4.233, avg. samples / sec: 53779.51
Iteration:   2860, Loss function: 3.600, Average Loss: 4.215, avg. samples / sec: 53774.11
Iteration:   2860, Loss function: 3.822, Average Loss: 4.228, avg. samples / sec: 53831.09
Iteration:   2860, Loss function: 3.167, Average Loss: 4.221, avg. samples / sec: 53807.23
Iteration:   2860, Loss function: 3.057, Average Loss: 4.233, avg. samples / sec: 53870.41
Iteration:   2860, Loss function: 3.135, Average Loss: 4.217, avg. samples / sec: 53771.88
Iteration:   2860, Loss function: 4.324, Average Loss: 4.219, avg. samples / sec: 53794.84
Iteration:   2860, Loss function: 4.257, Average Loss: 4.207, avg. samples / sec: 53732.12
Iteration:   2860, Loss function: 3.749, Average Loss: 4.217, avg. samples / sec: 53782.18
Iteration:   2860, Loss function: 5.585, Average Loss: 4.190, avg. samples / sec: 53811.44
Iteration:   2860, Loss function: 3.846, Average Loss: 4.246, avg. samples / sec: 53766.58
Iteration:   2860, Loss function: 4.308, Average Loss: 4.222, avg. samples / sec: 53759.84
Iteration:   2860, Loss function: 4.945, Average Loss: 4.218, avg. samples / sec: 53786.00
Iteration:   2860, Loss function: 3.962, Average Loss: 4.228, avg. samples / sec: 53729.17
Iteration:   2860, Loss function: 4.263, Average Loss: 4.215, avg. samples / sec: 53786.65
Iteration:   2860, Loss function: 4.406, Average Loss: 4.246, avg. samples / sec: 53771.49
Iteration:   2860, Loss function: 5.718, Average Loss: 4.228, avg. samples / sec: 53691.92
Iteration:   2860, Loss function: 4.953, Average Loss: 4.216, avg. samples / sec: 53797.93
Iteration:   2860, Loss function: 4.292, Average Loss: 4.230, avg. samples / sec: 53806.06
Iteration:   2860, Loss function: 4.453, Average Loss: 4.235, avg. samples / sec: 53754.22
Iteration:   2860, Loss function: 2.924, Average Loss: 4.212, avg. samples / sec: 53757.27
Iteration:   2860, Loss function: 3.400, Average Loss: 4.242, avg. samples / sec: 53596.05
Iteration:   2860, Loss function: 4.652, Average Loss: 4.237, avg. samples / sec: 53758.15
Iteration:   2860, Loss function: 3.415, Average Loss: 4.236, avg. samples / sec: 53783.43
Iteration:   2860, Loss function: 3.368, Average Loss: 4.205, avg. samples / sec: 53758.79
Iteration:   2860, Loss function: 4.018, Average Loss: 4.210, avg. samples / sec: 53783.47
Iteration:   2860, Loss function: 4.311, Average Loss: 4.212, avg. samples / sec: 53845.22
Iteration:   2860, Loss function: 3.599, Average Loss: 4.261, avg. samples / sec: 53755.80
Iteration:   2860, Loss function: 3.842, Average Loss: 4.211, avg. samples / sec: 53733.21
Iteration:   2860, Loss function: 4.038, Average Loss: 4.226, avg. samples / sec: 53760.12
:::MLL 1558641192.707 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558641192.707 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 5.137, Average Loss: 4.229, avg. samples / sec: 53605.28
Iteration:   2880, Loss function: 4.234, Average Loss: 4.222, avg. samples / sec: 53552.28
Iteration:   2880, Loss function: 4.755, Average Loss: 4.222, avg. samples / sec: 53680.69
Iteration:   2880, Loss function: 4.237, Average Loss: 4.223, avg. samples / sec: 53642.87
Iteration:   2880, Loss function: 4.708, Average Loss: 4.212, avg. samples / sec: 53613.54
Iteration:   2880, Loss function: 3.501, Average Loss: 4.219, avg. samples / sec: 53552.85
Iteration:   2880, Loss function: 4.606, Average Loss: 4.213, avg. samples / sec: 53572.09
Iteration:   2880, Loss function: 5.305, Average Loss: 4.202, avg. samples / sec: 53573.25
Iteration:   2880, Loss function: 3.716, Average Loss: 4.213, avg. samples / sec: 53563.31
Iteration:   2880, Loss function: 4.093, Average Loss: 4.207, avg. samples / sec: 53624.95
Iteration:   2880, Loss function: 4.389, Average Loss: 4.226, avg. samples / sec: 53490.29
Iteration:   2880, Loss function: 3.583, Average Loss: 4.228, avg. samples / sec: 53537.45
Iteration:   2880, Loss function: 3.340, Average Loss: 4.188, avg. samples / sec: 53577.02
Iteration:   2880, Loss function: 4.200, Average Loss: 4.239, avg. samples / sec: 53580.83
Iteration:   2880, Loss function: 3.546, Average Loss: 4.241, avg. samples / sec: 53595.64
Iteration:   2880, Loss function: 3.191, Average Loss: 4.221, avg. samples / sec: 53574.98
Iteration:   2880, Loss function: 3.087, Average Loss: 4.215, avg. samples / sec: 53579.01
Iteration:   2880, Loss function: 3.013, Average Loss: 4.236, avg. samples / sec: 53629.31
Iteration:   2880, Loss function: 4.972, Average Loss: 4.226, avg. samples / sec: 53617.32
Iteration:   2880, Loss function: 3.707, Average Loss: 4.195, avg. samples / sec: 53621.54
Iteration:   2880, Loss function: 4.813, Average Loss: 4.216, avg. samples / sec: 53573.74
Iteration:   2880, Loss function: 3.415, Average Loss: 4.212, avg. samples / sec: 53585.31
Iteration:   2880, Loss function: 4.122, Average Loss: 4.232, avg. samples / sec: 53596.11
Iteration:   2880, Loss function: 2.447, Average Loss: 4.206, avg. samples / sec: 53624.48
Iteration:   2880, Loss function: 4.459, Average Loss: 4.227, avg. samples / sec: 53564.39
Iteration:   2880, Loss function: 4.433, Average Loss: 4.201, avg. samples / sec: 53623.87
Iteration:   2880, Loss function: 4.026, Average Loss: 4.255, avg. samples / sec: 53620.62
Iteration:   2880, Loss function: 4.271, Average Loss: 4.228, avg. samples / sec: 53574.15
Iteration:   2880, Loss function: 4.873, Average Loss: 4.223, avg. samples / sec: 53622.30
Iteration:   2880, Loss function: 5.714, Average Loss: 4.214, avg. samples / sec: 53571.03
Iteration:   2900, Loss function: 3.974, Average Loss: 4.226, avg. samples / sec: 53737.31
Iteration:   2900, Loss function: 3.918, Average Loss: 4.218, avg. samples / sec: 53799.40
Iteration:   2900, Loss function: 3.349, Average Loss: 4.210, avg. samples / sec: 53774.48
Iteration:   2900, Loss function: 4.641, Average Loss: 4.221, avg. samples / sec: 53727.31
Iteration:   2900, Loss function: 4.014, Average Loss: 4.235, avg. samples / sec: 53783.76
Iteration:   2900, Loss function: 3.905, Average Loss: 4.203, avg. samples / sec: 53759.90
Iteration:   2900, Loss function: 4.449, Average Loss: 4.212, avg. samples / sec: 53735.55
Iteration:   2900, Loss function: 4.148, Average Loss: 4.201, avg. samples / sec: 53750.20
Iteration:   2900, Loss function: 5.096, Average Loss: 4.226, avg. samples / sec: 53760.37
Iteration:   2900, Loss function: 4.077, Average Loss: 4.214, avg. samples / sec: 53732.12
Iteration:   2900, Loss function: 4.198, Average Loss: 4.185, avg. samples / sec: 53752.17
Iteration:   2900, Loss function: 4.233, Average Loss: 4.211, avg. samples / sec: 53762.19
Iteration:   2900, Loss function: 5.811, Average Loss: 4.212, avg. samples / sec: 53711.36
Iteration:   2900, Loss function: 4.269, Average Loss: 4.213, avg. samples / sec: 53723.75
Iteration:   2900, Loss function: 3.285, Average Loss: 4.237, avg. samples / sec: 53700.59
Iteration:   2900, Loss function: 3.593, Average Loss: 4.218, avg. samples / sec: 53673.80
Iteration:   2900, Loss function: 3.687, Average Loss: 4.231, avg. samples / sec: 53734.97
Iteration:   2900, Loss function: 5.046, Average Loss: 4.222, avg. samples / sec: 53774.54
Iteration:   2900, Loss function: 4.404, Average Loss: 4.212, avg. samples / sec: 53756.29
Iteration:   2900, Loss function: 2.820, Average Loss: 4.217, avg. samples / sec: 53714.18
Iteration:   2900, Loss function: 3.509, Average Loss: 4.209, avg. samples / sec: 53735.36
Iteration:   2900, Loss function: 2.795, Average Loss: 4.191, avg. samples / sec: 53713.65
Iteration:   2900, Loss function: 3.059, Average Loss: 4.198, avg. samples / sec: 53721.37
Iteration:   2900, Loss function: 4.521, Average Loss: 4.228, avg. samples / sec: 53706.26
Iteration:   2900, Loss function: 5.589, Average Loss: 4.197, avg. samples / sec: 53725.90
Iteration:   2900, Loss function: 4.384, Average Loss: 4.212, avg. samples / sec: 53739.46
Iteration:   2900, Loss function: 4.762, Average Loss: 4.216, avg. samples / sec: 53721.66
Iteration:   2900, Loss function: 4.653, Average Loss: 4.220, avg. samples / sec: 53717.48
Iteration:   2900, Loss function: 4.174, Average Loss: 4.218, avg. samples / sec: 53443.19
Iteration:   2900, Loss function: 3.812, Average Loss: 4.254, avg. samples / sec: 53686.44
Iteration:   2920, Loss function: 3.281, Average Loss: 4.222, avg. samples / sec: 53754.18
Iteration:   2920, Loss function: 3.692, Average Loss: 4.217, avg. samples / sec: 53744.97
Iteration:   2920, Loss function: 3.937, Average Loss: 4.205, avg. samples / sec: 53814.73
Iteration:   2920, Loss function: 2.981, Average Loss: 4.197, avg. samples / sec: 53779.37
Iteration:   2920, Loss function: 3.659, Average Loss: 4.221, avg. samples / sec: 53794.19
Iteration:   2920, Loss function: 5.544, Average Loss: 4.216, avg. samples / sec: 53860.04
Iteration:   2920, Loss function: 4.317, Average Loss: 4.208, avg. samples / sec: 53823.51
Iteration:   2920, Loss function: 3.396, Average Loss: 4.205, avg. samples / sec: 53745.94
Iteration:   2920, Loss function: 3.154, Average Loss: 4.191, avg. samples / sec: 53771.79
Iteration:   2920, Loss function: 3.174, Average Loss: 4.206, avg. samples / sec: 53799.63
Iteration:   2920, Loss function: 5.218, Average Loss: 4.220, avg. samples / sec: 53736.63
Iteration:   2920, Loss function: 4.588, Average Loss: 4.220, avg. samples / sec: 54035.33
Iteration:   2920, Loss function: 4.625, Average Loss: 4.208, avg. samples / sec: 53756.10
Iteration:   2920, Loss function: 3.194, Average Loss: 4.237, avg. samples / sec: 53723.83
Iteration:   2920, Loss function: 4.052, Average Loss: 4.233, avg. samples / sec: 53797.78
Iteration:   2920, Loss function: 4.074, Average Loss: 4.182, avg. samples / sec: 53740.75
Iteration:   2920, Loss function: 3.905, Average Loss: 4.208, avg. samples / sec: 53683.98
Iteration:   2920, Loss function: 3.058, Average Loss: 4.209, avg. samples / sec: 53773.29
Iteration:   2920, Loss function: 4.273, Average Loss: 4.224, avg. samples / sec: 53754.61
Iteration:   2920, Loss function: 3.493, Average Loss: 4.199, avg. samples / sec: 53789.49
Iteration:   2920, Loss function: 4.805, Average Loss: 4.214, avg. samples / sec: 53752.21
Iteration:   2920, Loss function: 2.943, Average Loss: 4.202, avg. samples / sec: 53820.83
Iteration:   2920, Loss function: 2.852, Average Loss: 4.222, avg. samples / sec: 53808.98
Iteration:   2920, Loss function: 4.345, Average Loss: 4.213, avg. samples / sec: 53755.41
Iteration:   2920, Loss function: 4.227, Average Loss: 4.186, avg. samples / sec: 53769.87
Iteration:   2920, Loss function: 3.754, Average Loss: 4.216, avg. samples / sec: 53800.84
Iteration:   2920, Loss function: 3.990, Average Loss: 4.250, avg. samples / sec: 53841.35
Iteration:   2920, Loss function: 3.758, Average Loss: 4.193, avg. samples / sec: 53774.42
Iteration:   2920, Loss function: 3.426, Average Loss: 4.190, avg. samples / sec: 53771.67
Iteration:   2920, Loss function: 3.901, Average Loss: 4.213, avg. samples / sec: 53757.50
:::MLL 1558641194.898 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558641194.899 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 4.820, Average Loss: 4.218, avg. samples / sec: 53270.28
Iteration:   2940, Loss function: 4.199, Average Loss: 4.215, avg. samples / sec: 53422.04
Iteration:   2940, Loss function: 3.847, Average Loss: 4.215, avg. samples / sec: 53255.61
Iteration:   2940, Loss function: 4.156, Average Loss: 4.211, avg. samples / sec: 53373.28
Iteration:   2940, Loss function: 2.988, Average Loss: 4.200, avg. samples / sec: 53345.05
Iteration:   2940, Loss function: 3.858, Average Loss: 4.194, avg. samples / sec: 53298.65
Iteration:   2940, Loss function: 5.596, Average Loss: 4.206, avg. samples / sec: 53330.72
Iteration:   2940, Loss function: 4.258, Average Loss: 4.200, avg. samples / sec: 53311.53
Iteration:   2940, Loss function: 5.381, Average Loss: 4.221, avg. samples / sec: 53318.03
Iteration:   2940, Loss function: 4.497, Average Loss: 4.178, avg. samples / sec: 53341.78
Iteration:   2940, Loss function: 4.129, Average Loss: 4.235, avg. samples / sec: 53314.84
Iteration:   2940, Loss function: 4.351, Average Loss: 4.205, avg. samples / sec: 53272.88
Iteration:   2940, Loss function: 4.528, Average Loss: 4.186, avg. samples / sec: 53264.89
Iteration:   2940, Loss function: 5.111, Average Loss: 4.226, avg. samples / sec: 53313.97
Iteration:   2940, Loss function: 4.402, Average Loss: 4.201, avg. samples / sec: 53253.90
Iteration:   2940, Loss function: 3.539, Average Loss: 4.205, avg. samples / sec: 53343.07
Iteration:   2940, Loss function: 3.561, Average Loss: 4.217, avg. samples / sec: 53230.22
Iteration:   2940, Loss function: 3.940, Average Loss: 4.194, avg. samples / sec: 53429.17
Iteration:   2940, Loss function: 3.623, Average Loss: 4.181, avg. samples / sec: 53456.97
Iteration:   2940, Loss function: 4.399, Average Loss: 4.247, avg. samples / sec: 53424.91
Iteration:   2940, Loss function: 4.551, Average Loss: 4.216, avg. samples / sec: 53348.43
Iteration:   2940, Loss function: 4.061, Average Loss: 4.206, avg. samples / sec: 53295.53
Iteration:   2940, Loss function: 3.875, Average Loss: 4.217, avg. samples / sec: 53288.98
Iteration:   2940, Loss function: 3.074, Average Loss: 4.211, avg. samples / sec: 53311.29
Iteration:   2940, Loss function: 3.464, Average Loss: 4.218, avg. samples / sec: 53300.28
Iteration:   2940, Loss function: 2.813, Average Loss: 4.184, avg. samples / sec: 53299.42
Iteration:   2940, Loss function: 3.505, Average Loss: 4.182, avg. samples / sec: 53305.53
Iteration:   2940, Loss function: 3.776, Average Loss: 4.216, avg. samples / sec: 53257.52
Iteration:   2940, Loss function: 3.829, Average Loss: 4.213, avg. samples / sec: 53320.29
Iteration:   2940, Loss function: 3.493, Average Loss: 4.199, avg. samples / sec: 53248.75
Iteration:   2960, Loss function: 3.522, Average Loss: 4.215, avg. samples / sec: 53356.22
Iteration:   2960, Loss function: 3.533, Average Loss: 4.214, avg. samples / sec: 53358.46
Iteration:   2960, Loss function: 4.365, Average Loss: 4.199, avg. samples / sec: 53371.09
Iteration:   2960, Loss function: 2.818, Average Loss: 4.195, avg. samples / sec: 53399.83
Iteration:   2960, Loss function: 4.192, Average Loss: 4.189, avg. samples / sec: 53349.37
Iteration:   2960, Loss function: 3.025, Average Loss: 4.198, avg. samples / sec: 53344.33
Iteration:   2960, Loss function: 4.917, Average Loss: 4.235, avg. samples / sec: 53360.97
Iteration:   2960, Loss function: 4.259, Average Loss: 4.211, avg. samples / sec: 53236.40
Iteration:   2960, Loss function: 3.649, Average Loss: 4.220, avg. samples / sec: 53369.46
Iteration:   2960, Loss function: 3.514, Average Loss: 4.211, avg. samples / sec: 53379.44
Iteration:   2960, Loss function: 4.702, Average Loss: 4.216, avg. samples / sec: 53320.41
Iteration:   2960, Loss function: 4.446, Average Loss: 4.198, avg. samples / sec: 53364.53
Iteration:   2960, Loss function: 4.251, Average Loss: 4.175, avg. samples / sec: 53314.84
Iteration:   2960, Loss function: 3.224, Average Loss: 4.208, avg. samples / sec: 53224.90
Iteration:   2960, Loss function: 3.726, Average Loss: 4.202, avg. samples / sec: 53316.98
Iteration:   2960, Loss function: 2.558, Average Loss: 4.181, avg. samples / sec: 53320.39
Iteration:   2960, Loss function: 5.048, Average Loss: 4.206, avg. samples / sec: 53368.47
Iteration:   2960, Loss function: 3.964, Average Loss: 4.211, avg. samples / sec: 53385.69
Iteration:   2960, Loss function: 3.722, Average Loss: 4.210, avg. samples / sec: 53342.93
Iteration:   2960, Loss function: 4.833, Average Loss: 4.196, avg. samples / sec: 53395.38
Iteration:   2960, Loss function: 3.703, Average Loss: 4.192, avg. samples / sec: 53108.42
Iteration:   2960, Loss function: 3.808, Average Loss: 4.175, avg. samples / sec: 53195.64
Iteration:   2960, Loss function: 3.487, Average Loss: 4.206, avg. samples / sec: 53322.79
Iteration:   2960, Loss function: 3.974, Average Loss: 4.238, avg. samples / sec: 53212.26
Iteration:   2960, Loss function: 4.115, Average Loss: 4.210, avg. samples / sec: 53270.97
Iteration:   2960, Loss function: 3.623, Average Loss: 4.189, avg. samples / sec: 53175.33
Iteration:   2960, Loss function: 5.562, Average Loss: 4.209, avg. samples / sec: 53353.66
Iteration:   2960, Loss function: 4.669, Average Loss: 4.177, avg. samples / sec: 53336.25
Iteration:   2960, Loss function: 3.347, Average Loss: 4.209, avg. samples / sec: 53311.31
Iteration:   2960, Loss function: 3.314, Average Loss: 4.182, avg. samples / sec: 53300.02
Iteration:   2980, Loss function: 4.375, Average Loss: 4.208, avg. samples / sec: 53637.79
Iteration:   2980, Loss function: 3.758, Average Loss: 4.209, avg. samples / sec: 53511.00
Iteration:   2980, Loss function: 4.644, Average Loss: 4.189, avg. samples / sec: 53610.08
Iteration:   2980, Loss function: 3.019, Average Loss: 4.196, avg. samples / sec: 53531.96
Iteration:   2980, Loss function: 3.574, Average Loss: 4.193, avg. samples / sec: 53614.50
Iteration:   2980, Loss function: 3.850, Average Loss: 4.214, avg. samples / sec: 53629.11
Iteration:   2980, Loss function: 5.024, Average Loss: 4.211, avg. samples / sec: 53629.87
Iteration:   2980, Loss function: 3.574, Average Loss: 4.180, avg. samples / sec: 53594.05
Iteration:   2980, Loss function: 3.248, Average Loss: 4.229, avg. samples / sec: 53604.63
Iteration:   2980, Loss function: 4.344, Average Loss: 4.207, avg. samples / sec: 53601.47
Iteration:   2980, Loss function: 3.691, Average Loss: 4.187, avg. samples / sec: 53824.25
Iteration:   2980, Loss function: 3.953, Average Loss: 4.202, avg. samples / sec: 53629.03
Iteration:   2980, Loss function: 3.676, Average Loss: 4.170, avg. samples / sec: 53624.29
Iteration:   2980, Loss function: 3.540, Average Loss: 4.196, avg. samples / sec: 53646.22
Iteration:   2980, Loss function: 3.936, Average Loss: 4.196, avg. samples / sec: 53611.63
Iteration:   2980, Loss function: 5.123, Average Loss: 4.213, avg. samples / sec: 53614.38
Iteration:   2980, Loss function: 3.491, Average Loss: 4.176, avg. samples / sec: 53625.68
Iteration:   2980, Loss function: 3.363, Average Loss: 4.232, avg. samples / sec: 53731.16
Iteration:   2980, Loss function: 4.345, Average Loss: 4.205, avg. samples / sec: 53656.19
Iteration:   2980, Loss function: 4.238, Average Loss: 4.206, avg. samples / sec: 53628.70
Iteration:   2980, Loss function: 3.854, Average Loss: 4.194, avg. samples / sec: 53656.41
Iteration:   2980, Loss function: 4.042, Average Loss: 4.202, avg. samples / sec: 53584.23
Iteration:   2980, Loss function: 3.835, Average Loss: 4.185, avg. samples / sec: 53605.73
Iteration:   2980, Loss function: 3.766, Average Loss: 4.207, avg. samples / sec: 53588.92
Iteration:   2980, Loss function: 3.337, Average Loss: 4.203, avg. samples / sec: 53610.59
Iteration:   2980, Loss function: 3.502, Average Loss: 4.168, avg. samples / sec: 53590.04
Iteration:   2980, Loss function: 4.103, Average Loss: 4.177, avg. samples / sec: 53655.92
Iteration:   2980, Loss function: 4.185, Average Loss: 4.200, avg. samples / sec: 53625.60
Iteration:   2980, Loss function: 4.303, Average Loss: 4.201, avg. samples / sec: 53591.99
Iteration:   2980, Loss function: 4.566, Average Loss: 4.177, avg. samples / sec: 53584.66
Iteration:   3000, Loss function: 4.262, Average Loss: 4.206, avg. samples / sec: 53633.93
Iteration:   3000, Loss function: 4.484, Average Loss: 4.184, avg. samples / sec: 53690.43
Iteration:   3000, Loss function: 3.495, Average Loss: 4.195, avg. samples / sec: 53717.32
Iteration:   3000, Loss function: 3.699, Average Loss: 4.181, avg. samples / sec: 53684.96
Iteration:   3000, Loss function: 3.363, Average Loss: 4.184, avg. samples / sec: 53668.45
Iteration:   3000, Loss function: 4.677, Average Loss: 4.204, avg. samples / sec: 53682.57
Iteration:   3000, Loss function: 3.168, Average Loss: 4.206, avg. samples / sec: 53654.90
Iteration:   3000, Loss function: 4.186, Average Loss: 4.198, avg. samples / sec: 53931.13
Iteration:   3000, Loss function: 3.030, Average Loss: 4.204, avg. samples / sec: 53676.70
Iteration:   3000, Loss function: 3.380, Average Loss: 4.204, avg. samples / sec: 53651.18
Iteration:   3000, Loss function: 4.539, Average Loss: 4.189, avg. samples / sec: 53677.48
Iteration:   3000, Loss function: 3.818, Average Loss: 4.211, avg. samples / sec: 53646.32
Iteration:   3000, Loss function: 2.978, Average Loss: 4.177, avg. samples / sec: 53661.93
Iteration:   3000, Loss function: 3.518, Average Loss: 4.192, avg. samples / sec: 53615.77
Iteration:   3000, Loss function: 5.161, Average Loss: 4.224, avg. samples / sec: 53618.99
Iteration:   3000, Loss function: 4.396, Average Loss: 4.171, avg. samples / sec: 53652.32
Iteration:   3000, Loss function: 4.134, Average Loss: 4.167, avg. samples / sec: 53587.31
Iteration:   3000, Loss function: 4.189, Average Loss: 4.200, avg. samples / sec: 53670.45
Iteration:   3000, Loss function: 4.048, Average Loss: 4.202, avg. samples / sec: 53653.26
Iteration:   3000, Loss function: 3.598, Average Loss: 4.169, avg. samples / sec: 53710.54
Iteration:   3000, Loss function: 4.541, Average Loss: 4.200, avg. samples / sec: 53662.46
Iteration:   3000, Loss function: 4.117, Average Loss: 4.202, avg. samples / sec: 53689.50
Iteration:   3000, Loss function: 3.408, Average Loss: 4.194, avg. samples / sec: 53652.06
Iteration:   3000, Loss function: 3.260, Average Loss: 4.193, avg. samples / sec: 53435.22
Iteration:   3000, Loss function: 3.433, Average Loss: 4.228, avg. samples / sec: 53537.02
Iteration:   3000, Loss function: 3.356, Average Loss: 4.182, avg. samples / sec: 53638.64
Iteration:   3000, Loss function: 4.568, Average Loss: 4.200, avg. samples / sec: 53683.14
Iteration:   3000, Loss function: 4.388, Average Loss: 4.202, avg. samples / sec: 53649.71
Iteration:   3000, Loss function: 4.690, Average Loss: 4.174, avg. samples / sec: 53657.82
Iteration:   3000, Loss function: 4.582, Average Loss: 4.170, avg. samples / sec: 53661.62
:::MLL 1558641197.098 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558641197.098 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 4.933, Average Loss: 4.207, avg. samples / sec: 53461.80
Iteration:   3020, Loss function: 3.273, Average Loss: 4.186, avg. samples / sec: 53482.80
Iteration:   3020, Loss function: 4.672, Average Loss: 4.182, avg. samples / sec: 53461.09
Iteration:   3020, Loss function: 3.566, Average Loss: 4.201, avg. samples / sec: 53480.04
Iteration:   3020, Loss function: 3.068, Average Loss: 4.179, avg. samples / sec: 53456.12
Iteration:   3020, Loss function: 2.990, Average Loss: 4.200, avg. samples / sec: 53486.43
Iteration:   3020, Loss function: 3.088, Average Loss: 4.175, avg. samples / sec: 53479.92
Iteration:   3020, Loss function: 4.539, Average Loss: 4.195, avg. samples / sec: 53453.02
Iteration:   3020, Loss function: 3.729, Average Loss: 4.188, avg. samples / sec: 53414.85
Iteration:   3020, Loss function: 3.207, Average Loss: 4.199, avg. samples / sec: 53441.30
Iteration:   3020, Loss function: 2.839, Average Loss: 4.206, avg. samples / sec: 53446.37
Iteration:   3020, Loss function: 3.997, Average Loss: 4.192, avg. samples / sec: 53474.13
Iteration:   3020, Loss function: 4.917, Average Loss: 4.170, avg. samples / sec: 53479.16
Iteration:   3020, Loss function: 4.998, Average Loss: 4.181, avg. samples / sec: 53438.26
Iteration:   3020, Loss function: 3.673, Average Loss: 4.203, avg. samples / sec: 53432.73
Iteration:   3020, Loss function: 3.851, Average Loss: 4.161, avg. samples / sec: 53471.94
Iteration:   3020, Loss function: 4.942, Average Loss: 4.219, avg. samples / sec: 53416.71
Iteration:   3020, Loss function: 4.215, Average Loss: 4.193, avg. samples / sec: 53555.33
Iteration:   3020, Loss function: 4.113, Average Loss: 4.198, avg. samples / sec: 53492.09
Iteration:   3020, Loss function: 3.897, Average Loss: 4.167, avg. samples / sec: 53466.04
Iteration:   3020, Loss function: 3.527, Average Loss: 4.198, avg. samples / sec: 53461.84
Iteration:   3020, Loss function: 2.850, Average Loss: 4.225, avg. samples / sec: 53500.20
Iteration:   3020, Loss function: 3.757, Average Loss: 4.187, avg. samples / sec: 53452.65
Iteration:   3020, Loss function: 4.264, Average Loss: 4.170, avg. samples / sec: 53504.97
Iteration:   3020, Loss function: 4.069, Average Loss: 4.200, avg. samples / sec: 53467.13
Iteration:   3020, Loss function: 6.767, Average Loss: 4.205, avg. samples / sec: 53464.76
Iteration:   3020, Loss function: 4.620, Average Loss: 4.180, avg. samples / sec: 53458.96
Iteration:   3020, Loss function: 3.571, Average Loss: 4.190, avg. samples / sec: 53440.27
Iteration:   3020, Loss function: 3.200, Average Loss: 4.169, avg. samples / sec: 53421.73
Iteration:   3020, Loss function: 5.160, Average Loss: 4.197, avg. samples / sec: 53272.00
Iteration:   3040, Loss function: 3.334, Average Loss: 4.200, avg. samples / sec: 53838.82
Iteration:   3040, Loss function: 4.009, Average Loss: 4.173, avg. samples / sec: 53945.81
Iteration:   3040, Loss function: 4.285, Average Loss: 4.169, avg. samples / sec: 53929.48
Iteration:   3040, Loss function: 3.691, Average Loss: 4.176, avg. samples / sec: 53876.02
Iteration:   3040, Loss function: 2.912, Average Loss: 4.198, avg. samples / sec: 53880.14
Iteration:   3040, Loss function: 4.135, Average Loss: 4.191, avg. samples / sec: 53902.39
Iteration:   3040, Loss function: 4.477, Average Loss: 4.216, avg. samples / sec: 53978.27
Iteration:   3040, Loss function: 3.921, Average Loss: 4.180, avg. samples / sec: 53914.83
Iteration:   3040, Loss function: 2.424, Average Loss: 4.183, avg. samples / sec: 53904.78
Iteration:   3040, Loss function: 3.854, Average Loss: 4.196, avg. samples / sec: 53917.22
Iteration:   3040, Loss function: 4.460, Average Loss: 4.185, avg. samples / sec: 53827.58
Iteration:   3040, Loss function: 4.759, Average Loss: 4.165, avg. samples / sec: 53896.44
Iteration:   3040, Loss function: 2.938, Average Loss: 4.157, avg. samples / sec: 53942.19
Iteration:   3040, Loss function: 3.653, Average Loss: 4.196, avg. samples / sec: 53855.02
Iteration:   3040, Loss function: 4.389, Average Loss: 4.183, avg. samples / sec: 53838.80
Iteration:   3040, Loss function: 3.203, Average Loss: 4.189, avg. samples / sec: 53884.11
Iteration:   3040, Loss function: 3.304, Average Loss: 4.204, avg. samples / sec: 53941.82
Iteration:   3040, Loss function: 3.222, Average Loss: 4.191, avg. samples / sec: 54070.55
Iteration:   3040, Loss function: 4.208, Average Loss: 4.183, avg. samples / sec: 53899.77
Iteration:   3040, Loss function: 4.691, Average Loss: 4.197, avg. samples / sec: 53887.02
Iteration:   3040, Loss function: 4.227, Average Loss: 4.188, avg. samples / sec: 53926.57
Iteration:   3040, Loss function: 3.437, Average Loss: 4.161, avg. samples / sec: 53856.91
Iteration:   3040, Loss function: 3.734, Average Loss: 4.162, avg. samples / sec: 53950.02
Iteration:   3040, Loss function: 4.197, Average Loss: 4.218, avg. samples / sec: 53861.75
Iteration:   3040, Loss function: 3.598, Average Loss: 4.193, avg. samples / sec: 53886.36
Iteration:   3040, Loss function: 3.828, Average Loss: 4.190, avg. samples / sec: 53803.14
Iteration:   3040, Loss function: 3.697, Average Loss: 4.172, avg. samples / sec: 53875.17
Iteration:   3040, Loss function: 4.673, Average Loss: 4.166, avg. samples / sec: 53848.93
Iteration:   3040, Loss function: 3.761, Average Loss: 4.196, avg. samples / sec: 53570.01
Iteration:   3040, Loss function: 4.269, Average Loss: 4.191, avg. samples / sec: 53573.05
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558641198.305 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.67 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.62s)
DONE (t=0.64s)
DONE (t=2.72s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17799
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32471
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04221
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18481
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.28758
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28958
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07825
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30948
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.45299
Current AP: 0.17799 AP goal: 0.23000
:::MLL 1558641202.312 eval_accuracy: {"value": 0.1779925903761461, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558641202.434 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558641202.440 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558641202.441 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 3.906, Average Loss: 4.192, avg. samples / sec: 7028.31
Iteration:   3060, Loss function: 3.225, Average Loss: 4.181, avg. samples / sec: 7033.62
Iteration:   3060, Loss function: 3.979, Average Loss: 4.171, avg. samples / sec: 7026.44
Iteration:   3060, Loss function: 4.332, Average Loss: 4.174, avg. samples / sec: 7028.53
Iteration:   3060, Loss function: 3.905, Average Loss: 4.172, avg. samples / sec: 7027.03
Iteration:   3060, Loss function: 4.445, Average Loss: 4.175, avg. samples / sec: 7027.79
Iteration:   3060, Loss function: 3.926, Average Loss: 4.171, avg. samples / sec: 7027.50
Iteration:   3060, Loss function: 4.231, Average Loss: 4.167, avg. samples / sec: 7026.47
Iteration:   3060, Loss function: 4.089, Average Loss: 4.176, avg. samples / sec: 7027.33
Iteration:   3060, Loss function: 4.243, Average Loss: 4.187, avg. samples / sec: 7032.20
Iteration:   3060, Loss function: 2.607, Average Loss: 4.160, avg. samples / sec: 7031.35
Iteration:   3060, Loss function: 4.440, Average Loss: 4.152, avg. samples / sec: 7027.44
Iteration:   3060, Loss function: 2.647, Average Loss: 4.159, avg. samples / sec: 7027.33
Iteration:   3060, Loss function: 4.572, Average Loss: 4.186, avg. samples / sec: 7026.92
Iteration:   3060, Loss function: 4.269, Average Loss: 4.190, avg. samples / sec: 7027.75
Iteration:   3060, Loss function: 3.660, Average Loss: 4.179, avg. samples / sec: 7026.56
Iteration:   3060, Loss function: 4.230, Average Loss: 4.188, avg. samples / sec: 7025.63
Iteration:   3060, Loss function: 3.741, Average Loss: 4.208, avg. samples / sec: 7025.70
Iteration:   3060, Loss function: 3.041, Average Loss: 4.153, avg. samples / sec: 7027.94
Iteration:   3060, Loss function: 3.651, Average Loss: 4.185, avg. samples / sec: 7027.37
Iteration:   3060, Loss function: 3.039, Average Loss: 4.178, avg. samples / sec: 7027.36
Iteration:   3060, Loss function: 3.228, Average Loss: 4.191, avg. samples / sec: 7027.18
Iteration:   3060, Loss function: 2.991, Average Loss: 4.212, avg. samples / sec: 7027.84
Iteration:   3060, Loss function: 2.986, Average Loss: 4.163, avg. samples / sec: 7028.04
Iteration:   3060, Loss function: 4.347, Average Loss: 4.180, avg. samples / sec: 7025.37
Iteration:   3060, Loss function: 3.326, Average Loss: 4.193, avg. samples / sec: 7026.82
Iteration:   3060, Loss function: 3.867, Average Loss: 4.183, avg. samples / sec: 7027.44
Iteration:   3060, Loss function: 3.482, Average Loss: 4.181, avg. samples / sec: 7026.40
Iteration:   3060, Loss function: 2.670, Average Loss: 4.183, avg. samples / sec: 7026.59
Iteration:   3060, Loss function: 3.632, Average Loss: 4.160, avg. samples / sec: 7027.04
:::MLL 1558641203.448 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558641203.449 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 5.555, Average Loss: 4.179, avg. samples / sec: 53099.80
Iteration:   3080, Loss function: 2.344, Average Loss: 4.162, avg. samples / sec: 53223.27
Iteration:   3080, Loss function: 3.350, Average Loss: 4.156, avg. samples / sec: 53212.90
Iteration:   3080, Loss function: 4.244, Average Loss: 4.170, avg. samples / sec: 53225.70
Iteration:   3080, Loss function: 3.300, Average Loss: 4.177, avg. samples / sec: 53250.98
Iteration:   3080, Loss function: 3.759, Average Loss: 4.153, avg. samples / sec: 53180.13
Iteration:   3080, Loss function: 4.824, Average Loss: 4.166, avg. samples / sec: 53103.20
Iteration:   3080, Loss function: 3.290, Average Loss: 4.175, avg. samples / sec: 53149.26
Iteration:   3080, Loss function: 3.585, Average Loss: 4.163, avg. samples / sec: 53098.42
Iteration:   3080, Loss function: 4.685, Average Loss: 4.177, avg. samples / sec: 53112.24
Iteration:   3080, Loss function: 3.585, Average Loss: 4.164, avg. samples / sec: 53087.70
Iteration:   3080, Loss function: 3.387, Average Loss: 4.162, avg. samples / sec: 53081.40
Iteration:   3080, Loss function: 3.513, Average Loss: 4.156, avg. samples / sec: 53066.29
Iteration:   3080, Loss function: 3.000, Average Loss: 4.196, avg. samples / sec: 53161.07
Iteration:   3080, Loss function: 3.575, Average Loss: 4.145, avg. samples / sec: 53065.19
Iteration:   3080, Loss function: 3.400, Average Loss: 4.168, avg. samples / sec: 53003.02
Iteration:   3080, Loss function: 3.591, Average Loss: 4.146, avg. samples / sec: 53068.00
Iteration:   3080, Loss function: 3.405, Average Loss: 4.181, avg. samples / sec: 53043.16
Iteration:   3080, Loss function: 3.651, Average Loss: 4.163, avg. samples / sec: 53205.65
Iteration:   3080, Loss function: 2.957, Average Loss: 4.197, avg. samples / sec: 53213.80
Iteration:   3080, Loss function: 3.490, Average Loss: 4.173, avg. samples / sec: 53188.34
Iteration:   3080, Loss function: 4.080, Average Loss: 4.169, avg. samples / sec: 53125.50
Iteration:   3080, Loss function: 4.719, Average Loss: 4.142, avg. samples / sec: 53087.08
Iteration:   3080, Loss function: 3.826, Average Loss: 4.180, avg. samples / sec: 53102.58
Iteration:   3080, Loss function: 2.961, Average Loss: 4.181, avg. samples / sec: 53097.06
Iteration:   3080, Loss function: 2.506, Average Loss: 4.153, avg. samples / sec: 53087.10
Iteration:   3080, Loss function: 3.862, Average Loss: 4.172, avg. samples / sec: 53119.01
Iteration:   3080, Loss function: 3.763, Average Loss: 4.148, avg. samples / sec: 53115.03
Iteration:   3080, Loss function: 3.855, Average Loss: 4.172, avg. samples / sec: 53079.70
Iteration:   3080, Loss function: 3.157, Average Loss: 4.173, avg. samples / sec: 53032.56
Iteration:   3100, Loss function: 3.981, Average Loss: 4.172, avg. samples / sec: 53633.74
Iteration:   3100, Loss function: 2.773, Average Loss: 4.153, avg. samples / sec: 53705.57
Iteration:   3100, Loss function: 2.912, Average Loss: 4.155, avg. samples / sec: 53616.17
Iteration:   3100, Loss function: 5.206, Average Loss: 4.153, avg. samples / sec: 53626.54
Iteration:   3100, Loss function: 4.579, Average Loss: 4.154, avg. samples / sec: 53618.83
Iteration:   3100, Loss function: 3.062, Average Loss: 4.145, avg. samples / sec: 53468.80
Iteration:   3100, Loss function: 3.070, Average Loss: 4.128, avg. samples / sec: 53650.10
Iteration:   3100, Loss function: 4.034, Average Loss: 4.166, avg. samples / sec: 53589.47
Iteration:   3100, Loss function: 3.432, Average Loss: 4.166, avg. samples / sec: 53561.69
Iteration:   3100, Loss function: 2.984, Average Loss: 4.148, avg. samples / sec: 53606.87
Iteration:   3100, Loss function: 3.775, Average Loss: 4.153, avg. samples / sec: 53483.73
Iteration:   3100, Loss function: 2.837, Average Loss: 4.163, avg. samples / sec: 53491.28
Iteration:   3100, Loss function: 4.077, Average Loss: 4.185, avg. samples / sec: 53570.97
Iteration:   3100, Loss function: 3.744, Average Loss: 4.172, avg. samples / sec: 53625.56
Iteration:   3100, Loss function: 2.562, Average Loss: 4.138, avg. samples / sec: 53591.18
Iteration:   3100, Loss function: 3.811, Average Loss: 4.160, avg. samples / sec: 53539.14
Iteration:   3100, Loss function: 4.006, Average Loss: 4.153, avg. samples / sec: 53510.84
Iteration:   3100, Loss function: 2.874, Average Loss: 4.129, avg. samples / sec: 53607.81
Iteration:   3100, Loss function: 4.152, Average Loss: 4.158, avg. samples / sec: 53600.31
Iteration:   3100, Loss function: 4.049, Average Loss: 4.164, avg. samples / sec: 53708.72
Iteration:   3100, Loss function: 3.852, Average Loss: 4.171, avg. samples / sec: 53592.30
Iteration:   3100, Loss function: 4.202, Average Loss: 4.166, avg. samples / sec: 53643.15
Iteration:   3100, Loss function: 4.717, Average Loss: 4.142, avg. samples / sec: 53601.13
Iteration:   3100, Loss function: 3.159, Average Loss: 4.169, avg. samples / sec: 53598.17
Iteration:   3100, Loss function: 3.231, Average Loss: 4.185, avg. samples / sec: 53447.77
Iteration:   3100, Loss function: 3.040, Average Loss: 4.146, avg. samples / sec: 53233.46
Iteration:   3100, Loss function: 3.797, Average Loss: 4.145, avg. samples / sec: 53367.60
Iteration:   3100, Loss function: 4.012, Average Loss: 4.141, avg. samples / sec: 53629.99
Iteration:   3100, Loss function: 3.685, Average Loss: 4.145, avg. samples / sec: 53259.05
Iteration:   3100, Loss function: 2.619, Average Loss: 4.164, avg. samples / sec: 53607.89
Iteration:   3120, Loss function: 4.065, Average Loss: 4.161, avg. samples / sec: 53685.68
Iteration:   3120, Loss function: 3.026, Average Loss: 4.145, avg. samples / sec: 53767.16
Iteration:   3120, Loss function: 3.564, Average Loss: 4.140, avg. samples / sec: 53734.60
Iteration:   3120, Loss function: 3.673, Average Loss: 4.159, avg. samples / sec: 53793.82
Iteration:   3120, Loss function: 3.928, Average Loss: 4.145, avg. samples / sec: 53706.38
Iteration:   3120, Loss function: 4.463, Average Loss: 4.132, avg. samples / sec: 53758.13
Iteration:   3120, Loss function: 3.541, Average Loss: 4.140, avg. samples / sec: 53724.18
Iteration:   3120, Loss function: 3.717, Average Loss: 4.152, avg. samples / sec: 53755.53
Iteration:   3120, Loss function: 2.674, Average Loss: 4.131, avg. samples / sec: 53749.87
Iteration:   3120, Loss function: 2.717, Average Loss: 4.171, avg. samples / sec: 53782.57
Iteration:   3120, Loss function: 5.183, Average Loss: 4.124, avg. samples / sec: 53789.79
Iteration:   3120, Loss function: 2.798, Average Loss: 4.160, avg. samples / sec: 53782.42
Iteration:   3120, Loss function: 2.612, Average Loss: 4.138, avg. samples / sec: 53709.82
Iteration:   3120, Loss function: 3.366, Average Loss: 4.117, avg. samples / sec: 53715.70
Iteration:   3120, Loss function: 3.402, Average Loss: 4.131, avg. samples / sec: 53965.26
Iteration:   3120, Loss function: 3.822, Average Loss: 4.132, avg. samples / sec: 53958.96
Iteration:   3120, Loss function: 2.906, Average Loss: 4.134, avg. samples / sec: 53963.80
Iteration:   3120, Loss function: 3.640, Average Loss: 4.152, avg. samples / sec: 53674.25
Iteration:   3120, Loss function: 4.103, Average Loss: 4.147, avg. samples / sec: 53759.67
Iteration:   3120, Loss function: 3.267, Average Loss: 4.115, avg. samples / sec: 53778.34
Iteration:   3120, Loss function: 3.262, Average Loss: 4.142, avg. samples / sec: 53771.08
Iteration:   3120, Loss function: 4.722, Average Loss: 4.160, avg. samples / sec: 53812.67
Iteration:   3120, Loss function: 4.628, Average Loss: 4.160, avg. samples / sec: 53769.66
Iteration:   3120, Loss function: 3.413, Average Loss: 4.131, avg. samples / sec: 53781.69
Iteration:   3120, Loss function: 2.804, Average Loss: 4.140, avg. samples / sec: 53728.87
Iteration:   3120, Loss function: 4.160, Average Loss: 4.160, avg. samples / sec: 53752.72
Iteration:   3120, Loss function: 2.786, Average Loss: 4.170, avg. samples / sec: 53784.31
Iteration:   3120, Loss function: 4.255, Average Loss: 4.151, avg. samples / sec: 53803.80
Iteration:   3120, Loss function: 2.942, Average Loss: 4.129, avg. samples / sec: 53731.73
Iteration:   3120, Loss function: 3.746, Average Loss: 4.151, avg. samples / sec: 53700.76
Iteration:   3140, Loss function: 3.442, Average Loss: 4.123, avg. samples / sec: 53857.59
Iteration:   3140, Loss function: 3.444, Average Loss: 4.117, avg. samples / sec: 53706.69
Iteration:   3140, Loss function: 3.462, Average Loss: 4.126, avg. samples / sec: 53692.12
Iteration:   3140, Loss function: 4.070, Average Loss: 4.132, avg. samples / sec: 53616.17
Iteration:   3140, Loss function: 3.960, Average Loss: 4.132, avg. samples / sec: 53669.04
Iteration:   3140, Loss function: 4.423, Average Loss: 4.145, avg. samples / sec: 53679.59
Iteration:   3140, Loss function: 3.914, Average Loss: 4.117, avg. samples / sec: 53708.39
Iteration:   3140, Loss function: 3.136, Average Loss: 4.117, avg. samples / sec: 53688.63
Iteration:   3140, Loss function: 2.472, Average Loss: 4.112, avg. samples / sec: 53663.23
Iteration:   3140, Loss function: 2.957, Average Loss: 4.134, avg. samples / sec: 53637.42
Iteration:   3140, Loss function: 4.743, Average Loss: 4.125, avg. samples / sec: 53678.83
Iteration:   3140, Loss function: 4.365, Average Loss: 4.129, avg. samples / sec: 53588.45
Iteration:   3140, Loss function: 3.436, Average Loss: 4.134, avg. samples / sec: 53714.08
Iteration:   3140, Loss function: 4.155, Average Loss: 4.159, avg. samples / sec: 53628.70
Iteration:   3140, Loss function: 2.543, Average Loss: 4.145, avg. samples / sec: 53567.57
Iteration:   3140, Loss function: 3.717, Average Loss: 4.120, avg. samples / sec: 53603.51
Iteration:   3140, Loss function: 4.510, Average Loss: 4.104, avg. samples / sec: 53575.37
Iteration:   3140, Loss function: 3.967, Average Loss: 4.144, avg. samples / sec: 53752.19
Iteration:   3140, Loss function: 3.595, Average Loss: 4.148, avg. samples / sec: 53315.20
Iteration:   3140, Loss function: 2.998, Average Loss: 4.149, avg. samples / sec: 53653.82
Iteration:   3140, Loss function: 2.096, Average Loss: 4.149, avg. samples / sec: 53675.23
Iteration:   3140, Loss function: 3.018, Average Loss: 4.102, avg. samples / sec: 53621.70
Iteration:   3140, Loss function: 3.835, Average Loss: 4.157, avg. samples / sec: 53668.32
Iteration:   3140, Loss function: 4.067, Average Loss: 4.147, avg. samples / sec: 53615.58
Iteration:   3140, Loss function: 2.845, Average Loss: 4.135, avg. samples / sec: 53585.00
Iteration:   3140, Loss function: 3.394, Average Loss: 4.131, avg. samples / sec: 53600.19
Iteration:   3140, Loss function: 3.654, Average Loss: 4.120, avg. samples / sec: 53619.15
Iteration:   3140, Loss function: 2.481, Average Loss: 4.128, avg. samples / sec: 53614.91
Iteration:   3140, Loss function: 1.979, Average Loss: 4.123, avg. samples / sec: 53666.05
Iteration:   3140, Loss function: 3.087, Average Loss: 4.138, avg. samples / sec: 53629.66
:::MLL 1558641205.643 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558641205.644 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 4.395, Average Loss: 4.109, avg. samples / sec: 53416.53
Iteration:   3160, Loss function: 2.857, Average Loss: 4.113, avg. samples / sec: 53486.09
Iteration:   3160, Loss function: 4.214, Average Loss: 4.124, avg. samples / sec: 53493.29
Iteration:   3160, Loss function: 2.837, Average Loss: 4.112, avg. samples / sec: 53520.76
Iteration:   3160, Loss function: 2.471, Average Loss: 4.103, avg. samples / sec: 53502.78
Iteration:   3160, Loss function: 4.202, Average Loss: 4.105, avg. samples / sec: 53494.67
Iteration:   3160, Loss function: 3.239, Average Loss: 4.093, avg. samples / sec: 53580.24
Iteration:   3160, Loss function: 3.208, Average Loss: 4.119, avg. samples / sec: 53484.14
Iteration:   3160, Loss function: 2.581, Average Loss: 4.146, avg. samples / sec: 53508.53
Iteration:   3160, Loss function: 3.547, Average Loss: 4.101, avg. samples / sec: 53513.02
Iteration:   3160, Loss function: 2.448, Average Loss: 4.120, avg. samples / sec: 53446.00
Iteration:   3160, Loss function: 2.865, Average Loss: 4.132, avg. samples / sec: 53436.80
Iteration:   3160, Loss function: 3.212, Average Loss: 4.108, avg. samples / sec: 53393.66
Iteration:   3160, Loss function: 3.783, Average Loss: 4.130, avg. samples / sec: 53488.01
Iteration:   3160, Loss function: 2.988, Average Loss: 4.112, avg. samples / sec: 53448.58
Iteration:   3160, Loss function: 3.254, Average Loss: 4.119, avg. samples / sec: 53463.01
Iteration:   3160, Loss function: 3.766, Average Loss: 4.107, avg. samples / sec: 53436.50
Iteration:   3160, Loss function: 4.850, Average Loss: 4.138, avg. samples / sec: 53522.08
Iteration:   3160, Loss function: 4.074, Average Loss: 4.122, avg. samples / sec: 53519.17
Iteration:   3160, Loss function: 4.650, Average Loss: 4.136, avg. samples / sec: 53473.56
Iteration:   3160, Loss function: 3.466, Average Loss: 4.142, avg. samples / sec: 53483.41
Iteration:   3160, Loss function: 4.066, Average Loss: 4.118, avg. samples / sec: 53519.64
Iteration:   3160, Loss function: 3.910, Average Loss: 4.114, avg. samples / sec: 53517.18
Iteration:   3160, Loss function: 3.078, Average Loss: 4.085, avg. samples / sec: 53471.88
Iteration:   3160, Loss function: 3.605, Average Loss: 4.142, avg. samples / sec: 53471.23
Iteration:   3160, Loss function: 3.054, Average Loss: 4.137, avg. samples / sec: 53456.06
Iteration:   3160, Loss function: 4.917, Average Loss: 4.136, avg. samples / sec: 53422.99
Iteration:   3160, Loss function: 3.872, Average Loss: 4.110, avg. samples / sec: 53502.59
Iteration:   3160, Loss function: 3.335, Average Loss: 4.126, avg. samples / sec: 53497.58
Iteration:   3160, Loss function: 5.024, Average Loss: 4.123, avg. samples / sec: 53462.18
Iteration:   3180, Loss function: 3.188, Average Loss: 4.105, avg. samples / sec: 53668.26
Iteration:   3180, Loss function: 3.557, Average Loss: 4.110, avg. samples / sec: 53570.40
Iteration:   3180, Loss function: 3.927, Average Loss: 4.108, avg. samples / sec: 53618.60
Iteration:   3180, Loss function: 2.955, Average Loss: 4.094, avg. samples / sec: 53581.68
Iteration:   3180, Loss function: 4.312, Average Loss: 4.093, avg. samples / sec: 53577.26
Iteration:   3180, Loss function: 3.153, Average Loss: 4.120, avg. samples / sec: 53624.62
Iteration:   3180, Loss function: 3.106, Average Loss: 4.088, avg. samples / sec: 53591.85
Iteration:   3180, Loss function: 6.005, Average Loss: 4.094, avg. samples / sec: 53623.85
Iteration:   3180, Loss function: 3.150, Average Loss: 4.099, avg. samples / sec: 53608.95
Iteration:   3180, Loss function: 3.902, Average Loss: 4.138, avg. samples / sec: 53575.04
Iteration:   3180, Loss function: 4.012, Average Loss: 4.103, avg. samples / sec: 53512.65
Iteration:   3180, Loss function: 2.090, Average Loss: 4.114, avg. samples / sec: 53557.43
Iteration:   3180, Loss function: 3.034, Average Loss: 4.082, avg. samples / sec: 53510.17
Iteration:   3180, Loss function: 2.732, Average Loss: 4.098, avg. samples / sec: 53386.66
Iteration:   3180, Loss function: 3.827, Average Loss: 4.122, avg. samples / sec: 53656.66
Iteration:   3180, Loss function: 3.551, Average Loss: 4.114, avg. samples / sec: 53585.70
Iteration:   3180, Loss function: 3.057, Average Loss: 4.127, avg. samples / sec: 53602.00
Iteration:   3180, Loss function: 4.361, Average Loss: 4.074, avg. samples / sec: 53590.36
Iteration:   3180, Loss function: 2.713, Average Loss: 4.127, avg. samples / sec: 53563.52
Iteration:   3180, Loss function: 3.747, Average Loss: 4.126, avg. samples / sec: 53546.77
Iteration:   3180, Loss function: 3.420, Average Loss: 4.107, avg. samples / sec: 53552.85
Iteration:   3180, Loss function: 5.155, Average Loss: 4.117, avg. samples / sec: 53594.50
Iteration:   3180, Loss function: 3.823, Average Loss: 4.126, avg. samples / sec: 53574.41
Iteration:   3180, Loss function: 3.587, Average Loss: 4.111, avg. samples / sec: 53589.12
Iteration:   3180, Loss function: 3.123, Average Loss: 4.095, avg. samples / sec: 53563.42
Iteration:   3180, Loss function: 4.466, Average Loss: 4.107, avg. samples / sec: 53363.70
Iteration:   3180, Loss function: 3.874, Average Loss: 4.127, avg. samples / sec: 53498.67
Iteration:   3180, Loss function: 4.291, Average Loss: 4.101, avg. samples / sec: 53518.85
Iteration:   3180, Loss function: 3.465, Average Loss: 4.100, avg. samples / sec: 53290.31
Iteration:   3180, Loss function: 3.778, Average Loss: 4.106, avg. samples / sec: 53289.02
Iteration:   3200, Loss function: 3.818, Average Loss: 4.097, avg. samples / sec: 53831.59
Iteration:   3200, Loss function: 3.878, Average Loss: 4.088, avg. samples / sec: 53820.85
Iteration:   3200, Loss function: 4.066, Average Loss: 4.094, avg. samples / sec: 53855.92
Iteration:   3200, Loss function: 2.467, Average Loss: 4.068, avg. samples / sec: 53904.68
Iteration:   3200, Loss function: 3.901, Average Loss: 4.090, avg. samples / sec: 54103.31
Iteration:   3200, Loss function: 3.595, Average Loss: 4.085, avg. samples / sec: 53828.93
Iteration:   3200, Loss function: 3.262, Average Loss: 4.127, avg. samples / sec: 53820.96
Iteration:   3200, Loss function: 2.884, Average Loss: 4.075, avg. samples / sec: 53802.22
Iteration:   3200, Loss function: 3.524, Average Loss: 4.100, avg. samples / sec: 53858.70
Iteration:   3200, Loss function: 3.632, Average Loss: 4.109, avg. samples / sec: 53793.51
Iteration:   3200, Loss function: 3.031, Average Loss: 4.093, avg. samples / sec: 53757.15
Iteration:   3200, Loss function: 4.377, Average Loss: 4.086, avg. samples / sec: 53860.04
Iteration:   3200, Loss function: 3.181, Average Loss: 4.094, avg. samples / sec: 54092.76
Iteration:   3200, Loss function: 2.886, Average Loss: 4.082, avg. samples / sec: 53770.83
Iteration:   3200, Loss function: 4.104, Average Loss: 4.080, avg. samples / sec: 53777.23
Iteration:   3200, Loss function: 2.284, Average Loss: 4.095, avg. samples / sec: 53716.35
Iteration:   3200, Loss function: 4.258, Average Loss: 4.091, avg. samples / sec: 54025.90
Iteration:   3200, Loss function: 2.749, Average Loss: 4.111, avg. samples / sec: 53790.00
Iteration:   3200, Loss function: 3.600, Average Loss: 4.105, avg. samples / sec: 53808.13
Iteration:   3200, Loss function: 2.877, Average Loss: 4.111, avg. samples / sec: 53829.90
Iteration:   3200, Loss function: 2.804, Average Loss: 4.105, avg. samples / sec: 53840.88
Iteration:   3200, Loss function: 3.633, Average Loss: 4.110, avg. samples / sec: 53797.90
Iteration:   3200, Loss function: 2.790, Average Loss: 4.112, avg. samples / sec: 53859.61
Iteration:   3200, Loss function: 4.309, Average Loss: 4.091, avg. samples / sec: 53857.98
Iteration:   3200, Loss function: 3.572, Average Loss: 4.061, avg. samples / sec: 53792.11
Iteration:   3200, Loss function: 3.949, Average Loss: 4.117, avg. samples / sec: 53782.65
Iteration:   3200, Loss function: 3.393, Average Loss: 4.094, avg. samples / sec: 53812.76
Iteration:   3200, Loss function: 3.882, Average Loss: 4.084, avg. samples / sec: 53829.80
Iteration:   3200, Loss function: 5.507, Average Loss: 4.104, avg. samples / sec: 53787.76
Iteration:   3200, Loss function: 4.493, Average Loss: 4.116, avg. samples / sec: 53787.39
:::MLL 1558641207.836 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558641207.837 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 2.389, Average Loss: 4.072, avg. samples / sec: 53420.66
Iteration:   3220, Loss function: 2.995, Average Loss: 4.077, avg. samples / sec: 53452.39
Iteration:   3220, Loss function: 3.071, Average Loss: 4.076, avg. samples / sec: 53395.20
Iteration:   3220, Loss function: 3.336, Average Loss: 4.071, avg. samples / sec: 53449.98
Iteration:   3220, Loss function: 4.396, Average Loss: 4.084, avg. samples / sec: 53451.80
Iteration:   3220, Loss function: 3.029, Average Loss: 4.079, avg. samples / sec: 53379.50
Iteration:   3220, Loss function: 3.479, Average Loss: 4.087, avg. samples / sec: 53311.61
Iteration:   3220, Loss function: 2.669, Average Loss: 4.060, avg. samples / sec: 53350.12
Iteration:   3220, Loss function: 4.081, Average Loss: 4.082, avg. samples / sec: 53377.70
Iteration:   3220, Loss function: 2.912, Average Loss: 4.058, avg. samples / sec: 53307.74
Iteration:   3220, Loss function: 4.306, Average Loss: 4.079, avg. samples / sec: 53287.97
Iteration:   3220, Loss function: 3.585, Average Loss: 4.098, avg. samples / sec: 53289.54
Iteration:   3220, Loss function: 4.670, Average Loss: 4.083, avg. samples / sec: 53307.16
Iteration:   3220, Loss function: 2.252, Average Loss: 4.080, avg. samples / sec: 53254.58
Iteration:   3220, Loss function: 3.477, Average Loss: 4.117, avg. samples / sec: 53278.70
Iteration:   3220, Loss function: 3.731, Average Loss: 4.073, avg. samples / sec: 53300.32
Iteration:   3220, Loss function: 3.177, Average Loss: 4.051, avg. samples / sec: 53465.79
Iteration:   3220, Loss function: 4.085, Average Loss: 4.085, avg. samples / sec: 53238.71
Iteration:   3220, Loss function: 3.450, Average Loss: 4.079, avg. samples / sec: 53443.55
Iteration:   3220, Loss function: 2.793, Average Loss: 4.109, avg. samples / sec: 53453.75
Iteration:   3220, Loss function: 2.888, Average Loss: 4.110, avg. samples / sec: 53419.08
Iteration:   3220, Loss function: 3.483, Average Loss: 4.094, avg. samples / sec: 53333.55
Iteration:   3220, Loss function: 4.231, Average Loss: 4.098, avg. samples / sec: 53311.27
Iteration:   3220, Loss function: 3.956, Average Loss: 4.103, avg. samples / sec: 53267.69
Iteration:   3220, Loss function: 3.403, Average Loss: 4.080, avg. samples / sec: 53326.14
Iteration:   3220, Loss function: 3.103, Average Loss: 4.099, avg. samples / sec: 53314.44
Iteration:   3220, Loss function: 2.565, Average Loss: 4.089, avg. samples / sec: 53274.59
Iteration:   3220, Loss function: 3.275, Average Loss: 4.067, avg. samples / sec: 53290.51
Iteration:   3220, Loss function: 3.249, Average Loss: 4.095, avg. samples / sec: 53303.43
Iteration:   3220, Loss function: 3.934, Average Loss: 4.098, avg. samples / sec: 53249.41
Iteration:   3240, Loss function: 3.012, Average Loss: 4.085, avg. samples / sec: 53924.96
Iteration:   3240, Loss function: 3.182, Average Loss: 4.039, avg. samples / sec: 53943.33
Iteration:   3240, Loss function: 3.995, Average Loss: 4.076, avg. samples / sec: 53822.09
Iteration:   3240, Loss function: 4.276, Average Loss: 4.077, avg. samples / sec: 53904.35
Iteration:   3240, Loss function: 4.049, Average Loss: 4.063, avg. samples / sec: 53742.02
Iteration:   3240, Loss function: 3.531, Average Loss: 4.070, avg. samples / sec: 53894.39
Iteration:   3240, Loss function: 3.576, Average Loss: 4.068, avg. samples / sec: 53839.40
Iteration:   3240, Loss function: 2.359, Average Loss: 4.040, avg. samples / sec: 53811.42
Iteration:   3240, Loss function: 3.581, Average Loss: 4.073, avg. samples / sec: 53741.55
Iteration:   3240, Loss function: 2.995, Average Loss: 4.106, avg. samples / sec: 53863.87
Iteration:   3240, Loss function: 3.672, Average Loss: 4.061, avg. samples / sec: 53877.77
Iteration:   3240, Loss function: 2.802, Average Loss: 4.070, avg. samples / sec: 53810.80
Iteration:   3240, Loss function: 3.220, Average Loss: 4.053, avg. samples / sec: 53776.94
Iteration:   3240, Loss function: 2.559, Average Loss: 4.073, avg. samples / sec: 53881.58
Iteration:   3240, Loss function: 3.811, Average Loss: 4.065, avg. samples / sec: 53716.44
Iteration:   3240, Loss function: 4.416, Average Loss: 4.065, avg. samples / sec: 53639.60
Iteration:   3240, Loss function: 3.152, Average Loss: 4.087, avg. samples / sec: 53963.88
Iteration:   3240, Loss function: 3.075, Average Loss: 4.067, avg. samples / sec: 53780.80
Iteration:   3240, Loss function: 2.521, Average Loss: 4.083, avg. samples / sec: 53837.30
Iteration:   3240, Loss function: 2.330, Average Loss: 4.085, avg. samples / sec: 53846.46
Iteration:   3240, Loss function: 3.136, Average Loss: 4.071, avg. samples / sec: 53856.58
Iteration:   3240, Loss function: 2.938, Average Loss: 4.088, avg. samples / sec: 53854.98
Iteration:   3240, Loss function: 2.973, Average Loss: 4.093, avg. samples / sec: 53760.92
Iteration:   3240, Loss function: 4.428, Average Loss: 4.076, avg. samples / sec: 53874.88
Iteration:   3240, Loss function: 3.685, Average Loss: 4.091, avg. samples / sec: 53842.69
Iteration:   3240, Loss function: 3.454, Average Loss: 4.061, avg. samples / sec: 53509.30
Iteration:   3240, Loss function: 3.203, Average Loss: 4.064, avg. samples / sec: 53505.64
Iteration:   3240, Loss function: 2.410, Average Loss: 4.056, avg. samples / sec: 53885.86
Iteration:   3240, Loss function: 4.267, Average Loss: 4.086, avg. samples / sec: 53866.26
Iteration:   3240, Loss function: 3.013, Average Loss: 4.095, avg. samples / sec: 53687.97
Iteration:   3260, Loss function: 3.497, Average Loss: 4.064, avg. samples / sec: 54002.09
Iteration:   3260, Loss function: 3.563, Average Loss: 4.056, avg. samples / sec: 54006.52
Iteration:   3260, Loss function: 3.267, Average Loss: 4.061, avg. samples / sec: 54019.75
Iteration:   3260, Loss function: 4.549, Average Loss: 4.052, avg. samples / sec: 54219.54
Iteration:   3260, Loss function: 3.284, Average Loss: 4.049, avg. samples / sec: 54079.76
Iteration:   3260, Loss function: 4.394, Average Loss: 4.032, avg. samples / sec: 53957.68
Iteration:   3260, Loss function: 3.528, Average Loss: 4.050, avg. samples / sec: 53967.37
Iteration:   3260, Loss function: 3.702, Average Loss: 4.079, avg. samples / sec: 53935.59
Iteration:   3260, Loss function: 4.083, Average Loss: 4.040, avg. samples / sec: 54007.58
Iteration:   3260, Loss function: 4.286, Average Loss: 4.059, avg. samples / sec: 53960.86
Iteration:   3260, Loss function: 3.728, Average Loss: 4.064, avg. samples / sec: 54016.17
Iteration:   3260, Loss function: 2.825, Average Loss: 4.029, avg. samples / sec: 53969.29
Iteration:   3260, Loss function: 3.180, Average Loss: 4.051, avg. samples / sec: 53971.40
Iteration:   3260, Loss function: 4.004, Average Loss: 4.064, avg. samples / sec: 53960.24
Iteration:   3260, Loss function: 2.823, Average Loss: 4.061, avg. samples / sec: 53915.47
Iteration:   3260, Loss function: 3.222, Average Loss: 4.059, avg. samples / sec: 54028.51
Iteration:   3260, Loss function: 4.122, Average Loss: 4.094, avg. samples / sec: 53924.61
Iteration:   3260, Loss function: 4.071, Average Loss: 4.050, avg. samples / sec: 54136.89
Iteration:   3260, Loss function: 3.842, Average Loss: 4.072, avg. samples / sec: 53984.82
Iteration:   3260, Loss function: 2.809, Average Loss: 4.076, avg. samples / sec: 53982.90
Iteration:   3260, Loss function: 2.740, Average Loss: 4.080, avg. samples / sec: 53997.83
Iteration:   3260, Loss function: 2.915, Average Loss: 4.057, avg. samples / sec: 53940.37
Iteration:   3260, Loss function: 3.065, Average Loss: 4.077, avg. samples / sec: 53984.16
Iteration:   3260, Loss function: 2.664, Average Loss: 4.071, avg. samples / sec: 53914.08
Iteration:   3260, Loss function: 3.686, Average Loss: 4.069, avg. samples / sec: 53958.67
Iteration:   3260, Loss function: 3.127, Average Loss: 4.087, avg. samples / sec: 53942.34
Iteration:   3260, Loss function: 4.815, Average Loss: 4.049, avg. samples / sec: 53955.47
Iteration:   3260, Loss function: 5.127, Average Loss: 4.074, avg. samples / sec: 53976.61
Iteration:   3260, Loss function: 3.141, Average Loss: 4.057, avg. samples / sec: 53915.28
Iteration:   3260, Loss function: 3.514, Average Loss: 4.080, avg. samples / sec: 53969.81
Iteration:   3280, Loss function: 5.130, Average Loss: 4.045, avg. samples / sec: 54002.65
Iteration:   3280, Loss function: 3.498, Average Loss: 4.046, avg. samples / sec: 54044.13
Iteration:   3280, Loss function: 2.896, Average Loss: 4.029, avg. samples / sec: 54017.33
Iteration:   3280, Loss function: 2.999, Average Loss: 4.040, avg. samples / sec: 54056.14
Iteration:   3280, Loss function: 2.946, Average Loss: 4.038, avg. samples / sec: 54003.65
Iteration:   3280, Loss function: 4.689, Average Loss: 4.048, avg. samples / sec: 54012.61
Iteration:   3280, Loss function: 2.872, Average Loss: 4.048, avg. samples / sec: 53956.46
Iteration:   3280, Loss function: 3.930, Average Loss: 4.064, avg. samples / sec: 54003.96
Iteration:   3280, Loss function: 4.872, Average Loss: 4.059, avg. samples / sec: 54034.43
Iteration:   3280, Loss function: 3.945, Average Loss: 4.043, avg. samples / sec: 54037.98
Iteration:   3280, Loss function: 3.791, Average Loss: 4.082, avg. samples / sec: 54072.04
Iteration:   3280, Loss function: 3.281, Average Loss: 4.039, avg. samples / sec: 53980.95
Iteration:   3280, Loss function: 3.513, Average Loss: 4.053, avg. samples / sec: 54006.73
Iteration:   3280, Loss function: 2.978, Average Loss: 4.047, avg. samples / sec: 54032.47
Iteration:   3280, Loss function: 3.410, Average Loss: 4.025, avg. samples / sec: 53989.70
Iteration:   3280, Loss function: 2.529, Average Loss: 4.036, avg. samples / sec: 54055.84
Iteration:   3280, Loss function: 3.081, Average Loss: 4.047, avg. samples / sec: 53930.34
Iteration:   3280, Loss function: 3.918, Average Loss: 4.024, avg. samples / sec: 53976.55
Iteration:   3280, Loss function: 4.649, Average Loss: 4.063, avg. samples / sec: 54004.18
Iteration:   3280, Loss function: 3.702, Average Loss: 4.064, avg. samples / sec: 54037.21
Iteration:   3280, Loss function: 2.128, Average Loss: 4.065, avg. samples / sec: 54003.40
Iteration:   3280, Loss function: 4.887, Average Loss: 4.050, avg. samples / sec: 54005.88
Iteration:   3280, Loss function: 4.365, Average Loss: 4.067, avg. samples / sec: 53988.17
Iteration:   3280, Loss function: 3.574, Average Loss: 4.048, avg. samples / sec: 54042.74
Iteration:   3280, Loss function: 4.134, Average Loss: 4.065, avg. samples / sec: 53971.20
Iteration:   3280, Loss function: 3.958, Average Loss: 4.059, avg. samples / sec: 53993.22
Iteration:   3280, Loss function: 4.706, Average Loss: 4.086, avg. samples / sec: 54001.66
Iteration:   3280, Loss function: 4.715, Average Loss: 4.066, avg. samples / sec: 54000.71
Iteration:   3280, Loss function: 3.402, Average Loss: 4.036, avg. samples / sec: 53999.24
Iteration:   3280, Loss function: 2.896, Average Loss: 4.067, avg. samples / sec: 54028.86
:::MLL 1558641210.021 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558641210.021 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 4.090, Average Loss: 4.053, avg. samples / sec: 53695.07
Iteration:   3300, Loss function: 2.553, Average Loss: 4.035, avg. samples / sec: 53663.85
Iteration:   3300, Loss function: 2.758, Average Loss: 4.036, avg. samples / sec: 53671.63
Iteration:   3300, Loss function: 3.695, Average Loss: 4.024, avg. samples / sec: 53656.31
Iteration:   3300, Loss function: 3.295, Average Loss: 4.027, avg. samples / sec: 53695.78
Iteration:   3300, Loss function: 3.560, Average Loss: 4.035, avg. samples / sec: 53685.41
Iteration:   3300, Loss function: 3.899, Average Loss: 4.037, avg. samples / sec: 53671.37
Iteration:   3300, Loss function: 4.775, Average Loss: 4.074, avg. samples / sec: 53670.71
Iteration:   3300, Loss function: 3.170, Average Loss: 4.013, avg. samples / sec: 53638.79
Iteration:   3300, Loss function: 3.745, Average Loss: 4.031, avg. samples / sec: 53667.61
Iteration:   3300, Loss function: 3.921, Average Loss: 4.044, avg. samples / sec: 53656.02
Iteration:   3300, Loss function: 2.969, Average Loss: 4.009, avg. samples / sec: 53657.72
Iteration:   3300, Loss function: 2.885, Average Loss: 4.036, avg. samples / sec: 53692.16
Iteration:   3300, Loss function: 4.485, Average Loss: 4.013, avg. samples / sec: 53677.28
Iteration:   3300, Loss function: 2.945, Average Loss: 4.031, avg. samples / sec: 53623.95
Iteration:   3300, Loss function: 2.728, Average Loss: 4.033, avg. samples / sec: 53565.17
Iteration:   3300, Loss function: 2.590, Average Loss: 4.044, avg. samples / sec: 53594.79
Iteration:   3300, Loss function: 3.695, Average Loss: 4.028, avg. samples / sec: 53558.20
Iteration:   3300, Loss function: 2.747, Average Loss: 4.057, avg. samples / sec: 53719.10
Iteration:   3300, Loss function: 2.787, Average Loss: 4.054, avg. samples / sec: 53642.81
Iteration:   3300, Loss function: 3.177, Average Loss: 4.054, avg. samples / sec: 53652.43
Iteration:   3300, Loss function: 3.763, Average Loss: 4.039, avg. samples / sec: 53656.53
Iteration:   3300, Loss function: 2.554, Average Loss: 4.049, avg. samples / sec: 53646.38
Iteration:   3300, Loss function: 3.395, Average Loss: 4.074, avg. samples / sec: 53695.97
Iteration:   3300, Loss function: 2.724, Average Loss: 4.047, avg. samples / sec: 53691.49
Iteration:   3300, Loss function: 3.180, Average Loss: 4.025, avg. samples / sec: 53692.84
Iteration:   3300, Loss function: 4.133, Average Loss: 4.058, avg. samples / sec: 53645.12
Iteration:   3300, Loss function: 4.412, Average Loss: 4.035, avg. samples / sec: 53652.53
Iteration:   3300, Loss function: 4.476, Average Loss: 4.065, avg. samples / sec: 53685.80
Iteration:   3300, Loss function: 4.048, Average Loss: 4.062, avg. samples / sec: 53662.68
Iteration:   3320, Loss function: 3.664, Average Loss: 4.020, avg. samples / sec: 54000.04
Iteration:   3320, Loss function: 2.919, Average Loss: 4.031, avg. samples / sec: 54004.27
Iteration:   3320, Loss function: 3.294, Average Loss: 4.023, avg. samples / sec: 53986.68
Iteration:   3320, Loss function: 4.600, Average Loss: 4.017, avg. samples / sec: 53999.90
Iteration:   3320, Loss function: 3.084, Average Loss: 4.009, avg. samples / sec: 53979.61
Iteration:   3320, Loss function: 4.133, Average Loss: 4.021, avg. samples / sec: 53978.84
Iteration:   3320, Loss function: 3.894, Average Loss: 3.995, avg. samples / sec: 54010.50
Iteration:   3320, Loss function: 3.780, Average Loss: 4.029, avg. samples / sec: 54005.36
Iteration:   3320, Loss function: 2.763, Average Loss: 4.022, avg. samples / sec: 54010.74
Iteration:   3320, Loss function: 3.945, Average Loss: 4.060, avg. samples / sec: 53978.58
Iteration:   3320, Loss function: 4.357, Average Loss: 4.003, avg. samples / sec: 53981.08
Iteration:   3320, Loss function: 4.419, Average Loss: 4.046, avg. samples / sec: 53936.25
Iteration:   3320, Loss function: 4.181, Average Loss: 4.017, avg. samples / sec: 54033.30
Iteration:   3320, Loss function: 4.929, Average Loss: 4.029, avg. samples / sec: 53919.45
Iteration:   3320, Loss function: 4.565, Average Loss: 4.006, avg. samples / sec: 53984.01
Iteration:   3320, Loss function: 2.395, Average Loss: 4.020, avg. samples / sec: 53937.17
Iteration:   3320, Loss function: 3.676, Average Loss: 4.052, avg. samples / sec: 54044.63
Iteration:   3320, Loss function: 3.132, Average Loss: 4.043, avg. samples / sec: 54009.42
Iteration:   3320, Loss function: 4.374, Average Loss: 4.046, avg. samples / sec: 53980.79
Iteration:   3320, Loss function: 3.142, Average Loss: 4.038, avg. samples / sec: 54006.63
Iteration:   3320, Loss function: 3.814, Average Loss: 4.064, avg. samples / sec: 53994.54
Iteration:   3320, Loss function: 5.105, Average Loss: 4.039, avg. samples / sec: 53971.51
Iteration:   3320, Loss function: 3.717, Average Loss: 4.043, avg. samples / sec: 53950.51
Iteration:   3320, Loss function: 2.162, Average Loss: 4.017, avg. samples / sec: 53974.87
Iteration:   3320, Loss function: 3.048, Average Loss: 4.031, avg. samples / sec: 53809.00
Iteration:   3320, Loss function: 3.013, Average Loss: 4.031, avg. samples / sec: 53947.89
Iteration:   3320, Loss function: 3.153, Average Loss: 4.023, avg. samples / sec: 53957.45
Iteration:   3320, Loss function: 2.543, Average Loss: 4.053, avg. samples / sec: 53977.81
Iteration:   3320, Loss function: 3.318, Average Loss: 4.050, avg. samples / sec: 53958.61
Iteration:   3320, Loss function: 3.184, Average Loss: 4.024, avg. samples / sec: 53744.44
Iteration:   3340, Loss function: 2.961, Average Loss: 4.007, avg. samples / sec: 54063.46
Iteration:   3340, Loss function: 4.108, Average Loss: 4.017, avg. samples / sec: 54120.72
Iteration:   3340, Loss function: 4.178, Average Loss: 4.016, avg. samples / sec: 54044.28
Iteration:   3340, Loss function: 3.576, Average Loss: 4.007, avg. samples / sec: 54012.17
Iteration:   3340, Loss function: 3.550, Average Loss: 3.995, avg. samples / sec: 54032.98
Iteration:   3340, Loss function: 2.768, Average Loss: 4.038, avg. samples / sec: 54059.00
Iteration:   3340, Loss function: 4.575, Average Loss: 4.016, avg. samples / sec: 54029.36
Iteration:   3340, Loss function: 3.136, Average Loss: 3.991, avg. samples / sec: 54040.26
Iteration:   3340, Loss function: 3.547, Average Loss: 3.995, avg. samples / sec: 54070.05
Iteration:   3340, Loss function: 3.231, Average Loss: 4.012, avg. samples / sec: 54024.76
Iteration:   3340, Loss function: 4.059, Average Loss: 4.015, avg. samples / sec: 54329.25
Iteration:   3340, Loss function: 3.317, Average Loss: 4.047, avg. samples / sec: 54024.62
Iteration:   3340, Loss function: 2.686, Average Loss: 4.015, avg. samples / sec: 54023.75
Iteration:   3340, Loss function: 3.691, Average Loss: 4.005, avg. samples / sec: 54052.92
Iteration:   3340, Loss function: 1.836, Average Loss: 4.008, avg. samples / sec: 54106.25
Iteration:   3340, Loss function: 4.139, Average Loss: 4.017, avg. samples / sec: 54010.35
Iteration:   3340, Loss function: 3.505, Average Loss: 4.017, avg. samples / sec: 54247.82
Iteration:   3340, Loss function: 3.019, Average Loss: 3.983, avg. samples / sec: 53994.98
Iteration:   3340, Loss function: 3.214, Average Loss: 4.030, avg. samples / sec: 54035.84
Iteration:   3340, Loss function: 3.769, Average Loss: 4.017, avg. samples / sec: 54102.31
Iteration:   3340, Loss function: 3.453, Average Loss: 4.020, avg. samples / sec: 54043.30
Iteration:   3340, Loss function: 2.695, Average Loss: 4.035, avg. samples / sec: 54033.90
Iteration:   3340, Loss function: 3.310, Average Loss: 4.009, avg. samples / sec: 54105.26
Iteration:   3340, Loss function: 3.643, Average Loss: 4.054, avg. samples / sec: 54043.26
Iteration:   3340, Loss function: 2.774, Average Loss: 4.029, avg. samples / sec: 54063.06
Iteration:   3340, Loss function: 2.882, Average Loss: 4.025, avg. samples / sec: 54050.87
Iteration:   3340, Loss function: 3.306, Average Loss: 4.007, avg. samples / sec: 54048.15
Iteration:   3340, Loss function: 3.504, Average Loss: 4.043, avg. samples / sec: 54069.37
Iteration:   3340, Loss function: 2.741, Average Loss: 4.037, avg. samples / sec: 54062.25
Iteration:   3340, Loss function: 3.590, Average Loss: 4.041, avg. samples / sec: 53779.80
:::MLL 1558641212.203 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558641212.204 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 3.961, Average Loss: 3.985, avg. samples / sec: 53704.73
Iteration:   3360, Loss function: 4.458, Average Loss: 4.003, avg. samples / sec: 53720.26
Iteration:   3360, Loss function: 2.984, Average Loss: 4.005, avg. samples / sec: 53629.97
Iteration:   3360, Loss function: 3.813, Average Loss: 3.999, avg. samples / sec: 53695.05
Iteration:   3360, Loss function: 2.883, Average Loss: 4.006, avg. samples / sec: 53598.01
Iteration:   3360, Loss function: 2.957, Average Loss: 4.002, avg. samples / sec: 53648.75
Iteration:   3360, Loss function: 5.152, Average Loss: 4.003, avg. samples / sec: 53623.11
Iteration:   3360, Loss function: 3.571, Average Loss: 4.006, avg. samples / sec: 53595.87
Iteration:   3360, Loss function: 3.725, Average Loss: 3.995, avg. samples / sec: 53584.13
Iteration:   3360, Loss function: 4.474, Average Loss: 4.030, avg. samples / sec: 53552.87
Iteration:   3360, Loss function: 3.488, Average Loss: 3.998, avg. samples / sec: 53568.08
Iteration:   3360, Loss function: 3.649, Average Loss: 3.993, avg. samples / sec: 53530.13
Iteration:   3360, Loss function: 2.433, Average Loss: 3.988, avg. samples / sec: 53545.45
Iteration:   3360, Loss function: 3.643, Average Loss: 3.981, avg. samples / sec: 53528.63
Iteration:   3360, Loss function: 2.860, Average Loss: 3.970, avg. samples / sec: 53568.65
Iteration:   3360, Loss function: 2.602, Average Loss: 3.999, avg. samples / sec: 53475.04
Iteration:   3360, Loss function: 3.288, Average Loss: 4.034, avg. samples / sec: 53511.41
Iteration:   3360, Loss function: 3.427, Average Loss: 4.040, avg. samples / sec: 53706.20
Iteration:   3360, Loss function: 3.663, Average Loss: 4.005, avg. samples / sec: 53484.16
Iteration:   3360, Loss function: 1.861, Average Loss: 4.008, avg. samples / sec: 53672.35
Iteration:   3360, Loss function: 5.132, Average Loss: 4.028, avg. samples / sec: 53665.28
Iteration:   3360, Loss function: 4.619, Average Loss: 4.028, avg. samples / sec: 53811.24
Iteration:   3360, Loss function: 3.026, Average Loss: 4.019, avg. samples / sec: 53553.16
Iteration:   3360, Loss function: 4.377, Average Loss: 4.031, avg. samples / sec: 53557.13
Iteration:   3360, Loss function: 4.340, Average Loss: 4.008, avg. samples / sec: 53538.47
Iteration:   3360, Loss function: 3.649, Average Loss: 4.013, avg. samples / sec: 53556.15
Iteration:   3360, Loss function: 3.231, Average Loss: 4.030, avg. samples / sec: 53563.60
Iteration:   3360, Loss function: 4.064, Average Loss: 3.997, avg. samples / sec: 53550.96
Iteration:   3360, Loss function: 3.581, Average Loss: 4.017, avg. samples / sec: 53500.83
Iteration:   3360, Loss function: 3.558, Average Loss: 4.000, avg. samples / sec: 53482.09
Iteration:   3380, Loss function: 2.925, Average Loss: 3.991, avg. samples / sec: 54161.07
Iteration:   3380, Loss function: 2.815, Average Loss: 3.988, avg. samples / sec: 54232.14
Iteration:   3380, Loss function: 4.001, Average Loss: 4.001, avg. samples / sec: 54149.87
Iteration:   3380, Loss function: 3.156, Average Loss: 3.979, avg. samples / sec: 54188.68
Iteration:   3380, Loss function: 3.387, Average Loss: 3.997, avg. samples / sec: 54049.89
Iteration:   3380, Loss function: 3.614, Average Loss: 3.981, avg. samples / sec: 54179.22
Iteration:   3380, Loss function: 2.551, Average Loss: 3.997, avg. samples / sec: 54236.17
Iteration:   3380, Loss function: 2.393, Average Loss: 3.988, avg. samples / sec: 54173.73
Iteration:   3380, Loss function: 3.597, Average Loss: 3.973, avg. samples / sec: 54183.81
Iteration:   3380, Loss function: 3.958, Average Loss: 3.993, avg. samples / sec: 54020.14
Iteration:   3380, Loss function: 3.181, Average Loss: 4.025, avg. samples / sec: 54205.96
Iteration:   3380, Loss function: 3.268, Average Loss: 3.961, avg. samples / sec: 54173.50
Iteration:   3380, Loss function: 2.051, Average Loss: 3.995, avg. samples / sec: 54065.09
Iteration:   3380, Loss function: 2.988, Average Loss: 3.986, avg. samples / sec: 54111.28
Iteration:   3380, Loss function: 3.571, Average Loss: 4.022, avg. samples / sec: 54097.30
Iteration:   3380, Loss function: 4.811, Average Loss: 3.986, avg. samples / sec: 53967.66
Iteration:   3380, Loss function: 2.987, Average Loss: 4.002, avg. samples / sec: 54262.35
Iteration:   3380, Loss function: 2.996, Average Loss: 4.012, avg. samples / sec: 54152.08
Iteration:   3380, Loss function: 3.101, Average Loss: 3.995, avg. samples / sec: 54045.91
Iteration:   3380, Loss function: 4.189, Average Loss: 4.015, avg. samples / sec: 54141.61
Iteration:   3380, Loss function: 3.154, Average Loss: 4.001, avg. samples / sec: 54181.87
Iteration:   3380, Loss function: 3.056, Average Loss: 4.022, avg. samples / sec: 54148.37
Iteration:   3380, Loss function: 3.291, Average Loss: 3.998, avg. samples / sec: 54154.14
Iteration:   3380, Loss function: 3.314, Average Loss: 4.027, avg. samples / sec: 53997.58
Iteration:   3380, Loss function: 4.336, Average Loss: 3.975, avg. samples / sec: 53775.20
Iteration:   3380, Loss function: 2.711, Average Loss: 3.986, avg. samples / sec: 53846.44
Iteration:   3380, Loss function: 4.215, Average Loss: 4.015, avg. samples / sec: 54047.10
Iteration:   3380, Loss function: 2.393, Average Loss: 3.990, avg. samples / sec: 54182.83
Iteration:   3380, Loss function: 4.106, Average Loss: 4.019, avg. samples / sec: 54128.32
Iteration:   3380, Loss function: 2.862, Average Loss: 3.983, avg. samples / sec: 54134.75
Iteration:   3400, Loss function: 4.649, Average Loss: 3.977, avg. samples / sec: 53930.28
Iteration:   3400, Loss function: 3.895, Average Loss: 3.981, avg. samples / sec: 53851.13
Iteration:   3400, Loss function: 2.044, Average Loss: 3.970, avg. samples / sec: 53911.69
Iteration:   3400, Loss function: 3.987, Average Loss: 3.968, avg. samples / sec: 54143.19
Iteration:   3400, Loss function: 2.831, Average Loss: 3.985, avg. samples / sec: 53900.48
Iteration:   3400, Loss function: 4.778, Average Loss: 3.985, avg. samples / sec: 53944.48
Iteration:   3400, Loss function: 3.392, Average Loss: 4.010, avg. samples / sec: 53916.64
Iteration:   3400, Loss function: 3.153, Average Loss: 3.987, avg. samples / sec: 53889.43
Iteration:   3400, Loss function: 2.965, Average Loss: 3.969, avg. samples / sec: 53884.50
Iteration:   3400, Loss function: 3.807, Average Loss: 3.990, avg. samples / sec: 53886.42
Iteration:   3400, Loss function: 3.422, Average Loss: 4.012, avg. samples / sec: 53958.80
Iteration:   3400, Loss function: 3.248, Average Loss: 3.973, avg. samples / sec: 53924.69
Iteration:   3400, Loss function: 4.455, Average Loss: 3.953, avg. samples / sec: 53894.02
Iteration:   3400, Loss function: 4.272, Average Loss: 3.973, avg. samples / sec: 53925.64
Iteration:   3400, Loss function: 3.175, Average Loss: 3.981, avg. samples / sec: 53839.05
Iteration:   3400, Loss function: 3.783, Average Loss: 3.972, avg. samples / sec: 54073.54
Iteration:   3400, Loss function: 2.349, Average Loss: 3.983, avg. samples / sec: 53835.88
Iteration:   3400, Loss function: 4.422, Average Loss: 4.000, avg. samples / sec: 53908.89
Iteration:   3400, Loss function: 3.667, Average Loss: 4.008, avg. samples / sec: 53886.73
Iteration:   3400, Loss function: 4.452, Average Loss: 4.013, avg. samples / sec: 53903.67
Iteration:   3400, Loss function: 3.585, Average Loss: 3.988, avg. samples / sec: 53878.67
Iteration:   3400, Loss function: 4.933, Average Loss: 3.982, avg. samples / sec: 53911.69
Iteration:   3400, Loss function: 2.454, Average Loss: 3.989, avg. samples / sec: 53894.75
Iteration:   3400, Loss function: 3.630, Average Loss: 3.989, avg. samples / sec: 53842.24
Iteration:   3400, Loss function: 3.570, Average Loss: 3.965, avg. samples / sec: 53665.13
Iteration:   3400, Loss function: 3.824, Average Loss: 4.012, avg. samples / sec: 53916.89
Iteration:   3400, Loss function: 4.030, Average Loss: 3.983, avg. samples / sec: 53906.74
Iteration:   3400, Loss function: 4.281, Average Loss: 4.020, avg. samples / sec: 53873.90
Iteration:   3400, Loss function: 3.951, Average Loss: 3.971, avg. samples / sec: 53909.94
Iteration:   3400, Loss function: 4.486, Average Loss: 4.006, avg. samples / sec: 53887.55
Iteration:   3420, Loss function: 4.520, Average Loss: 3.978, avg. samples / sec: 54318.22
Iteration:   3420, Loss function: 3.046, Average Loss: 3.951, avg. samples / sec: 54346.52
Iteration:   3420, Loss function: 2.993, Average Loss: 3.968, avg. samples / sec: 54219.91
Iteration:   3420, Loss function: 2.824, Average Loss: 3.978, avg. samples / sec: 54274.68
Iteration:   3420, Loss function: 2.816, Average Loss: 3.960, avg. samples / sec: 54249.34
Iteration:   3420, Loss function: 2.749, Average Loss: 3.994, avg. samples / sec: 54269.02
Iteration:   3420, Loss function: 2.944, Average Loss: 3.972, avg. samples / sec: 54252.22
Iteration:   3420, Loss function: 2.872, Average Loss: 3.981, avg. samples / sec: 54245.62
Iteration:   3420, Loss function: 3.786, Average Loss: 3.963, avg. samples / sec: 54326.61
Iteration:   3420, Loss function: 4.029, Average Loss: 3.998, avg. samples / sec: 54244.96
Iteration:   3420, Loss function: 4.113, Average Loss: 3.971, avg. samples / sec: 54220.31
Iteration:   3420, Loss function: 3.526, Average Loss: 3.958, avg. samples / sec: 54210.19
Iteration:   3420, Loss function: 3.700, Average Loss: 3.960, avg. samples / sec: 54261.79
Iteration:   3420, Loss function: 2.560, Average Loss: 3.962, avg. samples / sec: 54206.00
Iteration:   3420, Loss function: 3.878, Average Loss: 3.962, avg. samples / sec: 54226.71
Iteration:   3420, Loss function: 2.736, Average Loss: 3.969, avg. samples / sec: 54263.13
Iteration:   3420, Loss function: 2.856, Average Loss: 3.981, avg. samples / sec: 54276.63
Iteration:   3420, Loss function: 3.923, Average Loss: 3.974, avg. samples / sec: 54296.16
Iteration:   3420, Loss function: 3.108, Average Loss: 3.980, avg. samples / sec: 54298.90
Iteration:   3420, Loss function: 3.974, Average Loss: 3.979, avg. samples / sec: 54307.50
Iteration:   3420, Loss function: 2.267, Average Loss: 4.002, avg. samples / sec: 54277.65
Iteration:   3420, Loss function: 3.237, Average Loss: 3.978, avg. samples / sec: 54264.97
Iteration:   3420, Loss function: 3.371, Average Loss: 3.999, avg. samples / sec: 54259.01
Iteration:   3420, Loss function: 2.734, Average Loss: 3.973, avg. samples / sec: 54292.67
Iteration:   3420, Loss function: 2.406, Average Loss: 3.973, avg. samples / sec: 54096.00
Iteration:   3420, Loss function: 2.751, Average Loss: 4.008, avg. samples / sec: 54272.22
Iteration:   3420, Loss function: 3.809, Average Loss: 3.999, avg. samples / sec: 54258.28
Iteration:   3420, Loss function: 3.528, Average Loss: 3.963, avg. samples / sec: 54268.87
Iteration:   3420, Loss function: 3.042, Average Loss: 3.955, avg. samples / sec: 54251.33
Iteration:   3420, Loss function: 4.263, Average Loss: 3.994, avg. samples / sec: 54278.11
:::MLL 1558641214.362 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.60s)
DONE (t=0.60s)
DONE (t=0.60s)
DONE (t=0.60s)
DONE (t=0.61s)
DONE (t=0.65s)
DONE (t=2.54s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22117
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38219
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22656
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05646
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.22949
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36262
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33169
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09775
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.35715
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.51965
Current AP: 0.22117 AP goal: 0.23000
:::MLL 1558641218.167 eval_accuracy: {"value": 0.221166668990799, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558641218.286 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558641218.293 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558641218.293 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558641218.327 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558641218.327 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.193, Average Loss: 3.957, avg. samples / sec: 7346.69
Iteration:   3440, Loss function: 3.766, Average Loss: 3.990, avg. samples / sec: 7344.69
Iteration:   3440, Loss function: 3.157, Average Loss: 3.957, avg. samples / sec: 7340.18
Iteration:   3440, Loss function: 2.950, Average Loss: 3.940, avg. samples / sec: 7338.52
Iteration:   3440, Loss function: 3.330, Average Loss: 3.947, avg. samples / sec: 7339.89
Iteration:   3440, Loss function: 3.629, Average Loss: 3.965, avg. samples / sec: 7339.23
Iteration:   3440, Loss function: 4.570, Average Loss: 3.960, avg. samples / sec: 7338.68
Iteration:   3440, Loss function: 3.094, Average Loss: 3.951, avg. samples / sec: 7339.82
Iteration:   3440, Loss function: 2.657, Average Loss: 3.967, avg. samples / sec: 7338.69
Iteration:   3440, Loss function: 4.560, Average Loss: 3.950, avg. samples / sec: 7339.53
Iteration:   3440, Loss function: 2.563, Average Loss: 3.963, avg. samples / sec: 7342.75
Iteration:   3440, Loss function: 4.193, Average Loss: 3.985, avg. samples / sec: 7338.29
Iteration:   3440, Loss function: 4.116, Average Loss: 3.945, avg. samples / sec: 7338.15
Iteration:   3440, Loss function: 4.323, Average Loss: 3.955, avg. samples / sec: 7339.51
Iteration:   3440, Loss function: 3.975, Average Loss: 3.986, avg. samples / sec: 7338.04
Iteration:   3440, Loss function: 4.033, Average Loss: 3.969, avg. samples / sec: 7335.19
Iteration:   3440, Loss function: 4.740, Average Loss: 3.972, avg. samples / sec: 7338.87
Iteration:   3440, Loss function: 3.862, Average Loss: 3.961, avg. samples / sec: 7338.43
Iteration:   3440, Loss function: 2.925, Average Loss: 3.969, avg. samples / sec: 7338.43
Iteration:   3440, Loss function: 3.656, Average Loss: 3.959, avg. samples / sec: 7335.86
Iteration:   3440, Loss function: 3.173, Average Loss: 3.962, avg. samples / sec: 7334.94
Iteration:   3440, Loss function: 3.526, Average Loss: 3.969, avg. samples / sec: 7337.78
Iteration:   3440, Loss function: 3.188, Average Loss: 3.944, avg. samples / sec: 7339.42
Iteration:   3440, Loss function: 2.332, Average Loss: 3.961, avg. samples / sec: 7338.62
Iteration:   3440, Loss function: 2.763, Average Loss: 3.992, avg. samples / sec: 7338.63
Iteration:   3440, Loss function: 3.270, Average Loss: 3.960, avg. samples / sec: 7338.60
Iteration:   3440, Loss function: 2.648, Average Loss: 3.997, avg. samples / sec: 7337.90
Iteration:   3440, Loss function: 3.690, Average Loss: 3.955, avg. samples / sec: 7334.58
Iteration:   3440, Loss function: 2.753, Average Loss: 3.981, avg. samples / sec: 7339.00
Iteration:   3440, Loss function: 3.539, Average Loss: 3.991, avg. samples / sec: 7338.42
Iteration:   3460, Loss function: 4.624, Average Loss: 3.942, avg. samples / sec: 53853.97
Iteration:   3460, Loss function: 4.126, Average Loss: 3.935, avg. samples / sec: 53893.14
Iteration:   3460, Loss function: 2.527, Average Loss: 3.984, avg. samples / sec: 53793.39
Iteration:   3460, Loss function: 3.894, Average Loss: 3.979, avg. samples / sec: 53887.86
Iteration:   3460, Loss function: 4.086, Average Loss: 3.931, avg. samples / sec: 53784.58
Iteration:   3460, Loss function: 3.916, Average Loss: 3.973, avg. samples / sec: 53844.93
Iteration:   3460, Loss function: 3.234, Average Loss: 3.945, avg. samples / sec: 53763.47
Iteration:   3460, Loss function: 2.194, Average Loss: 3.937, avg. samples / sec: 53834.18
Iteration:   3460, Loss function: 4.116, Average Loss: 3.951, avg. samples / sec: 53809.37
Iteration:   3460, Loss function: 2.831, Average Loss: 3.957, avg. samples / sec: 53785.89
Iteration:   3460, Loss function: 3.767, Average Loss: 3.941, avg. samples / sec: 53776.94
Iteration:   3460, Loss function: 3.869, Average Loss: 3.952, avg. samples / sec: 53754.24
Iteration:   3460, Loss function: 3.470, Average Loss: 3.959, avg. samples / sec: 53873.42
Iteration:   3460, Loss function: 2.970, Average Loss: 3.984, avg. samples / sec: 53883.56
Iteration:   3460, Loss function: 3.292, Average Loss: 3.948, avg. samples / sec: 53828.62
Iteration:   3460, Loss function: 4.434, Average Loss: 3.953, avg. samples / sec: 53833.19
Iteration:   3460, Loss function: 3.749, Average Loss: 3.960, avg. samples / sec: 53797.02
Iteration:   3460, Loss function: 4.081, Average Loss: 3.943, avg. samples / sec: 53593.40
Iteration:   3460, Loss function: 3.377, Average Loss: 3.951, avg. samples / sec: 53840.57
Iteration:   3460, Loss function: 2.037, Average Loss: 3.977, avg. samples / sec: 53832.57
Iteration:   3460, Loss function: 4.507, Average Loss: 3.980, avg. samples / sec: 53871.05
Iteration:   3460, Loss function: 1.773, Average Loss: 3.950, avg. samples / sec: 53807.56
Iteration:   3460, Loss function: 3.728, Average Loss: 3.952, avg. samples / sec: 53814.34
Iteration:   3460, Loss function: 3.199, Average Loss: 3.931, avg. samples / sec: 53808.13
Iteration:   3460, Loss function: 3.469, Average Loss: 3.950, avg. samples / sec: 53616.03
Iteration:   3460, Loss function: 3.776, Average Loss: 3.962, avg. samples / sec: 53705.69
Iteration:   3460, Loss function: 2.784, Average Loss: 3.955, avg. samples / sec: 53774.13
Iteration:   3460, Loss function: 3.431, Average Loss: 3.945, avg. samples / sec: 53805.55
Iteration:   3460, Loss function: 3.610, Average Loss: 3.967, avg. samples / sec: 53804.33
Iteration:   3460, Loss function: 3.856, Average Loss: 3.946, avg. samples / sec: 53576.00
Iteration:   3480, Loss function: 3.300, Average Loss: 3.932, avg. samples / sec: 53961.94
Iteration:   3480, Loss function: 2.831, Average Loss: 3.937, avg. samples / sec: 54183.93
Iteration:   3480, Loss function: 4.239, Average Loss: 3.937, avg. samples / sec: 54116.62
Iteration:   3480, Loss function: 4.400, Average Loss: 3.929, avg. samples / sec: 54063.66
Iteration:   3480, Loss function: 4.032, Average Loss: 3.941, avg. samples / sec: 54045.85
Iteration:   3480, Loss function: 2.908, Average Loss: 3.974, avg. samples / sec: 53994.44
Iteration:   3480, Loss function: 3.237, Average Loss: 3.924, avg. samples / sec: 53994.58
Iteration:   3480, Loss function: 3.048, Average Loss: 3.938, avg. samples / sec: 54298.21
Iteration:   3480, Loss function: 4.042, Average Loss: 3.962, avg. samples / sec: 54017.58
Iteration:   3480, Loss function: 4.141, Average Loss: 3.943, avg. samples / sec: 54042.04
Iteration:   3480, Loss function: 3.329, Average Loss: 3.970, avg. samples / sec: 53992.43
Iteration:   3480, Loss function: 2.578, Average Loss: 3.918, avg. samples / sec: 54001.68
Iteration:   3480, Loss function: 4.166, Average Loss: 3.929, avg. samples / sec: 54028.80
Iteration:   3480, Loss function: 2.357, Average Loss: 3.936, avg. samples / sec: 54230.41
Iteration:   3480, Loss function: 3.461, Average Loss: 3.950, avg. samples / sec: 54123.00
Iteration:   3480, Loss function: 4.093, Average Loss: 3.971, avg. samples / sec: 54037.69
Iteration:   3480, Loss function: 5.133, Average Loss: 3.934, avg. samples / sec: 54059.22
Iteration:   3480, Loss function: 3.859, Average Loss: 3.943, avg. samples / sec: 54073.37
Iteration:   3480, Loss function: 2.844, Average Loss: 3.952, avg. samples / sec: 53995.10
Iteration:   3480, Loss function: 2.681, Average Loss: 3.936, avg. samples / sec: 54050.95
Iteration:   3480, Loss function: 3.167, Average Loss: 3.946, avg. samples / sec: 54080.26
Iteration:   3480, Loss function: 3.541, Average Loss: 3.940, avg. samples / sec: 54023.60
Iteration:   3480, Loss function: 3.809, Average Loss: 3.968, avg. samples / sec: 54036.84
Iteration:   3480, Loss function: 2.981, Average Loss: 3.942, avg. samples / sec: 54003.27
Iteration:   3480, Loss function: 3.913, Average Loss: 3.948, avg. samples / sec: 54026.63
Iteration:   3480, Loss function: 3.456, Average Loss: 3.930, avg. samples / sec: 54050.93
Iteration:   3480, Loss function: 4.867, Average Loss: 3.953, avg. samples / sec: 54042.41
Iteration:   3480, Loss function: 4.770, Average Loss: 3.920, avg. samples / sec: 54021.61
Iteration:   3480, Loss function: 3.565, Average Loss: 3.974, avg. samples / sec: 53977.36
Iteration:   3480, Loss function: 3.564, Average Loss: 3.955, avg. samples / sec: 54020.35
:::MLL 1558641220.516 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558641220.517 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 3.312, Average Loss: 3.918, avg. samples / sec: 53861.03
Iteration:   3500, Loss function: 2.556, Average Loss: 3.919, avg. samples / sec: 53977.50
Iteration:   3500, Loss function: 3.510, Average Loss: 3.927, avg. samples / sec: 53915.59
Iteration:   3500, Loss function: 4.465, Average Loss: 3.925, avg. samples / sec: 53930.10
Iteration:   3500, Loss function: 4.032, Average Loss: 3.934, avg. samples / sec: 53861.15
Iteration:   3500, Loss function: 3.391, Average Loss: 3.929, avg. samples / sec: 53763.88
Iteration:   3500, Loss function: 3.648, Average Loss: 3.928, avg. samples / sec: 53735.96
Iteration:   3500, Loss function: 4.697, Average Loss: 3.956, avg. samples / sec: 53838.50
Iteration:   3500, Loss function: 3.542, Average Loss: 3.966, avg. samples / sec: 53825.17
Iteration:   3500, Loss function: 2.839, Average Loss: 3.911, avg. samples / sec: 53845.98
Iteration:   3500, Loss function: 3.374, Average Loss: 3.921, avg. samples / sec: 53787.80
Iteration:   3500, Loss function: 3.277, Average Loss: 3.919, avg. samples / sec: 53799.98
Iteration:   3500, Loss function: 4.137, Average Loss: 3.929, avg. samples / sec: 53770.32
Iteration:   3500, Loss function: 4.501, Average Loss: 3.942, avg. samples / sec: 53867.57
Iteration:   3500, Loss function: 4.219, Average Loss: 3.926, avg. samples / sec: 53921.94
Iteration:   3500, Loss function: 3.176, Average Loss: 3.964, avg. samples / sec: 53738.99
Iteration:   3500, Loss function: 2.411, Average Loss: 3.933, avg. samples / sec: 53918.89
Iteration:   3500, Loss function: 3.114, Average Loss: 3.931, avg. samples / sec: 53877.97
Iteration:   3500, Loss function: 4.128, Average Loss: 3.937, avg. samples / sec: 53916.04
Iteration:   3500, Loss function: 4.625, Average Loss: 3.946, avg. samples / sec: 53941.86
Iteration:   3500, Loss function: 3.966, Average Loss: 3.945, avg. samples / sec: 53884.38
Iteration:   3500, Loss function: 3.004, Average Loss: 3.945, avg. samples / sec: 53829.51
Iteration:   3500, Loss function: 3.034, Average Loss: 3.958, avg. samples / sec: 53781.60
Iteration:   3500, Loss function: 3.748, Average Loss: 3.925, avg. samples / sec: 53775.45
Iteration:   3500, Loss function: 3.737, Average Loss: 3.933, avg. samples / sec: 53817.65
Iteration:   3500, Loss function: 3.570, Average Loss: 3.957, avg. samples / sec: 53798.71
Iteration:   3500, Loss function: 2.898, Average Loss: 3.965, avg. samples / sec: 53824.20
Iteration:   3500, Loss function: 3.151, Average Loss: 3.918, avg. samples / sec: 53782.32
Iteration:   3500, Loss function: 4.253, Average Loss: 3.909, avg. samples / sec: 53792.89
Iteration:   3500, Loss function: 2.818, Average Loss: 3.938, avg. samples / sec: 53731.41
Iteration:   3520, Loss function: 2.690, Average Loss: 3.953, avg. samples / sec: 54667.08
Iteration:   3520, Loss function: 3.486, Average Loss: 3.917, avg. samples / sec: 54642.77
Iteration:   3520, Loss function: 3.153, Average Loss: 3.910, avg. samples / sec: 54642.62
Iteration:   3520, Loss function: 2.590, Average Loss: 3.916, avg. samples / sec: 54685.32
Iteration:   3520, Loss function: 4.899, Average Loss: 3.923, avg. samples / sec: 54600.11
Iteration:   3520, Loss function: 3.101, Average Loss: 3.912, avg. samples / sec: 54641.16
Iteration:   3520, Loss function: 3.301, Average Loss: 3.952, avg. samples / sec: 54732.17
Iteration:   3520, Loss function: 3.299, Average Loss: 3.911, avg. samples / sec: 54496.65
Iteration:   3520, Loss function: 3.517, Average Loss: 3.916, avg. samples / sec: 54516.97
Iteration:   3520, Loss function: 1.812, Average Loss: 3.923, avg. samples / sec: 54581.46
Iteration:   3520, Loss function: 3.449, Average Loss: 3.944, avg. samples / sec: 54601.27
Iteration:   3520, Loss function: 2.786, Average Loss: 3.906, avg. samples / sec: 54429.47
Iteration:   3520, Loss function: 3.250, Average Loss: 3.920, avg. samples / sec: 54517.88
Iteration:   3520, Loss function: 3.530, Average Loss: 3.934, avg. samples / sec: 54571.90
Iteration:   3520, Loss function: 3.681, Average Loss: 3.933, avg. samples / sec: 54643.93
Iteration:   3520, Loss function: 2.607, Average Loss: 3.922, avg. samples / sec: 54557.14
Iteration:   3520, Loss function: 3.768, Average Loss: 3.946, avg. samples / sec: 54671.11
Iteration:   3520, Loss function: 2.695, Average Loss: 3.904, avg. samples / sec: 54695.53
Iteration:   3520, Loss function: 2.878, Average Loss: 3.926, avg. samples / sec: 54638.32
Iteration:   3520, Loss function: 3.676, Average Loss: 3.931, avg. samples / sec: 54529.99
Iteration:   3520, Loss function: 3.647, Average Loss: 3.934, avg. samples / sec: 54585.12
Iteration:   3520, Loss function: 2.994, Average Loss: 3.926, avg. samples / sec: 54695.81
Iteration:   3520, Loss function: 3.789, Average Loss: 3.928, avg. samples / sec: 54504.39
Iteration:   3520, Loss function: 3.572, Average Loss: 3.945, avg. samples / sec: 54602.35
Iteration:   3520, Loss function: 3.659, Average Loss: 3.915, avg. samples / sec: 54614.75
Iteration:   3520, Loss function: 3.184, Average Loss: 3.918, avg. samples / sec: 54470.72
Iteration:   3520, Loss function: 3.184, Average Loss: 3.907, avg. samples / sec: 54638.47
Iteration:   3520, Loss function: 3.043, Average Loss: 3.899, avg. samples / sec: 54356.10
Iteration:   3520, Loss function: 2.508, Average Loss: 3.934, avg. samples / sec: 54498.57
Iteration:   3520, Loss function: 3.284, Average Loss: 3.952, avg. samples / sec: 54596.22
Iteration:   3540, Loss function: 3.584, Average Loss: 3.898, avg. samples / sec: 54616.25
Iteration:   3540, Loss function: 3.487, Average Loss: 3.948, avg. samples / sec: 54426.02
Iteration:   3540, Loss function: 2.523, Average Loss: 3.904, avg. samples / sec: 54422.07
Iteration:   3540, Loss function: 3.434, Average Loss: 3.912, avg. samples / sec: 54445.30
Iteration:   3540, Loss function: 3.931, Average Loss: 3.902, avg. samples / sec: 54408.18
Iteration:   3540, Loss function: 4.117, Average Loss: 3.936, avg. samples / sec: 54434.98
Iteration:   3540, Loss function: 3.222, Average Loss: 3.905, avg. samples / sec: 54417.80
Iteration:   3540, Loss function: 3.915, Average Loss: 3.922, avg. samples / sec: 54528.26
Iteration:   3540, Loss function: 4.592, Average Loss: 3.938, avg. samples / sec: 54407.05
Iteration:   3540, Loss function: 3.286, Average Loss: 3.888, avg. samples / sec: 54670.13
Iteration:   3540, Loss function: 2.535, Average Loss: 3.907, avg. samples / sec: 54443.24
Iteration:   3540, Loss function: 3.092, Average Loss: 3.900, avg. samples / sec: 54407.45
Iteration:   3540, Loss function: 3.790, Average Loss: 3.920, avg. samples / sec: 54398.04
Iteration:   3540, Loss function: 3.546, Average Loss: 3.904, avg. samples / sec: 54386.53
Iteration:   3540, Loss function: 3.018, Average Loss: 3.907, avg. samples / sec: 54362.24
Iteration:   3540, Loss function: 2.265, Average Loss: 3.917, avg. samples / sec: 54461.38
Iteration:   3540, Loss function: 3.124, Average Loss: 3.923, avg. samples / sec: 54459.00
Iteration:   3540, Loss function: 3.554, Average Loss: 3.902, avg. samples / sec: 54480.49
Iteration:   3540, Loss function: 2.879, Average Loss: 3.911, avg. samples / sec: 54423.50
Iteration:   3540, Loss function: 2.831, Average Loss: 3.923, avg. samples / sec: 54403.64
Iteration:   3540, Loss function: 3.217, Average Loss: 3.912, avg. samples / sec: 54444.63
Iteration:   3540, Loss function: 2.059, Average Loss: 3.916, avg. samples / sec: 54447.97
Iteration:   3540, Loss function: 2.755, Average Loss: 3.938, avg. samples / sec: 54406.56
Iteration:   3540, Loss function: 3.518, Average Loss: 3.906, avg. samples / sec: 54453.30
Iteration:   3540, Loss function: 4.227, Average Loss: 3.938, avg. samples / sec: 54434.64
Iteration:   3540, Loss function: 2.962, Average Loss: 3.939, avg. samples / sec: 54490.44
Iteration:   3540, Loss function: 3.564, Average Loss: 3.896, avg. samples / sec: 54464.70
Iteration:   3540, Loss function: 2.839, Average Loss: 3.923, avg. samples / sec: 54462.60
Iteration:   3540, Loss function: 2.806, Average Loss: 3.928, avg. samples / sec: 54397.93
Iteration:   3540, Loss function: 3.417, Average Loss: 3.892, avg. samples / sec: 54367.52
:::MLL 1558641222.371 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558641222.371 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 3.553, Average Loss: 3.885, avg. samples / sec: 54039.72
Iteration:   3560, Loss function: 3.788, Average Loss: 3.899, avg. samples / sec: 54221.29
Iteration:   3560, Loss function: 3.431, Average Loss: 3.890, avg. samples / sec: 54170.64
Iteration:   3560, Loss function: 2.188, Average Loss: 3.899, avg. samples / sec: 54143.96
Iteration:   3560, Loss function: 4.095, Average Loss: 3.933, avg. samples / sec: 54038.35
Iteration:   3560, Loss function: 2.860, Average Loss: 3.899, avg. samples / sec: 54012.75
Iteration:   3560, Loss function: 2.580, Average Loss: 3.900, avg. samples / sec: 53994.09
Iteration:   3560, Loss function: 3.111, Average Loss: 3.921, avg. samples / sec: 54014.55
Iteration:   3560, Loss function: 3.112, Average Loss: 3.909, avg. samples / sec: 54015.92
Iteration:   3560, Loss function: 3.678, Average Loss: 3.908, avg. samples / sec: 54024.04
Iteration:   3560, Loss function: 2.948, Average Loss: 3.894, avg. samples / sec: 54024.39
Iteration:   3560, Loss function: 2.742, Average Loss: 3.878, avg. samples / sec: 53994.29
Iteration:   3560, Loss function: 3.335, Average Loss: 3.892, avg. samples / sec: 53970.00
Iteration:   3560, Loss function: 2.363, Average Loss: 3.930, avg. samples / sec: 53984.43
Iteration:   3560, Loss function: 2.558, Average Loss: 3.893, avg. samples / sec: 53969.91
Iteration:   3560, Loss function: 2.750, Average Loss: 3.902, avg. samples / sec: 54125.14
Iteration:   3560, Loss function: 4.217, Average Loss: 3.903, avg. samples / sec: 54119.22
Iteration:   3560, Loss function: 4.304, Average Loss: 3.915, avg. samples / sec: 54089.97
Iteration:   3560, Loss function: 2.087, Average Loss: 3.911, avg. samples / sec: 54132.52
Iteration:   3560, Loss function: 3.262, Average Loss: 3.924, avg. samples / sec: 54094.54
Iteration:   3560, Loss function: 3.092, Average Loss: 3.919, avg. samples / sec: 54099.21
Iteration:   3560, Loss function: 2.801, Average Loss: 3.914, avg. samples / sec: 54036.38
Iteration:   3560, Loss function: 4.187, Average Loss: 3.891, avg. samples / sec: 53990.84
Iteration:   3560, Loss function: 2.135, Average Loss: 3.927, avg. samples / sec: 54013.29
Iteration:   3560, Loss function: 3.615, Average Loss: 3.903, avg. samples / sec: 53980.02
Iteration:   3560, Loss function: 3.004, Average Loss: 3.899, avg. samples / sec: 53964.58
Iteration:   3560, Loss function: 3.799, Average Loss: 3.882, avg. samples / sec: 54040.32
Iteration:   3560, Loss function: 2.708, Average Loss: 3.887, avg. samples / sec: 53993.61
Iteration:   3560, Loss function: 4.226, Average Loss: 3.897, avg. samples / sec: 53968.16
Iteration:   3560, Loss function: 2.823, Average Loss: 3.930, avg. samples / sec: 53959.77
Iteration:   3580, Loss function: 3.336, Average Loss: 3.875, avg. samples / sec: 54458.41
Iteration:   3580, Loss function: 3.401, Average Loss: 3.884, avg. samples / sec: 54517.48
Iteration:   3580, Loss function: 3.301, Average Loss: 3.891, avg. samples / sec: 54515.65
Iteration:   3580, Loss function: 3.404, Average Loss: 3.880, avg. samples / sec: 54512.99
Iteration:   3580, Loss function: 4.801, Average Loss: 3.871, avg. samples / sec: 54516.09
Iteration:   3580, Loss function: 3.183, Average Loss: 3.912, avg. samples / sec: 54477.23
Iteration:   3580, Loss function: 3.964, Average Loss: 3.886, avg. samples / sec: 54319.75
Iteration:   3580, Loss function: 3.246, Average Loss: 3.880, avg. samples / sec: 54503.94
Iteration:   3580, Loss function: 3.089, Average Loss: 3.900, avg. samples / sec: 54466.58
Iteration:   3580, Loss function: 2.848, Average Loss: 3.872, avg. samples / sec: 54317.17
Iteration:   3580, Loss function: 3.156, Average Loss: 3.926, avg. samples / sec: 54489.28
Iteration:   3580, Loss function: 3.282, Average Loss: 3.883, avg. samples / sec: 54486.58
Iteration:   3580, Loss function: 4.501, Average Loss: 3.900, avg. samples / sec: 54450.75
Iteration:   3580, Loss function: 4.662, Average Loss: 3.891, avg. samples / sec: 54305.93
Iteration:   3580, Loss function: 4.134, Average Loss: 3.908, avg. samples / sec: 54447.72
Iteration:   3580, Loss function: 3.467, Average Loss: 3.880, avg. samples / sec: 54505.84
Iteration:   3580, Loss function: 3.216, Average Loss: 3.909, avg. samples / sec: 54458.22
Iteration:   3580, Loss function: 3.290, Average Loss: 3.892, avg. samples / sec: 54359.03
Iteration:   3580, Loss function: 3.298, Average Loss: 3.885, avg. samples / sec: 54557.71
Iteration:   3580, Loss function: 4.122, Average Loss: 3.897, avg. samples / sec: 54491.78
Iteration:   3580, Loss function: 3.444, Average Loss: 3.891, avg. samples / sec: 54365.38
Iteration:   3580, Loss function: 3.818, Average Loss: 3.921, avg. samples / sec: 54397.60
Iteration:   3580, Loss function: 3.518, Average Loss: 3.891, avg. samples / sec: 54487.00
Iteration:   3580, Loss function: 2.035, Average Loss: 3.869, avg. samples / sec: 54487.99
Iteration:   3580, Loss function: 3.591, Average Loss: 3.922, avg. samples / sec: 54163.44
Iteration:   3580, Loss function: 4.335, Average Loss: 3.910, avg. samples / sec: 54404.88
Iteration:   3580, Loss function: 3.932, Average Loss: 3.917, avg. samples / sec: 54454.75
Iteration:   3580, Loss function: 3.395, Average Loss: 3.879, avg. samples / sec: 54470.01
Iteration:   3580, Loss function: 4.132, Average Loss: 3.920, avg. samples / sec: 54504.87
Iteration:   3580, Loss function: 4.021, Average Loss: 3.901, avg. samples / sec: 54321.78
Iteration:   3600, Loss function: 4.023, Average Loss: 3.863, avg. samples / sec: 54543.22
Iteration:   3600, Loss function: 3.604, Average Loss: 3.883, avg. samples / sec: 54578.94
Iteration:   3600, Loss function: 3.712, Average Loss: 3.859, avg. samples / sec: 54589.60
Iteration:   3600, Loss function: 2.936, Average Loss: 3.876, avg. samples / sec: 54586.36
Iteration:   3600, Loss function: 2.092, Average Loss: 3.903, avg. samples / sec: 54566.52
Iteration:   3600, Loss function: 3.174, Average Loss: 3.870, avg. samples / sec: 54570.28
Iteration:   3600, Loss function: 2.673, Average Loss: 3.878, avg. samples / sec: 54483.53
Iteration:   3600, Loss function: 3.216, Average Loss: 3.888, avg. samples / sec: 54608.97
Iteration:   3600, Loss function: 3.260, Average Loss: 3.910, avg. samples / sec: 54579.01
Iteration:   3600, Loss function: 4.120, Average Loss: 3.875, avg. samples / sec: 54536.57
Iteration:   3600, Loss function: 2.720, Average Loss: 3.863, avg. samples / sec: 54545.50
Iteration:   3600, Loss function: 3.865, Average Loss: 3.870, avg. samples / sec: 54544.02
Iteration:   3600, Loss function: 3.165, Average Loss: 3.885, avg. samples / sec: 54563.50
Iteration:   3600, Loss function: 2.974, Average Loss: 3.903, avg. samples / sec: 54544.40
Iteration:   3600, Loss function: 2.783, Average Loss: 3.883, avg. samples / sec: 54559.55
Iteration:   3600, Loss function: 3.448, Average Loss: 3.890, avg. samples / sec: 54556.52
Iteration:   3600, Loss function: 2.644, Average Loss: 3.906, avg. samples / sec: 54591.75
Iteration:   3600, Loss function: 4.281, Average Loss: 3.867, avg. samples / sec: 54586.72
Iteration:   3600, Loss function: 3.514, Average Loss: 3.877, avg. samples / sec: 54381.62
Iteration:   3600, Loss function: 3.355, Average Loss: 3.902, avg. samples / sec: 54473.44
Iteration:   3600, Loss function: 2.992, Average Loss: 3.869, avg. samples / sec: 54511.56
Iteration:   3600, Loss function: 2.826, Average Loss: 3.874, avg. samples / sec: 54343.02
Iteration:   3600, Loss function: 3.633, Average Loss: 3.913, avg. samples / sec: 54573.38
Iteration:   3600, Loss function: 4.031, Average Loss: 3.880, avg. samples / sec: 54539.80
Iteration:   3600, Loss function: 3.484, Average Loss: 3.894, avg. samples / sec: 54307.25
Iteration:   3600, Loss function: 3.760, Average Loss: 3.907, avg. samples / sec: 54512.55
Iteration:   3600, Loss function: 3.290, Average Loss: 3.903, avg. samples / sec: 54524.48
Iteration:   3600, Loss function: 4.681, Average Loss: 3.858, avg. samples / sec: 54499.27
Iteration:   3600, Loss function: 3.472, Average Loss: 3.892, avg. samples / sec: 54535.43
Iteration:   3600, Loss function: 2.548, Average Loss: 3.914, avg. samples / sec: 54488.92
Iteration:   3620, Loss function: 3.680, Average Loss: 3.856, avg. samples / sec: 54688.68
Iteration:   3620, Loss function: 3.826, Average Loss: 3.874, avg. samples / sec: 54660.29
Iteration:   3620, Loss function: 3.686, Average Loss: 3.870, avg. samples / sec: 54692.41
Iteration:   3620, Loss function: 2.750, Average Loss: 3.898, avg. samples / sec: 54705.21
Iteration:   3620, Loss function: 3.147, Average Loss: 3.903, avg. samples / sec: 54711.48
Iteration:   3620, Loss function: 2.978, Average Loss: 3.859, avg. samples / sec: 54696.06
Iteration:   3620, Loss function: 2.885, Average Loss: 3.853, avg. samples / sec: 54656.14
Iteration:   3620, Loss function: 3.325, Average Loss: 3.884, avg. samples / sec: 54963.22
Iteration:   3620, Loss function: 2.457, Average Loss: 3.865, avg. samples / sec: 54675.18
Iteration:   3620, Loss function: 5.617, Average Loss: 3.870, avg. samples / sec: 54912.87
Iteration:   3620, Loss function: 3.043, Average Loss: 3.879, avg. samples / sec: 54671.32
Iteration:   3620, Loss function: 3.616, Average Loss: 3.864, avg. samples / sec: 54704.32
Iteration:   3620, Loss function: 2.213, Average Loss: 3.853, avg. samples / sec: 54691.75
Iteration:   3620, Loss function: 2.963, Average Loss: 3.861, avg. samples / sec: 54902.00
Iteration:   3620, Loss function: 3.427, Average Loss: 3.895, avg. samples / sec: 54742.34
Iteration:   3620, Loss function: 3.716, Average Loss: 3.859, avg. samples / sec: 54733.77
Iteration:   3620, Loss function: 4.690, Average Loss: 3.878, avg. samples / sec: 54743.17
Iteration:   3620, Loss function: 3.437, Average Loss: 3.893, avg. samples / sec: 54768.44
Iteration:   3620, Loss function: 4.238, Average Loss: 3.876, avg. samples / sec: 54713.64
Iteration:   3620, Loss function: 3.094, Average Loss: 3.873, avg. samples / sec: 54737.79
Iteration:   3620, Loss function: 2.646, Average Loss: 3.894, avg. samples / sec: 54709.52
Iteration:   3620, Loss function: 3.298, Average Loss: 3.869, avg. samples / sec: 54674.33
Iteration:   3620, Loss function: 3.134, Average Loss: 3.858, avg. samples / sec: 54715.09
Iteration:   3620, Loss function: 3.581, Average Loss: 3.895, avg. samples / sec: 54728.43
Iteration:   3620, Loss function: 3.237, Average Loss: 3.902, avg. samples / sec: 54714.62
Iteration:   3620, Loss function: 3.358, Average Loss: 3.902, avg. samples / sec: 54758.22
Iteration:   3620, Loss function: 3.015, Average Loss: 3.860, avg. samples / sec: 54681.14
Iteration:   3620, Loss function: 3.496, Average Loss: 3.883, avg. samples / sec: 54744.97
Iteration:   3620, Loss function: 4.014, Average Loss: 3.895, avg. samples / sec: 54644.00
Iteration:   3620, Loss function: 3.505, Average Loss: 3.848, avg. samples / sec: 54696.61
:::MLL 1558641224.529 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558641224.530 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 3.103, Average Loss: 3.851, avg. samples / sec: 54503.42
Iteration:   3640, Loss function: 2.602, Average Loss: 3.859, avg. samples / sec: 54511.45
Iteration:   3640, Loss function: 2.744, Average Loss: 3.852, avg. samples / sec: 54476.98
Iteration:   3640, Loss function: 2.931, Average Loss: 3.864, avg. samples / sec: 54444.36
Iteration:   3640, Loss function: 3.600, Average Loss: 3.844, avg. samples / sec: 54508.20
Iteration:   3640, Loss function: 3.278, Average Loss: 3.895, avg. samples / sec: 54456.28
Iteration:   3640, Loss function: 3.306, Average Loss: 3.873, avg. samples / sec: 54483.34
Iteration:   3640, Loss function: 3.009, Average Loss: 3.891, avg. samples / sec: 54440.49
Iteration:   3640, Loss function: 4.317, Average Loss: 3.863, avg. samples / sec: 54424.59
Iteration:   3640, Loss function: 3.990, Average Loss: 3.872, avg. samples / sec: 54463.42
Iteration:   3640, Loss function: 3.410, Average Loss: 3.857, avg. samples / sec: 54469.78
Iteration:   3640, Loss function: 3.336, Average Loss: 3.854, avg. samples / sec: 54478.45
Iteration:   3640, Loss function: 3.885, Average Loss: 3.865, avg. samples / sec: 54442.17
Iteration:   3640, Loss function: 3.653, Average Loss: 3.844, avg. samples / sec: 54424.40
Iteration:   3640, Loss function: 4.540, Average Loss: 3.850, avg. samples / sec: 54456.26
Iteration:   3640, Loss function: 3.067, Average Loss: 3.883, avg. samples / sec: 54447.74
Iteration:   3640, Loss function: 3.975, Average Loss: 3.860, avg. samples / sec: 54504.64
Iteration:   3640, Loss function: 3.862, Average Loss: 3.866, avg. samples / sec: 54448.50
Iteration:   3640, Loss function: 2.636, Average Loss: 3.863, avg. samples / sec: 54472.20
Iteration:   3640, Loss function: 3.358, Average Loss: 3.861, avg. samples / sec: 54467.99
Iteration:   3640, Loss function: 4.215, Average Loss: 3.850, avg. samples / sec: 54484.28
Iteration:   3640, Loss function: 4.379, Average Loss: 3.886, avg. samples / sec: 54490.88
Iteration:   3640, Loss function: 4.054, Average Loss: 3.856, avg. samples / sec: 54498.68
Iteration:   3640, Loss function: 3.543, Average Loss: 3.838, avg. samples / sec: 54536.38
Iteration:   3640, Loss function: 3.205, Average Loss: 3.890, avg. samples / sec: 54496.61
Iteration:   3640, Loss function: 2.478, Average Loss: 3.882, avg. samples / sec: 54526.64
Iteration:   3640, Loss function: 3.113, Average Loss: 3.886, avg. samples / sec: 54442.42
Iteration:   3640, Loss function: 3.624, Average Loss: 3.888, avg. samples / sec: 54450.75
Iteration:   3640, Loss function: 3.399, Average Loss: 3.894, avg. samples / sec: 54462.89
Iteration:   3640, Loss function: 2.266, Average Loss: 3.871, avg. samples / sec: 54439.14
Iteration:   3660, Loss function: 2.844, Average Loss: 3.849, avg. samples / sec: 54497.71
Iteration:   3660, Loss function: 3.572, Average Loss: 3.846, avg. samples / sec: 54439.83
Iteration:   3660, Loss function: 4.710, Average Loss: 3.858, avg. samples / sec: 54431.36
Iteration:   3660, Loss function: 3.507, Average Loss: 3.882, avg. samples / sec: 54442.59
Iteration:   3660, Loss function: 3.471, Average Loss: 3.847, avg. samples / sec: 54409.02
Iteration:   3660, Loss function: 3.994, Average Loss: 3.841, avg. samples / sec: 54394.11
Iteration:   3660, Loss function: 3.794, Average Loss: 3.865, avg. samples / sec: 54408.20
Iteration:   3660, Loss function: 2.556, Average Loss: 3.844, avg. samples / sec: 54426.27
Iteration:   3660, Loss function: 3.590, Average Loss: 3.869, avg. samples / sec: 54400.07
Iteration:   3660, Loss function: 2.773, Average Loss: 3.856, avg. samples / sec: 54390.35
Iteration:   3660, Loss function: 3.880, Average Loss: 3.859, avg. samples / sec: 54412.19
Iteration:   3660, Loss function: 3.227, Average Loss: 3.878, avg. samples / sec: 54365.87
Iteration:   3660, Loss function: 4.601, Average Loss: 3.849, avg. samples / sec: 54104.76
Iteration:   3660, Loss function: 3.616, Average Loss: 3.872, avg. samples / sec: 54466.22
Iteration:   3660, Loss function: 3.520, Average Loss: 3.852, avg. samples / sec: 54446.90
Iteration:   3660, Loss function: 2.273, Average Loss: 3.875, avg. samples / sec: 54461.36
Iteration:   3660, Loss function: 3.103, Average Loss: 3.871, avg. samples / sec: 54404.11
Iteration:   3660, Loss function: 4.265, Average Loss: 3.852, avg. samples / sec: 54406.14
Iteration:   3660, Loss function: 2.627, Average Loss: 3.832, avg. samples / sec: 54433.82
Iteration:   3660, Loss function: 3.539, Average Loss: 3.837, avg. samples / sec: 54414.50
Iteration:   3660, Loss function: 2.278, Average Loss: 3.878, avg. samples / sec: 54408.58
Iteration:   3660, Loss function: 4.022, Average Loss: 3.852, avg. samples / sec: 54389.20
Iteration:   3660, Loss function: 3.432, Average Loss: 3.876, avg. samples / sec: 54388.86
Iteration:   3660, Loss function: 3.543, Average Loss: 3.881, avg. samples / sec: 54405.32
Iteration:   3660, Loss function: 2.902, Average Loss: 3.860, avg. samples / sec: 54465.06
Iteration:   3660, Loss function: 2.139, Average Loss: 3.857, avg. samples / sec: 54373.27
Iteration:   3660, Loss function: 3.051, Average Loss: 3.883, avg. samples / sec: 54401.04
Iteration:   3660, Loss function: 3.907, Average Loss: 3.836, avg. samples / sec: 54201.48
Iteration:   3660, Loss function: 3.091, Average Loss: 3.845, avg. samples / sec: 54302.98
Iteration:   3660, Loss function: 3.570, Average Loss: 3.853, avg. samples / sec: 54333.63
Iteration:   3680, Loss function: 2.607, Average Loss: 3.842, avg. samples / sec: 54330.87
Iteration:   3680, Loss function: 4.850, Average Loss: 3.854, avg. samples / sec: 54131.09
Iteration:   3680, Loss function: 4.146, Average Loss: 3.835, avg. samples / sec: 54048.82
Iteration:   3680, Loss function: 3.063, Average Loss: 3.843, avg. samples / sec: 54112.86
Iteration:   3680, Loss function: 3.654, Average Loss: 3.846, avg. samples / sec: 53998.51
Iteration:   3680, Loss function: 3.740, Average Loss: 3.850, avg. samples / sec: 54045.44
Iteration:   3680, Loss function: 3.041, Average Loss: 3.827, avg. samples / sec: 54328.62
Iteration:   3680, Loss function: 3.712, Average Loss: 3.837, avg. samples / sec: 54051.55
Iteration:   3680, Loss function: 2.983, Average Loss: 3.874, avg. samples / sec: 54119.24
Iteration:   3680, Loss function: 2.347, Average Loss: 3.874, avg. samples / sec: 54040.59
Iteration:   3680, Loss function: 2.608, Average Loss: 3.859, avg. samples / sec: 54087.88
Iteration:   3680, Loss function: 3.404, Average Loss: 3.833, avg. samples / sec: 54074.82
Iteration:   3680, Loss function: 3.519, Average Loss: 3.855, avg. samples / sec: 54073.87
Iteration:   3680, Loss function: 4.227, Average Loss: 3.832, avg. samples / sec: 54058.44
Iteration:   3680, Loss function: 3.200, Average Loss: 3.868, avg. samples / sec: 54115.87
Iteration:   3680, Loss function: 3.148, Average Loss: 3.838, avg. samples / sec: 54101.62
Iteration:   3680, Loss function: 3.693, Average Loss: 3.830, avg. samples / sec: 54087.30
Iteration:   3680, Loss function: 4.242, Average Loss: 3.842, avg. samples / sec: 54069.47
Iteration:   3680, Loss function: 2.895, Average Loss: 3.827, avg. samples / sec: 54071.01
Iteration:   3680, Loss function: 4.015, Average Loss: 3.838, avg. samples / sec: 54168.15
Iteration:   3680, Loss function: 3.101, Average Loss: 3.840, avg. samples / sec: 54033.83
Iteration:   3680, Loss function: 1.941, Average Loss: 3.868, avg. samples / sec: 54044.53
Iteration:   3680, Loss function: 3.500, Average Loss: 3.868, avg. samples / sec: 54100.67
Iteration:   3680, Loss function: 4.496, Average Loss: 3.862, avg. samples / sec: 54021.16
Iteration:   3680, Loss function: 3.891, Average Loss: 3.850, avg. samples / sec: 54085.88
Iteration:   3680, Loss function: 3.814, Average Loss: 3.837, avg. samples / sec: 54131.80
Iteration:   3680, Loss function: 4.204, Average Loss: 3.865, avg. samples / sec: 54030.35
Iteration:   3680, Loss function: 3.326, Average Loss: 3.869, avg. samples / sec: 54041.21
Iteration:   3680, Loss function: 3.340, Average Loss: 3.878, avg. samples / sec: 54051.53
Iteration:   3680, Loss function: 4.239, Average Loss: 3.847, avg. samples / sec: 54039.43
:::MLL 1558641226.703 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558641226.703 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 2.938, Average Loss: 3.844, avg. samples / sec: 53531.21
Iteration:   3700, Loss function: 4.454, Average Loss: 3.833, avg. samples / sec: 53394.43
Iteration:   3700, Loss function: 2.760, Average Loss: 3.825, avg. samples / sec: 53518.83
Iteration:   3700, Loss function: 3.552, Average Loss: 3.827, avg. samples / sec: 53534.67
Iteration:   3700, Loss function: 4.045, Average Loss: 3.842, avg. samples / sec: 53511.96
Iteration:   3700, Loss function: 3.948, Average Loss: 3.837, avg. samples / sec: 53495.14
Iteration:   3700, Loss function: 2.222, Average Loss: 3.838, avg. samples / sec: 53472.27
Iteration:   3700, Loss function: 3.470, Average Loss: 3.831, avg. samples / sec: 53465.65
Iteration:   3700, Loss function: 4.896, Average Loss: 3.823, avg. samples / sec: 53472.47
Iteration:   3700, Loss function: 2.519, Average Loss: 3.824, avg. samples / sec: 53430.58
Iteration:   3700, Loss function: 4.009, Average Loss: 3.866, avg. samples / sec: 53438.40
Iteration:   3700, Loss function: 3.581, Average Loss: 3.847, avg. samples / sec: 53434.98
Iteration:   3700, Loss function: 3.624, Average Loss: 3.825, avg. samples / sec: 53435.04
Iteration:   3700, Loss function: 2.012, Average Loss: 3.862, avg. samples / sec: 53382.31
Iteration:   3700, Loss function: 2.692, Average Loss: 3.856, avg. samples / sec: 53609.93
Iteration:   3700, Loss function: 3.435, Average Loss: 3.826, avg. samples / sec: 53528.06
Iteration:   3700, Loss function: 2.705, Average Loss: 3.837, avg. samples / sec: 53580.81
Iteration:   3700, Loss function: 4.062, Average Loss: 3.856, avg. samples / sec: 53517.51
Iteration:   3700, Loss function: 2.450, Average Loss: 3.859, avg. samples / sec: 53502.94
Iteration:   3700, Loss function: 2.456, Average Loss: 3.847, avg. samples / sec: 53503.12
Iteration:   3700, Loss function: 3.879, Average Loss: 3.844, avg. samples / sec: 53486.73
Iteration:   3700, Loss function: 2.963, Average Loss: 3.835, avg. samples / sec: 53456.18
Iteration:   3700, Loss function: 2.863, Average Loss: 3.824, avg. samples / sec: 53477.82
Iteration:   3700, Loss function: 3.439, Average Loss: 3.823, avg. samples / sec: 53428.31
Iteration:   3700, Loss function: 3.688, Average Loss: 3.859, avg. samples / sec: 53427.91
Iteration:   3700, Loss function: 3.550, Average Loss: 3.861, avg. samples / sec: 53447.40
Iteration:   3700, Loss function: 2.844, Average Loss: 3.825, avg. samples / sec: 53418.27
Iteration:   3700, Loss function: 3.181, Average Loss: 3.819, avg. samples / sec: 53402.72
Iteration:   3700, Loss function: 3.612, Average Loss: 3.867, avg. samples / sec: 53444.71
Iteration:   3700, Loss function: 2.726, Average Loss: 3.831, avg. samples / sec: 53380.43
Iteration:   3720, Loss function: 4.492, Average Loss: 3.824, avg. samples / sec: 53997.42
Iteration:   3720, Loss function: 3.122, Average Loss: 3.830, avg. samples / sec: 53947.15
Iteration:   3720, Loss function: 3.089, Average Loss: 3.834, avg. samples / sec: 53946.45
Iteration:   3720, Loss function: 3.255, Average Loss: 3.821, avg. samples / sec: 53916.93
Iteration:   3720, Loss function: 2.554, Average Loss: 3.814, avg. samples / sec: 53907.16
Iteration:   3720, Loss function: 3.937, Average Loss: 3.813, avg. samples / sec: 53940.31
Iteration:   3720, Loss function: 3.998, Average Loss: 3.855, avg. samples / sec: 53989.10
Iteration:   3720, Loss function: 4.501, Average Loss: 3.817, avg. samples / sec: 53842.59
Iteration:   3720, Loss function: 4.146, Average Loss: 3.839, avg. samples / sec: 53859.30
Iteration:   3720, Loss function: 2.971, Average Loss: 3.857, avg. samples / sec: 53923.39
Iteration:   3720, Loss function: 3.673, Average Loss: 3.835, avg. samples / sec: 53797.90
Iteration:   3720, Loss function: 3.843, Average Loss: 3.814, avg. samples / sec: 53914.21
Iteration:   3720, Loss function: 3.424, Average Loss: 3.840, avg. samples / sec: 53900.33
Iteration:   3720, Loss function: 3.266, Average Loss: 3.826, avg. samples / sec: 53781.73
Iteration:   3720, Loss function: 3.634, Average Loss: 3.845, avg. samples / sec: 53912.81
Iteration:   3720, Loss function: 3.782, Average Loss: 3.823, avg. samples / sec: 53926.59
Iteration:   3720, Loss function: 3.216, Average Loss: 3.853, avg. samples / sec: 53943.43
Iteration:   3720, Loss function: 3.166, Average Loss: 3.849, avg. samples / sec: 53924.03
Iteration:   3720, Loss function: 3.567, Average Loss: 3.839, avg. samples / sec: 53903.20
Iteration:   3720, Loss function: 2.784, Average Loss: 3.817, avg. samples / sec: 53926.65
Iteration:   3720, Loss function: 4.459, Average Loss: 3.817, avg. samples / sec: 53946.11
Iteration:   3720, Loss function: 3.780, Average Loss: 3.838, avg. samples / sec: 53861.05
Iteration:   3720, Loss function: 3.519, Average Loss: 3.817, avg. samples / sec: 53890.95
Iteration:   3720, Loss function: 2.931, Average Loss: 3.814, avg. samples / sec: 53937.84
Iteration:   3720, Loss function: 5.506, Average Loss: 3.820, avg. samples / sec: 53808.03
Iteration:   3720, Loss function: 3.920, Average Loss: 3.845, avg. samples / sec: 53829.06
Iteration:   3720, Loss function: 4.174, Average Loss: 3.861, avg. samples / sec: 53948.49
Iteration:   3720, Loss function: 3.283, Average Loss: 3.824, avg. samples / sec: 53954.83
Iteration:   3720, Loss function: 2.259, Average Loss: 3.840, avg. samples / sec: 53755.06
Iteration:   3720, Loss function: 4.703, Average Loss: 3.830, avg. samples / sec: 53788.40
Iteration:   3740, Loss function: 4.219, Average Loss: 3.821, avg. samples / sec: 53777.13
Iteration:   3740, Loss function: 3.525, Average Loss: 3.823, avg. samples / sec: 53801.19
Iteration:   3740, Loss function: 4.048, Average Loss: 3.821, avg. samples / sec: 53760.29
Iteration:   3740, Loss function: 2.753, Average Loss: 3.808, avg. samples / sec: 53804.87
Iteration:   3740, Loss function: 2.482, Average Loss: 3.805, avg. samples / sec: 53787.97
Iteration:   3740, Loss function: 3.015, Average Loss: 3.806, avg. samples / sec: 53782.94
Iteration:   3740, Loss function: 4.289, Average Loss: 3.847, avg. samples / sec: 53795.15
Iteration:   3740, Loss function: 2.283, Average Loss: 3.829, avg. samples / sec: 53784.89
Iteration:   3740, Loss function: 4.232, Average Loss: 3.821, avg. samples / sec: 53841.89
Iteration:   3740, Loss function: 3.349, Average Loss: 3.810, avg. samples / sec: 53716.27
Iteration:   3740, Loss function: 4.643, Average Loss: 3.851, avg. samples / sec: 53724.46
Iteration:   3740, Loss function: 4.961, Average Loss: 3.840, avg. samples / sec: 53787.72
Iteration:   3740, Loss function: 2.459, Average Loss: 3.810, avg. samples / sec: 53834.83
Iteration:   3740, Loss function: 4.172, Average Loss: 3.833, avg. samples / sec: 53791.52
Iteration:   3740, Loss function: 3.661, Average Loss: 3.816, avg. samples / sec: 53815.67
Iteration:   3740, Loss function: 4.339, Average Loss: 3.815, avg. samples / sec: 53765.93
Iteration:   3740, Loss function: 2.864, Average Loss: 3.847, avg. samples / sec: 53759.53
Iteration:   3740, Loss function: 3.034, Average Loss: 3.829, avg. samples / sec: 53588.47
Iteration:   3740, Loss function: 2.167, Average Loss: 3.805, avg. samples / sec: 53774.46
Iteration:   3740, Loss function: 3.779, Average Loss: 3.842, avg. samples / sec: 53759.18
Iteration:   3740, Loss function: 2.300, Average Loss: 3.826, avg. samples / sec: 53766.17
Iteration:   3740, Loss function: 4.325, Average Loss: 3.803, avg. samples / sec: 53570.71
Iteration:   3740, Loss function: 2.753, Average Loss: 3.816, avg. samples / sec: 53779.45
Iteration:   3740, Loss function: 3.211, Average Loss: 3.852, avg. samples / sec: 53777.25
Iteration:   3740, Loss function: 3.833, Average Loss: 3.811, avg. samples / sec: 53737.92
Iteration:   3740, Loss function: 3.993, Average Loss: 3.833, avg. samples / sec: 53784.07
Iteration:   3740, Loss function: 3.494, Average Loss: 3.819, avg. samples / sec: 53775.63
Iteration:   3740, Loss function: 2.948, Average Loss: 3.803, avg. samples / sec: 53738.00
Iteration:   3740, Loss function: 2.369, Average Loss: 3.827, avg. samples / sec: 53535.95
Iteration:   3740, Loss function: 4.042, Average Loss: 3.840, avg. samples / sec: 53727.82
Iteration:   3760, Loss function: 2.664, Average Loss: 3.814, avg. samples / sec: 53722.70
Iteration:   3760, Loss function: 4.341, Average Loss: 3.808, avg. samples / sec: 53623.27
Iteration:   3760, Loss function: 2.707, Average Loss: 3.811, avg. samples / sec: 53716.50
Iteration:   3760, Loss function: 4.614, Average Loss: 3.802, avg. samples / sec: 53697.54
Iteration:   3760, Loss function: 2.652, Average Loss: 3.796, avg. samples / sec: 53719.53
Iteration:   3760, Loss function: 3.158, Average Loss: 3.799, avg. samples / sec: 53715.66
Iteration:   3760, Loss function: 3.842, Average Loss: 3.820, avg. samples / sec: 54013.10
Iteration:   3760, Loss function: 3.804, Average Loss: 3.843, avg. samples / sec: 53799.55
Iteration:   3760, Loss function: 2.335, Average Loss: 3.837, avg. samples / sec: 53708.86
Iteration:   3760, Loss function: 3.460, Average Loss: 3.824, avg. samples / sec: 53726.94
Iteration:   3760, Loss function: 3.329, Average Loss: 3.813, avg. samples / sec: 53723.42
Iteration:   3760, Loss function: 3.490, Average Loss: 3.790, avg. samples / sec: 53939.80
Iteration:   3760, Loss function: 3.064, Average Loss: 3.821, avg. samples / sec: 53898.54
Iteration:   3760, Loss function: 3.881, Average Loss: 3.796, avg. samples / sec: 53736.12
Iteration:   3760, Loss function: 1.971, Average Loss: 3.838, avg. samples / sec: 53759.41
Iteration:   3760, Loss function: 3.743, Average Loss: 3.795, avg. samples / sec: 53820.94
Iteration:   3760, Loss function: 3.899, Average Loss: 3.797, avg. samples / sec: 53796.92
Iteration:   3760, Loss function: 2.869, Average Loss: 3.832, avg. samples / sec: 53770.32
Iteration:   3760, Loss function: 4.159, Average Loss: 3.800, avg. samples / sec: 53712.24
Iteration:   3760, Loss function: 2.657, Average Loss: 3.806, avg. samples / sec: 53741.34
Iteration:   3760, Loss function: 3.078, Average Loss: 3.827, avg. samples / sec: 53724.87
Iteration:   3760, Loss function: 2.748, Average Loss: 3.828, avg. samples / sec: 53691.84
Iteration:   3760, Loss function: 3.079, Average Loss: 3.795, avg. samples / sec: 53738.00
Iteration:   3760, Loss function: 3.677, Average Loss: 3.820, avg. samples / sec: 53757.05
Iteration:   3760, Loss function: 3.907, Average Loss: 3.829, avg. samples / sec: 53807.99
Iteration:   3760, Loss function: 3.119, Average Loss: 3.802, avg. samples / sec: 53769.64
Iteration:   3760, Loss function: 3.043, Average Loss: 3.806, avg. samples / sec: 53691.69
Iteration:   3760, Loss function: 3.458, Average Loss: 3.822, avg. samples / sec: 53751.39
Iteration:   3760, Loss function: 3.546, Average Loss: 3.844, avg. samples / sec: 53727.78
Iteration:   3760, Loss function: 2.979, Average Loss: 3.806, avg. samples / sec: 53690.63
:::MLL 1558641228.893 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558641228.894 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 2.090, Average Loss: 3.799, avg. samples / sec: 53458.53
Iteration:   3780, Loss function: 2.968, Average Loss: 3.803, avg. samples / sec: 53349.74
Iteration:   3780, Loss function: 2.552, Average Loss: 3.790, avg. samples / sec: 53409.77
Iteration:   3780, Loss function: 2.934, Average Loss: 3.790, avg. samples / sec: 53391.92
Iteration:   3780, Loss function: 2.304, Average Loss: 3.803, avg. samples / sec: 53359.66
Iteration:   3780, Loss function: 3.501, Average Loss: 3.787, avg. samples / sec: 53440.61
Iteration:   3780, Loss function: 2.866, Average Loss: 3.814, avg. samples / sec: 53392.51
Iteration:   3780, Loss function: 3.992, Average Loss: 3.830, avg. samples / sec: 53385.95
Iteration:   3780, Loss function: 2.908, Average Loss: 3.786, avg. samples / sec: 53373.90
Iteration:   3780, Loss function: 2.698, Average Loss: 3.790, avg. samples / sec: 53552.75
Iteration:   3780, Loss function: 3.499, Average Loss: 3.814, avg. samples / sec: 53410.98
Iteration:   3780, Loss function: 3.049, Average Loss: 3.807, avg. samples / sec: 53365.62
Iteration:   3780, Loss function: 3.541, Average Loss: 3.782, avg. samples / sec: 53374.33
Iteration:   3780, Loss function: 3.767, Average Loss: 3.832, avg. samples / sec: 53330.54
Iteration:   3780, Loss function: 3.302, Average Loss: 3.814, avg. samples / sec: 53325.09
Iteration:   3780, Loss function: 3.470, Average Loss: 3.798, avg. samples / sec: 53415.86
Iteration:   3780, Loss function: 3.503, Average Loss: 3.817, avg. samples / sec: 53396.31
Iteration:   3780, Loss function: 4.236, Average Loss: 3.786, avg. samples / sec: 53398.84
Iteration:   3780, Loss function: 3.397, Average Loss: 3.790, avg. samples / sec: 53378.82
Iteration:   3780, Loss function: 2.208, Average Loss: 3.815, avg. samples / sec: 53378.43
Iteration:   3780, Loss function: 4.454, Average Loss: 3.794, avg. samples / sec: 53414.93
Iteration:   3780, Loss function: 4.259, Average Loss: 3.812, avg. samples / sec: 53384.64
Iteration:   3780, Loss function: 3.723, Average Loss: 3.832, avg. samples / sec: 53336.07
Iteration:   3780, Loss function: 3.230, Average Loss: 3.823, avg. samples / sec: 53368.30
Iteration:   3780, Loss function: 3.601, Average Loss: 3.816, avg. samples / sec: 53392.37
Iteration:   3780, Loss function: 3.906, Average Loss: 3.822, avg. samples / sec: 53310.34
Iteration:   3780, Loss function: 3.501, Average Loss: 3.791, avg. samples / sec: 53346.67
Iteration:   3780, Loss function: 2.965, Average Loss: 3.796, avg. samples / sec: 53403.76
Iteration:   3780, Loss function: 4.330, Average Loss: 3.835, avg. samples / sec: 53361.05
Iteration:   3780, Loss function: 4.328, Average Loss: 3.784, avg. samples / sec: 53284.69
Iteration:   3800, Loss function: 3.462, Average Loss: 3.797, avg. samples / sec: 53822.40
Iteration:   3800, Loss function: 2.540, Average Loss: 3.794, avg. samples / sec: 53808.38
Iteration:   3800, Loss function: 2.279, Average Loss: 3.782, avg. samples / sec: 53840.57
Iteration:   3800, Loss function: 3.455, Average Loss: 3.785, avg. samples / sec: 53794.91
Iteration:   3800, Loss function: 2.783, Average Loss: 3.779, avg. samples / sec: 53819.46
Iteration:   3800, Loss function: 3.369, Average Loss: 3.783, avg. samples / sec: 54098.61
Iteration:   3800, Loss function: 3.971, Average Loss: 3.825, avg. samples / sec: 53862.92
Iteration:   3800, Loss function: 3.598, Average Loss: 3.811, avg. samples / sec: 53797.41
Iteration:   3800, Loss function: 3.174, Average Loss: 3.783, avg. samples / sec: 53750.86
Iteration:   3800, Loss function: 2.989, Average Loss: 3.808, avg. samples / sec: 53771.59
Iteration:   3800, Loss function: 2.412, Average Loss: 3.789, avg. samples / sec: 53623.95
Iteration:   3800, Loss function: 3.462, Average Loss: 3.822, avg. samples / sec: 53757.48
Iteration:   3800, Loss function: 3.721, Average Loss: 3.805, avg. samples / sec: 53805.48
Iteration:   3800, Loss function: 4.098, Average Loss: 3.773, avg. samples / sec: 53784.19
Iteration:   3800, Loss function: 2.533, Average Loss: 3.799, avg. samples / sec: 53771.32
Iteration:   3800, Loss function: 2.792, Average Loss: 3.808, avg. samples / sec: 53794.39
Iteration:   3800, Loss function: 2.379, Average Loss: 3.785, avg. samples / sec: 53741.16
Iteration:   3800, Loss function: 3.185, Average Loss: 3.782, avg. samples / sec: 53767.30
Iteration:   3800, Loss function: 1.755, Average Loss: 3.785, avg. samples / sec: 53758.17
Iteration:   3800, Loss function: 3.225, Average Loss: 3.775, avg. samples / sec: 53847.05
Iteration:   3800, Loss function: 2.345, Average Loss: 3.815, avg. samples / sec: 53795.85
Iteration:   3800, Loss function: 5.215, Average Loss: 3.802, avg. samples / sec: 53764.00
Iteration:   3800, Loss function: 2.464, Average Loss: 3.787, avg. samples / sec: 53818.72
Iteration:   3800, Loss function: 3.227, Average Loss: 3.824, avg. samples / sec: 53780.13
Iteration:   3800, Loss function: 3.257, Average Loss: 3.786, avg. samples / sec: 53748.89
Iteration:   3800, Loss function: 3.308, Average Loss: 3.812, avg. samples / sec: 53804.79
Iteration:   3800, Loss function: 3.992, Average Loss: 3.809, avg. samples / sec: 53743.80
Iteration:   3800, Loss function: 2.765, Average Loss: 3.809, avg. samples / sec: 53774.15
Iteration:   3800, Loss function: 3.135, Average Loss: 3.828, avg. samples / sec: 53782.47
Iteration:   3800, Loss function: 4.198, Average Loss: 3.781, avg. samples / sec: 53490.31
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558641230.158 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.68 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.61s)
DONE (t=2.43s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22589
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38761
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23103
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06252
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23288
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37105
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32017
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10380
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36177
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52238
Current AP: 0.22589 AP goal: 0.23000
:::MLL 1558641233.864 eval_accuracy: {"value": 0.2258936419730638, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558641233.994 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558641234.001 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558641234.001 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 4.457, Average Loss: 3.781, avg. samples / sec: 7485.36
Iteration:   3820, Loss function: 2.813, Average Loss: 3.801, avg. samples / sec: 7487.17
Iteration:   3820, Loss function: 2.326, Average Loss: 3.801, avg. samples / sec: 7488.24
Iteration:   3820, Loss function: 3.986, Average Loss: 3.812, avg. samples / sec: 7483.44
Iteration:   3820, Loss function: 4.194, Average Loss: 3.775, avg. samples / sec: 7482.36
Iteration:   3820, Loss function: 4.053, Average Loss: 3.773, avg. samples / sec: 7482.18
Iteration:   3820, Loss function: 3.468, Average Loss: 3.775, avg. samples / sec: 7482.05
Iteration:   3820, Loss function: 3.325, Average Loss: 3.783, avg. samples / sec: 7481.84
Iteration:   3820, Loss function: 6.455, Average Loss: 3.802, avg. samples / sec: 7482.75
Iteration:   3820, Loss function: 3.227, Average Loss: 3.799, avg. samples / sec: 7483.21
Iteration:   3820, Loss function: 2.457, Average Loss: 3.791, avg. samples / sec: 7483.38
Iteration:   3820, Loss function: 2.832, Average Loss: 3.775, avg. samples / sec: 7488.27
Iteration:   3820, Loss function: 2.593, Average Loss: 3.806, avg. samples / sec: 7482.27
Iteration:   3820, Loss function: 4.473, Average Loss: 3.770, avg. samples / sec: 7481.38
Iteration:   3820, Loss function: 2.833, Average Loss: 3.765, avg. samples / sec: 7482.57
Iteration:   3820, Loss function: 3.110, Average Loss: 3.818, avg. samples / sec: 7481.09
Iteration:   3820, Loss function: 2.768, Average Loss: 3.779, avg. samples / sec: 7483.40
Iteration:   3820, Loss function: 3.139, Average Loss: 3.794, avg. samples / sec: 7477.15
Iteration:   3820, Loss function: 4.092, Average Loss: 3.794, avg. samples / sec: 7483.15
Iteration:   3820, Loss function: 3.700, Average Loss: 3.771, avg. samples / sec: 7482.53
Iteration:   3820, Loss function: 3.765, Average Loss: 3.812, avg. samples / sec: 7483.04
Iteration:   3820, Loss function: 2.795, Average Loss: 3.772, avg. samples / sec: 7482.44
Iteration:   3820, Loss function: 2.633, Average Loss: 3.800, avg. samples / sec: 7482.94
Iteration:   3820, Loss function: 4.693, Average Loss: 3.806, avg. samples / sec: 7482.67
Iteration:   3820, Loss function: 4.800, Average Loss: 3.771, avg. samples / sec: 7482.27
Iteration:   3820, Loss function: 2.467, Average Loss: 3.777, avg. samples / sec: 7478.11
Iteration:   3820, Loss function: 2.753, Average Loss: 3.781, avg. samples / sec: 7481.75
Iteration:   3820, Loss function: 2.996, Average Loss: 3.800, avg. samples / sec: 7482.02
Iteration:   3820, Loss function: 3.176, Average Loss: 3.818, avg. samples / sec: 7482.93
Iteration:   3820, Loss function: 3.266, Average Loss: 3.777, avg. samples / sec: 7481.91
:::MLL 1558641234.958 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558641234.959 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 4.117, Average Loss: 3.775, avg. samples / sec: 52794.39
Iteration:   3840, Loss function: 3.571, Average Loss: 3.769, avg. samples / sec: 52842.62
Iteration:   3840, Loss function: 2.075, Average Loss: 3.782, avg. samples / sec: 52867.24
Iteration:   3840, Loss function: 3.510, Average Loss: 3.794, avg. samples / sec: 52868.45
Iteration:   3840, Loss function: 3.232, Average Loss: 3.794, avg. samples / sec: 52727.37
Iteration:   3840, Loss function: 3.763, Average Loss: 3.800, avg. samples / sec: 52783.52
Iteration:   3840, Loss function: 3.567, Average Loss: 3.795, avg. samples / sec: 52742.03
Iteration:   3840, Loss function: 3.347, Average Loss: 3.757, avg. samples / sec: 52780.59
Iteration:   3840, Loss function: 3.085, Average Loss: 3.765, avg. samples / sec: 52728.75
Iteration:   3840, Loss function: 3.412, Average Loss: 3.764, avg. samples / sec: 52745.57
Iteration:   3840, Loss function: 3.503, Average Loss: 3.793, avg. samples / sec: 52725.28
Iteration:   3840, Loss function: 2.884, Average Loss: 3.763, avg. samples / sec: 52709.64
Iteration:   3840, Loss function: 3.741, Average Loss: 3.773, avg. samples / sec: 52705.84
Iteration:   3840, Loss function: 3.607, Average Loss: 3.813, avg. samples / sec: 52753.92
Iteration:   3840, Loss function: 2.762, Average Loss: 3.805, avg. samples / sec: 52681.23
Iteration:   3840, Loss function: 4.117, Average Loss: 3.763, avg. samples / sec: 52741.42
Iteration:   3840, Loss function: 3.442, Average Loss: 3.784, avg. samples / sec: 52863.01
Iteration:   3840, Loss function: 2.713, Average Loss: 3.767, avg. samples / sec: 52850.94
Iteration:   3840, Loss function: 4.018, Average Loss: 3.765, avg. samples / sec: 52851.67
Iteration:   3840, Loss function: 3.942, Average Loss: 3.772, avg. samples / sec: 52890.49
Iteration:   3840, Loss function: 2.107, Average Loss: 3.786, avg. samples / sec: 52819.40
Iteration:   3840, Loss function: 3.104, Average Loss: 3.803, avg. samples / sec: 52776.97
Iteration:   3840, Loss function: 4.097, Average Loss: 3.776, avg. samples / sec: 52776.94
Iteration:   3840, Loss function: 4.156, Average Loss: 3.762, avg. samples / sec: 52761.23
Iteration:   3840, Loss function: 4.024, Average Loss: 3.799, avg. samples / sec: 52752.52
Iteration:   3840, Loss function: 2.681, Average Loss: 3.793, avg. samples / sec: 52743.24
Iteration:   3840, Loss function: 3.775, Average Loss: 3.761, avg. samples / sec: 52720.53
Iteration:   3840, Loss function: 4.208, Average Loss: 3.764, avg. samples / sec: 52743.55
Iteration:   3840, Loss function: 2.865, Average Loss: 3.784, avg. samples / sec: 52756.25
Iteration:   3840, Loss function: 2.967, Average Loss: 3.811, avg. samples / sec: 52745.63
Iteration:   3860, Loss function: 4.012, Average Loss: 3.787, avg. samples / sec: 53399.18
Iteration:   3860, Loss function: 3.805, Average Loss: 3.763, avg. samples / sec: 53315.65
Iteration:   3860, Loss function: 3.393, Average Loss: 3.762, avg. samples / sec: 53457.07
Iteration:   3860, Loss function: 3.473, Average Loss: 3.784, avg. samples / sec: 53390.44
Iteration:   3860, Loss function: 3.766, Average Loss: 3.799, avg. samples / sec: 53453.57
Iteration:   3860, Loss function: 2.746, Average Loss: 3.759, avg. samples / sec: 53445.01
Iteration:   3860, Loss function: 3.008, Average Loss: 3.757, avg. samples / sec: 53387.45
Iteration:   3860, Loss function: 3.673, Average Loss: 3.750, avg. samples / sec: 53364.30
Iteration:   3860, Loss function: 4.052, Average Loss: 3.767, avg. samples / sec: 53211.39
Iteration:   3860, Loss function: 4.802, Average Loss: 3.775, avg. samples / sec: 53238.79
Iteration:   3860, Loss function: 2.755, Average Loss: 3.791, avg. samples / sec: 53256.68
Iteration:   3860, Loss function: 3.978, Average Loss: 3.759, avg. samples / sec: 53384.42
Iteration:   3860, Loss function: 2.783, Average Loss: 3.759, avg. samples / sec: 53331.57
Iteration:   3860, Loss function: 3.654, Average Loss: 3.791, avg. samples / sec: 53352.53
Iteration:   3860, Loss function: 2.872, Average Loss: 3.807, avg. samples / sec: 53365.09
Iteration:   3860, Loss function: 3.500, Average Loss: 3.794, avg. samples / sec: 53290.06
Iteration:   3860, Loss function: 3.095, Average Loss: 3.792, avg. samples / sec: 53371.56
Iteration:   3860, Loss function: 2.858, Average Loss: 3.764, avg. samples / sec: 53267.43
Iteration:   3860, Loss function: 4.455, Average Loss: 3.781, avg. samples / sec: 53404.81
Iteration:   3860, Loss function: 3.070, Average Loss: 3.786, avg. samples / sec: 53396.35
Iteration:   3860, Loss function: 4.269, Average Loss: 3.755, avg. samples / sec: 53376.39
Iteration:   3860, Loss function: 3.228, Average Loss: 3.774, avg. samples / sec: 53235.91
Iteration:   3860, Loss function: 3.312, Average Loss: 3.759, avg. samples / sec: 53384.48
Iteration:   3860, Loss function: 2.679, Average Loss: 3.756, avg. samples / sec: 53257.12
Iteration:   3860, Loss function: 3.110, Average Loss: 3.758, avg. samples / sec: 53380.13
Iteration:   3860, Loss function: 3.453, Average Loss: 3.770, avg. samples / sec: 53343.64
Iteration:   3860, Loss function: 3.611, Average Loss: 3.777, avg. samples / sec: 53267.47
Iteration:   3860, Loss function: 3.859, Average Loss: 3.765, avg. samples / sec: 53255.23
Iteration:   3860, Loss function: 3.257, Average Loss: 3.773, avg. samples / sec: 53357.09
Iteration:   3860, Loss function: 2.426, Average Loss: 3.807, avg. samples / sec: 53351.29
Iteration:   3880, Loss function: 3.214, Average Loss: 3.751, avg. samples / sec: 53534.69
Iteration:   3880, Loss function: 2.639, Average Loss: 3.756, avg. samples / sec: 53509.28
Iteration:   3880, Loss function: 3.164, Average Loss: 3.779, avg. samples / sec: 53505.34
Iteration:   3880, Loss function: 3.842, Average Loss: 3.764, avg. samples / sec: 53556.05
Iteration:   3880, Loss function: 3.862, Average Loss: 3.777, avg. samples / sec: 53483.81
Iteration:   3880, Loss function: 3.929, Average Loss: 3.784, avg. samples / sec: 53589.77
Iteration:   3880, Loss function: 3.941, Average Loss: 3.752, avg. samples / sec: 53510.17
Iteration:   3880, Loss function: 3.820, Average Loss: 3.748, avg. samples / sec: 53580.71
Iteration:   3880, Loss function: 2.643, Average Loss: 3.787, avg. samples / sec: 53492.20
Iteration:   3880, Loss function: 3.433, Average Loss: 3.742, avg. samples / sec: 53518.85
Iteration:   3880, Loss function: 3.993, Average Loss: 3.793, avg. samples / sec: 53574.62
Iteration:   3880, Loss function: 3.786, Average Loss: 3.752, avg. samples / sec: 53490.47
Iteration:   3880, Loss function: 3.400, Average Loss: 3.749, avg. samples / sec: 53595.05
Iteration:   3880, Loss function: 3.799, Average Loss: 3.787, avg. samples / sec: 53541.32
Iteration:   3880, Loss function: 2.814, Average Loss: 3.776, avg. samples / sec: 53552.83
Iteration:   3880, Loss function: 2.712, Average Loss: 3.771, avg. samples / sec: 53545.38
Iteration:   3880, Loss function: 2.909, Average Loss: 3.754, avg. samples / sec: 53539.04
Iteration:   3880, Loss function: 2.184, Average Loss: 3.746, avg. samples / sec: 53564.01
Iteration:   3880, Loss function: 5.203, Average Loss: 3.752, avg. samples / sec: 53550.92
Iteration:   3880, Loss function: 3.313, Average Loss: 3.781, avg. samples / sec: 53314.92
Iteration:   3880, Loss function: 2.777, Average Loss: 3.767, avg. samples / sec: 53312.10
Iteration:   3880, Loss function: 4.376, Average Loss: 3.760, avg. samples / sec: 53541.68
Iteration:   3880, Loss function: 3.245, Average Loss: 3.750, avg. samples / sec: 53509.60
Iteration:   3880, Loss function: 2.869, Average Loss: 3.798, avg. samples / sec: 53574.25
Iteration:   3880, Loss function: 2.428, Average Loss: 3.763, avg. samples / sec: 53551.81
Iteration:   3880, Loss function: 3.409, Average Loss: 3.768, avg. samples / sec: 53522.61
Iteration:   3880, Loss function: 2.241, Average Loss: 3.748, avg. samples / sec: 53292.79
Iteration:   3880, Loss function: 2.813, Average Loss: 3.755, avg. samples / sec: 53518.85
Iteration:   3880, Loss function: 3.297, Average Loss: 3.764, avg. samples / sec: 53464.37
Iteration:   3880, Loss function: 2.794, Average Loss: 3.784, avg. samples / sec: 53280.58
Iteration:   3900, Loss function: 2.700, Average Loss: 3.772, avg. samples / sec: 53651.81
Iteration:   3900, Loss function: 2.963, Average Loss: 3.746, avg. samples / sec: 53619.56
Iteration:   3900, Loss function: 2.926, Average Loss: 3.743, avg. samples / sec: 53581.30
Iteration:   3900, Loss function: 2.513, Average Loss: 3.772, avg. samples / sec: 53610.10
Iteration:   3900, Loss function: 2.035, Average Loss: 3.741, avg. samples / sec: 53638.30
Iteration:   3900, Loss function: 3.599, Average Loss: 3.741, avg. samples / sec: 53903.18
Iteration:   3900, Loss function: 2.539, Average Loss: 3.745, avg. samples / sec: 53629.25
Iteration:   3900, Loss function: 3.900, Average Loss: 3.776, avg. samples / sec: 53618.26
Iteration:   3900, Loss function: 3.227, Average Loss: 3.744, avg. samples / sec: 53644.20
Iteration:   3900, Loss function: 2.970, Average Loss: 3.783, avg. samples / sec: 53592.89
Iteration:   3900, Loss function: 4.298, Average Loss: 3.784, avg. samples / sec: 53577.63
Iteration:   3900, Loss function: 3.877, Average Loss: 3.735, avg. samples / sec: 53577.63
Iteration:   3900, Loss function: 3.453, Average Loss: 3.778, avg. samples / sec: 53859.07
Iteration:   3900, Loss function: 3.673, Average Loss: 3.757, avg. samples / sec: 53787.15
Iteration:   3900, Loss function: 2.458, Average Loss: 3.749, avg. samples / sec: 53720.06
Iteration:   3900, Loss function: 2.325, Average Loss: 3.775, avg. samples / sec: 53618.11
Iteration:   3900, Loss function: 2.645, Average Loss: 3.774, avg. samples / sec: 53644.83
Iteration:   3900, Loss function: 3.913, Average Loss: 3.752, avg. samples / sec: 53643.69
Iteration:   3900, Loss function: 2.403, Average Loss: 3.744, avg. samples / sec: 53624.91
Iteration:   3900, Loss function: 3.097, Average Loss: 3.744, avg. samples / sec: 53571.25
Iteration:   3900, Loss function: 3.758, Average Loss: 3.744, avg. samples / sec: 53640.09
Iteration:   3900, Loss function: 2.132, Average Loss: 3.762, avg. samples / sec: 53583.50
Iteration:   3900, Loss function: 3.301, Average Loss: 3.757, avg. samples / sec: 53367.25
Iteration:   3900, Loss function: 2.247, Average Loss: 3.766, avg. samples / sec: 53572.31
Iteration:   3900, Loss function: 2.825, Average Loss: 3.749, avg. samples / sec: 53669.67
Iteration:   3900, Loss function: 3.437, Average Loss: 3.743, avg. samples / sec: 53582.72
Iteration:   3900, Loss function: 3.677, Average Loss: 3.760, avg. samples / sec: 53623.64
Iteration:   3900, Loss function: 2.525, Average Loss: 3.756, avg. samples / sec: 53598.96
Iteration:   3900, Loss function: 3.822, Average Loss: 3.791, avg. samples / sec: 53590.49
Iteration:   3900, Loss function: 1.871, Average Loss: 3.743, avg. samples / sec: 53614.44
:::MLL 1558641237.159 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558641237.159 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 2.849, Average Loss: 3.740, avg. samples / sec: 53285.23
Iteration:   3920, Loss function: 3.605, Average Loss: 3.737, avg. samples / sec: 53305.95
Iteration:   3920, Loss function: 4.607, Average Loss: 3.729, avg. samples / sec: 53349.29
Iteration:   3920, Loss function: 3.034, Average Loss: 3.763, avg. samples / sec: 53245.87
Iteration:   3920, Loss function: 1.967, Average Loss: 3.732, avg. samples / sec: 53282.39
Iteration:   3920, Loss function: 2.681, Average Loss: 3.737, avg. samples / sec: 53282.33
Iteration:   3920, Loss function: 3.129, Average Loss: 3.769, avg. samples / sec: 53319.80
Iteration:   3920, Loss function: 3.040, Average Loss: 3.761, avg. samples / sec: 53235.69
Iteration:   3920, Loss function: 2.838, Average Loss: 3.731, avg. samples / sec: 53228.37
Iteration:   3920, Loss function: 4.905, Average Loss: 3.752, avg. samples / sec: 53306.73
Iteration:   3920, Loss function: 4.565, Average Loss: 3.778, avg. samples / sec: 53283.56
Iteration:   3920, Loss function: 2.437, Average Loss: 3.775, avg. samples / sec: 53264.28
Iteration:   3920, Loss function: 4.032, Average Loss: 3.767, avg. samples / sec: 53394.11
Iteration:   3920, Loss function: 3.253, Average Loss: 3.740, avg. samples / sec: 53179.04
Iteration:   3920, Loss function: 3.251, Average Loss: 3.772, avg. samples / sec: 53159.04
Iteration:   3920, Loss function: 2.779, Average Loss: 3.740, avg. samples / sec: 53286.06
Iteration:   3920, Loss function: 2.756, Average Loss: 3.742, avg. samples / sec: 53286.80
Iteration:   3920, Loss function: 2.503, Average Loss: 3.749, avg. samples / sec: 53300.73
Iteration:   3920, Loss function: 4.146, Average Loss: 3.743, avg. samples / sec: 53163.18
Iteration:   3920, Loss function: 3.250, Average Loss: 3.759, avg. samples / sec: 53301.78
Iteration:   3920, Loss function: 3.463, Average Loss: 3.737, avg. samples / sec: 53287.28
Iteration:   3920, Loss function: 3.341, Average Loss: 3.764, avg. samples / sec: 53245.81
Iteration:   3920, Loss function: 2.894, Average Loss: 3.748, avg. samples / sec: 53300.14
Iteration:   3920, Loss function: 2.928, Average Loss: 3.732, avg. samples / sec: 53266.78
Iteration:   3920, Loss function: 4.383, Average Loss: 3.746, avg. samples / sec: 53313.99
Iteration:   3920, Loss function: 3.996, Average Loss: 3.747, avg. samples / sec: 53279.00
Iteration:   3920, Loss function: 3.448, Average Loss: 3.754, avg. samples / sec: 53260.22
Iteration:   3920, Loss function: 2.544, Average Loss: 3.730, avg. samples / sec: 53284.08
Iteration:   3920, Loss function: 3.965, Average Loss: 3.787, avg. samples / sec: 53268.83
Iteration:   3920, Loss function: 2.846, Average Loss: 3.738, avg. samples / sec: 53228.25
Iteration:   3940, Loss function: 3.381, Average Loss: 3.734, avg. samples / sec: 53350.10
Iteration:   3940, Loss function: 3.005, Average Loss: 3.727, avg. samples / sec: 53321.20
Iteration:   3940, Loss function: 3.084, Average Loss: 3.755, avg. samples / sec: 53377.66
Iteration:   3940, Loss function: 3.196, Average Loss: 3.723, avg. samples / sec: 53317.48
Iteration:   3940, Loss function: 2.367, Average Loss: 3.732, avg. samples / sec: 53331.24
Iteration:   3940, Loss function: 4.076, Average Loss: 3.759, avg. samples / sec: 53326.42
Iteration:   3940, Loss function: 2.305, Average Loss: 3.770, avg. samples / sec: 53351.47
Iteration:   3940, Loss function: 3.642, Average Loss: 3.726, avg. samples / sec: 53278.20
Iteration:   3940, Loss function: 4.091, Average Loss: 3.763, avg. samples / sec: 53398.98
Iteration:   3940, Loss function: 4.052, Average Loss: 3.741, avg. samples / sec: 53318.11
Iteration:   3940, Loss function: 3.381, Average Loss: 3.731, avg. samples / sec: 53368.97
Iteration:   3940, Loss function: 2.598, Average Loss: 3.770, avg. samples / sec: 53306.57
Iteration:   3940, Loss function: 2.983, Average Loss: 3.758, avg. samples / sec: 53336.78
Iteration:   3940, Loss function: 3.004, Average Loss: 3.740, avg. samples / sec: 53358.81
Iteration:   3940, Loss function: 2.275, Average Loss: 3.731, avg. samples / sec: 53302.90
Iteration:   3940, Loss function: 3.202, Average Loss: 3.751, avg. samples / sec: 53311.39
Iteration:   3940, Loss function: 2.980, Average Loss: 3.740, avg. samples / sec: 53322.47
Iteration:   3940, Loss function: 3.472, Average Loss: 3.733, avg. samples / sec: 53301.15
Iteration:   3940, Loss function: 3.589, Average Loss: 3.730, avg. samples / sec: 53291.21
Iteration:   3940, Loss function: 4.227, Average Loss: 3.737, avg. samples / sec: 53305.44
Iteration:   3940, Loss function: 2.082, Average Loss: 3.753, avg. samples / sec: 53049.69
Iteration:   3940, Loss function: 2.881, Average Loss: 3.753, avg. samples / sec: 53290.00
Iteration:   3940, Loss function: 3.563, Average Loss: 3.735, avg. samples / sec: 53279.99
Iteration:   3940, Loss function: 2.869, Average Loss: 3.743, avg. samples / sec: 53265.94
Iteration:   3940, Loss function: 2.778, Average Loss: 3.721, avg. samples / sec: 53281.32
Iteration:   3940, Loss function: 3.307, Average Loss: 3.781, avg. samples / sec: 53312.54
Iteration:   3940, Loss function: 2.957, Average Loss: 3.722, avg. samples / sec: 53297.20
Iteration:   3940, Loss function: 4.020, Average Loss: 3.744, avg. samples / sec: 53263.10
Iteration:   3940, Loss function: 2.867, Average Loss: 3.723, avg. samples / sec: 53048.79
Iteration:   3940, Loss function: 2.586, Average Loss: 3.731, avg. samples / sec: 53311.64
Iteration:   3960, Loss function: 3.502, Average Loss: 3.720, avg. samples / sec: 53171.72
Iteration:   3960, Loss function: 2.754, Average Loss: 3.715, avg. samples / sec: 53184.92
Iteration:   3960, Loss function: 2.967, Average Loss: 3.723, avg. samples / sec: 53121.95
Iteration:   3960, Loss function: 4.144, Average Loss: 3.737, avg. samples / sec: 53227.83
Iteration:   3960, Loss function: 3.215, Average Loss: 3.720, avg. samples / sec: 53210.19
Iteration:   3960, Loss function: 3.457, Average Loss: 3.715, avg. samples / sec: 53487.71
Iteration:   3960, Loss function: 4.069, Average Loss: 3.756, avg. samples / sec: 53191.81
Iteration:   3960, Loss function: 3.642, Average Loss: 3.751, avg. samples / sec: 53131.05
Iteration:   3960, Loss function: 3.261, Average Loss: 3.746, avg. samples / sec: 53402.91
Iteration:   3960, Loss function: 3.406, Average Loss: 3.760, avg. samples / sec: 53206.27
Iteration:   3960, Loss function: 3.471, Average Loss: 3.752, avg. samples / sec: 53158.24
Iteration:   3960, Loss function: 3.094, Average Loss: 3.723, avg. samples / sec: 53143.03
Iteration:   3960, Loss function: 2.857, Average Loss: 3.755, avg. samples / sec: 53211.13
Iteration:   3960, Loss function: 2.581, Average Loss: 3.716, avg. samples / sec: 53170.58
Iteration:   3960, Loss function: 2.875, Average Loss: 3.760, avg. samples / sec: 53145.97
Iteration:   3960, Loss function: 4.293, Average Loss: 3.747, avg. samples / sec: 53253.66
Iteration:   3960, Loss function: 4.218, Average Loss: 3.738, avg. samples / sec: 53193.32
Iteration:   3960, Loss function: 2.365, Average Loss: 3.727, avg. samples / sec: 53208.64
Iteration:   3960, Loss function: 3.483, Average Loss: 3.712, avg. samples / sec: 53245.75
Iteration:   3960, Loss function: 3.798, Average Loss: 3.733, avg. samples / sec: 53227.83
Iteration:   3960, Loss function: 3.170, Average Loss: 3.725, avg. samples / sec: 53193.15
Iteration:   3960, Loss function: 2.709, Average Loss: 3.737, avg. samples / sec: 53172.44
Iteration:   3960, Loss function: 3.977, Average Loss: 3.727, avg. samples / sec: 53205.12
Iteration:   3960, Loss function: 4.386, Average Loss: 3.725, avg. samples / sec: 53185.39
Iteration:   3960, Loss function: 3.369, Average Loss: 3.728, avg. samples / sec: 53163.22
Iteration:   3960, Loss function: 2.902, Average Loss: 3.727, avg. samples / sec: 53192.79
Iteration:   3960, Loss function: 3.146, Average Loss: 3.736, avg. samples / sec: 53240.00
Iteration:   3960, Loss function: 2.589, Average Loss: 3.713, avg. samples / sec: 53219.23
Iteration:   3960, Loss function: 3.175, Average Loss: 3.765, avg. samples / sec: 53203.03
Iteration:   3960, Loss function: 2.775, Average Loss: 3.724, avg. samples / sec: 53218.22
:::MLL 1558641239.367 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558641239.368 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 2.694, Average Loss: 3.714, avg. samples / sec: 53264.93
Iteration:   3980, Loss function: 4.011, Average Loss: 3.733, avg. samples / sec: 53225.16
Iteration:   3980, Loss function: 2.439, Average Loss: 3.747, avg. samples / sec: 53260.72
Iteration:   3980, Loss function: 4.449, Average Loss: 3.744, avg. samples / sec: 53211.51
Iteration:   3980, Loss function: 3.429, Average Loss: 3.754, avg. samples / sec: 53229.68
Iteration:   3980, Loss function: 3.549, Average Loss: 3.741, avg. samples / sec: 53192.83
Iteration:   3980, Loss function: 3.545, Average Loss: 3.705, avg. samples / sec: 53129.42
Iteration:   3980, Loss function: 3.075, Average Loss: 3.713, avg. samples / sec: 53115.85
Iteration:   3980, Loss function: 2.478, Average Loss: 3.746, avg. samples / sec: 53167.37
Iteration:   3980, Loss function: 3.599, Average Loss: 3.712, avg. samples / sec: 53136.02
Iteration:   3980, Loss function: 1.535, Average Loss: 3.712, avg. samples / sec: 53122.50
Iteration:   3980, Loss function: 3.604, Average Loss: 3.753, avg. samples / sec: 53155.17
Iteration:   3980, Loss function: 3.197, Average Loss: 3.743, avg. samples / sec: 53145.89
Iteration:   3980, Loss function: 3.497, Average Loss: 3.711, avg. samples / sec: 53139.28
Iteration:   3980, Loss function: 2.581, Average Loss: 3.707, avg. samples / sec: 53152.65
Iteration:   3980, Loss function: 3.955, Average Loss: 3.706, avg. samples / sec: 53295.02
Iteration:   3980, Loss function: 2.629, Average Loss: 3.717, avg. samples / sec: 53250.34
Iteration:   3980, Loss function: 3.485, Average Loss: 3.706, avg. samples / sec: 53225.38
Iteration:   3980, Loss function: 2.931, Average Loss: 3.732, avg. samples / sec: 53170.14
Iteration:   3980, Loss function: 2.328, Average Loss: 3.727, avg. samples / sec: 53170.78
Iteration:   3980, Loss function: 4.200, Average Loss: 3.729, avg. samples / sec: 53178.54
Iteration:   3980, Loss function: 3.155, Average Loss: 3.736, avg. samples / sec: 53117.97
Iteration:   3980, Loss function: 3.276, Average Loss: 3.725, avg. samples / sec: 53176.21
Iteration:   3980, Loss function: 2.853, Average Loss: 3.723, avg. samples / sec: 53154.15
Iteration:   3980, Loss function: 4.400, Average Loss: 3.719, avg. samples / sec: 53114.81
Iteration:   3980, Loss function: 3.053, Average Loss: 3.721, avg. samples / sec: 53178.02
Iteration:   3980, Loss function: 3.138, Average Loss: 3.721, avg. samples / sec: 53126.04
Iteration:   3980, Loss function: 2.984, Average Loss: 3.751, avg. samples / sec: 53145.49
Iteration:   3980, Loss function: 3.983, Average Loss: 3.720, avg. samples / sec: 53084.52
Iteration:   3980, Loss function: 4.440, Average Loss: 3.726, avg. samples / sec: 53098.76
Iteration:   4000, Loss function: 3.293, Average Loss: 3.705, avg. samples / sec: 53661.15
Iteration:   4000, Loss function: 4.174, Average Loss: 3.704, avg. samples / sec: 53500.95
Iteration:   4000, Loss function: 2.247, Average Loss: 3.705, avg. samples / sec: 53600.04
Iteration:   4000, Loss function: 4.107, Average Loss: 3.698, avg. samples / sec: 53597.66
Iteration:   4000, Loss function: 2.746, Average Loss: 3.733, avg. samples / sec: 53582.52
Iteration:   4000, Loss function: 5.039, Average Loss: 3.730, avg. samples / sec: 53495.38
Iteration:   4000, Loss function: 3.788, Average Loss: 3.748, avg. samples / sec: 53608.98
Iteration:   4000, Loss function: 2.666, Average Loss: 3.695, avg. samples / sec: 53616.44
Iteration:   4000, Loss function: 3.748, Average Loss: 3.740, avg. samples / sec: 53513.42
Iteration:   4000, Loss function: 3.001, Average Loss: 3.735, avg. samples / sec: 53583.54
Iteration:   4000, Loss function: 2.982, Average Loss: 3.741, avg. samples / sec: 53548.15
Iteration:   4000, Loss function: 2.876, Average Loss: 3.705, avg. samples / sec: 53545.87
Iteration:   4000, Loss function: 2.698, Average Loss: 3.706, avg. samples / sec: 53576.73
Iteration:   4000, Loss function: 3.158, Average Loss: 3.737, avg. samples / sec: 53462.26
Iteration:   4000, Loss function: 3.593, Average Loss: 3.748, avg. samples / sec: 53501.96
Iteration:   4000, Loss function: 3.412, Average Loss: 3.701, avg. samples / sec: 53506.13
Iteration:   4000, Loss function: 3.072, Average Loss: 3.725, avg. samples / sec: 53588.14
Iteration:   4000, Loss function: 3.221, Average Loss: 3.718, avg. samples / sec: 53573.15
Iteration:   4000, Loss function: 3.824, Average Loss: 3.719, avg. samples / sec: 53601.43
Iteration:   4000, Loss function: 3.030, Average Loss: 3.718, avg. samples / sec: 53583.58
Iteration:   4000, Loss function: 4.037, Average Loss: 3.722, avg. samples / sec: 53642.22
Iteration:   4000, Loss function: 3.039, Average Loss: 3.706, avg. samples / sec: 53586.33
Iteration:   4000, Loss function: 3.836, Average Loss: 3.709, avg. samples / sec: 53479.85
Iteration:   4000, Loss function: 3.406, Average Loss: 3.714, avg. samples / sec: 53612.81
Iteration:   4000, Loss function: 3.751, Average Loss: 3.720, avg. samples / sec: 53548.68
Iteration:   4000, Loss function: 3.927, Average Loss: 3.728, avg. samples / sec: 53520.29
Iteration:   4000, Loss function: 4.255, Average Loss: 3.714, avg. samples / sec: 53590.34
Iteration:   4000, Loss function: 3.140, Average Loss: 3.740, avg. samples / sec: 53599.01
Iteration:   4000, Loss function: 3.000, Average Loss: 3.699, avg. samples / sec: 53494.19
Iteration:   4000, Loss function: 3.154, Average Loss: 3.718, avg. samples / sec: 53590.36
Iteration:   4020, Loss function: 4.061, Average Loss: 3.731, avg. samples / sec: 53632.74
Iteration:   4020, Loss function: 2.757, Average Loss: 3.696, avg. samples / sec: 53539.97
Iteration:   4020, Loss function: 3.644, Average Loss: 3.728, avg. samples / sec: 53524.89
Iteration:   4020, Loss function: 3.324, Average Loss: 3.692, avg. samples / sec: 53502.92
Iteration:   4020, Loss function: 3.271, Average Loss: 3.689, avg. samples / sec: 53549.51
Iteration:   4020, Loss function: 3.243, Average Loss: 3.696, avg. samples / sec: 53486.39
Iteration:   4020, Loss function: 3.385, Average Loss: 3.733, avg. samples / sec: 53543.88
Iteration:   4020, Loss function: 4.477, Average Loss: 3.703, avg. samples / sec: 53531.74
Iteration:   4020, Loss function: 3.779, Average Loss: 3.739, avg. samples / sec: 53476.79
Iteration:   4020, Loss function: 3.038, Average Loss: 3.701, avg. samples / sec: 53505.66
Iteration:   4020, Loss function: 3.727, Average Loss: 3.692, avg. samples / sec: 53571.64
Iteration:   4020, Loss function: 2.799, Average Loss: 3.738, avg. samples / sec: 53486.13
Iteration:   4020, Loss function: 3.649, Average Loss: 3.715, avg. samples / sec: 53579.40
Iteration:   4020, Loss function: 3.251, Average Loss: 3.699, avg. samples / sec: 53559.65
Iteration:   4020, Loss function: 3.627, Average Loss: 3.732, avg. samples / sec: 53354.46
Iteration:   4020, Loss function: 2.695, Average Loss: 3.712, avg. samples / sec: 53523.40
Iteration:   4020, Loss function: 3.876, Average Loss: 3.718, avg. samples / sec: 53500.60
Iteration:   4020, Loss function: 3.470, Average Loss: 3.712, avg. samples / sec: 53520.51
Iteration:   4020, Loss function: 3.027, Average Loss: 3.712, avg. samples / sec: 53492.52
Iteration:   4020, Loss function: 3.046, Average Loss: 3.700, avg. samples / sec: 53500.77
Iteration:   4020, Loss function: 2.989, Average Loss: 3.718, avg. samples / sec: 53473.40
Iteration:   4020, Loss function: 3.607, Average Loss: 3.696, avg. samples / sec: 53202.81
Iteration:   4020, Loss function: 4.039, Average Loss: 3.713, avg. samples / sec: 53491.28
Iteration:   4020, Loss function: 3.113, Average Loss: 3.708, avg. samples / sec: 53486.47
Iteration:   4020, Loss function: 3.600, Average Loss: 3.722, avg. samples / sec: 53246.74
Iteration:   4020, Loss function: 2.810, Average Loss: 3.734, avg. samples / sec: 53504.87
Iteration:   4020, Loss function: 3.193, Average Loss: 3.723, avg. samples / sec: 53477.48
Iteration:   4020, Loss function: 3.803, Average Loss: 3.715, avg. samples / sec: 53522.99
Iteration:   4020, Loss function: 3.314, Average Loss: 3.691, avg. samples / sec: 53495.42
Iteration:   4020, Loss function: 3.915, Average Loss: 3.729, avg. samples / sec: 53250.34
Iteration:   4040, Loss function: 2.849, Average Loss: 3.720, avg. samples / sec: 53735.36
Iteration:   4040, Loss function: 4.356, Average Loss: 3.730, avg. samples / sec: 53646.79
Iteration:   4040, Loss function: 3.161, Average Loss: 3.689, avg. samples / sec: 53660.33
Iteration:   4040, Loss function: 3.296, Average Loss: 3.694, avg. samples / sec: 53733.19
Iteration:   4040, Loss function: 3.025, Average Loss: 3.687, avg. samples / sec: 53683.43
Iteration:   4040, Loss function: 3.959, Average Loss: 3.712, avg. samples / sec: 53960.51
Iteration:   4040, Loss function: 2.333, Average Loss: 3.680, avg. samples / sec: 53677.09
Iteration:   4040, Loss function: 3.221, Average Loss: 3.700, avg. samples / sec: 53732.14
Iteration:   4040, Loss function: 4.672, Average Loss: 3.689, avg. samples / sec: 53744.40
Iteration:   4040, Loss function: 2.677, Average Loss: 3.692, avg. samples / sec: 53662.93
Iteration:   4040, Loss function: 3.695, Average Loss: 3.725, avg. samples / sec: 53658.76
Iteration:   4040, Loss function: 2.683, Average Loss: 3.722, avg. samples / sec: 53861.56
Iteration:   4040, Loss function: 2.899, Average Loss: 3.718, avg. samples / sec: 53938.25
Iteration:   4040, Loss function: 2.926, Average Loss: 3.733, avg. samples / sec: 53619.36
Iteration:   4040, Loss function: 3.357, Average Loss: 3.735, avg. samples / sec: 53564.19
Iteration:   4040, Loss function: 3.936, Average Loss: 3.710, avg. samples / sec: 53741.53
Iteration:   4040, Loss function: 2.934, Average Loss: 3.708, avg. samples / sec: 53741.32
Iteration:   4040, Loss function: 2.799, Average Loss: 3.706, avg. samples / sec: 53665.83
Iteration:   4040, Loss function: 3.405, Average Loss: 3.699, avg. samples / sec: 53692.14
Iteration:   4040, Loss function: 3.646, Average Loss: 3.692, avg. samples / sec: 53742.43
Iteration:   4040, Loss function: 4.936, Average Loss: 3.706, avg. samples / sec: 53753.36
Iteration:   4040, Loss function: 3.654, Average Loss: 3.724, avg. samples / sec: 53746.45
Iteration:   4040, Loss function: 2.968, Average Loss: 3.708, avg. samples / sec: 53724.69
Iteration:   4040, Loss function: 3.386, Average Loss: 3.709, avg. samples / sec: 53680.28
Iteration:   4040, Loss function: 3.366, Average Loss: 3.701, avg. samples / sec: 53738.45
Iteration:   4040, Loss function: 3.107, Average Loss: 3.703, avg. samples / sec: 53699.51
Iteration:   4040, Loss function: 2.798, Average Loss: 3.680, avg. samples / sec: 53724.91
Iteration:   4040, Loss function: 3.420, Average Loss: 3.721, avg. samples / sec: 53717.71
Iteration:   4040, Loss function: 3.208, Average Loss: 3.708, avg. samples / sec: 53690.43
Iteration:   4040, Loss function: 3.999, Average Loss: 3.688, avg. samples / sec: 53668.32
:::MLL 1558641241.566 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558641241.567 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 2.806, Average Loss: 3.678, avg. samples / sec: 53249.55
Iteration:   4060, Loss function: 2.779, Average Loss: 3.715, avg. samples / sec: 53207.59
Iteration:   4060, Loss function: 3.046, Average Loss: 3.724, avg. samples / sec: 53208.68
Iteration:   4060, Loss function: 2.018, Average Loss: 3.727, avg. samples / sec: 53402.81
Iteration:   4060, Loss function: 3.686, Average Loss: 3.701, avg. samples / sec: 53230.06
Iteration:   4060, Loss function: 2.842, Average Loss: 3.683, avg. samples / sec: 53260.84
Iteration:   4060, Loss function: 3.745, Average Loss: 3.684, avg. samples / sec: 53221.84
Iteration:   4060, Loss function: 3.904, Average Loss: 3.717, avg. samples / sec: 53262.29
Iteration:   4060, Loss function: 2.926, Average Loss: 3.677, avg. samples / sec: 53239.96
Iteration:   4060, Loss function: 3.642, Average Loss: 3.715, avg. samples / sec: 53236.74
Iteration:   4060, Loss function: 4.443, Average Loss: 3.713, avg. samples / sec: 53251.20
Iteration:   4060, Loss function: 3.796, Average Loss: 3.696, avg. samples / sec: 53204.70
Iteration:   4060, Loss function: 4.049, Average Loss: 3.729, avg. samples / sec: 53340.27
Iteration:   4060, Loss function: 3.042, Average Loss: 3.676, avg. samples / sec: 53187.01
Iteration:   4060, Loss function: 3.716, Average Loss: 3.685, avg. samples / sec: 53152.21
Iteration:   4060, Loss function: 2.937, Average Loss: 3.703, avg. samples / sec: 53249.95
Iteration:   4060, Loss function: 3.789, Average Loss: 3.694, avg. samples / sec: 53215.65
Iteration:   4060, Loss function: 3.609, Average Loss: 3.700, avg. samples / sec: 53194.14
Iteration:   4060, Loss function: 3.190, Average Loss: 3.698, avg. samples / sec: 53196.71
Iteration:   4060, Loss function: 3.621, Average Loss: 3.699, avg. samples / sec: 53225.26
Iteration:   4060, Loss function: 4.044, Average Loss: 3.703, avg. samples / sec: 53189.30
Iteration:   4060, Loss function: 3.300, Average Loss: 3.685, avg. samples / sec: 53181.61
Iteration:   4060, Loss function: 3.648, Average Loss: 3.703, avg. samples / sec: 53192.67
Iteration:   4060, Loss function: 3.279, Average Loss: 3.691, avg. samples / sec: 53200.06
Iteration:   4060, Loss function: 2.544, Average Loss: 3.697, avg. samples / sec: 53203.01
Iteration:   4060, Loss function: 3.590, Average Loss: 3.715, avg. samples / sec: 53220.21
Iteration:   4060, Loss function: 2.881, Average Loss: 3.715, avg. samples / sec: 53178.44
Iteration:   4060, Loss function: 2.903, Average Loss: 3.674, avg. samples / sec: 53207.76
Iteration:   4060, Loss function: 2.325, Average Loss: 3.677, avg. samples / sec: 53226.22
Iteration:   4060, Loss function: 4.191, Average Loss: 3.704, avg. samples / sec: 53196.97
Iteration:   4080, Loss function: 2.240, Average Loss: 3.706, avg. samples / sec: 53744.73
Iteration:   4080, Loss function: 3.523, Average Loss: 3.687, avg. samples / sec: 53789.65
Iteration:   4080, Loss function: 2.447, Average Loss: 3.679, avg. samples / sec: 53750.08
Iteration:   4080, Loss function: 4.010, Average Loss: 3.679, avg. samples / sec: 53731.96
Iteration:   4080, Loss function: 2.975, Average Loss: 3.693, avg. samples / sec: 53712.28
Iteration:   4080, Loss function: 4.947, Average Loss: 3.673, avg. samples / sec: 53716.89
Iteration:   4080, Loss function: 4.088, Average Loss: 3.711, avg. samples / sec: 53737.98
Iteration:   4080, Loss function: 3.363, Average Loss: 3.668, avg. samples / sec: 53746.06
Iteration:   4080, Loss function: 3.600, Average Loss: 3.701, avg. samples / sec: 53719.32
Iteration:   4080, Loss function: 2.511, Average Loss: 3.715, avg. samples / sec: 53645.85
Iteration:   4080, Loss function: 3.116, Average Loss: 3.707, avg. samples / sec: 53646.83
Iteration:   4080, Loss function: 3.568, Average Loss: 3.673, avg. samples / sec: 53575.45
Iteration:   4080, Loss function: 3.519, Average Loss: 3.724, avg. samples / sec: 53679.01
Iteration:   4080, Loss function: 1.966, Average Loss: 3.693, avg. samples / sec: 53774.69
Iteration:   4080, Loss function: 4.260, Average Loss: 3.698, avg. samples / sec: 53813.50
Iteration:   4080, Loss function: 3.511, Average Loss: 3.691, avg. samples / sec: 53740.93
Iteration:   4080, Loss function: 2.610, Average Loss: 3.691, avg. samples / sec: 53764.68
Iteration:   4080, Loss function: 4.267, Average Loss: 3.709, avg. samples / sec: 53750.04
Iteration:   4080, Loss function: 3.004, Average Loss: 3.689, avg. samples / sec: 53704.58
Iteration:   4080, Loss function: 2.780, Average Loss: 3.688, avg. samples / sec: 53685.60
Iteration:   4080, Loss function: 3.275, Average Loss: 3.695, avg. samples / sec: 53685.13
Iteration:   4080, Loss function: 3.136, Average Loss: 3.712, avg. samples / sec: 53446.27
Iteration:   4080, Loss function: 2.140, Average Loss: 3.695, avg. samples / sec: 53727.68
Iteration:   4080, Loss function: 3.261, Average Loss: 3.710, avg. samples / sec: 53738.74
Iteration:   4080, Loss function: 2.855, Average Loss: 3.667, avg. samples / sec: 53732.92
Iteration:   4080, Loss function: 2.764, Average Loss: 3.695, avg. samples / sec: 53687.79
Iteration:   4080, Loss function: 3.816, Average Loss: 3.670, avg. samples / sec: 53732.90
Iteration:   4080, Loss function: 3.388, Average Loss: 3.673, avg. samples / sec: 53695.50
Iteration:   4080, Loss function: 3.316, Average Loss: 3.684, avg. samples / sec: 53695.33
Iteration:   4080, Loss function: 2.599, Average Loss: 3.678, avg. samples / sec: 53477.16
Iteration:   4100, Loss function: 3.403, Average Loss: 3.700, avg. samples / sec: 53630.07
Iteration:   4100, Loss function: 3.732, Average Loss: 3.706, avg. samples / sec: 53949.60
Iteration:   4100, Loss function: 3.852, Average Loss: 3.680, avg. samples / sec: 53643.01
Iteration:   4100, Loss function: 2.975, Average Loss: 3.665, avg. samples / sec: 53759.73
Iteration:   4100, Loss function: 2.880, Average Loss: 3.676, avg. samples / sec: 53653.71
Iteration:   4100, Loss function: 3.630, Average Loss: 3.703, avg. samples / sec: 53722.05
Iteration:   4100, Loss function: 4.814, Average Loss: 3.717, avg. samples / sec: 53741.82
Iteration:   4100, Loss function: 3.154, Average Loss: 3.706, avg. samples / sec: 53731.57
Iteration:   4100, Loss function: 4.077, Average Loss: 3.684, avg. samples / sec: 53649.63
Iteration:   4100, Loss function: 3.060, Average Loss: 3.670, avg. samples / sec: 53645.42
Iteration:   4100, Loss function: 4.132, Average Loss: 3.701, avg. samples / sec: 53624.07
Iteration:   4100, Loss function: 2.578, Average Loss: 3.667, avg. samples / sec: 53919.41
Iteration:   4100, Loss function: 2.972, Average Loss: 3.665, avg. samples / sec: 53629.62
Iteration:   4100, Loss function: 4.688, Average Loss: 3.677, avg. samples / sec: 53567.35
Iteration:   4100, Loss function: 2.701, Average Loss: 3.694, avg. samples / sec: 53494.75
Iteration:   4100, Loss function: 3.520, Average Loss: 3.682, avg. samples / sec: 53705.52
Iteration:   4100, Loss function: 3.457, Average Loss: 3.677, avg. samples / sec: 53680.08
Iteration:   4100, Loss function: 4.198, Average Loss: 3.683, avg. samples / sec: 53648.77
Iteration:   4100, Loss function: 2.577, Average Loss: 3.688, avg. samples / sec: 53597.27
Iteration:   4100, Loss function: 3.174, Average Loss: 3.705, avg. samples / sec: 53672.27
Iteration:   4100, Loss function: 3.747, Average Loss: 3.688, avg. samples / sec: 53701.90
Iteration:   4100, Loss function: 2.453, Average Loss: 3.685, avg. samples / sec: 53630.54
Iteration:   4100, Loss function: 2.712, Average Loss: 3.684, avg. samples / sec: 53666.77
Iteration:   4100, Loss function: 3.389, Average Loss: 3.687, avg. samples / sec: 53667.26
Iteration:   4100, Loss function: 3.606, Average Loss: 3.705, avg. samples / sec: 53648.32
Iteration:   4100, Loss function: 3.237, Average Loss: 3.678, avg. samples / sec: 53696.19
Iteration:   4100, Loss function: 3.722, Average Loss: 3.693, avg. samples / sec: 53587.00
Iteration:   4100, Loss function: 3.972, Average Loss: 3.669, avg. samples / sec: 53638.56
Iteration:   4100, Loss function: 2.763, Average Loss: 3.659, avg. samples / sec: 53622.27
Iteration:   4100, Loss function: 3.248, Average Loss: 3.663, avg. samples / sec: 53531.82
:::MLL 1558641243.763 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558641243.764 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 3.891, Average Loss: 3.699, avg. samples / sec: 53340.33
Iteration:   4120, Loss function: 3.491, Average Loss: 3.652, avg. samples / sec: 53208.86
Iteration:   4120, Loss function: 3.539, Average Loss: 3.677, avg. samples / sec: 53234.49
Iteration:   4120, Loss function: 4.490, Average Loss: 3.659, avg. samples / sec: 53267.06
Iteration:   4120, Loss function: 3.149, Average Loss: 3.691, avg. samples / sec: 53154.75
Iteration:   4120, Loss function: 2.647, Average Loss: 3.697, avg. samples / sec: 53173.99
Iteration:   4120, Loss function: 3.152, Average Loss: 3.670, avg. samples / sec: 53227.19
Iteration:   4120, Loss function: 2.914, Average Loss: 3.702, avg. samples / sec: 53129.77
Iteration:   4120, Loss function: 3.593, Average Loss: 3.667, avg. samples / sec: 53202.09
Iteration:   4120, Loss function: 3.680, Average Loss: 3.709, avg. samples / sec: 53132.81
Iteration:   4120, Loss function: 3.056, Average Loss: 3.667, avg. samples / sec: 53137.84
Iteration:   4120, Loss function: 4.716, Average Loss: 3.704, avg. samples / sec: 53106.76
Iteration:   4120, Loss function: 3.087, Average Loss: 3.674, avg. samples / sec: 53074.90
Iteration:   4120, Loss function: 3.272, Average Loss: 3.676, avg. samples / sec: 53245.37
Iteration:   4120, Loss function: 3.409, Average Loss: 3.703, avg. samples / sec: 53263.48
Iteration:   4120, Loss function: 2.126, Average Loss: 3.660, avg. samples / sec: 53419.24
Iteration:   4120, Loss function: 3.403, Average Loss: 3.650, avg. samples / sec: 53290.93
Iteration:   4120, Loss function: 3.429, Average Loss: 3.676, avg. samples / sec: 53210.49
Iteration:   4120, Loss function: 3.791, Average Loss: 3.669, avg. samples / sec: 52947.94
Iteration:   4120, Loss function: 3.634, Average Loss: 3.681, avg. samples / sec: 53193.42
Iteration:   4120, Loss function: 3.749, Average Loss: 3.681, avg. samples / sec: 53171.30
Iteration:   4120, Loss function: 3.876, Average Loss: 3.667, avg. samples / sec: 53164.12
Iteration:   4120, Loss function: 2.740, Average Loss: 3.690, avg. samples / sec: 53137.60
Iteration:   4120, Loss function: 2.857, Average Loss: 3.701, avg. samples / sec: 53177.76
Iteration:   4120, Loss function: 3.330, Average Loss: 3.680, avg. samples / sec: 53168.25
Iteration:   4120, Loss function: 3.973, Average Loss: 3.666, avg. samples / sec: 53183.78
Iteration:   4120, Loss function: 2.841, Average Loss: 3.664, avg. samples / sec: 53224.66
Iteration:   4120, Loss function: 2.532, Average Loss: 3.678, avg. samples / sec: 53154.61
Iteration:   4120, Loss function: 2.834, Average Loss: 3.677, avg. samples / sec: 53143.89
Iteration:   4120, Loss function: 3.065, Average Loss: 3.688, avg. samples / sec: 53164.06
Iteration:   4140, Loss function: 3.886, Average Loss: 3.658, avg. samples / sec: 53400.80
Iteration:   4140, Loss function: 4.696, Average Loss: 3.685, avg. samples / sec: 53238.81
Iteration:   4140, Loss function: 2.885, Average Loss: 3.695, avg. samples / sec: 53249.47
Iteration:   4140, Loss function: 4.000, Average Loss: 3.653, avg. samples / sec: 53185.77
Iteration:   4140, Loss function: 3.314, Average Loss: 3.666, avg. samples / sec: 53213.22
Iteration:   4140, Loss function: 3.787, Average Loss: 3.695, avg. samples / sec: 53207.45
Iteration:   4140, Loss function: 3.451, Average Loss: 3.695, avg. samples / sec: 53265.65
Iteration:   4140, Loss function: 3.555, Average Loss: 3.654, avg. samples / sec: 53255.25
Iteration:   4140, Loss function: 2.571, Average Loss: 3.670, avg. samples / sec: 53144.29
Iteration:   4140, Loss function: 2.737, Average Loss: 3.667, avg. samples / sec: 53269.44
Iteration:   4140, Loss function: 2.549, Average Loss: 3.696, avg. samples / sec: 53065.41
Iteration:   4140, Loss function: 2.636, Average Loss: 3.653, avg. samples / sec: 53141.95
Iteration:   4140, Loss function: 2.752, Average Loss: 3.700, avg. samples / sec: 53192.61
Iteration:   4140, Loss function: 3.462, Average Loss: 3.680, avg. samples / sec: 53257.36
Iteration:   4140, Loss function: 3.026, Average Loss: 3.655, avg. samples / sec: 53257.18
Iteration:   4140, Loss function: 2.656, Average Loss: 3.672, avg. samples / sec: 53231.23
Iteration:   4140, Loss function: 4.205, Average Loss: 3.680, avg. samples / sec: 53233.06
Iteration:   4140, Loss function: 2.691, Average Loss: 3.666, avg. samples / sec: 53198.88
Iteration:   4140, Loss function: 3.225, Average Loss: 3.656, avg. samples / sec: 53222.18
Iteration:   4140, Loss function: 3.343, Average Loss: 3.666, avg. samples / sec: 53124.56
Iteration:   4140, Loss function: 3.116, Average Loss: 3.700, avg. samples / sec: 53135.79
Iteration:   4140, Loss function: 3.921, Average Loss: 3.671, avg. samples / sec: 53248.12
Iteration:   4140, Loss function: 2.901, Average Loss: 3.658, avg. samples / sec: 53191.17
Iteration:   4140, Loss function: 2.701, Average Loss: 3.690, avg. samples / sec: 53200.91
Iteration:   4140, Loss function: 4.704, Average Loss: 3.681, avg. samples / sec: 53254.99
Iteration:   4140, Loss function: 4.811, Average Loss: 3.671, avg. samples / sec: 53173.19
Iteration:   4140, Loss function: 2.963, Average Loss: 3.643, avg. samples / sec: 53127.92
Iteration:   4140, Loss function: 3.412, Average Loss: 3.654, avg. samples / sec: 53099.24
Iteration:   4140, Loss function: 4.155, Average Loss: 3.668, avg. samples / sec: 53204.18
Iteration:   4140, Loss function: 2.924, Average Loss: 3.657, avg. samples / sec: 53182.09
Iteration:   4160, Loss function: 3.810, Average Loss: 3.658, avg. samples / sec: 53613.91
Iteration:   4160, Loss function: 3.206, Average Loss: 3.680, avg. samples / sec: 53621.03
Iteration:   4160, Loss function: 4.496, Average Loss: 3.648, avg. samples / sec: 53689.28
Iteration:   4160, Loss function: 4.072, Average Loss: 3.689, avg. samples / sec: 53622.64
Iteration:   4160, Loss function: 5.037, Average Loss: 3.655, avg. samples / sec: 53637.79
Iteration:   4160, Loss function: 3.424, Average Loss: 3.649, avg. samples / sec: 53613.32
Iteration:   4160, Loss function: 3.220, Average Loss: 3.649, avg. samples / sec: 53634.09
Iteration:   4160, Loss function: 3.838, Average Loss: 3.691, avg. samples / sec: 53608.08
Iteration:   4160, Loss function: 3.398, Average Loss: 3.659, avg. samples / sec: 53623.11
Iteration:   4160, Loss function: 3.502, Average Loss: 3.659, avg. samples / sec: 53828.46
Iteration:   4160, Loss function: 2.986, Average Loss: 3.691, avg. samples / sec: 53641.75
Iteration:   4160, Loss function: 3.402, Average Loss: 3.687, avg. samples / sec: 53581.74
Iteration:   4160, Loss function: 3.761, Average Loss: 3.660, avg. samples / sec: 53654.47
Iteration:   4160, Loss function: 2.785, Average Loss: 3.665, avg. samples / sec: 53644.52
Iteration:   4160, Loss function: 3.497, Average Loss: 3.665, avg. samples / sec: 53676.48
Iteration:   4160, Loss function: 3.144, Average Loss: 3.671, avg. samples / sec: 53603.37
Iteration:   4160, Loss function: 4.071, Average Loss: 3.649, avg. samples / sec: 53682.33
Iteration:   4160, Loss function: 3.406, Average Loss: 3.665, avg. samples / sec: 53613.42
Iteration:   4160, Loss function: 2.858, Average Loss: 3.650, avg. samples / sec: 53626.70
Iteration:   4160, Loss function: 3.305, Average Loss: 3.684, avg. samples / sec: 53645.26
Iteration:   4160, Loss function: 2.419, Average Loss: 3.668, avg. samples / sec: 53409.81
Iteration:   4160, Loss function: 3.620, Average Loss: 3.663, avg. samples / sec: 53652.14
Iteration:   4160, Loss function: 3.354, Average Loss: 3.638, avg. samples / sec: 53640.48
Iteration:   4160, Loss function: 3.965, Average Loss: 3.649, avg. samples / sec: 53575.00
Iteration:   4160, Loss function: 3.478, Average Loss: 3.674, avg. samples / sec: 53585.35
Iteration:   4160, Loss function: 3.396, Average Loss: 3.692, avg. samples / sec: 53587.39
Iteration:   4160, Loss function: 2.955, Average Loss: 3.648, avg. samples / sec: 53609.53
Iteration:   4160, Loss function: 3.312, Average Loss: 3.690, avg. samples / sec: 53366.28
Iteration:   4160, Loss function: 3.739, Average Loss: 3.667, avg. samples / sec: 53569.69
Iteration:   4160, Loss function: 1.785, Average Loss: 3.679, avg. samples / sec: 53562.09
Iteration:   4180, Loss function: 3.569, Average Loss: 3.657, avg. samples / sec: 53039.56
Iteration:   4180, Loss function: 2.123, Average Loss: 3.641, avg. samples / sec: 53081.06
Iteration:   4180, Loss function: 4.177, Average Loss: 3.672, avg. samples / sec: 53025.93
Iteration:   4180, Loss function: 2.109, Average Loss: 3.677, avg. samples / sec: 53035.79
Iteration:   4180, Loss function: 4.362, Average Loss: 3.645, avg. samples / sec: 53011.69
Iteration:   4180, Loss function: 3.973, Average Loss: 3.652, avg. samples / sec: 53046.33
Iteration:   4180, Loss function: 2.951, Average Loss: 3.659, avg. samples / sec: 53247.70
Iteration:   4180, Loss function: 3.784, Average Loss: 3.682, avg. samples / sec: 53038.55
Iteration:   4180, Loss function: 3.636, Average Loss: 3.682, avg. samples / sec: 53255.27
Iteration:   4180, Loss function: 2.758, Average Loss: 3.637, avg. samples / sec: 52937.73
Iteration:   4180, Loss function: 3.968, Average Loss: 3.646, avg. samples / sec: 52976.84
Iteration:   4180, Loss function: 3.112, Average Loss: 3.683, avg. samples / sec: 52995.27
Iteration:   4180, Loss function: 4.401, Average Loss: 3.685, avg. samples / sec: 52968.73
Iteration:   4180, Loss function: 3.082, Average Loss: 3.655, avg. samples / sec: 52888.88
Iteration:   4180, Loss function: 2.703, Average Loss: 3.664, avg. samples / sec: 53045.49
Iteration:   4180, Loss function: 3.739, Average Loss: 3.646, avg. samples / sec: 53053.38
Iteration:   4180, Loss function: 3.480, Average Loss: 3.658, avg. samples / sec: 53012.01
Iteration:   4180, Loss function: 2.866, Average Loss: 3.661, avg. samples / sec: 53012.21
Iteration:   4180, Loss function: 3.292, Average Loss: 3.668, avg. samples / sec: 53063.15
Iteration:   4180, Loss function: 3.606, Average Loss: 3.683, avg. samples / sec: 53031.86
Iteration:   4180, Loss function: 3.653, Average Loss: 3.641, avg. samples / sec: 53057.90
Iteration:   4180, Loss function: 2.927, Average Loss: 3.641, avg. samples / sec: 53013.97
Iteration:   4180, Loss function: 2.673, Average Loss: 3.661, avg. samples / sec: 53092.38
Iteration:   4180, Loss function: 3.040, Average Loss: 3.687, avg. samples / sec: 53063.87
Iteration:   4180, Loss function: 3.642, Average Loss: 3.659, avg. samples / sec: 53006.57
Iteration:   4180, Loss function: 3.428, Average Loss: 3.630, avg. samples / sec: 53042.40
Iteration:   4180, Loss function: 2.842, Average Loss: 3.659, avg. samples / sec: 53008.16
Iteration:   4180, Loss function: 2.978, Average Loss: 3.660, avg. samples / sec: 53023.92
Iteration:   4180, Loss function: 3.820, Average Loss: 3.638, avg. samples / sec: 53046.69
Iteration:   4180, Loss function: 3.769, Average Loss: 3.672, avg. samples / sec: 53063.19
:::MLL 1558641245.975 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558641245.976 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558641246.047 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.69 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.60s)
DONE (t=0.63s)
DONE (t=2.48s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23011
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39412
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06073
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23891
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37922
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22343
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32463
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34061
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10264
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37070
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52853
Current AP: 0.23011 AP goal: 0.23000
:::MLL 1558641249.834 eval_accuracy: {"value": 0.23010992548749803, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558641249.957 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558641249.964 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558641250.512 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 07:54:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:55 PM
ENDING TIMING RUN AT 2019-05-23 07:54:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:55 PM
ENDING TIMING RUN AT 2019-05-23 07:54:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:51:02 PM
ENDING TIMING RUN AT 2019-05-23 07:54:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:55 PM
ENDING TIMING RUN AT 2019-05-23 07:54:19 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:51:06 PM
ENDING TIMING RUN AT 2019-05-23 07:54:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:54 PM
ENDING TIMING RUN AT 2019-05-23 07:54:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:55 PM
ENDING TIMING RUN AT 2019-05-23 07:54:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:58 PM
ENDING TIMING RUN AT 2019-05-23 07:54:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:58 PM
ENDING TIMING RUN AT 2019-05-23 07:54:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:56 PM
ENDING TIMING RUN AT 2019-05-23 07:54:08 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:54 PM
ENDING TIMING RUN AT 2019-05-23 07:54:08 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:54 PM
ENDING TIMING RUN AT 2019-05-23 07:54:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:53 PM
ENDING TIMING RUN AT 2019-05-23 07:54:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:56 PM
ENDING TIMING RUN AT 2019-05-23 07:54:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:53 PM
ENDING TIMING RUN AT 2019-05-23 07:54:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:54 PM
ENDING TIMING RUN AT 2019-05-23 07:54:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:53 PM
ENDING TIMING RUN AT 2019-05-23 07:54:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:58 PM
ENDING TIMING RUN AT 2019-05-23 07:54:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:57 PM
ENDING TIMING RUN AT 2019-05-23 07:54:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:54 PM
ENDING TIMING RUN AT 2019-05-23 07:54:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:52 PM
ENDING TIMING RUN AT 2019-05-23 07:54:12 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:58 PM
ENDING TIMING RUN AT 2019-05-23 07:54:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:51 PM
ENDING TIMING RUN AT 2019-05-23 07:54:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:56 PM
ENDING TIMING RUN AT 2019-05-23 07:54:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:51 PM
ENDING TIMING RUN AT 2019-05-23 07:54:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:53 PM
ENDING TIMING RUN AT 2019-05-23 07:54:08 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:54 PM
ENDING TIMING RUN AT 2019-05-23 07:54:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,193,nvidia,2019-05-23 07:50:57 PM
ENDING TIMING RUN AT 2019-05-23 07:54:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:51:01 PM
ENDING TIMING RUN AT 2019-05-23 07:54:07 PM
RESULT,SINGLE_STAGE_DETECTOR,,194,nvidia,2019-05-23 07:50:53 PM
