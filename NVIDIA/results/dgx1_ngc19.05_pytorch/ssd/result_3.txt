Beginning trial 1 of 1
Gathering sys log on sc-sdgx-737
:::MLL 1558570770.061 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558570770.062 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558570770.063 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558570770.064 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558570770.064 submission_platform: {"value": "1xDGX-1 with V100", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558570770.065 submission_entry: {"value": "{'hardware': 'DGX-1 with V100', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.2 LTS / NVIDIA DGX Server 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '1', 'cpu': '2x Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz', 'num_cores': '40', 'num_vcpus': '80', 'accelerator': 'Tesla V100-SXM2-16GB', 'num_accelerators': '8', 'sys_mem_size': '503 GB', 'sys_storage_type': 'SATA SSD', 'sys_storage_size': '1x 7T + 1x 446.6G', 'cpu_accel_interconnect': 'QPI', 'network_card': 'Mellanox Technologies MT27700 Family [ConnectX-4]', 'num_network_cards': '4', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558570770.066 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558570770.067 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
:::MLL 1558570817.976 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node sc-sdgx-737
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w sc-sdgx-737
+ srun --mem=0 -N 1 -n 1 -w sc-sdgx-737 docker exec -e DGXSYSTEM=DGX1 -e 'MULTI_NODE= --master_port=4310' -e SLURM_JOB_ID=326350 -e SLURM_NTASKS_PER_NODE=8 cont_326350 ./run_and_time.sh
Run vars: id 326350 gpus 8 mparams  --master_port=4310
STARTING TIMING RUN AT 2019-05-23 12:20:18 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --master_port=4310 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 120 --eval-batch-size 160 --warmup 650 --lr 2.92e-3 --wd 1.6e-4 --use-nvjpeg --use-roi-decode
:::MLL 1558570822.261 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558570822.261 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558570822.261 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558570822.261 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558570822.262 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558570822.262 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558570822.262 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558570822.262 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
BN group: 1
BN group: 1
BN group: 1
BN group: 1
BN group: 1
2 Using seed = 4059896276
1 Using seed = 4059896275
3 Using seed = 4059896277
4 Using seed = 4059896278
5 Using seed = 4059896279
7 Using seed = 4059896281
6 Using seed = 4059896280
0 Using seed = 4059896274
:::MLL 1558570828.944 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1558570832.987 model_bn_span: {"value": 120, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558570832.987 global_batch_size: {"value": 960, "metadata": {"file": "train.py", "lineno": 481}}
:::MLL 1558570832.994 opt_base_learning_rate: {"value": 0.08750000000000001, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1558570832.994 opt_weight_decay: {"value": 0.00016, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1558570832.995 opt_learning_rate_warmup_steps: {"value": 650, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558570832.995 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
epoch nbatch loss
:::MLL 1558570841.247 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558570841.248 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.49s)
creating index...
Done (t=0.49s)
creating index...
time_check a: 1558570843.088867664
time_check b: 1558570846.819602013
:::MLL 1558570848.041 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558570848.041 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.600, Average Loss: 0.023, avg. samples / sec: 78.56
Iteration:     20, Loss function: 20.690, Average Loss: 0.444, avg. samples / sec: 3820.39
Iteration:     40, Loss function: 18.834, Average Loss: 0.835, avg. samples / sec: 4354.37
Iteration:     60, Loss function: 15.334, Average Loss: 1.113, avg. samples / sec: 4426.78
Iteration:     80, Loss function: 10.194, Average Loss: 1.319, avg. samples / sec: 4465.53
Iteration:    100, Loss function: 9.728, Average Loss: 1.488, avg. samples / sec: 4457.97
Iteration:    120, Loss function: 9.029, Average Loss: 1.643, avg. samples / sec: 4470.50
:::MLL 1558570876.349 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558570876.350 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 8.614, Average Loss: 1.784, avg. samples / sec: 4471.62
Iteration:    160, Loss function: 8.714, Average Loss: 1.920, avg. samples / sec: 4473.71
Iteration:    180, Loss function: 8.552, Average Loss: 2.056, avg. samples / sec: 4471.91
Iteration:    200, Loss function: 7.986, Average Loss: 2.179, avg. samples / sec: 4478.06
Iteration:    220, Loss function: 8.112, Average Loss: 2.298, avg. samples / sec: 4476.27
Iteration:    240, Loss function: 8.177, Average Loss: 2.417, avg. samples / sec: 4464.03
:::MLL 1558570902.540 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558570902.541 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    260, Loss function: 7.574, Average Loss: 2.523, avg. samples / sec: 4432.76
Iteration:    280, Loss function: 7.399, Average Loss: 2.624, avg. samples / sec: 4446.03
Iteration:    300, Loss function: 7.419, Average Loss: 2.720, avg. samples / sec: 4477.81
Iteration:    320, Loss function: 7.253, Average Loss: 2.813, avg. samples / sec: 4446.18
Iteration:    340, Loss function: 7.243, Average Loss: 2.900, avg. samples / sec: 4447.83
Iteration:    360, Loss function: 7.528, Average Loss: 2.988, avg. samples / sec: 4463.25
:::MLL 1558570928.840 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558570928.841 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    380, Loss function: 6.998, Average Loss: 3.071, avg. samples / sec: 4461.77
Iteration:    400, Loss function: 6.924, Average Loss: 3.145, avg. samples / sec: 4463.05
Iteration:    420, Loss function: 6.562, Average Loss: 3.215, avg. samples / sec: 4469.15
Iteration:    440, Loss function: 6.647, Average Loss: 3.283, avg. samples / sec: 4467.92
Iteration:    460, Loss function: 6.311, Average Loss: 3.352, avg. samples / sec: 4455.16
Iteration:    480, Loss function: 6.490, Average Loss: 3.417, avg. samples / sec: 4446.01
:::MLL 1558570955.100 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558570955.101 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 6.188, Average Loss: 3.475, avg. samples / sec: 4454.56
Iteration:    520, Loss function: 6.095, Average Loss: 3.530, avg. samples / sec: 4458.97
Iteration:    540, Loss function: 6.030, Average Loss: 3.582, avg. samples / sec: 4428.28
Iteration:    560, Loss function: 5.920, Average Loss: 3.634, avg. samples / sec: 4447.01
Iteration:    580, Loss function: 6.275, Average Loss: 3.687, avg. samples / sec: 4451.40
Iteration:    600, Loss function: 5.606, Average Loss: 3.735, avg. samples / sec: 4464.50
:::MLL 1558570981.415 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558570981.416 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    620, Loss function: 5.989, Average Loss: 3.779, avg. samples / sec: 4448.39
Iteration:    640, Loss function: 6.054, Average Loss: 3.830, avg. samples / sec: 4459.27
Iteration:    660, Loss function: 5.740, Average Loss: 3.870, avg. samples / sec: 4454.07
Iteration:    680, Loss function: 5.765, Average Loss: 3.907, avg. samples / sec: 4444.82
Iteration:    700, Loss function: 5.407, Average Loss: 3.943, avg. samples / sec: 4424.75
Iteration:    720, Loss function: 5.561, Average Loss: 3.975, avg. samples / sec: 4428.58
:::MLL 1558571007.780 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558571007.781 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    740, Loss function: 5.681, Average Loss: 4.006, avg. samples / sec: 4441.99
Iteration:    760, Loss function: 5.580, Average Loss: 4.035, avg. samples / sec: 4451.86
Iteration:    780, Loss function: 5.430, Average Loss: 4.062, avg. samples / sec: 4445.87
Iteration:    800, Loss function: 5.501, Average Loss: 4.087, avg. samples / sec: 4454.88
Iteration:    820, Loss function: 5.542, Average Loss: 4.112, avg. samples / sec: 4459.69
Iteration:    840, Loss function: 5.497, Average Loss: 4.137, avg. samples / sec: 4437.31
:::MLL 1558571034.315 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558571034.316 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    860, Loss function: 5.207, Average Loss: 4.159, avg. samples / sec: 4446.06
Iteration:    880, Loss function: 5.207, Average Loss: 4.181, avg. samples / sec: 4435.61
Iteration:    900, Loss function: 5.459, Average Loss: 4.202, avg. samples / sec: 4444.49
Iteration:    920, Loss function: 5.314, Average Loss: 4.223, avg. samples / sec: 4411.63
Iteration:    940, Loss function: 5.188, Average Loss: 4.241, avg. samples / sec: 4403.30
Iteration:    960, Loss function: 4.972, Average Loss: 4.259, avg. samples / sec: 4436.14
:::MLL 1558571060.767 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558571060.767 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 4.741, Average Loss: 4.274, avg. samples / sec: 4438.32
Iteration:   1000, Loss function: 5.274, Average Loss: 4.289, avg. samples / sec: 4441.34
Iteration:   1020, Loss function: 4.634, Average Loss: 4.302, avg. samples / sec: 4442.51
Iteration:   1040, Loss function: 4.883, Average Loss: 4.313, avg. samples / sec: 4440.03
Iteration:   1060, Loss function: 4.669, Average Loss: 4.325, avg. samples / sec: 4447.43
Iteration:   1080, Loss function: 4.773, Average Loss: 4.337, avg. samples / sec: 4457.41
:::MLL 1558571087.124 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558571087.125 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:   1100, Loss function: 4.872, Average Loss: 4.350, avg. samples / sec: 4433.47
Iteration:   1120, Loss function: 5.064, Average Loss: 4.359, avg. samples / sec: 4454.25
Iteration:   1140, Loss function: 4.907, Average Loss: 4.366, avg. samples / sec: 4454.80
Iteration:   1160, Loss function: 5.156, Average Loss: 4.375, avg. samples / sec: 4459.99
Iteration:   1180, Loss function: 4.815, Average Loss: 4.385, avg. samples / sec: 4446.92
Iteration:   1200, Loss function: 4.806, Average Loss: 4.393, avg. samples / sec: 4452.09
Iteration:   1220, Loss function: 4.878, Average Loss: 4.400, avg. samples / sec: 4456.32
:::MLL 1558571113.437 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558571113.437 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:   1240, Loss function: 4.440, Average Loss: 4.406, avg. samples / sec: 4426.50
Iteration:   1260, Loss function: 4.905, Average Loss: 4.412, avg. samples / sec: 4449.53
Iteration:   1280, Loss function: 4.708, Average Loss: 4.417, avg. samples / sec: 4451.69
Iteration:   1300, Loss function: 4.663, Average Loss: 4.424, avg. samples / sec: 4451.75
Iteration:   1320, Loss function: 4.727, Average Loss: 4.431, avg. samples / sec: 4450.37
Iteration:   1340, Loss function: 4.874, Average Loss: 4.437, avg. samples / sec: 4453.65
:::MLL 1558571139.766 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558571139.767 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:   1360, Loss function: 4.864, Average Loss: 4.441, avg. samples / sec: 4439.78
Iteration:   1380, Loss function: 4.528, Average Loss: 4.444, avg. samples / sec: 4455.14
Iteration:   1400, Loss function: 4.435, Average Loss: 4.448, avg. samples / sec: 4458.45
Iteration:   1420, Loss function: 4.549, Average Loss: 4.452, avg. samples / sec: 4452.20
Iteration:   1440, Loss function: 4.610, Average Loss: 4.456, avg. samples / sec: 4448.53
Iteration:   1460, Loss function: 4.892, Average Loss: 4.459, avg. samples / sec: 4450.22
:::MLL 1558571166.077 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558571166.077 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.474, Average Loss: 4.461, avg. samples / sec: 4436.88
Iteration:   1500, Loss function: 4.369, Average Loss: 4.462, avg. samples / sec: 4451.45
Iteration:   1520, Loss function: 4.654, Average Loss: 4.464, avg. samples / sec: 4455.90
Iteration:   1540, Loss function: 4.326, Average Loss: 4.465, avg. samples / sec: 4449.57
Iteration:   1560, Loss function: 4.481, Average Loss: 4.465, avg. samples / sec: 4440.27
Iteration:   1580, Loss function: 4.439, Average Loss: 4.467, avg. samples / sec: 4450.28
:::MLL 1558571192.417 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558571192.418 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:   1600, Loss function: 4.615, Average Loss: 4.467, avg. samples / sec: 4409.56
Iteration:   1620, Loss function: 4.412, Average Loss: 4.469, avg. samples / sec: 4417.60
Iteration:   1640, Loss function: 4.472, Average Loss: 4.468, avg. samples / sec: 4442.76
Iteration:   1660, Loss function: 4.250, Average Loss: 4.468, avg. samples / sec: 4414.06
Iteration:   1680, Loss function: 4.392, Average Loss: 4.467, avg. samples / sec: 4429.35
Iteration:   1700, Loss function: 4.185, Average Loss: 4.466, avg. samples / sec: 4437.07
:::MLL 1558571219.097 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558571219.097 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:   1720, Loss function: 4.381, Average Loss: 4.466, avg. samples / sec: 4436.10
Iteration:   1740, Loss function: 4.498, Average Loss: 4.464, avg. samples / sec: 4444.23
Iteration:   1760, Loss function: 4.467, Average Loss: 4.463, avg. samples / sec: 4449.51
Iteration:   1780, Loss function: 4.224, Average Loss: 4.462, avg. samples / sec: 4443.60
Iteration:   1800, Loss function: 4.258, Average Loss: 4.460, avg. samples / sec: 4440.65
Iteration:   1820, Loss function: 4.758, Average Loss: 4.461, avg. samples / sec: 4446.47
:::MLL 1558571245.463 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558571245.464 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1840, Loss function: 4.342, Average Loss: 4.460, avg. samples / sec: 4420.67
Iteration:   1860, Loss function: 4.268, Average Loss: 4.459, avg. samples / sec: 4438.20
Iteration:   1880, Loss function: 4.597, Average Loss: 4.457, avg. samples / sec: 4444.14
Iteration:   1900, Loss function: 4.343, Average Loss: 4.455, avg. samples / sec: 4442.29
Iteration:   1920, Loss function: 4.281, Average Loss: 4.453, avg. samples / sec: 4429.16
Iteration:   1940, Loss function: 4.408, Average Loss: 4.450, avg. samples / sec: 4427.55
:::MLL 1558571271.878 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558571271.879 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.401, Average Loss: 4.448, avg. samples / sec: 4428.60
Iteration:   1980, Loss function: 4.227, Average Loss: 4.446, avg. samples / sec: 4442.00
Iteration:   2000, Loss function: 4.313, Average Loss: 4.441, avg. samples / sec: 4438.64
Iteration:   2020, Loss function: 4.317, Average Loss: 4.439, avg. samples / sec: 4436.27
Iteration:   2040, Loss function: 4.079, Average Loss: 4.436, avg. samples / sec: 4440.43
Iteration:   2060, Loss function: 4.498, Average Loss: 4.433, avg. samples / sec: 4439.22
:::MLL 1558571298.272 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558571298.272 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   2080, Loss function: 4.511, Average Loss: 4.431, avg. samples / sec: 4423.35
Iteration:   2100, Loss function: 4.353, Average Loss: 4.430, avg. samples / sec: 4429.99
Iteration:   2120, Loss function: 4.355, Average Loss: 4.427, avg. samples / sec: 4422.88
Iteration:   2140, Loss function: 4.286, Average Loss: 4.423, avg. samples / sec: 4399.13
Iteration:   2160, Loss function: 4.472, Average Loss: 4.421, avg. samples / sec: 4415.91
Iteration:   2180, Loss function: 4.243, Average Loss: 4.417, avg. samples / sec: 4418.80
:::MLL 1558571324.807 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558571324.808 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   2200, Loss function: 4.308, Average Loss: 4.414, avg. samples / sec: 4392.62
Iteration:   2220, Loss function: 4.081, Average Loss: 4.410, avg. samples / sec: 4386.39
Iteration:   2240, Loss function: 4.072, Average Loss: 4.405, avg. samples / sec: 4412.46
Iteration:   2260, Loss function: 4.439, Average Loss: 4.401, avg. samples / sec: 4426.15
Iteration:   2280, Loss function: 4.467, Average Loss: 4.398, avg. samples / sec: 4432.09
Iteration:   2300, Loss function: 4.390, Average Loss: 4.396, avg. samples / sec: 4407.71
Iteration:   2320, Loss function: 4.578, Average Loss: 4.391, avg. samples / sec: 4433.33
:::MLL 1558571351.341 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558571351.342 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   2340, Loss function: 4.061, Average Loss: 4.387, avg. samples / sec: 4434.35
Iteration:   2360, Loss function: 4.035, Average Loss: 4.384, avg. samples / sec: 4425.98
Iteration:   2380, Loss function: 4.207, Average Loss: 4.379, avg. samples / sec: 4437.87
Iteration:   2400, Loss function: 4.401, Average Loss: 4.375, avg. samples / sec: 4434.23
Iteration:   2420, Loss function: 4.174, Average Loss: 4.371, avg. samples / sec: 4430.71
Iteration:   2440, Loss function: 3.979, Average Loss: 4.367, avg. samples / sec: 4439.03
:::MLL 1558571377.973 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558571377.974 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.315, Average Loss: 4.362, avg. samples / sec: 4403.08
Iteration:   2480, Loss function: 4.073, Average Loss: 4.357, avg. samples / sec: 4402.22
Iteration:   2500, Loss function: 4.380, Average Loss: 4.353, avg. samples / sec: 4400.13
Iteration:   2520, Loss function: 4.137, Average Loss: 4.348, avg. samples / sec: 4385.62
Iteration:   2540, Loss function: 4.276, Average Loss: 4.344, avg. samples / sec: 4436.66
Iteration:   2560, Loss function: 3.967, Average Loss: 4.340, avg. samples / sec: 4428.61
:::MLL 1558571404.531 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558571404.532 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   2580, Loss function: 4.184, Average Loss: 4.335, avg. samples / sec: 4427.92
Iteration:   2600, Loss function: 4.160, Average Loss: 4.330, avg. samples / sec: 4439.76
Iteration:   2620, Loss function: 3.960, Average Loss: 4.324, avg. samples / sec: 4437.67
Iteration:   2640, Loss function: 4.013, Average Loss: 4.320, avg. samples / sec: 4429.44
Iteration:   2660, Loss function: 4.028, Average Loss: 4.314, avg. samples / sec: 4436.70
Iteration:   2680, Loss function: 3.994, Average Loss: 4.311, avg. samples / sec: 4422.23
:::MLL 1558571430.956 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558571430.956 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   2700, Loss function: 4.252, Average Loss: 4.306, avg. samples / sec: 4424.96
Iteration:   2720, Loss function: 3.773, Average Loss: 4.301, avg. samples / sec: 4432.09
Iteration:   2740, Loss function: 3.846, Average Loss: 4.297, avg. samples / sec: 4441.05
Iteration:   2760, Loss function: 4.378, Average Loss: 4.294, avg. samples / sec: 4435.37
Iteration:   2780, Loss function: 4.144, Average Loss: 4.290, avg. samples / sec: 4437.72
Iteration:   2800, Loss function: 3.953, Average Loss: 4.285, avg. samples / sec: 4427.38
:::MLL 1558571457.377 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558571457.378 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   2820, Loss function: 3.876, Average Loss: 4.280, avg. samples / sec: 4422.68
Iteration:   2840, Loss function: 4.029, Average Loss: 4.275, avg. samples / sec: 4420.52
Iteration:   2860, Loss function: 3.720, Average Loss: 4.271, avg. samples / sec: 4437.37
Iteration:   2880, Loss function: 4.142, Average Loss: 4.266, avg. samples / sec: 4438.26
Iteration:   2900, Loss function: 4.326, Average Loss: 4.263, avg. samples / sec: 4444.42
Iteration:   2920, Loss function: 4.190, Average Loss: 4.260, avg. samples / sec: 4390.14
:::MLL 1558571483.862 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558571483.863 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.881, Average Loss: 4.256, avg. samples / sec: 4387.85
Iteration:   2960, Loss function: 4.173, Average Loss: 4.252, avg. samples / sec: 4401.55
Iteration:   2980, Loss function: 3.979, Average Loss: 4.247, avg. samples / sec: 4421.74
Iteration:   3000, Loss function: 4.362, Average Loss: 4.243, avg. samples / sec: 4430.26
Iteration:   3020, Loss function: 4.409, Average Loss: 4.239, avg. samples / sec: 4430.21
Iteration:   3040, Loss function: 3.996, Average Loss: 4.236, avg. samples / sec: 4425.49
:::MLL 1558571510.369 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558571510.370 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   3060, Loss function: 3.935, Average Loss: 4.232, avg. samples / sec: 4408.51
Iteration:   3080, Loss function: 4.128, Average Loss: 4.227, avg. samples / sec: 4420.89
Iteration:   3100, Loss function: 3.935, Average Loss: 4.221, avg. samples / sec: 4417.74
Iteration:   3120, Loss function: 3.970, Average Loss: 4.217, avg. samples / sec: 4421.87
Iteration:   3140, Loss function: 3.956, Average Loss: 4.213, avg. samples / sec: 4425.87
Iteration:   3160, Loss function: 4.064, Average Loss: 4.209, avg. samples / sec: 4439.70
:::MLL 1558571536.838 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558571536.839 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   3180, Loss function: 4.182, Average Loss: 4.205, avg. samples / sec: 4429.05
Iteration:   3200, Loss function: 4.001, Average Loss: 4.200, avg. samples / sec: 4430.12
Iteration:   3220, Loss function: 3.924, Average Loss: 4.195, avg. samples / sec: 4428.16
Iteration:   3240, Loss function: 4.234, Average Loss: 4.191, avg. samples / sec: 4420.27
Iteration:   3260, Loss function: 3.806, Average Loss: 4.186, avg. samples / sec: 4417.17
Iteration:   3280, Loss function: 3.970, Average Loss: 4.182, avg. samples / sec: 4396.62
:::MLL 1558571563.610 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558571563.611 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 3.994, Average Loss: 4.180, avg. samples / sec: 4370.30
Iteration:   3320, Loss function: 3.801, Average Loss: 4.175, avg. samples / sec: 4391.66
Iteration:   3340, Loss function: 3.958, Average Loss: 4.171, avg. samples / sec: 4391.06
Iteration:   3360, Loss function: 3.936, Average Loss: 4.168, avg. samples / sec: 4407.15
Iteration:   3380, Loss function: 3.858, Average Loss: 4.163, avg. samples / sec: 4429.28
Iteration:   3400, Loss function: 3.900, Average Loss: 4.159, avg. samples / sec: 4429.18
Iteration:   3420, Loss function: 3.587, Average Loss: 4.155, avg. samples / sec: 4427.98
:::MLL 1558571590.160 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558571590.161 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.724, Average Loss: 4.150, avg. samples / sec: 4416.80
Iteration:   3460, Loss function: 4.065, Average Loss: 4.146, avg. samples / sec: 4423.48
Iteration:   3480, Loss function: 4.035, Average Loss: 4.141, avg. samples / sec: 4395.91
Iteration:   3500, Loss function: 3.993, Average Loss: 4.137, avg. samples / sec: 4415.54
Iteration:   3520, Loss function: 3.542, Average Loss: 4.133, avg. samples / sec: 4428.05
Iteration:   3540, Loss function: 4.232, Average Loss: 4.128, avg. samples / sec: 4437.11
:::MLL 1558571616.660 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558571616.661 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 4.193, Average Loss: 4.124, avg. samples / sec: 4424.26
Iteration:   3580, Loss function: 3.679, Average Loss: 4.119, avg. samples / sec: 4430.32
Iteration:   3600, Loss function: 3.717, Average Loss: 4.116, avg. samples / sec: 4430.84
Iteration:   3620, Loss function: 3.863, Average Loss: 4.113, avg. samples / sec: 4417.38
Iteration:   3640, Loss function: 4.220, Average Loss: 4.110, avg. samples / sec: 4428.71
Iteration:   3660, Loss function: 3.608, Average Loss: 4.106, avg. samples / sec: 4430.05
:::MLL 1558571643.114 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558571643.114 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   3680, Loss function: 3.990, Average Loss: 4.101, avg. samples / sec: 4417.67
Iteration:   3700, Loss function: 3.876, Average Loss: 4.097, avg. samples / sec: 4426.63
Iteration:   3720, Loss function: 3.908, Average Loss: 4.094, avg. samples / sec: 4425.75
Iteration:   3740, Loss function: 3.777, Average Loss: 4.090, avg. samples / sec: 4426.95
Iteration:   3760, Loss function: 3.919, Average Loss: 4.086, avg. samples / sec: 4427.80
Iteration:   3780, Loss function: 3.649, Average Loss: 4.083, avg. samples / sec: 4407.45
:::MLL 1558571669.604 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558571669.605 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   3800, Loss function: 3.900, Average Loss: 4.078, avg. samples / sec: 4419.33
Iteration:   3820, Loss function: 4.229, Average Loss: 4.075, avg. samples / sec: 4431.44
Iteration:   3840, Loss function: 3.911, Average Loss: 4.071, avg. samples / sec: 4422.99
Iteration:   3860, Loss function: 3.803, Average Loss: 4.069, avg. samples / sec: 4436.55
Iteration:   3880, Loss function: 3.783, Average Loss: 4.065, avg. samples / sec: 4435.69
Iteration:   3900, Loss function: 4.008, Average Loss: 4.063, avg. samples / sec: 4425.78
:::MLL 1558571696.047 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558571696.048 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 3.806, Average Loss: 4.060, avg. samples / sec: 4421.10
Iteration:   3940, Loss function: 3.832, Average Loss: 4.056, avg. samples / sec: 4418.60
Iteration:   3960, Loss function: 3.817, Average Loss: 4.053, avg. samples / sec: 4434.29
Iteration:   3980, Loss function: 3.816, Average Loss: 4.050, avg. samples / sec: 4436.39
Iteration:   4000, Loss function: 4.191, Average Loss: 4.045, avg. samples / sec: 4422.54
:::MLL 1558571716.005 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 1/4Parsing batch: 3/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 3/4Parsing batch: 1/4Parsing batch: 3/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 8.38 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=2.68s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32685
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17449
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.27982
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27244
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28822
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08209
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.44075
Current AP: 0.17472 AP goal: 0.23000
:::MLL 1558571727.574 eval_accuracy: {"value": 0.17471709048253384, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558571727.607 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558571727.636 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558571727.637 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   4020, Loss function: 3.782, Average Loss: 4.041, avg. samples / sec: 1189.69
:::MLL 1558571734.523 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558571734.523 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   4040, Loss function: 4.010, Average Loss: 4.038, avg. samples / sec: 4424.88
Iteration:   4060, Loss function: 4.093, Average Loss: 4.035, avg. samples / sec: 4454.19
Iteration:   4080, Loss function: 3.896, Average Loss: 4.032, avg. samples / sec: 4444.14
Iteration:   4100, Loss function: 3.905, Average Loss: 4.030, avg. samples / sec: 4443.84
Iteration:   4120, Loss function: 3.838, Average Loss: 4.028, avg. samples / sec: 4432.20
Iteration:   4140, Loss function: 3.917, Average Loss: 4.027, avg. samples / sec: 4429.12
:::MLL 1558571760.914 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558571760.915 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   4160, Loss function: 3.548, Average Loss: 4.023, avg. samples / sec: 4422.20
Iteration:   4180, Loss function: 4.017, Average Loss: 4.019, avg. samples / sec: 4423.22
Iteration:   4200, Loss function: 4.048, Average Loss: 4.016, avg. samples / sec: 4427.91
Iteration:   4220, Loss function: 3.962, Average Loss: 4.013, avg. samples / sec: 4414.87
Iteration:   4240, Loss function: 3.821, Average Loss: 4.010, avg. samples / sec: 4433.43
Iteration:   4260, Loss function: 3.811, Average Loss: 4.007, avg. samples / sec: 4422.51
:::MLL 1558571787.393 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558571787.394 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   4280, Loss function: 3.782, Average Loss: 4.004, avg. samples / sec: 4412.95
Iteration:   4300, Loss function: 3.917, Average Loss: 4.000, avg. samples / sec: 4422.35
Iteration:   4320, Loss function: 3.889, Average Loss: 3.997, avg. samples / sec: 4425.33
Iteration:   4340, Loss function: 3.877, Average Loss: 3.995, avg. samples / sec: 4421.20
Iteration:   4360, Loss function: 3.608, Average Loss: 3.991, avg. samples / sec: 4420.72
Iteration:   4380, Loss function: 3.787, Average Loss: 3.988, avg. samples / sec: 4422.31
:::MLL 1558571813.897 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558571813.898 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   4400, Loss function: 3.781, Average Loss: 3.986, avg. samples / sec: 4404.59
Iteration:   4420, Loss function: 3.802, Average Loss: 3.982, avg. samples / sec: 4426.65
Iteration:   4440, Loss function: 3.735, Average Loss: 3.980, avg. samples / sec: 4433.63
Iteration:   4460, Loss function: 3.995, Average Loss: 3.977, avg. samples / sec: 4425.99
Iteration:   4480, Loss function: 3.734, Average Loss: 3.973, avg. samples / sec: 4427.56
Iteration:   4500, Loss function: 3.921, Average Loss: 3.970, avg. samples / sec: 4416.57
:::MLL 1558571840.376 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558571840.377 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   4520, Loss function: 3.875, Average Loss: 3.967, avg. samples / sec: 4407.19
Iteration:   4540, Loss function: 3.755, Average Loss: 3.964, avg. samples / sec: 4413.73
Iteration:   4560, Loss function: 3.872, Average Loss: 3.961, avg. samples / sec: 4422.10
Iteration:   4580, Loss function: 3.789, Average Loss: 3.957, avg. samples / sec: 4426.16
Iteration:   4600, Loss function: 4.007, Average Loss: 3.955, avg. samples / sec: 4427.98
Iteration:   4620, Loss function: 3.661, Average Loss: 3.952, avg. samples / sec: 4421.46
Iteration:   4640, Loss function: 3.838, Average Loss: 3.950, avg. samples / sec: 4425.24
:::MLL 1558571866.869 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558571866.870 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   4660, Loss function: 3.798, Average Loss: 3.946, avg. samples / sec: 4417.56
Iteration:   4680, Loss function: 3.788, Average Loss: 3.942, avg. samples / sec: 4427.22
Iteration:   4700, Loss function: 3.783, Average Loss: 3.939, avg. samples / sec: 4426.93
Iteration:   4720, Loss function: 3.944, Average Loss: 3.937, avg. samples / sec: 4428.47
Iteration:   4740, Loss function: 3.912, Average Loss: 3.936, avg. samples / sec: 4431.69
Iteration:   4760, Loss function: 3.805, Average Loss: 3.934, avg. samples / sec: 4424.08
:::MLL 1558571893.331 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558571893.332 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   4780, Loss function: 3.948, Average Loss: 3.931, avg. samples / sec: 4412.14
Iteration:   4800, Loss function: 3.450, Average Loss: 3.926, avg. samples / sec: 4423.01
Iteration:   4820, Loss function: 3.801, Average Loss: 3.923, avg. samples / sec: 4422.92
Iteration:   4840, Loss function: 3.823, Average Loss: 3.920, avg. samples / sec: 4422.17
Iteration:   4860, Loss function: 3.814, Average Loss: 3.916, avg. samples / sec: 4410.37
Iteration:   4880, Loss function: 4.243, Average Loss: 3.914, avg. samples / sec: 4423.69
:::MLL 1558571920.054 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558571920.055 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   4900, Loss function: 3.834, Average Loss: 3.911, avg. samples / sec: 4394.81
Iteration:   4920, Loss function: 3.517, Average Loss: 3.908, avg. samples / sec: 4417.26
Iteration:   4940, Loss function: 3.589, Average Loss: 3.904, avg. samples / sec: 4415.21
Iteration:   4960, Loss function: 3.605, Average Loss: 3.902, avg. samples / sec: 4418.98
Iteration:   4980, Loss function: 3.660, Average Loss: 3.899, avg. samples / sec: 4422.70
Iteration:   5000, Loss function: 3.473, Average Loss: 3.897, avg. samples / sec: 4423.18
:::MLL 1558571946.579 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558571946.580 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   5020, Loss function: 3.613, Average Loss: 3.894, avg. samples / sec: 4416.12
Iteration:   5040, Loss function: 4.150, Average Loss: 3.893, avg. samples / sec: 4415.34
Iteration:   5060, Loss function: 3.851, Average Loss: 3.891, avg. samples / sec: 4422.84
Iteration:   5080, Loss function: 4.004, Average Loss: 3.889, avg. samples / sec: 4414.93
Iteration:   5100, Loss function: 3.818, Average Loss: 3.887, avg. samples / sec: 4419.85
Iteration:   5120, Loss function: 3.689, Average Loss: 3.884, avg. samples / sec: 4412.84
:::MLL 1558571973.097 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558571973.098 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   5140, Loss function: 3.309, Average Loss: 3.881, avg. samples / sec: 4407.72
Iteration:   5160, Loss function: 3.804, Average Loss: 3.879, avg. samples / sec: 4416.11
Iteration:   5180, Loss function: 3.671, Average Loss: 3.876, avg. samples / sec: 4416.75
Iteration:   5200, Loss function: 3.906, Average Loss: 3.873, avg. samples / sec: 4399.20
Iteration:   5220, Loss function: 3.476, Average Loss: 3.870, avg. samples / sec: 4409.95
Iteration:   5240, Loss function: 3.400, Average Loss: 3.868, avg. samples / sec: 4415.04
:::MLL 1558571999.649 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558571999.650 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   5260, Loss function: 3.840, Average Loss: 3.866, avg. samples / sec: 4409.77
Iteration:   5280, Loss function: 3.992, Average Loss: 3.863, avg. samples / sec: 4424.11
Iteration:   5300, Loss function: 3.966, Average Loss: 3.860, avg. samples / sec: 4420.32
Iteration:   5320, Loss function: 3.697, Average Loss: 3.857, avg. samples / sec: 4421.82
lr decay step #1
:::MLL 1558572017.249 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 5.97 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=2.73s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.18840
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.34251
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.19081
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04498
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.19229
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31227
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.19369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.28442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29939
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.47466
Current AP: 0.18840 AP goal: 0.23000
:::MLL 1558572026.582 eval_accuracy: {"value": 0.18839993019691245, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558572026.653 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558572026.682 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558572026.683 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   5340, Loss function: 3.594, Average Loss: 3.854, avg. samples / sec: 1393.42
Iteration:   5360, Loss function: 3.507, Average Loss: 3.847, avg. samples / sec: 4456.19
:::MLL 1558572035.526 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558572035.527 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   5380, Loss function: 3.309, Average Loss: 3.842, avg. samples / sec: 4442.04
Iteration:   5400, Loss function: 3.346, Average Loss: 3.834, avg. samples / sec: 4439.76
Iteration:   5420, Loss function: 3.366, Average Loss: 3.824, avg. samples / sec: 4439.45
Iteration:   5440, Loss function: 3.330, Average Loss: 3.814, avg. samples / sec: 4423.82
Iteration:   5460, Loss function: 3.645, Average Loss: 3.805, avg. samples / sec: 4440.69
Iteration:   5480, Loss function: 3.068, Average Loss: 3.797, avg. samples / sec: 4444.35
:::MLL 1558572061.925 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558572061.925 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   5500, Loss function: 3.552, Average Loss: 3.789, avg. samples / sec: 4416.71
Iteration:   5520, Loss function: 3.480, Average Loss: 3.781, avg. samples / sec: 4416.36
Iteration:   5540, Loss function: 3.373, Average Loss: 3.772, avg. samples / sec: 4426.32
Iteration:   5560, Loss function: 3.283, Average Loss: 3.764, avg. samples / sec: 4445.27
Iteration:   5580, Loss function: 3.516, Average Loss: 3.756, avg. samples / sec: 4443.25
Iteration:   5600, Loss function: 3.224, Average Loss: 3.748, avg. samples / sec: 4438.05
:::MLL 1558572088.350 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558572088.351 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   5620, Loss function: 3.329, Average Loss: 3.741, avg. samples / sec: 4434.58
Iteration:   5640, Loss function: 3.449, Average Loss: 3.733, avg. samples / sec: 4447.03
Iteration:   5660, Loss function: 3.563, Average Loss: 3.726, avg. samples / sec: 4435.20
Iteration:   5680, Loss function: 3.473, Average Loss: 3.718, avg. samples / sec: 4440.75
Iteration:   5700, Loss function: 3.154, Average Loss: 3.711, avg. samples / sec: 4431.45
Iteration:   5720, Loss function: 3.373, Average Loss: 3.702, avg. samples / sec: 4436.26
Iteration:   5740, Loss function: 3.484, Average Loss: 3.697, avg. samples / sec: 4437.58
:::MLL 1558572114.967 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558572114.968 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   5760, Loss function: 3.375, Average Loss: 3.688, avg. samples / sec: 4408.02
Iteration:   5780, Loss function: 3.361, Average Loss: 3.682, avg. samples / sec: 4432.33
Iteration:   5800, Loss function: 3.641, Average Loss: 3.676, avg. samples / sec: 4434.66
Iteration:   5820, Loss function: 3.602, Average Loss: 3.669, avg. samples / sec: 4432.00
Iteration:   5840, Loss function: 3.639, Average Loss: 3.663, avg. samples / sec: 4438.61
Iteration:   5860, Loss function: 3.190, Average Loss: 3.657, avg. samples / sec: 4435.71
:::MLL 1558572141.405 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558572141.406 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   5880, Loss function: 3.533, Average Loss: 3.649, avg. samples / sec: 4416.90
Iteration:   5900, Loss function: 3.183, Average Loss: 3.642, avg. samples / sec: 4423.59
Iteration:   5920, Loss function: 3.346, Average Loss: 3.633, avg. samples / sec: 4423.65
Iteration:   5940, Loss function: 3.441, Average Loss: 3.627, avg. samples / sec: 4425.75
Iteration:   5960, Loss function: 3.489, Average Loss: 3.622, avg. samples / sec: 4418.56
Iteration:   5980, Loss function: 2.952, Average Loss: 3.613, avg. samples / sec: 4421.51
:::MLL 1558572167.897 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558572167.898 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   6000, Loss function: 3.409, Average Loss: 3.608, avg. samples / sec: 4410.79
:::MLL 1558572171.163 eval_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 6.04 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=2.52s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23160
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39532
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23810
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06024
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24049
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22331
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32393
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10178
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36748
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52878
Current AP: 0.23160 AP goal: 0.23000
:::MLL 1558572180.310 eval_accuracy: {"value": 0.2316000976753141, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 389}}
:::MLL 1558572180.311 eval_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 392}}
:::MLL 1558572180.339 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558572180.834 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 12:43:05 AM
RESULT,SINGLE_STAGE_DETECTOR,,1367,nvidia,2019-05-23 12:20:18 AM
