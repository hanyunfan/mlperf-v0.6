Beginning trial 3 of 5
Gathering sys log on circe-n001
:::MLL 1558651490.899 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558651490.900 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558651490.901 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558651490.901 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558651490.901 submission_platform: {"value": "30xNVIDIA DGX-2H", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558651490.902 submission_entry: {"value": "{'hardware': 'NVIDIA DGX-2H', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.1 LTS / NVIDIA DGX Server 4.0.4 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) Platinum 8174 CPU @ 3.10GHz', 'num_cores': '48', 'num_vcpus': '96', 'accelerator': 'Tesla V100-SXM3-32GB-H', 'num_accelerators': '8', 'sys_mem_size': '1510 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '2x 894.3G + 8x 3.5T', 'cpu_accel_interconnect': 'UPI', 'network_card': 'Mellanox Technologies MT27800 Family [ConnectX-5]', 'num_network_cards': '10', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558651490.902 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558651490.903 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558651493.535 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.543 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.514 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.536 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.563 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.544 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.551 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.580 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.532 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.537 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.558 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.586 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.550 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.553 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.565 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.577 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.553 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.567 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.584 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.559 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.574 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.583 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.562 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.561 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.589 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.580 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.610 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.623 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.616 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651493.719 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node circe-n001
+ pids+=($!)
+ set +x
Launching on node circe-n002
+ pids+=($!)
+ set +x
Launching on node circe-n003
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n001
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n002
+ pids+=($!)
+ set +x
Launching on node circe-n004
+ srun --mem=0 -N 1 -n 1 -w circe-n001 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n005
+ srun --mem=0 -N 1 -n 1 -w circe-n002 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n003
+ pids+=($!)
+ set +x
Launching on node circe-n006
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n004
+ pids+=($!)
+ set +x
Launching on node circe-n007
+ srun --mem=0 -N 1 -n 1 -w circe-n003 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n004 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n005
+ pids+=($!)
+ set +x
Launching on node circe-n008
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n006
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w circe-n005 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ set +x
Launching on node circe-n009
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n007
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n008
+ srun --mem=0 -N 1 -n 1 -w circe-n006 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ set +x
Launching on node circe-n010
+ srun --mem=0 -N 1 -n 1 -w circe-n007 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n011
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n008 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n009
+ pids+=($!)
+ set +x
Launching on node circe-n012
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n010
+ srun --mem=0 -N 1 -n 1 -w circe-n009 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n013
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n011
+ srun --mem=0 -N 1 -n 1 -w circe-n010 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n014
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n012
+ srun --mem=0 -N 1 -n 1 -w circe-n011 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n015
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n013
+ srun --mem=0 -N 1 -n 1 -w circe-n012 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n014
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w circe-n013 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ set +x
Launching on node circe-n016
+ pids+=($!)
+ set +x
Launching on node circe-n017
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n015
+ srun --mem=0 -N 1 -n 1 -w circe-n014 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n018
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n015 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n016
+ pids+=($!)
+ set +x
Launching on node circe-n019
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n017
+ srun --mem=0 -N 1 -n 1 -w circe-n016 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n020
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n018
+ srun --mem=0 -N 1 -n 1 -w circe-n017 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n021
+ srun --mem=0 -N 1 -n 1 -w circe-n018 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n019
+ pids+=($!)
+ set +x
Launching on node circe-n022
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n020
+ srun --mem=0 -N 1 -n 1 -w circe-n019 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n023
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n021
+ srun --mem=0 -N 1 -n 1 -w circe-n020 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n024
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n022
+ srun --mem=0 -N 1 -n 1 -w circe-n021 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node circe-n025
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n023
+ srun --mem=0 -N 1 -n 1 -w circe-n022 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n026
+ srun --mem=0 -N 1 -n 1 -w circe-n023 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n024
+ pids+=($!)
+ set +x
Launching on node circe-n027
+ srun --mem=0 -N 1 -n 1 -w circe-n024 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n025
+ pids+=($!)
+ set +x
Launching on node circe-n028
+ srun --mem=0 -N 1 -n 1 -w circe-n025 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n026
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n027
+ pids+=($!)
+ set +x
Launching on node circe-n029
+ srun --mem=0 -N 1 -n 1 -w circe-n026 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node circe-n030
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n028
+ srun --mem=0 -N 1 -n 1 -w circe-n027 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n028 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n029
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n030
+ srun --mem=0 -N 1 -n 1 -w circe-n029 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n030 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
+ export DATASET_DIR=/data/coco2017
running benchmark
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:53 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:44:54 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558651497.254 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651497.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.281 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.281 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.281 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.281 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.281 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.281 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.281 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.282 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.293 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.293 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.293 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.293 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.293 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.293 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.293 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.293 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.294 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.294 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.294 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.294 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.294 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.294 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.294 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.294 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.299 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.347 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.347 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.347 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.348 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.348 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.348 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.348 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.335 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.355 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.316 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.316 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.317 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.318 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.318 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.318 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.318 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.318 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.333 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.386 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.386 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.386 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.386 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.386 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.386 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.351 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.351 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.351 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.351 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.351 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.351 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.351 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.352 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.343 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.343 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.343 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.343 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.344 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.344 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.381 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.381 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.344 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.381 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.381 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.381 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.381 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.381 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.381 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.344 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.394 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.394 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.394 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.394 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.394 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.394 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.394 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.394 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.366 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.366 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.366 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.366 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.367 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.367 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.367 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.367 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.362 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.362 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.362 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.362 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.363 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.363 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.363 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.363 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.398 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.398 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.398 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.398 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.399 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.399 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.399 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.399 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.413 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.413 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.413 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.413 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.414 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.414 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.414 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.414 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.388 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.388 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.388 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.388 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.388 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.388 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.388 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.388 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.387 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.410 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.404 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.405 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.429 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.429 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.429 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.429 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.429 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.429 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.429 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.430 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.444 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.444 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.444 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.444 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.430 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.430 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.430 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.431 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.431 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.431 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.431 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558651497.431 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.458 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.458 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.458 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.458 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.457 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.457 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651497.442 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.442 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.442 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.442 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651497.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
0 Using seed = 1873830663
2 Using seed = 1873830665
1 Using seed = 1873830664
:::MLL 1558651511.044 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
4 Using seed = 1873830667
3 Using seed = 1873830666
15 Using seed = 1873830678
8 Using seed = 1873830671
11 Using seed = 1873830674
10 Using seed = 1873830673
14 Using seed = 1873830677
13 Using seed = 1873830676
9 Using seed = 1873830672
12 Using seed = 1873830675
17 Using seed = 1873830680
18 Using seed = 1873830681
16 Using seed = 1873830679
19 Using seed = 1873830682
23 Using seed = 1873830686
22 Using seed = 1873830685
20 Using seed = 1873830683
21 Using seed = 1873830684
29 Using seed = 1873830692
31 Using seed = 1873830694
27 Using seed = 1873830690
30 Using seed = 1873830693
24 Using seed = 1873830687
28 Using seed = 1873830691
25 Using seed = 1873830688
26 Using seed = 1873830689
38 Using seed = 1873830701
39 Using seed = 1873830702
37 Using seed = 1873830700
32 Using seed = 1873830695
35 Using seed = 1873830698
33 Using seed = 1873830696
36 Using seed = 1873830699
34 Using seed = 1873830697
44 Using seed = 1873830707
45 Using seed = 1873830708
46 Using seed = 1873830709
43 Using seed = 1873830706
47 Using seed = 1873830710
40 Using seed = 1873830703
41 Using seed = 1873830704
42 Using seed = 1873830705
49 Using seed = 1873830712
53 Using seed = 1873830716
51 Using seed = 1873830714
55 Using seed = 1873830718
48 Using seed = 1873830711
50 Using seed = 1873830713
54 Using seed = 1873830717
52 Using seed = 1873830715
62 Using seed = 1873830725
61 Using seed = 1873830724
59 Using seed = 1873830722
63 Using seed = 1873830726
60 Using seed = 1873830723
57 Using seed = 1873830720
58 Using seed = 1873830721
56 Using seed = 1873830719
65 Using seed = 1873830728
66 Using seed = 1873830729
67 Using seed = 1873830730
70 Using seed = 1873830733
68 Using seed = 1873830731
69 Using seed = 1873830732
71 Using seed = 1873830734
64 Using seed = 1873830727
78 Using seed = 1873830741
77 Using seed = 1873830740
79 Using seed = 1873830742
76 Using seed = 1873830739
74 Using seed = 1873830737
72 Using seed = 1873830735
75 Using seed = 1873830738
73 Using seed = 1873830736
87 Using seed = 1873830750
82 Using seed = 1873830745
85 Using seed = 1873830748
81 Using seed = 1873830744
80 Using seed = 1873830743
86 Using seed = 1873830749
83 Using seed = 1873830746
84 Using seed = 1873830747
94 Using seed = 1873830757
95 Using seed = 1873830758
92 Using seed = 1873830755
93 Using seed = 1873830756
89 Using seed = 1873830752
88 Using seed = 1873830751
91 Using seed = 1873830754
90 Using seed = 1873830753
103 Using seed = 1873830766
99 Using seed = 1873830762
101 Using seed = 1873830764
97 Using seed = 1873830760
96 Using seed = 1873830759
98 Using seed = 1873830761
102 Using seed = 1873830765
100 Using seed = 1873830763
110 Using seed = 1873830773
108 Using seed = 1873830771
109 Using seed = 1873830772
111 Using seed = 1873830774
104 Using seed = 1873830767
105 Using seed = 1873830768
107 Using seed = 1873830770
106 Using seed = 1873830769
115 Using seed = 1873830778
114 Using seed = 1873830777
112 Using seed = 1873830775
117 Using seed = 1873830780
119 Using seed = 1873830782
118 Using seed = 1873830781
113 Using seed = 1873830776
116 Using seed = 1873830779
123 Using seed = 1873830786
124 Using seed = 1873830787
121 Using seed = 1873830784
120 Using seed = 1873830783
126 Using seed = 1873830789
125 Using seed = 1873830788
127 Using seed = 1873830790
122 Using seed = 1873830785
128 Using seed = 1873830791
135 Using seed = 1873830798
131 Using seed = 1873830794
134 Using seed = 1873830797
129 Using seed = 1873830792
133 Using seed = 1873830796
130 Using seed = 1873830793
132 Using seed = 1873830795
136 Using seed = 1873830799
138 Using seed = 1873830801
137 Using seed = 1873830800
139 Using seed = 1873830802
142 Using seed = 1873830805
143 Using seed = 1873830806
141 Using seed = 1873830804
140 Using seed = 1873830803
145 Using seed = 1873830808
146 Using seed = 1873830809
144 Using seed = 1873830807
147 Using seed = 1873830810
149 Using seed = 1873830812
150 Using seed = 1873830813
151 Using seed = 1873830814
148 Using seed = 1873830811
158 Using seed = 1873830821
156 Using seed = 1873830819
159 Using seed = 1873830822
155 Using seed = 1873830818
157 Using seed = 1873830820
154 Using seed = 1873830817
153 Using seed = 1873830816
152 Using seed = 1873830815
161 Using seed = 1873830824
163 Using seed = 1873830826
160 Using seed = 1873830823
162 Using seed = 1873830825
167 Using seed = 1873830830
165 Using seed = 1873830828
166 Using seed = 1873830829
164 Using seed = 1873830827
169 Using seed = 1873830832
172 Using seed = 1873830835
171 Using seed = 1873830834
173 Using seed = 1873830836
174 Using seed = 1873830837
175 Using seed = 1873830838
168 Using seed = 1873830831
170 Using seed = 1873830833
183 Using seed = 1873830846
181 Using seed = 1873830844
178 Using seed = 1873830841
182 Using seed = 1873830845
177 Using seed = 1873830840
176 Using seed = 1873830839
179 Using seed = 1873830842
180 Using seed = 1873830843
191 Using seed = 1873830854
188 Using seed = 1873830851
189 Using seed = 1873830852
184 Using seed = 1873830847
190 Using seed = 1873830853
187 Using seed = 1873830850
185 Using seed = 1873830848
186 Using seed = 1873830849
193 Using seed = 1873830856
194 Using seed = 1873830857
192 Using seed = 1873830855
195 Using seed = 1873830858
197 Using seed = 1873830860
199 Using seed = 1873830862
198 Using seed = 1873830861
196 Using seed = 1873830859
206 Using seed = 1873830869
204 Using seed = 1873830867
207 Using seed = 1873830870
205 Using seed = 1873830868
203 Using seed = 1873830866
201 Using seed = 1873830864
200 Using seed = 1873830863
202 Using seed = 1873830865
214 Using seed = 1873830877
213 Using seed = 1873830876
215 Using seed = 1873830878
209 Using seed = 1873830872
208 Using seed = 1873830871
210 Using seed = 1873830873
212 Using seed = 1873830875
211 Using seed = 1873830874
222 Using seed = 1873830885
221 Using seed = 1873830884
223 Using seed = 1873830886
217 Using seed = 1873830880
216 Using seed = 1873830879
218 Using seed = 1873830881
220 Using seed = 1873830883
219 Using seed = 1873830882
229 Using seed = 1873830892
230 Using seed = 1873830893
227 Using seed = 1873830890
226 Using seed = 1873830889
224 Using seed = 1873830887
231 Using seed = 1873830894
225 Using seed = 1873830888
228 Using seed = 1873830891
238 Using seed = 1873830901
239 Using seed = 1873830902
237 Using seed = 1873830900
235 Using seed = 1873830898
234 Using seed = 1873830897
233 Using seed = 1873830896
232 Using seed = 1873830895
236 Using seed = 1873830899
5 Using seed = 1873830668
7 Using seed = 1873830670
6 Using seed = 1873830669
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651513.045 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558651513.045 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651513.058 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1558651513.058 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1558651513.058 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558651513.058 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558651516.924 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558651516.925 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
Done (t=0.44s)
creating index...
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.45s)
creating index...
time_check a: 1558651518.551686287
time_check a: 1558651518.574792385
time_check a: 1558651518.593684435
time_check a: 1558651518.556285143
time_check a: 1558651518.573652267
time_check a: 1558651518.575923204
time_check a: 1558651518.576342344
time_check a: 1558651518.559662342
time_check a: 1558651518.587966442
time_check a: 1558651518.613874197
time_check a: 1558651518.584972620
time_check a: 1558651518.573518038
time_check a: 1558651518.590455294
time_check a: 1558651518.582179785
time_check a: 1558651518.613790512
time_check a: 1558651518.593794346
time_check a: 1558651518.586939573
time_check a: 1558651518.606693029
time_check a: 1558651518.594816923
time_check a: 1558651518.600633383
time_check a: 1558651518.571020126
time_check a: 1558651518.600185394
time_check a: 1558651518.594802380
time_check a: 1558651518.576611042
time_check a: 1558651518.580789328
time_check a: 1558651518.578493834
time_check a: 1558651518.578185558
time_check a: 1558651518.577512980
time_check a: 1558651518.569861650
time_check a: 1558651518.595338345
time_check b: 1558651522.318357229
time_check b: 1558651522.331707716
time_check b: 1558651522.367438555
time_check b: 1558651522.410076618
time_check b: 1558651522.406554222
time_check b: 1558651522.398238659
time_check b: 1558651522.400565147
time_check b: 1558651522.411804914
time_check b: 1558651522.408729076
time_check b: 1558651522.438241720
time_check b: 1558651522.444938660
time_check b: 1558651522.424221039
time_check b: 1558651522.451172829
time_check b: 1558651522.456719398
time_check b: 1558651522.444048405
time_check b: 1558651522.459236145
time_check b: 1558651522.497916698
time_check b: 1558651522.473839283
time_check b: 1558651522.488913059
time_check b: 1558651522.460195541
time_check b: 1558651522.472080946
time_check b: 1558651522.485886097
time_check b: 1558651522.490793228
time_check b: 1558651522.484395742
time_check b: 1558651522.516121387
time_check b: 1558651522.487468481
time_check b: 1558651522.516477346
time_check b: 1558651522.565158606
time_check b: 1558651522.550026178
time_check b: 1558651522.540297508
:::MLL 1558651523.217 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558651523.218 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.659, Average Loss: 0.023, avg. samples / sec: 177.12
Iteration:      0, Loss function: 22.493, Average Loss: 0.022, avg. samples / sec: 179.66
Iteration:      0, Loss function: 22.684, Average Loss: 0.023, avg. samples / sec: 177.23
Iteration:      0, Loss function: 23.632, Average Loss: 0.024, avg. samples / sec: 176.76
Iteration:      0, Loss function: 22.526, Average Loss: 0.023, avg. samples / sec: 177.22
Iteration:      0, Loss function: 22.440, Average Loss: 0.022, avg. samples / sec: 164.58
Iteration:      0, Loss function: 23.576, Average Loss: 0.024, avg. samples / sec: 179.06
Iteration:      0, Loss function: 22.057, Average Loss: 0.022, avg. samples / sec: 177.51
Iteration:      0, Loss function: 22.817, Average Loss: 0.023, avg. samples / sec: 178.46
Iteration:      0, Loss function: 24.131, Average Loss: 0.024, avg. samples / sec: 177.37
Iteration:      0, Loss function: 22.225, Average Loss: 0.022, avg. samples / sec: 175.65
Iteration:      0, Loss function: 22.862, Average Loss: 0.023, avg. samples / sec: 178.01
Iteration:      0, Loss function: 22.259, Average Loss: 0.022, avg. samples / sec: 174.78
Iteration:      0, Loss function: 22.473, Average Loss: 0.022, avg. samples / sec: 175.92
Iteration:      0, Loss function: 22.402, Average Loss: 0.022, avg. samples / sec: 178.33
Iteration:      0, Loss function: 22.433, Average Loss: 0.022, avg. samples / sec: 175.51
Iteration:      0, Loss function: 22.173, Average Loss: 0.022, avg. samples / sec: 176.17
Iteration:      0, Loss function: 22.723, Average Loss: 0.023, avg. samples / sec: 178.83
Iteration:      0, Loss function: 23.202, Average Loss: 0.023, avg. samples / sec: 178.02
Iteration:      0, Loss function: 22.551, Average Loss: 0.023, avg. samples / sec: 175.36
Iteration:      0, Loss function: 22.314, Average Loss: 0.022, avg. samples / sec: 176.96
Iteration:      0, Loss function: 22.089, Average Loss: 0.022, avg. samples / sec: 175.00
Iteration:      0, Loss function: 22.207, Average Loss: 0.022, avg. samples / sec: 177.32
Iteration:      0, Loss function: 22.584, Average Loss: 0.023, avg. samples / sec: 178.89
Iteration:      0, Loss function: 23.108, Average Loss: 0.023, avg. samples / sec: 176.07
Iteration:      0, Loss function: 22.163, Average Loss: 0.022, avg. samples / sec: 177.49
Iteration:      0, Loss function: 22.250, Average Loss: 0.022, avg. samples / sec: 177.89
Iteration:      0, Loss function: 22.535, Average Loss: 0.023, avg. samples / sec: 179.09
Iteration:      0, Loss function: 22.311, Average Loss: 0.022, avg. samples / sec: 175.11
Iteration:      0, Loss function: 22.950, Average Loss: 0.023, avg. samples / sec: 178.04
Iteration:     20, Loss function: 20.575, Average Loss: 0.445, avg. samples / sec: 43839.22
Iteration:     20, Loss function: 20.523, Average Loss: 0.442, avg. samples / sec: 42910.28
Iteration:     20, Loss function: 20.305, Average Loss: 0.442, avg. samples / sec: 43685.61
Iteration:     20, Loss function: 21.349, Average Loss: 0.446, avg. samples / sec: 43599.15
Iteration:     20, Loss function: 20.863, Average Loss: 0.441, avg. samples / sec: 43805.52
Iteration:     20, Loss function: 20.982, Average Loss: 0.444, avg. samples / sec: 43689.94
Iteration:     20, Loss function: 20.860, Average Loss: 0.449, avg. samples / sec: 44404.42
Iteration:     20, Loss function: 20.217, Average Loss: 0.443, avg. samples / sec: 43464.02
Iteration:     20, Loss function: 20.168, Average Loss: 0.442, avg. samples / sec: 43752.68
Iteration:     20, Loss function: 20.415, Average Loss: 0.442, avg. samples / sec: 43767.71
Iteration:     20, Loss function: 20.483, Average Loss: 0.442, avg. samples / sec: 43874.03
Iteration:     20, Loss function: 20.766, Average Loss: 0.441, avg. samples / sec: 43532.47
Iteration:     20, Loss function: 20.773, Average Loss: 0.446, avg. samples / sec: 43625.56
Iteration:     20, Loss function: 22.619, Average Loss: 0.445, avg. samples / sec: 43548.06
Iteration:     20, Loss function: 20.203, Average Loss: 0.442, avg. samples / sec: 43509.22
Iteration:     20, Loss function: 20.231, Average Loss: 0.441, avg. samples / sec: 43830.91
Iteration:     20, Loss function: 20.938, Average Loss: 0.443, avg. samples / sec: 43624.10
Iteration:     20, Loss function: 20.590, Average Loss: 0.439, avg. samples / sec: 43507.74
Iteration:     20, Loss function: 20.394, Average Loss: 0.440, avg. samples / sec: 43634.34
Iteration:     20, Loss function: 20.045, Average Loss: 0.444, avg. samples / sec: 43757.07
Iteration:     20, Loss function: 21.151, Average Loss: 0.445, avg. samples / sec: 43809.67
Iteration:     20, Loss function: 20.634, Average Loss: 0.446, avg. samples / sec: 43487.86
Iteration:     20, Loss function: 20.842, Average Loss: 0.439, avg. samples / sec: 43646.60
Iteration:     20, Loss function: 20.370, Average Loss: 0.444, avg. samples / sec: 43599.29
Iteration:     20, Loss function: 20.135, Average Loss: 0.442, avg. samples / sec: 43379.33
Iteration:     20, Loss function: 20.334, Average Loss: 0.439, avg. samples / sec: 43868.92
Iteration:     20, Loss function: 21.464, Average Loss: 0.443, avg. samples / sec: 43247.01
Iteration:     20, Loss function: 21.308, Average Loss: 0.443, avg. samples / sec: 43495.60
Iteration:     20, Loss function: 20.467, Average Loss: 0.440, avg. samples / sec: 43205.16
Iteration:     20, Loss function: 20.503, Average Loss: 0.449, avg. samples / sec: 43231.82
Iteration:     40, Loss function: 17.588, Average Loss: 0.827, avg. samples / sec: 62453.16
Iteration:     40, Loss function: 18.070, Average Loss: 0.833, avg. samples / sec: 62447.62
Iteration:     40, Loss function: 17.449, Average Loss: 0.830, avg. samples / sec: 62764.71
Iteration:     40, Loss function: 19.562, Average Loss: 0.835, avg. samples / sec: 62565.67
Iteration:     40, Loss function: 18.542, Average Loss: 0.829, avg. samples / sec: 62446.71
Iteration:     40, Loss function: 17.654, Average Loss: 0.838, avg. samples / sec: 62310.62
Iteration:     40, Loss function: 18.521, Average Loss: 0.833, avg. samples / sec: 62157.65
Iteration:     40, Loss function: 18.251, Average Loss: 0.828, avg. samples / sec: 62154.61
Iteration:     40, Loss function: 17.767, Average Loss: 0.828, avg. samples / sec: 62317.29
Iteration:     40, Loss function: 17.463, Average Loss: 0.829, avg. samples / sec: 62568.09
Iteration:     40, Loss function: 17.276, Average Loss: 0.828, avg. samples / sec: 62303.93
Iteration:     40, Loss function: 17.664, Average Loss: 0.823, avg. samples / sec: 62563.09
Iteration:     40, Loss function: 18.128, Average Loss: 0.836, avg. samples / sec: 62461.71
Iteration:     40, Loss function: 17.970, Average Loss: 0.828, avg. samples / sec: 62315.61
Iteration:     40, Loss function: 17.197, Average Loss: 0.822, avg. samples / sec: 62397.41
Iteration:     40, Loss function: 17.127, Average Loss: 0.829, avg. samples / sec: 62329.66
Iteration:     40, Loss function: 18.167, Average Loss: 0.831, avg. samples / sec: 61949.58
Iteration:     40, Loss function: 17.909, Average Loss: 0.830, avg. samples / sec: 62503.99
Iteration:     40, Loss function: 18.143, Average Loss: 0.828, avg. samples / sec: 62070.16
Iteration:     40, Loss function: 17.307, Average Loss: 0.828, avg. samples / sec: 62337.77
Iteration:     40, Loss function: 17.819, Average Loss: 0.824, avg. samples / sec: 62325.67
Iteration:     40, Loss function: 18.491, Average Loss: 0.830, avg. samples / sec: 62326.93
Iteration:     40, Loss function: 17.657, Average Loss: 0.832, avg. samples / sec: 62164.01
Iteration:     40, Loss function: 17.440, Average Loss: 0.828, avg. samples / sec: 62198.36
Iteration:     40, Loss function: 18.187, Average Loss: 0.830, avg. samples / sec: 61913.47
Iteration:     40, Loss function: 18.119, Average Loss: 0.830, avg. samples / sec: 61992.34
Iteration:     40, Loss function: 18.707, Average Loss: 0.833, avg. samples / sec: 61697.95
Iteration:     40, Loss function: 17.685, Average Loss: 0.826, avg. samples / sec: 61411.30
Iteration:     40, Loss function: 18.435, Average Loss: 0.836, avg. samples / sec: 61528.09
Iteration:     40, Loss function: 18.283, Average Loss: 0.828, avg. samples / sec: 61373.59
Iteration:     60, Loss function: 11.265, Average Loss: 1.083, avg. samples / sec: 64802.90
Iteration:     60, Loss function: 12.192, Average Loss: 1.082, avg. samples / sec: 65897.20
Iteration:     60, Loss function: 11.895, Average Loss: 1.097, avg. samples / sec: 65757.36
Iteration:     60, Loss function: 11.620, Average Loss: 1.094, avg. samples / sec: 64527.58
Iteration:     60, Loss function: 12.773, Average Loss: 1.083, avg. samples / sec: 64114.91
Iteration:     60, Loss function: 12.597, Average Loss: 1.093, avg. samples / sec: 64257.63
Iteration:     60, Loss function: 10.367, Average Loss: 1.085, avg. samples / sec: 64299.38
Iteration:     60, Loss function: 12.166, Average Loss: 1.092, avg. samples / sec: 64344.09
Iteration:     60, Loss function: 12.884, Average Loss: 1.083, avg. samples / sec: 64184.47
Iteration:     60, Loss function: 11.109, Average Loss: 1.080, avg. samples / sec: 65357.32
Iteration:     60, Loss function: 12.314, Average Loss: 1.085, avg. samples / sec: 64386.54
Iteration:     60, Loss function: 12.393, Average Loss: 1.093, avg. samples / sec: 64716.01
Iteration:     60, Loss function: 10.665, Average Loss: 1.072, avg. samples / sec: 64273.25
Iteration:     60, Loss function: 13.443, Average Loss: 1.085, avg. samples / sec: 64438.24
Iteration:     60, Loss function: 14.029, Average Loss: 1.081, avg. samples / sec: 64610.85
Iteration:     60, Loss function: 13.393, Average Loss: 1.088, avg. samples / sec: 63972.07
Iteration:     60, Loss function: 11.891, Average Loss: 1.079, avg. samples / sec: 64352.93
Iteration:     60, Loss function: 13.234, Average Loss: 1.079, avg. samples / sec: 64293.25
Iteration:     60, Loss function: 12.075, Average Loss: 1.092, avg. samples / sec: 64172.83
Iteration:     60, Loss function: 12.233, Average Loss: 1.089, avg. samples / sec: 64414.03
Iteration:     60, Loss function: 13.147, Average Loss: 1.094, avg. samples / sec: 64166.61
Iteration:     60, Loss function: 13.474, Average Loss: 1.090, avg. samples / sec: 64174.41
Iteration:     60, Loss function: 11.876, Average Loss: 1.079, avg. samples / sec: 64256.11
Iteration:     60, Loss function: 12.210, Average Loss: 1.084, avg. samples / sec: 64181.49
Iteration:     60, Loss function: 12.553, Average Loss: 1.093, avg. samples / sec: 64217.60
Iteration:     60, Loss function: 14.534, Average Loss: 1.090, avg. samples / sec: 63896.48
Iteration:     60, Loss function: 13.982, Average Loss: 1.088, avg. samples / sec: 63833.48
Iteration:     60, Loss function: 12.483, Average Loss: 1.088, avg. samples / sec: 64104.18
Iteration:     60, Loss function: 13.095, Average Loss: 1.085, avg. samples / sec: 64327.17
Iteration:     60, Loss function: 14.908, Average Loss: 1.090, avg. samples / sec: 63067.87
:::MLL 1558651525.986 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558651525.986 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 10.409, Average Loss: 1.290, avg. samples / sec: 64243.28
Iteration:     80, Loss function: 10.648, Average Loss: 1.283, avg. samples / sec: 64220.56
Iteration:     80, Loss function: 10.674, Average Loss: 1.276, avg. samples / sec: 64063.38
Iteration:     80, Loss function: 10.059, Average Loss: 1.285, avg. samples / sec: 64568.32
Iteration:     80, Loss function: 10.809, Average Loss: 1.279, avg. samples / sec: 64246.62
Iteration:     80, Loss function: 9.846, Average Loss: 1.277, avg. samples / sec: 64395.16
Iteration:     80, Loss function: 10.015, Average Loss: 1.287, avg. samples / sec: 64274.95
Iteration:     80, Loss function: 10.161, Average Loss: 1.284, avg. samples / sec: 64565.42
Iteration:     80, Loss function: 10.459, Average Loss: 1.289, avg. samples / sec: 64153.00
Iteration:     80, Loss function: 8.702, Average Loss: 1.277, avg. samples / sec: 64138.55
Iteration:     80, Loss function: 10.120, Average Loss: 1.285, avg. samples / sec: 64215.47
Iteration:     80, Loss function: 9.906, Average Loss: 1.280, avg. samples / sec: 64316.52
Iteration:     80, Loss function: 9.793, Average Loss: 1.288, avg. samples / sec: 65371.60
Iteration:     80, Loss function: 9.653, Average Loss: 1.272, avg. samples / sec: 64182.80
Iteration:     80, Loss function: 10.406, Average Loss: 1.290, avg. samples / sec: 64427.40
Iteration:     80, Loss function: 10.799, Average Loss: 1.281, avg. samples / sec: 64121.50
Iteration:     80, Loss function: 9.749, Average Loss: 1.278, avg. samples / sec: 64153.85
Iteration:     80, Loss function: 9.976, Average Loss: 1.282, avg. samples / sec: 64106.80
Iteration:     80, Loss function: 10.374, Average Loss: 1.289, avg. samples / sec: 64182.71
Iteration:     80, Loss function: 10.532, Average Loss: 1.270, avg. samples / sec: 64065.33
Iteration:     80, Loss function: 10.105, Average Loss: 1.285, avg. samples / sec: 64220.47
Iteration:     80, Loss function: 10.574, Average Loss: 1.291, avg. samples / sec: 64210.23
Iteration:     80, Loss function: 9.880, Average Loss: 1.295, avg. samples / sec: 63804.87
Iteration:     80, Loss function: 10.365, Average Loss: 1.280, avg. samples / sec: 64075.03
Iteration:     80, Loss function: 10.243, Average Loss: 1.279, avg. samples / sec: 63782.28
Iteration:     80, Loss function: 9.783, Average Loss: 1.290, avg. samples / sec: 64048.27
Iteration:     80, Loss function: 10.139, Average Loss: 1.291, avg. samples / sec: 63757.29
Iteration:     80, Loss function: 10.582, Average Loss: 1.276, avg. samples / sec: 63851.32
Iteration:     80, Loss function: 10.021, Average Loss: 1.277, avg. samples / sec: 63745.50
Iteration:     80, Loss function: 10.026, Average Loss: 1.290, avg. samples / sec: 63750.23
Iteration:    100, Loss function: 9.269, Average Loss: 1.450, avg. samples / sec: 66278.80
Iteration:    100, Loss function: 9.195, Average Loss: 1.458, avg. samples / sec: 66082.51
Iteration:    100, Loss function: 9.738, Average Loss: 1.460, avg. samples / sec: 66036.12
Iteration:    100, Loss function: 9.325, Average Loss: 1.445, avg. samples / sec: 66064.70
Iteration:    100, Loss function: 9.526, Average Loss: 1.463, avg. samples / sec: 65643.30
Iteration:    100, Loss function: 9.183, Average Loss: 1.463, avg. samples / sec: 65821.67
Iteration:    100, Loss function: 10.260, Average Loss: 1.453, avg. samples / sec: 65823.73
Iteration:    100, Loss function: 9.235, Average Loss: 1.463, avg. samples / sec: 66035.88
Iteration:    100, Loss function: 9.751, Average Loss: 1.456, avg. samples / sec: 65727.31
Iteration:    100, Loss function: 9.405, Average Loss: 1.457, avg. samples / sec: 65682.00
Iteration:    100, Loss function: 10.059, Average Loss: 1.459, avg. samples / sec: 65754.51
Iteration:    100, Loss function: 9.167, Average Loss: 1.463, avg. samples / sec: 65813.04
Iteration:    100, Loss function: 10.485, Average Loss: 1.468, avg. samples / sec: 65887.90
Iteration:    100, Loss function: 9.770, Average Loss: 1.464, avg. samples / sec: 65710.88
Iteration:    100, Loss function: 10.137, Average Loss: 1.454, avg. samples / sec: 65860.19
Iteration:    100, Loss function: 9.813, Average Loss: 1.451, avg. samples / sec: 65658.84
Iteration:    100, Loss function: 9.815, Average Loss: 1.453, avg. samples / sec: 65703.62
Iteration:    100, Loss function: 9.873, Average Loss: 1.453, avg. samples / sec: 65774.09
Iteration:    100, Loss function: 9.558, Average Loss: 1.452, avg. samples / sec: 65658.99
Iteration:    100, Loss function: 9.042, Average Loss: 1.457, avg. samples / sec: 65595.64
Iteration:    100, Loss function: 9.447, Average Loss: 1.450, avg. samples / sec: 65541.58
Iteration:    100, Loss function: 9.410, Average Loss: 1.446, avg. samples / sec: 65483.62
Iteration:    100, Loss function: 9.781, Average Loss: 1.452, avg. samples / sec: 65471.73
Iteration:    100, Loss function: 10.318, Average Loss: 1.453, avg. samples / sec: 65749.48
Iteration:    100, Loss function: 9.196, Average Loss: 1.457, avg. samples / sec: 65891.38
Iteration:    100, Loss function: 9.971, Average Loss: 1.450, avg. samples / sec: 65463.91
Iteration:    100, Loss function: 9.394, Average Loss: 1.449, avg. samples / sec: 65568.26
Iteration:    100, Loss function: 9.650, Average Loss: 1.443, avg. samples / sec: 65527.59
Iteration:    100, Loss function: 9.872, Average Loss: 1.440, avg. samples / sec: 65610.57
Iteration:    100, Loss function: 10.043, Average Loss: 1.455, avg. samples / sec: 65196.16
Iteration:    120, Loss function: 8.350, Average Loss: 1.599, avg. samples / sec: 65579.88
Iteration:    120, Loss function: 8.991, Average Loss: 1.607, avg. samples / sec: 65596.73
Iteration:    120, Loss function: 8.771, Average Loss: 1.619, avg. samples / sec: 65603.91
Iteration:    120, Loss function: 9.443, Average Loss: 1.602, avg. samples / sec: 65316.82
Iteration:    120, Loss function: 8.834, Average Loss: 1.600, avg. samples / sec: 65644.64
Iteration:    120, Loss function: 9.662, Average Loss: 1.601, avg. samples / sec: 65471.94
Iteration:    120, Loss function: 9.805, Average Loss: 1.601, avg. samples / sec: 65710.88
Iteration:    120, Loss function: 9.578, Average Loss: 1.618, avg. samples / sec: 65535.91
Iteration:    120, Loss function: 9.628, Average Loss: 1.600, avg. samples / sec: 65542.86
Iteration:    120, Loss function: 9.058, Average Loss: 1.610, avg. samples / sec: 65274.16
Iteration:    120, Loss function: 9.249, Average Loss: 1.605, avg. samples / sec: 65877.92
Iteration:    120, Loss function: 8.633, Average Loss: 1.603, avg. samples / sec: 65539.38
Iteration:    120, Loss function: 9.813, Average Loss: 1.605, avg. samples / sec: 65490.41
Iteration:    120, Loss function: 8.800, Average Loss: 1.604, avg. samples / sec: 65584.86
Iteration:    120, Loss function: 9.712, Average Loss: 1.608, avg. samples / sec: 65416.75
Iteration:    120, Loss function: 9.070, Average Loss: 1.619, avg. samples / sec: 65388.80
Iteration:    120, Loss function: 9.012, Average Loss: 1.608, avg. samples / sec: 65463.39
Iteration:    120, Loss function: 9.054, Average Loss: 1.601, avg. samples / sec: 65504.69
Iteration:    120, Loss function: 9.792, Average Loss: 1.594, avg. samples / sec: 65595.06
Iteration:    120, Loss function: 8.916, Average Loss: 1.609, avg. samples / sec: 65510.59
Iteration:    120, Loss function: 10.285, Average Loss: 1.606, avg. samples / sec: 65365.20
Iteration:    120, Loss function: 7.921, Average Loss: 1.593, avg. samples / sec: 65418.27
Iteration:    120, Loss function: 9.622, Average Loss: 1.614, avg. samples / sec: 65226.85
Iteration:    120, Loss function: 9.890, Average Loss: 1.588, avg. samples / sec: 65488.00
Iteration:    120, Loss function: 8.647, Average Loss: 1.597, avg. samples / sec: 65469.90
Iteration:    120, Loss function: 9.681, Average Loss: 1.598, avg. samples / sec: 65300.78
Iteration:    120, Loss function: 9.782, Average Loss: 1.609, avg. samples / sec: 65209.59
Iteration:    120, Loss function: 8.151, Average Loss: 1.608, avg. samples / sec: 65112.48
Iteration:    120, Loss function: 9.039, Average Loss: 1.614, avg. samples / sec: 64997.53
Iteration:    120, Loss function: 8.225, Average Loss: 1.615, avg. samples / sec: 64928.11
:::MLL 1558651527.780 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558651527.781 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 8.565, Average Loss: 1.754, avg. samples / sec: 65939.91
Iteration:    140, Loss function: 8.745, Average Loss: 1.735, avg. samples / sec: 65833.60
Iteration:    140, Loss function: 8.207, Average Loss: 1.742, avg. samples / sec: 65549.93
Iteration:    140, Loss function: 8.287, Average Loss: 1.767, avg. samples / sec: 65647.49
Iteration:    140, Loss function: 8.951, Average Loss: 1.752, avg. samples / sec: 65961.05
Iteration:    140, Loss function: 8.693, Average Loss: 1.756, avg. samples / sec: 66192.57
Iteration:    140, Loss function: 9.038, Average Loss: 1.749, avg. samples / sec: 65703.37
Iteration:    140, Loss function: 9.262, Average Loss: 1.741, avg. samples / sec: 65880.91
Iteration:    140, Loss function: 9.032, Average Loss: 1.744, avg. samples / sec: 65584.07
Iteration:    140, Loss function: 8.556, Average Loss: 1.749, avg. samples / sec: 65679.34
Iteration:    140, Loss function: 8.301, Average Loss: 1.748, avg. samples / sec: 65794.69
Iteration:    140, Loss function: 8.773, Average Loss: 1.747, avg. samples / sec: 65560.79
Iteration:    140, Loss function: 7.996, Average Loss: 1.753, avg. samples / sec: 65603.54
Iteration:    140, Loss function: 8.877, Average Loss: 1.747, avg. samples / sec: 65705.30
Iteration:    140, Loss function: 8.625, Average Loss: 1.763, avg. samples / sec: 65462.63
Iteration:    140, Loss function: 8.966, Average Loss: 1.753, avg. samples / sec: 65830.62
Iteration:    140, Loss function: 8.485, Average Loss: 1.744, avg. samples / sec: 65559.38
Iteration:    140, Loss function: 10.063, Average Loss: 1.737, avg. samples / sec: 65674.23
Iteration:    140, Loss function: 8.712, Average Loss: 1.743, avg. samples / sec: 65450.84
Iteration:    140, Loss function: 9.184, Average Loss: 1.751, avg. samples / sec: 65483.74
Iteration:    140, Loss function: 8.656, Average Loss: 1.754, avg. samples / sec: 65570.67
Iteration:    140, Loss function: 8.969, Average Loss: 1.758, avg. samples / sec: 65549.08
Iteration:    140, Loss function: 9.817, Average Loss: 1.748, avg. samples / sec: 65450.20
Iteration:    140, Loss function: 8.666, Average Loss: 1.743, avg. samples / sec: 65690.11
Iteration:    140, Loss function: 8.906, Average Loss: 1.749, avg. samples / sec: 65470.54
Iteration:    140, Loss function: 9.491, Average Loss: 1.731, avg. samples / sec: 65630.70
Iteration:    140, Loss function: 8.699, Average Loss: 1.749, avg. samples / sec: 65266.33
Iteration:    140, Loss function: 8.552, Average Loss: 1.757, avg. samples / sec: 65787.05
Iteration:    140, Loss function: 8.443, Average Loss: 1.748, avg. samples / sec: 65278.82
Iteration:    140, Loss function: 8.957, Average Loss: 1.755, avg. samples / sec: 65285.62
Iteration:    160, Loss function: 8.364, Average Loss: 1.908, avg. samples / sec: 65372.84
Iteration:    160, Loss function: 8.113, Average Loss: 1.888, avg. samples / sec: 65437.74
Iteration:    160, Loss function: 9.169, Average Loss: 1.886, avg. samples / sec: 65382.36
Iteration:    160, Loss function: 8.133, Average Loss: 1.887, avg. samples / sec: 65268.48
Iteration:    160, Loss function: 8.018, Average Loss: 1.879, avg. samples / sec: 65286.29
Iteration:    160, Loss function: 8.607, Average Loss: 1.883, avg. samples / sec: 65344.83
Iteration:    160, Loss function: 9.034, Average Loss: 1.875, avg. samples / sec: 65429.39
Iteration:    160, Loss function: 8.246, Average Loss: 1.892, avg. samples / sec: 65264.43
Iteration:    160, Loss function: 7.945, Average Loss: 1.879, avg. samples / sec: 65413.20
Iteration:    160, Loss function: 7.913, Average Loss: 1.887, avg. samples / sec: 65761.26
Iteration:    160, Loss function: 8.702, Average Loss: 1.885, avg. samples / sec: 65503.92
Iteration:    160, Loss function: 8.629, Average Loss: 1.885, avg. samples / sec: 65473.49
Iteration:    160, Loss function: 8.627, Average Loss: 1.871, avg. samples / sec: 65196.95
Iteration:    160, Loss function: 8.725, Average Loss: 1.906, avg. samples / sec: 65334.41
Iteration:    160, Loss function: 9.131, Average Loss: 1.888, avg. samples / sec: 65541.18
Iteration:    160, Loss function: 8.693, Average Loss: 1.886, avg. samples / sec: 65237.24
Iteration:    160, Loss function: 7.567, Average Loss: 1.876, avg. samples / sec: 65228.78
Iteration:    160, Loss function: 7.744, Average Loss: 1.887, avg. samples / sec: 65493.70
Iteration:    160, Loss function: 8.116, Average Loss: 1.893, avg. samples / sec: 65392.13
Iteration:    160, Loss function: 8.028, Average Loss: 1.876, avg. samples / sec: 65216.59
Iteration:    160, Loss function: 8.377, Average Loss: 1.868, avg. samples / sec: 65447.53
Iteration:    160, Loss function: 7.932, Average Loss: 1.886, avg. samples / sec: 65451.02
Iteration:    160, Loss function: 8.343, Average Loss: 1.885, avg. samples / sec: 65146.89
Iteration:    160, Loss function: 8.849, Average Loss: 1.887, avg. samples / sec: 65233.07
Iteration:    160, Loss function: 8.722, Average Loss: 1.878, avg. samples / sec: 65356.77
Iteration:    160, Loss function: 9.295, Average Loss: 1.892, avg. samples / sec: 65200.90
Iteration:    160, Loss function: 8.299, Average Loss: 1.885, avg. samples / sec: 65259.47
Iteration:    160, Loss function: 8.575, Average Loss: 1.892, avg. samples / sec: 65247.45
Iteration:    160, Loss function: 7.794, Average Loss: 1.882, avg. samples / sec: 65142.19
Iteration:    160, Loss function: 8.161, Average Loss: 1.882, avg. samples / sec: 65044.45
Iteration:    180, Loss function: 9.296, Average Loss: 2.021, avg. samples / sec: 65778.48
Iteration:    180, Loss function: 8.566, Average Loss: 2.022, avg. samples / sec: 65791.87
Iteration:    180, Loss function: 8.272, Average Loss: 2.041, avg. samples / sec: 65542.00
Iteration:    180, Loss function: 8.213, Average Loss: 2.017, avg. samples / sec: 65719.18
Iteration:    180, Loss function: 9.323, Average Loss: 2.025, avg. samples / sec: 65654.74
Iteration:    180, Loss function: 7.873, Average Loss: 2.014, avg. samples / sec: 65834.40
Iteration:    180, Loss function: 8.440, Average Loss: 2.019, avg. samples / sec: 65685.18
Iteration:    180, Loss function: 8.795, Average Loss: 2.002, avg. samples / sec: 65680.65
Iteration:    180, Loss function: 8.676, Average Loss: 2.013, avg. samples / sec: 65595.30
Iteration:    180, Loss function: 7.840, Average Loss: 2.002, avg. samples / sec: 65614.45
Iteration:    180, Loss function: 7.936, Average Loss: 2.008, avg. samples / sec: 65629.15
Iteration:    180, Loss function: 8.434, Average Loss: 2.013, avg. samples / sec: 65774.76
Iteration:    180, Loss function: 8.324, Average Loss: 2.019, avg. samples / sec: 65536.91
Iteration:    180, Loss function: 9.319, Average Loss: 2.007, avg. samples / sec: 65559.90
Iteration:    180, Loss function: 8.153, Average Loss: 2.014, avg. samples / sec: 65597.86
Iteration:    180, Loss function: 7.787, Average Loss: 2.026, avg. samples / sec: 65657.80
Iteration:    180, Loss function: 8.856, Average Loss: 2.017, avg. samples / sec: 65522.01
Iteration:    180, Loss function: 7.428, Average Loss: 2.019, avg. samples / sec: 65554.41
Iteration:    180, Loss function: 8.948, Average Loss: 2.015, avg. samples / sec: 65460.60
Iteration:    180, Loss function: 8.107, Average Loss: 2.018, avg. samples / sec: 65350.89
Iteration:    180, Loss function: 8.030, Average Loss: 2.011, avg. samples / sec: 65339.23
Iteration:    180, Loss function: 8.054, Average Loss: 2.027, avg. samples / sec: 65445.70
Iteration:    180, Loss function: 8.102, Average Loss: 2.018, avg. samples / sec: 65266.00
Iteration:    180, Loss function: 8.248, Average Loss: 2.016, avg. samples / sec: 65338.74
Iteration:    180, Loss function: 9.572, Average Loss: 2.040, avg. samples / sec: 65355.11
Iteration:    180, Loss function: 9.109, Average Loss: 2.015, avg. samples / sec: 65582.84
Iteration:    180, Loss function: 7.767, Average Loss: 2.008, avg. samples / sec: 65458.68
Iteration:    180, Loss function: 7.969, Average Loss: 2.018, avg. samples / sec: 65216.05
Iteration:    180, Loss function: 8.792, Average Loss: 2.003, avg. samples / sec: 65241.98
Iteration:    180, Loss function: 8.834, Average Loss: 2.025, avg. samples / sec: 65462.24
Iteration:    200, Loss function: 8.014, Average Loss: 2.140, avg. samples / sec: 65127.50
Iteration:    200, Loss function: 8.506, Average Loss: 2.151, avg. samples / sec: 65258.42
Iteration:    200, Loss function: 9.327, Average Loss: 2.143, avg. samples / sec: 65163.52
Iteration:    200, Loss function: 7.629, Average Loss: 2.142, avg. samples / sec: 64984.73
Iteration:    200, Loss function: 8.466, Average Loss: 2.154, avg. samples / sec: 64974.51
Iteration:    200, Loss function: 8.409, Average Loss: 2.148, avg. samples / sec: 64697.38
Iteration:    200, Loss function: 8.591, Average Loss: 2.138, avg. samples / sec: 64967.47
Iteration:    200, Loss function: 7.899, Average Loss: 2.131, avg. samples / sec: 65202.95
Iteration:    200, Loss function: 9.029, Average Loss: 2.138, avg. samples / sec: 64833.40
Iteration:    200, Loss function: 7.832, Average Loss: 2.170, avg. samples / sec: 64765.58
Iteration:    200, Loss function: 7.504, Average Loss: 2.138, avg. samples / sec: 65123.59
Iteration:    200, Loss function: 9.397, Average Loss: 2.146, avg. samples / sec: 65060.48
Iteration:    200, Loss function: 7.976, Average Loss: 2.135, avg. samples / sec: 64937.03
Iteration:    200, Loss function: 8.279, Average Loss: 2.145, avg. samples / sec: 64897.35
Iteration:    200, Loss function: 9.144, Average Loss: 2.125, avg. samples / sec: 64811.12
Iteration:    200, Loss function: 7.670, Average Loss: 2.138, avg. samples / sec: 64917.14
Iteration:    200, Loss function: 8.385, Average Loss: 2.134, avg. samples / sec: 64838.29
Iteration:    200, Loss function: 9.688, Average Loss: 2.149, avg. samples / sec: 64793.16
Iteration:    200, Loss function: 7.567, Average Loss: 2.151, avg. samples / sec: 64733.16
Iteration:    200, Loss function: 9.031, Average Loss: 2.148, avg. samples / sec: 64694.50
Iteration:    200, Loss function: 8.319, Average Loss: 2.165, avg. samples / sec: 64999.45
Iteration:    200, Loss function: 8.233, Average Loss: 2.142, avg. samples / sec: 64808.32
Iteration:    200, Loss function: 7.623, Average Loss: 2.144, avg. samples / sec: 64882.41
Iteration:    200, Loss function: 8.456, Average Loss: 2.138, avg. samples / sec: 64684.07
Iteration:    200, Loss function: 8.680, Average Loss: 2.139, avg. samples / sec: 64916.84
Iteration:    200, Loss function: 7.592, Average Loss: 2.132, avg. samples / sec: 64971.01
Iteration:    200, Loss function: 8.438, Average Loss: 2.142, avg. samples / sec: 64627.12
Iteration:    200, Loss function: 8.568, Average Loss: 2.141, avg. samples / sec: 64890.45
Iteration:    200, Loss function: 9.484, Average Loss: 2.128, avg. samples / sec: 64671.84
Iteration:    200, Loss function: 8.422, Average Loss: 2.156, avg. samples / sec: 64844.26
:::MLL 1558651529.583 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558651529.584 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 7.761, Average Loss: 2.246, avg. samples / sec: 65071.72
Iteration:    220, Loss function: 9.062, Average Loss: 2.263, avg. samples / sec: 65037.75
Iteration:    220, Loss function: 7.786, Average Loss: 2.255, avg. samples / sec: 64954.18
Iteration:    220, Loss function: 8.566, Average Loss: 2.258, avg. samples / sec: 65062.25
Iteration:    220, Loss function: 7.779, Average Loss: 2.250, avg. samples / sec: 65050.15
Iteration:    220, Loss function: 8.014, Average Loss: 2.261, avg. samples / sec: 65052.94
Iteration:    220, Loss function: 8.728, Average Loss: 2.257, avg. samples / sec: 65017.89
Iteration:    220, Loss function: 8.568, Average Loss: 2.257, avg. samples / sec: 64974.33
Iteration:    220, Loss function: 7.046, Average Loss: 2.251, avg. samples / sec: 65113.60
Iteration:    220, Loss function: 7.405, Average Loss: 2.259, avg. samples / sec: 65098.32
Iteration:    220, Loss function: 7.420, Average Loss: 2.249, avg. samples / sec: 65007.12
Iteration:    220, Loss function: 8.431, Average Loss: 2.256, avg. samples / sec: 65099.61
Iteration:    220, Loss function: 8.508, Average Loss: 2.269, avg. samples / sec: 65028.75
Iteration:    220, Loss function: 8.634, Average Loss: 2.287, avg. samples / sec: 65049.55
Iteration:    220, Loss function: 7.786, Average Loss: 2.264, avg. samples / sec: 64955.77
Iteration:    220, Loss function: 8.160, Average Loss: 2.242, avg. samples / sec: 64950.17
Iteration:    220, Loss function: 7.489, Average Loss: 2.254, avg. samples / sec: 65147.10
Iteration:    220, Loss function: 7.933, Average Loss: 2.246, avg. samples / sec: 65093.24
Iteration:    220, Loss function: 7.827, Average Loss: 2.285, avg. samples / sec: 64912.05
Iteration:    220, Loss function: 7.980, Average Loss: 2.270, avg. samples / sec: 64875.42
Iteration:    220, Loss function: 7.354, Average Loss: 2.268, avg. samples / sec: 64943.88
Iteration:    220, Loss function: 8.807, Average Loss: 2.249, avg. samples / sec: 65025.03
Iteration:    220, Loss function: 7.861, Average Loss: 2.257, avg. samples / sec: 64881.63
Iteration:    220, Loss function: 8.325, Average Loss: 2.261, avg. samples / sec: 64841.66
Iteration:    220, Loss function: 7.804, Average Loss: 2.257, avg. samples / sec: 64972.81
Iteration:    220, Loss function: 8.358, Average Loss: 2.269, avg. samples / sec: 64784.40
Iteration:    220, Loss function: 7.181, Average Loss: 2.261, avg. samples / sec: 64773.83
Iteration:    220, Loss function: 7.840, Average Loss: 2.251, avg. samples / sec: 64805.10
Iteration:    220, Loss function: 7.340, Average Loss: 2.256, avg. samples / sec: 64927.79
Iteration:    220, Loss function: 7.819, Average Loss: 2.267, avg. samples / sec: 64979.49
Iteration:    240, Loss function: 7.048, Average Loss: 2.391, avg. samples / sec: 66036.77
Iteration:    240, Loss function: 8.238, Average Loss: 2.374, avg. samples / sec: 65898.07
Iteration:    240, Loss function: 6.964, Average Loss: 2.361, avg. samples / sec: 65953.45
Iteration:    240, Loss function: 8.546, Average Loss: 2.362, avg. samples / sec: 65900.56
Iteration:    240, Loss function: 7.494, Average Loss: 2.365, avg. samples / sec: 66025.23
Iteration:    240, Loss function: 7.509, Average Loss: 2.361, avg. samples / sec: 65940.52
Iteration:    240, Loss function: 7.001, Average Loss: 2.371, avg. samples / sec: 65851.08
Iteration:    240, Loss function: 8.064, Average Loss: 2.375, avg. samples / sec: 65909.38
Iteration:    240, Loss function: 8.092, Average Loss: 2.381, avg. samples / sec: 65899.76
Iteration:    240, Loss function: 8.148, Average Loss: 2.363, avg. samples / sec: 65849.72
Iteration:    240, Loss function: 8.293, Average Loss: 2.356, avg. samples / sec: 65764.33
Iteration:    240, Loss function: 8.401, Average Loss: 2.365, avg. samples / sec: 65768.87
Iteration:    240, Loss function: 8.040, Average Loss: 2.361, avg. samples / sec: 66024.37
Iteration:    240, Loss function: 8.239, Average Loss: 2.351, avg. samples / sec: 65888.36
Iteration:    240, Loss function: 7.756, Average Loss: 2.368, avg. samples / sec: 65904.48
Iteration:    240, Loss function: 7.157, Average Loss: 2.365, avg. samples / sec: 65901.27
Iteration:    240, Loss function: 7.028, Average Loss: 2.366, avg. samples / sec: 65783.61
Iteration:    240, Loss function: 7.486, Average Loss: 2.372, avg. samples / sec: 65948.55
Iteration:    240, Loss function: 8.279, Average Loss: 2.366, avg. samples / sec: 65769.85
Iteration:    240, Loss function: 7.568, Average Loss: 2.374, avg. samples / sec: 65868.19
Iteration:    240, Loss function: 7.511, Average Loss: 2.365, avg. samples / sec: 65693.70
Iteration:    240, Loss function: 7.593, Average Loss: 2.366, avg. samples / sec: 65948.70
Iteration:    240, Loss function: 9.246, Average Loss: 2.383, avg. samples / sec: 65869.67
Iteration:    240, Loss function: 8.449, Average Loss: 2.369, avg. samples / sec: 65712.63
Iteration:    240, Loss function: 7.745, Average Loss: 2.393, avg. samples / sec: 65769.09
Iteration:    240, Loss function: 8.292, Average Loss: 2.355, avg. samples / sec: 65712.01
Iteration:    240, Loss function: 7.575, Average Loss: 2.373, avg. samples / sec: 65858.71
Iteration:    240, Loss function: 7.866, Average Loss: 2.369, avg. samples / sec: 65604.92
Iteration:    240, Loss function: 8.008, Average Loss: 2.356, avg. samples / sec: 65716.64
Iteration:    240, Loss function: 7.371, Average Loss: 2.379, avg. samples / sec: 65581.17
Iteration:    260, Loss function: 7.801, Average Loss: 2.480, avg. samples / sec: 65727.12
Iteration:    260, Loss function: 8.037, Average Loss: 2.480, avg. samples / sec: 65800.35
Iteration:    260, Loss function: 8.198, Average Loss: 2.501, avg. samples / sec: 65745.43
Iteration:    260, Loss function: 8.030, Average Loss: 2.491, avg. samples / sec: 65628.08
Iteration:    260, Loss function: 7.955, Average Loss: 2.510, avg. samples / sec: 65579.95
Iteration:    260, Loss function: 8.125, Average Loss: 2.506, avg. samples / sec: 65872.93
Iteration:    260, Loss function: 8.791, Average Loss: 2.479, avg. samples / sec: 65697.95
Iteration:    260, Loss function: 7.630, Average Loss: 2.483, avg. samples / sec: 65851.02
Iteration:    260, Loss function: 7.661, Average Loss: 2.482, avg. samples / sec: 65672.30
Iteration:    260, Loss function: 7.965, Average Loss: 2.489, avg. samples / sec: 65769.70
Iteration:    260, Loss function: 7.932, Average Loss: 2.472, avg. samples / sec: 65714.25
Iteration:    260, Loss function: 8.181, Average Loss: 2.486, avg. samples / sec: 65777.93
Iteration:    260, Loss function: 7.211, Average Loss: 2.493, avg. samples / sec: 66044.26
Iteration:    260, Loss function: 7.739, Average Loss: 2.490, avg. samples / sec: 65923.56
Iteration:    260, Loss function: 7.946, Average Loss: 2.485, avg. samples / sec: 65820.41
Iteration:    260, Loss function: 8.413, Average Loss: 2.486, avg. samples / sec: 65754.88
Iteration:    260, Loss function: 8.142, Average Loss: 2.493, avg. samples / sec: 65632.45
Iteration:    260, Loss function: 7.513, Average Loss: 2.484, avg. samples / sec: 65605.86
Iteration:    260, Loss function: 8.399, Average Loss: 2.491, avg. samples / sec: 65728.50
Iteration:    260, Loss function: 7.569, Average Loss: 2.485, avg. samples / sec: 65685.03
Iteration:    260, Loss function: 8.973, Average Loss: 2.483, avg. samples / sec: 65604.09
Iteration:    260, Loss function: 9.054, Average Loss: 2.483, avg. samples / sec: 65654.74
Iteration:    260, Loss function: 8.439, Average Loss: 2.501, avg. samples / sec: 65723.20
Iteration:    260, Loss function: 7.700, Average Loss: 2.470, avg. samples / sec: 65643.57
Iteration:    260, Loss function: 7.448, Average Loss: 2.477, avg. samples / sec: 65851.05
Iteration:    260, Loss function: 8.156, Average Loss: 2.494, avg. samples / sec: 65560.73
Iteration:    260, Loss function: 7.304, Average Loss: 2.489, avg. samples / sec: 65799.70
Iteration:    260, Loss function: 7.726, Average Loss: 2.474, avg. samples / sec: 65717.62
Iteration:    260, Loss function: 8.449, Average Loss: 2.484, avg. samples / sec: 65594.44
Iteration:    260, Loss function: 7.888, Average Loss: 2.481, avg. samples / sec: 65565.12
:::MLL 1558651531.374 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558651531.374 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 7.591, Average Loss: 2.615, avg. samples / sec: 66038.75
Iteration:    280, Loss function: 9.304, Average Loss: 2.589, avg. samples / sec: 66133.55
Iteration:    280, Loss function: 8.765, Average Loss: 2.592, avg. samples / sec: 66008.75
Iteration:    280, Loss function: 7.893, Average Loss: 2.588, avg. samples / sec: 66095.59
Iteration:    280, Loss function: 7.353, Average Loss: 2.604, avg. samples / sec: 65982.42
Iteration:    280, Loss function: 7.303, Average Loss: 2.578, avg. samples / sec: 66009.65
Iteration:    280, Loss function: 7.027, Average Loss: 2.590, avg. samples / sec: 66011.50
Iteration:    280, Loss function: 7.803, Average Loss: 2.584, avg. samples / sec: 65931.33
Iteration:    280, Loss function: 7.759, Average Loss: 2.595, avg. samples / sec: 65982.36
Iteration:    280, Loss function: 7.945, Average Loss: 2.582, avg. samples / sec: 66050.30
Iteration:    280, Loss function: 7.597, Average Loss: 2.602, avg. samples / sec: 66087.50
Iteration:    280, Loss function: 7.688, Average Loss: 2.598, avg. samples / sec: 66002.01
Iteration:    280, Loss function: 6.538, Average Loss: 2.585, avg. samples / sec: 66032.13
Iteration:    280, Loss function: 8.836, Average Loss: 2.585, avg. samples / sec: 65813.34
Iteration:    280, Loss function: 7.105, Average Loss: 2.581, avg. samples / sec: 66127.62
Iteration:    280, Loss function: 7.306, Average Loss: 2.576, avg. samples / sec: 66087.75
Iteration:    280, Loss function: 8.022, Average Loss: 2.583, avg. samples / sec: 65860.06
Iteration:    280, Loss function: 8.026, Average Loss: 2.600, avg. samples / sec: 65950.92
Iteration:    280, Loss function: 7.838, Average Loss: 2.584, avg. samples / sec: 66004.95
Iteration:    280, Loss function: 7.229, Average Loss: 2.593, avg. samples / sec: 65920.32
Iteration:    280, Loss function: 7.813, Average Loss: 2.606, avg. samples / sec: 65962.53
Iteration:    280, Loss function: 7.400, Average Loss: 2.580, avg. samples / sec: 65763.90
Iteration:    280, Loss function: 8.962, Average Loss: 2.586, avg. samples / sec: 65800.50
Iteration:    280, Loss function: 7.014, Average Loss: 2.589, avg. samples / sec: 65957.68
Iteration:    280, Loss function: 7.340, Average Loss: 2.608, avg. samples / sec: 65740.68
Iteration:    280, Loss function: 7.861, Average Loss: 2.595, avg. samples / sec: 65780.11
Iteration:    280, Loss function: 7.801, Average Loss: 2.587, avg. samples / sec: 65714.59
Iteration:    280, Loss function: 7.429, Average Loss: 2.589, avg. samples / sec: 65876.26
Iteration:    280, Loss function: 7.733, Average Loss: 2.577, avg. samples / sec: 65589.68
Iteration:    280, Loss function: 7.803, Average Loss: 2.589, avg. samples / sec: 65478.48
Iteration:    300, Loss function: 8.016, Average Loss: 2.681, avg. samples / sec: 65917.39
Iteration:    300, Loss function: 7.563, Average Loss: 2.687, avg. samples / sec: 65859.66
Iteration:    300, Loss function: 6.813, Average Loss: 2.687, avg. samples / sec: 65773.47
Iteration:    300, Loss function: 7.555, Average Loss: 2.670, avg. samples / sec: 65925.87
Iteration:    300, Loss function: 7.728, Average Loss: 2.679, avg. samples / sec: 65857.54
Iteration:    300, Loss function: 6.410, Average Loss: 2.685, avg. samples / sec: 65837.42
Iteration:    300, Loss function: 7.085, Average Loss: 2.709, avg. samples / sec: 65719.83
Iteration:    300, Loss function: 7.419, Average Loss: 2.676, avg. samples / sec: 65882.79
Iteration:    300, Loss function: 7.649, Average Loss: 2.685, avg. samples / sec: 65835.08
Iteration:    300, Loss function: 7.772, Average Loss: 2.682, avg. samples / sec: 66056.12
Iteration:    300, Loss function: 8.635, Average Loss: 2.681, avg. samples / sec: 65929.42
Iteration:    300, Loss function: 7.144, Average Loss: 2.683, avg. samples / sec: 65679.55
Iteration:    300, Loss function: 7.297, Average Loss: 2.697, avg. samples / sec: 65673.46
Iteration:    300, Loss function: 6.547, Average Loss: 2.672, avg. samples / sec: 66227.44
Iteration:    300, Loss function: 6.351, Average Loss: 2.672, avg. samples / sec: 65858.15
Iteration:    300, Loss function: 6.979, Average Loss: 2.694, avg. samples / sec: 65726.97
Iteration:    300, Loss function: 7.720, Average Loss: 2.690, avg. samples / sec: 65923.19
Iteration:    300, Loss function: 7.177, Average Loss: 2.692, avg. samples / sec: 65707.97
Iteration:    300, Loss function: 7.818, Average Loss: 2.682, avg. samples / sec: 65966.61
Iteration:    300, Loss function: 7.595, Average Loss: 2.687, avg. samples / sec: 65792.97
Iteration:    300, Loss function: 7.530, Average Loss: 2.682, avg. samples / sec: 65595.42
Iteration:    300, Loss function: 7.805, Average Loss: 2.683, avg. samples / sec: 65832.71
Iteration:    300, Loss function: 7.364, Average Loss: 2.699, avg. samples / sec: 65859.23
Iteration:    300, Loss function: 6.903, Average Loss: 2.677, avg. samples / sec: 65717.96
Iteration:    300, Loss function: 7.487, Average Loss: 2.673, avg. samples / sec: 65569.27
Iteration:    300, Loss function: 7.063, Average Loss: 2.678, avg. samples / sec: 66128.34
Iteration:    300, Loss function: 7.425, Average Loss: 2.696, avg. samples / sec: 65687.33
Iteration:    300, Loss function: 7.630, Average Loss: 2.699, avg. samples / sec: 65709.99
Iteration:    300, Loss function: 7.643, Average Loss: 2.676, avg. samples / sec: 65558.65
Iteration:    300, Loss function: 6.790, Average Loss: 2.676, avg. samples / sec: 65464.88
Iteration:    320, Loss function: 7.293, Average Loss: 2.774, avg. samples / sec: 66155.59
Iteration:    320, Loss function: 6.059, Average Loss: 2.775, avg. samples / sec: 66039.99
Iteration:    320, Loss function: 7.041, Average Loss: 2.766, avg. samples / sec: 66084.18
Iteration:    320, Loss function: 7.820, Average Loss: 2.771, avg. samples / sec: 66042.68
Iteration:    320, Loss function: 7.885, Average Loss: 2.790, avg. samples / sec: 66079.56
Iteration:    320, Loss function: 7.417, Average Loss: 2.795, avg. samples / sec: 66136.41
Iteration:    320, Loss function: 7.614, Average Loss: 2.769, avg. samples / sec: 66158.67
Iteration:    320, Loss function: 6.698, Average Loss: 2.775, avg. samples / sec: 65878.57
Iteration:    320, Loss function: 7.550, Average Loss: 2.802, avg. samples / sec: 65959.69
Iteration:    320, Loss function: 6.775, Average Loss: 2.774, avg. samples / sec: 65918.47
Iteration:    320, Loss function: 7.225, Average Loss: 2.775, avg. samples / sec: 65916.31
Iteration:    320, Loss function: 6.774, Average Loss: 2.768, avg. samples / sec: 65942.81
Iteration:    320, Loss function: 7.025, Average Loss: 2.771, avg. samples / sec: 66109.01
Iteration:    320, Loss function: 6.823, Average Loss: 2.789, avg. samples / sec: 66146.77
Iteration:    320, Loss function: 7.417, Average Loss: 2.784, avg. samples / sec: 66028.76
Iteration:    320, Loss function: 6.969, Average Loss: 2.768, avg. samples / sec: 66329.71
Iteration:    320, Loss function: 7.305, Average Loss: 2.769, avg. samples / sec: 65867.17
Iteration:    320, Loss function: 7.900, Average Loss: 2.769, avg. samples / sec: 66147.55
Iteration:    320, Loss function: 7.846, Average Loss: 2.777, avg. samples / sec: 65995.12
Iteration:    320, Loss function: 7.480, Average Loss: 2.773, avg. samples / sec: 66020.22
Iteration:    320, Loss function: 9.594, Average Loss: 2.796, avg. samples / sec: 66066.99
Iteration:    320, Loss function: 7.096, Average Loss: 2.780, avg. samples / sec: 65969.82
Iteration:    320, Loss function: 6.884, Average Loss: 2.773, avg. samples / sec: 65990.67
Iteration:    320, Loss function: 7.955, Average Loss: 2.765, avg. samples / sec: 65918.56
Iteration:    320, Loss function: 6.685, Average Loss: 2.777, avg. samples / sec: 65796.11
Iteration:    320, Loss function: 7.627, Average Loss: 2.780, avg. samples / sec: 65770.59
Iteration:    320, Loss function: 6.907, Average Loss: 2.770, avg. samples / sec: 66027.99
Iteration:    320, Loss function: 8.283, Average Loss: 2.785, avg. samples / sec: 65953.95
Iteration:    320, Loss function: 6.656, Average Loss: 2.781, avg. samples / sec: 65878.66
Iteration:    320, Loss function: 6.938, Average Loss: 2.777, avg. samples / sec: 65754.17
Iteration:    340, Loss function: 8.055, Average Loss: 2.862, avg. samples / sec: 66329.84
Iteration:    340, Loss function: 7.501, Average Loss: 2.866, avg. samples / sec: 66307.15
Iteration:    340, Loss function: 7.663, Average Loss: 2.857, avg. samples / sec: 66189.62
Iteration:    340, Loss function: 6.880, Average Loss: 2.875, avg. samples / sec: 66098.84
Iteration:    340, Loss function: 6.319, Average Loss: 2.860, avg. samples / sec: 66147.71
Iteration:    340, Loss function: 7.043, Average Loss: 2.870, avg. samples / sec: 66165.75
Iteration:    340, Loss function: 7.026, Average Loss: 2.864, avg. samples / sec: 66378.26
Iteration:    340, Loss function: 7.073, Average Loss: 2.883, avg. samples / sec: 66115.40
Iteration:    340, Loss function: 6.891, Average Loss: 2.858, avg. samples / sec: 66130.36
Iteration:    340, Loss function: 7.067, Average Loss: 2.871, avg. samples / sec: 66230.71
Iteration:    340, Loss function: 6.386, Average Loss: 2.855, avg. samples / sec: 66050.55
Iteration:    340, Loss function: 7.691, Average Loss: 2.860, avg. samples / sec: 66015.61
Iteration:    340, Loss function: 6.538, Average Loss: 2.859, avg. samples / sec: 66059.52
Iteration:    340, Loss function: 6.490, Average Loss: 2.859, avg. samples / sec: 65984.58
Iteration:    340, Loss function: 8.038, Average Loss: 2.859, avg. samples / sec: 66023.38
Iteration:    340, Loss function: 6.695, Average Loss: 2.862, avg. samples / sec: 66091.43
Iteration:    340, Loss function: 8.082, Average Loss: 2.859, avg. samples / sec: 66093.36
Iteration:    340, Loss function: 8.109, Average Loss: 2.858, avg. samples / sec: 66029.93
Iteration:    340, Loss function: 7.051, Average Loss: 2.873, avg. samples / sec: 66020.93
Iteration:    340, Loss function: 8.246, Average Loss: 2.856, avg. samples / sec: 66100.89
Iteration:    340, Loss function: 6.781, Average Loss: 2.864, avg. samples / sec: 66055.93
Iteration:    340, Loss function: 7.412, Average Loss: 2.890, avg. samples / sec: 65978.25
Iteration:    340, Loss function: 6.941, Average Loss: 2.855, avg. samples / sec: 65896.37
Iteration:    340, Loss function: 6.430, Average Loss: 2.858, avg. samples / sec: 65976.64
Iteration:    340, Loss function: 6.898, Average Loss: 2.856, avg. samples / sec: 65980.78
Iteration:    340, Loss function: 7.389, Average Loss: 2.861, avg. samples / sec: 66033.09
Iteration:    340, Loss function: 5.845, Average Loss: 2.867, avg. samples / sec: 66046.55
Iteration:    340, Loss function: 7.882, Average Loss: 2.861, avg. samples / sec: 65961.14
Iteration:    340, Loss function: 6.638, Average Loss: 2.884, avg. samples / sec: 65982.79
Iteration:    340, Loss function: 6.731, Average Loss: 2.857, avg. samples / sec: 65939.60
:::MLL 1558651533.160 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558651533.160 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 7.527, Average Loss: 2.947, avg. samples / sec: 65608.19
Iteration:    360, Loss function: 5.925, Average Loss: 2.941, avg. samples / sec: 65671.38
Iteration:    360, Loss function: 6.356, Average Loss: 2.966, avg. samples / sec: 65596.31
Iteration:    360, Loss function: 6.831, Average Loss: 2.936, avg. samples / sec: 65595.33
Iteration:    360, Loss function: 7.008, Average Loss: 2.955, avg. samples / sec: 65514.86
Iteration:    360, Loss function: 6.714, Average Loss: 2.937, avg. samples / sec: 65625.97
Iteration:    360, Loss function: 6.664, Average Loss: 2.952, avg. samples / sec: 65525.58
Iteration:    360, Loss function: 8.665, Average Loss: 2.947, avg. samples / sec: 65516.99
Iteration:    360, Loss function: 5.929, Average Loss: 2.937, avg. samples / sec: 65536.70
Iteration:    360, Loss function: 7.652, Average Loss: 2.946, avg. samples / sec: 65605.56
Iteration:    360, Loss function: 5.915, Average Loss: 2.942, avg. samples / sec: 65802.10
Iteration:    360, Loss function: 5.401, Average Loss: 2.939, avg. samples / sec: 65447.16
Iteration:    360, Loss function: 7.366, Average Loss: 2.957, avg. samples / sec: 65610.48
Iteration:    360, Loss function: 6.698, Average Loss: 2.938, avg. samples / sec: 65675.79
Iteration:    360, Loss function: 6.555, Average Loss: 2.945, avg. samples / sec: 65467.53
Iteration:    360, Loss function: 6.741, Average Loss: 2.946, avg. samples / sec: 65404.33
Iteration:    360, Loss function: 6.982, Average Loss: 2.977, avg. samples / sec: 65592.80
Iteration:    360, Loss function: 7.966, Average Loss: 2.940, avg. samples / sec: 65648.93
Iteration:    360, Loss function: 8.103, Average Loss: 2.955, avg. samples / sec: 65468.87
Iteration:    360, Loss function: 6.611, Average Loss: 2.947, avg. samples / sec: 65651.98
Iteration:    360, Loss function: 7.443, Average Loss: 2.942, avg. samples / sec: 65688.64
Iteration:    360, Loss function: 7.424, Average Loss: 2.944, avg. samples / sec: 65480.91
Iteration:    360, Loss function: 5.572, Average Loss: 2.964, avg. samples / sec: 65676.22
Iteration:    360, Loss function: 7.388, Average Loss: 2.946, avg. samples / sec: 65601.19
Iteration:    360, Loss function: 7.384, Average Loss: 2.939, avg. samples / sec: 65595.21
Iteration:    360, Loss function: 8.149, Average Loss: 2.941, avg. samples / sec: 65584.07
Iteration:    360, Loss function: 6.938, Average Loss: 2.934, avg. samples / sec: 65450.72
Iteration:    360, Loss function: 6.708, Average Loss: 2.940, avg. samples / sec: 65546.82
Iteration:    360, Loss function: 6.268, Average Loss: 2.944, avg. samples / sec: 65453.94
Iteration:    360, Loss function: 6.109, Average Loss: 2.937, avg. samples / sec: 65440.66
Iteration:    380, Loss function: 7.398, Average Loss: 3.044, avg. samples / sec: 65547.00
Iteration:    380, Loss function: 7.544, Average Loss: 3.026, avg. samples / sec: 65643.73
Iteration:    380, Loss function: 6.610, Average Loss: 3.028, avg. samples / sec: 65569.85
Iteration:    380, Loss function: 6.215, Average Loss: 3.039, avg. samples / sec: 65571.19
Iteration:    380, Loss function: 7.648, Average Loss: 3.020, avg. samples / sec: 65500.51
Iteration:    380, Loss function: 6.542, Average Loss: 3.033, avg. samples / sec: 65544.23
Iteration:    380, Loss function: 8.346, Average Loss: 3.026, avg. samples / sec: 65480.88
Iteration:    380, Loss function: 7.257, Average Loss: 3.034, avg. samples / sec: 65296.97
Iteration:    380, Loss function: 7.489, Average Loss: 3.030, avg. samples / sec: 65523.54
Iteration:    380, Loss function: 6.627, Average Loss: 3.030, avg. samples / sec: 65453.48
Iteration:    380, Loss function: 7.362, Average Loss: 3.034, avg. samples / sec: 65367.63
Iteration:    380, Loss function: 7.165, Average Loss: 3.024, avg. samples / sec: 65648.13
Iteration:    380, Loss function: 6.803, Average Loss: 3.031, avg. samples / sec: 65489.10
Iteration:    380, Loss function: 6.447, Average Loss: 3.046, avg. samples / sec: 65511.81
Iteration:    380, Loss function: 6.883, Average Loss: 3.061, avg. samples / sec: 65494.58
Iteration:    380, Loss function: 6.767, Average Loss: 3.053, avg. samples / sec: 65337.87
Iteration:    380, Loss function: 7.900, Average Loss: 3.037, avg. samples / sec: 65431.36
Iteration:    380, Loss function: 7.105, Average Loss: 3.037, avg. samples / sec: 65384.97
Iteration:    380, Loss function: 7.440, Average Loss: 3.030, avg. samples / sec: 65482.41
Iteration:    380, Loss function: 7.789, Average Loss: 3.033, avg. samples / sec: 65476.41
Iteration:    380, Loss function: 6.878, Average Loss: 3.041, avg. samples / sec: 65467.26
Iteration:    380, Loss function: 8.052, Average Loss: 3.027, avg. samples / sec: 65493.64
Iteration:    380, Loss function: 7.183, Average Loss: 3.031, avg. samples / sec: 65445.55
Iteration:    380, Loss function: 7.107, Average Loss: 3.022, avg. samples / sec: 65370.23
Iteration:    380, Loss function: 7.423, Average Loss: 3.031, avg. samples / sec: 65411.59
Iteration:    380, Loss function: 7.956, Average Loss: 3.029, avg. samples / sec: 65439.65
Iteration:    380, Loss function: 8.223, Average Loss: 3.032, avg. samples / sec: 65528.87
Iteration:    380, Loss function: 7.018, Average Loss: 3.025, avg. samples / sec: 65355.20
Iteration:    380, Loss function: 7.174, Average Loss: 3.031, avg. samples / sec: 65305.11
Iteration:    380, Loss function: 7.737, Average Loss: 3.046, avg. samples / sec: 64554.30
Iteration:    400, Loss function: 5.871, Average Loss: 3.109, avg. samples / sec: 65923.13
Iteration:    400, Loss function: 6.372, Average Loss: 3.112, avg. samples / sec: 65908.11
Iteration:    400, Loss function: 6.698, Average Loss: 3.111, avg. samples / sec: 65849.88
Iteration:    400, Loss function: 6.740, Average Loss: 3.107, avg. samples / sec: 65760.19
Iteration:    400, Loss function: 6.247, Average Loss: 3.133, avg. samples / sec: 65870.04
Iteration:    400, Loss function: 7.246, Average Loss: 3.125, avg. samples / sec: 65678.51
Iteration:    400, Loss function: 6.766, Average Loss: 3.109, avg. samples / sec: 65912.89
Iteration:    400, Loss function: 7.307, Average Loss: 3.112, avg. samples / sec: 65805.38
Iteration:    400, Loss function: 6.449, Average Loss: 3.106, avg. samples / sec: 65862.19
Iteration:    400, Loss function: 5.742, Average Loss: 3.094, avg. samples / sec: 65717.47
Iteration:    400, Loss function: 7.979, Average Loss: 3.114, avg. samples / sec: 65744.32
Iteration:    400, Loss function: 7.726, Average Loss: 3.109, avg. samples / sec: 65782.38
Iteration:    400, Loss function: 6.725, Average Loss: 3.145, avg. samples / sec: 65792.42
Iteration:    400, Loss function: 6.803, Average Loss: 3.114, avg. samples / sec: 65747.70
Iteration:    400, Loss function: 6.263, Average Loss: 3.109, avg. samples / sec: 65807.17
Iteration:    400, Loss function: 7.185, Average Loss: 3.104, avg. samples / sec: 65748.19
Iteration:    400, Loss function: 7.740, Average Loss: 3.125, avg. samples / sec: 66695.92
Iteration:    400, Loss function: 7.630, Average Loss: 3.107, avg. samples / sec: 65644.55
Iteration:    400, Loss function: 7.064, Average Loss: 3.102, avg. samples / sec: 65790.52
Iteration:    400, Loss function: 6.367, Average Loss: 3.112, avg. samples / sec: 65777.90
Iteration:    400, Loss function: 7.750, Average Loss: 3.100, avg. samples / sec: 65792.08
Iteration:    400, Loss function: 5.952, Average Loss: 3.101, avg. samples / sec: 65662.29
Iteration:    400, Loss function: 6.467, Average Loss: 3.106, avg. samples / sec: 65778.66
Iteration:    400, Loss function: 8.092, Average Loss: 3.117, avg. samples / sec: 65729.61
Iteration:    400, Loss function: 6.074, Average Loss: 3.128, avg. samples / sec: 65678.14
Iteration:    400, Loss function: 7.711, Average Loss: 3.109, avg. samples / sec: 65729.76
Iteration:    400, Loss function: 6.230, Average Loss: 3.107, avg. samples / sec: 65648.74
Iteration:    400, Loss function: 7.246, Average Loss: 3.107, avg. samples / sec: 65709.78
Iteration:    400, Loss function: 6.861, Average Loss: 3.109, avg. samples / sec: 65739.02
Iteration:    400, Loss function: 6.465, Average Loss: 3.112, avg. samples / sec: 65566.58
:::MLL 1558651534.949 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558651534.950 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 7.120, Average Loss: 3.178, avg. samples / sec: 66082.17
Iteration:    420, Loss function: 8.048, Average Loss: 3.193, avg. samples / sec: 66025.17
Iteration:    420, Loss function: 5.724, Average Loss: 3.199, avg. samples / sec: 66060.36
Iteration:    420, Loss function: 6.747, Average Loss: 3.179, avg. samples / sec: 65873.82
Iteration:    420, Loss function: 6.408, Average Loss: 3.175, avg. samples / sec: 65917.61
Iteration:    420, Loss function: 6.870, Average Loss: 3.178, avg. samples / sec: 65893.91
Iteration:    420, Loss function: 7.712, Average Loss: 3.185, avg. samples / sec: 65858.40
Iteration:    420, Loss function: 6.626, Average Loss: 3.187, avg. samples / sec: 65848.71
Iteration:    420, Loss function: 6.799, Average Loss: 3.183, avg. samples / sec: 65744.29
Iteration:    420, Loss function: 7.068, Average Loss: 3.184, avg. samples / sec: 66085.33
Iteration:    420, Loss function: 6.954, Average Loss: 3.175, avg. samples / sec: 65895.38
Iteration:    420, Loss function: 5.440, Average Loss: 3.186, avg. samples / sec: 65676.95
Iteration:    420, Loss function: 7.889, Average Loss: 3.172, avg. samples / sec: 65907.19
Iteration:    420, Loss function: 6.268, Average Loss: 3.174, avg. samples / sec: 65858.77
Iteration:    420, Loss function: 6.988, Average Loss: 3.182, avg. samples / sec: 65825.70
Iteration:    420, Loss function: 6.269, Average Loss: 3.179, avg. samples / sec: 65825.55
Iteration:    420, Loss function: 6.339, Average Loss: 3.183, avg. samples / sec: 65733.19
Iteration:    420, Loss function: 7.295, Average Loss: 3.166, avg. samples / sec: 65759.17
Iteration:    420, Loss function: 6.747, Average Loss: 3.178, avg. samples / sec: 65607.85
Iteration:    420, Loss function: 6.056, Average Loss: 3.195, avg. samples / sec: 65734.24
Iteration:    420, Loss function: 5.896, Average Loss: 3.180, avg. samples / sec: 65975.34
Iteration:    420, Loss function: 5.895, Average Loss: 3.183, avg. samples / sec: 65915.57
Iteration:    420, Loss function: 6.470, Average Loss: 3.209, avg. samples / sec: 65659.91
Iteration:    420, Loss function: 6.936, Average Loss: 3.189, avg. samples / sec: 65837.57
Iteration:    420, Loss function: 5.962, Average Loss: 3.220, avg. samples / sec: 65745.00
Iteration:    420, Loss function: 6.641, Average Loss: 3.181, avg. samples / sec: 65811.93
Iteration:    420, Loss function: 8.125, Average Loss: 3.177, avg. samples / sec: 65766.02
Iteration:    420, Loss function: 7.855, Average Loss: 3.177, avg. samples / sec: 65854.15
Iteration:    420, Loss function: 6.221, Average Loss: 3.181, avg. samples / sec: 65688.49
Iteration:    420, Loss function: 6.589, Average Loss: 3.173, avg. samples / sec: 65555.63
Iteration:    440, Loss function: 6.477, Average Loss: 3.248, avg. samples / sec: 65555.39
Iteration:    440, Loss function: 5.829, Average Loss: 3.258, avg. samples / sec: 65597.96
Iteration:    440, Loss function: 7.507, Average Loss: 3.276, avg. samples / sec: 65676.55
Iteration:    440, Loss function: 8.310, Average Loss: 3.260, avg. samples / sec: 65412.80
Iteration:    440, Loss function: 5.934, Average Loss: 3.254, avg. samples / sec: 65504.14
Iteration:    440, Loss function: 7.148, Average Loss: 3.255, avg. samples / sec: 65592.43
Iteration:    440, Loss function: 5.472, Average Loss: 3.254, avg. samples / sec: 65506.27
Iteration:    440, Loss function: 6.729, Average Loss: 3.253, avg. samples / sec: 65516.50
Iteration:    440, Loss function: 6.077, Average Loss: 3.248, avg. samples / sec: 65687.97
Iteration:    440, Loss function: 7.156, Average Loss: 3.252, avg. samples / sec: 65321.84
Iteration:    440, Loss function: 6.997, Average Loss: 3.235, avg. samples / sec: 65573.63
Iteration:    440, Loss function: 5.974, Average Loss: 3.240, avg. samples / sec: 65519.67
Iteration:    440, Loss function: 6.759, Average Loss: 3.240, avg. samples / sec: 65491.78
Iteration:    440, Loss function: 6.237, Average Loss: 3.266, avg. samples / sec: 65565.30
Iteration:    440, Loss function: 5.868, Average Loss: 3.243, avg. samples / sec: 65642.57
Iteration:    440, Loss function: 6.517, Average Loss: 3.243, avg. samples / sec: 65404.27
Iteration:    440, Loss function: 5.680, Average Loss: 3.252, avg. samples / sec: 65480.03
Iteration:    440, Loss function: 7.410, Average Loss: 3.249, avg. samples / sec: 65448.41
Iteration:    440, Loss function: 7.138, Average Loss: 3.269, avg. samples / sec: 65326.05
Iteration:    440, Loss function: 6.931, Average Loss: 3.251, avg. samples / sec: 65543.96
Iteration:    440, Loss function: 5.810, Average Loss: 3.240, avg. samples / sec: 65591.21
Iteration:    440, Loss function: 5.590, Average Loss: 3.245, avg. samples / sec: 65420.82
Iteration:    440, Loss function: 5.829, Average Loss: 3.248, avg. samples / sec: 65490.56
Iteration:    440, Loss function: 5.995, Average Loss: 3.291, avg. samples / sec: 65486.97
Iteration:    440, Loss function: 5.969, Average Loss: 3.248, avg. samples / sec: 65449.14
Iteration:    440, Loss function: 7.317, Average Loss: 3.251, avg. samples / sec: 65562.80
Iteration:    440, Loss function: 6.908, Average Loss: 3.247, avg. samples / sec: 65416.45
Iteration:    440, Loss function: 6.916, Average Loss: 3.255, avg. samples / sec: 65396.59
Iteration:    440, Loss function: 6.038, Average Loss: 3.247, avg. samples / sec: 65220.78
Iteration:    440, Loss function: 6.803, Average Loss: 3.249, avg. samples / sec: 65559.44
Iteration:    460, Loss function: 5.760, Average Loss: 3.322, avg. samples / sec: 66020.69
Iteration:    460, Loss function: 5.185, Average Loss: 3.342, avg. samples / sec: 65965.96
Iteration:    460, Loss function: 8.290, Average Loss: 3.316, avg. samples / sec: 66041.79
Iteration:    460, Loss function: 6.267, Average Loss: 3.302, avg. samples / sec: 66026.22
Iteration:    460, Loss function: 7.374, Average Loss: 3.339, avg. samples / sec: 66036.12
Iteration:    460, Loss function: 6.652, Average Loss: 3.326, avg. samples / sec: 65886.05
Iteration:    460, Loss function: 5.990, Average Loss: 3.321, avg. samples / sec: 65955.09
Iteration:    460, Loss function: 5.545, Average Loss: 3.314, avg. samples / sec: 66174.67
Iteration:    460, Loss function: 6.047, Average Loss: 3.329, avg. samples / sec: 65911.66
Iteration:    460, Loss function: 5.993, Average Loss: 3.320, avg. samples / sec: 65937.75
Iteration:    460, Loss function: 6.830, Average Loss: 3.305, avg. samples / sec: 65941.48
Iteration:    460, Loss function: 7.037, Average Loss: 3.312, avg. samples / sec: 65949.41
Iteration:    460, Loss function: 6.967, Average Loss: 3.313, avg. samples / sec: 65761.32
Iteration:    460, Loss function: 6.709, Average Loss: 3.315, avg. samples / sec: 66061.20
Iteration:    460, Loss function: 6.551, Average Loss: 3.297, avg. samples / sec: 65923.00
Iteration:    460, Loss function: 6.544, Average Loss: 3.318, avg. samples / sec: 65833.48
Iteration:    460, Loss function: 6.187, Average Loss: 3.318, avg. samples / sec: 66018.89
Iteration:    460, Loss function: 6.782, Average Loss: 3.319, avg. samples / sec: 65936.30
Iteration:    460, Loss function: 6.081, Average Loss: 3.316, avg. samples / sec: 65850.77
Iteration:    460, Loss function: 5.641, Average Loss: 3.335, avg. samples / sec: 65939.57
Iteration:    460, Loss function: 6.383, Average Loss: 3.358, avg. samples / sec: 66009.80
Iteration:    460, Loss function: 6.311, Average Loss: 3.313, avg. samples / sec: 65974.39
Iteration:    460, Loss function: 6.166, Average Loss: 3.317, avg. samples / sec: 66027.71
Iteration:    460, Loss function: 6.243, Average Loss: 3.313, avg. samples / sec: 65903.30
Iteration:    460, Loss function: 6.249, Average Loss: 3.320, avg. samples / sec: 65902.50
Iteration:    460, Loss function: 5.553, Average Loss: 3.309, avg. samples / sec: 65994.47
Iteration:    460, Loss function: 6.987, Average Loss: 3.308, avg. samples / sec: 65928.86
Iteration:    460, Loss function: 6.535, Average Loss: 3.315, avg. samples / sec: 65770.47
Iteration:    460, Loss function: 7.252, Average Loss: 3.317, avg. samples / sec: 66052.37
Iteration:    460, Loss function: 5.242, Average Loss: 3.309, avg. samples / sec: 65820.60
Iteration:    480, Loss function: 5.681, Average Loss: 3.385, avg. samples / sec: 66325.75
Iteration:    480, Loss function: 7.144, Average Loss: 3.386, avg. samples / sec: 66349.35
Iteration:    480, Loss function: 5.608, Average Loss: 3.405, avg. samples / sec: 66286.19
Iteration:    480, Loss function: 6.329, Average Loss: 3.382, avg. samples / sec: 66430.73
Iteration:    480, Loss function: 6.779, Average Loss: 3.388, avg. samples / sec: 66345.82
Iteration:    480, Loss function: 6.728, Average Loss: 3.393, avg. samples / sec: 66340.48
Iteration:    480, Loss function: 6.945, Average Loss: 3.363, avg. samples / sec: 66293.64
Iteration:    480, Loss function: 5.872, Average Loss: 3.401, avg. samples / sec: 66305.31
Iteration:    480, Loss function: 7.354, Average Loss: 3.385, avg. samples / sec: 66471.56
Iteration:    480, Loss function: 6.237, Average Loss: 3.391, avg. samples / sec: 66308.05
Iteration:    480, Loss function: 6.736, Average Loss: 3.377, avg. samples / sec: 66452.50
Iteration:    480, Loss function: 6.136, Average Loss: 3.380, avg. samples / sec: 66349.95
Iteration:    480, Loss function: 6.650, Average Loss: 3.382, avg. samples / sec: 66369.82
Iteration:    480, Loss function: 5.294, Average Loss: 3.421, avg. samples / sec: 66374.92
Iteration:    480, Loss function: 6.689, Average Loss: 3.379, avg. samples / sec: 66342.70
Iteration:    480, Loss function: 7.214, Average Loss: 3.379, avg. samples / sec: 66212.07
Iteration:    480, Loss function: 8.394, Average Loss: 3.380, avg. samples / sec: 66318.79
Iteration:    480, Loss function: 7.001, Average Loss: 3.383, avg. samples / sec: 66250.91
Iteration:    480, Loss function: 7.242, Average Loss: 3.378, avg. samples / sec: 66371.07
Iteration:    480, Loss function: 6.994, Average Loss: 3.383, avg. samples / sec: 66353.04
Iteration:    480, Loss function: 6.354, Average Loss: 3.363, avg. samples / sec: 66266.24
Iteration:    480, Loss function: 6.577, Average Loss: 3.378, avg. samples / sec: 66328.81
Iteration:    480, Loss function: 6.614, Average Loss: 3.376, avg. samples / sec: 66355.16
Iteration:    480, Loss function: 6.583, Average Loss: 3.401, avg. samples / sec: 66280.67
Iteration:    480, Loss function: 6.106, Average Loss: 3.361, avg. samples / sec: 66217.14
Iteration:    480, Loss function: 7.301, Average Loss: 3.381, avg. samples / sec: 66232.48
Iteration:    480, Loss function: 5.996, Average Loss: 3.376, avg. samples / sec: 66342.14
Iteration:    480, Loss function: 5.897, Average Loss: 3.376, avg. samples / sec: 66189.24
Iteration:    480, Loss function: 6.179, Average Loss: 3.373, avg. samples / sec: 66388.55
Iteration:    480, Loss function: 5.072, Average Loss: 3.380, avg. samples / sec: 66307.46
:::MLL 1558651536.742 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558651536.742 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 7.163, Average Loss: 3.447, avg. samples / sec: 65017.89
Iteration:    500, Loss function: 6.350, Average Loss: 3.421, avg. samples / sec: 64958.19
Iteration:    500, Loss function: 6.654, Average Loss: 3.447, avg. samples / sec: 64903.77
Iteration:    500, Loss function: 6.691, Average Loss: 3.455, avg. samples / sec: 64931.88
Iteration:    500, Loss function: 6.640, Average Loss: 3.460, avg. samples / sec: 64879.45
Iteration:    500, Loss function: 6.502, Average Loss: 3.441, avg. samples / sec: 64973.61
Iteration:    500, Loss function: 7.616, Average Loss: 3.445, avg. samples / sec: 64920.91
Iteration:    500, Loss function: 6.699, Average Loss: 3.424, avg. samples / sec: 65004.90
Iteration:    500, Loss function: 7.006, Average Loss: 3.442, avg. samples / sec: 64840.26
Iteration:    500, Loss function: 7.230, Average Loss: 3.446, avg. samples / sec: 64775.32
Iteration:    500, Loss function: 7.371, Average Loss: 3.441, avg. samples / sec: 64954.27
Iteration:    500, Loss function: 6.033, Average Loss: 3.483, avg. samples / sec: 64864.07
Iteration:    500, Loss function: 6.674, Average Loss: 3.443, avg. samples / sec: 64869.75
Iteration:    500, Loss function: 6.859, Average Loss: 3.438, avg. samples / sec: 64922.79
Iteration:    500, Loss function: 7.054, Average Loss: 3.439, avg. samples / sec: 64866.76
Iteration:    500, Loss function: 7.059, Average Loss: 3.467, avg. samples / sec: 64777.01
Iteration:    500, Loss function: 6.763, Average Loss: 3.436, avg. samples / sec: 64985.27
Iteration:    500, Loss function: 7.162, Average Loss: 3.446, avg. samples / sec: 64774.93
Iteration:    500, Loss function: 7.282, Average Loss: 3.444, avg. samples / sec: 64792.11
Iteration:    500, Loss function: 8.039, Average Loss: 3.426, avg. samples / sec: 64910.17
Iteration:    500, Loss function: 6.645, Average Loss: 3.439, avg. samples / sec: 64834.77
Iteration:    500, Loss function: 7.476, Average Loss: 3.450, avg. samples / sec: 64859.24
Iteration:    500, Loss function: 7.457, Average Loss: 3.433, avg. samples / sec: 64918.78
Iteration:    500, Loss function: 6.829, Average Loss: 3.448, avg. samples / sec: 64904.40
Iteration:    500, Loss function: 6.551, Average Loss: 3.438, avg. samples / sec: 64807.43
Iteration:    500, Loss function: 6.311, Average Loss: 3.452, avg. samples / sec: 64730.18
Iteration:    500, Loss function: 7.594, Average Loss: 3.442, avg. samples / sec: 64941.52
Iteration:    500, Loss function: 6.607, Average Loss: 3.442, avg. samples / sec: 64738.54
Iteration:    500, Loss function: 7.226, Average Loss: 3.441, avg. samples / sec: 64893.40
Iteration:    500, Loss function: 6.493, Average Loss: 3.467, avg. samples / sec: 64834.62
Iteration:    520, Loss function: 6.462, Average Loss: 3.511, avg. samples / sec: 66272.91
Iteration:    520, Loss function: 6.469, Average Loss: 3.509, avg. samples / sec: 66313.42
Iteration:    520, Loss function: 5.828, Average Loss: 3.517, avg. samples / sec: 66235.88
Iteration:    520, Loss function: 6.860, Average Loss: 3.508, avg. samples / sec: 66327.81
Iteration:    520, Loss function: 6.145, Average Loss: 3.484, avg. samples / sec: 66256.89
Iteration:    520, Loss function: 6.881, Average Loss: 3.513, avg. samples / sec: 66330.96
Iteration:    520, Loss function: 7.012, Average Loss: 3.519, avg. samples / sec: 66178.77
Iteration:    520, Loss function: 6.488, Average Loss: 3.510, avg. samples / sec: 66243.47
Iteration:    520, Loss function: 6.424, Average Loss: 3.507, avg. samples / sec: 66202.08
Iteration:    520, Loss function: 5.869, Average Loss: 3.528, avg. samples / sec: 66397.37
Iteration:    520, Loss function: 7.260, Average Loss: 3.500, avg. samples / sec: 66252.91
Iteration:    520, Loss function: 6.868, Average Loss: 3.502, avg. samples / sec: 66166.71
Iteration:    520, Loss function: 6.246, Average Loss: 3.506, avg. samples / sec: 66357.73
Iteration:    520, Loss function: 5.800, Average Loss: 3.502, avg. samples / sec: 65991.81
Iteration:    520, Loss function: 5.707, Average Loss: 3.506, avg. samples / sec: 66322.25
Iteration:    520, Loss function: 5.951, Average Loss: 3.492, avg. samples / sec: 66262.35
Iteration:    520, Loss function: 5.382, Average Loss: 3.508, avg. samples / sec: 66206.91
Iteration:    520, Loss function: 5.735, Average Loss: 3.540, avg. samples / sec: 66182.16
Iteration:    520, Loss function: 6.107, Average Loss: 3.514, avg. samples / sec: 66243.91
Iteration:    520, Loss function: 5.534, Average Loss: 3.512, avg. samples / sec: 66224.20
Iteration:    520, Loss function: 5.914, Average Loss: 3.502, avg. samples / sec: 66218.76
Iteration:    520, Loss function: 7.658, Average Loss: 3.513, avg. samples / sec: 66237.84
Iteration:    520, Loss function: 6.848, Average Loss: 3.498, avg. samples / sec: 66208.71
Iteration:    520, Loss function: 7.071, Average Loss: 3.506, avg. samples / sec: 66234.79
Iteration:    520, Loss function: 6.736, Average Loss: 3.528, avg. samples / sec: 66157.95
Iteration:    520, Loss function: 6.546, Average Loss: 3.482, avg. samples / sec: 65979.61
Iteration:    520, Loss function: 6.064, Average Loss: 3.501, avg. samples / sec: 66111.00
Iteration:    520, Loss function: 6.147, Average Loss: 3.503, avg. samples / sec: 66136.28
Iteration:    520, Loss function: 5.700, Average Loss: 3.513, avg. samples / sec: 66145.53
Iteration:    520, Loss function: 6.329, Average Loss: 3.508, avg. samples / sec: 66181.25
Iteration:    540, Loss function: 6.423, Average Loss: 3.538, avg. samples / sec: 66308.43
Iteration:    540, Loss function: 5.806, Average Loss: 3.574, avg. samples / sec: 66099.59
Iteration:    540, Loss function: 5.892, Average Loss: 3.565, avg. samples / sec: 66226.41
Iteration:    540, Loss function: 6.817, Average Loss: 3.568, avg. samples / sec: 66238.65
Iteration:    540, Loss function: 4.896, Average Loss: 3.561, avg. samples / sec: 66021.68
Iteration:    540, Loss function: 6.900, Average Loss: 3.560, avg. samples / sec: 66075.54
Iteration:    540, Loss function: 5.035, Average Loss: 3.560, avg. samples / sec: 66136.00
Iteration:    540, Loss function: 5.434, Average Loss: 3.575, avg. samples / sec: 66119.74
Iteration:    540, Loss function: 7.024, Average Loss: 3.554, avg. samples / sec: 66212.19
Iteration:    540, Loss function: 6.016, Average Loss: 3.562, avg. samples / sec: 66093.14
Iteration:    540, Loss function: 6.518, Average Loss: 3.536, avg. samples / sec: 66036.53
Iteration:    540, Loss function: 5.143, Average Loss: 3.579, avg. samples / sec: 66218.94
Iteration:    540, Loss function: 6.762, Average Loss: 3.592, avg. samples / sec: 66161.81
Iteration:    540, Loss function: 5.860, Average Loss: 3.559, avg. samples / sec: 66102.75
Iteration:    540, Loss function: 6.665, Average Loss: 3.548, avg. samples / sec: 66216.21
Iteration:    540, Loss function: 6.259, Average Loss: 3.561, avg. samples / sec: 66263.53
Iteration:    540, Loss function: 4.808, Average Loss: 3.563, avg. samples / sec: 66056.12
Iteration:    540, Loss function: 6.148, Average Loss: 3.555, avg. samples / sec: 66205.72
Iteration:    540, Loss function: 5.673, Average Loss: 3.558, avg. samples / sec: 66042.25
Iteration:    540, Loss function: 6.570, Average Loss: 3.572, avg. samples / sec: 66190.86
Iteration:    540, Loss function: 5.655, Average Loss: 3.579, avg. samples / sec: 66022.51
Iteration:    540, Loss function: 5.722, Average Loss: 3.557, avg. samples / sec: 66154.94
Iteration:    540, Loss function: 5.934, Average Loss: 3.552, avg. samples / sec: 66049.43
Iteration:    540, Loss function: 5.628, Average Loss: 3.560, avg. samples / sec: 66169.85
Iteration:    540, Loss function: 6.217, Average Loss: 3.552, avg. samples / sec: 66042.00
Iteration:    540, Loss function: 6.241, Average Loss: 3.561, avg. samples / sec: 66110.22
Iteration:    540, Loss function: 6.337, Average Loss: 3.548, avg. samples / sec: 66057.70
Iteration:    540, Loss function: 7.365, Average Loss: 3.564, avg. samples / sec: 65908.82
Iteration:    540, Loss function: 7.302, Average Loss: 3.571, avg. samples / sec: 66079.10
Iteration:    540, Loss function: 7.923, Average Loss: 3.564, avg. samples / sec: 65994.96
:::MLL 1558651538.519 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558651538.520 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 5.379, Average Loss: 3.616, avg. samples / sec: 66448.24
Iteration:    560, Loss function: 5.707, Average Loss: 3.609, avg. samples / sec: 66461.81
Iteration:    560, Loss function: 5.633, Average Loss: 3.608, avg. samples / sec: 66368.91
Iteration:    560, Loss function: 6.289, Average Loss: 3.593, avg. samples / sec: 66305.99
Iteration:    560, Loss function: 5.728, Average Loss: 3.607, avg. samples / sec: 66495.27
Iteration:    560, Loss function: 7.063, Average Loss: 3.611, avg. samples / sec: 66401.25
Iteration:    560, Loss function: 6.712, Average Loss: 3.608, avg. samples / sec: 66346.35
Iteration:    560, Loss function: 6.000, Average Loss: 3.605, avg. samples / sec: 66434.46
Iteration:    560, Loss function: 6.708, Average Loss: 3.625, avg. samples / sec: 66286.66
Iteration:    560, Loss function: 5.978, Average Loss: 3.621, avg. samples / sec: 66307.05
Iteration:    560, Loss function: 5.983, Average Loss: 3.630, avg. samples / sec: 66417.30
Iteration:    560, Loss function: 6.235, Average Loss: 3.606, avg. samples / sec: 66291.40
Iteration:    560, Loss function: 5.415, Average Loss: 3.607, avg. samples / sec: 66301.00
Iteration:    560, Loss function: 7.114, Average Loss: 3.589, avg. samples / sec: 66289.84
Iteration:    560, Loss function: 5.023, Average Loss: 3.615, avg. samples / sec: 66364.91
Iteration:    560, Loss function: 5.986, Average Loss: 3.610, avg. samples / sec: 66288.62
Iteration:    560, Loss function: 4.931, Average Loss: 3.628, avg. samples / sec: 66228.16
Iteration:    560, Loss function: 5.238, Average Loss: 3.615, avg. samples / sec: 66347.01
Iteration:    560, Loss function: 4.882, Average Loss: 3.609, avg. samples / sec: 66298.35
Iteration:    560, Loss function: 6.190, Average Loss: 3.620, avg. samples / sec: 66186.04
Iteration:    560, Loss function: 6.056, Average Loss: 3.603, avg. samples / sec: 66284.51
Iteration:    560, Loss function: 6.823, Average Loss: 3.634, avg. samples / sec: 66218.20
Iteration:    560, Loss function: 6.247, Average Loss: 3.620, avg. samples / sec: 66320.19
Iteration:    560, Loss function: 6.543, Average Loss: 3.601, avg. samples / sec: 66288.06
Iteration:    560, Loss function: 6.732, Average Loss: 3.619, avg. samples / sec: 66202.86
Iteration:    560, Loss function: 5.877, Average Loss: 3.619, avg. samples / sec: 66205.85
Iteration:    560, Loss function: 4.910, Average Loss: 3.613, avg. samples / sec: 66264.71
Iteration:    560, Loss function: 7.015, Average Loss: 3.616, avg. samples / sec: 66149.10
Iteration:    560, Loss function: 6.132, Average Loss: 3.643, avg. samples / sec: 66084.74
Iteration:    560, Loss function: 6.084, Average Loss: 3.600, avg. samples / sec: 66081.08
Iteration:    580, Loss function: 6.208, Average Loss: 3.654, avg. samples / sec: 66263.13
Iteration:    580, Loss function: 5.827, Average Loss: 3.649, avg. samples / sec: 66209.58
Iteration:    580, Loss function: 5.899, Average Loss: 3.664, avg. samples / sec: 66302.06
Iteration:    580, Loss function: 6.458, Average Loss: 3.665, avg. samples / sec: 66292.99
Iteration:    580, Loss function: 4.993, Average Loss: 3.658, avg. samples / sec: 66211.54
Iteration:    580, Loss function: 5.524, Average Loss: 3.655, avg. samples / sec: 66130.73
Iteration:    580, Loss function: 6.292, Average Loss: 3.653, avg. samples / sec: 66282.51
Iteration:    580, Loss function: 6.282, Average Loss: 3.653, avg. samples / sec: 66073.34
Iteration:    580, Loss function: 6.033, Average Loss: 3.678, avg. samples / sec: 66232.39
Iteration:    580, Loss function: 6.419, Average Loss: 3.658, avg. samples / sec: 66099.80
Iteration:    580, Loss function: 6.357, Average Loss: 3.662, avg. samples / sec: 66306.80
Iteration:    580, Loss function: 5.080, Average Loss: 3.673, avg. samples / sec: 66110.66
Iteration:    580, Loss function: 5.235, Average Loss: 3.674, avg. samples / sec: 66122.07
Iteration:    580, Loss function: 6.173, Average Loss: 3.659, avg. samples / sec: 66154.16
Iteration:    580, Loss function: 6.243, Average Loss: 3.636, avg. samples / sec: 66147.40
Iteration:    580, Loss function: 6.008, Average Loss: 3.653, avg. samples / sec: 66365.76
Iteration:    580, Loss function: 5.707, Average Loss: 3.649, avg. samples / sec: 66251.79
Iteration:    580, Loss function: 6.018, Average Loss: 3.665, avg. samples / sec: 66243.19
Iteration:    580, Loss function: 5.789, Average Loss: 3.664, avg. samples / sec: 65982.14
Iteration:    580, Loss function: 5.289, Average Loss: 3.662, avg. samples / sec: 66292.36
Iteration:    580, Loss function: 6.072, Average Loss: 3.669, avg. samples / sec: 66265.59
Iteration:    580, Loss function: 5.714, Average Loss: 3.641, avg. samples / sec: 66025.11
Iteration:    580, Loss function: 5.523, Average Loss: 3.683, avg. samples / sec: 66179.89
Iteration:    580, Loss function: 4.778, Average Loss: 3.657, avg. samples / sec: 66325.96
Iteration:    580, Loss function: 6.083, Average Loss: 3.654, avg. samples / sec: 66127.78
Iteration:    580, Loss function: 5.210, Average Loss: 3.671, avg. samples / sec: 66044.60
Iteration:    580, Loss function: 6.567, Average Loss: 3.658, avg. samples / sec: 66001.08
Iteration:    580, Loss function: 6.263, Average Loss: 3.688, avg. samples / sec: 66309.30
Iteration:    580, Loss function: 6.284, Average Loss: 3.664, avg. samples / sec: 66080.34
Iteration:    580, Loss function: 5.647, Average Loss: 3.654, avg. samples / sec: 66038.32
Iteration:    600, Loss function: 7.121, Average Loss: 3.684, avg. samples / sec: 66336.92
Iteration:    600, Loss function: 6.451, Average Loss: 3.695, avg. samples / sec: 66224.51
Iteration:    600, Loss function: 5.834, Average Loss: 3.695, avg. samples / sec: 66027.89
Iteration:    600, Loss function: 5.382, Average Loss: 3.706, avg. samples / sec: 66141.12
Iteration:    600, Loss function: 6.073, Average Loss: 3.701, avg. samples / sec: 66163.86
Iteration:    600, Loss function: 5.539, Average Loss: 3.700, avg. samples / sec: 66251.82
Iteration:    600, Loss function: 6.397, Average Loss: 3.700, avg. samples / sec: 66106.93
Iteration:    600, Loss function: 6.811, Average Loss: 3.693, avg. samples / sec: 66036.15
Iteration:    600, Loss function: 6.605, Average Loss: 3.705, avg. samples / sec: 66228.87
Iteration:    600, Loss function: 6.096, Average Loss: 3.721, avg. samples / sec: 66143.89
Iteration:    600, Loss function: 6.055, Average Loss: 3.688, avg. samples / sec: 66212.44
Iteration:    600, Loss function: 5.339, Average Loss: 3.705, avg. samples / sec: 66198.45
Iteration:    600, Loss function: 5.907, Average Loss: 3.711, avg. samples / sec: 66078.82
Iteration:    600, Loss function: 5.847, Average Loss: 3.725, avg. samples / sec: 66217.30
Iteration:    600, Loss function: 5.077, Average Loss: 3.702, avg. samples / sec: 66127.44
Iteration:    600, Loss function: 5.772, Average Loss: 3.713, avg. samples / sec: 66180.01
Iteration:    600, Loss function: 5.545, Average Loss: 3.696, avg. samples / sec: 66166.15
Iteration:    600, Loss function: 6.042, Average Loss: 3.704, avg. samples / sec: 66041.20
Iteration:    600, Loss function: 6.719, Average Loss: 3.708, avg. samples / sec: 66121.08
Iteration:    600, Loss function: 5.604, Average Loss: 3.704, avg. samples / sec: 66078.60
Iteration:    600, Loss function: 5.355, Average Loss: 3.698, avg. samples / sec: 66288.93
Iteration:    600, Loss function: 6.143, Average Loss: 3.712, avg. samples / sec: 66116.89
Iteration:    600, Loss function: 7.052, Average Loss: 3.707, avg. samples / sec: 66136.25
Iteration:    600, Loss function: 5.930, Average Loss: 3.734, avg. samples / sec: 66147.89
Iteration:    600, Loss function: 6.133, Average Loss: 3.704, avg. samples / sec: 66173.80
Iteration:    600, Loss function: 5.922, Average Loss: 3.703, avg. samples / sec: 66112.39
Iteration:    600, Loss function: 5.614, Average Loss: 3.715, avg. samples / sec: 66033.68
Iteration:    600, Loss function: 5.645, Average Loss: 3.718, avg. samples / sec: 66037.52
Iteration:    600, Loss function: 5.151, Average Loss: 3.692, avg. samples / sec: 66048.16
Iteration:    600, Loss function: 5.349, Average Loss: 3.711, avg. samples / sec: 66054.94
Iteration:    620, Loss function: 5.518, Average Loss: 3.759, avg. samples / sec: 66639.81
Iteration:    620, Loss function: 5.651, Average Loss: 3.737, avg. samples / sec: 66559.21
Iteration:    620, Loss function: 5.739, Average Loss: 3.764, avg. samples / sec: 66492.60
Iteration:    620, Loss function: 5.803, Average Loss: 3.751, avg. samples / sec: 66510.59
Iteration:    620, Loss function: 5.679, Average Loss: 3.735, avg. samples / sec: 66370.63
Iteration:    620, Loss function: 7.566, Average Loss: 3.737, avg. samples / sec: 66346.70
Iteration:    620, Loss function: 6.025, Average Loss: 3.744, avg. samples / sec: 66410.04
Iteration:    620, Loss function: 5.985, Average Loss: 3.764, avg. samples / sec: 66459.96
Iteration:    620, Loss function: 5.398, Average Loss: 3.748, avg. samples / sec: 66476.86
Iteration:    620, Loss function: 5.638, Average Loss: 3.735, avg. samples / sec: 66556.38
Iteration:    620, Loss function: 7.402, Average Loss: 3.752, avg. samples / sec: 66417.36
Iteration:    620, Loss function: 5.555, Average Loss: 3.752, avg. samples / sec: 66424.94
Iteration:    620, Loss function: 5.476, Average Loss: 3.725, avg. samples / sec: 66221.68
Iteration:    620, Loss function: 6.387, Average Loss: 3.747, avg. samples / sec: 66343.29
Iteration:    620, Loss function: 7.001, Average Loss: 3.762, avg. samples / sec: 66487.62
Iteration:    620, Loss function: 5.560, Average Loss: 3.757, avg. samples / sec: 66396.02
Iteration:    620, Loss function: 5.844, Average Loss: 3.747, avg. samples / sec: 66468.61
Iteration:    620, Loss function: 6.516, Average Loss: 3.749, avg. samples / sec: 66322.31
Iteration:    620, Loss function: 5.300, Average Loss: 3.745, avg. samples / sec: 66303.72
Iteration:    620, Loss function: 5.622, Average Loss: 3.733, avg. samples / sec: 66312.98
Iteration:    620, Loss function: 6.604, Average Loss: 3.753, avg. samples / sec: 66417.87
Iteration:    620, Loss function: 5.188, Average Loss: 3.757, avg. samples / sec: 66486.17
Iteration:    620, Loss function: 7.596, Average Loss: 3.782, avg. samples / sec: 66417.15
Iteration:    620, Loss function: 5.265, Average Loss: 3.731, avg. samples / sec: 66266.58
Iteration:    620, Loss function: 5.744, Average Loss: 3.750, avg. samples / sec: 66287.59
Iteration:    620, Loss function: 6.115, Average Loss: 3.738, avg. samples / sec: 66273.69
Iteration:    620, Loss function: 5.948, Average Loss: 3.745, avg. samples / sec: 66340.33
Iteration:    620, Loss function: 4.742, Average Loss: 3.742, avg. samples / sec: 66257.42
Iteration:    620, Loss function: 6.413, Average Loss: 3.745, avg. samples / sec: 66229.68
Iteration:    620, Loss function: 6.260, Average Loss: 3.752, avg. samples / sec: 66243.32
:::MLL 1558651540.296 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558651540.296 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 4.837, Average Loss: 3.775, avg. samples / sec: 66158.95
Iteration:    640, Loss function: 5.357, Average Loss: 3.790, avg. samples / sec: 66371.98
Iteration:    640, Loss function: 5.820, Average Loss: 3.769, avg. samples / sec: 66220.22
Iteration:    640, Loss function: 5.762, Average Loss: 3.777, avg. samples / sec: 66139.05
Iteration:    640, Loss function: 4.372, Average Loss: 3.787, avg. samples / sec: 66216.05
Iteration:    640, Loss function: 5.213, Average Loss: 3.784, avg. samples / sec: 66082.69
Iteration:    640, Loss function: 5.139, Average Loss: 3.795, avg. samples / sec: 66049.77
Iteration:    640, Loss function: 5.070, Average Loss: 3.771, avg. samples / sec: 66299.38
Iteration:    640, Loss function: 5.723, Average Loss: 3.777, avg. samples / sec: 66137.90
Iteration:    640, Loss function: 5.686, Average Loss: 3.784, avg. samples / sec: 66104.27
Iteration:    640, Loss function: 5.830, Average Loss: 3.787, avg. samples / sec: 66129.05
Iteration:    640, Loss function: 6.305, Average Loss: 3.785, avg. samples / sec: 66309.42
Iteration:    640, Loss function: 5.759, Average Loss: 3.821, avg. samples / sec: 66220.53
Iteration:    640, Loss function: 5.081, Average Loss: 3.796, avg. samples / sec: 66125.30
Iteration:    640, Loss function: 7.246, Average Loss: 3.774, avg. samples / sec: 66217.05
Iteration:    640, Loss function: 4.731, Average Loss: 3.793, avg. samples / sec: 66182.22
Iteration:    640, Loss function: 6.849, Average Loss: 3.785, avg. samples / sec: 66173.70
Iteration:    640, Loss function: 5.908, Average Loss: 3.777, avg. samples / sec: 66260.13
Iteration:    640, Loss function: 5.559, Average Loss: 3.790, avg. samples / sec: 66083.04
Iteration:    640, Loss function: 7.341, Average Loss: 3.807, avg. samples / sec: 66027.12
Iteration:    640, Loss function: 4.852, Average Loss: 3.801, avg. samples / sec: 66097.29
Iteration:    640, Loss function: 6.557, Average Loss: 3.784, avg. samples / sec: 66139.67
Iteration:    640, Loss function: 5.513, Average Loss: 3.787, avg. samples / sec: 65991.56
Iteration:    640, Loss function: 5.587, Average Loss: 3.790, avg. samples / sec: 66187.22
Iteration:    640, Loss function: 5.661, Average Loss: 3.788, avg. samples / sec: 66075.07
Iteration:    640, Loss function: 6.156, Average Loss: 3.787, avg. samples / sec: 66161.65
Iteration:    640, Loss function: 5.777, Average Loss: 3.813, avg. samples / sec: 65916.90
Iteration:    640, Loss function: 6.837, Average Loss: 3.791, avg. samples / sec: 66057.57
Iteration:    640, Loss function: 4.885, Average Loss: 3.797, avg. samples / sec: 65989.90
Iteration:    640, Loss function: 6.651, Average Loss: 3.794, avg. samples / sec: 66154.41
Iteration:    660, Loss function: 5.627, Average Loss: 3.816, avg. samples / sec: 66516.83
Iteration:    660, Loss function: 5.694, Average Loss: 3.830, avg. samples / sec: 66711.26
Iteration:    660, Loss function: 6.663, Average Loss: 3.858, avg. samples / sec: 66697.18
Iteration:    660, Loss function: 4.850, Average Loss: 3.816, avg. samples / sec: 66500.64
Iteration:    660, Loss function: 6.070, Average Loss: 3.827, avg. samples / sec: 66630.30
Iteration:    660, Loss function: 6.624, Average Loss: 3.838, avg. samples / sec: 66488.56
Iteration:    660, Loss function: 5.219, Average Loss: 3.852, avg. samples / sec: 66530.37
Iteration:    660, Loss function: 5.700, Average Loss: 3.801, avg. samples / sec: 66456.01
Iteration:    660, Loss function: 5.477, Average Loss: 3.826, avg. samples / sec: 66448.96
Iteration:    660, Loss function: 6.135, Average Loss: 3.829, avg. samples / sec: 66563.96
Iteration:    660, Loss function: 6.956, Average Loss: 3.814, avg. samples / sec: 66511.53
Iteration:    660, Loss function: 6.327, Average Loss: 3.810, avg. samples / sec: 66459.15
Iteration:    660, Loss function: 7.076, Average Loss: 3.834, avg. samples / sec: 66478.68
Iteration:    660, Loss function: 5.682, Average Loss: 3.822, avg. samples / sec: 66476.73
Iteration:    660, Loss function: 5.782, Average Loss: 3.835, avg. samples / sec: 66489.84
Iteration:    660, Loss function: 6.315, Average Loss: 3.818, avg. samples / sec: 66456.92
Iteration:    660, Loss function: 5.463, Average Loss: 3.824, avg. samples / sec: 66556.35
Iteration:    660, Loss function: 5.413, Average Loss: 3.820, avg. samples / sec: 66469.40
Iteration:    660, Loss function: 6.234, Average Loss: 3.821, avg. samples / sec: 66397.02
Iteration:    660, Loss function: 6.100, Average Loss: 3.828, avg. samples / sec: 66370.35
Iteration:    660, Loss function: 6.457, Average Loss: 3.829, avg. samples / sec: 66511.21
Iteration:    660, Loss function: 5.999, Average Loss: 3.833, avg. samples / sec: 66605.01
Iteration:    660, Loss function: 6.105, Average Loss: 3.820, avg. samples / sec: 66386.02
Iteration:    660, Loss function: 5.640, Average Loss: 3.824, avg. samples / sec: 66516.42
Iteration:    660, Loss function: 6.536, Average Loss: 3.841, avg. samples / sec: 66448.59
Iteration:    660, Loss function: 5.152, Average Loss: 3.847, avg. samples / sec: 66431.70
Iteration:    660, Loss function: 6.972, Average Loss: 3.836, avg. samples / sec: 66536.59
Iteration:    660, Loss function: 5.828, Average Loss: 3.832, avg. samples / sec: 66334.99
Iteration:    660, Loss function: 6.617, Average Loss: 3.830, avg. samples / sec: 66463.66
Iteration:    660, Loss function: 7.033, Average Loss: 3.821, avg. samples / sec: 66296.82
Iteration:    680, Loss function: 5.987, Average Loss: 3.884, avg. samples / sec: 66508.42
Iteration:    680, Loss function: 5.142, Average Loss: 3.850, avg. samples / sec: 66337.83
Iteration:    680, Loss function: 4.583, Average Loss: 3.865, avg. samples / sec: 66283.88
Iteration:    680, Loss function: 6.651, Average Loss: 3.869, avg. samples / sec: 66223.36
Iteration:    680, Loss function: 4.479, Average Loss: 3.840, avg. samples / sec: 66267.02
Iteration:    680, Loss function: 5.181, Average Loss: 3.863, avg. samples / sec: 66302.75
Iteration:    680, Loss function: 6.127, Average Loss: 3.866, avg. samples / sec: 66367.51
Iteration:    680, Loss function: 5.215, Average Loss: 3.863, avg. samples / sec: 66237.53
Iteration:    680, Loss function: 6.031, Average Loss: 3.883, avg. samples / sec: 66385.95
Iteration:    680, Loss function: 7.246, Average Loss: 3.854, avg. samples / sec: 66264.96
Iteration:    680, Loss function: 4.309, Average Loss: 3.868, avg. samples / sec: 66358.23
Iteration:    680, Loss function: 4.889, Average Loss: 3.865, avg. samples / sec: 66230.46
Iteration:    680, Loss function: 5.481, Average Loss: 3.863, avg. samples / sec: 66291.40
Iteration:    680, Loss function: 5.430, Average Loss: 3.897, avg. samples / sec: 66194.00
Iteration:    680, Loss function: 4.658, Average Loss: 3.868, avg. samples / sec: 66262.97
Iteration:    680, Loss function: 5.343, Average Loss: 3.855, avg. samples / sec: 66153.02
Iteration:    680, Loss function: 4.584, Average Loss: 3.892, avg. samples / sec: 66198.26
Iteration:    680, Loss function: 6.491, Average Loss: 3.872, avg. samples / sec: 66358.63
Iteration:    680, Loss function: 5.935, Average Loss: 3.865, avg. samples / sec: 66406.60
Iteration:    680, Loss function: 5.360, Average Loss: 3.854, avg. samples / sec: 66212.04
Iteration:    680, Loss function: 7.068, Average Loss: 3.874, avg. samples / sec: 66362.79
Iteration:    680, Loss function: 5.029, Average Loss: 3.855, avg. samples / sec: 66149.54
Iteration:    680, Loss function: 5.931, Average Loss: 3.864, avg. samples / sec: 66396.74
Iteration:    680, Loss function: 5.618, Average Loss: 3.870, avg. samples / sec: 66242.72
Iteration:    680, Loss function: 4.498, Average Loss: 3.861, avg. samples / sec: 66216.18
Iteration:    680, Loss function: 7.071, Average Loss: 3.876, avg. samples / sec: 66117.11
Iteration:    680, Loss function: 5.650, Average Loss: 3.873, avg. samples / sec: 66145.22
Iteration:    680, Loss function: 5.683, Average Loss: 3.866, avg. samples / sec: 66244.59
Iteration:    680, Loss function: 5.452, Average Loss: 3.862, avg. samples / sec: 66212.97
Iteration:    680, Loss function: 5.981, Average Loss: 3.865, avg. samples / sec: 66072.22
:::MLL 1558651542.069 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558651542.070 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 5.338, Average Loss: 3.907, avg. samples / sec: 66405.57
Iteration:    700, Loss function: 6.529, Average Loss: 3.900, avg. samples / sec: 66592.58
Iteration:    700, Loss function: 6.935, Average Loss: 3.911, avg. samples / sec: 66441.79
Iteration:    700, Loss function: 5.631, Average Loss: 3.898, avg. samples / sec: 66385.89
Iteration:    700, Loss function: 5.765, Average Loss: 3.890, avg. samples / sec: 66253.31
Iteration:    700, Loss function: 6.172, Average Loss: 3.906, avg. samples / sec: 66379.04
Iteration:    700, Loss function: 5.647, Average Loss: 3.910, avg. samples / sec: 66415.39
Iteration:    700, Loss function: 5.208, Average Loss: 3.933, avg. samples / sec: 66293.64
Iteration:    700, Loss function: 5.581, Average Loss: 3.897, avg. samples / sec: 66293.77
Iteration:    700, Loss function: 7.497, Average Loss: 3.903, avg. samples / sec: 66247.89
Iteration:    700, Loss function: 5.607, Average Loss: 3.910, avg. samples / sec: 66394.99
Iteration:    700, Loss function: 6.371, Average Loss: 3.907, avg. samples / sec: 66258.11
Iteration:    700, Loss function: 6.487, Average Loss: 3.921, avg. samples / sec: 66128.34
Iteration:    700, Loss function: 6.069, Average Loss: 3.898, avg. samples / sec: 66391.86
Iteration:    700, Loss function: 5.426, Average Loss: 3.902, avg. samples / sec: 66168.67
Iteration:    700, Loss function: 5.907, Average Loss: 3.872, avg. samples / sec: 66170.29
Iteration:    700, Loss function: 5.416, Average Loss: 3.889, avg. samples / sec: 66216.21
Iteration:    700, Loss function: 6.268, Average Loss: 3.901, avg. samples / sec: 66178.96
Iteration:    700, Loss function: 7.071, Average Loss: 3.906, avg. samples / sec: 66202.80
Iteration:    700, Loss function: 6.424, Average Loss: 3.902, avg. samples / sec: 66139.67
Iteration:    700, Loss function: 5.798, Average Loss: 3.910, avg. samples / sec: 66272.07
Iteration:    700, Loss function: 5.205, Average Loss: 3.930, avg. samples / sec: 66180.88
Iteration:    700, Loss function: 5.526, Average Loss: 3.915, avg. samples / sec: 66127.90
Iteration:    700, Loss function: 6.131, Average Loss: 3.894, avg. samples / sec: 66207.53
Iteration:    700, Loss function: 5.681, Average Loss: 3.907, avg. samples / sec: 66107.71
Iteration:    700, Loss function: 6.120, Average Loss: 3.894, avg. samples / sec: 66145.07
Iteration:    700, Loss function: 6.642, Average Loss: 3.910, avg. samples / sec: 66167.61
Iteration:    700, Loss function: 6.010, Average Loss: 3.888, avg. samples / sec: 66056.61
Iteration:    700, Loss function: 5.803, Average Loss: 3.912, avg. samples / sec: 66122.44
Iteration:    700, Loss function: 6.399, Average Loss: 3.907, avg. samples / sec: 66128.37
Iteration:    720, Loss function: 5.767, Average Loss: 3.949, avg. samples / sec: 66267.99
Iteration:    720, Loss function: 5.712, Average Loss: 3.924, avg. samples / sec: 66355.04
Iteration:    720, Loss function: 4.010, Average Loss: 3.903, avg. samples / sec: 66341.64
Iteration:    720, Loss function: 5.873, Average Loss: 3.931, avg. samples / sec: 66186.45
Iteration:    720, Loss function: 5.270, Average Loss: 3.938, avg. samples / sec: 66080.15
Iteration:    720, Loss function: 4.600, Average Loss: 3.944, avg. samples / sec: 66439.53
Iteration:    720, Loss function: 5.741, Average Loss: 3.936, avg. samples / sec: 66317.44
Iteration:    720, Loss function: 4.472, Average Loss: 3.929, avg. samples / sec: 66275.90
Iteration:    720, Loss function: 6.575, Average Loss: 3.949, avg. samples / sec: 66236.00
Iteration:    720, Loss function: 6.121, Average Loss: 3.961, avg. samples / sec: 66347.20
Iteration:    720, Loss function: 5.118, Average Loss: 3.924, avg. samples / sec: 66416.71
Iteration:    720, Loss function: 6.067, Average Loss: 3.939, avg. samples / sec: 66186.13
Iteration:    720, Loss function: 5.392, Average Loss: 3.932, avg. samples / sec: 66281.26
Iteration:    720, Loss function: 4.322, Average Loss: 3.926, avg. samples / sec: 66382.51
Iteration:    720, Loss function: 6.023, Average Loss: 3.931, avg. samples / sec: 66186.07
Iteration:    720, Loss function: 3.911, Average Loss: 3.944, avg. samples / sec: 66286.91
Iteration:    720, Loss function: 5.440, Average Loss: 3.936, avg. samples / sec: 66248.86
Iteration:    720, Loss function: 5.067, Average Loss: 3.936, avg. samples / sec: 66119.56
Iteration:    720, Loss function: 5.319, Average Loss: 3.942, avg. samples / sec: 66293.08
Iteration:    720, Loss function: 4.140, Average Loss: 3.951, avg. samples / sec: 66193.04
Iteration:    720, Loss function: 5.320, Average Loss: 3.931, avg. samples / sec: 66096.30
Iteration:    720, Loss function: 5.539, Average Loss: 3.929, avg. samples / sec: 66186.73
Iteration:    720, Loss function: 5.188, Average Loss: 3.944, avg. samples / sec: 66128.18
Iteration:    720, Loss function: 5.450, Average Loss: 3.940, avg. samples / sec: 66348.29
Iteration:    720, Loss function: 6.083, Average Loss: 3.940, avg. samples / sec: 66322.16
Iteration:    720, Loss function: 5.355, Average Loss: 3.962, avg. samples / sec: 66082.73
Iteration:    720, Loss function: 4.516, Average Loss: 3.941, avg. samples / sec: 66075.32
Iteration:    720, Loss function: 4.952, Average Loss: 3.929, avg. samples / sec: 66252.66
Iteration:    720, Loss function: 4.835, Average Loss: 3.923, avg. samples / sec: 66020.59
Iteration:    720, Loss function: 5.974, Average Loss: 3.945, avg. samples / sec: 66247.15
Iteration:    740, Loss function: 5.464, Average Loss: 3.981, avg. samples / sec: 66335.08
Iteration:    740, Loss function: 4.710, Average Loss: 3.964, avg. samples / sec: 66439.60
Iteration:    740, Loss function: 6.679, Average Loss: 3.973, avg. samples / sec: 66430.86
Iteration:    740, Loss function: 6.221, Average Loss: 3.975, avg. samples / sec: 66454.38
Iteration:    740, Loss function: 6.127, Average Loss: 3.968, avg. samples / sec: 66368.04
Iteration:    740, Loss function: 5.250, Average Loss: 3.953, avg. samples / sec: 66295.23
Iteration:    740, Loss function: 4.798, Average Loss: 3.963, avg. samples / sec: 66381.76
Iteration:    740, Loss function: 5.412, Average Loss: 3.962, avg. samples / sec: 66349.54
Iteration:    740, Loss function: 4.761, Average Loss: 3.951, avg. samples / sec: 66481.25
Iteration:    740, Loss function: 5.533, Average Loss: 3.960, avg. samples / sec: 66295.51
Iteration:    740, Loss function: 5.864, Average Loss: 3.969, avg. samples / sec: 66356.13
Iteration:    740, Loss function: 4.625, Average Loss: 3.967, avg. samples / sec: 66432.96
Iteration:    740, Loss function: 4.829, Average Loss: 3.964, avg. samples / sec: 66379.20
Iteration:    740, Loss function: 6.359, Average Loss: 3.965, avg. samples / sec: 66391.77
Iteration:    740, Loss function: 6.431, Average Loss: 3.934, avg. samples / sec: 66247.33
Iteration:    740, Loss function: 4.423, Average Loss: 3.973, avg. samples / sec: 66412.61
Iteration:    740, Loss function: 6.507, Average Loss: 3.973, avg. samples / sec: 66283.76
Iteration:    740, Loss function: 6.375, Average Loss: 3.970, avg. samples / sec: 66257.21
Iteration:    740, Loss function: 4.983, Average Loss: 3.979, avg. samples / sec: 66437.75
Iteration:    740, Loss function: 5.515, Average Loss: 3.999, avg. samples / sec: 66405.47
Iteration:    740, Loss function: 5.817, Average Loss: 3.966, avg. samples / sec: 66296.57
Iteration:    740, Loss function: 6.421, Average Loss: 3.983, avg. samples / sec: 66252.60
Iteration:    740, Loss function: 5.632, Average Loss: 3.952, avg. samples / sec: 66271.82
Iteration:    740, Loss function: 6.401, Average Loss: 3.970, avg. samples / sec: 66327.21
Iteration:    740, Loss function: 5.955, Average Loss: 3.962, avg. samples / sec: 66330.62
Iteration:    740, Loss function: 5.259, Average Loss: 3.958, avg. samples / sec: 66252.35
Iteration:    740, Loss function: 5.852, Average Loss: 3.974, avg. samples / sec: 66298.54
Iteration:    740, Loss function: 4.903, Average Loss: 3.984, avg. samples / sec: 66252.88
Iteration:    740, Loss function: 5.249, Average Loss: 3.991, avg. samples / sec: 66137.43
Iteration:    740, Loss function: 5.810, Average Loss: 3.960, avg. samples / sec: 66041.69
Iteration:    760, Loss function: 5.305, Average Loss: 4.013, avg. samples / sec: 66684.12
Iteration:    760, Loss function: 6.927, Average Loss: 4.009, avg. samples / sec: 66408.44
Iteration:    760, Loss function: 6.050, Average Loss: 3.973, avg. samples / sec: 66527.13
Iteration:    760, Loss function: 6.168, Average Loss: 3.982, avg. samples / sec: 66485.11
Iteration:    760, Loss function: 6.103, Average Loss: 3.986, avg. samples / sec: 66449.71
Iteration:    760, Loss function: 5.273, Average Loss: 4.030, avg. samples / sec: 66513.22
Iteration:    760, Loss function: 5.462, Average Loss: 4.001, avg. samples / sec: 66474.88
Iteration:    760, Loss function: 5.600, Average Loss: 3.996, avg. samples / sec: 66359.19
Iteration:    760, Loss function: 5.606, Average Loss: 3.998, avg. samples / sec: 66509.71
Iteration:    760, Loss function: 5.236, Average Loss: 4.003, avg. samples / sec: 66431.99
Iteration:    760, Loss function: 5.348, Average Loss: 4.005, avg. samples / sec: 66410.35
Iteration:    760, Loss function: 5.931, Average Loss: 4.004, avg. samples / sec: 66474.88
Iteration:    760, Loss function: 4.831, Average Loss: 4.000, avg. samples / sec: 66428.73
Iteration:    760, Loss function: 4.681, Average Loss: 3.991, avg. samples / sec: 66454.54
Iteration:    760, Loss function: 6.533, Average Loss: 4.009, avg. samples / sec: 66533.98
Iteration:    760, Loss function: 6.101, Average Loss: 4.001, avg. samples / sec: 66500.04
Iteration:    760, Loss function: 5.682, Average Loss: 3.999, avg. samples / sec: 66402.56
Iteration:    760, Loss function: 4.698, Average Loss: 4.003, avg. samples / sec: 66325.84
Iteration:    760, Loss function: 4.755, Average Loss: 3.995, avg. samples / sec: 66427.73
Iteration:    760, Loss function: 5.750, Average Loss: 3.996, avg. samples / sec: 66395.93
Iteration:    760, Loss function: 6.214, Average Loss: 4.005, avg. samples / sec: 66418.27
Iteration:    760, Loss function: 5.469, Average Loss: 3.993, avg. samples / sec: 66498.13
Iteration:    760, Loss function: 5.454, Average Loss: 4.021, avg. samples / sec: 66578.68
Iteration:    760, Loss function: 5.219, Average Loss: 4.007, avg. samples / sec: 66317.57
Iteration:    760, Loss function: 5.908, Average Loss: 3.998, avg. samples / sec: 66376.51
Iteration:    760, Loss function: 6.305, Average Loss: 4.011, avg. samples / sec: 66473.63
Iteration:    760, Loss function: 4.988, Average Loss: 3.988, avg. samples / sec: 66710.70
Iteration:    760, Loss function: 4.976, Average Loss: 4.011, avg. samples / sec: 66388.33
Iteration:    760, Loss function: 3.976, Average Loss: 3.984, avg. samples / sec: 66397.68
Iteration:    760, Loss function: 5.284, Average Loss: 3.998, avg. samples / sec: 66347.51
:::MLL 1558651543.845 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558651543.845 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 6.000, Average Loss: 4.001, avg. samples / sec: 65942.71
Iteration:    780, Loss function: 5.612, Average Loss: 4.014, avg. samples / sec: 65873.27
Iteration:    780, Loss function: 5.143, Average Loss: 4.023, avg. samples / sec: 65938.86
Iteration:    780, Loss function: 6.360, Average Loss: 4.031, avg. samples / sec: 65851.57
Iteration:    780, Loss function: 6.285, Average Loss: 4.038, avg. samples / sec: 65833.33
Iteration:    780, Loss function: 4.570, Average Loss: 4.028, avg. samples / sec: 65853.20
Iteration:    780, Loss function: 4.733, Average Loss: 4.007, avg. samples / sec: 65778.88
Iteration:    780, Loss function: 5.406, Average Loss: 4.035, avg. samples / sec: 65741.44
Iteration:    780, Loss function: 5.913, Average Loss: 4.049, avg. samples / sec: 65702.70
Iteration:    780, Loss function: 4.990, Average Loss: 4.032, avg. samples / sec: 65795.61
Iteration:    780, Loss function: 5.781, Average Loss: 4.009, avg. samples / sec: 65931.70
Iteration:    780, Loss function: 5.414, Average Loss: 4.027, avg. samples / sec: 65783.82
Iteration:    780, Loss function: 5.679, Average Loss: 4.029, avg. samples / sec: 65820.17
Iteration:    780, Loss function: 5.013, Average Loss: 4.021, avg. samples / sec: 65748.96
Iteration:    780, Loss function: 5.670, Average Loss: 4.038, avg. samples / sec: 65828.13
Iteration:    780, Loss function: 4.970, Average Loss: 4.018, avg. samples / sec: 65814.60
Iteration:    780, Loss function: 5.593, Average Loss: 4.051, avg. samples / sec: 65816.91
Iteration:    780, Loss function: 4.686, Average Loss: 4.032, avg. samples / sec: 65812.21
Iteration:    780, Loss function: 4.987, Average Loss: 4.012, avg. samples / sec: 65749.23
Iteration:    780, Loss function: 4.234, Average Loss: 4.033, avg. samples / sec: 65777.96
Iteration:    780, Loss function: 5.674, Average Loss: 4.057, avg. samples / sec: 65713.03
Iteration:    780, Loss function: 5.018, Average Loss: 4.013, avg. samples / sec: 65811.90
Iteration:    780, Loss function: 5.540, Average Loss: 4.037, avg. samples / sec: 65831.42
Iteration:    780, Loss function: 5.704, Average Loss: 4.034, avg. samples / sec: 65733.41
Iteration:    780, Loss function: 4.323, Average Loss: 4.018, avg. samples / sec: 65763.53
Iteration:    780, Loss function: 5.673, Average Loss: 4.014, avg. samples / sec: 65774.40
Iteration:    780, Loss function: 5.384, Average Loss: 4.028, avg. samples / sec: 65708.34
Iteration:    780, Loss function: 4.802, Average Loss: 4.020, avg. samples / sec: 65843.97
Iteration:    780, Loss function: 5.131, Average Loss: 4.031, avg. samples / sec: 65664.01
Iteration:    780, Loss function: 4.739, Average Loss: 4.031, avg. samples / sec: 65637.40
Iteration:    800, Loss function: 4.311, Average Loss: 4.052, avg. samples / sec: 66595.95
Iteration:    800, Loss function: 4.282, Average Loss: 4.028, avg. samples / sec: 66378.98
Iteration:    800, Loss function: 4.766, Average Loss: 4.058, avg. samples / sec: 66498.91
Iteration:    800, Loss function: 4.409, Average Loss: 4.083, avg. samples / sec: 66598.59
Iteration:    800, Loss function: 5.297, Average Loss: 4.045, avg. samples / sec: 66562.04
Iteration:    800, Loss function: 5.434, Average Loss: 4.042, avg. samples / sec: 66406.79
Iteration:    800, Loss function: 4.762, Average Loss: 4.057, avg. samples / sec: 66571.38
Iteration:    800, Loss function: 5.835, Average Loss: 4.036, avg. samples / sec: 66547.83
Iteration:    800, Loss function: 4.330, Average Loss: 4.041, avg. samples / sec: 66564.30
Iteration:    800, Loss function: 4.255, Average Loss: 4.048, avg. samples / sec: 66570.56
Iteration:    800, Loss function: 5.814, Average Loss: 4.060, avg. samples / sec: 66452.53
Iteration:    800, Loss function: 5.830, Average Loss: 4.058, avg. samples / sec: 66470.59
Iteration:    800, Loss function: 4.848, Average Loss: 4.049, avg. samples / sec: 66371.60
Iteration:    800, Loss function: 4.826, Average Loss: 4.036, avg. samples / sec: 66521.51
Iteration:    800, Loss function: 6.320, Average Loss: 4.077, avg. samples / sec: 66505.25
Iteration:    800, Loss function: 4.485, Average Loss: 4.034, avg. samples / sec: 66436.15
Iteration:    800, Loss function: 4.381, Average Loss: 4.052, avg. samples / sec: 66653.75
Iteration:    800, Loss function: 6.213, Average Loss: 4.075, avg. samples / sec: 66442.35
Iteration:    800, Loss function: 5.365, Average Loss: 4.055, avg. samples / sec: 66379.89
Iteration:    800, Loss function: 4.800, Average Loss: 4.030, avg. samples / sec: 66405.28
Iteration:    800, Loss function: 5.083, Average Loss: 4.061, avg. samples / sec: 66456.33
Iteration:    800, Loss function: 5.270, Average Loss: 4.054, avg. samples / sec: 66338.89
Iteration:    800, Loss function: 5.845, Average Loss: 4.044, avg. samples / sec: 66409.20
Iteration:    800, Loss function: 4.783, Average Loss: 4.057, avg. samples / sec: 66495.40
Iteration:    800, Loss function: 4.894, Average Loss: 4.057, avg. samples / sec: 66577.29
Iteration:    800, Loss function: 5.569, Average Loss: 4.066, avg. samples / sec: 66412.39
Iteration:    800, Loss function: 6.012, Average Loss: 4.066, avg. samples / sec: 66361.82
Iteration:    800, Loss function: 5.292, Average Loss: 4.056, avg. samples / sec: 66391.36
Iteration:    800, Loss function: 6.074, Average Loss: 4.056, avg. samples / sec: 66503.62
Iteration:    800, Loss function: 4.465, Average Loss: 4.060, avg. samples / sec: 66322.19
Iteration:    820, Loss function: 5.085, Average Loss: 4.072, avg. samples / sec: 66397.78
Iteration:    820, Loss function: 6.169, Average Loss: 4.093, avg. samples / sec: 66404.35
Iteration:    820, Loss function: 6.148, Average Loss: 4.089, avg. samples / sec: 66521.86
Iteration:    820, Loss function: 5.458, Average Loss: 4.090, avg. samples / sec: 66261.85
Iteration:    820, Loss function: 4.918, Average Loss: 4.093, avg. samples / sec: 66465.92
Iteration:    820, Loss function: 5.057, Average Loss: 4.080, avg. samples / sec: 66334.11
Iteration:    820, Loss function: 6.127, Average Loss: 4.067, avg. samples / sec: 66375.88
Iteration:    820, Loss function: 5.773, Average Loss: 4.083, avg. samples / sec: 66270.79
Iteration:    820, Loss function: 7.099, Average Loss: 4.114, avg. samples / sec: 66254.40
Iteration:    820, Loss function: 5.398, Average Loss: 4.095, avg. samples / sec: 66446.27
Iteration:    820, Loss function: 4.813, Average Loss: 4.078, avg. samples / sec: 66268.86
Iteration:    820, Loss function: 5.280, Average Loss: 4.088, avg. samples / sec: 66391.05
Iteration:    820, Loss function: 5.357, Average Loss: 4.096, avg. samples / sec: 66279.42
Iteration:    820, Loss function: 4.843, Average Loss: 4.062, avg. samples / sec: 66271.79
Iteration:    820, Loss function: 5.060, Average Loss: 4.082, avg. samples / sec: 66300.13
Iteration:    820, Loss function: 5.004, Average Loss: 4.086, avg. samples / sec: 66222.09
Iteration:    820, Loss function: 5.852, Average Loss: 4.076, avg. samples / sec: 66226.29
Iteration:    820, Loss function: 5.331, Average Loss: 4.110, avg. samples / sec: 66263.16
Iteration:    820, Loss function: 5.559, Average Loss: 4.060, avg. samples / sec: 66145.56
Iteration:    820, Loss function: 4.585, Average Loss: 4.069, avg. samples / sec: 66200.53
Iteration:    820, Loss function: 5.224, Average Loss: 4.092, avg. samples / sec: 66271.57
Iteration:    820, Loss function: 5.621, Average Loss: 4.086, avg. samples / sec: 66096.46
Iteration:    820, Loss function: 5.885, Average Loss: 4.060, avg. samples / sec: 66254.75
Iteration:    820, Loss function: 4.897, Average Loss: 4.083, avg. samples / sec: 66288.37
Iteration:    820, Loss function: 4.592, Average Loss: 4.087, avg. samples / sec: 66305.90
Iteration:    820, Loss function: 5.042, Average Loss: 4.084, avg. samples / sec: 66180.54
Iteration:    820, Loss function: 5.387, Average Loss: 4.087, avg. samples / sec: 66319.38
Iteration:    820, Loss function: 6.372, Average Loss: 4.096, avg. samples / sec: 66294.02
Iteration:    820, Loss function: 5.401, Average Loss: 4.105, avg. samples / sec: 66160.41
Iteration:    820, Loss function: 5.916, Average Loss: 4.074, avg. samples / sec: 66182.00
:::MLL 1558651545.620 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558651545.620 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 6.248, Average Loss: 4.098, avg. samples / sec: 66117.91
Iteration:    840, Loss function: 5.594, Average Loss: 4.096, avg. samples / sec: 66426.13
Iteration:    840, Loss function: 4.188, Average Loss: 4.122, avg. samples / sec: 66370.13
Iteration:    840, Loss function: 4.764, Average Loss: 4.114, avg. samples / sec: 66169.57
Iteration:    840, Loss function: 5.283, Average Loss: 4.112, avg. samples / sec: 66163.73
Iteration:    840, Loss function: 5.054, Average Loss: 4.121, avg. samples / sec: 66221.59
Iteration:    840, Loss function: 5.365, Average Loss: 4.104, avg. samples / sec: 66166.62
Iteration:    840, Loss function: 5.032, Average Loss: 4.082, avg. samples / sec: 66226.26
Iteration:    840, Loss function: 5.901, Average Loss: 4.115, avg. samples / sec: 66145.07
Iteration:    840, Loss function: 4.270, Average Loss: 4.080, avg. samples / sec: 66226.54
Iteration:    840, Loss function: 4.733, Average Loss: 4.130, avg. samples / sec: 66239.83
Iteration:    840, Loss function: 4.770, Average Loss: 4.096, avg. samples / sec: 66247.77
Iteration:    840, Loss function: 5.893, Average Loss: 4.103, avg. samples / sec: 66123.62
Iteration:    840, Loss function: 4.214, Average Loss: 4.116, avg. samples / sec: 66221.59
Iteration:    840, Loss function: 5.035, Average Loss: 4.139, avg. samples / sec: 66107.83
Iteration:    840, Loss function: 4.918, Average Loss: 4.084, avg. samples / sec: 66219.75
Iteration:    840, Loss function: 6.216, Average Loss: 4.108, avg. samples / sec: 66245.65
Iteration:    840, Loss function: 4.107, Average Loss: 4.104, avg. samples / sec: 66147.52
Iteration:    840, Loss function: 5.598, Average Loss: 4.113, avg. samples / sec: 66129.46
Iteration:    840, Loss function: 4.586, Average Loss: 4.093, avg. samples / sec: 66053.77
Iteration:    840, Loss function: 5.243, Average Loss: 4.105, avg. samples / sec: 66222.43
Iteration:    840, Loss function: 4.939, Average Loss: 4.115, avg. samples / sec: 66124.96
Iteration:    840, Loss function: 5.497, Average Loss: 4.111, avg. samples / sec: 66176.90
Iteration:    840, Loss function: 4.938, Average Loss: 4.103, avg. samples / sec: 66058.87
Iteration:    840, Loss function: 5.434, Average Loss: 4.118, avg. samples / sec: 66012.58
Iteration:    840, Loss function: 5.315, Average Loss: 4.113, avg. samples / sec: 66117.82
Iteration:    840, Loss function: 5.542, Average Loss: 4.107, avg. samples / sec: 66077.09
Iteration:    840, Loss function: 4.688, Average Loss: 4.111, avg. samples / sec: 65789.41
Iteration:    840, Loss function: 6.736, Average Loss: 4.133, avg. samples / sec: 65994.50
Iteration:    840, Loss function: 4.767, Average Loss: 4.098, avg. samples / sec: 65856.09
Iteration:    860, Loss function: 5.300, Average Loss: 4.152, avg. samples / sec: 66095.84
Iteration:    860, Loss function: 6.321, Average Loss: 4.105, avg. samples / sec: 66144.85
Iteration:    860, Loss function: 5.649, Average Loss: 4.128, avg. samples / sec: 66089.88
Iteration:    860, Loss function: 5.778, Average Loss: 4.106, avg. samples / sec: 66080.49
Iteration:    860, Loss function: 6.067, Average Loss: 4.129, avg. samples / sec: 66012.31
Iteration:    860, Loss function: 6.309, Average Loss: 4.127, avg. samples / sec: 66161.53
Iteration:    860, Loss function: 5.002, Average Loss: 4.136, avg. samples / sec: 66322.44
Iteration:    860, Loss function: 6.058, Average Loss: 4.150, avg. samples / sec: 65991.97
Iteration:    860, Loss function: 4.276, Average Loss: 4.095, avg. samples / sec: 66007.36
Iteration:    860, Loss function: 4.937, Average Loss: 4.122, avg. samples / sec: 66372.35
Iteration:    860, Loss function: 4.784, Average Loss: 4.138, avg. samples / sec: 65962.19
Iteration:    860, Loss function: 5.838, Average Loss: 4.117, avg. samples / sec: 66065.44
Iteration:    860, Loss function: 4.352, Average Loss: 4.159, avg. samples / sec: 66038.82
Iteration:    860, Loss function: 4.369, Average Loss: 4.125, avg. samples / sec: 66005.13
Iteration:    860, Loss function: 4.792, Average Loss: 4.137, avg. samples / sec: 66032.72
Iteration:    860, Loss function: 5.215, Average Loss: 4.128, avg. samples / sec: 66028.26
Iteration:    860, Loss function: 5.169, Average Loss: 4.136, avg. samples / sec: 66037.48
Iteration:    860, Loss function: 5.120, Average Loss: 4.131, avg. samples / sec: 66108.73
Iteration:    860, Loss function: 4.774, Average Loss: 4.145, avg. samples / sec: 65882.51
Iteration:    860, Loss function: 4.362, Average Loss: 4.135, avg. samples / sec: 66045.56
Iteration:    860, Loss function: 4.486, Average Loss: 4.129, avg. samples / sec: 65970.71
Iteration:    860, Loss function: 5.747, Average Loss: 4.140, avg. samples / sec: 65972.41
Iteration:    860, Loss function: 6.569, Average Loss: 4.144, avg. samples / sec: 66040.86
Iteration:    860, Loss function: 5.630, Average Loss: 4.131, avg. samples / sec: 65857.66
Iteration:    860, Loss function: 4.837, Average Loss: 4.134, avg. samples / sec: 66027.55
Iteration:    860, Loss function: 5.973, Average Loss: 4.130, avg. samples / sec: 65854.68
Iteration:    860, Loss function: 6.268, Average Loss: 4.134, avg. samples / sec: 65889.93
Iteration:    860, Loss function: 6.075, Average Loss: 4.117, avg. samples / sec: 65808.09
Iteration:    860, Loss function: 5.662, Average Loss: 4.139, avg. samples / sec: 65833.20
Iteration:    860, Loss function: 4.820, Average Loss: 4.156, avg. samples / sec: 66169.54
Iteration:    880, Loss function: 4.459, Average Loss: 4.118, avg. samples / sec: 66281.61
Iteration:    880, Loss function: 5.465, Average Loss: 4.131, avg. samples / sec: 66202.33
Iteration:    880, Loss function: 4.846, Average Loss: 4.143, avg. samples / sec: 66268.27
Iteration:    880, Loss function: 5.548, Average Loss: 4.149, avg. samples / sec: 66157.39
Iteration:    880, Loss function: 4.796, Average Loss: 4.154, avg. samples / sec: 66356.82
Iteration:    880, Loss function: 4.968, Average Loss: 4.171, avg. samples / sec: 66193.32
Iteration:    880, Loss function: 6.337, Average Loss: 4.136, avg. samples / sec: 66126.69
Iteration:    880, Loss function: 5.284, Average Loss: 4.153, avg. samples / sec: 66236.59
Iteration:    880, Loss function: 5.395, Average Loss: 4.160, avg. samples / sec: 66210.33
Iteration:    880, Loss function: 4.968, Average Loss: 4.177, avg. samples / sec: 66083.19
Iteration:    880, Loss function: 5.726, Average Loss: 4.163, avg. samples / sec: 66154.32
Iteration:    880, Loss function: 4.361, Average Loss: 4.157, avg. samples / sec: 66284.66
Iteration:    880, Loss function: 4.213, Average Loss: 4.153, avg. samples / sec: 66238.40
Iteration:    880, Loss function: 4.843, Average Loss: 4.139, avg. samples / sec: 66156.62
Iteration:    880, Loss function: 4.921, Average Loss: 4.162, avg. samples / sec: 66203.83
Iteration:    880, Loss function: 6.105, Average Loss: 4.150, avg. samples / sec: 66142.74
Iteration:    880, Loss function: 5.361, Average Loss: 4.163, avg. samples / sec: 66302.31
Iteration:    880, Loss function: 5.293, Average Loss: 4.166, avg. samples / sec: 66215.58
Iteration:    880, Loss function: 4.785, Average Loss: 4.154, avg. samples / sec: 66106.07
Iteration:    880, Loss function: 5.860, Average Loss: 4.187, avg. samples / sec: 66124.21
Iteration:    880, Loss function: 5.723, Average Loss: 4.157, avg. samples / sec: 66019.91
Iteration:    880, Loss function: 5.460, Average Loss: 4.163, avg. samples / sec: 66110.16
Iteration:    880, Loss function: 5.629, Average Loss: 4.171, avg. samples / sec: 66200.59
Iteration:    880, Loss function: 6.138, Average Loss: 4.143, avg. samples / sec: 66255.65
Iteration:    880, Loss function: 4.901, Average Loss: 4.157, avg. samples / sec: 66141.25
Iteration:    880, Loss function: 4.139, Average Loss: 4.154, avg. samples / sec: 66180.66
Iteration:    880, Loss function: 5.473, Average Loss: 4.178, avg. samples / sec: 66258.92
Iteration:    880, Loss function: 5.007, Average Loss: 4.160, avg. samples / sec: 66185.45
Iteration:    880, Loss function: 5.365, Average Loss: 4.160, avg. samples / sec: 66173.58
Iteration:    880, Loss function: 4.263, Average Loss: 4.160, avg. samples / sec: 66054.60
Iteration:    900, Loss function: 4.839, Average Loss: 4.184, avg. samples / sec: 66418.18
Iteration:    900, Loss function: 5.675, Average Loss: 4.177, avg. samples / sec: 66256.68
Iteration:    900, Loss function: 4.632, Average Loss: 4.179, avg. samples / sec: 66250.76
Iteration:    900, Loss function: 5.128, Average Loss: 4.184, avg. samples / sec: 66214.37
Iteration:    900, Loss function: 3.926, Average Loss: 4.205, avg. samples / sec: 66289.12
Iteration:    900, Loss function: 5.203, Average Loss: 4.199, avg. samples / sec: 66217.51
Iteration:    900, Loss function: 3.809, Average Loss: 4.189, avg. samples / sec: 66183.43
Iteration:    900, Loss function: 5.395, Average Loss: 4.176, avg. samples / sec: 66300.13
Iteration:    900, Loss function: 5.727, Average Loss: 4.173, avg. samples / sec: 66161.31
Iteration:    900, Loss function: 4.962, Average Loss: 4.168, avg. samples / sec: 66188.99
Iteration:    900, Loss function: 5.251, Average Loss: 4.159, avg. samples / sec: 66231.83
Iteration:    900, Loss function: 3.621, Average Loss: 4.161, avg. samples / sec: 66143.02
Iteration:    900, Loss function: 5.445, Average Loss: 4.173, avg. samples / sec: 66241.26
Iteration:    900, Loss function: 4.522, Average Loss: 4.177, avg. samples / sec: 66236.34
Iteration:    900, Loss function: 4.268, Average Loss: 4.164, avg. samples / sec: 66073.00
Iteration:    900, Loss function: 6.649, Average Loss: 4.198, avg. samples / sec: 66232.30
Iteration:    900, Loss function: 4.927, Average Loss: 4.188, avg. samples / sec: 66207.56
Iteration:    900, Loss function: 5.266, Average Loss: 4.187, avg. samples / sec: 66090.50
Iteration:    900, Loss function: 4.320, Average Loss: 4.153, avg. samples / sec: 65971.67
Iteration:    900, Loss function: 5.110, Average Loss: 4.171, avg. samples / sec: 66187.72
Iteration:    900, Loss function: 4.572, Average Loss: 4.181, avg. samples / sec: 66189.68
Iteration:    900, Loss function: 5.045, Average Loss: 4.186, avg. samples / sec: 66137.31
Iteration:    900, Loss function: 5.725, Average Loss: 4.197, avg. samples / sec: 66158.20
Iteration:    900, Loss function: 5.233, Average Loss: 4.152, avg. samples / sec: 66001.11
Iteration:    900, Loss function: 4.702, Average Loss: 4.188, avg. samples / sec: 66083.25
Iteration:    900, Loss function: 4.322, Average Loss: 4.183, avg. samples / sec: 66096.05
Iteration:    900, Loss function: 4.177, Average Loss: 4.175, avg. samples / sec: 66159.10
Iteration:    900, Loss function: 5.603, Average Loss: 4.138, avg. samples / sec: 65908.91
Iteration:    900, Loss function: 4.264, Average Loss: 4.182, avg. samples / sec: 66209.08
Iteration:    900, Loss function: 5.065, Average Loss: 4.160, avg. samples / sec: 66053.61
:::MLL 1558651547.400 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558651547.400 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 5.187, Average Loss: 4.178, avg. samples / sec: 66013.79
Iteration:    920, Loss function: 4.653, Average Loss: 4.207, avg. samples / sec: 66067.61
Iteration:    920, Loss function: 4.974, Average Loss: 4.175, avg. samples / sec: 66106.53
Iteration:    920, Loss function: 4.414, Average Loss: 4.221, avg. samples / sec: 65917.79
Iteration:    920, Loss function: 5.121, Average Loss: 4.191, avg. samples / sec: 65961.14
Iteration:    920, Loss function: 5.805, Average Loss: 4.203, avg. samples / sec: 65906.17
Iteration:    920, Loss function: 4.584, Average Loss: 4.202, avg. samples / sec: 65884.08
Iteration:    920, Loss function: 5.747, Average Loss: 4.160, avg. samples / sec: 66078.51
Iteration:    920, Loss function: 4.315, Average Loss: 4.218, avg. samples / sec: 65858.65
Iteration:    920, Loss function: 5.466, Average Loss: 4.201, avg. samples / sec: 65865.36
Iteration:    920, Loss function: 3.568, Average Loss: 4.193, avg. samples / sec: 65828.81
Iteration:    920, Loss function: 4.499, Average Loss: 4.199, avg. samples / sec: 65891.23
Iteration:    920, Loss function: 4.008, Average Loss: 4.204, avg. samples / sec: 65983.41
Iteration:    920, Loss function: 4.939, Average Loss: 4.213, avg. samples / sec: 66003.46
Iteration:    920, Loss function: 5.186, Average Loss: 4.191, avg. samples / sec: 65873.05
Iteration:    920, Loss function: 4.615, Average Loss: 4.183, avg. samples / sec: 65854.00
Iteration:    920, Loss function: 4.355, Average Loss: 4.214, avg. samples / sec: 65976.18
Iteration:    920, Loss function: 4.145, Average Loss: 4.194, avg. samples / sec: 65793.10
Iteration:    920, Loss function: 4.791, Average Loss: 4.191, avg. samples / sec: 65817.46
Iteration:    920, Loss function: 4.851, Average Loss: 4.180, avg. samples / sec: 65864.74
Iteration:    920, Loss function: 4.713, Average Loss: 4.202, avg. samples / sec: 65957.84
Iteration:    920, Loss function: 5.010, Average Loss: 4.198, avg. samples / sec: 65768.01
Iteration:    920, Loss function: 5.205, Average Loss: 4.187, avg. samples / sec: 65879.74
Iteration:    920, Loss function: 4.785, Average Loss: 4.173, avg. samples / sec: 65924.18
Iteration:    920, Loss function: 4.752, Average Loss: 4.215, avg. samples / sec: 65860.25
Iteration:    920, Loss function: 6.006, Average Loss: 4.200, avg. samples / sec: 65969.26
Iteration:    920, Loss function: 3.828, Average Loss: 4.195, avg. samples / sec: 65940.34
Iteration:    920, Loss function: 4.836, Average Loss: 4.201, avg. samples / sec: 65851.05
Iteration:    920, Loss function: 4.888, Average Loss: 4.178, avg. samples / sec: 65939.20
Iteration:    920, Loss function: 5.860, Average Loss: 4.207, avg. samples / sec: 65845.39
Iteration:    940, Loss function: 4.682, Average Loss: 4.239, avg. samples / sec: 66520.79
Iteration:    940, Loss function: 6.096, Average Loss: 4.175, avg. samples / sec: 66468.61
Iteration:    940, Loss function: 5.533, Average Loss: 4.223, avg. samples / sec: 66460.31
Iteration:    940, Loss function: 6.260, Average Loss: 4.228, avg. samples / sec: 66486.05
Iteration:    940, Loss function: 4.438, Average Loss: 4.195, avg. samples / sec: 66582.64
Iteration:    940, Loss function: 5.504, Average Loss: 4.195, avg. samples / sec: 66331.96
Iteration:    940, Loss function: 5.367, Average Loss: 4.211, avg. samples / sec: 66437.87
Iteration:    940, Loss function: 5.111, Average Loss: 4.196, avg. samples / sec: 66602.65
Iteration:    940, Loss function: 4.606, Average Loss: 4.216, avg. samples / sec: 66349.01
Iteration:    940, Loss function: 5.374, Average Loss: 4.204, avg. samples / sec: 66484.61
Iteration:    940, Loss function: 4.376, Average Loss: 4.199, avg. samples / sec: 66285.63
Iteration:    940, Loss function: 4.911, Average Loss: 4.231, avg. samples / sec: 66408.35
Iteration:    940, Loss function: 5.984, Average Loss: 4.217, avg. samples / sec: 66394.52
Iteration:    940, Loss function: 5.818, Average Loss: 4.226, avg. samples / sec: 66291.30
Iteration:    940, Loss function: 5.089, Average Loss: 4.212, avg. samples / sec: 66324.56
Iteration:    940, Loss function: 6.017, Average Loss: 4.218, avg. samples / sec: 66451.41
Iteration:    940, Loss function: 5.785, Average Loss: 4.241, avg. samples / sec: 66305.84
Iteration:    940, Loss function: 5.501, Average Loss: 4.227, avg. samples / sec: 66361.16
Iteration:    940, Loss function: 6.070, Average Loss: 4.203, avg. samples / sec: 66410.67
Iteration:    940, Loss function: 5.288, Average Loss: 4.212, avg. samples / sec: 66369.04
Iteration:    940, Loss function: 3.974, Average Loss: 4.202, avg. samples / sec: 66369.60
Iteration:    940, Loss function: 5.033, Average Loss: 4.220, avg. samples / sec: 66431.36
Iteration:    940, Loss function: 6.144, Average Loss: 4.234, avg. samples / sec: 66410.20
Iteration:    940, Loss function: 5.115, Average Loss: 4.214, avg. samples / sec: 66341.01
Iteration:    940, Loss function: 4.588, Average Loss: 4.235, avg. samples / sec: 66327.40
Iteration:    940, Loss function: 4.945, Average Loss: 4.229, avg. samples / sec: 66478.36
Iteration:    940, Loss function: 5.257, Average Loss: 4.222, avg. samples / sec: 66402.84
Iteration:    940, Loss function: 4.632, Average Loss: 4.209, avg. samples / sec: 66350.26
Iteration:    940, Loss function: 6.213, Average Loss: 4.223, avg. samples / sec: 66323.94
Iteration:    940, Loss function: 6.158, Average Loss: 4.218, avg. samples / sec: 66196.55
Iteration:    960, Loss function: 4.546, Average Loss: 4.220, avg. samples / sec: 66023.22
Iteration:    960, Loss function: 4.877, Average Loss: 4.219, avg. samples / sec: 65971.42
Iteration:    960, Loss function: 4.954, Average Loss: 4.234, avg. samples / sec: 66140.88
Iteration:    960, Loss function: 5.871, Average Loss: 4.217, avg. samples / sec: 65968.33
Iteration:    960, Loss function: 4.644, Average Loss: 4.244, avg. samples / sec: 65884.08
Iteration:    960, Loss function: 6.515, Average Loss: 4.226, avg. samples / sec: 66015.00
Iteration:    960, Loss function: 5.131, Average Loss: 4.229, avg. samples / sec: 65906.26
Iteration:    960, Loss function: 5.048, Average Loss: 4.237, avg. samples / sec: 66132.84
Iteration:    960, Loss function: 6.022, Average Loss: 4.217, avg. samples / sec: 65929.57
Iteration:    960, Loss function: 5.142, Average Loss: 4.253, avg. samples / sec: 66063.05
Iteration:    960, Loss function: 4.428, Average Loss: 4.243, avg. samples / sec: 65959.07
Iteration:    960, Loss function: 4.385, Average Loss: 4.253, avg. samples / sec: 65822.53
Iteration:    960, Loss function: 5.178, Average Loss: 4.216, avg. samples / sec: 65847.51
Iteration:    960, Loss function: 5.716, Average Loss: 4.235, avg. samples / sec: 65902.72
Iteration:    960, Loss function: 4.809, Average Loss: 4.236, avg. samples / sec: 66195.34
Iteration:    960, Loss function: 6.255, Average Loss: 4.241, avg. samples / sec: 65931.89
Iteration:    960, Loss function: 5.488, Average Loss: 4.229, avg. samples / sec: 65955.83
Iteration:    960, Loss function: 4.659, Average Loss: 4.244, avg. samples / sec: 65897.11
Iteration:    960, Loss function: 7.026, Average Loss: 4.238, avg. samples / sec: 65960.00
Iteration:    960, Loss function: 4.643, Average Loss: 4.234, avg. samples / sec: 65883.80
Iteration:    960, Loss function: 6.325, Average Loss: 4.233, avg. samples / sec: 65879.37
Iteration:    960, Loss function: 5.147, Average Loss: 4.190, avg. samples / sec: 65780.97
Iteration:    960, Loss function: 3.837, Average Loss: 4.258, avg. samples / sec: 65858.86
Iteration:    960, Loss function: 4.623, Average Loss: 4.238, avg. samples / sec: 65966.70
Iteration:    960, Loss function: 3.918, Average Loss: 4.254, avg. samples / sec: 65907.80
Iteration:    960, Loss function: 3.413, Average Loss: 4.223, avg. samples / sec: 65873.36
Iteration:    960, Loss function: 5.444, Average Loss: 4.233, avg. samples / sec: 65946.66
Iteration:    960, Loss function: 4.518, Average Loss: 4.242, avg. samples / sec: 65875.98
Iteration:    960, Loss function: 4.363, Average Loss: 4.246, avg. samples / sec: 65685.80
Iteration:    960, Loss function: 5.604, Average Loss: 4.252, avg. samples / sec: 65719.43
:::MLL 1558651549.183 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558651549.184 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 5.436, Average Loss: 4.261, avg. samples / sec: 65563.99
Iteration:    980, Loss function: 4.499, Average Loss: 4.245, avg. samples / sec: 65533.74
Iteration:    980, Loss function: 4.948, Average Loss: 4.237, avg. samples / sec: 65451.93
Iteration:    980, Loss function: 4.742, Average Loss: 4.236, avg. samples / sec: 65529.48
Iteration:    980, Loss function: 5.292, Average Loss: 4.237, avg. samples / sec: 65494.94
Iteration:    980, Loss function: 3.737, Average Loss: 4.237, avg. samples / sec: 65410.10
Iteration:    980, Loss function: 5.701, Average Loss: 4.259, avg. samples / sec: 65681.85
Iteration:    980, Loss function: 4.637, Average Loss: 4.258, avg. samples / sec: 65514.25
Iteration:    980, Loss function: 4.927, Average Loss: 4.271, avg. samples / sec: 65495.10
Iteration:    980, Loss function: 4.640, Average Loss: 4.260, avg. samples / sec: 65487.70
Iteration:    980, Loss function: 7.690, Average Loss: 4.240, avg. samples / sec: 65606.02
Iteration:    980, Loss function: 5.618, Average Loss: 4.252, avg. samples / sec: 65487.94
Iteration:    980, Loss function: 4.681, Average Loss: 4.263, avg. samples / sec: 65675.57
Iteration:    980, Loss function: 3.441, Average Loss: 4.232, avg. samples / sec: 65462.76
Iteration:    980, Loss function: 4.774, Average Loss: 4.246, avg. samples / sec: 65570.58
Iteration:    980, Loss function: 4.430, Average Loss: 4.249, avg. samples / sec: 65455.82
Iteration:    980, Loss function: 3.882, Average Loss: 4.262, avg. samples / sec: 65600.37
Iteration:    980, Loss function: 5.058, Average Loss: 4.268, avg. samples / sec: 65525.61
Iteration:    980, Loss function: 5.347, Average Loss: 4.250, avg. samples / sec: 65304.08
Iteration:    980, Loss function: 5.036, Average Loss: 4.258, avg. samples / sec: 65484.90
Iteration:    980, Loss function: 4.703, Average Loss: 4.253, avg. samples / sec: 65404.94
Iteration:    980, Loss function: 5.493, Average Loss: 4.239, avg. samples / sec: 65334.53
Iteration:    980, Loss function: 5.003, Average Loss: 4.266, avg. samples / sec: 65352.86
Iteration:    980, Loss function: 5.993, Average Loss: 4.275, avg. samples / sec: 65460.78
Iteration:    980, Loss function: 4.728, Average Loss: 4.256, avg. samples / sec: 65317.76
Iteration:    980, Loss function: 4.466, Average Loss: 4.249, avg. samples / sec: 65392.98
Iteration:    980, Loss function: 6.521, Average Loss: 4.256, avg. samples / sec: 65397.44
Iteration:    980, Loss function: 4.577, Average Loss: 4.257, avg. samples / sec: 65362.47
Iteration:    980, Loss function: 5.107, Average Loss: 4.251, avg. samples / sec: 65398.72
Iteration:    980, Loss function: 5.931, Average Loss: 4.206, avg. samples / sec: 65368.48
Iteration:   1000, Loss function: 4.967, Average Loss: 4.272, avg. samples / sec: 66078.54
Iteration:   1000, Loss function: 5.326, Average Loss: 4.253, avg. samples / sec: 66006.62
Iteration:   1000, Loss function: 5.319, Average Loss: 4.290, avg. samples / sec: 66099.40
Iteration:   1000, Loss function: 5.298, Average Loss: 4.276, avg. samples / sec: 66104.33
Iteration:   1000, Loss function: 4.035, Average Loss: 4.254, avg. samples / sec: 65968.12
Iteration:   1000, Loss function: 5.566, Average Loss: 4.271, avg. samples / sec: 65973.55
Iteration:   1000, Loss function: 5.859, Average Loss: 4.286, avg. samples / sec: 65935.99
Iteration:   1000, Loss function: 5.087, Average Loss: 4.277, avg. samples / sec: 65822.44
Iteration:   1000, Loss function: 4.630, Average Loss: 4.248, avg. samples / sec: 65993.85
Iteration:   1000, Loss function: 5.273, Average Loss: 4.264, avg. samples / sec: 66003.65
Iteration:   1000, Loss function: 5.960, Average Loss: 4.281, avg. samples / sec: 65915.63
Iteration:   1000, Loss function: 4.531, Average Loss: 4.248, avg. samples / sec: 65844.31
Iteration:   1000, Loss function: 6.353, Average Loss: 4.221, avg. samples / sec: 66100.21
Iteration:   1000, Loss function: 5.113, Average Loss: 4.278, avg. samples / sec: 65965.62
Iteration:   1000, Loss function: 5.870, Average Loss: 4.283, avg. samples / sec: 66017.31
Iteration:   1000, Loss function: 3.843, Average Loss: 4.273, avg. samples / sec: 66054.88
Iteration:   1000, Loss function: 4.140, Average Loss: 4.258, avg. samples / sec: 66016.63
Iteration:   1000, Loss function: 6.092, Average Loss: 4.264, avg. samples / sec: 65803.42
Iteration:   1000, Loss function: 5.849, Average Loss: 4.273, avg. samples / sec: 65859.39
Iteration:   1000, Loss function: 4.481, Average Loss: 4.267, avg. samples / sec: 66008.29
Iteration:   1000, Loss function: 4.620, Average Loss: 4.251, avg. samples / sec: 65809.81
Iteration:   1000, Loss function: 4.364, Average Loss: 4.261, avg. samples / sec: 65928.15
Iteration:   1000, Loss function: 5.391, Average Loss: 4.267, avg. samples / sec: 66018.55
Iteration:   1000, Loss function: 3.266, Average Loss: 4.274, avg. samples / sec: 65930.13
Iteration:   1000, Loss function: 4.529, Average Loss: 4.274, avg. samples / sec: 65971.98
Iteration:   1000, Loss function: 5.244, Average Loss: 4.282, avg. samples / sec: 65935.59
Iteration:   1000, Loss function: 4.929, Average Loss: 4.283, avg. samples / sec: 65853.78
Iteration:   1000, Loss function: 5.751, Average Loss: 4.287, avg. samples / sec: 65862.77
Iteration:   1000, Loss function: 5.873, Average Loss: 4.273, avg. samples / sec: 65852.37
Iteration:   1000, Loss function: 6.108, Average Loss: 4.252, avg. samples / sec: 65718.23
Iteration:   1020, Loss function: 5.010, Average Loss: 4.232, avg. samples / sec: 66656.61
Iteration:   1020, Loss function: 5.657, Average Loss: 4.288, avg. samples / sec: 66431.73
Iteration:   1020, Loss function: 4.040, Average Loss: 4.267, avg. samples / sec: 66611.09
Iteration:   1020, Loss function: 4.302, Average Loss: 4.300, avg. samples / sec: 66587.33
Iteration:   1020, Loss function: 6.369, Average Loss: 4.296, avg. samples / sec: 66519.31
Iteration:   1020, Loss function: 3.737, Average Loss: 4.298, avg. samples / sec: 66526.88
Iteration:   1020, Loss function: 5.856, Average Loss: 4.294, avg. samples / sec: 66546.64
Iteration:   1020, Loss function: 4.715, Average Loss: 4.296, avg. samples / sec: 66568.23
Iteration:   1020, Loss function: 5.137, Average Loss: 4.309, avg. samples / sec: 66494.77
Iteration:   1020, Loss function: 4.154, Average Loss: 4.263, avg. samples / sec: 66700.85
Iteration:   1020, Loss function: 4.819, Average Loss: 4.270, avg. samples / sec: 66412.48
Iteration:   1020, Loss function: 4.640, Average Loss: 4.274, avg. samples / sec: 66561.73
Iteration:   1020, Loss function: 4.842, Average Loss: 4.269, avg. samples / sec: 66475.51
Iteration:   1020, Loss function: 4.814, Average Loss: 4.281, avg. samples / sec: 66594.53
Iteration:   1020, Loss function: 5.504, Average Loss: 4.289, avg. samples / sec: 66470.40
Iteration:   1020, Loss function: 5.178, Average Loss: 4.271, avg. samples / sec: 66571.79
Iteration:   1020, Loss function: 5.188, Average Loss: 4.287, avg. samples / sec: 66535.24
Iteration:   1020, Loss function: 6.591, Average Loss: 4.291, avg. samples / sec: 66536.65
Iteration:   1020, Loss function: 5.770, Average Loss: 4.262, avg. samples / sec: 66453.85
Iteration:   1020, Loss function: 4.400, Average Loss: 4.294, avg. samples / sec: 66585.22
Iteration:   1020, Loss function: 4.182, Average Loss: 4.286, avg. samples / sec: 66581.92
Iteration:   1020, Loss function: 4.439, Average Loss: 4.290, avg. samples / sec: 66581.10
Iteration:   1020, Loss function: 5.327, Average Loss: 4.275, avg. samples / sec: 66531.31
Iteration:   1020, Loss function: 4.143, Average Loss: 4.307, avg. samples / sec: 66595.29
Iteration:   1020, Loss function: 4.391, Average Loss: 4.298, avg. samples / sec: 66438.41
Iteration:   1020, Loss function: 4.808, Average Loss: 4.279, avg. samples / sec: 66482.41
Iteration:   1020, Loss function: 4.162, Average Loss: 4.280, avg. samples / sec: 66387.27
Iteration:   1020, Loss function: 5.759, Average Loss: 4.303, avg. samples / sec: 66530.52
Iteration:   1020, Loss function: 6.560, Average Loss: 4.283, avg. samples / sec: 66476.01
Iteration:   1020, Loss function: 5.884, Average Loss: 4.290, avg. samples / sec: 66551.89
Iteration:   1040, Loss function: 5.302, Average Loss: 4.305, avg. samples / sec: 66701.92
Iteration:   1040, Loss function: 5.296, Average Loss: 4.248, avg. samples / sec: 66443.45
Iteration:   1040, Loss function: 5.357, Average Loss: 4.306, avg. samples / sec: 66519.72
Iteration:   1040, Loss function: 4.962, Average Loss: 4.293, avg. samples / sec: 66658.00
Iteration:   1040, Loss function: 4.826, Average Loss: 4.274, avg. samples / sec: 66539.13
Iteration:   1040, Loss function: 4.010, Average Loss: 4.276, avg. samples / sec: 66470.24
Iteration:   1040, Loss function: 4.163, Average Loss: 4.307, avg. samples / sec: 66504.84
Iteration:   1040, Loss function: 4.544, Average Loss: 4.288, avg. samples / sec: 66533.35
Iteration:   1040, Loss function: 5.113, Average Loss: 4.304, avg. samples / sec: 66423.06
Iteration:   1040, Loss function: 5.403, Average Loss: 4.310, avg. samples / sec: 66596.36
Iteration:   1040, Loss function: 5.072, Average Loss: 4.293, avg. samples / sec: 66481.50
Iteration:   1040, Loss function: 6.611, Average Loss: 4.310, avg. samples / sec: 66522.48
Iteration:   1040, Loss function: 4.908, Average Loss: 4.311, avg. samples / sec: 66511.46
Iteration:   1040, Loss function: 4.700, Average Loss: 4.303, avg. samples / sec: 66482.06
Iteration:   1040, Loss function: 5.692, Average Loss: 4.299, avg. samples / sec: 66487.27
Iteration:   1040, Loss function: 4.787, Average Loss: 4.321, avg. samples / sec: 66410.20
Iteration:   1040, Loss function: 4.191, Average Loss: 4.278, avg. samples / sec: 66455.89
Iteration:   1040, Loss function: 4.803, Average Loss: 4.308, avg. samples / sec: 66376.01
Iteration:   1040, Loss function: 4.438, Average Loss: 4.324, avg. samples / sec: 66464.07
Iteration:   1040, Loss function: 5.290, Average Loss: 4.289, avg. samples / sec: 66410.57
Iteration:   1040, Loss function: 5.918, Average Loss: 4.309, avg. samples / sec: 66550.41
Iteration:   1040, Loss function: 4.967, Average Loss: 4.295, avg. samples / sec: 66479.68
Iteration:   1040, Loss function: 5.212, Average Loss: 4.303, avg. samples / sec: 66416.99
Iteration:   1040, Loss function: 4.117, Average Loss: 4.294, avg. samples / sec: 66379.70
Iteration:   1040, Loss function: 5.044, Average Loss: 4.286, avg. samples / sec: 66372.76
Iteration:   1040, Loss function: 4.999, Average Loss: 4.310, avg. samples / sec: 66314.89
Iteration:   1040, Loss function: 5.099, Average Loss: 4.301, avg. samples / sec: 66361.07
Iteration:   1040, Loss function: 4.983, Average Loss: 4.312, avg. samples / sec: 66296.20
Iteration:   1040, Loss function: 5.283, Average Loss: 4.287, avg. samples / sec: 66368.82
Iteration:   1040, Loss function: 4.981, Average Loss: 4.303, avg. samples / sec: 66405.25
:::MLL 1558651550.959 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558651550.959 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 4.964, Average Loss: 4.292, avg. samples / sec: 65929.45
Iteration:   1060, Loss function: 5.592, Average Loss: 4.321, avg. samples / sec: 65903.92
Iteration:   1060, Loss function: 4.663, Average Loss: 4.313, avg. samples / sec: 65978.96
Iteration:   1060, Loss function: 5.232, Average Loss: 4.320, avg. samples / sec: 65857.94
Iteration:   1060, Loss function: 5.823, Average Loss: 4.305, avg. samples / sec: 66053.05
Iteration:   1060, Loss function: 5.732, Average Loss: 4.328, avg. samples / sec: 66059.09
Iteration:   1060, Loss function: 3.404, Average Loss: 4.285, avg. samples / sec: 65861.54
Iteration:   1060, Loss function: 4.963, Average Loss: 4.303, avg. samples / sec: 66008.19
Iteration:   1060, Loss function: 4.431, Average Loss: 4.320, avg. samples / sec: 65910.79
Iteration:   1060, Loss function: 5.496, Average Loss: 4.307, avg. samples / sec: 65894.74
Iteration:   1060, Loss function: 4.606, Average Loss: 4.300, avg. samples / sec: 66099.87
Iteration:   1060, Loss function: 4.785, Average Loss: 4.300, avg. samples / sec: 65861.42
Iteration:   1060, Loss function: 4.596, Average Loss: 4.288, avg. samples / sec: 65985.14
Iteration:   1060, Loss function: 4.405, Average Loss: 4.260, avg. samples / sec: 65822.57
Iteration:   1060, Loss function: 5.816, Average Loss: 4.306, avg. samples / sec: 65922.91
Iteration:   1060, Loss function: 5.230, Average Loss: 4.305, avg. samples / sec: 65976.58
Iteration:   1060, Loss function: 4.548, Average Loss: 4.325, avg. samples / sec: 65907.53
Iteration:   1060, Loss function: 3.729, Average Loss: 4.339, avg. samples / sec: 65917.73
Iteration:   1060, Loss function: 5.371, Average Loss: 4.313, avg. samples / sec: 66008.25
Iteration:   1060, Loss function: 5.501, Average Loss: 4.325, avg. samples / sec: 65849.91
Iteration:   1060, Loss function: 5.789, Average Loss: 4.301, avg. samples / sec: 65931.30
Iteration:   1060, Loss function: 4.625, Average Loss: 4.340, avg. samples / sec: 65920.57
Iteration:   1060, Loss function: 3.831, Average Loss: 4.320, avg. samples / sec: 65899.11
Iteration:   1060, Loss function: 4.454, Average Loss: 4.318, avg. samples / sec: 65684.60
Iteration:   1060, Loss function: 4.843, Average Loss: 4.327, avg. samples / sec: 65893.38
Iteration:   1060, Loss function: 3.806, Average Loss: 4.321, avg. samples / sec: 65837.82
Iteration:   1060, Loss function: 4.619, Average Loss: 4.316, avg. samples / sec: 65965.89
Iteration:   1060, Loss function: 5.573, Average Loss: 4.318, avg. samples / sec: 65971.89
Iteration:   1060, Loss function: 6.306, Average Loss: 4.306, avg. samples / sec: 65712.38
Iteration:   1060, Loss function: 5.067, Average Loss: 4.321, avg. samples / sec: 65846.25
Iteration:   1080, Loss function: 5.585, Average Loss: 4.336, avg. samples / sec: 66484.45
Iteration:   1080, Loss function: 5.161, Average Loss: 4.335, avg. samples / sec: 66424.88
Iteration:   1080, Loss function: 4.775, Average Loss: 4.333, avg. samples / sec: 66401.75
Iteration:   1080, Loss function: 4.542, Average Loss: 4.303, avg. samples / sec: 66355.98
Iteration:   1080, Loss function: 4.781, Average Loss: 4.272, avg. samples / sec: 66447.58
Iteration:   1080, Loss function: 5.028, Average Loss: 4.324, avg. samples / sec: 66485.67
Iteration:   1080, Loss function: 6.783, Average Loss: 4.303, avg. samples / sec: 66412.98
Iteration:   1080, Loss function: 4.214, Average Loss: 4.326, avg. samples / sec: 66415.96
Iteration:   1080, Loss function: 4.737, Average Loss: 4.320, avg. samples / sec: 66372.26
Iteration:   1080, Loss function: 5.061, Average Loss: 4.339, avg. samples / sec: 66390.89
Iteration:   1080, Loss function: 5.849, Average Loss: 4.332, avg. samples / sec: 66519.53
Iteration:   1080, Loss function: 6.022, Average Loss: 4.329, avg. samples / sec: 66498.91
Iteration:   1080, Loss function: 4.137, Average Loss: 4.319, avg. samples / sec: 66423.50
Iteration:   1080, Loss function: 4.873, Average Loss: 4.330, avg. samples / sec: 66368.88
Iteration:   1080, Loss function: 5.595, Average Loss: 4.355, avg. samples / sec: 66410.60
Iteration:   1080, Loss function: 5.239, Average Loss: 4.331, avg. samples / sec: 66399.56
Iteration:   1080, Loss function: 5.027, Average Loss: 4.336, avg. samples / sec: 66460.34
Iteration:   1080, Loss function: 3.978, Average Loss: 4.321, avg. samples / sec: 66490.35
Iteration:   1080, Loss function: 5.337, Average Loss: 4.307, avg. samples / sec: 66322.72
Iteration:   1080, Loss function: 4.887, Average Loss: 4.338, avg. samples / sec: 66431.30
Iteration:   1080, Loss function: 4.445, Average Loss: 4.354, avg. samples / sec: 66411.51
Iteration:   1080, Loss function: 4.745, Average Loss: 4.315, avg. samples / sec: 66335.24
Iteration:   1080, Loss function: 5.422, Average Loss: 4.319, avg. samples / sec: 66392.86
Iteration:   1080, Loss function: 3.865, Average Loss: 4.331, avg. samples / sec: 66390.74
Iteration:   1080, Loss function: 4.655, Average Loss: 4.302, avg. samples / sec: 66309.77
Iteration:   1080, Loss function: 4.981, Average Loss: 4.334, avg. samples / sec: 66423.63
Iteration:   1080, Loss function: 3.954, Average Loss: 4.316, avg. samples / sec: 66315.67
Iteration:   1080, Loss function: 4.260, Average Loss: 4.339, avg. samples / sec: 66448.34
Iteration:   1080, Loss function: 4.818, Average Loss: 4.337, avg. samples / sec: 66346.14
Iteration:   1080, Loss function: 4.415, Average Loss: 4.312, avg. samples / sec: 66268.58
Iteration:   1100, Loss function: 5.656, Average Loss: 4.357, avg. samples / sec: 66312.11
Iteration:   1100, Loss function: 5.420, Average Loss: 4.315, avg. samples / sec: 66358.91
Iteration:   1100, Loss function: 6.559, Average Loss: 4.343, avg. samples / sec: 66353.85
Iteration:   1100, Loss function: 5.158, Average Loss: 4.351, avg. samples / sec: 66230.37
Iteration:   1100, Loss function: 6.035, Average Loss: 4.343, avg. samples / sec: 66333.71
Iteration:   1100, Loss function: 4.244, Average Loss: 4.334, avg. samples / sec: 66380.86
Iteration:   1100, Loss function: 4.745, Average Loss: 4.332, avg. samples / sec: 66306.27
Iteration:   1100, Loss function: 4.533, Average Loss: 4.319, avg. samples / sec: 66342.29
Iteration:   1100, Loss function: 4.613, Average Loss: 4.356, avg. samples / sec: 66403.31
Iteration:   1100, Loss function: 5.049, Average Loss: 4.333, avg. samples / sec: 66270.85
Iteration:   1100, Loss function: 4.682, Average Loss: 4.366, avg. samples / sec: 66363.76
Iteration:   1100, Loss function: 5.545, Average Loss: 4.340, avg. samples / sec: 66272.04
Iteration:   1100, Loss function: 5.082, Average Loss: 4.317, avg. samples / sec: 66340.17
Iteration:   1100, Loss function: 4.551, Average Loss: 4.323, avg. samples / sec: 66398.06
Iteration:   1100, Loss function: 4.149, Average Loss: 4.345, avg. samples / sec: 66242.85
Iteration:   1100, Loss function: 5.455, Average Loss: 4.344, avg. samples / sec: 66243.85
Iteration:   1100, Loss function: 4.525, Average Loss: 4.361, avg. samples / sec: 66259.67
Iteration:   1100, Loss function: 4.575, Average Loss: 4.350, avg. samples / sec: 66262.60
Iteration:   1100, Loss function: 5.095, Average Loss: 4.338, avg. samples / sec: 66179.95
Iteration:   1100, Loss function: 4.654, Average Loss: 4.347, avg. samples / sec: 66217.54
Iteration:   1100, Loss function: 4.889, Average Loss: 4.346, avg. samples / sec: 66306.27
Iteration:   1100, Loss function: 5.004, Average Loss: 4.354, avg. samples / sec: 66313.20
Iteration:   1100, Loss function: 4.706, Average Loss: 4.282, avg. samples / sec: 66141.78
Iteration:   1100, Loss function: 6.078, Average Loss: 4.345, avg. samples / sec: 66118.16
Iteration:   1100, Loss function: 4.596, Average Loss: 4.331, avg. samples / sec: 66201.09
Iteration:   1100, Loss function: 5.463, Average Loss: 4.325, avg. samples / sec: 66246.77
Iteration:   1100, Loss function: 4.749, Average Loss: 4.335, avg. samples / sec: 66198.91
Iteration:   1100, Loss function: 5.162, Average Loss: 4.346, avg. samples / sec: 66238.15
Iteration:   1100, Loss function: 4.196, Average Loss: 4.317, avg. samples / sec: 66062.37
Iteration:   1100, Loss function: 4.491, Average Loss: 4.348, avg. samples / sec: 66126.60
:::MLL 1558651552.733 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558651552.734 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 6.071, Average Loss: 4.325, avg. samples / sec: 66446.96
Iteration:   1120, Loss function: 4.163, Average Loss: 4.341, avg. samples / sec: 66404.56
Iteration:   1120, Loss function: 5.800, Average Loss: 4.353, avg. samples / sec: 66363.01
Iteration:   1120, Loss function: 4.276, Average Loss: 4.363, avg. samples / sec: 66300.60
Iteration:   1120, Loss function: 5.407, Average Loss: 4.372, avg. samples / sec: 66382.61
Iteration:   1120, Loss function: 5.803, Average Loss: 4.328, avg. samples / sec: 66566.25
Iteration:   1120, Loss function: 4.422, Average Loss: 4.351, avg. samples / sec: 66365.48
Iteration:   1120, Loss function: 3.965, Average Loss: 4.329, avg. samples / sec: 66377.10
Iteration:   1120, Loss function: 4.111, Average Loss: 4.366, avg. samples / sec: 66297.73
Iteration:   1120, Loss function: 5.182, Average Loss: 4.355, avg. samples / sec: 66389.33
Iteration:   1120, Loss function: 4.735, Average Loss: 4.367, avg. samples / sec: 66381.95
Iteration:   1120, Loss function: 4.250, Average Loss: 4.292, avg. samples / sec: 66423.72
Iteration:   1120, Loss function: 5.794, Average Loss: 4.357, avg. samples / sec: 66418.96
Iteration:   1120, Loss function: 4.014, Average Loss: 4.336, avg. samples / sec: 66312.23
Iteration:   1120, Loss function: 4.720, Average Loss: 4.344, avg. samples / sec: 66415.58
Iteration:   1120, Loss function: 4.601, Average Loss: 4.368, avg. samples / sec: 66359.98
Iteration:   1120, Loss function: 3.800, Average Loss: 4.327, avg. samples / sec: 66265.62
Iteration:   1120, Loss function: 5.430, Average Loss: 4.352, avg. samples / sec: 66189.71
Iteration:   1120, Loss function: 3.952, Average Loss: 4.349, avg. samples / sec: 66319.22
Iteration:   1120, Loss function: 3.567, Average Loss: 4.347, avg. samples / sec: 66209.74
Iteration:   1120, Loss function: 5.386, Average Loss: 4.356, avg. samples / sec: 66289.21
Iteration:   1120, Loss function: 4.524, Average Loss: 4.342, avg. samples / sec: 66350.38
Iteration:   1120, Loss function: 4.192, Average Loss: 4.377, avg. samples / sec: 66212.16
Iteration:   1120, Loss function: 3.914, Average Loss: 4.356, avg. samples / sec: 66231.89
Iteration:   1120, Loss function: 6.270, Average Loss: 4.360, avg. samples / sec: 66348.42
Iteration:   1120, Loss function: 3.355, Average Loss: 4.353, avg. samples / sec: 66276.03
Iteration:   1120, Loss function: 4.410, Average Loss: 4.354, avg. samples / sec: 66395.21
Iteration:   1120, Loss function: 5.303, Average Loss: 4.348, avg. samples / sec: 66169.35
Iteration:   1120, Loss function: 3.778, Average Loss: 4.342, avg. samples / sec: 66309.36
Iteration:   1120, Loss function: 5.132, Average Loss: 4.362, avg. samples / sec: 66116.49
Iteration:   1140, Loss function: 4.995, Average Loss: 4.364, avg. samples / sec: 66321.10
Iteration:   1140, Loss function: 5.054, Average Loss: 4.358, avg. samples / sec: 66539.44
Iteration:   1140, Loss function: 5.256, Average Loss: 4.361, avg. samples / sec: 66331.52
Iteration:   1140, Loss function: 4.554, Average Loss: 4.338, avg. samples / sec: 66308.74
Iteration:   1140, Loss function: 5.539, Average Loss: 4.378, avg. samples / sec: 66342.67
Iteration:   1140, Loss function: 5.205, Average Loss: 4.368, avg. samples / sec: 66333.08
Iteration:   1140, Loss function: 4.270, Average Loss: 4.377, avg. samples / sec: 66317.97
Iteration:   1140, Loss function: 6.291, Average Loss: 4.357, avg. samples / sec: 66383.23
Iteration:   1140, Loss function: 3.884, Average Loss: 4.345, avg. samples / sec: 66216.42
Iteration:   1140, Loss function: 4.257, Average Loss: 4.340, avg. samples / sec: 66268.67
Iteration:   1140, Loss function: 5.620, Average Loss: 4.353, avg. samples / sec: 66343.01
Iteration:   1140, Loss function: 5.496, Average Loss: 4.299, avg. samples / sec: 66304.34
Iteration:   1140, Loss function: 5.194, Average Loss: 4.352, avg. samples / sec: 66399.25
Iteration:   1140, Loss function: 6.199, Average Loss: 4.346, avg. samples / sec: 66321.84
Iteration:   1140, Loss function: 4.951, Average Loss: 4.334, avg. samples / sec: 66063.58
Iteration:   1140, Loss function: 5.763, Average Loss: 4.366, avg. samples / sec: 66396.81
Iteration:   1140, Loss function: 4.644, Average Loss: 4.371, avg. samples / sec: 66527.07
Iteration:   1140, Loss function: 4.748, Average Loss: 4.334, avg. samples / sec: 66316.63
Iteration:   1140, Loss function: 5.449, Average Loss: 4.361, avg. samples / sec: 66284.57
Iteration:   1140, Loss function: 4.064, Average Loss: 4.370, avg. samples / sec: 66177.74
Iteration:   1140, Loss function: 5.364, Average Loss: 4.361, avg. samples / sec: 66405.53
Iteration:   1140, Loss function: 4.671, Average Loss: 4.365, avg. samples / sec: 66350.42
Iteration:   1140, Loss function: 3.913, Average Loss: 4.371, avg. samples / sec: 66295.01
Iteration:   1140, Loss function: 5.705, Average Loss: 4.388, avg. samples / sec: 66346.64
Iteration:   1140, Loss function: 6.011, Average Loss: 4.351, avg. samples / sec: 66328.21
Iteration:   1140, Loss function: 5.804, Average Loss: 4.386, avg. samples / sec: 66146.28
Iteration:   1140, Loss function: 5.953, Average Loss: 4.357, avg. samples / sec: 66301.53
Iteration:   1140, Loss function: 4.005, Average Loss: 4.367, avg. samples / sec: 66329.40
Iteration:   1140, Loss function: 4.142, Average Loss: 4.362, avg. samples / sec: 66318.69
Iteration:   1140, Loss function: 6.361, Average Loss: 4.353, avg. samples / sec: 66295.11
Iteration:   1160, Loss function: 4.259, Average Loss: 4.345, avg. samples / sec: 66497.25
Iteration:   1160, Loss function: 5.338, Average Loss: 4.377, avg. samples / sec: 66612.82
Iteration:   1160, Loss function: 4.660, Average Loss: 4.389, avg. samples / sec: 66529.96
Iteration:   1160, Loss function: 4.701, Average Loss: 4.384, avg. samples / sec: 66518.94
Iteration:   1160, Loss function: 5.363, Average Loss: 4.380, avg. samples / sec: 66533.26
Iteration:   1160, Loss function: 4.418, Average Loss: 4.347, avg. samples / sec: 66515.17
Iteration:   1160, Loss function: 5.966, Average Loss: 4.373, avg. samples / sec: 66534.04
Iteration:   1160, Loss function: 5.759, Average Loss: 4.351, avg. samples / sec: 66514.95
Iteration:   1160, Loss function: 4.310, Average Loss: 4.313, avg. samples / sec: 66503.49
Iteration:   1160, Loss function: 5.192, Average Loss: 4.369, avg. samples / sec: 66479.90
Iteration:   1160, Loss function: 5.061, Average Loss: 4.369, avg. samples / sec: 66460.56
Iteration:   1160, Loss function: 4.942, Average Loss: 4.376, avg. samples / sec: 66509.33
Iteration:   1160, Loss function: 3.990, Average Loss: 4.360, avg. samples / sec: 66451.50
Iteration:   1160, Loss function: 5.876, Average Loss: 4.373, avg. samples / sec: 66366.16
Iteration:   1160, Loss function: 5.916, Average Loss: 4.377, avg. samples / sec: 66342.01
Iteration:   1160, Loss function: 5.491, Average Loss: 4.397, avg. samples / sec: 66526.63
Iteration:   1160, Loss function: 3.716, Average Loss: 4.383, avg. samples / sec: 66515.07
Iteration:   1160, Loss function: 4.826, Average Loss: 4.348, avg. samples / sec: 66444.39
Iteration:   1160, Loss function: 5.498, Average Loss: 4.377, avg. samples / sec: 66537.28
Iteration:   1160, Loss function: 5.483, Average Loss: 4.371, avg. samples / sec: 66316.60
Iteration:   1160, Loss function: 4.067, Average Loss: 4.366, avg. samples / sec: 66484.51
Iteration:   1160, Loss function: 5.390, Average Loss: 4.381, avg. samples / sec: 66471.47
Iteration:   1160, Loss function: 6.488, Average Loss: 4.385, avg. samples / sec: 66453.16
Iteration:   1160, Loss function: 4.205, Average Loss: 4.391, avg. samples / sec: 66363.13
Iteration:   1160, Loss function: 4.752, Average Loss: 4.364, avg. samples / sec: 66531.84
Iteration:   1160, Loss function: 6.132, Average Loss: 4.398, avg. samples / sec: 66452.75
Iteration:   1160, Loss function: 5.142, Average Loss: 4.361, avg. samples / sec: 66387.77
Iteration:   1160, Loss function: 5.825, Average Loss: 4.369, avg. samples / sec: 66441.01
Iteration:   1160, Loss function: 5.662, Average Loss: 4.383, avg. samples / sec: 66374.92
Iteration:   1160, Loss function: 5.357, Average Loss: 4.363, avg. samples / sec: 66221.37
Iteration:   1180, Loss function: 5.292, Average Loss: 4.357, avg. samples / sec: 66375.23
Iteration:   1180, Loss function: 4.850, Average Loss: 4.398, avg. samples / sec: 66347.79
Iteration:   1180, Loss function: 5.260, Average Loss: 4.384, avg. samples / sec: 66420.15
Iteration:   1180, Loss function: 3.901, Average Loss: 4.397, avg. samples / sec: 66466.26
Iteration:   1180, Loss function: 3.940, Average Loss: 4.389, avg. samples / sec: 66477.27
Iteration:   1180, Loss function: 3.097, Average Loss: 4.356, avg. samples / sec: 66380.11
Iteration:   1180, Loss function: 4.517, Average Loss: 4.398, avg. samples / sec: 66313.67
Iteration:   1180, Loss function: 5.387, Average Loss: 4.381, avg. samples / sec: 66425.75
Iteration:   1180, Loss function: 4.281, Average Loss: 4.392, avg. samples / sec: 66277.18
Iteration:   1180, Loss function: 3.979, Average Loss: 4.360, avg. samples / sec: 66447.05
Iteration:   1180, Loss function: 5.374, Average Loss: 4.374, avg. samples / sec: 66459.74
Iteration:   1180, Loss function: 6.043, Average Loss: 4.383, avg. samples / sec: 66324.15
Iteration:   1180, Loss function: 3.611, Average Loss: 4.382, avg. samples / sec: 66310.33
Iteration:   1180, Loss function: 4.683, Average Loss: 4.374, avg. samples / sec: 66548.31
Iteration:   1180, Loss function: 4.675, Average Loss: 4.328, avg. samples / sec: 66282.20
Iteration:   1180, Loss function: 5.803, Average Loss: 4.383, avg. samples / sec: 66358.94
Iteration:   1180, Loss function: 3.732, Average Loss: 4.366, avg. samples / sec: 66397.59
Iteration:   1180, Loss function: 4.307, Average Loss: 4.382, avg. samples / sec: 66409.20
Iteration:   1180, Loss function: 4.344, Average Loss: 4.406, avg. samples / sec: 66311.33
Iteration:   1180, Loss function: 5.027, Average Loss: 4.412, avg. samples / sec: 66378.64
Iteration:   1180, Loss function: 6.569, Average Loss: 4.379, avg. samples / sec: 66357.54
Iteration:   1180, Loss function: 4.838, Average Loss: 4.365, avg. samples / sec: 66234.69
Iteration:   1180, Loss function: 5.302, Average Loss: 4.386, avg. samples / sec: 66306.37
Iteration:   1180, Loss function: 4.479, Average Loss: 4.393, avg. samples / sec: 66321.66
Iteration:   1180, Loss function: 5.126, Average Loss: 4.389, avg. samples / sec: 66218.42
Iteration:   1180, Loss function: 4.571, Average Loss: 4.392, avg. samples / sec: 66432.24
Iteration:   1180, Loss function: 4.974, Average Loss: 4.374, avg. samples / sec: 66266.58
Iteration:   1180, Loss function: 5.158, Average Loss: 4.393, avg. samples / sec: 66257.67
Iteration:   1180, Loss function: 4.473, Average Loss: 4.384, avg. samples / sec: 66126.82
Iteration:   1180, Loss function: 4.851, Average Loss: 4.395, avg. samples / sec: 66210.14
:::MLL 1558651554.508 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558651554.508 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 4.595, Average Loss: 4.406, avg. samples / sec: 65770.77
Iteration:   1200, Loss function: 5.723, Average Loss: 4.391, avg. samples / sec: 65742.88
Iteration:   1200, Loss function: 4.200, Average Loss: 4.403, avg. samples / sec: 65751.93
Iteration:   1200, Loss function: 5.308, Average Loss: 4.362, avg. samples / sec: 65706.71
Iteration:   1200, Loss function: 3.978, Average Loss: 4.401, avg. samples / sec: 65718.66
Iteration:   1200, Loss function: 5.861, Average Loss: 4.373, avg. samples / sec: 65804.59
Iteration:   1200, Loss function: 4.208, Average Loss: 4.401, avg. samples / sec: 65688.83
Iteration:   1200, Loss function: 4.456, Average Loss: 4.334, avg. samples / sec: 65788.30
Iteration:   1200, Loss function: 4.453, Average Loss: 4.390, avg. samples / sec: 65734.63
Iteration:   1200, Loss function: 4.259, Average Loss: 4.392, avg. samples / sec: 65759.63
Iteration:   1200, Loss function: 4.778, Average Loss: 4.388, avg. samples / sec: 65718.76
Iteration:   1200, Loss function: 4.495, Average Loss: 4.363, avg. samples / sec: 65666.82
Iteration:   1200, Loss function: 5.653, Average Loss: 4.400, avg. samples / sec: 65774.83
Iteration:   1200, Loss function: 3.698, Average Loss: 4.370, avg. samples / sec: 65744.51
Iteration:   1200, Loss function: 4.299, Average Loss: 4.366, avg. samples / sec: 65578.72
Iteration:   1200, Loss function: 4.776, Average Loss: 4.380, avg. samples / sec: 65782.53
Iteration:   1200, Loss function: 3.624, Average Loss: 4.412, avg. samples / sec: 65752.70
Iteration:   1200, Loss function: 4.640, Average Loss: 4.381, avg. samples / sec: 65702.06
Iteration:   1200, Loss function: 4.606, Average Loss: 4.401, avg. samples / sec: 65751.90
Iteration:   1200, Loss function: 4.162, Average Loss: 4.379, avg. samples / sec: 65646.36
Iteration:   1200, Loss function: 4.114, Average Loss: 4.398, avg. samples / sec: 65862.71
Iteration:   1200, Loss function: 4.985, Average Loss: 4.399, avg. samples / sec: 65822.78
Iteration:   1200, Loss function: 4.358, Average Loss: 4.396, avg. samples / sec: 65618.60
Iteration:   1200, Loss function: 4.985, Average Loss: 4.392, avg. samples / sec: 65823.30
Iteration:   1200, Loss function: 4.942, Average Loss: 4.391, avg. samples / sec: 65600.15
Iteration:   1200, Loss function: 5.662, Average Loss: 4.402, avg. samples / sec: 65714.71
Iteration:   1200, Loss function: 4.161, Average Loss: 4.392, avg. samples / sec: 65717.25
Iteration:   1200, Loss function: 6.011, Average Loss: 4.389, avg. samples / sec: 65678.27
Iteration:   1200, Loss function: 5.291, Average Loss: 4.419, avg. samples / sec: 65638.93
Iteration:   1200, Loss function: 4.638, Average Loss: 4.392, avg. samples / sec: 65614.72
Iteration:   1220, Loss function: 4.265, Average Loss: 4.409, avg. samples / sec: 66525.00
Iteration:   1220, Loss function: 6.205, Average Loss: 4.404, avg. samples / sec: 66456.04
Iteration:   1220, Loss function: 5.129, Average Loss: 4.412, avg. samples / sec: 66401.37
Iteration:   1220, Loss function: 5.470, Average Loss: 4.402, avg. samples / sec: 66547.36
Iteration:   1220, Loss function: 4.518, Average Loss: 4.374, avg. samples / sec: 66420.09
Iteration:   1220, Loss function: 5.238, Average Loss: 4.399, avg. samples / sec: 66566.19
Iteration:   1220, Loss function: 5.097, Average Loss: 4.386, avg. samples / sec: 66510.33
Iteration:   1220, Loss function: 3.899, Average Loss: 4.401, avg. samples / sec: 66452.85
Iteration:   1220, Loss function: 4.372, Average Loss: 4.378, avg. samples / sec: 66433.21
Iteration:   1220, Loss function: 5.214, Average Loss: 4.399, avg. samples / sec: 66449.12
Iteration:   1220, Loss function: 4.143, Average Loss: 4.394, avg. samples / sec: 66498.94
Iteration:   1220, Loss function: 5.273, Average Loss: 4.426, avg. samples / sec: 66443.76
Iteration:   1220, Loss function: 3.620, Average Loss: 4.342, avg. samples / sec: 66375.63
Iteration:   1220, Loss function: 5.811, Average Loss: 4.374, avg. samples / sec: 66428.98
Iteration:   1220, Loss function: 3.556, Average Loss: 4.432, avg. samples / sec: 66533.95
Iteration:   1220, Loss function: 4.400, Average Loss: 4.414, avg. samples / sec: 66440.69
Iteration:   1220, Loss function: 4.378, Average Loss: 4.406, avg. samples / sec: 66410.13
Iteration:   1220, Loss function: 4.086, Average Loss: 4.409, avg. samples / sec: 66357.54
Iteration:   1220, Loss function: 4.414, Average Loss: 4.379, avg. samples / sec: 66411.48
Iteration:   1220, Loss function: 4.843, Average Loss: 4.415, avg. samples / sec: 66222.49
Iteration:   1220, Loss function: 4.563, Average Loss: 4.405, avg. samples / sec: 66405.50
Iteration:   1220, Loss function: 5.136, Average Loss: 4.406, avg. samples / sec: 66522.89
Iteration:   1220, Loss function: 4.718, Average Loss: 4.374, avg. samples / sec: 66388.77
Iteration:   1220, Loss function: 4.555, Average Loss: 4.399, avg. samples / sec: 66350.17
Iteration:   1220, Loss function: 4.879, Average Loss: 4.416, avg. samples / sec: 66443.14
Iteration:   1220, Loss function: 5.384, Average Loss: 4.396, avg. samples / sec: 66382.67
Iteration:   1220, Loss function: 5.859, Average Loss: 4.412, avg. samples / sec: 66327.78
Iteration:   1220, Loss function: 5.785, Average Loss: 4.407, avg. samples / sec: 66375.85
Iteration:   1220, Loss function: 4.817, Average Loss: 4.401, avg. samples / sec: 66342.33
Iteration:   1220, Loss function: 5.210, Average Loss: 4.394, avg. samples / sec: 66279.99
Iteration:   1240, Loss function: 4.340, Average Loss: 4.383, avg. samples / sec: 66898.29
Iteration:   1240, Loss function: 3.853, Average Loss: 4.389, avg. samples / sec: 66751.49
Iteration:   1240, Loss function: 4.528, Average Loss: 4.423, avg. samples / sec: 66835.98
Iteration:   1240, Loss function: 5.079, Average Loss: 4.422, avg. samples / sec: 66620.47
Iteration:   1240, Loss function: 4.821, Average Loss: 4.405, avg. samples / sec: 66938.49
Iteration:   1240, Loss function: 5.217, Average Loss: 4.425, avg. samples / sec: 66646.69
Iteration:   1240, Loss function: 5.150, Average Loss: 4.406, avg. samples / sec: 66709.40
Iteration:   1240, Loss function: 4.786, Average Loss: 4.403, avg. samples / sec: 66710.95
Iteration:   1240, Loss function: 4.972, Average Loss: 4.412, avg. samples / sec: 66589.81
Iteration:   1240, Loss function: 4.285, Average Loss: 4.384, avg. samples / sec: 66670.14
Iteration:   1240, Loss function: 4.350, Average Loss: 4.412, avg. samples / sec: 66633.07
Iteration:   1240, Loss function: 4.907, Average Loss: 4.416, avg. samples / sec: 66757.24
Iteration:   1240, Loss function: 2.885, Average Loss: 4.408, avg. samples / sec: 66629.61
Iteration:   1240, Loss function: 5.305, Average Loss: 4.421, avg. samples / sec: 66799.17
Iteration:   1240, Loss function: 4.970, Average Loss: 4.343, avg. samples / sec: 66686.48
Iteration:   1240, Loss function: 5.005, Average Loss: 4.382, avg. samples / sec: 66615.31
Iteration:   1240, Loss function: 5.054, Average Loss: 4.414, avg. samples / sec: 66764.30
Iteration:   1240, Loss function: 4.901, Average Loss: 4.412, avg. samples / sec: 66624.60
Iteration:   1240, Loss function: 5.744, Average Loss: 4.417, avg. samples / sec: 66689.01
Iteration:   1240, Loss function: 4.862, Average Loss: 4.419, avg. samples / sec: 66689.61
Iteration:   1240, Loss function: 4.819, Average Loss: 4.387, avg. samples / sec: 66657.18
Iteration:   1240, Loss function: 5.310, Average Loss: 4.442, avg. samples / sec: 66659.14
Iteration:   1240, Loss function: 5.116, Average Loss: 4.409, avg. samples / sec: 66784.93
Iteration:   1240, Loss function: 6.099, Average Loss: 4.405, avg. samples / sec: 66706.62
Iteration:   1240, Loss function: 4.264, Average Loss: 4.421, avg. samples / sec: 66686.45
Iteration:   1240, Loss function: 5.682, Average Loss: 4.408, avg. samples / sec: 66679.86
Iteration:   1240, Loss function: 4.903, Average Loss: 4.440, avg. samples / sec: 66634.68
Iteration:   1240, Loss function: 4.661, Average Loss: 4.419, avg. samples / sec: 66626.14
Iteration:   1240, Loss function: 6.522, Average Loss: 4.419, avg. samples / sec: 66629.10
Iteration:   1240, Loss function: 5.756, Average Loss: 4.393, avg. samples / sec: 66581.79
:::MLL 1558651556.279 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558651556.280 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 3.666, Average Loss: 4.412, avg. samples / sec: 66612.66
Iteration:   1260, Loss function: 5.602, Average Loss: 4.432, avg. samples / sec: 66439.78
Iteration:   1260, Loss function: 4.901, Average Loss: 4.421, avg. samples / sec: 66469.77
Iteration:   1260, Loss function: 4.009, Average Loss: 4.435, avg. samples / sec: 66457.71
Iteration:   1260, Loss function: 4.198, Average Loss: 4.427, avg. samples / sec: 66433.49
Iteration:   1260, Loss function: 4.842, Average Loss: 4.420, avg. samples / sec: 66587.42
Iteration:   1260, Loss function: 5.506, Average Loss: 4.423, avg. samples / sec: 66512.78
Iteration:   1260, Loss function: 5.446, Average Loss: 4.346, avg. samples / sec: 66468.02
Iteration:   1260, Loss function: 4.069, Average Loss: 4.391, avg. samples / sec: 66481.28
Iteration:   1260, Loss function: 5.430, Average Loss: 4.410, avg. samples / sec: 66424.60
Iteration:   1260, Loss function: 3.507, Average Loss: 4.422, avg. samples / sec: 66552.08
Iteration:   1260, Loss function: 4.706, Average Loss: 4.399, avg. samples / sec: 66601.08
Iteration:   1260, Loss function: 5.120, Average Loss: 4.396, avg. samples / sec: 66343.48
Iteration:   1260, Loss function: 4.705, Average Loss: 4.449, avg. samples / sec: 66491.13
Iteration:   1260, Loss function: 3.480, Average Loss: 4.413, avg. samples / sec: 66452.94
Iteration:   1260, Loss function: 4.266, Average Loss: 4.443, avg. samples / sec: 66511.72
Iteration:   1260, Loss function: 4.878, Average Loss: 4.424, avg. samples / sec: 66483.73
Iteration:   1260, Loss function: 6.784, Average Loss: 4.416, avg. samples / sec: 66506.32
Iteration:   1260, Loss function: 4.924, Average Loss: 4.392, avg. samples / sec: 66270.20
Iteration:   1260, Loss function: 5.328, Average Loss: 4.394, avg. samples / sec: 66473.41
Iteration:   1260, Loss function: 4.758, Average Loss: 4.417, avg. samples / sec: 66412.86
Iteration:   1260, Loss function: 4.630, Average Loss: 4.395, avg. samples / sec: 66365.54
Iteration:   1260, Loss function: 4.538, Average Loss: 4.427, avg. samples / sec: 66391.71
Iteration:   1260, Loss function: 6.581, Average Loss: 4.428, avg. samples / sec: 66382.20
Iteration:   1260, Loss function: 5.355, Average Loss: 4.424, avg. samples / sec: 66340.83
Iteration:   1260, Loss function: 5.003, Average Loss: 4.416, avg. samples / sec: 66383.83
Iteration:   1260, Loss function: 4.774, Average Loss: 4.412, avg. samples / sec: 66350.51
Iteration:   1260, Loss function: 4.315, Average Loss: 4.422, avg. samples / sec: 66304.31
Iteration:   1260, Loss function: 3.939, Average Loss: 4.426, avg. samples / sec: 66247.71
Iteration:   1260, Loss function: 5.602, Average Loss: 4.413, avg. samples / sec: 66209.46
Iteration:   1280, Loss function: 4.876, Average Loss: 4.441, avg. samples / sec: 66461.15
Iteration:   1280, Loss function: 4.777, Average Loss: 4.435, avg. samples / sec: 66355.38
Iteration:   1280, Loss function: 4.314, Average Loss: 4.427, avg. samples / sec: 66481.85
Iteration:   1280, Loss function: 5.974, Average Loss: 4.405, avg. samples / sec: 66361.73
Iteration:   1280, Loss function: 4.574, Average Loss: 4.395, avg. samples / sec: 66331.96
Iteration:   1280, Loss function: 4.212, Average Loss: 4.438, avg. samples / sec: 66227.75
Iteration:   1280, Loss function: 4.002, Average Loss: 4.424, avg. samples / sec: 66369.88
Iteration:   1280, Loss function: 6.051, Average Loss: 4.422, avg. samples / sec: 66106.72
Iteration:   1280, Loss function: 4.414, Average Loss: 4.434, avg. samples / sec: 66361.38
Iteration:   1280, Loss function: 6.344, Average Loss: 4.409, avg. samples / sec: 66264.62
Iteration:   1280, Loss function: 4.941, Average Loss: 4.406, avg. samples / sec: 66335.58
Iteration:   1280, Loss function: 4.575, Average Loss: 4.431, avg. samples / sec: 66221.71
Iteration:   1280, Loss function: 4.197, Average Loss: 4.400, avg. samples / sec: 66288.28
Iteration:   1280, Loss function: 4.624, Average Loss: 4.416, avg. samples / sec: 66249.79
Iteration:   1280, Loss function: 5.427, Average Loss: 4.421, avg. samples / sec: 66252.47
Iteration:   1280, Loss function: 4.244, Average Loss: 4.429, avg. samples / sec: 66253.06
Iteration:   1280, Loss function: 4.386, Average Loss: 4.436, avg. samples / sec: 66448.09
Iteration:   1280, Loss function: 4.968, Average Loss: 4.451, avg. samples / sec: 66190.77
Iteration:   1280, Loss function: 4.083, Average Loss: 4.349, avg. samples / sec: 66220.90
Iteration:   1280, Loss function: 5.601, Average Loss: 4.429, avg. samples / sec: 66163.11
Iteration:   1280, Loss function: 4.955, Average Loss: 4.427, avg. samples / sec: 66246.37
Iteration:   1280, Loss function: 5.026, Average Loss: 4.453, avg. samples / sec: 66233.42
Iteration:   1280, Loss function: 5.509, Average Loss: 4.412, avg. samples / sec: 66198.07
Iteration:   1280, Loss function: 4.429, Average Loss: 4.430, avg. samples / sec: 66302.66
Iteration:   1280, Loss function: 4.727, Average Loss: 4.431, avg. samples / sec: 66179.05
Iteration:   1280, Loss function: 3.701, Average Loss: 4.456, avg. samples / sec: 66204.32
Iteration:   1280, Loss function: 4.432, Average Loss: 4.419, avg. samples / sec: 66334.58
Iteration:   1280, Loss function: 4.738, Average Loss: 4.432, avg. samples / sec: 66360.38
Iteration:   1280, Loss function: 5.309, Average Loss: 4.421, avg. samples / sec: 66322.09
Iteration:   1280, Loss function: 3.972, Average Loss: 4.418, avg. samples / sec: 66145.60
Iteration:   1300, Loss function: 5.136, Average Loss: 4.445, avg. samples / sec: 66753.67
Iteration:   1300, Loss function: 3.906, Average Loss: 4.440, avg. samples / sec: 66789.01
Iteration:   1300, Loss function: 4.782, Average Loss: 4.445, avg. samples / sec: 66686.89
Iteration:   1300, Loss function: 4.261, Average Loss: 4.355, avg. samples / sec: 66748.45
Iteration:   1300, Loss function: 4.383, Average Loss: 4.415, avg. samples / sec: 66598.50
Iteration:   1300, Loss function: 4.522, Average Loss: 4.432, avg. samples / sec: 66619.15
Iteration:   1300, Loss function: 4.041, Average Loss: 4.455, avg. samples / sec: 66680.02
Iteration:   1300, Loss function: 5.028, Average Loss: 4.432, avg. samples / sec: 66681.47
Iteration:   1300, Loss function: 5.508, Average Loss: 4.449, avg. samples / sec: 66526.47
Iteration:   1300, Loss function: 4.295, Average Loss: 4.402, avg. samples / sec: 66558.74
Iteration:   1300, Loss function: 5.961, Average Loss: 4.415, avg. samples / sec: 66684.31
Iteration:   1300, Loss function: 5.832, Average Loss: 4.436, avg. samples / sec: 66672.73
Iteration:   1300, Loss function: 4.660, Average Loss: 4.432, avg. samples / sec: 66596.92
Iteration:   1300, Loss function: 6.195, Average Loss: 4.461, avg. samples / sec: 66649.58
Iteration:   1300, Loss function: 3.748, Average Loss: 4.422, avg. samples / sec: 66652.17
Iteration:   1300, Loss function: 4.349, Average Loss: 4.432, avg. samples / sec: 66495.21
Iteration:   1300, Loss function: 5.332, Average Loss: 4.409, avg. samples / sec: 66567.26
Iteration:   1300, Loss function: 4.915, Average Loss: 4.441, avg. samples / sec: 66583.65
Iteration:   1300, Loss function: 4.249, Average Loss: 4.429, avg. samples / sec: 66677.49
Iteration:   1300, Loss function: 3.978, Average Loss: 4.434, avg. samples / sec: 66603.88
Iteration:   1300, Loss function: 5.580, Average Loss: 4.422, avg. samples / sec: 66522.08
Iteration:   1300, Loss function: 5.173, Average Loss: 4.417, avg. samples / sec: 66533.16
Iteration:   1300, Loss function: 4.839, Average Loss: 4.461, avg. samples / sec: 66538.82
Iteration:   1300, Loss function: 4.581, Average Loss: 4.432, avg. samples / sec: 66498.75
Iteration:   1300, Loss function: 5.297, Average Loss: 4.442, avg. samples / sec: 66459.08
Iteration:   1300, Loss function: 5.856, Average Loss: 4.440, avg. samples / sec: 66376.70
Iteration:   1300, Loss function: 4.157, Average Loss: 4.433, avg. samples / sec: 66352.51
Iteration:   1300, Loss function: 5.059, Average Loss: 4.426, avg. samples / sec: 66525.84
Iteration:   1300, Loss function: 3.936, Average Loss: 4.405, avg. samples / sec: 66313.98
Iteration:   1300, Loss function: 4.492, Average Loss: 4.439, avg. samples / sec: 66384.70
Iteration:   1320, Loss function: 3.631, Average Loss: 4.424, avg. samples / sec: 66389.74
Iteration:   1320, Loss function: 3.958, Average Loss: 4.451, avg. samples / sec: 66305.99
Iteration:   1320, Loss function: 5.781, Average Loss: 4.412, avg. samples / sec: 66372.48
Iteration:   1320, Loss function: 4.995, Average Loss: 4.440, avg. samples / sec: 66410.64
Iteration:   1320, Loss function: 3.843, Average Loss: 4.423, avg. samples / sec: 66487.08
Iteration:   1320, Loss function: 2.569, Average Loss: 4.429, avg. samples / sec: 66419.15
Iteration:   1320, Loss function: 4.074, Average Loss: 4.450, avg. samples / sec: 66357.91
Iteration:   1320, Loss function: 5.327, Average Loss: 4.435, avg. samples / sec: 66430.01
Iteration:   1320, Loss function: 4.160, Average Loss: 4.442, avg. samples / sec: 66474.91
Iteration:   1320, Loss function: 5.835, Average Loss: 4.448, avg. samples / sec: 66204.07
Iteration:   1320, Loss function: 4.798, Average Loss: 4.442, avg. samples / sec: 66365.41
Iteration:   1320, Loss function: 5.514, Average Loss: 4.412, avg. samples / sec: 66354.95
Iteration:   1320, Loss function: 4.549, Average Loss: 4.429, avg. samples / sec: 66528.11
Iteration:   1320, Loss function: 4.177, Average Loss: 4.435, avg. samples / sec: 66360.29
Iteration:   1320, Loss function: 4.928, Average Loss: 4.421, avg. samples / sec: 66284.51
Iteration:   1320, Loss function: 4.365, Average Loss: 4.442, avg. samples / sec: 66273.38
Iteration:   1320, Loss function: 4.723, Average Loss: 4.440, avg. samples / sec: 66273.94
Iteration:   1320, Loss function: 4.486, Average Loss: 4.463, avg. samples / sec: 66291.99
Iteration:   1320, Loss function: 3.658, Average Loss: 4.435, avg. samples / sec: 66218.60
Iteration:   1320, Loss function: 4.543, Average Loss: 4.434, avg. samples / sec: 66380.45
Iteration:   1320, Loss function: 4.528, Average Loss: 4.366, avg. samples / sec: 66145.13
Iteration:   1320, Loss function: 4.172, Average Loss: 4.444, avg. samples / sec: 66538.28
Iteration:   1320, Loss function: 3.959, Average Loss: 4.406, avg. samples / sec: 66532.19
Iteration:   1320, Loss function: 4.951, Average Loss: 4.434, avg. samples / sec: 66447.27
Iteration:   1320, Loss function: 6.139, Average Loss: 4.435, avg. samples / sec: 66209.11
Iteration:   1320, Loss function: 4.226, Average Loss: 4.422, avg. samples / sec: 66315.13
Iteration:   1320, Loss function: 5.173, Average Loss: 4.461, avg. samples / sec: 66364.91
Iteration:   1320, Loss function: 4.229, Average Loss: 4.447, avg. samples / sec: 66102.62
Iteration:   1320, Loss function: 4.713, Average Loss: 4.445, avg. samples / sec: 66327.21
Iteration:   1320, Loss function: 4.882, Average Loss: 4.457, avg. samples / sec: 66161.62
:::MLL 1558651558.052 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558651558.052 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 3.348, Average Loss: 4.453, avg. samples / sec: 66034.27
Iteration:   1340, Loss function: 4.317, Average Loss: 4.453, avg. samples / sec: 65960.21
Iteration:   1340, Loss function: 4.269, Average Loss: 4.462, avg. samples / sec: 66190.08
Iteration:   1340, Loss function: 4.059, Average Loss: 4.445, avg. samples / sec: 66036.96
Iteration:   1340, Loss function: 4.162, Average Loss: 4.451, avg. samples / sec: 66174.32
Iteration:   1340, Loss function: 4.120, Average Loss: 4.366, avg. samples / sec: 66116.80
Iteration:   1340, Loss function: 5.062, Average Loss: 4.418, avg. samples / sec: 66041.23
Iteration:   1340, Loss function: 3.192, Average Loss: 4.422, avg. samples / sec: 65937.07
Iteration:   1340, Loss function: 5.332, Average Loss: 4.441, avg. samples / sec: 66096.77
Iteration:   1340, Loss function: 5.017, Average Loss: 4.426, avg. samples / sec: 66085.79
Iteration:   1340, Loss function: 3.828, Average Loss: 4.435, avg. samples / sec: 66090.13
Iteration:   1340, Loss function: 4.581, Average Loss: 4.436, avg. samples / sec: 66052.53
Iteration:   1340, Loss function: 4.827, Average Loss: 4.429, avg. samples / sec: 65859.11
Iteration:   1340, Loss function: 3.401, Average Loss: 4.445, avg. samples / sec: 66071.08
Iteration:   1340, Loss function: 3.637, Average Loss: 4.454, avg. samples / sec: 65937.41
Iteration:   1340, Loss function: 4.688, Average Loss: 4.424, avg. samples / sec: 65991.50
Iteration:   1340, Loss function: 4.523, Average Loss: 4.441, avg. samples / sec: 65886.48
Iteration:   1340, Loss function: 5.669, Average Loss: 4.409, avg. samples / sec: 66031.79
Iteration:   1340, Loss function: 4.077, Average Loss: 4.466, avg. samples / sec: 66025.02
Iteration:   1340, Loss function: 3.758, Average Loss: 4.467, avg. samples / sec: 65992.06
Iteration:   1340, Loss function: 5.923, Average Loss: 4.446, avg. samples / sec: 65993.67
Iteration:   1340, Loss function: 4.979, Average Loss: 4.413, avg. samples / sec: 65848.98
Iteration:   1340, Loss function: 3.471, Average Loss: 4.435, avg. samples / sec: 65979.95
Iteration:   1340, Loss function: 3.855, Average Loss: 4.432, avg. samples / sec: 65938.67
Iteration:   1340, Loss function: 4.427, Average Loss: 4.435, avg. samples / sec: 65840.25
Iteration:   1340, Loss function: 5.479, Average Loss: 4.444, avg. samples / sec: 65945.80
Iteration:   1340, Loss function: 4.902, Average Loss: 4.444, avg. samples / sec: 65956.79
Iteration:   1340, Loss function: 4.324, Average Loss: 4.442, avg. samples / sec: 65817.92
Iteration:   1340, Loss function: 4.210, Average Loss: 4.441, avg. samples / sec: 65886.70
Iteration:   1340, Loss function: 5.868, Average Loss: 4.449, avg. samples / sec: 65772.83
Iteration:   1360, Loss function: 4.239, Average Loss: 4.458, avg. samples / sec: 66547.55
Iteration:   1360, Loss function: 4.721, Average Loss: 4.420, avg. samples / sec: 66646.65
Iteration:   1360, Loss function: 4.430, Average Loss: 4.444, avg. samples / sec: 66533.01
Iteration:   1360, Loss function: 4.184, Average Loss: 4.467, avg. samples / sec: 66467.92
Iteration:   1360, Loss function: 3.935, Average Loss: 4.453, avg. samples / sec: 66442.01
Iteration:   1360, Loss function: 4.790, Average Loss: 4.419, avg. samples / sec: 66535.99
Iteration:   1360, Loss function: 4.418, Average Loss: 4.414, avg. samples / sec: 66597.46
Iteration:   1360, Loss function: 4.453, Average Loss: 4.371, avg. samples / sec: 66481.56
Iteration:   1360, Loss function: 5.645, Average Loss: 4.428, avg. samples / sec: 66558.27
Iteration:   1360, Loss function: 3.768, Average Loss: 4.432, avg. samples / sec: 66518.78
Iteration:   1360, Loss function: 5.074, Average Loss: 4.439, avg. samples / sec: 66483.23
Iteration:   1360, Loss function: 3.938, Average Loss: 4.437, avg. samples / sec: 66453.00
Iteration:   1360, Loss function: 4.359, Average Loss: 4.449, avg. samples / sec: 66600.64
Iteration:   1360, Loss function: 4.976, Average Loss: 4.452, avg. samples / sec: 66517.08
Iteration:   1360, Loss function: 4.947, Average Loss: 4.439, avg. samples / sec: 66542.30
Iteration:   1360, Loss function: 4.675, Average Loss: 4.456, avg. samples / sec: 66664.97
Iteration:   1360, Loss function: 4.833, Average Loss: 4.448, avg. samples / sec: 66571.88
Iteration:   1360, Loss function: 4.996, Average Loss: 4.429, avg. samples / sec: 66416.27
Iteration:   1360, Loss function: 4.550, Average Loss: 4.457, avg. samples / sec: 66449.53
Iteration:   1360, Loss function: 4.502, Average Loss: 4.423, avg. samples / sec: 66386.42
Iteration:   1360, Loss function: 4.061, Average Loss: 4.466, avg. samples / sec: 66461.00
Iteration:   1360, Loss function: 3.163, Average Loss: 4.441, avg. samples / sec: 66533.54
Iteration:   1360, Loss function: 4.588, Average Loss: 4.448, avg. samples / sec: 66337.70
Iteration:   1360, Loss function: 5.124, Average Loss: 4.437, avg. samples / sec: 66463.97
Iteration:   1360, Loss function: 4.344, Average Loss: 4.465, avg. samples / sec: 66430.01
Iteration:   1360, Loss function: 5.083, Average Loss: 4.447, avg. samples / sec: 66443.23
Iteration:   1360, Loss function: 3.821, Average Loss: 4.449, avg. samples / sec: 66483.51
Iteration:   1360, Loss function: 3.915, Average Loss: 4.453, avg. samples / sec: 66320.19
Iteration:   1360, Loss function: 4.608, Average Loss: 4.441, avg. samples / sec: 66459.46
Iteration:   1360, Loss function: 3.480, Average Loss: 4.445, avg. samples / sec: 66344.51
Iteration:   1380, Loss function: 4.588, Average Loss: 4.440, avg. samples / sec: 66355.63
Iteration:   1380, Loss function: 4.393, Average Loss: 4.426, avg. samples / sec: 66305.99
Iteration:   1380, Loss function: 5.737, Average Loss: 4.466, avg. samples / sec: 66229.56
Iteration:   1380, Loss function: 4.774, Average Loss: 4.461, avg. samples / sec: 66418.30
Iteration:   1380, Loss function: 5.299, Average Loss: 4.453, avg. samples / sec: 66460.75
Iteration:   1380, Loss function: 5.604, Average Loss: 4.428, avg. samples / sec: 66271.98
Iteration:   1380, Loss function: 4.633, Average Loss: 4.447, avg. samples / sec: 66330.12
Iteration:   1380, Loss function: 5.307, Average Loss: 4.450, avg. samples / sec: 66469.33
Iteration:   1380, Loss function: 4.552, Average Loss: 4.451, avg. samples / sec: 66401.59
Iteration:   1380, Loss function: 3.999, Average Loss: 4.474, avg. samples / sec: 66250.45
Iteration:   1380, Loss function: 4.759, Average Loss: 4.465, avg. samples / sec: 66344.73
Iteration:   1380, Loss function: 4.519, Average Loss: 4.437, avg. samples / sec: 66268.27
Iteration:   1380, Loss function: 5.305, Average Loss: 4.447, avg. samples / sec: 66416.61
Iteration:   1380, Loss function: 4.271, Average Loss: 4.455, avg. samples / sec: 66246.87
Iteration:   1380, Loss function: 5.326, Average Loss: 4.444, avg. samples / sec: 66326.68
Iteration:   1380, Loss function: 4.287, Average Loss: 4.377, avg. samples / sec: 66265.00
Iteration:   1380, Loss function: 4.721, Average Loss: 4.467, avg. samples / sec: 66339.61
Iteration:   1380, Loss function: 5.994, Average Loss: 4.454, avg. samples / sec: 66371.51
Iteration:   1380, Loss function: 4.979, Average Loss: 4.472, avg. samples / sec: 66371.57
Iteration:   1380, Loss function: 3.611, Average Loss: 4.425, avg. samples / sec: 66182.40
Iteration:   1380, Loss function: 4.710, Average Loss: 4.440, avg. samples / sec: 66300.69
Iteration:   1380, Loss function: 3.794, Average Loss: 4.457, avg. samples / sec: 66349.29
Iteration:   1380, Loss function: 5.238, Average Loss: 4.447, avg. samples / sec: 66152.55
Iteration:   1380, Loss function: 5.143, Average Loss: 4.456, avg. samples / sec: 66270.45
Iteration:   1380, Loss function: 4.425, Average Loss: 4.457, avg. samples / sec: 66222.18
Iteration:   1380, Loss function: 4.917, Average Loss: 4.450, avg. samples / sec: 66235.00
Iteration:   1380, Loss function: 4.493, Average Loss: 4.432, avg. samples / sec: 66251.57
Iteration:   1380, Loss function: 4.966, Average Loss: 4.446, avg. samples / sec: 66240.92
Iteration:   1380, Loss function: 3.416, Average Loss: 4.446, avg. samples / sec: 66242.97
Iteration:   1380, Loss function: 6.207, Average Loss: 4.456, avg. samples / sec: 66146.84
:::MLL 1558651559.826 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558651559.827 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 4.692, Average Loss: 4.453, avg. samples / sec: 66402.62
Iteration:   1400, Loss function: 4.456, Average Loss: 4.446, avg. samples / sec: 66288.28
Iteration:   1400, Loss function: 4.202, Average Loss: 4.472, avg. samples / sec: 66313.39
Iteration:   1400, Loss function: 4.461, Average Loss: 4.437, avg. samples / sec: 66382.51
Iteration:   1400, Loss function: 4.188, Average Loss: 4.441, avg. samples / sec: 66313.64
Iteration:   1400, Loss function: 3.021, Average Loss: 4.380, avg. samples / sec: 66305.09
Iteration:   1400, Loss function: 4.995, Average Loss: 4.481, avg. samples / sec: 66313.70
Iteration:   1400, Loss function: 4.457, Average Loss: 4.432, avg. samples / sec: 66168.86
Iteration:   1400, Loss function: 5.364, Average Loss: 4.452, avg. samples / sec: 66214.03
Iteration:   1400, Loss function: 3.984, Average Loss: 4.444, avg. samples / sec: 66305.18
Iteration:   1400, Loss function: 5.321, Average Loss: 4.463, avg. samples / sec: 66413.95
Iteration:   1400, Loss function: 3.644, Average Loss: 4.463, avg. samples / sec: 66281.86
Iteration:   1400, Loss function: 4.670, Average Loss: 4.468, avg. samples / sec: 66178.89
Iteration:   1400, Loss function: 3.969, Average Loss: 4.455, avg. samples / sec: 66375.95
Iteration:   1400, Loss function: 4.417, Average Loss: 4.460, avg. samples / sec: 66243.16
Iteration:   1400, Loss function: 4.922, Average Loss: 4.459, avg. samples / sec: 66156.43
Iteration:   1400, Loss function: 5.962, Average Loss: 4.480, avg. samples / sec: 66187.19
Iteration:   1400, Loss function: 5.379, Average Loss: 4.458, avg. samples / sec: 66274.97
Iteration:   1400, Loss function: 3.685, Average Loss: 4.457, avg. samples / sec: 66149.10
Iteration:   1400, Loss function: 4.180, Average Loss: 4.470, avg. samples / sec: 66183.15
Iteration:   1400, Loss function: 4.659, Average Loss: 4.457, avg. samples / sec: 66249.45
Iteration:   1400, Loss function: 4.140, Average Loss: 4.461, avg. samples / sec: 66241.01
Iteration:   1400, Loss function: 5.068, Average Loss: 4.456, avg. samples / sec: 66120.92
Iteration:   1400, Loss function: 5.254, Average Loss: 4.458, avg. samples / sec: 66139.42
Iteration:   1400, Loss function: 3.851, Average Loss: 4.439, avg. samples / sec: 66229.21
Iteration:   1400, Loss function: 4.070, Average Loss: 4.451, avg. samples / sec: 66267.08
Iteration:   1400, Loss function: 4.404, Average Loss: 4.451, avg. samples / sec: 66191.85
Iteration:   1400, Loss function: 4.226, Average Loss: 4.471, avg. samples / sec: 66065.69
Iteration:   1400, Loss function: 4.760, Average Loss: 4.458, avg. samples / sec: 66067.14
Iteration:   1400, Loss function: 4.415, Average Loss: 4.438, avg. samples / sec: 66008.07
Iteration:   1420, Loss function: 3.782, Average Loss: 4.460, avg. samples / sec: 66471.97
Iteration:   1420, Loss function: 3.955, Average Loss: 4.453, avg. samples / sec: 66480.56
Iteration:   1420, Loss function: 4.694, Average Loss: 4.441, avg. samples / sec: 66494.58
Iteration:   1420, Loss function: 4.291, Average Loss: 4.454, avg. samples / sec: 66435.05
Iteration:   1420, Loss function: 4.700, Average Loss: 4.452, avg. samples / sec: 66184.46
Iteration:   1420, Loss function: 3.732, Average Loss: 4.473, avg. samples / sec: 66169.32
Iteration:   1420, Loss function: 3.981, Average Loss: 4.385, avg. samples / sec: 66261.79
Iteration:   1420, Loss function: 5.040, Average Loss: 4.459, avg. samples / sec: 66158.76
Iteration:   1420, Loss function: 5.588, Average Loss: 4.469, avg. samples / sec: 66337.17
Iteration:   1420, Loss function: 4.177, Average Loss: 4.469, avg. samples / sec: 66321.10
Iteration:   1420, Loss function: 3.752, Average Loss: 4.473, avg. samples / sec: 66473.38
Iteration:   1420, Loss function: 3.876, Average Loss: 4.454, avg. samples / sec: 66474.66
Iteration:   1420, Loss function: 5.204, Average Loss: 4.463, avg. samples / sec: 66354.70
Iteration:   1420, Loss function: 4.057, Average Loss: 4.443, avg. samples / sec: 66224.20
Iteration:   1420, Loss function: 4.153, Average Loss: 4.459, avg. samples / sec: 66372.73
Iteration:   1420, Loss function: 4.853, Average Loss: 4.470, avg. samples / sec: 66373.10
Iteration:   1420, Loss function: 4.434, Average Loss: 4.447, avg. samples / sec: 66269.61
Iteration:   1420, Loss function: 5.068, Average Loss: 4.458, avg. samples / sec: 66287.50
Iteration:   1420, Loss function: 3.941, Average Loss: 4.462, avg. samples / sec: 66296.98
Iteration:   1420, Loss function: 3.848, Average Loss: 4.453, avg. samples / sec: 66258.02
Iteration:   1420, Loss function: 4.767, Average Loss: 4.434, avg. samples / sec: 66234.51
Iteration:   1420, Loss function: 3.921, Average Loss: 4.443, avg. samples / sec: 66427.60
Iteration:   1420, Loss function: 4.890, Average Loss: 4.481, avg. samples / sec: 66269.26
Iteration:   1420, Loss function: 5.661, Average Loss: 4.482, avg. samples / sec: 66189.83
Iteration:   1420, Loss function: 5.568, Average Loss: 4.462, avg. samples / sec: 66198.32
Iteration:   1420, Loss function: 5.322, Average Loss: 4.447, avg. samples / sec: 66245.96
Iteration:   1420, Loss function: 4.101, Average Loss: 4.465, avg. samples / sec: 66126.38
Iteration:   1420, Loss function: 4.579, Average Loss: 4.445, avg. samples / sec: 66021.86
Iteration:   1420, Loss function: 4.054, Average Loss: 4.463, avg. samples / sec: 66194.53
Iteration:   1420, Loss function: 4.099, Average Loss: 4.453, avg. samples / sec: 66217.89
Iteration:   1440, Loss function: 3.449, Average Loss: 4.453, avg. samples / sec: 66612.88
Iteration:   1440, Loss function: 5.109, Average Loss: 4.467, avg. samples / sec: 66577.95
Iteration:   1440, Loss function: 4.927, Average Loss: 4.479, avg. samples / sec: 66566.85
Iteration:   1440, Loss function: 4.849, Average Loss: 4.486, avg. samples / sec: 66630.52
Iteration:   1440, Loss function: 3.502, Average Loss: 4.452, avg. samples / sec: 66473.13
Iteration:   1440, Loss function: 4.343, Average Loss: 4.459, avg. samples / sec: 66558.43
Iteration:   1440, Loss function: 4.480, Average Loss: 4.460, avg. samples / sec: 66514.01
Iteration:   1440, Loss function: 4.523, Average Loss: 4.461, avg. samples / sec: 66432.67
Iteration:   1440, Loss function: 4.480, Average Loss: 4.465, avg. samples / sec: 66659.39
Iteration:   1440, Loss function: 4.222, Average Loss: 4.437, avg. samples / sec: 66557.51
Iteration:   1440, Loss function: 4.517, Average Loss: 4.446, avg. samples / sec: 66677.97
Iteration:   1440, Loss function: 4.739, Average Loss: 4.469, avg. samples / sec: 66481.06
Iteration:   1440, Loss function: 4.949, Average Loss: 4.467, avg. samples / sec: 66600.35
Iteration:   1440, Loss function: 5.725, Average Loss: 4.470, avg. samples / sec: 66659.93
Iteration:   1440, Loss function: 4.692, Average Loss: 4.463, avg. samples / sec: 66414.17
Iteration:   1440, Loss function: 4.155, Average Loss: 4.461, avg. samples / sec: 66438.91
Iteration:   1440, Loss function: 2.855, Average Loss: 4.391, avg. samples / sec: 66403.84
Iteration:   1440, Loss function: 4.182, Average Loss: 4.450, avg. samples / sec: 66604.79
Iteration:   1440, Loss function: 3.955, Average Loss: 4.470, avg. samples / sec: 66464.44
Iteration:   1440, Loss function: 4.846, Average Loss: 4.450, avg. samples / sec: 66346.51
Iteration:   1440, Loss function: 3.970, Average Loss: 4.457, avg. samples / sec: 66370.63
Iteration:   1440, Loss function: 3.716, Average Loss: 4.472, avg. samples / sec: 66420.53
Iteration:   1440, Loss function: 4.584, Average Loss: 4.445, avg. samples / sec: 66421.87
Iteration:   1440, Loss function: 3.972, Average Loss: 4.454, avg. samples / sec: 66617.61
Iteration:   1440, Loss function: 3.850, Average Loss: 4.480, avg. samples / sec: 66472.16
Iteration:   1440, Loss function: 3.535, Average Loss: 4.460, avg. samples / sec: 66410.20
Iteration:   1440, Loss function: 4.590, Average Loss: 4.480, avg. samples / sec: 66359.32
Iteration:   1440, Loss function: 4.563, Average Loss: 4.451, avg. samples / sec: 66431.86
Iteration:   1440, Loss function: 4.944, Average Loss: 4.445, avg. samples / sec: 66386.30
Iteration:   1440, Loss function: 5.094, Average Loss: 4.473, avg. samples / sec: 66248.39
Iteration:   1460, Loss function: 4.250, Average Loss: 4.451, avg. samples / sec: 66381.82
Iteration:   1460, Loss function: 4.599, Average Loss: 4.450, avg. samples / sec: 66567.26
Iteration:   1460, Loss function: 3.640, Average Loss: 4.467, avg. samples / sec: 66388.36
Iteration:   1460, Loss function: 3.727, Average Loss: 4.450, avg. samples / sec: 66425.72
Iteration:   1460, Loss function: 3.622, Average Loss: 4.470, avg. samples / sec: 66720.42
Iteration:   1460, Loss function: 4.301, Average Loss: 4.452, avg. samples / sec: 66621.67
Iteration:   1460, Loss function: 4.764, Average Loss: 4.465, avg. samples / sec: 66433.30
Iteration:   1460, Loss function: 3.394, Average Loss: 4.433, avg. samples / sec: 66459.59
Iteration:   1460, Loss function: 4.408, Average Loss: 4.464, avg. samples / sec: 66454.51
Iteration:   1460, Loss function: 3.505, Average Loss: 4.451, avg. samples / sec: 66538.53
Iteration:   1460, Loss function: 4.164, Average Loss: 4.390, avg. samples / sec: 66518.09
Iteration:   1460, Loss function: 5.097, Average Loss: 4.462, avg. samples / sec: 66501.33
Iteration:   1460, Loss function: 5.009, Average Loss: 4.467, avg. samples / sec: 66501.36
Iteration:   1460, Loss function: 3.936, Average Loss: 4.491, avg. samples / sec: 66339.55
Iteration:   1460, Loss function: 3.382, Average Loss: 4.470, avg. samples / sec: 66485.64
Iteration:   1460, Loss function: 4.882, Average Loss: 4.482, avg. samples / sec: 66467.64
Iteration:   1460, Loss function: 4.172, Average Loss: 4.444, avg. samples / sec: 66492.54
Iteration:   1460, Loss function: 4.947, Average Loss: 4.470, avg. samples / sec: 66454.73
Iteration:   1460, Loss function: 3.729, Average Loss: 4.457, avg. samples / sec: 66333.05
Iteration:   1460, Loss function: 4.010, Average Loss: 4.471, avg. samples / sec: 66356.51
Iteration:   1460, Loss function: 4.483, Average Loss: 4.459, avg. samples / sec: 66328.74
Iteration:   1460, Loss function: 4.325, Average Loss: 4.454, avg. samples / sec: 66404.22
Iteration:   1460, Loss function: 4.889, Average Loss: 4.453, avg. samples / sec: 66404.72
Iteration:   1460, Loss function: 3.898, Average Loss: 4.458, avg. samples / sec: 66444.01
Iteration:   1460, Loss function: 3.825, Average Loss: 4.474, avg. samples / sec: 66349.51
Iteration:   1460, Loss function: 4.794, Average Loss: 4.467, avg. samples / sec: 66329.12
Iteration:   1460, Loss function: 3.658, Average Loss: 4.447, avg. samples / sec: 66317.91
Iteration:   1460, Loss function: 5.123, Average Loss: 4.478, avg. samples / sec: 66208.43
Iteration:   1460, Loss function: 4.537, Average Loss: 4.480, avg. samples / sec: 66390.83
Iteration:   1460, Loss function: 4.671, Average Loss: 4.455, avg. samples / sec: 66235.41
:::MLL 1558651561.599 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558651561.599 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 3.448, Average Loss: 4.474, avg. samples / sec: 66312.42
Iteration:   1480, Loss function: 5.074, Average Loss: 4.456, avg. samples / sec: 66229.81
Iteration:   1480, Loss function: 4.467, Average Loss: 4.471, avg. samples / sec: 66201.34
Iteration:   1480, Loss function: 4.338, Average Loss: 4.471, avg. samples / sec: 66067.98
Iteration:   1480, Loss function: 4.100, Average Loss: 4.454, avg. samples / sec: 66381.01
Iteration:   1480, Loss function: 4.813, Average Loss: 4.459, avg. samples / sec: 65984.80
Iteration:   1480, Loss function: 3.860, Average Loss: 4.490, avg. samples / sec: 66113.76
Iteration:   1480, Loss function: 3.996, Average Loss: 4.467, avg. samples / sec: 66063.86
Iteration:   1480, Loss function: 4.272, Average Loss: 4.470, avg. samples / sec: 66036.28
Iteration:   1480, Loss function: 5.553, Average Loss: 4.483, avg. samples / sec: 66113.35
Iteration:   1480, Loss function: 4.730, Average Loss: 4.454, avg. samples / sec: 66008.04
Iteration:   1480, Loss function: 4.338, Average Loss: 4.442, avg. samples / sec: 66109.94
Iteration:   1480, Loss function: 4.547, Average Loss: 4.454, avg. samples / sec: 66038.17
Iteration:   1480, Loss function: 4.563, Average Loss: 4.469, avg. samples / sec: 66028.79
Iteration:   1480, Loss function: 3.615, Average Loss: 4.480, avg. samples / sec: 66180.07
Iteration:   1480, Loss function: 5.735, Average Loss: 4.439, avg. samples / sec: 65980.19
Iteration:   1480, Loss function: 5.486, Average Loss: 4.472, avg. samples / sec: 66055.93
Iteration:   1480, Loss function: 3.901, Average Loss: 4.455, avg. samples / sec: 66045.04
Iteration:   1480, Loss function: 3.324, Average Loss: 4.462, avg. samples / sec: 65973.77
Iteration:   1480, Loss function: 5.137, Average Loss: 4.475, avg. samples / sec: 66120.21
Iteration:   1480, Loss function: 4.983, Average Loss: 4.460, avg. samples / sec: 66072.41
Iteration:   1480, Loss function: 4.385, Average Loss: 4.451, avg. samples / sec: 66091.65
Iteration:   1480, Loss function: 4.667, Average Loss: 4.454, avg. samples / sec: 65899.17
Iteration:   1480, Loss function: 5.645, Average Loss: 4.466, avg. samples / sec: 65951.14
Iteration:   1480, Loss function: 3.794, Average Loss: 4.456, avg. samples / sec: 66027.71
Iteration:   1480, Loss function: 3.602, Average Loss: 4.389, avg. samples / sec: 65919.80
Iteration:   1480, Loss function: 3.437, Average Loss: 4.459, avg. samples / sec: 66019.02
Iteration:   1480, Loss function: 4.837, Average Loss: 4.455, avg. samples / sec: 65844.95
Iteration:   1480, Loss function: 4.910, Average Loss: 4.473, avg. samples / sec: 65997.25
Iteration:   1480, Loss function: 4.488, Average Loss: 4.475, avg. samples / sec: 65894.37
Iteration:   1500, Loss function: 5.484, Average Loss: 4.488, avg. samples / sec: 66583.96
Iteration:   1500, Loss function: 4.551, Average Loss: 4.478, avg. samples / sec: 66490.35
Iteration:   1500, Loss function: 4.132, Average Loss: 4.472, avg. samples / sec: 66626.02
Iteration:   1500, Loss function: 4.273, Average Loss: 4.470, avg. samples / sec: 66539.04
Iteration:   1500, Loss function: 4.934, Average Loss: 4.439, avg. samples / sec: 66601.55
Iteration:   1500, Loss function: 4.225, Average Loss: 4.465, avg. samples / sec: 66529.02
Iteration:   1500, Loss function: 5.481, Average Loss: 4.457, avg. samples / sec: 66472.81
Iteration:   1500, Loss function: 4.318, Average Loss: 4.467, avg. samples / sec: 66566.95
Iteration:   1500, Loss function: 5.645, Average Loss: 4.454, avg. samples / sec: 66593.18
Iteration:   1500, Loss function: 4.333, Average Loss: 4.455, avg. samples / sec: 66565.97
Iteration:   1500, Loss function: 5.287, Average Loss: 4.475, avg. samples / sec: 66404.19
Iteration:   1500, Loss function: 5.300, Average Loss: 4.455, avg. samples / sec: 66453.07
Iteration:   1500, Loss function: 4.661, Average Loss: 4.461, avg. samples / sec: 66523.02
Iteration:   1500, Loss function: 3.390, Average Loss: 4.443, avg. samples / sec: 66433.74
Iteration:   1500, Loss function: 4.990, Average Loss: 4.396, avg. samples / sec: 66536.59
Iteration:   1500, Loss function: 4.436, Average Loss: 4.483, avg. samples / sec: 66418.15
Iteration:   1500, Loss function: 4.041, Average Loss: 4.457, avg. samples / sec: 66505.31
Iteration:   1500, Loss function: 3.863, Average Loss: 4.484, avg. samples / sec: 66610.02
Iteration:   1500, Loss function: 4.740, Average Loss: 4.458, avg. samples / sec: 66323.25
Iteration:   1500, Loss function: 4.592, Average Loss: 4.463, avg. samples / sec: 66364.01
Iteration:   1500, Loss function: 4.603, Average Loss: 4.470, avg. samples / sec: 66501.61
Iteration:   1500, Loss function: 4.115, Average Loss: 4.474, avg. samples / sec: 66334.92
Iteration:   1500, Loss function: 5.282, Average Loss: 4.484, avg. samples / sec: 66407.13
Iteration:   1500, Loss function: 5.894, Average Loss: 4.464, avg. samples / sec: 66496.84
Iteration:   1500, Loss function: 4.542, Average Loss: 4.466, avg. samples / sec: 66431.05
Iteration:   1500, Loss function: 6.052, Average Loss: 4.454, avg. samples / sec: 66338.52
Iteration:   1500, Loss function: 4.970, Average Loss: 4.473, avg. samples / sec: 66395.99
Iteration:   1500, Loss function: 5.125, Average Loss: 4.478, avg. samples / sec: 66505.28
Iteration:   1500, Loss function: 4.209, Average Loss: 4.465, avg. samples / sec: 66395.55
Iteration:   1500, Loss function: 4.702, Average Loss: 4.474, avg. samples / sec: 66311.02
Iteration:   1520, Loss function: 3.119, Average Loss: 4.469, avg. samples / sec: 66597.36
Iteration:   1520, Loss function: 5.043, Average Loss: 4.439, avg. samples / sec: 66561.85
Iteration:   1520, Loss function: 4.713, Average Loss: 4.485, avg. samples / sec: 66768.76
Iteration:   1520, Loss function: 4.431, Average Loss: 4.473, avg. samples / sec: 66520.13
Iteration:   1520, Loss function: 4.799, Average Loss: 4.464, avg. samples / sec: 66701.89
Iteration:   1520, Loss function: 4.426, Average Loss: 4.470, avg. samples / sec: 66474.16
Iteration:   1520, Loss function: 4.930, Average Loss: 4.466, avg. samples / sec: 66563.27
Iteration:   1520, Loss function: 4.693, Average Loss: 4.460, avg. samples / sec: 66730.82
Iteration:   1520, Loss function: 5.442, Average Loss: 4.476, avg. samples / sec: 66648.07
Iteration:   1520, Loss function: 4.615, Average Loss: 4.458, avg. samples / sec: 66588.43
Iteration:   1520, Loss function: 4.865, Average Loss: 4.465, avg. samples / sec: 66479.40
Iteration:   1520, Loss function: 3.299, Average Loss: 4.477, avg. samples / sec: 66599.72
Iteration:   1520, Loss function: 4.187, Average Loss: 4.448, avg. samples / sec: 66579.59
Iteration:   1520, Loss function: 5.737, Average Loss: 4.452, avg. samples / sec: 66522.70
Iteration:   1520, Loss function: 5.294, Average Loss: 4.469, avg. samples / sec: 66656.43
Iteration:   1520, Loss function: 3.849, Average Loss: 4.458, avg. samples / sec: 66503.62
Iteration:   1520, Loss function: 4.045, Average Loss: 4.475, avg. samples / sec: 66620.69
Iteration:   1520, Loss function: 3.597, Average Loss: 4.397, avg. samples / sec: 66573.52
Iteration:   1520, Loss function: 5.176, Average Loss: 4.480, avg. samples / sec: 66573.14
Iteration:   1520, Loss function: 4.084, Average Loss: 4.454, avg. samples / sec: 66492.42
Iteration:   1520, Loss function: 4.559, Average Loss: 4.461, avg. samples / sec: 66565.63
Iteration:   1520, Loss function: 5.870, Average Loss: 4.477, avg. samples / sec: 66684.72
Iteration:   1520, Loss function: 3.579, Average Loss: 4.464, avg. samples / sec: 66617.51
Iteration:   1520, Loss function: 3.554, Average Loss: 4.486, avg. samples / sec: 66325.31
Iteration:   1520, Loss function: 3.772, Average Loss: 4.457, avg. samples / sec: 66533.32
Iteration:   1520, Loss function: 4.872, Average Loss: 4.467, avg. samples / sec: 66466.98
Iteration:   1520, Loss function: 3.449, Average Loss: 4.480, avg. samples / sec: 66582.54
Iteration:   1520, Loss function: 3.676, Average Loss: 4.479, avg. samples / sec: 66556.67
Iteration:   1520, Loss function: 6.046, Average Loss: 4.469, avg. samples / sec: 66593.15
Iteration:   1520, Loss function: 4.206, Average Loss: 4.485, avg. samples / sec: 66421.84
:::MLL 1558651563.375 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558651563.376 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.337, Average Loss: 4.468, avg. samples / sec: 65763.68
Iteration:   1540, Loss function: 4.582, Average Loss: 4.433, avg. samples / sec: 65718.73
Iteration:   1540, Loss function: 4.671, Average Loss: 4.465, avg. samples / sec: 65745.77
Iteration:   1540, Loss function: 5.774, Average Loss: 4.471, avg. samples / sec: 65573.51
Iteration:   1540, Loss function: 4.774, Average Loss: 4.469, avg. samples / sec: 65832.50
Iteration:   1540, Loss function: 4.668, Average Loss: 4.403, avg. samples / sec: 65755.86
Iteration:   1540, Loss function: 4.322, Average Loss: 4.461, avg. samples / sec: 65645.68
Iteration:   1540, Loss function: 3.734, Average Loss: 4.472, avg. samples / sec: 65597.10
Iteration:   1540, Loss function: 4.217, Average Loss: 4.484, avg. samples / sec: 65721.48
Iteration:   1540, Loss function: 4.655, Average Loss: 4.488, avg. samples / sec: 65756.72
Iteration:   1540, Loss function: 3.419, Average Loss: 4.463, avg. samples / sec: 65625.97
Iteration:   1540, Loss function: 4.253, Average Loss: 4.447, avg. samples / sec: 65669.73
Iteration:   1540, Loss function: 4.963, Average Loss: 4.473, avg. samples / sec: 65661.80
Iteration:   1540, Loss function: 4.758, Average Loss: 4.478, avg. samples / sec: 65656.02
Iteration:   1540, Loss function: 4.201, Average Loss: 4.476, avg. samples / sec: 65624.38
Iteration:   1540, Loss function: 4.613, Average Loss: 4.454, avg. samples / sec: 65644.12
Iteration:   1540, Loss function: 3.444, Average Loss: 4.475, avg. samples / sec: 65741.84
Iteration:   1540, Loss function: 4.531, Average Loss: 4.461, avg. samples / sec: 65694.77
Iteration:   1540, Loss function: 4.649, Average Loss: 4.460, avg. samples / sec: 65591.18
Iteration:   1540, Loss function: 4.278, Average Loss: 4.474, avg. samples / sec: 65608.37
Iteration:   1540, Loss function: 4.761, Average Loss: 4.457, avg. samples / sec: 65718.14
Iteration:   1540, Loss function: 4.640, Average Loss: 4.451, avg. samples / sec: 65611.45
Iteration:   1540, Loss function: 3.637, Average Loss: 4.482, avg. samples / sec: 65792.33
Iteration:   1540, Loss function: 3.764, Average Loss: 4.478, avg. samples / sec: 65740.83
Iteration:   1540, Loss function: 4.841, Average Loss: 4.459, avg. samples / sec: 65614.97
Iteration:   1540, Loss function: 4.209, Average Loss: 4.453, avg. samples / sec: 65569.69
Iteration:   1540, Loss function: 4.312, Average Loss: 4.477, avg. samples / sec: 65648.71
Iteration:   1540, Loss function: 5.321, Average Loss: 4.474, avg. samples / sec: 65654.83
Iteration:   1540, Loss function: 5.008, Average Loss: 4.487, avg. samples / sec: 65409.31
Iteration:   1540, Loss function: 4.588, Average Loss: 4.464, avg. samples / sec: 65547.80
Iteration:   1560, Loss function: 4.243, Average Loss: 4.470, avg. samples / sec: 66178.40
Iteration:   1560, Loss function: 5.412, Average Loss: 4.456, avg. samples / sec: 66330.99
Iteration:   1560, Loss function: 4.070, Average Loss: 4.405, avg. samples / sec: 66190.92
Iteration:   1560, Loss function: 4.447, Average Loss: 4.488, avg. samples / sec: 66209.21
Iteration:   1560, Loss function: 4.311, Average Loss: 4.461, avg. samples / sec: 66326.75
Iteration:   1560, Loss function: 3.766, Average Loss: 4.474, avg. samples / sec: 66286.63
Iteration:   1560, Loss function: 4.649, Average Loss: 4.475, avg. samples / sec: 66192.54
Iteration:   1560, Loss function: 4.629, Average Loss: 4.455, avg. samples / sec: 66247.71
Iteration:   1560, Loss function: 3.832, Average Loss: 4.486, avg. samples / sec: 66209.30
Iteration:   1560, Loss function: 4.732, Average Loss: 4.466, avg. samples / sec: 66069.84
Iteration:   1560, Loss function: 4.610, Average Loss: 4.459, avg. samples / sec: 66244.34
Iteration:   1560, Loss function: 4.480, Average Loss: 4.463, avg. samples / sec: 66238.52
Iteration:   1560, Loss function: 4.380, Average Loss: 4.461, avg. samples / sec: 66136.84
Iteration:   1560, Loss function: 3.474, Average Loss: 4.450, avg. samples / sec: 66231.52
Iteration:   1560, Loss function: 4.549, Average Loss: 4.492, avg. samples / sec: 66310.11
Iteration:   1560, Loss function: 4.837, Average Loss: 4.466, avg. samples / sec: 66343.08
Iteration:   1560, Loss function: 3.836, Average Loss: 4.447, avg. samples / sec: 66164.51
Iteration:   1560, Loss function: 4.217, Average Loss: 4.481, avg. samples / sec: 66188.25
Iteration:   1560, Loss function: 3.236, Average Loss: 4.473, avg. samples / sec: 66296.64
Iteration:   1560, Loss function: 4.193, Average Loss: 4.472, avg. samples / sec: 66191.42
Iteration:   1560, Loss function: 3.881, Average Loss: 4.432, avg. samples / sec: 65986.71
Iteration:   1560, Loss function: 4.408, Average Loss: 4.448, avg. samples / sec: 66162.08
Iteration:   1560, Loss function: 3.935, Average Loss: 4.461, avg. samples / sec: 66005.75
Iteration:   1560, Loss function: 4.257, Average Loss: 4.473, avg. samples / sec: 66056.92
Iteration:   1560, Loss function: 3.632, Average Loss: 4.476, avg. samples / sec: 66134.42
Iteration:   1560, Loss function: 2.871, Average Loss: 4.474, avg. samples / sec: 66104.30
Iteration:   1560, Loss function: 5.702, Average Loss: 4.476, avg. samples / sec: 66188.87
Iteration:   1560, Loss function: 3.573, Average Loss: 4.479, avg. samples / sec: 66136.93
Iteration:   1560, Loss function: 4.762, Average Loss: 4.472, avg. samples / sec: 66069.31
Iteration:   1560, Loss function: 5.301, Average Loss: 4.463, avg. samples / sec: 66019.29
Iteration:   1580, Loss function: 4.762, Average Loss: 4.459, avg. samples / sec: 66712.62
Iteration:   1580, Loss function: 4.712, Average Loss: 4.474, avg. samples / sec: 66638.65
Iteration:   1580, Loss function: 4.581, Average Loss: 4.470, avg. samples / sec: 66598.75
Iteration:   1580, Loss function: 3.372, Average Loss: 4.487, avg. samples / sec: 66636.25
Iteration:   1580, Loss function: 4.068, Average Loss: 4.475, avg. samples / sec: 66747.38
Iteration:   1580, Loss function: 3.694, Average Loss: 4.474, avg. samples / sec: 66716.48
Iteration:   1580, Loss function: 4.758, Average Loss: 4.488, avg. samples / sec: 66572.45
Iteration:   1580, Loss function: 3.567, Average Loss: 4.467, avg. samples / sec: 66574.08
Iteration:   1580, Loss function: 5.035, Average Loss: 4.493, avg. samples / sec: 66632.91
Iteration:   1580, Loss function: 4.441, Average Loss: 4.464, avg. samples / sec: 66601.08
Iteration:   1580, Loss function: 5.617, Average Loss: 4.404, avg. samples / sec: 66523.05
Iteration:   1580, Loss function: 4.350, Average Loss: 4.478, avg. samples / sec: 66690.05
Iteration:   1580, Loss function: 4.891, Average Loss: 4.435, avg. samples / sec: 66618.33
Iteration:   1580, Loss function: 4.746, Average Loss: 4.479, avg. samples / sec: 66598.81
Iteration:   1580, Loss function: 4.473, Average Loss: 4.447, avg. samples / sec: 66610.43
Iteration:   1580, Loss function: 4.498, Average Loss: 4.469, avg. samples / sec: 66587.92
Iteration:   1580, Loss function: 5.666, Average Loss: 4.466, avg. samples / sec: 66509.74
Iteration:   1580, Loss function: 3.713, Average Loss: 4.474, avg. samples / sec: 66719.16
Iteration:   1580, Loss function: 4.914, Average Loss: 4.449, avg. samples / sec: 66611.94
Iteration:   1580, Loss function: 4.742, Average Loss: 4.477, avg. samples / sec: 66565.85
Iteration:   1580, Loss function: 4.099, Average Loss: 4.460, avg. samples / sec: 66473.97
Iteration:   1580, Loss function: 5.389, Average Loss: 4.457, avg. samples / sec: 66520.13
Iteration:   1580, Loss function: 3.684, Average Loss: 4.461, avg. samples / sec: 66573.45
Iteration:   1580, Loss function: 5.445, Average Loss: 4.464, avg. samples / sec: 66408.60
Iteration:   1580, Loss function: 4.211, Average Loss: 4.477, avg. samples / sec: 66429.82
Iteration:   1580, Loss function: 4.535, Average Loss: 4.474, avg. samples / sec: 66404.60
Iteration:   1580, Loss function: 4.122, Average Loss: 4.478, avg. samples / sec: 66472.16
Iteration:   1580, Loss function: 4.293, Average Loss: 4.476, avg. samples / sec: 66558.99
Iteration:   1580, Loss function: 5.948, Average Loss: 4.477, avg. samples / sec: 66478.46
Iteration:   1580, Loss function: 4.535, Average Loss: 4.467, avg. samples / sec: 66587.17
Iteration:   1600, Loss function: 4.088, Average Loss: 4.473, avg. samples / sec: 66749.28
Iteration:   1600, Loss function: 3.751, Average Loss: 4.464, avg. samples / sec: 66709.05
Iteration:   1600, Loss function: 3.520, Average Loss: 4.441, avg. samples / sec: 66606.08
Iteration:   1600, Loss function: 4.139, Average Loss: 4.478, avg. samples / sec: 66572.45
Iteration:   1600, Loss function: 4.765, Average Loss: 4.458, avg. samples / sec: 66664.56
Iteration:   1600, Loss function: 4.014, Average Loss: 4.471, avg. samples / sec: 66557.80
Iteration:   1600, Loss function: 4.047, Average Loss: 4.491, avg. samples / sec: 66493.39
Iteration:   1600, Loss function: 3.500, Average Loss: 4.475, avg. samples / sec: 66565.97
Iteration:   1600, Loss function: 3.720, Average Loss: 4.479, avg. samples / sec: 66564.74
Iteration:   1600, Loss function: 4.059, Average Loss: 4.476, avg. samples / sec: 66684.81
Iteration:   1600, Loss function: 3.340, Average Loss: 4.463, avg. samples / sec: 66516.93
Iteration:   1600, Loss function: 4.172, Average Loss: 4.466, avg. samples / sec: 66477.05
Iteration:   1600, Loss function: 4.162, Average Loss: 4.470, avg. samples / sec: 66387.11
Iteration:   1600, Loss function: 4.838, Average Loss: 4.480, avg. samples / sec: 66633.73
Iteration:   1600, Loss function: 4.669, Average Loss: 4.406, avg. samples / sec: 66474.54
Iteration:   1600, Loss function: 4.457, Average Loss: 4.447, avg. samples / sec: 66483.35
Iteration:   1600, Loss function: 4.083, Average Loss: 4.486, avg. samples / sec: 66384.42
Iteration:   1600, Loss function: 4.789, Average Loss: 4.489, avg. samples / sec: 66441.19
Iteration:   1600, Loss function: 3.805, Average Loss: 4.471, avg. samples / sec: 66485.51
Iteration:   1600, Loss function: 3.472, Average Loss: 4.463, avg. samples / sec: 66545.54
Iteration:   1600, Loss function: 4.288, Average Loss: 4.461, avg. samples / sec: 66305.21
Iteration:   1600, Loss function: 5.289, Average Loss: 4.475, avg. samples / sec: 66607.59
Iteration:   1600, Loss function: 5.013, Average Loss: 4.471, avg. samples / sec: 66344.79
Iteration:   1600, Loss function: 3.338, Average Loss: 4.471, avg. samples / sec: 66386.02
Iteration:   1600, Loss function: 3.682, Average Loss: 4.453, avg. samples / sec: 66469.62
Iteration:   1600, Loss function: 5.718, Average Loss: 4.480, avg. samples / sec: 66428.89
Iteration:   1600, Loss function: 4.769, Average Loss: 4.463, avg. samples / sec: 66592.20
Iteration:   1600, Loss function: 4.907, Average Loss: 4.472, avg. samples / sec: 66328.90
Iteration:   1600, Loss function: 4.262, Average Loss: 4.459, avg. samples / sec: 66468.08
Iteration:   1600, Loss function: 3.722, Average Loss: 4.476, avg. samples / sec: 66525.06
:::MLL 1558651565.149 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558651565.149 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 4.063, Average Loss: 4.459, avg. samples / sec: 65979.85
Iteration:   1620, Loss function: 4.103, Average Loss: 4.460, avg. samples / sec: 65944.63
Iteration:   1620, Loss function: 3.802, Average Loss: 4.470, avg. samples / sec: 65905.92
Iteration:   1620, Loss function: 3.471, Average Loss: 4.448, avg. samples / sec: 65917.98
Iteration:   1620, Loss function: 3.416, Average Loss: 4.471, avg. samples / sec: 65932.50
Iteration:   1620, Loss function: 5.244, Average Loss: 4.463, avg. samples / sec: 65935.16
Iteration:   1620, Loss function: 4.653, Average Loss: 4.475, avg. samples / sec: 65833.48
Iteration:   1620, Loss function: 4.320, Average Loss: 4.478, avg. samples / sec: 65873.15
Iteration:   1620, Loss function: 5.077, Average Loss: 4.463, avg. samples / sec: 65990.14
Iteration:   1620, Loss function: 3.585, Average Loss: 4.484, avg. samples / sec: 65892.30
Iteration:   1620, Loss function: 5.583, Average Loss: 4.454, avg. samples / sec: 65779.52
Iteration:   1620, Loss function: 3.922, Average Loss: 4.461, avg. samples / sec: 65844.49
Iteration:   1620, Loss function: 6.058, Average Loss: 4.492, avg. samples / sec: 65813.44
Iteration:   1620, Loss function: 3.795, Average Loss: 4.474, avg. samples / sec: 65845.51
Iteration:   1620, Loss function: 3.643, Average Loss: 4.479, avg. samples / sec: 65846.15
Iteration:   1620, Loss function: 4.053, Average Loss: 4.467, avg. samples / sec: 65737.15
Iteration:   1620, Loss function: 4.153, Average Loss: 4.474, avg. samples / sec: 65744.14
Iteration:   1620, Loss function: 4.649, Average Loss: 4.461, avg. samples / sec: 65686.65
Iteration:   1620, Loss function: 3.871, Average Loss: 4.471, avg. samples / sec: 65861.39
Iteration:   1620, Loss function: 4.684, Average Loss: 4.472, avg. samples / sec: 65820.84
Iteration:   1620, Loss function: 5.791, Average Loss: 4.472, avg. samples / sec: 65879.37
Iteration:   1620, Loss function: 3.863, Average Loss: 4.410, avg. samples / sec: 65797.30
Iteration:   1620, Loss function: 4.071, Average Loss: 4.443, avg. samples / sec: 65675.51
Iteration:   1620, Loss function: 3.684, Average Loss: 4.475, avg. samples / sec: 65631.68
Iteration:   1620, Loss function: 5.152, Average Loss: 4.478, avg. samples / sec: 65850.55
Iteration:   1620, Loss function: 3.385, Average Loss: 4.487, avg. samples / sec: 65752.88
Iteration:   1620, Loss function: 4.988, Average Loss: 4.474, avg. samples / sec: 65721.51
Iteration:   1620, Loss function: 3.345, Average Loss: 4.453, avg. samples / sec: 65775.78
Iteration:   1620, Loss function: 3.121, Average Loss: 4.463, avg. samples / sec: 65826.32
Iteration:   1620, Loss function: 4.285, Average Loss: 4.467, avg. samples / sec: 65729.94
Iteration:   1640, Loss function: 3.605, Average Loss: 4.469, avg. samples / sec: 66374.23
Iteration:   1640, Loss function: 5.698, Average Loss: 4.470, avg. samples / sec: 66415.30
Iteration:   1640, Loss function: 4.684, Average Loss: 4.472, avg. samples / sec: 66309.83
Iteration:   1640, Loss function: 4.720, Average Loss: 4.469, avg. samples / sec: 66480.94
Iteration:   1640, Loss function: 5.871, Average Loss: 4.413, avg. samples / sec: 66377.76
Iteration:   1640, Loss function: 4.612, Average Loss: 4.446, avg. samples / sec: 66402.53
Iteration:   1640, Loss function: 4.911, Average Loss: 4.465, avg. samples / sec: 66359.35
Iteration:   1640, Loss function: 5.505, Average Loss: 4.469, avg. samples / sec: 66375.85
Iteration:   1640, Loss function: 4.335, Average Loss: 4.459, avg. samples / sec: 66149.54
Iteration:   1640, Loss function: 3.712, Average Loss: 4.466, avg. samples / sec: 66274.00
Iteration:   1640, Loss function: 3.635, Average Loss: 4.460, avg. samples / sec: 66194.78
Iteration:   1640, Loss function: 6.173, Average Loss: 4.447, avg. samples / sec: 66215.43
Iteration:   1640, Loss function: 4.561, Average Loss: 4.478, avg. samples / sec: 66301.16
Iteration:   1640, Loss function: 5.060, Average Loss: 4.471, avg. samples / sec: 66329.87
Iteration:   1640, Loss function: 4.718, Average Loss: 4.469, avg. samples / sec: 66323.78
Iteration:   1640, Loss function: 4.561, Average Loss: 4.476, avg. samples / sec: 66196.70
Iteration:   1640, Loss function: 4.764, Average Loss: 4.454, avg. samples / sec: 66219.35
Iteration:   1640, Loss function: 3.353, Average Loss: 4.461, avg. samples / sec: 66198.45
Iteration:   1640, Loss function: 3.847, Average Loss: 4.492, avg. samples / sec: 66232.05
Iteration:   1640, Loss function: 3.952, Average Loss: 4.470, avg. samples / sec: 66280.52
Iteration:   1640, Loss function: 3.105, Average Loss: 4.463, avg. samples / sec: 66336.58
Iteration:   1640, Loss function: 4.029, Average Loss: 4.472, avg. samples / sec: 66157.95
Iteration:   1640, Loss function: 4.150, Average Loss: 4.483, avg. samples / sec: 66173.83
Iteration:   1640, Loss function: 3.619, Average Loss: 4.482, avg. samples / sec: 66317.48
Iteration:   1640, Loss function: 3.279, Average Loss: 4.465, avg. samples / sec: 66343.17
Iteration:   1640, Loss function: 3.528, Average Loss: 4.456, avg. samples / sec: 66318.41
Iteration:   1640, Loss function: 4.234, Average Loss: 4.477, avg. samples / sec: 66188.09
Iteration:   1640, Loss function: 4.310, Average Loss: 4.466, avg. samples / sec: 66089.08
Iteration:   1640, Loss function: 4.097, Average Loss: 4.475, avg. samples / sec: 66230.86
Iteration:   1640, Loss function: 3.610, Average Loss: 4.474, avg. samples / sec: 66044.85
Iteration:   1660, Loss function: 3.866, Average Loss: 4.494, avg. samples / sec: 66707.35
Iteration:   1660, Loss function: 4.434, Average Loss: 4.470, avg. samples / sec: 66551.20
Iteration:   1660, Loss function: 5.129, Average Loss: 4.470, avg. samples / sec: 66500.64
Iteration:   1660, Loss function: 4.418, Average Loss: 4.479, avg. samples / sec: 66675.06
Iteration:   1660, Loss function: 4.226, Average Loss: 4.469, avg. samples / sec: 66554.69
Iteration:   1660, Loss function: 4.029, Average Loss: 4.469, avg. samples / sec: 66603.34
Iteration:   1660, Loss function: 4.034, Average Loss: 4.409, avg. samples / sec: 66539.54
Iteration:   1660, Loss function: 3.765, Average Loss: 4.461, avg. samples / sec: 66566.88
Iteration:   1660, Loss function: 5.475, Average Loss: 4.486, avg. samples / sec: 66540.01
Iteration:   1660, Loss function: 4.603, Average Loss: 4.470, avg. samples / sec: 66520.38
Iteration:   1660, Loss function: 3.512, Average Loss: 4.441, avg. samples / sec: 66490.82
Iteration:   1660, Loss function: 5.344, Average Loss: 4.471, avg. samples / sec: 66600.51
Iteration:   1660, Loss function: 4.825, Average Loss: 4.480, avg. samples / sec: 66597.08
Iteration:   1660, Loss function: 2.820, Average Loss: 4.471, avg. samples / sec: 66425.54
Iteration:   1660, Loss function: 5.541, Average Loss: 4.472, avg. samples / sec: 66493.51
Iteration:   1660, Loss function: 4.669, Average Loss: 4.464, avg. samples / sec: 66549.47
Iteration:   1660, Loss function: 4.904, Average Loss: 4.466, avg. samples / sec: 66532.22
Iteration:   1660, Loss function: 3.044, Average Loss: 4.469, avg. samples / sec: 66480.18
Iteration:   1660, Loss function: 4.317, Average Loss: 4.449, avg. samples / sec: 66450.72
Iteration:   1660, Loss function: 4.340, Average Loss: 4.474, avg. samples / sec: 66608.73
Iteration:   1660, Loss function: 5.229, Average Loss: 4.468, avg. samples / sec: 66574.65
Iteration:   1660, Loss function: 3.562, Average Loss: 4.475, avg. samples / sec: 66284.94
Iteration:   1660, Loss function: 4.728, Average Loss: 4.474, avg. samples / sec: 66481.94
Iteration:   1660, Loss function: 4.033, Average Loss: 4.462, avg. samples / sec: 66466.76
Iteration:   1660, Loss function: 3.686, Average Loss: 4.479, avg. samples / sec: 66667.59
Iteration:   1660, Loss function: 3.464, Average Loss: 4.459, avg. samples / sec: 66418.08
Iteration:   1660, Loss function: 3.715, Average Loss: 4.456, avg. samples / sec: 66510.87
Iteration:   1660, Loss function: 5.150, Average Loss: 4.474, avg. samples / sec: 66485.30
Iteration:   1660, Loss function: 4.605, Average Loss: 4.480, avg. samples / sec: 66533.88
Iteration:   1660, Loss function: 4.148, Average Loss: 4.484, avg. samples / sec: 66419.81
:::MLL 1558651566.922 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558651566.923 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 4.071, Average Loss: 4.466, avg. samples / sec: 66383.98
Iteration:   1680, Loss function: 2.637, Average Loss: 4.474, avg. samples / sec: 66470.74
Iteration:   1680, Loss function: 5.038, Average Loss: 4.466, avg. samples / sec: 66541.27
Iteration:   1680, Loss function: 4.410, Average Loss: 4.438, avg. samples / sec: 66435.74
Iteration:   1680, Loss function: 3.546, Average Loss: 4.472, avg. samples / sec: 66359.16
Iteration:   1680, Loss function: 5.018, Average Loss: 4.473, avg. samples / sec: 66512.31
Iteration:   1680, Loss function: 5.502, Average Loss: 4.465, avg. samples / sec: 66457.49
Iteration:   1680, Loss function: 4.051, Average Loss: 4.494, avg. samples / sec: 66255.21
Iteration:   1680, Loss function: 2.984, Average Loss: 4.456, avg. samples / sec: 66309.99
Iteration:   1680, Loss function: 3.429, Average Loss: 4.455, avg. samples / sec: 66465.26
Iteration:   1680, Loss function: 4.765, Average Loss: 4.457, avg. samples / sec: 66463.60
Iteration:   1680, Loss function: 4.625, Average Loss: 4.465, avg. samples / sec: 66404.53
Iteration:   1680, Loss function: 4.473, Average Loss: 4.469, avg. samples / sec: 66219.54
Iteration:   1680, Loss function: 5.492, Average Loss: 4.406, avg. samples / sec: 66271.13
Iteration:   1680, Loss function: 3.791, Average Loss: 4.471, avg. samples / sec: 66368.91
Iteration:   1680, Loss function: 3.626, Average Loss: 4.461, avg. samples / sec: 66308.55
Iteration:   1680, Loss function: 4.638, Average Loss: 4.475, avg. samples / sec: 66406.97
Iteration:   1680, Loss function: 3.823, Average Loss: 4.464, avg. samples / sec: 66374.35
Iteration:   1680, Loss function: 5.979, Average Loss: 4.456, avg. samples / sec: 66407.91
Iteration:   1680, Loss function: 4.073, Average Loss: 4.464, avg. samples / sec: 66221.71
Iteration:   1680, Loss function: 4.022, Average Loss: 4.483, avg. samples / sec: 66240.48
Iteration:   1680, Loss function: 3.833, Average Loss: 4.466, avg. samples / sec: 66253.72
Iteration:   1680, Loss function: 4.608, Average Loss: 4.469, avg. samples / sec: 66345.14
Iteration:   1680, Loss function: 4.732, Average Loss: 4.474, avg. samples / sec: 66312.36
Iteration:   1680, Loss function: 3.602, Average Loss: 4.483, avg. samples / sec: 66332.49
Iteration:   1680, Loss function: 4.550, Average Loss: 4.481, avg. samples / sec: 66362.10
Iteration:   1680, Loss function: 3.721, Average Loss: 4.469, avg. samples / sec: 66218.85
Iteration:   1680, Loss function: 5.686, Average Loss: 4.469, avg. samples / sec: 66109.60
Iteration:   1680, Loss function: 4.125, Average Loss: 4.450, avg. samples / sec: 66236.72
Iteration:   1680, Loss function: 4.241, Average Loss: 4.477, avg. samples / sec: 66213.81
Iteration:   1700, Loss function: 4.041, Average Loss: 4.452, avg. samples / sec: 65702.58
Iteration:   1700, Loss function: 3.573, Average Loss: 4.434, avg. samples / sec: 65602.26
Iteration:   1700, Loss function: 4.755, Average Loss: 4.470, avg. samples / sec: 65575.61
Iteration:   1700, Loss function: 3.908, Average Loss: 4.468, avg. samples / sec: 65823.18
Iteration:   1700, Loss function: 3.648, Average Loss: 4.465, avg. samples / sec: 65543.47
Iteration:   1700, Loss function: 3.250, Average Loss: 4.472, avg. samples / sec: 65637.64
Iteration:   1700, Loss function: 3.515, Average Loss: 4.457, avg. samples / sec: 65668.41
Iteration:   1700, Loss function: 3.624, Average Loss: 4.467, avg. samples / sec: 65551.15
Iteration:   1700, Loss function: 4.730, Average Loss: 4.471, avg. samples / sec: 65645.90
Iteration:   1700, Loss function: 4.350, Average Loss: 4.459, avg. samples / sec: 65685.43
Iteration:   1700, Loss function: 4.007, Average Loss: 4.472, avg. samples / sec: 65649.78
Iteration:   1700, Loss function: 3.402, Average Loss: 4.403, avg. samples / sec: 65626.18
Iteration:   1700, Loss function: 4.728, Average Loss: 4.452, avg. samples / sec: 65585.96
Iteration:   1700, Loss function: 4.265, Average Loss: 4.468, avg. samples / sec: 65523.99
Iteration:   1700, Loss function: 4.744, Average Loss: 4.445, avg. samples / sec: 65792.36
Iteration:   1700, Loss function: 4.265, Average Loss: 4.455, avg. samples / sec: 65579.52
Iteration:   1700, Loss function: 5.603, Average Loss: 4.482, avg. samples / sec: 65680.59
Iteration:   1700, Loss function: 4.872, Average Loss: 4.483, avg. samples / sec: 65699.88
Iteration:   1700, Loss function: 4.521, Average Loss: 4.495, avg. samples / sec: 65517.29
Iteration:   1700, Loss function: 4.912, Average Loss: 4.471, avg. samples / sec: 65666.39
Iteration:   1700, Loss function: 3.872, Average Loss: 4.462, avg. samples / sec: 65553.92
Iteration:   1700, Loss function: 3.900, Average Loss: 4.474, avg. samples / sec: 65783.58
Iteration:   1700, Loss function: 5.307, Average Loss: 4.465, avg. samples / sec: 65475.17
Iteration:   1700, Loss function: 5.422, Average Loss: 4.468, avg. samples / sec: 65426.65
Iteration:   1700, Loss function: 5.032, Average Loss: 4.466, avg. samples / sec: 65691.95
Iteration:   1700, Loss function: 5.237, Average Loss: 4.478, avg. samples / sec: 65669.12
Iteration:   1700, Loss function: 3.974, Average Loss: 4.480, avg. samples / sec: 65644.58
Iteration:   1700, Loss function: 4.684, Average Loss: 4.466, avg. samples / sec: 65537.16
Iteration:   1700, Loss function: 4.820, Average Loss: 4.452, avg. samples / sec: 65526.83
Iteration:   1700, Loss function: 3.973, Average Loss: 4.465, avg. samples / sec: 65576.41
Iteration:   1720, Loss function: 4.442, Average Loss: 4.452, avg. samples / sec: 66631.72
Iteration:   1720, Loss function: 4.101, Average Loss: 4.471, avg. samples / sec: 66625.76
Iteration:   1720, Loss function: 4.099, Average Loss: 4.473, avg. samples / sec: 66615.31
Iteration:   1720, Loss function: 6.442, Average Loss: 4.462, avg. samples / sec: 66580.66
Iteration:   1720, Loss function: 3.804, Average Loss: 4.470, avg. samples / sec: 66527.73
Iteration:   1720, Loss function: 3.628, Average Loss: 4.468, avg. samples / sec: 66673.96
Iteration:   1720, Loss function: 4.056, Average Loss: 4.457, avg. samples / sec: 66580.78
Iteration:   1720, Loss function: 3.839, Average Loss: 4.466, avg. samples / sec: 66538.88
Iteration:   1720, Loss function: 3.367, Average Loss: 4.452, avg. samples / sec: 66498.31
Iteration:   1720, Loss function: 4.986, Average Loss: 4.474, avg. samples / sec: 66600.01
Iteration:   1720, Loss function: 3.191, Average Loss: 4.431, avg. samples / sec: 66480.40
Iteration:   1720, Loss function: 3.410, Average Loss: 4.457, avg. samples / sec: 66691.03
Iteration:   1720, Loss function: 4.884, Average Loss: 4.465, avg. samples / sec: 66613.45
Iteration:   1720, Loss function: 5.077, Average Loss: 4.471, avg. samples / sec: 66535.61
Iteration:   1720, Loss function: 4.583, Average Loss: 4.455, avg. samples / sec: 66562.67
Iteration:   1720, Loss function: 4.296, Average Loss: 4.456, avg. samples / sec: 66587.74
Iteration:   1720, Loss function: 4.025, Average Loss: 4.453, avg. samples / sec: 66534.14
Iteration:   1720, Loss function: 4.353, Average Loss: 4.495, avg. samples / sec: 66576.10
Iteration:   1720, Loss function: 4.874, Average Loss: 4.405, avg. samples / sec: 66536.43
Iteration:   1720, Loss function: 4.966, Average Loss: 4.446, avg. samples / sec: 66528.45
Iteration:   1720, Loss function: 5.037, Average Loss: 4.470, avg. samples / sec: 66499.73
Iteration:   1720, Loss function: 4.272, Average Loss: 4.461, avg. samples / sec: 66610.11
Iteration:   1720, Loss function: 3.949, Average Loss: 4.476, avg. samples / sec: 66540.95
Iteration:   1720, Loss function: 3.812, Average Loss: 4.481, avg. samples / sec: 66523.33
Iteration:   1720, Loss function: 4.462, Average Loss: 4.465, avg. samples / sec: 66546.70
Iteration:   1720, Loss function: 4.034, Average Loss: 4.470, avg. samples / sec: 66532.79
Iteration:   1720, Loss function: 3.918, Average Loss: 4.446, avg. samples / sec: 66591.79
Iteration:   1720, Loss function: 3.714, Average Loss: 4.472, avg. samples / sec: 66532.22
Iteration:   1720, Loss function: 4.594, Average Loss: 4.476, avg. samples / sec: 66426.07
Iteration:   1720, Loss function: 4.835, Average Loss: 4.479, avg. samples / sec: 66348.20
Iteration:   1740, Loss function: 4.804, Average Loss: 4.463, avg. samples / sec: 66524.31
Iteration:   1740, Loss function: 4.736, Average Loss: 4.470, avg. samples / sec: 66487.84
Iteration:   1740, Loss function: 5.429, Average Loss: 4.475, avg. samples / sec: 66496.49
Iteration:   1740, Loss function: 4.809, Average Loss: 4.468, avg. samples / sec: 66477.11
Iteration:   1740, Loss function: 4.852, Average Loss: 4.475, avg. samples / sec: 66722.13
Iteration:   1740, Loss function: 5.503, Average Loss: 4.456, avg. samples / sec: 66534.39
Iteration:   1740, Loss function: 5.081, Average Loss: 4.466, avg. samples / sec: 66452.22
Iteration:   1740, Loss function: 5.782, Average Loss: 4.455, avg. samples / sec: 66518.43
Iteration:   1740, Loss function: 4.964, Average Loss: 4.449, avg. samples / sec: 66424.28
Iteration:   1740, Loss function: 2.729, Average Loss: 4.471, avg. samples / sec: 66576.00
Iteration:   1740, Loss function: 3.883, Average Loss: 4.432, avg. samples / sec: 66438.78
Iteration:   1740, Loss function: 4.217, Average Loss: 4.489, avg. samples / sec: 66482.69
Iteration:   1740, Loss function: 4.363, Average Loss: 4.455, avg. samples / sec: 66458.49
Iteration:   1740, Loss function: 3.867, Average Loss: 4.452, avg. samples / sec: 66478.80
Iteration:   1740, Loss function: 5.083, Average Loss: 4.483, avg. samples / sec: 66515.77
Iteration:   1740, Loss function: 4.874, Average Loss: 4.447, avg. samples / sec: 66538.50
Iteration:   1740, Loss function: 5.504, Average Loss: 4.456, avg. samples / sec: 66342.04
Iteration:   1740, Loss function: 4.148, Average Loss: 4.475, avg. samples / sec: 66477.99
Iteration:   1740, Loss function: 5.089, Average Loss: 4.456, avg. samples / sec: 66479.56
Iteration:   1740, Loss function: 4.771, Average Loss: 4.455, avg. samples / sec: 66444.80
Iteration:   1740, Loss function: 5.976, Average Loss: 4.479, avg. samples / sec: 66380.23
Iteration:   1740, Loss function: 4.055, Average Loss: 4.462, avg. samples / sec: 66402.47
Iteration:   1740, Loss function: 3.557, Average Loss: 4.468, avg. samples / sec: 66311.83
Iteration:   1740, Loss function: 4.991, Average Loss: 4.455, avg. samples / sec: 66325.34
Iteration:   1740, Loss function: 6.367, Average Loss: 4.476, avg. samples / sec: 66351.32
Iteration:   1740, Loss function: 7.170, Average Loss: 4.472, avg. samples / sec: 66461.18
Iteration:   1740, Loss function: 3.858, Average Loss: 4.465, avg. samples / sec: 66404.00
Iteration:   1740, Loss function: 4.628, Average Loss: 4.476, avg. samples / sec: 66523.71
Iteration:   1740, Loss function: 4.993, Average Loss: 4.467, avg. samples / sec: 66372.95
Iteration:   1740, Loss function: 4.439, Average Loss: 4.403, avg. samples / sec: 66263.22
:::MLL 1558651568.699 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558651568.699 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 4.936, Average Loss: 4.453, avg. samples / sec: 66382.51
Iteration:   1760, Loss function: 4.299, Average Loss: 4.449, avg. samples / sec: 66505.34
Iteration:   1760, Loss function: 4.558, Average Loss: 4.464, avg. samples / sec: 66535.71
Iteration:   1760, Loss function: 5.311, Average Loss: 4.461, avg. samples / sec: 66328.46
Iteration:   1760, Loss function: 3.142, Average Loss: 4.470, avg. samples / sec: 66355.45
Iteration:   1760, Loss function: 4.212, Average Loss: 4.453, avg. samples / sec: 66317.57
Iteration:   1760, Loss function: 3.758, Average Loss: 4.469, avg. samples / sec: 66225.60
Iteration:   1760, Loss function: 5.040, Average Loss: 4.431, avg. samples / sec: 66350.17
Iteration:   1760, Loss function: 3.194, Average Loss: 4.463, avg. samples / sec: 66188.71
Iteration:   1760, Loss function: 5.420, Average Loss: 4.459, avg. samples / sec: 66356.32
Iteration:   1760, Loss function: 4.439, Average Loss: 4.452, avg. samples / sec: 66310.55
Iteration:   1760, Loss function: 4.354, Average Loss: 4.445, avg. samples / sec: 66336.24
Iteration:   1760, Loss function: 3.364, Average Loss: 4.474, avg. samples / sec: 66356.66
Iteration:   1760, Loss function: 4.668, Average Loss: 4.468, avg. samples / sec: 66271.66
Iteration:   1760, Loss function: 4.900, Average Loss: 4.474, avg. samples / sec: 66394.18
Iteration:   1760, Loss function: 4.060, Average Loss: 4.476, avg. samples / sec: 66293.98
Iteration:   1760, Loss function: 4.144, Average Loss: 4.462, avg. samples / sec: 66337.45
Iteration:   1760, Loss function: 3.506, Average Loss: 4.458, avg. samples / sec: 66285.85
Iteration:   1760, Loss function: 4.517, Average Loss: 4.452, avg. samples / sec: 66299.16
Iteration:   1760, Loss function: 4.855, Average Loss: 4.494, avg. samples / sec: 66279.92
Iteration:   1760, Loss function: 4.970, Average Loss: 4.459, avg. samples / sec: 66359.38
Iteration:   1760, Loss function: 5.147, Average Loss: 4.465, avg. samples / sec: 66385.80
Iteration:   1760, Loss function: 3.724, Average Loss: 4.456, avg. samples / sec: 66298.88
Iteration:   1760, Loss function: 3.706, Average Loss: 4.471, avg. samples / sec: 66333.49
Iteration:   1760, Loss function: 4.509, Average Loss: 4.464, avg. samples / sec: 66141.16
Iteration:   1760, Loss function: 5.742, Average Loss: 4.455, avg. samples / sec: 66178.55
Iteration:   1760, Loss function: 4.817, Average Loss: 4.466, avg. samples / sec: 66033.99
Iteration:   1760, Loss function: 4.174, Average Loss: 4.404, avg. samples / sec: 66349.82
Iteration:   1760, Loss function: 5.685, Average Loss: 4.472, avg. samples / sec: 66244.62
Iteration:   1760, Loss function: 4.006, Average Loss: 4.472, avg. samples / sec: 66143.52
Iteration:   1780, Loss function: 3.869, Average Loss: 4.447, avg. samples / sec: 66590.22
Iteration:   1780, Loss function: 3.537, Average Loss: 4.455, avg. samples / sec: 66633.01
Iteration:   1780, Loss function: 4.609, Average Loss: 4.469, avg. samples / sec: 66577.17
Iteration:   1780, Loss function: 5.381, Average Loss: 4.450, avg. samples / sec: 66521.29
Iteration:   1780, Loss function: 4.912, Average Loss: 4.457, avg. samples / sec: 66475.76
Iteration:   1780, Loss function: 3.883, Average Loss: 4.467, avg. samples / sec: 66458.49
Iteration:   1780, Loss function: 4.540, Average Loss: 4.468, avg. samples / sec: 66636.60
Iteration:   1780, Loss function: 3.542, Average Loss: 4.457, avg. samples / sec: 66537.91
Iteration:   1780, Loss function: 3.867, Average Loss: 4.431, avg. samples / sec: 66487.33
Iteration:   1780, Loss function: 4.376, Average Loss: 4.459, avg. samples / sec: 66543.91
Iteration:   1780, Loss function: 4.823, Average Loss: 4.466, avg. samples / sec: 66463.79
Iteration:   1780, Loss function: 4.855, Average Loss: 4.490, avg. samples / sec: 66524.27
Iteration:   1780, Loss function: 3.264, Average Loss: 4.451, avg. samples / sec: 66527.79
Iteration:   1780, Loss function: 5.409, Average Loss: 4.445, avg. samples / sec: 66501.70
Iteration:   1780, Loss function: 4.109, Average Loss: 4.473, avg. samples / sec: 66532.03
Iteration:   1780, Loss function: 3.649, Average Loss: 4.450, avg. samples / sec: 66594.88
Iteration:   1780, Loss function: 3.869, Average Loss: 4.445, avg. samples / sec: 66372.35
Iteration:   1780, Loss function: 3.907, Average Loss: 4.461, avg. samples / sec: 66370.91
Iteration:   1780, Loss function: 4.801, Average Loss: 4.468, avg. samples / sec: 66605.14
Iteration:   1780, Loss function: 4.822, Average Loss: 4.404, avg. samples / sec: 66618.74
Iteration:   1780, Loss function: 3.181, Average Loss: 4.455, avg. samples / sec: 66415.99
Iteration:   1780, Loss function: 4.251, Average Loss: 4.466, avg. samples / sec: 66558.55
Iteration:   1780, Loss function: 3.420, Average Loss: 4.473, avg. samples / sec: 66481.03
Iteration:   1780, Loss function: 4.141, Average Loss: 4.472, avg. samples / sec: 66647.28
Iteration:   1780, Loss function: 4.525, Average Loss: 4.464, avg. samples / sec: 66475.82
Iteration:   1780, Loss function: 3.854, Average Loss: 4.458, avg. samples / sec: 66444.26
Iteration:   1780, Loss function: 5.213, Average Loss: 4.472, avg. samples / sec: 66422.03
Iteration:   1780, Loss function: 5.121, Average Loss: 4.451, avg. samples / sec: 66471.28
Iteration:   1780, Loss function: 3.356, Average Loss: 4.442, avg. samples / sec: 66276.28
Iteration:   1780, Loss function: 4.426, Average Loss: 4.470, avg. samples / sec: 66544.41
Iteration:   1800, Loss function: 4.439, Average Loss: 4.459, avg. samples / sec: 66326.59
Iteration:   1800, Loss function: 3.813, Average Loss: 4.467, avg. samples / sec: 66243.35
Iteration:   1800, Loss function: 4.925, Average Loss: 4.462, avg. samples / sec: 66393.11
Iteration:   1800, Loss function: 3.341, Average Loss: 4.489, avg. samples / sec: 66327.74
Iteration:   1800, Loss function: 4.421, Average Loss: 4.442, avg. samples / sec: 66335.33
Iteration:   1800, Loss function: 4.194, Average Loss: 4.444, avg. samples / sec: 66335.02
Iteration:   1800, Loss function: 4.202, Average Loss: 4.397, avg. samples / sec: 66339.83
Iteration:   1800, Loss function: 4.367, Average Loss: 4.452, avg. samples / sec: 66223.36
Iteration:   1800, Loss function: 4.182, Average Loss: 4.476, avg. samples / sec: 66327.59
Iteration:   1800, Loss function: 5.459, Average Loss: 4.447, avg. samples / sec: 66162.15
Iteration:   1800, Loss function: 4.077, Average Loss: 4.439, avg. samples / sec: 66356.16
Iteration:   1800, Loss function: 5.102, Average Loss: 4.461, avg. samples / sec: 66330.62
Iteration:   1800, Loss function: 4.464, Average Loss: 4.450, avg. samples / sec: 66173.18
Iteration:   1800, Loss function: 4.035, Average Loss: 4.459, avg. samples / sec: 66147.12
Iteration:   1800, Loss function: 4.337, Average Loss: 4.429, avg. samples / sec: 66204.23
Iteration:   1800, Loss function: 4.572, Average Loss: 4.454, avg. samples / sec: 66318.19
Iteration:   1800, Loss function: 4.083, Average Loss: 4.468, avg. samples / sec: 66267.86
Iteration:   1800, Loss function: 4.810, Average Loss: 4.448, avg. samples / sec: 66285.85
Iteration:   1800, Loss function: 3.185, Average Loss: 4.464, avg. samples / sec: 66279.46
Iteration:   1800, Loss function: 4.604, Average Loss: 4.468, avg. samples / sec: 66160.19
Iteration:   1800, Loss function: 3.861, Average Loss: 4.447, avg. samples / sec: 66306.21
Iteration:   1800, Loss function: 4.504, Average Loss: 4.450, avg. samples / sec: 66195.71
Iteration:   1800, Loss function: 4.165, Average Loss: 4.439, avg. samples / sec: 66189.21
Iteration:   1800, Loss function: 4.025, Average Loss: 4.458, avg. samples / sec: 66161.77
Iteration:   1800, Loss function: 3.790, Average Loss: 4.460, avg. samples / sec: 66217.30
Iteration:   1800, Loss function: 4.020, Average Loss: 4.459, avg. samples / sec: 66127.69
Iteration:   1800, Loss function: 3.462, Average Loss: 4.473, avg. samples / sec: 66249.51
Iteration:   1800, Loss function: 3.975, Average Loss: 4.452, avg. samples / sec: 66068.54
Iteration:   1800, Loss function: 3.692, Average Loss: 4.469, avg. samples / sec: 66139.26
Iteration:   1800, Loss function: 3.155, Average Loss: 4.471, avg. samples / sec: 66274.25
:::MLL 1558651570.471 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558651570.472 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 3.976, Average Loss: 4.433, avg. samples / sec: 66378.70
Iteration:   1820, Loss function: 5.047, Average Loss: 4.487, avg. samples / sec: 66292.33
Iteration:   1820, Loss function: 4.902, Average Loss: 4.426, avg. samples / sec: 66366.54
Iteration:   1820, Loss function: 3.823, Average Loss: 4.458, avg. samples / sec: 66418.74
Iteration:   1820, Loss function: 4.105, Average Loss: 4.448, avg. samples / sec: 66306.40
Iteration:   1820, Loss function: 5.103, Average Loss: 4.469, avg. samples / sec: 66427.44
Iteration:   1820, Loss function: 3.691, Average Loss: 4.466, avg. samples / sec: 66351.85
Iteration:   1820, Loss function: 4.120, Average Loss: 4.467, avg. samples / sec: 66245.90
Iteration:   1820, Loss function: 4.215, Average Loss: 4.447, avg. samples / sec: 66311.39
Iteration:   1820, Loss function: 3.590, Average Loss: 4.455, avg. samples / sec: 66295.26
Iteration:   1820, Loss function: 4.974, Average Loss: 4.446, avg. samples / sec: 66259.64
Iteration:   1820, Loss function: 5.621, Average Loss: 4.461, avg. samples / sec: 66272.85
Iteration:   1820, Loss function: 4.924, Average Loss: 4.453, avg. samples / sec: 66354.98
Iteration:   1820, Loss function: 5.255, Average Loss: 4.450, avg. samples / sec: 66293.21
Iteration:   1820, Loss function: 4.871, Average Loss: 4.455, avg. samples / sec: 66171.68
Iteration:   1820, Loss function: 4.354, Average Loss: 4.448, avg. samples / sec: 66298.63
Iteration:   1820, Loss function: 4.842, Average Loss: 4.469, avg. samples / sec: 66214.09
Iteration:   1820, Loss function: 4.508, Average Loss: 4.460, avg. samples / sec: 66300.63
Iteration:   1820, Loss function: 3.978, Average Loss: 4.447, avg. samples / sec: 66234.10
Iteration:   1820, Loss function: 3.920, Average Loss: 4.437, avg. samples / sec: 66280.17
Iteration:   1820, Loss function: 4.605, Average Loss: 4.441, avg. samples / sec: 66138.86
Iteration:   1820, Loss function: 5.102, Average Loss: 4.474, avg. samples / sec: 66294.86
Iteration:   1820, Loss function: 3.809, Average Loss: 4.451, avg. samples / sec: 66205.97
Iteration:   1820, Loss function: 4.020, Average Loss: 4.460, avg. samples / sec: 66214.00
Iteration:   1820, Loss function: 4.115, Average Loss: 4.469, avg. samples / sec: 66272.35
Iteration:   1820, Loss function: 2.720, Average Loss: 4.439, avg. samples / sec: 66098.47
Iteration:   1820, Loss function: 4.355, Average Loss: 4.461, avg. samples / sec: 66233.82
Iteration:   1820, Loss function: 4.790, Average Loss: 4.402, avg. samples / sec: 66114.75
Iteration:   1820, Loss function: 3.704, Average Loss: 4.461, avg. samples / sec: 66166.31
Iteration:   1820, Loss function: 4.845, Average Loss: 4.462, avg. samples / sec: 66025.76
Iteration:   1840, Loss function: 4.941, Average Loss: 4.446, avg. samples / sec: 66314.45
Iteration:   1840, Loss function: 4.673, Average Loss: 4.445, avg. samples / sec: 66387.80
Iteration:   1840, Loss function: 4.525, Average Loss: 4.467, avg. samples / sec: 66279.49
Iteration:   1840, Loss function: 5.544, Average Loss: 4.456, avg. samples / sec: 66411.07
Iteration:   1840, Loss function: 4.188, Average Loss: 4.442, avg. samples / sec: 66416.08
Iteration:   1840, Loss function: 3.754, Average Loss: 4.425, avg. samples / sec: 66238.58
Iteration:   1840, Loss function: 4.571, Average Loss: 4.464, avg. samples / sec: 66404.91
Iteration:   1840, Loss function: 3.905, Average Loss: 4.458, avg. samples / sec: 66305.77
Iteration:   1840, Loss function: 4.860, Average Loss: 4.448, avg. samples / sec: 66268.42
Iteration:   1840, Loss function: 4.591, Average Loss: 4.444, avg. samples / sec: 66253.16
Iteration:   1840, Loss function: 3.595, Average Loss: 4.482, avg. samples / sec: 66176.19
Iteration:   1840, Loss function: 3.137, Average Loss: 4.461, avg. samples / sec: 66455.07
Iteration:   1840, Loss function: 3.530, Average Loss: 4.460, avg. samples / sec: 66243.72
Iteration:   1840, Loss function: 3.833, Average Loss: 4.400, avg. samples / sec: 66373.82
Iteration:   1840, Loss function: 4.772, Average Loss: 4.452, avg. samples / sec: 66260.01
Iteration:   1840, Loss function: 3.767, Average Loss: 4.445, avg. samples / sec: 66340.95
Iteration:   1840, Loss function: 5.189, Average Loss: 4.469, avg. samples / sec: 66158.20
Iteration:   1840, Loss function: 3.984, Average Loss: 4.449, avg. samples / sec: 66192.73
Iteration:   1840, Loss function: 4.128, Average Loss: 4.448, avg. samples / sec: 66231.67
Iteration:   1840, Loss function: 3.693, Average Loss: 4.435, avg. samples / sec: 66262.22
Iteration:   1840, Loss function: 4.578, Average Loss: 4.463, avg. samples / sec: 66145.81
Iteration:   1840, Loss function: 3.764, Average Loss: 4.469, avg. samples / sec: 66226.23
Iteration:   1840, Loss function: 5.130, Average Loss: 4.449, avg. samples / sec: 66149.66
Iteration:   1840, Loss function: 4.071, Average Loss: 4.461, avg. samples / sec: 66277.34
Iteration:   1840, Loss function: 4.179, Average Loss: 4.445, avg. samples / sec: 66149.48
Iteration:   1840, Loss function: 4.661, Average Loss: 4.436, avg. samples / sec: 66167.80
Iteration:   1840, Loss function: 3.350, Average Loss: 4.458, avg. samples / sec: 66002.66
Iteration:   1840, Loss function: 5.757, Average Loss: 4.462, avg. samples / sec: 66152.08
Iteration:   1840, Loss function: 5.507, Average Loss: 4.431, avg. samples / sec: 65923.56
Iteration:   1840, Loss function: 3.883, Average Loss: 4.468, avg. samples / sec: 66099.34
Iteration:   1860, Loss function: 2.580, Average Loss: 4.438, avg. samples / sec: 66217.05
Iteration:   1860, Loss function: 4.653, Average Loss: 4.443, avg. samples / sec: 66097.88
Iteration:   1860, Loss function: 4.000, Average Loss: 4.477, avg. samples / sec: 66187.75
Iteration:   1860, Loss function: 3.534, Average Loss: 4.454, avg. samples / sec: 66152.46
Iteration:   1860, Loss function: 4.122, Average Loss: 4.444, avg. samples / sec: 66285.22
Iteration:   1860, Loss function: 5.574, Average Loss: 4.445, avg. samples / sec: 66209.08
Iteration:   1860, Loss function: 4.077, Average Loss: 4.467, avg. samples / sec: 66186.23
Iteration:   1860, Loss function: 5.257, Average Loss: 4.452, avg. samples / sec: 66150.53
Iteration:   1860, Loss function: 4.235, Average Loss: 4.456, avg. samples / sec: 66141.87
Iteration:   1860, Loss function: 3.542, Average Loss: 4.439, avg. samples / sec: 66078.14
Iteration:   1860, Loss function: 4.615, Average Loss: 4.442, avg. samples / sec: 66128.25
Iteration:   1860, Loss function: 4.020, Average Loss: 4.458, avg. samples / sec: 66386.55
Iteration:   1860, Loss function: 4.645, Average Loss: 4.398, avg. samples / sec: 66121.14
Iteration:   1860, Loss function: 4.251, Average Loss: 4.423, avg. samples / sec: 66037.82
Iteration:   1860, Loss function: 4.785, Average Loss: 4.466, avg. samples / sec: 66165.53
Iteration:   1860, Loss function: 4.483, Average Loss: 4.442, avg. samples / sec: 66007.05
Iteration:   1860, Loss function: 3.417, Average Loss: 4.453, avg. samples / sec: 66083.62
Iteration:   1860, Loss function: 4.743, Average Loss: 4.432, avg. samples / sec: 66221.18
Iteration:   1860, Loss function: 5.730, Average Loss: 4.461, avg. samples / sec: 66052.06
Iteration:   1860, Loss function: 3.258, Average Loss: 4.459, avg. samples / sec: 66215.74
Iteration:   1860, Loss function: 5.886, Average Loss: 4.450, avg. samples / sec: 66111.46
Iteration:   1860, Loss function: 3.467, Average Loss: 4.443, avg. samples / sec: 66183.15
Iteration:   1860, Loss function: 4.187, Average Loss: 4.458, avg. samples / sec: 66049.34
Iteration:   1860, Loss function: 5.907, Average Loss: 4.456, avg. samples / sec: 66258.70
Iteration:   1860, Loss function: 4.131, Average Loss: 4.460, avg. samples / sec: 65975.84
Iteration:   1860, Loss function: 4.748, Average Loss: 4.461, avg. samples / sec: 66082.17
Iteration:   1860, Loss function: 4.154, Average Loss: 4.455, avg. samples / sec: 66188.81
Iteration:   1860, Loss function: 4.833, Average Loss: 4.444, avg. samples / sec: 65964.54
Iteration:   1860, Loss function: 4.450, Average Loss: 4.429, avg. samples / sec: 66044.91
Iteration:   1860, Loss function: 4.413, Average Loss: 4.430, avg. samples / sec: 66190.64
Iteration:   1880, Loss function: 4.731, Average Loss: 4.431, avg. samples / sec: 66580.25
Iteration:   1880, Loss function: 3.810, Average Loss: 4.446, avg. samples / sec: 66614.68
Iteration:   1880, Loss function: 3.610, Average Loss: 4.470, avg. samples / sec: 66510.30
Iteration:   1880, Loss function: 4.175, Average Loss: 4.440, avg. samples / sec: 66548.71
Iteration:   1880, Loss function: 4.149, Average Loss: 4.460, avg. samples / sec: 66651.48
Iteration:   1880, Loss function: 5.370, Average Loss: 4.418, avg. samples / sec: 66575.25
Iteration:   1880, Loss function: 5.422, Average Loss: 4.437, avg. samples / sec: 66424.75
Iteration:   1880, Loss function: 5.032, Average Loss: 4.443, avg. samples / sec: 66493.04
Iteration:   1880, Loss function: 3.998, Average Loss: 4.444, avg. samples / sec: 66615.65
Iteration:   1880, Loss function: 4.537, Average Loss: 4.460, avg. samples / sec: 66495.33
Iteration:   1880, Loss function: 5.080, Average Loss: 4.445, avg. samples / sec: 66453.00
Iteration:   1880, Loss function: 5.264, Average Loss: 4.452, avg. samples / sec: 66482.32
Iteration:   1880, Loss function: 4.529, Average Loss: 4.429, avg. samples / sec: 66504.15
Iteration:   1880, Loss function: 4.242, Average Loss: 4.427, avg. samples / sec: 66621.39
Iteration:   1880, Loss function: 4.635, Average Loss: 4.449, avg. samples / sec: 66360.94
Iteration:   1880, Loss function: 4.882, Average Loss: 4.431, avg. samples / sec: 66606.90
Iteration:   1880, Loss function: 4.871, Average Loss: 4.441, avg. samples / sec: 66387.77
Iteration:   1880, Loss function: 4.602, Average Loss: 4.436, avg. samples / sec: 66445.08
Iteration:   1880, Loss function: 4.009, Average Loss: 4.453, avg. samples / sec: 66475.10
Iteration:   1880, Loss function: 3.563, Average Loss: 4.442, avg. samples / sec: 66477.67
Iteration:   1880, Loss function: 3.457, Average Loss: 4.461, avg. samples / sec: 66527.89
Iteration:   1880, Loss function: 3.635, Average Loss: 4.393, avg. samples / sec: 66420.68
Iteration:   1880, Loss function: 4.487, Average Loss: 4.452, avg. samples / sec: 66466.17
Iteration:   1880, Loss function: 4.192, Average Loss: 4.449, avg. samples / sec: 66378.29
Iteration:   1880, Loss function: 4.419, Average Loss: 4.463, avg. samples / sec: 66352.91
Iteration:   1880, Loss function: 4.157, Average Loss: 4.439, avg. samples / sec: 66435.71
Iteration:   1880, Loss function: 5.407, Average Loss: 4.453, avg. samples / sec: 66456.48
Iteration:   1880, Loss function: 4.815, Average Loss: 4.459, avg. samples / sec: 66373.48
Iteration:   1880, Loss function: 3.734, Average Loss: 4.437, avg. samples / sec: 66476.67
Iteration:   1880, Loss function: 3.664, Average Loss: 4.455, avg. samples / sec: 66308.18
:::MLL 1558651572.247 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558651572.247 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 5.565, Average Loss: 4.435, avg. samples / sec: 66092.36
Iteration:   1900, Loss function: 4.465, Average Loss: 4.439, avg. samples / sec: 66147.15
Iteration:   1900, Loss function: 3.291, Average Loss: 4.459, avg. samples / sec: 66046.40
Iteration:   1900, Loss function: 4.606, Average Loss: 4.449, avg. samples / sec: 66140.97
Iteration:   1900, Loss function: 4.051, Average Loss: 4.470, avg. samples / sec: 65976.58
Iteration:   1900, Loss function: 5.211, Average Loss: 4.449, avg. samples / sec: 66181.38
Iteration:   1900, Loss function: 5.242, Average Loss: 4.440, avg. samples / sec: 66051.91
Iteration:   1900, Loss function: 4.855, Average Loss: 4.437, avg. samples / sec: 66231.24
Iteration:   1900, Loss function: 4.411, Average Loss: 4.456, avg. samples / sec: 66126.29
Iteration:   1900, Loss function: 5.384, Average Loss: 4.435, avg. samples / sec: 65828.47
Iteration:   1900, Loss function: 4.180, Average Loss: 4.440, avg. samples / sec: 66071.54
Iteration:   1900, Loss function: 3.234, Average Loss: 4.451, avg. samples / sec: 66056.24
Iteration:   1900, Loss function: 5.187, Average Loss: 4.428, avg. samples / sec: 66056.21
Iteration:   1900, Loss function: 4.661, Average Loss: 4.425, avg. samples / sec: 66043.98
Iteration:   1900, Loss function: 3.615, Average Loss: 4.426, avg. samples / sec: 66049.12
Iteration:   1900, Loss function: 3.987, Average Loss: 4.395, avg. samples / sec: 66088.64
Iteration:   1900, Loss function: 3.560, Average Loss: 4.421, avg. samples / sec: 65947.40
Iteration:   1900, Loss function: 4.713, Average Loss: 4.447, avg. samples / sec: 66088.77
Iteration:   1900, Loss function: 3.586, Average Loss: 4.454, avg. samples / sec: 66199.38
Iteration:   1900, Loss function: 3.361, Average Loss: 4.457, avg. samples / sec: 66009.77
Iteration:   1900, Loss function: 5.247, Average Loss: 4.459, avg. samples / sec: 66064.88
Iteration:   1900, Loss function: 3.348, Average Loss: 4.433, avg. samples / sec: 66055.93
Iteration:   1900, Loss function: 4.166, Average Loss: 4.442, avg. samples / sec: 65900.90
Iteration:   1900, Loss function: 4.219, Average Loss: 4.433, avg. samples / sec: 65959.23
Iteration:   1900, Loss function: 4.704, Average Loss: 4.447, avg. samples / sec: 66026.04
Iteration:   1900, Loss function: 4.590, Average Loss: 4.454, avg. samples / sec: 66089.70
Iteration:   1900, Loss function: 3.207, Average Loss: 4.432, avg. samples / sec: 66054.69
Iteration:   1900, Loss function: 4.104, Average Loss: 4.445, avg. samples / sec: 65922.02
Iteration:   1900, Loss function: 6.061, Average Loss: 4.452, avg. samples / sec: 66028.88
Iteration:   1900, Loss function: 3.915, Average Loss: 4.435, avg. samples / sec: 65955.71
Iteration:   1920, Loss function: 3.021, Average Loss: 4.417, avg. samples / sec: 66566.19
Iteration:   1920, Loss function: 5.209, Average Loss: 4.433, avg. samples / sec: 66539.10
Iteration:   1920, Loss function: 3.452, Average Loss: 4.437, avg. samples / sec: 66396.24
Iteration:   1920, Loss function: 5.305, Average Loss: 4.447, avg. samples / sec: 66560.91
Iteration:   1920, Loss function: 4.610, Average Loss: 4.439, avg. samples / sec: 66339.89
Iteration:   1920, Loss function: 5.003, Average Loss: 4.456, avg. samples / sec: 66394.83
Iteration:   1920, Loss function: 5.840, Average Loss: 4.434, avg. samples / sec: 66507.70
Iteration:   1920, Loss function: 4.286, Average Loss: 4.440, avg. samples / sec: 66430.51
Iteration:   1920, Loss function: 4.078, Average Loss: 4.437, avg. samples / sec: 66557.23
Iteration:   1920, Loss function: 3.583, Average Loss: 4.454, avg. samples / sec: 66484.57
Iteration:   1920, Loss function: 3.413, Average Loss: 4.449, avg. samples / sec: 66583.27
Iteration:   1920, Loss function: 5.082, Average Loss: 4.429, avg. samples / sec: 66476.11
Iteration:   1920, Loss function: 4.934, Average Loss: 4.442, avg. samples / sec: 66452.69
Iteration:   1920, Loss function: 3.140, Average Loss: 4.428, avg. samples / sec: 66561.85
Iteration:   1920, Loss function: 3.522, Average Loss: 4.451, avg. samples / sec: 66446.89
Iteration:   1920, Loss function: 4.097, Average Loss: 4.419, avg. samples / sec: 66408.85
Iteration:   1920, Loss function: 3.512, Average Loss: 4.450, avg. samples / sec: 66387.89
Iteration:   1920, Loss function: 4.271, Average Loss: 4.435, avg. samples / sec: 66342.51
Iteration:   1920, Loss function: 4.934, Average Loss: 4.432, avg. samples / sec: 66395.71
Iteration:   1920, Loss function: 5.875, Average Loss: 4.425, avg. samples / sec: 66383.58
Iteration:   1920, Loss function: 4.461, Average Loss: 4.395, avg. samples / sec: 66385.17
Iteration:   1920, Loss function: 4.124, Average Loss: 4.444, avg. samples / sec: 66311.05
Iteration:   1920, Loss function: 3.941, Average Loss: 4.437, avg. samples / sec: 66362.35
Iteration:   1920, Loss function: 4.170, Average Loss: 4.447, avg. samples / sec: 66375.04
Iteration:   1920, Loss function: 4.329, Average Loss: 4.469, avg. samples / sec: 66297.73
Iteration:   1920, Loss function: 5.327, Average Loss: 4.455, avg. samples / sec: 66361.79
Iteration:   1920, Loss function: 4.726, Average Loss: 4.455, avg. samples / sec: 66320.38
Iteration:   1920, Loss function: 4.832, Average Loss: 4.446, avg. samples / sec: 66228.81
Iteration:   1920, Loss function: 3.184, Average Loss: 4.427, avg. samples / sec: 66341.55
Iteration:   1920, Loss function: 3.003, Average Loss: 4.455, avg. samples / sec: 66203.73
Iteration:   1940, Loss function: 4.375, Average Loss: 4.415, avg. samples / sec: 65960.68
Iteration:   1940, Loss function: 5.071, Average Loss: 4.471, avg. samples / sec: 66117.54
Iteration:   1940, Loss function: 3.766, Average Loss: 4.432, avg. samples / sec: 66043.67
Iteration:   1940, Loss function: 3.921, Average Loss: 4.449, avg. samples / sec: 66115.34
Iteration:   1940, Loss function: 4.629, Average Loss: 4.427, avg. samples / sec: 65959.97
Iteration:   1940, Loss function: 4.987, Average Loss: 4.447, avg. samples / sec: 66022.82
Iteration:   1940, Loss function: 3.776, Average Loss: 4.418, avg. samples / sec: 66002.60
Iteration:   1940, Loss function: 4.417, Average Loss: 4.432, avg. samples / sec: 66004.98
Iteration:   1940, Loss function: 3.827, Average Loss: 4.440, avg. samples / sec: 66110.53
Iteration:   1940, Loss function: 3.383, Average Loss: 4.451, avg. samples / sec: 65892.95
Iteration:   1940, Loss function: 2.923, Average Loss: 4.430, avg. samples / sec: 66026.35
Iteration:   1940, Loss function: 4.166, Average Loss: 4.432, avg. samples / sec: 65874.87
Iteration:   1940, Loss function: 4.205, Average Loss: 4.447, avg. samples / sec: 65933.49
Iteration:   1940, Loss function: 4.235, Average Loss: 4.434, avg. samples / sec: 65855.26
Iteration:   1940, Loss function: 4.351, Average Loss: 4.434, avg. samples / sec: 65867.27
Iteration:   1940, Loss function: 3.886, Average Loss: 4.440, avg. samples / sec: 65841.39
Iteration:   1940, Loss function: 3.517, Average Loss: 4.454, avg. samples / sec: 66020.31
Iteration:   1940, Loss function: 4.579, Average Loss: 4.446, avg. samples / sec: 65993.33
Iteration:   1940, Loss function: 5.923, Average Loss: 4.420, avg. samples / sec: 65973.99
Iteration:   1940, Loss function: 4.262, Average Loss: 4.431, avg. samples / sec: 65820.69
Iteration:   1940, Loss function: 4.585, Average Loss: 4.436, avg. samples / sec: 65867.48
Iteration:   1940, Loss function: 5.200, Average Loss: 4.395, avg. samples / sec: 65963.89
Iteration:   1940, Loss function: 3.129, Average Loss: 4.429, avg. samples / sec: 65946.54
Iteration:   1940, Loss function: 3.532, Average Loss: 4.438, avg. samples / sec: 65861.60
Iteration:   1940, Loss function: 3.807, Average Loss: 4.450, avg. samples / sec: 65851.42
Iteration:   1940, Loss function: 4.685, Average Loss: 4.422, avg. samples / sec: 66032.90
Iteration:   1940, Loss function: 4.777, Average Loss: 4.439, avg. samples / sec: 65916.47
Iteration:   1940, Loss function: 3.961, Average Loss: 4.452, avg. samples / sec: 66091.22
Iteration:   1940, Loss function: 5.076, Average Loss: 4.426, avg. samples / sec: 65836.99
Iteration:   1940, Loss function: 4.183, Average Loss: 4.447, avg. samples / sec: 65742.27
:::MLL 1558651574.025 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558651574.026 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.277, Average Loss: 4.425, avg. samples / sec: 66203.55
Iteration:   1960, Loss function: 4.713, Average Loss: 4.416, avg. samples / sec: 66104.27
Iteration:   1960, Loss function: 4.631, Average Loss: 4.431, avg. samples / sec: 66242.91
Iteration:   1960, Loss function: 4.123, Average Loss: 4.450, avg. samples / sec: 66137.37
Iteration:   1960, Loss function: 4.990, Average Loss: 4.469, avg. samples / sec: 66049.12
Iteration:   1960, Loss function: 3.170, Average Loss: 4.426, avg. samples / sec: 66114.22
Iteration:   1960, Loss function: 3.350, Average Loss: 4.415, avg. samples / sec: 66135.51
Iteration:   1960, Loss function: 4.087, Average Loss: 4.444, avg. samples / sec: 66038.69
Iteration:   1960, Loss function: 4.483, Average Loss: 4.431, avg. samples / sec: 66100.02
Iteration:   1960, Loss function: 5.051, Average Loss: 4.446, avg. samples / sec: 66079.78
Iteration:   1960, Loss function: 4.923, Average Loss: 4.436, avg. samples / sec: 66138.98
Iteration:   1960, Loss function: 4.586, Average Loss: 4.438, avg. samples / sec: 66072.47
Iteration:   1960, Loss function: 4.720, Average Loss: 4.426, avg. samples / sec: 66060.89
Iteration:   1960, Loss function: 4.186, Average Loss: 4.418, avg. samples / sec: 66150.22
Iteration:   1960, Loss function: 4.221, Average Loss: 4.426, avg. samples / sec: 66041.14
Iteration:   1960, Loss function: 4.156, Average Loss: 4.448, avg. samples / sec: 66029.87
Iteration:   1960, Loss function: 4.193, Average Loss: 4.424, avg. samples / sec: 66071.26
Iteration:   1960, Loss function: 3.595, Average Loss: 4.436, avg. samples / sec: 66123.44
Iteration:   1960, Loss function: 4.849, Average Loss: 4.421, avg. samples / sec: 66006.77
Iteration:   1960, Loss function: 3.991, Average Loss: 4.421, avg. samples / sec: 66132.81
Iteration:   1960, Loss function: 3.312, Average Loss: 4.391, avg. samples / sec: 66048.29
Iteration:   1960, Loss function: 4.051, Average Loss: 4.434, avg. samples / sec: 66019.05
Iteration:   1960, Loss function: 4.076, Average Loss: 4.442, avg. samples / sec: 66055.99
Iteration:   1960, Loss function: 4.680, Average Loss: 4.448, avg. samples / sec: 66071.08
Iteration:   1960, Loss function: 4.624, Average Loss: 4.428, avg. samples / sec: 65874.04
Iteration:   1960, Loss function: 4.317, Average Loss: 4.437, avg. samples / sec: 65991.75
Iteration:   1960, Loss function: 5.048, Average Loss: 4.440, avg. samples / sec: 65948.82
Iteration:   1960, Loss function: 4.011, Average Loss: 4.453, avg. samples / sec: 65962.50
Iteration:   1960, Loss function: 3.677, Average Loss: 4.440, avg. samples / sec: 66145.50
Iteration:   1960, Loss function: 4.721, Average Loss: 4.416, avg. samples / sec: 65830.34
Iteration:   1980, Loss function: 4.296, Average Loss: 4.433, avg. samples / sec: 66305.46
Iteration:   1980, Loss function: 4.728, Average Loss: 4.429, avg. samples / sec: 66179.76
Iteration:   1980, Loss function: 3.646, Average Loss: 4.433, avg. samples / sec: 66251.13
Iteration:   1980, Loss function: 5.225, Average Loss: 4.433, avg. samples / sec: 66182.84
Iteration:   1980, Loss function: 3.117, Average Loss: 4.438, avg. samples / sec: 66259.79
Iteration:   1980, Loss function: 4.376, Average Loss: 4.448, avg. samples / sec: 66201.99
Iteration:   1980, Loss function: 5.025, Average Loss: 4.424, avg. samples / sec: 66270.07
Iteration:   1980, Loss function: 3.959, Average Loss: 4.449, avg. samples / sec: 66077.40
Iteration:   1980, Loss function: 4.078, Average Loss: 4.424, avg. samples / sec: 66183.15
Iteration:   1980, Loss function: 3.649, Average Loss: 4.423, avg. samples / sec: 66160.00
Iteration:   1980, Loss function: 4.276, Average Loss: 4.416, avg. samples / sec: 65982.17
Iteration:   1980, Loss function: 5.221, Average Loss: 4.431, avg. samples / sec: 66117.82
Iteration:   1980, Loss function: 3.719, Average Loss: 4.432, avg. samples / sec: 66272.88
Iteration:   1980, Loss function: 3.817, Average Loss: 4.423, avg. samples / sec: 65995.52
Iteration:   1980, Loss function: 3.104, Average Loss: 4.465, avg. samples / sec: 66057.60
Iteration:   1980, Loss function: 4.080, Average Loss: 4.452, avg. samples / sec: 66258.58
Iteration:   1980, Loss function: 4.824, Average Loss: 4.432, avg. samples / sec: 66001.05
Iteration:   1980, Loss function: 2.748, Average Loss: 4.430, avg. samples / sec: 66273.75
Iteration:   1980, Loss function: 4.117, Average Loss: 4.416, avg. samples / sec: 66105.38
Iteration:   1980, Loss function: 3.480, Average Loss: 4.428, avg. samples / sec: 66175.32
Iteration:   1980, Loss function: 3.679, Average Loss: 4.444, avg. samples / sec: 66200.00
Iteration:   1980, Loss function: 4.589, Average Loss: 4.444, avg. samples / sec: 66034.85
Iteration:   1980, Loss function: 4.042, Average Loss: 4.423, avg. samples / sec: 66124.03
Iteration:   1980, Loss function: 5.272, Average Loss: 4.413, avg. samples / sec: 66286.94
Iteration:   1980, Loss function: 4.503, Average Loss: 4.391, avg. samples / sec: 66130.45
Iteration:   1980, Loss function: 3.924, Average Loss: 4.423, avg. samples / sec: 66067.89
Iteration:   1980, Loss function: 4.287, Average Loss: 4.444, avg. samples / sec: 65976.89
Iteration:   1980, Loss function: 3.353, Average Loss: 4.436, avg. samples / sec: 66145.97
Iteration:   1980, Loss function: 3.865, Average Loss: 4.418, avg. samples / sec: 66053.77
Iteration:   1980, Loss function: 3.265, Average Loss: 4.408, avg. samples / sec: 65918.50
Iteration:   2000, Loss function: 3.974, Average Loss: 4.422, avg. samples / sec: 66455.57
Iteration:   2000, Loss function: 5.526, Average Loss: 4.424, avg. samples / sec: 66370.66
Iteration:   2000, Loss function: 4.190, Average Loss: 4.462, avg. samples / sec: 66373.67
Iteration:   2000, Loss function: 4.602, Average Loss: 4.413, avg. samples / sec: 66429.92
Iteration:   2000, Loss function: 4.055, Average Loss: 4.411, avg. samples / sec: 66336.86
Iteration:   2000, Loss function: 4.205, Average Loss: 4.446, avg. samples / sec: 66331.52
Iteration:   2000, Loss function: 4.275, Average Loss: 4.450, avg. samples / sec: 66290.09
Iteration:   2000, Loss function: 3.575, Average Loss: 4.442, avg. samples / sec: 66279.80
Iteration:   2000, Loss function: 3.584, Average Loss: 4.427, avg. samples / sec: 66294.98
Iteration:   2000, Loss function: 4.179, Average Loss: 4.417, avg. samples / sec: 66284.91
Iteration:   2000, Loss function: 3.408, Average Loss: 4.428, avg. samples / sec: 66297.26
Iteration:   2000, Loss function: 4.694, Average Loss: 4.426, avg. samples / sec: 66332.74
Iteration:   2000, Loss function: 3.448, Average Loss: 4.431, avg. samples / sec: 66095.59
Iteration:   2000, Loss function: 4.604, Average Loss: 4.415, avg. samples / sec: 66385.48
Iteration:   2000, Loss function: 4.606, Average Loss: 4.426, avg. samples / sec: 66203.58
Iteration:   2000, Loss function: 3.229, Average Loss: 4.385, avg. samples / sec: 66339.08
Iteration:   2000, Loss function: 4.555, Average Loss: 4.440, avg. samples / sec: 66314.35
Iteration:   2000, Loss function: 4.099, Average Loss: 4.438, avg. samples / sec: 66392.68
Iteration:   2000, Loss function: 2.738, Average Loss: 4.427, avg. samples / sec: 66400.59
Iteration:   2000, Loss function: 4.148, Average Loss: 4.429, avg. samples / sec: 66164.10
Iteration:   2000, Loss function: 3.487, Average Loss: 4.419, avg. samples / sec: 66226.82
Iteration:   2000, Loss function: 4.294, Average Loss: 4.432, avg. samples / sec: 66201.06
Iteration:   2000, Loss function: 3.531, Average Loss: 4.426, avg. samples / sec: 66262.50
Iteration:   2000, Loss function: 4.715, Average Loss: 4.408, avg. samples / sec: 66251.79
Iteration:   2000, Loss function: 4.414, Average Loss: 4.420, avg. samples / sec: 66288.31
Iteration:   2000, Loss function: 4.514, Average Loss: 4.426, avg. samples / sec: 66208.71
Iteration:   2000, Loss function: 3.826, Average Loss: 4.406, avg. samples / sec: 66396.74
Iteration:   2000, Loss function: 2.267, Average Loss: 4.438, avg. samples / sec: 66256.24
Iteration:   2000, Loss function: 5.137, Average Loss: 4.425, avg. samples / sec: 66131.50
Iteration:   2000, Loss function: 4.993, Average Loss: 4.413, avg. samples / sec: 66272.19
Iteration:   2020, Loss function: 4.584, Average Loss: 4.407, avg. samples / sec: 66423.72
Iteration:   2020, Loss function: 4.253, Average Loss: 4.445, avg. samples / sec: 66403.09
Iteration:   2020, Loss function: 4.155, Average Loss: 4.421, avg. samples / sec: 66462.91
Iteration:   2020, Loss function: 4.446, Average Loss: 4.422, avg. samples / sec: 66436.56
Iteration:   2020, Loss function: 6.070, Average Loss: 4.458, avg. samples / sec: 66333.61
Iteration:   2020, Loss function: 4.578, Average Loss: 4.412, avg. samples / sec: 66358.98
Iteration:   2020, Loss function: 3.728, Average Loss: 4.428, avg. samples / sec: 66394.27
Iteration:   2020, Loss function: 5.445, Average Loss: 4.386, avg. samples / sec: 66394.43
Iteration:   2020, Loss function: 4.146, Average Loss: 4.436, avg. samples / sec: 66356.20
Iteration:   2020, Loss function: 5.880, Average Loss: 4.423, avg. samples / sec: 66448.81
Iteration:   2020, Loss function: 3.245, Average Loss: 4.421, avg. samples / sec: 66469.84
Iteration:   2020, Loss function: 5.367, Average Loss: 4.412, avg. samples / sec: 66426.22
Iteration:   2020, Loss function: 4.282, Average Loss: 4.421, avg. samples / sec: 66167.09
Iteration:   2020, Loss function: 3.969, Average Loss: 4.419, avg. samples / sec: 66246.12
Iteration:   2020, Loss function: 4.634, Average Loss: 4.433, avg. samples / sec: 66382.83
Iteration:   2020, Loss function: 3.623, Average Loss: 4.425, avg. samples / sec: 66320.00
Iteration:   2020, Loss function: 4.883, Average Loss: 4.433, avg. samples / sec: 66362.63
Iteration:   2020, Loss function: 2.636, Average Loss: 4.412, avg. samples / sec: 66290.37
Iteration:   2020, Loss function: 4.205, Average Loss: 4.405, avg. samples / sec: 66381.76
Iteration:   2020, Loss function: 4.482, Average Loss: 4.420, avg. samples / sec: 66354.45
Iteration:   2020, Loss function: 4.507, Average Loss: 4.442, avg. samples / sec: 66259.85
Iteration:   2020, Loss function: 5.144, Average Loss: 4.410, avg. samples / sec: 66454.82
Iteration:   2020, Loss function: 4.573, Average Loss: 4.420, avg. samples / sec: 66267.55
Iteration:   2020, Loss function: 4.356, Average Loss: 4.422, avg. samples / sec: 66326.65
Iteration:   2020, Loss function: 5.762, Average Loss: 4.414, avg. samples / sec: 66342.73
Iteration:   2020, Loss function: 4.346, Average Loss: 4.422, avg. samples / sec: 66269.08
Iteration:   2020, Loss function: 3.207, Average Loss: 4.422, avg. samples / sec: 66305.93
Iteration:   2020, Loss function: 3.826, Average Loss: 4.413, avg. samples / sec: 66161.77
Iteration:   2020, Loss function: 5.308, Average Loss: 4.439, avg. samples / sec: 66304.09
Iteration:   2020, Loss function: 3.377, Average Loss: 4.430, avg. samples / sec: 66262.38
:::MLL 1558651575.803 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558651575.804 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 4.114, Average Loss: 4.437, avg. samples / sec: 65735.80
Iteration:   2040, Loss function: 5.569, Average Loss: 4.457, avg. samples / sec: 65706.10
Iteration:   2040, Loss function: 3.244, Average Loss: 4.402, avg. samples / sec: 65684.91
Iteration:   2040, Loss function: 4.196, Average Loss: 4.406, avg. samples / sec: 65699.88
Iteration:   2040, Loss function: 4.980, Average Loss: 4.417, avg. samples / sec: 65673.64
Iteration:   2040, Loss function: 5.656, Average Loss: 4.434, avg. samples / sec: 65750.67
Iteration:   2040, Loss function: 4.552, Average Loss: 4.417, avg. samples / sec: 65754.32
Iteration:   2040, Loss function: 3.757, Average Loss: 4.431, avg. samples / sec: 65689.23
Iteration:   2040, Loss function: 3.581, Average Loss: 4.419, avg. samples / sec: 65651.19
Iteration:   2040, Loss function: 5.566, Average Loss: 4.420, avg. samples / sec: 65781.64
Iteration:   2040, Loss function: 4.685, Average Loss: 4.412, avg. samples / sec: 65701.48
Iteration:   2040, Loss function: 4.897, Average Loss: 4.428, avg. samples / sec: 65829.73
Iteration:   2040, Loss function: 4.546, Average Loss: 4.423, avg. samples / sec: 65651.53
Iteration:   2040, Loss function: 5.331, Average Loss: 4.416, avg. samples / sec: 65763.62
Iteration:   2040, Loss function: 5.182, Average Loss: 4.417, avg. samples / sec: 65648.53
Iteration:   2040, Loss function: 3.832, Average Loss: 4.385, avg. samples / sec: 65614.42
Iteration:   2040, Loss function: 3.752, Average Loss: 4.405, avg. samples / sec: 65690.70
Iteration:   2040, Loss function: 5.133, Average Loss: 4.436, avg. samples / sec: 65760.71
Iteration:   2040, Loss function: 5.383, Average Loss: 4.444, avg. samples / sec: 65682.74
Iteration:   2040, Loss function: 4.084, Average Loss: 4.407, avg. samples / sec: 65651.95
Iteration:   2040, Loss function: 3.765, Average Loss: 4.415, avg. samples / sec: 65691.64
Iteration:   2040, Loss function: 3.626, Average Loss: 4.418, avg. samples / sec: 65671.93
Iteration:   2040, Loss function: 4.971, Average Loss: 4.422, avg. samples / sec: 65573.32
Iteration:   2040, Loss function: 3.560, Average Loss: 4.411, avg. samples / sec: 65578.08
Iteration:   2040, Loss function: 6.458, Average Loss: 4.412, avg. samples / sec: 65684.60
Iteration:   2040, Loss function: 3.263, Average Loss: 4.403, avg. samples / sec: 65616.04
Iteration:   2040, Loss function: 4.309, Average Loss: 4.414, avg. samples / sec: 65587.88
Iteration:   2040, Loss function: 3.947, Average Loss: 4.405, avg. samples / sec: 65575.80
Iteration:   2040, Loss function: 4.236, Average Loss: 4.418, avg. samples / sec: 65521.53
Iteration:   2040, Loss function: 5.072, Average Loss: 4.432, avg. samples / sec: 65542.49
Iteration:   2060, Loss function: 4.660, Average Loss: 4.411, avg. samples / sec: 66624.38
Iteration:   2060, Loss function: 4.002, Average Loss: 4.427, avg. samples / sec: 66705.52
Iteration:   2060, Loss function: 4.058, Average Loss: 4.419, avg. samples / sec: 66544.53
Iteration:   2060, Loss function: 4.053, Average Loss: 4.411, avg. samples / sec: 66506.76
Iteration:   2060, Loss function: 4.346, Average Loss: 4.411, avg. samples / sec: 66446.58
Iteration:   2060, Loss function: 3.523, Average Loss: 4.430, avg. samples / sec: 66361.85
Iteration:   2060, Loss function: 4.302, Average Loss: 4.396, avg. samples / sec: 66407.35
Iteration:   2060, Loss function: 3.032, Average Loss: 4.452, avg. samples / sec: 66387.77
Iteration:   2060, Loss function: 4.250, Average Loss: 4.408, avg. samples / sec: 66544.63
Iteration:   2060, Loss function: 3.669, Average Loss: 4.416, avg. samples / sec: 66443.82
Iteration:   2060, Loss function: 3.602, Average Loss: 4.402, avg. samples / sec: 66516.02
Iteration:   2060, Loss function: 4.864, Average Loss: 4.406, avg. samples / sec: 66433.14
Iteration:   2060, Loss function: 3.795, Average Loss: 4.438, avg. samples / sec: 66505.38
Iteration:   2060, Loss function: 4.876, Average Loss: 4.413, avg. samples / sec: 66507.85
Iteration:   2060, Loss function: 3.320, Average Loss: 4.414, avg. samples / sec: 66567.67
Iteration:   2060, Loss function: 4.723, Average Loss: 4.397, avg. samples / sec: 66568.11
Iteration:   2060, Loss function: 4.529, Average Loss: 4.413, avg. samples / sec: 66468.99
Iteration:   2060, Loss function: 4.174, Average Loss: 4.413, avg. samples / sec: 66403.59
Iteration:   2060, Loss function: 4.777, Average Loss: 4.404, avg. samples / sec: 66507.51
Iteration:   2060, Loss function: 4.717, Average Loss: 4.427, avg. samples / sec: 66330.96
Iteration:   2060, Loss function: 4.051, Average Loss: 4.404, avg. samples / sec: 66310.20
Iteration:   2060, Loss function: 4.103, Average Loss: 4.408, avg. samples / sec: 66505.47
Iteration:   2060, Loss function: 3.605, Average Loss: 4.408, avg. samples / sec: 66533.22
Iteration:   2060, Loss function: 3.506, Average Loss: 4.405, avg. samples / sec: 66446.08
Iteration:   2060, Loss function: 6.889, Average Loss: 4.438, avg. samples / sec: 66406.19
Iteration:   2060, Loss function: 3.424, Average Loss: 4.417, avg. samples / sec: 66417.68
Iteration:   2060, Loss function: 3.486, Average Loss: 4.411, avg. samples / sec: 66280.67
Iteration:   2060, Loss function: 4.169, Average Loss: 4.382, avg. samples / sec: 66361.44
Iteration:   2060, Loss function: 4.707, Average Loss: 4.432, avg. samples / sec: 66234.19
Iteration:   2060, Loss function: 4.263, Average Loss: 4.427, avg. samples / sec: 66296.79
Iteration:   2080, Loss function: 4.426, Average Loss: 4.408, avg. samples / sec: 66525.34
Iteration:   2080, Loss function: 3.763, Average Loss: 4.402, avg. samples / sec: 66403.94
Iteration:   2080, Loss function: 4.701, Average Loss: 4.414, avg. samples / sec: 66290.34
Iteration:   2080, Loss function: 4.353, Average Loss: 4.407, avg. samples / sec: 66352.79
Iteration:   2080, Loss function: 3.977, Average Loss: 4.452, avg. samples / sec: 66357.54
Iteration:   2080, Loss function: 4.033, Average Loss: 4.413, avg. samples / sec: 66359.91
Iteration:   2080, Loss function: 3.721, Average Loss: 4.406, avg. samples / sec: 66279.08
Iteration:   2080, Loss function: 4.351, Average Loss: 4.411, avg. samples / sec: 66289.65
Iteration:   2080, Loss function: 4.005, Average Loss: 4.394, avg. samples / sec: 66363.48
Iteration:   2080, Loss function: 3.703, Average Loss: 4.425, avg. samples / sec: 66229.37
Iteration:   2080, Loss function: 4.511, Average Loss: 4.405, avg. samples / sec: 66201.09
Iteration:   2080, Loss function: 4.294, Average Loss: 4.422, avg. samples / sec: 66463.13
Iteration:   2080, Loss function: 3.827, Average Loss: 4.425, avg. samples / sec: 66275.34
Iteration:   2080, Loss function: 3.164, Average Loss: 4.401, avg. samples / sec: 66322.75
Iteration:   2080, Loss function: 5.411, Average Loss: 4.404, avg. samples / sec: 66381.54
Iteration:   2080, Loss function: 3.168, Average Loss: 4.437, avg. samples / sec: 66298.57
Iteration:   2080, Loss function: 3.753, Average Loss: 4.432, avg. samples / sec: 66397.24
Iteration:   2080, Loss function: 5.559, Average Loss: 4.427, avg. samples / sec: 66356.98
Iteration:   2080, Loss function: 4.103, Average Loss: 4.403, avg. samples / sec: 66343.79
Iteration:   2080, Loss function: 4.476, Average Loss: 4.407, avg. samples / sec: 66418.21
Iteration:   2080, Loss function: 3.797, Average Loss: 4.405, avg. samples / sec: 66274.97
Iteration:   2080, Loss function: 4.054, Average Loss: 4.398, avg. samples / sec: 66367.88
Iteration:   2080, Loss function: 4.493, Average Loss: 4.427, avg. samples / sec: 66405.10
Iteration:   2080, Loss function: 3.094, Average Loss: 4.403, avg. samples / sec: 66310.70
Iteration:   2080, Loss function: 3.430, Average Loss: 4.405, avg. samples / sec: 66288.96
Iteration:   2080, Loss function: 3.486, Average Loss: 4.413, avg. samples / sec: 66238.37
Iteration:   2080, Loss function: 3.716, Average Loss: 4.378, avg. samples / sec: 66334.89
Iteration:   2080, Loss function: 5.166, Average Loss: 4.410, avg. samples / sec: 66247.18
Iteration:   2080, Loss function: 4.761, Average Loss: 4.409, avg. samples / sec: 66227.88
Iteration:   2080, Loss function: 3.356, Average Loss: 4.389, avg. samples / sec: 66066.89
:::MLL 1558651577.579 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558651577.579 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 5.600, Average Loss: 4.418, avg. samples / sec: 66270.29
Iteration:   2100, Loss function: 3.543, Average Loss: 4.423, avg. samples / sec: 66325.50
Iteration:   2100, Loss function: 5.208, Average Loss: 4.406, avg. samples / sec: 66143.83
Iteration:   2100, Loss function: 4.901, Average Loss: 4.411, avg. samples / sec: 66297.82
Iteration:   2100, Loss function: 4.448, Average Loss: 4.396, avg. samples / sec: 66199.75
Iteration:   2100, Loss function: 5.071, Average Loss: 4.411, avg. samples / sec: 66143.45
Iteration:   2100, Loss function: 3.637, Average Loss: 4.381, avg. samples / sec: 66365.38
Iteration:   2100, Loss function: 4.121, Average Loss: 4.448, avg. samples / sec: 66090.29
Iteration:   2100, Loss function: 3.989, Average Loss: 4.409, avg. samples / sec: 66243.50
Iteration:   2100, Loss function: 4.800, Average Loss: 4.403, avg. samples / sec: 66071.39
Iteration:   2100, Loss function: 5.066, Average Loss: 4.395, avg. samples / sec: 66195.93
Iteration:   2100, Loss function: 3.288, Average Loss: 4.395, avg. samples / sec: 66225.29
Iteration:   2100, Loss function: 4.041, Average Loss: 4.398, avg. samples / sec: 66078.39
Iteration:   2100, Loss function: 4.394, Average Loss: 4.429, avg. samples / sec: 66142.06
Iteration:   2100, Loss function: 4.997, Average Loss: 4.408, avg. samples / sec: 66028.70
Iteration:   2100, Loss function: 3.319, Average Loss: 4.397, avg. samples / sec: 66104.11
Iteration:   2100, Loss function: 4.875, Average Loss: 4.370, avg. samples / sec: 66216.39
Iteration:   2100, Loss function: 4.019, Average Loss: 4.388, avg. samples / sec: 66080.56
Iteration:   2100, Loss function: 5.018, Average Loss: 4.410, avg. samples / sec: 66212.32
Iteration:   2100, Loss function: 4.182, Average Loss: 4.425, avg. samples / sec: 66115.87
Iteration:   2100, Loss function: 4.792, Average Loss: 4.399, avg. samples / sec: 66124.61
Iteration:   2100, Loss function: 3.363, Average Loss: 4.424, avg. samples / sec: 66067.98
Iteration:   2100, Loss function: 4.585, Average Loss: 4.404, avg. samples / sec: 65973.15
Iteration:   2100, Loss function: 3.925, Average Loss: 4.413, avg. samples / sec: 66155.41
Iteration:   2100, Loss function: 3.747, Average Loss: 4.407, avg. samples / sec: 66040.61
Iteration:   2100, Loss function: 2.797, Average Loss: 4.396, avg. samples / sec: 66017.13
Iteration:   2100, Loss function: 4.453, Average Loss: 4.410, avg. samples / sec: 65956.76
Iteration:   2100, Loss function: 4.144, Average Loss: 4.398, avg. samples / sec: 66034.08
Iteration:   2100, Loss function: 3.938, Average Loss: 4.423, avg. samples / sec: 65993.08
Iteration:   2100, Loss function: 3.932, Average Loss: 4.413, avg. samples / sec: 65918.78
Iteration:   2120, Loss function: 3.938, Average Loss: 4.393, avg. samples / sec: 66352.07
Iteration:   2120, Loss function: 4.011, Average Loss: 4.414, avg. samples / sec: 66123.81
Iteration:   2120, Loss function: 5.215, Average Loss: 4.379, avg. samples / sec: 66234.57
Iteration:   2120, Loss function: 4.687, Average Loss: 4.387, avg. samples / sec: 66242.41
Iteration:   2120, Loss function: 3.895, Average Loss: 4.394, avg. samples / sec: 66275.12
Iteration:   2120, Loss function: 4.543, Average Loss: 4.421, avg. samples / sec: 66296.73
Iteration:   2120, Loss function: 5.133, Average Loss: 4.403, avg. samples / sec: 66147.71
Iteration:   2120, Loss function: 3.914, Average Loss: 4.409, avg. samples / sec: 66175.57
Iteration:   2120, Loss function: 3.724, Average Loss: 4.440, avg. samples / sec: 66191.85
Iteration:   2120, Loss function: 4.651, Average Loss: 4.400, avg. samples / sec: 66300.25
Iteration:   2120, Loss function: 4.326, Average Loss: 4.362, avg. samples / sec: 66217.67
Iteration:   2120, Loss function: 3.791, Average Loss: 4.393, avg. samples / sec: 66089.08
Iteration:   2120, Loss function: 5.914, Average Loss: 4.411, avg. samples / sec: 66128.09
Iteration:   2120, Loss function: 4.997, Average Loss: 4.405, avg. samples / sec: 66081.33
Iteration:   2120, Loss function: 4.007, Average Loss: 4.403, avg. samples / sec: 66249.20
Iteration:   2120, Loss function: 3.884, Average Loss: 4.421, avg. samples / sec: 66232.45
Iteration:   2120, Loss function: 4.364, Average Loss: 4.404, avg. samples / sec: 66108.21
Iteration:   2120, Loss function: 4.910, Average Loss: 4.407, avg. samples / sec: 66183.83
Iteration:   2120, Loss function: 4.850, Average Loss: 4.424, avg. samples / sec: 66269.89
Iteration:   2120, Loss function: 4.570, Average Loss: 4.389, avg. samples / sec: 66094.19
Iteration:   2120, Loss function: 4.437, Average Loss: 4.411, avg. samples / sec: 66237.40
Iteration:   2120, Loss function: 4.688, Average Loss: 4.424, avg. samples / sec: 66111.87
Iteration:   2120, Loss function: 3.939, Average Loss: 4.394, avg. samples / sec: 66099.68
Iteration:   2120, Loss function: 4.114, Average Loss: 4.378, avg. samples / sec: 66140.50
Iteration:   2120, Loss function: 5.120, Average Loss: 4.422, avg. samples / sec: 65968.83
Iteration:   2120, Loss function: 4.386, Average Loss: 4.397, avg. samples / sec: 66217.33
Iteration:   2120, Loss function: 4.635, Average Loss: 4.411, avg. samples / sec: 66300.78
Iteration:   2120, Loss function: 4.908, Average Loss: 4.390, avg. samples / sec: 66154.41
Iteration:   2120, Loss function: 3.581, Average Loss: 4.400, avg. samples / sec: 66051.72
Iteration:   2120, Loss function: 4.551, Average Loss: 4.405, avg. samples / sec: 66129.05
Iteration:   2140, Loss function: 3.733, Average Loss: 4.403, avg. samples / sec: 66529.90
Iteration:   2140, Loss function: 3.586, Average Loss: 4.415, avg. samples / sec: 66357.16
Iteration:   2140, Loss function: 3.143, Average Loss: 4.419, avg. samples / sec: 66543.34
Iteration:   2140, Loss function: 4.125, Average Loss: 4.389, avg. samples / sec: 66334.52
Iteration:   2140, Loss function: 3.820, Average Loss: 4.385, avg. samples / sec: 66511.18
Iteration:   2140, Loss function: 4.008, Average Loss: 4.418, avg. samples / sec: 66474.19
Iteration:   2140, Loss function: 4.211, Average Loss: 4.387, avg. samples / sec: 66323.78
Iteration:   2140, Loss function: 5.176, Average Loss: 4.405, avg. samples / sec: 66344.14
Iteration:   2140, Loss function: 3.043, Average Loss: 4.371, avg. samples / sec: 66302.50
Iteration:   2140, Loss function: 4.874, Average Loss: 4.420, avg. samples / sec: 66297.17
Iteration:   2140, Loss function: 4.497, Average Loss: 4.421, avg. samples / sec: 66467.39
Iteration:   2140, Loss function: 4.678, Average Loss: 4.383, avg. samples / sec: 66429.39
Iteration:   2140, Loss function: 4.549, Average Loss: 4.402, avg. samples / sec: 66402.97
Iteration:   2140, Loss function: 3.950, Average Loss: 4.403, avg. samples / sec: 66295.86
Iteration:   2140, Loss function: 3.827, Average Loss: 4.400, avg. samples / sec: 66500.61
Iteration:   2140, Loss function: 3.544, Average Loss: 4.367, avg. samples / sec: 66342.01
Iteration:   2140, Loss function: 4.620, Average Loss: 4.397, avg. samples / sec: 66251.82
Iteration:   2140, Loss function: 5.666, Average Loss: 4.403, avg. samples / sec: 66382.51
Iteration:   2140, Loss function: 4.870, Average Loss: 4.438, avg. samples / sec: 66274.47
Iteration:   2140, Loss function: 4.905, Average Loss: 4.411, avg. samples / sec: 66384.95
Iteration:   2140, Loss function: 4.804, Average Loss: 4.406, avg. samples / sec: 66351.23
Iteration:   2140, Loss function: 4.335, Average Loss: 4.403, avg. samples / sec: 66485.36
Iteration:   2140, Loss function: 3.358, Average Loss: 4.406, avg. samples / sec: 66335.96
Iteration:   2140, Loss function: 3.789, Average Loss: 4.418, avg. samples / sec: 66317.26
Iteration:   2140, Loss function: 5.032, Average Loss: 4.389, avg. samples / sec: 66421.90
Iteration:   2140, Loss function: 5.160, Average Loss: 4.375, avg. samples / sec: 66336.21
Iteration:   2140, Loss function: 3.773, Average Loss: 4.389, avg. samples / sec: 66265.28
Iteration:   2140, Loss function: 3.039, Average Loss: 4.394, avg. samples / sec: 66227.56
Iteration:   2140, Loss function: 2.730, Average Loss: 4.404, avg. samples / sec: 66340.83
Iteration:   2140, Loss function: 3.819, Average Loss: 4.392, avg. samples / sec: 66246.80
Iteration:   2160, Loss function: 4.240, Average Loss: 4.394, avg. samples / sec: 66555.88
Iteration:   2160, Loss function: 5.315, Average Loss: 4.419, avg. samples / sec: 66454.45
Iteration:   2160, Loss function: 3.687, Average Loss: 4.437, avg. samples / sec: 66542.78
Iteration:   2160, Loss function: 3.904, Average Loss: 4.415, avg. samples / sec: 66405.60
Iteration:   2160, Loss function: 3.944, Average Loss: 4.400, avg. samples / sec: 66514.29
Iteration:   2160, Loss function: 3.635, Average Loss: 4.368, avg. samples / sec: 66445.23
Iteration:   2160, Loss function: 4.473, Average Loss: 4.384, avg. samples / sec: 66385.70
Iteration:   2160, Loss function: 3.043, Average Loss: 4.420, avg. samples / sec: 66447.90
Iteration:   2160, Loss function: 3.276, Average Loss: 4.399, avg. samples / sec: 66291.71
Iteration:   2160, Loss function: 4.417, Average Loss: 4.404, avg. samples / sec: 66386.58
Iteration:   2160, Loss function: 2.639, Average Loss: 4.369, avg. samples / sec: 66523.33
Iteration:   2160, Loss function: 5.505, Average Loss: 4.415, avg. samples / sec: 66459.77
Iteration:   2160, Loss function: 4.368, Average Loss: 4.368, avg. samples / sec: 66417.24
Iteration:   2160, Loss function: 3.966, Average Loss: 4.389, avg. samples / sec: 66494.24
Iteration:   2160, Loss function: 3.331, Average Loss: 4.418, avg. samples / sec: 66371.16
Iteration:   2160, Loss function: 4.428, Average Loss: 4.405, avg. samples / sec: 66440.00
Iteration:   2160, Loss function: 3.630, Average Loss: 4.399, avg. samples / sec: 66398.59
Iteration:   2160, Loss function: 4.144, Average Loss: 4.390, avg. samples / sec: 66600.64
Iteration:   2160, Loss function: 4.185, Average Loss: 4.385, avg. samples / sec: 66495.33
Iteration:   2160, Loss function: 3.292, Average Loss: 4.406, avg. samples / sec: 66381.86
Iteration:   2160, Loss function: 4.443, Average Loss: 4.415, avg. samples / sec: 66286.00
Iteration:   2160, Loss function: 3.807, Average Loss: 4.393, avg. samples / sec: 66470.59
Iteration:   2160, Loss function: 4.190, Average Loss: 4.379, avg. samples / sec: 66291.74
Iteration:   2160, Loss function: 4.705, Average Loss: 4.395, avg. samples / sec: 66359.32
Iteration:   2160, Loss function: 4.436, Average Loss: 4.403, avg. samples / sec: 66402.94
Iteration:   2160, Loss function: 3.437, Average Loss: 4.379, avg. samples / sec: 66332.40
Iteration:   2160, Loss function: 5.132, Average Loss: 4.405, avg. samples / sec: 66343.39
Iteration:   2160, Loss function: 2.682, Average Loss: 4.382, avg. samples / sec: 66287.94
Iteration:   2160, Loss function: 4.297, Average Loss: 4.399, avg. samples / sec: 66419.34
Iteration:   2160, Loss function: 4.336, Average Loss: 4.419, avg. samples / sec: 66327.62
:::MLL 1558651579.353 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558651579.354 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 3.746, Average Loss: 4.413, avg. samples / sec: 66097.35
Iteration:   2180, Loss function: 3.756, Average Loss: 4.391, avg. samples / sec: 66177.09
Iteration:   2180, Loss function: 5.460, Average Loss: 4.387, avg. samples / sec: 66179.98
Iteration:   2180, Loss function: 5.173, Average Loss: 4.391, avg. samples / sec: 66043.15
Iteration:   2180, Loss function: 4.344, Average Loss: 4.394, avg. samples / sec: 66161.00
Iteration:   2180, Loss function: 4.204, Average Loss: 4.402, avg. samples / sec: 66159.63
Iteration:   2180, Loss function: 3.725, Average Loss: 4.412, avg. samples / sec: 66079.91
Iteration:   2180, Loss function: 5.414, Average Loss: 4.376, avg. samples / sec: 66179.39
Iteration:   2180, Loss function: 4.161, Average Loss: 4.380, avg. samples / sec: 66193.94
Iteration:   2180, Loss function: 3.451, Average Loss: 4.408, avg. samples / sec: 65990.11
Iteration:   2180, Loss function: 4.527, Average Loss: 4.396, avg. samples / sec: 66152.92
Iteration:   2180, Loss function: 4.551, Average Loss: 4.361, avg. samples / sec: 66090.07
Iteration:   2180, Loss function: 4.788, Average Loss: 4.378, avg. samples / sec: 66171.99
Iteration:   2180, Loss function: 4.157, Average Loss: 4.363, avg. samples / sec: 66025.48
Iteration:   2180, Loss function: 3.613, Average Loss: 4.400, avg. samples / sec: 66101.73
Iteration:   2180, Loss function: 2.984, Average Loss: 4.398, avg. samples / sec: 66040.55
Iteration:   2180, Loss function: 4.069, Average Loss: 4.397, avg. samples / sec: 66064.36
Iteration:   2180, Loss function: 2.946, Average Loss: 4.363, avg. samples / sec: 66076.59
Iteration:   2180, Loss function: 3.265, Average Loss: 4.429, avg. samples / sec: 65983.22
Iteration:   2180, Loss function: 4.769, Average Loss: 4.407, avg. samples / sec: 66039.22
Iteration:   2180, Loss function: 3.491, Average Loss: 4.409, avg. samples / sec: 66061.78
Iteration:   2180, Loss function: 3.959, Average Loss: 4.377, avg. samples / sec: 65981.43
Iteration:   2180, Loss function: 4.826, Average Loss: 4.411, avg. samples / sec: 66074.24
Iteration:   2180, Loss function: 3.777, Average Loss: 4.414, avg. samples / sec: 66185.30
Iteration:   2180, Loss function: 3.327, Average Loss: 4.387, avg. samples / sec: 66043.21
Iteration:   2180, Loss function: 4.630, Average Loss: 4.379, avg. samples / sec: 66049.99
Iteration:   2180, Loss function: 5.083, Average Loss: 4.392, avg. samples / sec: 66119.65
Iteration:   2180, Loss function: 3.308, Average Loss: 4.399, avg. samples / sec: 66079.84
Iteration:   2180, Loss function: 4.041, Average Loss: 4.403, avg. samples / sec: 66100.80
Iteration:   2180, Loss function: 4.664, Average Loss: 4.389, avg. samples / sec: 66015.12
Iteration:   2200, Loss function: 4.388, Average Loss: 4.388, avg. samples / sec: 66647.66
Iteration:   2200, Loss function: 3.443, Average Loss: 4.387, avg. samples / sec: 66556.04
Iteration:   2200, Loss function: 3.604, Average Loss: 4.358, avg. samples / sec: 66578.90
Iteration:   2200, Loss function: 3.849, Average Loss: 4.360, avg. samples / sec: 66555.25
Iteration:   2200, Loss function: 2.841, Average Loss: 4.384, avg. samples / sec: 66449.97
Iteration:   2200, Loss function: 4.226, Average Loss: 4.392, avg. samples / sec: 66552.36
Iteration:   2200, Loss function: 4.505, Average Loss: 4.383, avg. samples / sec: 66467.74
Iteration:   2200, Loss function: 4.437, Average Loss: 4.376, avg. samples / sec: 66518.81
Iteration:   2200, Loss function: 2.934, Average Loss: 4.411, avg. samples / sec: 66410.51
Iteration:   2200, Loss function: 4.438, Average Loss: 4.372, avg. samples / sec: 66543.87
Iteration:   2200, Loss function: 3.399, Average Loss: 4.410, avg. samples / sec: 66456.51
Iteration:   2200, Loss function: 4.353, Average Loss: 4.397, avg. samples / sec: 66576.19
Iteration:   2200, Loss function: 4.857, Average Loss: 4.387, avg. samples / sec: 66570.28
Iteration:   2200, Loss function: 3.716, Average Loss: 4.403, avg. samples / sec: 66510.43
Iteration:   2200, Loss function: 3.804, Average Loss: 4.377, avg. samples / sec: 66431.58
Iteration:   2200, Loss function: 3.526, Average Loss: 4.391, avg. samples / sec: 66564.21
Iteration:   2200, Loss function: 3.332, Average Loss: 4.422, avg. samples / sec: 66476.08
Iteration:   2200, Loss function: 4.059, Average Loss: 4.396, avg. samples / sec: 66448.81
Iteration:   2200, Loss function: 2.764, Average Loss: 4.392, avg. samples / sec: 66397.96
Iteration:   2200, Loss function: 4.202, Average Loss: 4.400, avg. samples / sec: 66452.44
Iteration:   2200, Loss function: 3.347, Average Loss: 4.403, avg. samples / sec: 66465.10
Iteration:   2200, Loss function: 3.394, Average Loss: 4.383, avg. samples / sec: 66551.10
Iteration:   2200, Loss function: 4.436, Average Loss: 4.401, avg. samples / sec: 66450.91
Iteration:   2200, Loss function: 5.598, Average Loss: 4.375, avg. samples / sec: 66478.33
Iteration:   2200, Loss function: 5.147, Average Loss: 4.394, avg. samples / sec: 66413.05
Iteration:   2200, Loss function: 3.911, Average Loss: 4.393, avg. samples / sec: 66415.14
Iteration:   2200, Loss function: 3.416, Average Loss: 4.377, avg. samples / sec: 66434.18
Iteration:   2200, Loss function: 3.783, Average Loss: 4.402, avg. samples / sec: 66455.61
Iteration:   2200, Loss function: 4.436, Average Loss: 4.353, avg. samples / sec: 66342.61
Iteration:   2200, Loss function: 3.678, Average Loss: 4.373, avg. samples / sec: 66309.64
Iteration:   2220, Loss function: 4.052, Average Loss: 4.359, avg. samples / sec: 66376.98
Iteration:   2220, Loss function: 3.935, Average Loss: 4.409, avg. samples / sec: 66408.76
Iteration:   2220, Loss function: 2.713, Average Loss: 4.350, avg. samples / sec: 66351.10
Iteration:   2220, Loss function: 4.437, Average Loss: 4.366, avg. samples / sec: 66406.47
Iteration:   2220, Loss function: 5.057, Average Loss: 4.385, avg. samples / sec: 66184.46
Iteration:   2220, Loss function: 4.928, Average Loss: 4.379, avg. samples / sec: 66250.57
Iteration:   2220, Loss function: 4.881, Average Loss: 4.400, avg. samples / sec: 66412.54
Iteration:   2220, Loss function: 4.240, Average Loss: 4.394, avg. samples / sec: 66445.17
Iteration:   2220, Loss function: 4.390, Average Loss: 4.420, avg. samples / sec: 66395.59
Iteration:   2220, Loss function: 4.989, Average Loss: 4.370, avg. samples / sec: 66427.19
Iteration:   2220, Loss function: 3.634, Average Loss: 4.373, avg. samples / sec: 66478.96
Iteration:   2220, Loss function: 3.177, Average Loss: 4.386, avg. samples / sec: 66376.26
Iteration:   2220, Loss function: 5.843, Average Loss: 4.401, avg. samples / sec: 66347.64
Iteration:   2220, Loss function: 3.531, Average Loss: 4.377, avg. samples / sec: 66391.89
Iteration:   2220, Loss function: 3.966, Average Loss: 4.384, avg. samples / sec: 66313.51
Iteration:   2220, Loss function: 3.892, Average Loss: 4.395, avg. samples / sec: 66392.52
Iteration:   2220, Loss function: 4.230, Average Loss: 4.377, avg. samples / sec: 66232.02
Iteration:   2220, Loss function: 4.331, Average Loss: 4.404, avg. samples / sec: 66290.37
Iteration:   2220, Loss function: 3.486, Average Loss: 4.394, avg. samples / sec: 66347.67
Iteration:   2220, Loss function: 4.291, Average Loss: 4.385, avg. samples / sec: 66242.79
Iteration:   2220, Loss function: 3.363, Average Loss: 4.395, avg. samples / sec: 66339.33
Iteration:   2220, Loss function: 5.397, Average Loss: 4.376, avg. samples / sec: 66304.43
Iteration:   2220, Loss function: 4.630, Average Loss: 4.386, avg. samples / sec: 66259.17
Iteration:   2220, Loss function: 4.763, Average Loss: 4.373, avg. samples / sec: 66225.14
Iteration:   2220, Loss function: 3.846, Average Loss: 4.344, avg. samples / sec: 66390.86
Iteration:   2220, Loss function: 4.373, Average Loss: 4.384, avg. samples / sec: 66211.79
Iteration:   2220, Loss function: 3.189, Average Loss: 4.373, avg. samples / sec: 66301.84
Iteration:   2220, Loss function: 4.728, Average Loss: 4.385, avg. samples / sec: 66229.09
Iteration:   2220, Loss function: 3.742, Average Loss: 4.395, avg. samples / sec: 66294.86
Iteration:   2220, Loss function: 5.324, Average Loss: 4.378, avg. samples / sec: 66109.54
:::MLL 1558651581.128 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558651581.128 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 3.804, Average Loss: 4.371, avg. samples / sec: 66225.17
Iteration:   2240, Loss function: 4.509, Average Loss: 4.369, avg. samples / sec: 66310.64
Iteration:   2240, Loss function: 3.072, Average Loss: 4.370, avg. samples / sec: 66323.78
Iteration:   2240, Loss function: 4.305, Average Loss: 4.379, avg. samples / sec: 66384.55
Iteration:   2240, Loss function: 5.233, Average Loss: 4.381, avg. samples / sec: 66256.55
Iteration:   2240, Loss function: 4.778, Average Loss: 4.391, avg. samples / sec: 66149.38
Iteration:   2240, Loss function: 4.947, Average Loss: 4.402, avg. samples / sec: 66097.70
Iteration:   2240, Loss function: 3.248, Average Loss: 4.412, avg. samples / sec: 66170.66
Iteration:   2240, Loss function: 4.560, Average Loss: 4.366, avg. samples / sec: 66293.45
Iteration:   2240, Loss function: 4.092, Average Loss: 4.364, avg. samples / sec: 66303.97
Iteration:   2240, Loss function: 3.222, Average Loss: 4.396, avg. samples / sec: 66157.02
Iteration:   2240, Loss function: 3.747, Average Loss: 4.376, avg. samples / sec: 66208.37
Iteration:   2240, Loss function: 2.586, Average Loss: 4.381, avg. samples / sec: 66284.60
Iteration:   2240, Loss function: 4.085, Average Loss: 4.386, avg. samples / sec: 66084.12
Iteration:   2240, Loss function: 4.209, Average Loss: 4.345, avg. samples / sec: 66040.02
Iteration:   2240, Loss function: 5.175, Average Loss: 4.392, avg. samples / sec: 66142.15
Iteration:   2240, Loss function: 4.448, Average Loss: 4.378, avg. samples / sec: 66184.95
Iteration:   2240, Loss function: 4.368, Average Loss: 4.363, avg. samples / sec: 66075.13
Iteration:   2240, Loss function: 3.647, Average Loss: 4.371, avg. samples / sec: 66281.01
Iteration:   2240, Loss function: 3.934, Average Loss: 4.361, avg. samples / sec: 65998.95
Iteration:   2240, Loss function: 5.454, Average Loss: 4.391, avg. samples / sec: 66045.16
Iteration:   2240, Loss function: 3.535, Average Loss: 4.391, avg. samples / sec: 66192.07
Iteration:   2240, Loss function: 4.593, Average Loss: 4.402, avg. samples / sec: 66095.43
Iteration:   2240, Loss function: 4.692, Average Loss: 4.336, avg. samples / sec: 66117.76
Iteration:   2240, Loss function: 3.458, Average Loss: 4.386, avg. samples / sec: 66104.24
Iteration:   2240, Loss function: 4.551, Average Loss: 4.380, avg. samples / sec: 66022.20
Iteration:   2240, Loss function: 4.046, Average Loss: 4.356, avg. samples / sec: 65900.59
Iteration:   2240, Loss function: 3.927, Average Loss: 4.380, avg. samples / sec: 66035.32
Iteration:   2240, Loss function: 3.974, Average Loss: 4.389, avg. samples / sec: 66010.76
Iteration:   2240, Loss function: 3.829, Average Loss: 4.366, avg. samples / sec: 65926.49
Iteration:   2260, Loss function: 4.514, Average Loss: 4.398, avg. samples / sec: 66517.93
Iteration:   2260, Loss function: 5.086, Average Loss: 4.377, avg. samples / sec: 66340.89
Iteration:   2260, Loss function: 4.361, Average Loss: 4.413, avg. samples / sec: 66324.00
Iteration:   2260, Loss function: 3.280, Average Loss: 4.382, avg. samples / sec: 66383.04
Iteration:   2260, Loss function: 5.378, Average Loss: 4.353, avg. samples / sec: 66493.89
Iteration:   2260, Loss function: 5.442, Average Loss: 4.366, avg. samples / sec: 66196.80
Iteration:   2260, Loss function: 4.671, Average Loss: 4.368, avg. samples / sec: 66411.48
Iteration:   2260, Loss function: 3.937, Average Loss: 4.365, avg. samples / sec: 66198.20
Iteration:   2260, Loss function: 4.272, Average Loss: 4.388, avg. samples / sec: 66416.64
Iteration:   2260, Loss function: 4.089, Average Loss: 4.367, avg. samples / sec: 66184.02
Iteration:   2260, Loss function: 4.356, Average Loss: 4.380, avg. samples / sec: 66510.43
Iteration:   2260, Loss function: 4.524, Average Loss: 4.373, avg. samples / sec: 66302.78
Iteration:   2260, Loss function: 3.609, Average Loss: 4.356, avg. samples / sec: 66549.25
Iteration:   2260, Loss function: 3.961, Average Loss: 4.389, avg. samples / sec: 66359.16
Iteration:   2260, Loss function: 3.610, Average Loss: 4.376, avg. samples / sec: 66410.07
Iteration:   2260, Loss function: 3.551, Average Loss: 4.395, avg. samples / sec: 66230.93
Iteration:   2260, Loss function: 5.172, Average Loss: 4.361, avg. samples / sec: 66336.64
Iteration:   2260, Loss function: 3.733, Average Loss: 4.382, avg. samples / sec: 66249.76
Iteration:   2260, Loss function: 4.350, Average Loss: 4.382, avg. samples / sec: 66206.47
Iteration:   2260, Loss function: 3.808, Average Loss: 4.332, avg. samples / sec: 66375.45
Iteration:   2260, Loss function: 3.460, Average Loss: 4.378, avg. samples / sec: 66365.54
Iteration:   2260, Loss function: 4.854, Average Loss: 4.396, avg. samples / sec: 66241.73
Iteration:   2260, Loss function: 4.530, Average Loss: 4.357, avg. samples / sec: 66277.12
Iteration:   2260, Loss function: 2.871, Average Loss: 4.339, avg. samples / sec: 66226.60
Iteration:   2260, Loss function: 5.104, Average Loss: 4.388, avg. samples / sec: 66290.59
Iteration:   2260, Loss function: 3.383, Average Loss: 4.375, avg. samples / sec: 66105.66
Iteration:   2260, Loss function: 3.860, Average Loss: 4.368, avg. samples / sec: 66121.92
Iteration:   2260, Loss function: 3.830, Average Loss: 4.361, avg. samples / sec: 66146.19
Iteration:   2260, Loss function: 3.962, Average Loss: 4.381, avg. samples / sec: 66211.07
Iteration:   2260, Loss function: 4.672, Average Loss: 4.375, avg. samples / sec: 66277.34
Iteration:   2280, Loss function: 5.250, Average Loss: 4.367, avg. samples / sec: 66612.06
Iteration:   2280, Loss function: 3.939, Average Loss: 4.379, avg. samples / sec: 66658.85
Iteration:   2280, Loss function: 4.131, Average Loss: 4.353, avg. samples / sec: 66630.33
Iteration:   2280, Loss function: 4.715, Average Loss: 4.391, avg. samples / sec: 66451.88
Iteration:   2280, Loss function: 4.573, Average Loss: 4.393, avg. samples / sec: 66623.78
Iteration:   2280, Loss function: 3.234, Average Loss: 4.393, avg. samples / sec: 66564.02
Iteration:   2280, Loss function: 4.401, Average Loss: 4.348, avg. samples / sec: 66499.04
Iteration:   2280, Loss function: 4.436, Average Loss: 4.348, avg. samples / sec: 66535.08
Iteration:   2280, Loss function: 4.414, Average Loss: 4.362, avg. samples / sec: 66510.90
Iteration:   2280, Loss function: 3.417, Average Loss: 4.370, avg. samples / sec: 66508.33
Iteration:   2280, Loss function: 4.542, Average Loss: 4.387, avg. samples / sec: 66476.17
Iteration:   2280, Loss function: 5.337, Average Loss: 4.402, avg. samples / sec: 66446.89
Iteration:   2280, Loss function: 4.176, Average Loss: 4.358, avg. samples / sec: 66451.00
Iteration:   2280, Loss function: 4.917, Average Loss: 4.377, avg. samples / sec: 66418.62
Iteration:   2280, Loss function: 4.403, Average Loss: 4.363, avg. samples / sec: 66621.26
Iteration:   2280, Loss function: 4.237, Average Loss: 4.332, avg. samples / sec: 66510.84
Iteration:   2280, Loss function: 4.083, Average Loss: 4.371, avg. samples / sec: 66643.19
Iteration:   2280, Loss function: 5.243, Average Loss: 4.383, avg. samples / sec: 66515.23
Iteration:   2280, Loss function: 4.032, Average Loss: 4.354, avg. samples / sec: 66574.62
Iteration:   2280, Loss function: 4.556, Average Loss: 4.370, avg. samples / sec: 66603.41
Iteration:   2280, Loss function: 3.408, Average Loss: 4.385, avg. samples / sec: 66435.46
Iteration:   2280, Loss function: 4.068, Average Loss: 4.377, avg. samples / sec: 66488.21
Iteration:   2280, Loss function: 4.120, Average Loss: 4.374, avg. samples / sec: 66361.19
Iteration:   2280, Loss function: 5.495, Average Loss: 4.380, avg. samples / sec: 66524.18
Iteration:   2280, Loss function: 4.015, Average Loss: 4.370, avg. samples / sec: 66453.26
Iteration:   2280, Loss function: 3.661, Average Loss: 4.377, avg. samples / sec: 66385.86
Iteration:   2280, Loss function: 4.563, Average Loss: 4.364, avg. samples / sec: 66333.52
Iteration:   2280, Loss function: 3.917, Average Loss: 4.335, avg. samples / sec: 66454.67
Iteration:   2280, Loss function: 4.090, Average Loss: 4.370, avg. samples / sec: 66416.33
Iteration:   2280, Loss function: 4.625, Average Loss: 4.359, avg. samples / sec: 66434.15
:::MLL 1558651582.306 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.73 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.30s)
DONE (t=0.31s)
DONE (t=0.30s)
DONE (t=0.31s)
DONE (t=0.31s)
DONE (t=0.31s)
DONE (t=0.31s)
DONE (t=0.31s)
DONE (t=0.31s)
DONE (t=0.31s)
DONE (t=0.32s)
DONE (t=0.32s)
DONE (t=0.32s)
DONE (t=2.15s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.14755
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.28300
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.14222
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03809
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.15475
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.23956
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.16497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.23939
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.25135
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.39481
Current AP: 0.14755 AP goal: 0.23000
:::MLL 1558651585.547 eval_accuracy: {"value": 0.1475521869947459, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558651585.594 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558651585.600 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558651585.601 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 3.419, Average Loss: 4.367, avg. samples / sec: 8703.18
Iteration:   2300, Loss function: 4.118, Average Loss: 4.362, avg. samples / sec: 8703.30
Iteration:   2300, Loss function: 4.077, Average Loss: 4.380, avg. samples / sec: 8698.83
Iteration:   2300, Loss function: 3.301, Average Loss: 4.373, avg. samples / sec: 8701.54
Iteration:   2300, Loss function: 4.963, Average Loss: 4.360, avg. samples / sec: 8699.79
Iteration:   2300, Loss function: 3.592, Average Loss: 4.383, avg. samples / sec: 8698.81
Iteration:   2300, Loss function: 3.904, Average Loss: 4.347, avg. samples / sec: 8699.72
Iteration:   2300, Loss function: 3.920, Average Loss: 4.356, avg. samples / sec: 8703.41
Iteration:   2300, Loss function: 3.596, Average Loss: 4.374, avg. samples / sec: 8699.99
Iteration:   2300, Loss function: 4.238, Average Loss: 4.370, avg. samples / sec: 8699.40
Iteration:   2300, Loss function: 3.104, Average Loss: 4.350, avg. samples / sec: 8698.73
Iteration:   2300, Loss function: 4.167, Average Loss: 4.337, avg. samples / sec: 8701.78
Iteration:   2300, Loss function: 4.083, Average Loss: 4.365, avg. samples / sec: 8702.07
Iteration:   2300, Loss function: 3.981, Average Loss: 4.329, avg. samples / sec: 8699.41
Iteration:   2300, Loss function: 3.393, Average Loss: 4.359, avg. samples / sec: 8699.12
Iteration:   2300, Loss function: 5.214, Average Loss: 4.368, avg. samples / sec: 8699.13
Iteration:   2300, Loss function: 3.399, Average Loss: 4.395, avg. samples / sec: 8698.69
Iteration:   2300, Loss function: 3.628, Average Loss: 4.354, avg. samples / sec: 8698.22
Iteration:   2300, Loss function: 3.981, Average Loss: 4.366, avg. samples / sec: 8695.69
Iteration:   2300, Loss function: 4.724, Average Loss: 4.347, avg. samples / sec: 8697.21
Iteration:   2300, Loss function: 4.944, Average Loss: 4.349, avg. samples / sec: 8696.03
Iteration:   2300, Loss function: 4.073, Average Loss: 4.362, avg. samples / sec: 8698.58
Iteration:   2300, Loss function: 4.659, Average Loss: 4.387, avg. samples / sec: 8696.70
Iteration:   2300, Loss function: 4.828, Average Loss: 4.385, avg. samples / sec: 8697.87
Iteration:   2300, Loss function: 4.379, Average Loss: 4.365, avg. samples / sec: 8697.44
Iteration:   2300, Loss function: 4.303, Average Loss: 4.375, avg. samples / sec: 8697.98
Iteration:   2300, Loss function: 5.720, Average Loss: 4.393, avg. samples / sec: 8695.57
Iteration:   2300, Loss function: 3.778, Average Loss: 4.372, avg. samples / sec: 8696.72
Iteration:   2300, Loss function: 4.736, Average Loss: 4.392, avg. samples / sec: 8695.23
Iteration:   2300, Loss function: 4.052, Average Loss: 4.373, avg. samples / sec: 8695.75
:::MLL 1558651586.260 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558651586.261 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 3.389, Average Loss: 4.362, avg. samples / sec: 65465.71
Iteration:   2320, Loss function: 4.780, Average Loss: 4.355, avg. samples / sec: 65519.24
Iteration:   2320, Loss function: 4.264, Average Loss: 4.365, avg. samples / sec: 65549.02
Iteration:   2320, Loss function: 4.039, Average Loss: 4.368, avg. samples / sec: 65409.31
Iteration:   2320, Loss function: 3.664, Average Loss: 4.376, avg. samples / sec: 65441.78
Iteration:   2320, Loss function: 3.765, Average Loss: 4.374, avg. samples / sec: 65375.48
Iteration:   2320, Loss function: 4.502, Average Loss: 4.381, avg. samples / sec: 65587.42
Iteration:   2320, Loss function: 4.344, Average Loss: 4.361, avg. samples / sec: 65455.79
Iteration:   2320, Loss function: 5.038, Average Loss: 4.341, avg. samples / sec: 65382.64
Iteration:   2320, Loss function: 4.124, Average Loss: 4.328, avg. samples / sec: 65396.05
Iteration:   2320, Loss function: 3.838, Average Loss: 4.379, avg. samples / sec: 65525.55
Iteration:   2320, Loss function: 4.451, Average Loss: 4.343, avg. samples / sec: 65364.56
Iteration:   2320, Loss function: 5.164, Average Loss: 4.358, avg. samples / sec: 65381.33
Iteration:   2320, Loss function: 4.143, Average Loss: 4.356, avg. samples / sec: 65456.40
Iteration:   2320, Loss function: 4.325, Average Loss: 4.349, avg. samples / sec: 65413.26
Iteration:   2320, Loss function: 3.514, Average Loss: 4.358, avg. samples / sec: 65407.07
Iteration:   2320, Loss function: 3.986, Average Loss: 4.361, avg. samples / sec: 65233.71
Iteration:   2320, Loss function: 4.231, Average Loss: 4.375, avg. samples / sec: 65236.48
Iteration:   2320, Loss function: 3.915, Average Loss: 4.371, avg. samples / sec: 65559.23
Iteration:   2320, Loss function: 3.970, Average Loss: 4.365, avg. samples / sec: 65471.09
Iteration:   2320, Loss function: 4.790, Average Loss: 4.360, avg. samples / sec: 65295.73
Iteration:   2320, Loss function: 4.494, Average Loss: 4.389, avg. samples / sec: 65486.21
Iteration:   2320, Loss function: 5.004, Average Loss: 4.389, avg. samples / sec: 65446.95
Iteration:   2320, Loss function: 3.949, Average Loss: 4.344, avg. samples / sec: 65341.47
Iteration:   2320, Loss function: 4.664, Average Loss: 4.393, avg. samples / sec: 65285.90
Iteration:   2320, Loss function: 3.770, Average Loss: 4.364, avg. samples / sec: 65414.14
Iteration:   2320, Loss function: 4.215, Average Loss: 4.379, avg. samples / sec: 65403.27
Iteration:   2320, Loss function: 4.158, Average Loss: 4.351, avg. samples / sec: 65224.29
Iteration:   2320, Loss function: 4.312, Average Loss: 4.341, avg. samples / sec: 65323.99
Iteration:   2320, Loss function: 4.256, Average Loss: 4.339, avg. samples / sec: 65239.35
Iteration:   2340, Loss function: 4.940, Average Loss: 4.340, avg. samples / sec: 65575.09
Iteration:   2340, Loss function: 4.082, Average Loss: 4.339, avg. samples / sec: 65559.75
Iteration:   2340, Loss function: 3.678, Average Loss: 4.360, avg. samples / sec: 65268.18
Iteration:   2340, Loss function: 4.413, Average Loss: 4.358, avg. samples / sec: 65472.97
Iteration:   2340, Loss function: 3.118, Average Loss: 4.360, avg. samples / sec: 65280.63
Iteration:   2340, Loss function: 3.035, Average Loss: 4.392, avg. samples / sec: 65461.54
Iteration:   2340, Loss function: 4.655, Average Loss: 4.364, avg. samples / sec: 65375.54
Iteration:   2340, Loss function: 4.601, Average Loss: 4.348, avg. samples / sec: 65352.68
Iteration:   2340, Loss function: 3.700, Average Loss: 4.352, avg. samples / sec: 65278.27
Iteration:   2340, Loss function: 4.320, Average Loss: 4.339, avg. samples / sec: 65331.60
Iteration:   2340, Loss function: 3.679, Average Loss: 4.353, avg. samples / sec: 65123.23
Iteration:   2340, Loss function: 3.343, Average Loss: 4.378, avg. samples / sec: 65247.05
Iteration:   2340, Loss function: 5.963, Average Loss: 4.341, avg. samples / sec: 65281.78
Iteration:   2340, Loss function: 3.917, Average Loss: 4.353, avg. samples / sec: 65334.81
Iteration:   2340, Loss function: 4.792, Average Loss: 4.337, avg. samples / sec: 65408.80
Iteration:   2340, Loss function: 4.560, Average Loss: 4.351, avg. samples / sec: 65338.38
Iteration:   2340, Loss function: 4.306, Average Loss: 4.370, avg. samples / sec: 65228.30
Iteration:   2340, Loss function: 5.044, Average Loss: 4.384, avg. samples / sec: 65364.50
Iteration:   2340, Loss function: 3.535, Average Loss: 4.325, avg. samples / sec: 65251.44
Iteration:   2340, Loss function: 5.436, Average Loss: 4.347, avg. samples / sec: 65375.39
Iteration:   2340, Loss function: 3.688, Average Loss: 4.358, avg. samples / sec: 65320.06
Iteration:   2340, Loss function: 4.225, Average Loss: 4.348, avg. samples / sec: 65052.40
Iteration:   2340, Loss function: 3.561, Average Loss: 4.387, avg. samples / sec: 65317.91
Iteration:   2340, Loss function: 3.226, Average Loss: 4.353, avg. samples / sec: 65271.23
Iteration:   2340, Loss function: 3.978, Average Loss: 4.373, avg. samples / sec: 65317.33
Iteration:   2340, Loss function: 3.265, Average Loss: 4.367, avg. samples / sec: 65106.92
Iteration:   2340, Loss function: 5.060, Average Loss: 4.376, avg. samples / sec: 65185.73
Iteration:   2340, Loss function: 4.183, Average Loss: 4.365, avg. samples / sec: 65234.07
Iteration:   2340, Loss function: 3.812, Average Loss: 4.354, avg. samples / sec: 65262.31
Iteration:   2340, Loss function: 3.258, Average Loss: 4.344, avg. samples / sec: 65189.41
Iteration:   2360, Loss function: 3.242, Average Loss: 4.359, avg. samples / sec: 65398.78
Iteration:   2360, Loss function: 4.047, Average Loss: 4.360, avg. samples / sec: 65324.21
Iteration:   2360, Loss function: 4.203, Average Loss: 4.335, avg. samples / sec: 65263.85
Iteration:   2360, Loss function: 3.715, Average Loss: 4.336, avg. samples / sec: 65420.36
Iteration:   2360, Loss function: 4.438, Average Loss: 4.364, avg. samples / sec: 65497.32
Iteration:   2360, Loss function: 3.711, Average Loss: 4.341, avg. samples / sec: 65422.55
Iteration:   2360, Loss function: 4.080, Average Loss: 4.347, avg. samples / sec: 65334.84
Iteration:   2360, Loss function: 4.035, Average Loss: 4.334, avg. samples / sec: 65368.66
Iteration:   2360, Loss function: 4.413, Average Loss: 4.329, avg. samples / sec: 65402.21
Iteration:   2360, Loss function: 4.696, Average Loss: 4.343, avg. samples / sec: 65401.66
Iteration:   2360, Loss function: 3.496, Average Loss: 4.385, avg. samples / sec: 65263.79
Iteration:   2360, Loss function: 4.691, Average Loss: 4.384, avg. samples / sec: 65381.45
Iteration:   2360, Loss function: 4.562, Average Loss: 4.361, avg. samples / sec: 65187.60
Iteration:   2360, Loss function: 4.726, Average Loss: 4.349, avg. samples / sec: 65283.14
Iteration:   2360, Loss function: 4.833, Average Loss: 4.340, avg. samples / sec: 65261.50
Iteration:   2360, Loss function: 4.647, Average Loss: 4.348, avg. samples / sec: 65302.11
Iteration:   2360, Loss function: 5.352, Average Loss: 4.364, avg. samples / sec: 65296.18
Iteration:   2360, Loss function: 4.386, Average Loss: 4.374, avg. samples / sec: 65256.99
Iteration:   2360, Loss function: 3.435, Average Loss: 4.349, avg. samples / sec: 65162.13
Iteration:   2360, Loss function: 3.889, Average Loss: 4.367, avg. samples / sec: 65371.48
Iteration:   2360, Loss function: 5.386, Average Loss: 4.348, avg. samples / sec: 65262.16
Iteration:   2360, Loss function: 3.744, Average Loss: 4.333, avg. samples / sec: 65100.57
Iteration:   2360, Loss function: 5.280, Average Loss: 4.354, avg. samples / sec: 65300.14
Iteration:   2360, Loss function: 3.299, Average Loss: 4.331, avg. samples / sec: 65229.15
Iteration:   2360, Loss function: 3.760, Average Loss: 4.339, avg. samples / sec: 65399.69
Iteration:   2360, Loss function: 3.048, Average Loss: 4.379, avg. samples / sec: 65271.87
Iteration:   2360, Loss function: 4.356, Average Loss: 4.371, avg. samples / sec: 65350.89
Iteration:   2360, Loss function: 2.997, Average Loss: 4.351, avg. samples / sec: 65355.89
Iteration:   2360, Loss function: 3.016, Average Loss: 4.339, avg. samples / sec: 65254.40
Iteration:   2360, Loss function: 3.910, Average Loss: 4.362, avg. samples / sec: 65306.10
:::MLL 1558651588.061 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558651588.062 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 3.518, Average Loss: 4.335, avg. samples / sec: 65174.27
Iteration:   2380, Loss function: 4.055, Average Loss: 4.356, avg. samples / sec: 65101.23
Iteration:   2380, Loss function: 4.732, Average Loss: 4.330, avg. samples / sec: 65160.44
Iteration:   2380, Loss function: 3.949, Average Loss: 4.330, avg. samples / sec: 65236.94
Iteration:   2380, Loss function: 3.649, Average Loss: 4.372, avg. samples / sec: 65242.07
Iteration:   2380, Loss function: 5.111, Average Loss: 4.330, avg. samples / sec: 65074.03
Iteration:   2380, Loss function: 4.104, Average Loss: 4.345, avg. samples / sec: 65088.85
Iteration:   2380, Loss function: 5.088, Average Loss: 4.336, avg. samples / sec: 65098.17
Iteration:   2380, Loss function: 3.959, Average Loss: 4.336, avg. samples / sec: 65132.26
Iteration:   2380, Loss function: 4.019, Average Loss: 4.332, avg. samples / sec: 65031.45
Iteration:   2380, Loss function: 3.933, Average Loss: 4.358, avg. samples / sec: 65004.93
Iteration:   2380, Loss function: 3.264, Average Loss: 4.326, avg. samples / sec: 65041.20
Iteration:   2380, Loss function: 3.837, Average Loss: 4.344, avg. samples / sec: 65077.70
Iteration:   2380, Loss function: 4.169, Average Loss: 4.357, avg. samples / sec: 64989.28
Iteration:   2380, Loss function: 3.458, Average Loss: 4.360, avg. samples / sec: 65052.16
Iteration:   2380, Loss function: 4.716, Average Loss: 4.378, avg. samples / sec: 65045.44
Iteration:   2380, Loss function: 3.918, Average Loss: 4.357, avg. samples / sec: 65060.90
Iteration:   2380, Loss function: 4.141, Average Loss: 4.331, avg. samples / sec: 65095.97
Iteration:   2380, Loss function: 3.741, Average Loss: 4.367, avg. samples / sec: 65100.18
Iteration:   2380, Loss function: 3.708, Average Loss: 4.330, avg. samples / sec: 65070.94
Iteration:   2380, Loss function: 4.484, Average Loss: 4.343, avg. samples / sec: 65057.27
Iteration:   2380, Loss function: 4.008, Average Loss: 4.350, avg. samples / sec: 65037.45
Iteration:   2380, Loss function: 3.715, Average Loss: 4.345, avg. samples / sec: 65000.26
Iteration:   2380, Loss function: 4.441, Average Loss: 4.383, avg. samples / sec: 64962.86
Iteration:   2380, Loss function: 3.913, Average Loss: 4.344, avg. samples / sec: 65066.25
Iteration:   2380, Loss function: 4.232, Average Loss: 4.369, avg. samples / sec: 64990.00
Iteration:   2380, Loss function: 4.378, Average Loss: 4.364, avg. samples / sec: 64985.06
Iteration:   2380, Loss function: 2.679, Average Loss: 4.349, avg. samples / sec: 64950.02
Iteration:   2380, Loss function: 4.620, Average Loss: 4.353, avg. samples / sec: 65004.12
Iteration:   2380, Loss function: 4.138, Average Loss: 4.334, avg. samples / sec: 64988.42
Iteration:   2400, Loss function: 3.536, Average Loss: 4.351, avg. samples / sec: 65909.35
Iteration:   2400, Loss function: 4.055, Average Loss: 4.328, avg. samples / sec: 65816.51
Iteration:   2400, Loss function: 3.081, Average Loss: 4.349, avg. samples / sec: 65821.61
Iteration:   2400, Loss function: 3.011, Average Loss: 4.328, avg. samples / sec: 65729.97
Iteration:   2400, Loss function: 2.965, Average Loss: 4.351, avg. samples / sec: 65688.06
Iteration:   2400, Loss function: 3.977, Average Loss: 4.337, avg. samples / sec: 65776.21
Iteration:   2400, Loss function: 3.098, Average Loss: 4.322, avg. samples / sec: 65825.27
Iteration:   2400, Loss function: 4.305, Average Loss: 4.331, avg. samples / sec: 65726.91
Iteration:   2400, Loss function: 3.873, Average Loss: 4.351, avg. samples / sec: 65849.08
Iteration:   2400, Loss function: 4.255, Average Loss: 4.327, avg. samples / sec: 65639.54
Iteration:   2400, Loss function: 4.841, Average Loss: 4.332, avg. samples / sec: 65994.56
Iteration:   2400, Loss function: 5.507, Average Loss: 4.350, avg. samples / sec: 65968.52
Iteration:   2400, Loss function: 4.295, Average Loss: 4.351, avg. samples / sec: 65759.66
Iteration:   2400, Loss function: 5.862, Average Loss: 4.365, avg. samples / sec: 65650.33
Iteration:   2400, Loss function: 3.697, Average Loss: 4.337, avg. samples / sec: 65694.40
Iteration:   2400, Loss function: 3.132, Average Loss: 4.333, avg. samples / sec: 65829.76
Iteration:   2400, Loss function: 3.957, Average Loss: 4.342, avg. samples / sec: 65926.73
Iteration:   2400, Loss function: 3.334, Average Loss: 4.342, avg. samples / sec: 65811.38
Iteration:   2400, Loss function: 4.213, Average Loss: 4.363, avg. samples / sec: 65858.68
Iteration:   2400, Loss function: 4.242, Average Loss: 4.328, avg. samples / sec: 65572.74
Iteration:   2400, Loss function: 3.870, Average Loss: 4.360, avg. samples / sec: 65771.14
Iteration:   2400, Loss function: 3.211, Average Loss: 4.374, avg. samples / sec: 65730.65
Iteration:   2400, Loss function: 4.658, Average Loss: 4.362, avg. samples / sec: 65838.43
Iteration:   2400, Loss function: 4.327, Average Loss: 4.341, avg. samples / sec: 65709.16
Iteration:   2400, Loss function: 4.014, Average Loss: 4.377, avg. samples / sec: 65806.28
Iteration:   2400, Loss function: 3.125, Average Loss: 4.346, avg. samples / sec: 65717.35
Iteration:   2400, Loss function: 4.071, Average Loss: 4.332, avg. samples / sec: 65707.66
Iteration:   2400, Loss function: 4.403, Average Loss: 4.334, avg. samples / sec: 65574.61
Iteration:   2400, Loss function: 5.055, Average Loss: 4.342, avg. samples / sec: 65727.74
Iteration:   2400, Loss function: 4.459, Average Loss: 4.326, avg. samples / sec: 65644.89
Iteration:   2420, Loss function: 4.074, Average Loss: 4.348, avg. samples / sec: 66249.08
Iteration:   2420, Loss function: 3.525, Average Loss: 4.312, avg. samples / sec: 66253.16
Iteration:   2420, Loss function: 3.906, Average Loss: 4.323, avg. samples / sec: 66255.99
Iteration:   2420, Loss function: 3.491, Average Loss: 4.345, avg. samples / sec: 66189.62
Iteration:   2420, Loss function: 4.956, Average Loss: 4.333, avg. samples / sec: 66177.65
Iteration:   2420, Loss function: 2.588, Average Loss: 4.341, avg. samples / sec: 66199.16
Iteration:   2420, Loss function: 4.999, Average Loss: 4.365, avg. samples / sec: 66312.23
Iteration:   2420, Loss function: 4.369, Average Loss: 4.326, avg. samples / sec: 66147.27
Iteration:   2420, Loss function: 4.238, Average Loss: 4.328, avg. samples / sec: 66155.62
Iteration:   2420, Loss function: 3.628, Average Loss: 4.341, avg. samples / sec: 66280.11
Iteration:   2420, Loss function: 4.596, Average Loss: 4.328, avg. samples / sec: 66152.74
Iteration:   2420, Loss function: 4.781, Average Loss: 4.348, avg. samples / sec: 66144.20
Iteration:   2420, Loss function: 4.373, Average Loss: 4.338, avg. samples / sec: 66233.38
Iteration:   2420, Loss function: 3.445, Average Loss: 4.359, avg. samples / sec: 66216.77
Iteration:   2420, Loss function: 5.013, Average Loss: 4.356, avg. samples / sec: 66224.64
Iteration:   2420, Loss function: 3.457, Average Loss: 4.352, avg. samples / sec: 66236.56
Iteration:   2420, Loss function: 5.204, Average Loss: 4.370, avg. samples / sec: 66265.06
Iteration:   2420, Loss function: 3.289, Average Loss: 4.345, avg. samples / sec: 66171.00
Iteration:   2420, Loss function: 3.331, Average Loss: 4.324, avg. samples / sec: 66314.60
Iteration:   2420, Loss function: 5.699, Average Loss: 4.341, avg. samples / sec: 66301.56
Iteration:   2420, Loss function: 5.520, Average Loss: 4.330, avg. samples / sec: 66203.05
Iteration:   2420, Loss function: 5.068, Average Loss: 4.337, avg. samples / sec: 66161.15
Iteration:   2420, Loss function: 4.526, Average Loss: 4.359, avg. samples / sec: 66181.22
Iteration:   2420, Loss function: 4.277, Average Loss: 4.346, avg. samples / sec: 66247.58
Iteration:   2420, Loss function: 4.528, Average Loss: 4.342, avg. samples / sec: 66146.34
Iteration:   2420, Loss function: 3.827, Average Loss: 4.344, avg. samples / sec: 66078.82
Iteration:   2420, Loss function: 3.520, Average Loss: 4.328, avg. samples / sec: 66096.02
Iteration:   2420, Loss function: 4.290, Average Loss: 4.326, avg. samples / sec: 66176.90
Iteration:   2420, Loss function: 5.327, Average Loss: 4.327, avg. samples / sec: 65989.80
Iteration:   2420, Loss function: 4.538, Average Loss: 4.330, avg. samples / sec: 66087.68
Iteration:   2440, Loss function: 4.397, Average Loss: 4.319, avg. samples / sec: 65921.12
Iteration:   2440, Loss function: 4.277, Average Loss: 4.313, avg. samples / sec: 65886.67
Iteration:   2440, Loss function: 3.370, Average Loss: 4.323, avg. samples / sec: 65977.78
Iteration:   2440, Loss function: 4.368, Average Loss: 4.338, avg. samples / sec: 66043.74
Iteration:   2440, Loss function: 4.032, Average Loss: 4.327, avg. samples / sec: 65912.30
Iteration:   2440, Loss function: 4.219, Average Loss: 4.342, avg. samples / sec: 65823.12
Iteration:   2440, Loss function: 5.118, Average Loss: 4.353, avg. samples / sec: 65940.03
Iteration:   2440, Loss function: 4.829, Average Loss: 4.358, avg. samples / sec: 66004.05
Iteration:   2440, Loss function: 4.650, Average Loss: 4.368, avg. samples / sec: 65936.27
Iteration:   2440, Loss function: 4.365, Average Loss: 4.344, avg. samples / sec: 65922.94
Iteration:   2440, Loss function: 3.867, Average Loss: 4.320, avg. samples / sec: 65886.45
Iteration:   2440, Loss function: 5.236, Average Loss: 4.324, avg. samples / sec: 66018.68
Iteration:   2440, Loss function: 4.349, Average Loss: 4.328, avg. samples / sec: 66130.23
Iteration:   2440, Loss function: 4.018, Average Loss: 4.334, avg. samples / sec: 65949.01
Iteration:   2440, Loss function: 3.128, Average Loss: 4.322, avg. samples / sec: 66073.68
Iteration:   2440, Loss function: 4.282, Average Loss: 4.336, avg. samples / sec: 65974.63
Iteration:   2440, Loss function: 2.139, Average Loss: 4.337, avg. samples / sec: 65778.51
Iteration:   2440, Loss function: 4.454, Average Loss: 4.329, avg. samples / sec: 65837.73
Iteration:   2440, Loss function: 4.068, Average Loss: 4.325, avg. samples / sec: 66053.12
Iteration:   2440, Loss function: 4.428, Average Loss: 4.345, avg. samples / sec: 65846.03
Iteration:   2440, Loss function: 3.972, Average Loss: 4.358, avg. samples / sec: 65784.40
Iteration:   2440, Loss function: 4.111, Average Loss: 4.321, avg. samples / sec: 65865.88
Iteration:   2440, Loss function: 4.609, Average Loss: 4.335, avg. samples / sec: 65761.38
Iteration:   2440, Loss function: 3.605, Average Loss: 4.324, avg. samples / sec: 65859.91
Iteration:   2440, Loss function: 4.275, Average Loss: 4.347, avg. samples / sec: 65896.93
Iteration:   2440, Loss function: 4.299, Average Loss: 4.354, avg. samples / sec: 65789.81
Iteration:   2440, Loss function: 4.481, Average Loss: 4.340, avg. samples / sec: 65909.62
Iteration:   2440, Loss function: 4.396, Average Loss: 4.336, avg. samples / sec: 65814.76
Iteration:   2440, Loss function: 4.446, Average Loss: 4.337, avg. samples / sec: 65718.82
Iteration:   2440, Loss function: 4.343, Average Loss: 4.333, avg. samples / sec: 65733.56
:::MLL 1558651589.847 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558651589.847 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.263, Average Loss: 4.325, avg. samples / sec: 65797.43
Iteration:   2460, Loss function: 4.021, Average Loss: 4.329, avg. samples / sec: 65652.84
Iteration:   2460, Loss function: 4.432, Average Loss: 4.312, avg. samples / sec: 65602.32
Iteration:   2460, Loss function: 4.341, Average Loss: 4.314, avg. samples / sec: 65590.14
Iteration:   2460, Loss function: 3.326, Average Loss: 4.323, avg. samples / sec: 65790.33
Iteration:   2460, Loss function: 3.320, Average Loss: 4.335, avg. samples / sec: 65643.76
Iteration:   2460, Loss function: 3.255, Average Loss: 4.348, avg. samples / sec: 65634.49
Iteration:   2460, Loss function: 2.761, Average Loss: 4.323, avg. samples / sec: 65841.76
Iteration:   2460, Loss function: 4.038, Average Loss: 4.315, avg. samples / sec: 65661.56
Iteration:   2460, Loss function: 3.392, Average Loss: 4.332, avg. samples / sec: 65740.28
Iteration:   2460, Loss function: 3.702, Average Loss: 4.342, avg. samples / sec: 65643.73
Iteration:   2460, Loss function: 4.307, Average Loss: 4.323, avg. samples / sec: 65663.79
Iteration:   2460, Loss function: 4.873, Average Loss: 4.315, avg. samples / sec: 65548.99
Iteration:   2460, Loss function: 4.294, Average Loss: 4.328, avg. samples / sec: 65785.51
Iteration:   2460, Loss function: 3.390, Average Loss: 4.348, avg. samples / sec: 65731.60
Iteration:   2460, Loss function: 4.508, Average Loss: 4.331, avg. samples / sec: 65631.19
Iteration:   2460, Loss function: 6.197, Average Loss: 4.335, avg. samples / sec: 65526.83
Iteration:   2460, Loss function: 3.708, Average Loss: 4.352, avg. samples / sec: 65562.59
Iteration:   2460, Loss function: 4.215, Average Loss: 4.322, avg. samples / sec: 65613.35
Iteration:   2460, Loss function: 3.548, Average Loss: 4.311, avg. samples / sec: 65680.44
Iteration:   2460, Loss function: 3.976, Average Loss: 4.338, avg. samples / sec: 65620.19
Iteration:   2460, Loss function: 4.623, Average Loss: 4.332, avg. samples / sec: 65580.86
Iteration:   2460, Loss function: 3.445, Average Loss: 4.340, avg. samples / sec: 65655.99
Iteration:   2460, Loss function: 4.724, Average Loss: 4.333, avg. samples / sec: 65677.81
Iteration:   2460, Loss function: 3.949, Average Loss: 4.333, avg. samples / sec: 65550.88
Iteration:   2460, Loss function: 3.976, Average Loss: 4.366, avg. samples / sec: 65471.64
Iteration:   2460, Loss function: 6.013, Average Loss: 4.350, avg. samples / sec: 65567.56
Iteration:   2460, Loss function: 3.650, Average Loss: 4.315, avg. samples / sec: 65512.79
Iteration:   2460, Loss function: 3.725, Average Loss: 4.336, avg. samples / sec: 65584.92
Iteration:   2460, Loss function: 5.083, Average Loss: 4.315, avg. samples / sec: 65406.28
Iteration:   2480, Loss function: 3.747, Average Loss: 4.330, avg. samples / sec: 65852.95
Iteration:   2480, Loss function: 5.298, Average Loss: 4.330, avg. samples / sec: 65880.69
Iteration:   2480, Loss function: 4.308, Average Loss: 4.314, avg. samples / sec: 65856.37
Iteration:   2480, Loss function: 2.997, Average Loss: 4.310, avg. samples / sec: 65863.48
Iteration:   2480, Loss function: 4.500, Average Loss: 4.321, avg. samples / sec: 65806.83
Iteration:   2480, Loss function: 3.803, Average Loss: 4.320, avg. samples / sec: 65857.02
Iteration:   2480, Loss function: 4.706, Average Loss: 4.324, avg. samples / sec: 65920.17
Iteration:   2480, Loss function: 3.447, Average Loss: 4.304, avg. samples / sec: 66056.37
Iteration:   2480, Loss function: 3.889, Average Loss: 4.334, avg. samples / sec: 65882.75
Iteration:   2480, Loss function: 5.204, Average Loss: 4.316, avg. samples / sec: 65805.45
Iteration:   2480, Loss function: 3.939, Average Loss: 4.334, avg. samples / sec: 65872.62
Iteration:   2480, Loss function: 3.888, Average Loss: 4.323, avg. samples / sec: 65721.54
Iteration:   2480, Loss function: 4.990, Average Loss: 4.362, avg. samples / sec: 65935.80
Iteration:   2480, Loss function: 5.254, Average Loss: 4.307, avg. samples / sec: 65825.52
Iteration:   2480, Loss function: 3.735, Average Loss: 4.323, avg. samples / sec: 65652.35
Iteration:   2480, Loss function: 4.378, Average Loss: 4.333, avg. samples / sec: 65940.52
Iteration:   2480, Loss function: 4.184, Average Loss: 4.313, avg. samples / sec: 65704.51
Iteration:   2480, Loss function: 4.397, Average Loss: 4.347, avg. samples / sec: 65742.70
Iteration:   2480, Loss function: 4.255, Average Loss: 4.345, avg. samples / sec: 65789.01
Iteration:   2480, Loss function: 3.495, Average Loss: 4.347, avg. samples / sec: 65878.90
Iteration:   2480, Loss function: 3.577, Average Loss: 4.322, avg. samples / sec: 65742.98
Iteration:   2480, Loss function: 3.326, Average Loss: 4.307, avg. samples / sec: 65655.23
Iteration:   2480, Loss function: 4.500, Average Loss: 4.309, avg. samples / sec: 65871.61
Iteration:   2480, Loss function: 4.136, Average Loss: 4.327, avg. samples / sec: 65749.72
Iteration:   2480, Loss function: 3.357, Average Loss: 4.331, avg. samples / sec: 65780.14
Iteration:   2480, Loss function: 3.951, Average Loss: 4.332, avg. samples / sec: 65728.23
Iteration:   2480, Loss function: 3.758, Average Loss: 4.330, avg. samples / sec: 65799.21
Iteration:   2480, Loss function: 4.194, Average Loss: 4.324, avg. samples / sec: 65617.04
Iteration:   2480, Loss function: 4.301, Average Loss: 4.338, avg. samples / sec: 65675.08
Iteration:   2480, Loss function: 5.107, Average Loss: 4.341, avg. samples / sec: 65696.73
Iteration:   2500, Loss function: 4.104, Average Loss: 4.311, avg. samples / sec: 65660.85
Iteration:   2500, Loss function: 3.485, Average Loss: 4.314, avg. samples / sec: 65702.70
Iteration:   2500, Loss function: 4.084, Average Loss: 4.314, avg. samples / sec: 65607.85
Iteration:   2500, Loss function: 3.612, Average Loss: 4.326, avg. samples / sec: 65641.25
Iteration:   2500, Loss function: 4.478, Average Loss: 4.342, avg. samples / sec: 65705.18
Iteration:   2500, Loss function: 3.495, Average Loss: 4.311, avg. samples / sec: 65699.55
Iteration:   2500, Loss function: 3.552, Average Loss: 4.324, avg. samples / sec: 65544.63
Iteration:   2500, Loss function: 2.515, Average Loss: 4.325, avg. samples / sec: 65728.53
Iteration:   2500, Loss function: 3.747, Average Loss: 4.316, avg. samples / sec: 65588.19
Iteration:   2500, Loss function: 4.048, Average Loss: 4.323, avg. samples / sec: 65707.63
Iteration:   2500, Loss function: 3.775, Average Loss: 4.316, avg. samples / sec: 65587.64
Iteration:   2500, Loss function: 4.757, Average Loss: 4.304, avg. samples / sec: 65682.67
Iteration:   2500, Loss function: 4.331, Average Loss: 4.336, avg. samples / sec: 65719.92
Iteration:   2500, Loss function: 3.438, Average Loss: 4.325, avg. samples / sec: 65458.23
Iteration:   2500, Loss function: 2.823, Average Loss: 4.321, avg. samples / sec: 65691.71
Iteration:   2500, Loss function: 5.082, Average Loss: 4.360, avg. samples / sec: 65525.91
Iteration:   2500, Loss function: 6.238, Average Loss: 4.304, avg. samples / sec: 65594.26
Iteration:   2500, Loss function: 3.664, Average Loss: 4.317, avg. samples / sec: 65580.07
Iteration:   2500, Loss function: 4.560, Average Loss: 4.328, avg. samples / sec: 65496.50
Iteration:   2500, Loss function: 4.727, Average Loss: 4.341, avg. samples / sec: 65517.96
Iteration:   2500, Loss function: 2.965, Average Loss: 4.349, avg. samples / sec: 65553.89
Iteration:   2500, Loss function: 4.346, Average Loss: 4.337, avg. samples / sec: 65611.61
Iteration:   2500, Loss function: 2.847, Average Loss: 4.299, avg. samples / sec: 65477.69
Iteration:   2500, Loss function: 5.035, Average Loss: 4.305, avg. samples / sec: 65506.57
Iteration:   2500, Loss function: 4.327, Average Loss: 4.323, avg. samples / sec: 65483.44
Iteration:   2500, Loss function: 3.633, Average Loss: 4.318, avg. samples / sec: 65546.76
Iteration:   2500, Loss function: 5.458, Average Loss: 4.318, avg. samples / sec: 65454.46
Iteration:   2500, Loss function: 3.738, Average Loss: 4.330, avg. samples / sec: 65445.00
Iteration:   2500, Loss function: 4.115, Average Loss: 4.324, avg. samples / sec: 65458.44
Iteration:   2500, Loss function: 4.146, Average Loss: 4.327, avg. samples / sec: 65533.78
:::MLL 1558651591.636 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558651591.636 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 5.245, Average Loss: 4.323, avg. samples / sec: 65913.91
Iteration:   2520, Loss function: 3.847, Average Loss: 4.325, avg. samples / sec: 65821.77
Iteration:   2520, Loss function: 4.310, Average Loss: 4.337, avg. samples / sec: 65842.19
Iteration:   2520, Loss function: 3.837, Average Loss: 4.307, avg. samples / sec: 65730.99
Iteration:   2520, Loss function: 4.127, Average Loss: 4.317, avg. samples / sec: 65983.65
Iteration:   2520, Loss function: 3.943, Average Loss: 4.319, avg. samples / sec: 65967.84
Iteration:   2520, Loss function: 3.127, Average Loss: 4.320, avg. samples / sec: 65788.61
Iteration:   2520, Loss function: 3.627, Average Loss: 4.306, avg. samples / sec: 65793.16
Iteration:   2520, Loss function: 3.231, Average Loss: 4.305, avg. samples / sec: 65737.27
Iteration:   2520, Loss function: 3.429, Average Loss: 4.313, avg. samples / sec: 65766.66
Iteration:   2520, Loss function: 3.773, Average Loss: 4.318, avg. samples / sec: 65945.68
Iteration:   2520, Loss function: 3.831, Average Loss: 4.339, avg. samples / sec: 65723.81
Iteration:   2520, Loss function: 4.159, Average Loss: 4.301, avg. samples / sec: 65763.84
Iteration:   2520, Loss function: 3.762, Average Loss: 4.306, avg. samples / sec: 65647.89
Iteration:   2520, Loss function: 2.571, Average Loss: 4.297, avg. samples / sec: 65867.14
Iteration:   2520, Loss function: 4.646, Average Loss: 4.317, avg. samples / sec: 65918.72
Iteration:   2520, Loss function: 4.916, Average Loss: 4.331, avg. samples / sec: 65872.32
Iteration:   2520, Loss function: 4.909, Average Loss: 4.325, avg. samples / sec: 65804.89
Iteration:   2520, Loss function: 3.727, Average Loss: 4.305, avg. samples / sec: 65856.86
Iteration:   2520, Loss function: 4.508, Average Loss: 4.325, avg. samples / sec: 65838.16
Iteration:   2520, Loss function: 4.952, Average Loss: 4.312, avg. samples / sec: 65635.32
Iteration:   2520, Loss function: 3.552, Average Loss: 4.325, avg. samples / sec: 65874.78
Iteration:   2520, Loss function: 3.493, Average Loss: 4.317, avg. samples / sec: 65657.86
Iteration:   2520, Loss function: 5.697, Average Loss: 4.354, avg. samples / sec: 65769.27
Iteration:   2520, Loss function: 4.491, Average Loss: 4.318, avg. samples / sec: 65851.78
Iteration:   2520, Loss function: 4.747, Average Loss: 4.296, avg. samples / sec: 65749.23
Iteration:   2520, Loss function: 4.368, Average Loss: 4.337, avg. samples / sec: 65769.88
Iteration:   2520, Loss function: 4.004, Average Loss: 4.317, avg. samples / sec: 65676.43
Iteration:   2520, Loss function: 3.388, Average Loss: 4.342, avg. samples / sec: 65730.92
Iteration:   2520, Loss function: 3.496, Average Loss: 4.313, avg. samples / sec: 65728.63
Iteration:   2540, Loss function: 3.857, Average Loss: 4.302, avg. samples / sec: 66093.54
Iteration:   2540, Loss function: 3.969, Average Loss: 4.314, avg. samples / sec: 66121.36
Iteration:   2540, Loss function: 4.773, Average Loss: 4.323, avg. samples / sec: 66106.84
Iteration:   2540, Loss function: 3.776, Average Loss: 4.313, avg. samples / sec: 65986.87
Iteration:   2540, Loss function: 3.945, Average Loss: 4.320, avg. samples / sec: 65944.50
Iteration:   2540, Loss function: 4.211, Average Loss: 4.318, avg. samples / sec: 65967.59
Iteration:   2540, Loss function: 4.006, Average Loss: 4.325, avg. samples / sec: 66008.56
Iteration:   2540, Loss function: 3.006, Average Loss: 4.300, avg. samples / sec: 66046.89
Iteration:   2540, Loss function: 3.848, Average Loss: 4.308, avg. samples / sec: 66147.64
Iteration:   2540, Loss function: 4.425, Average Loss: 4.303, avg. samples / sec: 65948.55
Iteration:   2540, Loss function: 4.048, Average Loss: 4.316, avg. samples / sec: 65792.64
Iteration:   2540, Loss function: 3.701, Average Loss: 4.302, avg. samples / sec: 65939.14
Iteration:   2540, Loss function: 4.021, Average Loss: 4.310, avg. samples / sec: 65979.70
Iteration:   2540, Loss function: 4.165, Average Loss: 4.294, avg. samples / sec: 66069.62
Iteration:   2540, Loss function: 3.532, Average Loss: 4.298, avg. samples / sec: 65953.98
Iteration:   2540, Loss function: 4.392, Average Loss: 4.315, avg. samples / sec: 66097.79
Iteration:   2540, Loss function: 3.345, Average Loss: 4.305, avg. samples / sec: 65937.41
Iteration:   2540, Loss function: 5.601, Average Loss: 4.348, avg. samples / sec: 66028.36
Iteration:   2540, Loss function: 4.054, Average Loss: 4.334, avg. samples / sec: 66044.01
Iteration:   2540, Loss function: 3.351, Average Loss: 4.312, avg. samples / sec: 65858.74
Iteration:   2540, Loss function: 3.574, Average Loss: 4.332, avg. samples / sec: 65904.51
Iteration:   2540, Loss function: 4.290, Average Loss: 4.339, avg. samples / sec: 66054.48
Iteration:   2540, Loss function: 2.911, Average Loss: 4.322, avg. samples / sec: 65904.97
Iteration:   2540, Loss function: 4.077, Average Loss: 4.303, avg. samples / sec: 65903.77
Iteration:   2540, Loss function: 3.417, Average Loss: 4.321, avg. samples / sec: 65896.96
Iteration:   2540, Loss function: 3.365, Average Loss: 4.310, avg. samples / sec: 65816.36
Iteration:   2540, Loss function: 4.243, Average Loss: 4.333, avg. samples / sec: 65763.87
Iteration:   2540, Loss function: 3.121, Average Loss: 4.290, avg. samples / sec: 65842.86
Iteration:   2540, Loss function: 3.375, Average Loss: 4.315, avg. samples / sec: 65897.60
Iteration:   2540, Loss function: 2.726, Average Loss: 4.312, avg. samples / sec: 65737.36
Iteration:   2560, Loss function: 4.591, Average Loss: 4.316, avg. samples / sec: 66095.74
Iteration:   2560, Loss function: 3.278, Average Loss: 4.313, avg. samples / sec: 66045.00
Iteration:   2560, Loss function: 3.960, Average Loss: 4.326, avg. samples / sec: 66160.38
Iteration:   2560, Loss function: 3.102, Average Loss: 4.303, avg. samples / sec: 66241.29
Iteration:   2560, Loss function: 4.062, Average Loss: 4.288, avg. samples / sec: 66097.23
Iteration:   2560, Loss function: 4.073, Average Loss: 4.296, avg. samples / sec: 66019.85
Iteration:   2560, Loss function: 3.545, Average Loss: 4.303, avg. samples / sec: 66009.12
Iteration:   2560, Loss function: 3.983, Average Loss: 4.308, avg. samples / sec: 65928.89
Iteration:   2560, Loss function: 4.013, Average Loss: 4.322, avg. samples / sec: 66137.99
Iteration:   2560, Loss function: 5.410, Average Loss: 4.310, avg. samples / sec: 66007.27
Iteration:   2560, Loss function: 5.210, Average Loss: 4.308, avg. samples / sec: 65962.59
Iteration:   2560, Loss function: 3.542, Average Loss: 4.318, avg. samples / sec: 65965.52
Iteration:   2560, Loss function: 3.618, Average Loss: 4.298, avg. samples / sec: 65871.58
Iteration:   2560, Loss function: 3.543, Average Loss: 4.287, avg. samples / sec: 66119.56
Iteration:   2560, Loss function: 3.390, Average Loss: 4.321, avg. samples / sec: 66050.67
Iteration:   2560, Loss function: 4.062, Average Loss: 4.306, avg. samples / sec: 65899.17
Iteration:   2560, Loss function: 4.021, Average Loss: 4.318, avg. samples / sec: 65860.37
Iteration:   2560, Loss function: 3.638, Average Loss: 4.306, avg. samples / sec: 66085.64
Iteration:   2560, Loss function: 3.394, Average Loss: 4.298, avg. samples / sec: 65901.21
Iteration:   2560, Loss function: 3.808, Average Loss: 4.324, avg. samples / sec: 65968.43
Iteration:   2560, Loss function: 3.646, Average Loss: 4.304, avg. samples / sec: 66159.04
Iteration:   2560, Loss function: 5.411, Average Loss: 4.310, avg. samples / sec: 65957.68
Iteration:   2560, Loss function: 3.339, Average Loss: 4.310, avg. samples / sec: 65983.47
Iteration:   2560, Loss function: 4.397, Average Loss: 4.298, avg. samples / sec: 65863.42
Iteration:   2560, Loss function: 4.784, Average Loss: 4.300, avg. samples / sec: 65883.12
Iteration:   2560, Loss function: 4.089, Average Loss: 4.289, avg. samples / sec: 65846.25
Iteration:   2560, Loss function: 4.776, Average Loss: 4.297, avg. samples / sec: 65934.88
Iteration:   2560, Loss function: 2.955, Average Loss: 4.330, avg. samples / sec: 65892.92
Iteration:   2560, Loss function: 4.027, Average Loss: 4.345, avg. samples / sec: 65774.79
Iteration:   2560, Loss function: 5.075, Average Loss: 4.313, avg. samples / sec: 65661.41
Iteration:   2580, Loss function: 3.356, Average Loss: 4.282, avg. samples / sec: 66000.74
Iteration:   2580, Loss function: 5.446, Average Loss: 4.297, avg. samples / sec: 66069.56
Iteration:   2580, Loss function: 5.232, Average Loss: 4.293, avg. samples / sec: 65985.14
Iteration:   2580, Loss function: 4.316, Average Loss: 4.295, avg. samples / sec: 65905.77
Iteration:   2580, Loss function: 5.439, Average Loss: 4.281, avg. samples / sec: 66009.31
Iteration:   2580, Loss function: 3.180, Average Loss: 4.310, avg. samples / sec: 65903.74
Iteration:   2580, Loss function: 4.094, Average Loss: 4.305, avg. samples / sec: 65966.36
Iteration:   2580, Loss function: 3.404, Average Loss: 4.306, avg. samples / sec: 65999.82
Iteration:   2580, Loss function: 3.556, Average Loss: 4.279, avg. samples / sec: 66140.50
Iteration:   2580, Loss function: 4.751, Average Loss: 4.311, avg. samples / sec: 66041.69
Iteration:   2580, Loss function: 3.797, Average Loss: 4.317, avg. samples / sec: 66049.40
Iteration:   2580, Loss function: 3.235, Average Loss: 4.288, avg. samples / sec: 66067.20
Iteration:   2580, Loss function: 3.057, Average Loss: 4.300, avg. samples / sec: 66229.12
Iteration:   2580, Loss function: 4.099, Average Loss: 4.318, avg. samples / sec: 65951.20
Iteration:   2580, Loss function: 4.095, Average Loss: 4.300, avg. samples / sec: 65953.30
Iteration:   2580, Loss function: 3.712, Average Loss: 4.308, avg. samples / sec: 65927.17
Iteration:   2580, Loss function: 3.321, Average Loss: 4.312, avg. samples / sec: 65776.02
Iteration:   2580, Loss function: 4.732, Average Loss: 4.307, avg. samples / sec: 65882.91
Iteration:   2580, Loss function: 2.705, Average Loss: 4.329, avg. samples / sec: 66037.89
Iteration:   2580, Loss function: 2.480, Average Loss: 4.289, avg. samples / sec: 65926.55
Iteration:   2580, Loss function: 3.241, Average Loss: 4.316, avg. samples / sec: 65867.08
Iteration:   2580, Loss function: 4.080, Average Loss: 4.294, avg. samples / sec: 65938.15
Iteration:   2580, Loss function: 4.245, Average Loss: 4.337, avg. samples / sec: 66094.94
Iteration:   2580, Loss function: 3.485, Average Loss: 4.296, avg. samples / sec: 65797.92
Iteration:   2580, Loss function: 4.893, Average Loss: 4.319, avg. samples / sec: 65866.56
Iteration:   2580, Loss function: 4.818, Average Loss: 4.290, avg. samples / sec: 65974.82
Iteration:   2580, Loss function: 3.794, Average Loss: 4.321, avg. samples / sec: 65691.52
Iteration:   2580, Loss function: 2.920, Average Loss: 4.295, avg. samples / sec: 65927.01
Iteration:   2580, Loss function: 4.648, Average Loss: 4.307, avg. samples / sec: 65904.51
Iteration:   2580, Loss function: 4.370, Average Loss: 4.301, avg. samples / sec: 65780.87
:::MLL 1558651593.421 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558651593.422 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 4.388, Average Loss: 4.284, avg. samples / sec: 65544.63
Iteration:   2600, Loss function: 4.416, Average Loss: 4.290, avg. samples / sec: 65404.42
Iteration:   2600, Loss function: 4.867, Average Loss: 4.306, avg. samples / sec: 65416.42
Iteration:   2600, Loss function: 3.012, Average Loss: 4.294, avg. samples / sec: 65506.36
Iteration:   2600, Loss function: 3.642, Average Loss: 4.291, avg. samples / sec: 65465.86
Iteration:   2600, Loss function: 2.474, Average Loss: 4.305, avg. samples / sec: 65493.64
Iteration:   2600, Loss function: 3.299, Average Loss: 4.292, avg. samples / sec: 65648.16
Iteration:   2600, Loss function: 4.325, Average Loss: 4.278, avg. samples / sec: 65263.19
Iteration:   2600, Loss function: 3.834, Average Loss: 4.285, avg. samples / sec: 65481.52
Iteration:   2600, Loss function: 3.501, Average Loss: 4.304, avg. samples / sec: 65384.61
Iteration:   2600, Loss function: 3.638, Average Loss: 4.288, avg. samples / sec: 65275.73
Iteration:   2600, Loss function: 4.496, Average Loss: 4.306, avg. samples / sec: 65317.33
Iteration:   2600, Loss function: 4.757, Average Loss: 4.329, avg. samples / sec: 65486.18
Iteration:   2600, Loss function: 3.906, Average Loss: 4.307, avg. samples / sec: 65376.87
Iteration:   2600, Loss function: 4.026, Average Loss: 4.309, avg. samples / sec: 65439.78
Iteration:   2600, Loss function: 4.574, Average Loss: 4.297, avg. samples / sec: 65354.32
Iteration:   2600, Loss function: 3.183, Average Loss: 4.289, avg. samples / sec: 65258.87
Iteration:   2600, Loss function: 4.751, Average Loss: 4.317, avg. samples / sec: 65459.35
Iteration:   2600, Loss function: 3.652, Average Loss: 4.277, avg. samples / sec: 65267.18
Iteration:   2600, Loss function: 3.797, Average Loss: 4.307, avg. samples / sec: 65324.96
Iteration:   2600, Loss function: 4.585, Average Loss: 4.288, avg. samples / sec: 65416.99
Iteration:   2600, Loss function: 2.928, Average Loss: 4.309, avg. samples / sec: 65282.93
Iteration:   2600, Loss function: 3.807, Average Loss: 4.281, avg. samples / sec: 65439.75
Iteration:   2600, Loss function: 4.200, Average Loss: 4.317, avg. samples / sec: 65433.94
Iteration:   2600, Loss function: 5.300, Average Loss: 4.299, avg. samples / sec: 65238.45
Iteration:   2600, Loss function: 3.651, Average Loss: 4.323, avg. samples / sec: 65340.74
Iteration:   2600, Loss function: 3.641, Average Loss: 4.285, avg. samples / sec: 65352.41
Iteration:   2600, Loss function: 3.169, Average Loss: 4.282, avg. samples / sec: 65215.50
Iteration:   2600, Loss function: 3.390, Average Loss: 4.292, avg. samples / sec: 65402.88
Iteration:   2600, Loss function: 3.415, Average Loss: 4.303, avg. samples / sec: 65356.17
Iteration:   2620, Loss function: 2.988, Average Loss: 4.291, avg. samples / sec: 66157.43
Iteration:   2620, Loss function: 3.284, Average Loss: 4.303, avg. samples / sec: 65995.95
Iteration:   2620, Loss function: 3.451, Average Loss: 4.304, avg. samples / sec: 66085.85
Iteration:   2620, Loss function: 4.132, Average Loss: 4.281, avg. samples / sec: 66031.48
Iteration:   2620, Loss function: 3.620, Average Loss: 4.284, avg. samples / sec: 66027.12
Iteration:   2620, Loss function: 3.939, Average Loss: 4.302, avg. samples / sec: 66021.83
Iteration:   2620, Loss function: 4.901, Average Loss: 4.274, avg. samples / sec: 66020.50
Iteration:   2620, Loss function: 4.662, Average Loss: 4.300, avg. samples / sec: 66121.36
Iteration:   2620, Loss function: 3.497, Average Loss: 4.300, avg. samples / sec: 65953.45
Iteration:   2620, Loss function: 2.925, Average Loss: 4.283, avg. samples / sec: 65936.73
Iteration:   2620, Loss function: 4.740, Average Loss: 4.289, avg. samples / sec: 65942.22
Iteration:   2620, Loss function: 3.270, Average Loss: 4.300, avg. samples / sec: 66025.29
Iteration:   2620, Loss function: 3.913, Average Loss: 4.284, avg. samples / sec: 66109.04
Iteration:   2620, Loss function: 4.581, Average Loss: 4.271, avg. samples / sec: 66034.17
Iteration:   2620, Loss function: 3.396, Average Loss: 4.306, avg. samples / sec: 66003.65
Iteration:   2620, Loss function: 5.128, Average Loss: 4.321, avg. samples / sec: 65958.21
Iteration:   2620, Loss function: 4.064, Average Loss: 4.312, avg. samples / sec: 66009.43
Iteration:   2620, Loss function: 2.660, Average Loss: 4.283, avg. samples / sec: 65781.12
Iteration:   2620, Loss function: 4.255, Average Loss: 4.283, avg. samples / sec: 66018.40
Iteration:   2620, Loss function: 3.646, Average Loss: 4.314, avg. samples / sec: 66069.16
Iteration:   2620, Loss function: 4.271, Average Loss: 4.284, avg. samples / sec: 65905.28
Iteration:   2620, Loss function: 4.206, Average Loss: 4.284, avg. samples / sec: 65978.28
Iteration:   2620, Loss function: 4.060, Average Loss: 4.281, avg. samples / sec: 66042.84
Iteration:   2620, Loss function: 2.612, Average Loss: 4.310, avg. samples / sec: 65979.73
Iteration:   2620, Loss function: 4.200, Average Loss: 4.283, avg. samples / sec: 66010.94
Iteration:   2620, Loss function: 5.361, Average Loss: 4.288, avg. samples / sec: 65739.91
Iteration:   2620, Loss function: 4.569, Average Loss: 4.302, avg. samples / sec: 65965.83
Iteration:   2620, Loss function: 3.886, Average Loss: 4.294, avg. samples / sec: 66071.94
Iteration:   2620, Loss function: 2.295, Average Loss: 4.283, avg. samples / sec: 65922.02
Iteration:   2620, Loss function: 4.446, Average Loss: 4.302, avg. samples / sec: 65873.67
Iteration:   2640, Loss function: 3.681, Average Loss: 4.284, avg. samples / sec: 66365.88
Iteration:   2640, Loss function: 3.164, Average Loss: 4.282, avg. samples / sec: 66120.15
Iteration:   2640, Loss function: 4.141, Average Loss: 4.299, avg. samples / sec: 66197.92
Iteration:   2640, Loss function: 4.327, Average Loss: 4.286, avg. samples / sec: 66196.77
Iteration:   2640, Loss function: 2.931, Average Loss: 4.282, avg. samples / sec: 66360.63
Iteration:   2640, Loss function: 4.299, Average Loss: 4.300, avg. samples / sec: 66103.21
Iteration:   2640, Loss function: 3.270, Average Loss: 4.272, avg. samples / sec: 66141.22
Iteration:   2640, Loss function: 4.788, Average Loss: 4.292, avg. samples / sec: 66191.42
Iteration:   2640, Loss function: 2.490, Average Loss: 4.280, avg. samples / sec: 66296.48
Iteration:   2640, Loss function: 4.630, Average Loss: 4.299, avg. samples / sec: 66291.21
Iteration:   2640, Loss function: 4.879, Average Loss: 4.282, avg. samples / sec: 66229.65
Iteration:   2640, Loss function: 4.257, Average Loss: 4.297, avg. samples / sec: 66080.56
Iteration:   2640, Loss function: 3.250, Average Loss: 4.280, avg. samples / sec: 66195.34
Iteration:   2640, Loss function: 3.252, Average Loss: 4.297, avg. samples / sec: 66342.04
Iteration:   2640, Loss function: 3.471, Average Loss: 4.281, avg. samples / sec: 66112.80
Iteration:   2640, Loss function: 3.802, Average Loss: 4.289, avg. samples / sec: 66230.12
Iteration:   2640, Loss function: 4.101, Average Loss: 4.271, avg. samples / sec: 66127.35
Iteration:   2640, Loss function: 4.227, Average Loss: 4.300, avg. samples / sec: 66060.45
Iteration:   2640, Loss function: 4.392, Average Loss: 4.304, avg. samples / sec: 66190.30
Iteration:   2640, Loss function: 3.206, Average Loss: 4.312, avg. samples / sec: 66115.31
Iteration:   2640, Loss function: 3.087, Average Loss: 4.280, avg. samples / sec: 66181.81
Iteration:   2640, Loss function: 4.691, Average Loss: 4.300, avg. samples / sec: 66088.68
Iteration:   2640, Loss function: 4.947, Average Loss: 4.282, avg. samples / sec: 66166.87
Iteration:   2640, Loss function: 3.217, Average Loss: 4.267, avg. samples / sec: 66013.63
Iteration:   2640, Loss function: 3.977, Average Loss: 4.280, avg. samples / sec: 66048.16
Iteration:   2640, Loss function: 4.619, Average Loss: 4.309, avg. samples / sec: 66099.83
Iteration:   2640, Loss function: 3.069, Average Loss: 4.275, avg. samples / sec: 66090.04
Iteration:   2640, Loss function: 3.486, Average Loss: 4.300, avg. samples / sec: 65992.71
Iteration:   2640, Loss function: 4.139, Average Loss: 4.281, avg. samples / sec: 66016.76
Iteration:   2640, Loss function: 4.416, Average Loss: 4.312, avg. samples / sec: 65994.16
:::MLL 1558651595.206 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558651595.207 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 3.408, Average Loss: 4.273, avg. samples / sec: 66009.03
Iteration:   2660, Loss function: 4.070, Average Loss: 4.278, avg. samples / sec: 65738.34
Iteration:   2660, Loss function: 4.061, Average Loss: 4.294, avg. samples / sec: 65803.79
Iteration:   2660, Loss function: 4.184, Average Loss: 4.298, avg. samples / sec: 65864.34
Iteration:   2660, Loss function: 4.014, Average Loss: 4.257, avg. samples / sec: 65893.84
Iteration:   2660, Loss function: 4.276, Average Loss: 4.293, avg. samples / sec: 65848.95
Iteration:   2660, Loss function: 4.295, Average Loss: 4.273, avg. samples / sec: 65872.75
Iteration:   2660, Loss function: 3.977, Average Loss: 4.271, avg. samples / sec: 65871.73
Iteration:   2660, Loss function: 4.716, Average Loss: 4.295, avg. samples / sec: 65867.76
Iteration:   2660, Loss function: 3.277, Average Loss: 4.296, avg. samples / sec: 65843.51
Iteration:   2660, Loss function: 3.888, Average Loss: 4.302, avg. samples / sec: 65854.12
Iteration:   2660, Loss function: 4.212, Average Loss: 4.280, avg. samples / sec: 65774.52
Iteration:   2660, Loss function: 4.108, Average Loss: 4.287, avg. samples / sec: 65747.73
Iteration:   2660, Loss function: 4.909, Average Loss: 4.279, avg. samples / sec: 65678.60
Iteration:   2660, Loss function: 5.092, Average Loss: 4.296, avg. samples / sec: 65700.43
Iteration:   2660, Loss function: 5.982, Average Loss: 4.274, avg. samples / sec: 65757.82
Iteration:   2660, Loss function: 2.458, Average Loss: 4.290, avg. samples / sec: 65674.90
Iteration:   2660, Loss function: 3.766, Average Loss: 4.272, avg. samples / sec: 65678.17
Iteration:   2660, Loss function: 4.276, Average Loss: 4.279, avg. samples / sec: 65747.45
Iteration:   2660, Loss function: 4.130, Average Loss: 4.310, avg. samples / sec: 65912.64
Iteration:   2660, Loss function: 4.569, Average Loss: 4.313, avg. samples / sec: 65764.39
Iteration:   2660, Loss function: 3.608, Average Loss: 4.264, avg. samples / sec: 65712.63
Iteration:   2660, Loss function: 4.313, Average Loss: 4.278, avg. samples / sec: 65814.11
Iteration:   2660, Loss function: 2.960, Average Loss: 4.267, avg. samples / sec: 65626.88
Iteration:   2660, Loss function: 3.259, Average Loss: 4.278, avg. samples / sec: 65622.24
Iteration:   2660, Loss function: 4.102, Average Loss: 4.277, avg. samples / sec: 65566.89
Iteration:   2660, Loss function: 4.063, Average Loss: 4.279, avg. samples / sec: 65588.64
Iteration:   2660, Loss function: 4.373, Average Loss: 4.294, avg. samples / sec: 65738.13
Iteration:   2660, Loss function: 3.464, Average Loss: 4.284, avg. samples / sec: 65554.26
Iteration:   2660, Loss function: 4.274, Average Loss: 4.278, avg. samples / sec: 65663.76
Iteration:   2680, Loss function: 2.707, Average Loss: 4.281, avg. samples / sec: 65888.85
Iteration:   2680, Loss function: 3.748, Average Loss: 4.259, avg. samples / sec: 66068.69
Iteration:   2680, Loss function: 3.333, Average Loss: 4.280, avg. samples / sec: 66013.79
Iteration:   2680, Loss function: 3.015, Average Loss: 4.273, avg. samples / sec: 66039.46
Iteration:   2680, Loss function: 4.285, Average Loss: 4.278, avg. samples / sec: 65921.74
Iteration:   2680, Loss function: 5.115, Average Loss: 4.276, avg. samples / sec: 65779.65
Iteration:   2680, Loss function: 3.397, Average Loss: 4.273, avg. samples / sec: 65881.92
Iteration:   2680, Loss function: 3.903, Average Loss: 4.293, avg. samples / sec: 65899.42
Iteration:   2680, Loss function: 4.464, Average Loss: 4.255, avg. samples / sec: 65845.63
Iteration:   2680, Loss function: 3.061, Average Loss: 4.289, avg. samples / sec: 65907.19
Iteration:   2680, Loss function: 5.217, Average Loss: 4.269, avg. samples / sec: 65943.98
Iteration:   2680, Loss function: 3.019, Average Loss: 4.257, avg. samples / sec: 65941.20
Iteration:   2680, Loss function: 4.504, Average Loss: 4.294, avg. samples / sec: 65758.90
Iteration:   2680, Loss function: 4.309, Average Loss: 4.284, avg. samples / sec: 65841.76
Iteration:   2680, Loss function: 4.910, Average Loss: 4.272, avg. samples / sec: 65939.44
Iteration:   2680, Loss function: 2.690, Average Loss: 4.269, avg. samples / sec: 65844.43
Iteration:   2680, Loss function: 4.027, Average Loss: 4.290, avg. samples / sec: 65823.64
Iteration:   2680, Loss function: 4.422, Average Loss: 4.286, avg. samples / sec: 65954.19
Iteration:   2680, Loss function: 4.849, Average Loss: 4.271, avg. samples / sec: 65815.65
Iteration:   2680, Loss function: 4.420, Average Loss: 4.275, avg. samples / sec: 65905.71
Iteration:   2680, Loss function: 4.059, Average Loss: 4.265, avg. samples / sec: 65631.22
Iteration:   2680, Loss function: 4.357, Average Loss: 4.292, avg. samples / sec: 65734.42
Iteration:   2680, Loss function: 4.440, Average Loss: 4.274, avg. samples / sec: 65918.29
Iteration:   2680, Loss function: 3.376, Average Loss: 4.268, avg. samples / sec: 65741.04
Iteration:   2680, Loss function: 3.519, Average Loss: 4.268, avg. samples / sec: 65882.11
Iteration:   2680, Loss function: 3.240, Average Loss: 4.271, avg. samples / sec: 65932.81
Iteration:   2680, Loss function: 4.499, Average Loss: 4.308, avg. samples / sec: 65814.20
Iteration:   2680, Loss function: 4.765, Average Loss: 4.282, avg. samples / sec: 65734.51
Iteration:   2680, Loss function: 6.419, Average Loss: 4.304, avg. samples / sec: 65774.86
Iteration:   2680, Loss function: 4.803, Average Loss: 4.272, avg. samples / sec: 65746.99
Iteration:   2700, Loss function: 3.981, Average Loss: 4.261, avg. samples / sec: 65528.41
Iteration:   2700, Loss function: 4.273, Average Loss: 4.276, avg. samples / sec: 65296.78
Iteration:   2700, Loss function: 4.298, Average Loss: 4.249, avg. samples / sec: 65414.47
Iteration:   2700, Loss function: 3.563, Average Loss: 4.262, avg. samples / sec: 65414.53
Iteration:   2700, Loss function: 4.325, Average Loss: 4.273, avg. samples / sec: 65372.27
Iteration:   2700, Loss function: 4.060, Average Loss: 4.268, avg. samples / sec: 65373.60
Iteration:   2700, Loss function: 3.874, Average Loss: 4.267, avg. samples / sec: 65339.29
Iteration:   2700, Loss function: 3.857, Average Loss: 4.275, avg. samples / sec: 65304.89
Iteration:   2700, Loss function: 3.075, Average Loss: 4.268, avg. samples / sec: 65353.26
Iteration:   2700, Loss function: 3.730, Average Loss: 4.284, avg. samples / sec: 65357.23
Iteration:   2700, Loss function: 4.410, Average Loss: 4.265, avg. samples / sec: 65478.85
Iteration:   2700, Loss function: 4.594, Average Loss: 4.267, avg. samples / sec: 65465.61
Iteration:   2700, Loss function: 3.294, Average Loss: 4.282, avg. samples / sec: 65357.62
Iteration:   2700, Loss function: 3.580, Average Loss: 4.287, avg. samples / sec: 65471.70
Iteration:   2700, Loss function: 5.057, Average Loss: 4.255, avg. samples / sec: 65372.84
Iteration:   2700, Loss function: 4.929, Average Loss: 4.275, avg. samples / sec: 65451.72
Iteration:   2700, Loss function: 2.905, Average Loss: 4.297, avg. samples / sec: 65505.36
Iteration:   2700, Loss function: 3.399, Average Loss: 4.279, avg. samples / sec: 65424.80
Iteration:   2700, Loss function: 4.595, Average Loss: 4.286, avg. samples / sec: 65367.14
Iteration:   2700, Loss function: 5.615, Average Loss: 4.276, avg. samples / sec: 65433.09
Iteration:   2700, Loss function: 4.568, Average Loss: 4.265, avg. samples / sec: 65398.60
Iteration:   2700, Loss function: 4.430, Average Loss: 4.259, avg. samples / sec: 65185.91
Iteration:   2700, Loss function: 4.249, Average Loss: 4.268, avg. samples / sec: 65411.59
Iteration:   2700, Loss function: 4.488, Average Loss: 4.274, avg. samples / sec: 65458.16
Iteration:   2700, Loss function: 3.713, Average Loss: 4.272, avg. samples / sec: 65290.22
Iteration:   2700, Loss function: 5.737, Average Loss: 4.293, avg. samples / sec: 65268.21
Iteration:   2700, Loss function: 4.569, Average Loss: 4.286, avg. samples / sec: 65274.04
Iteration:   2700, Loss function: 3.045, Average Loss: 4.302, avg. samples / sec: 65369.93
Iteration:   2700, Loss function: 3.878, Average Loss: 4.280, avg. samples / sec: 65416.48
Iteration:   2700, Loss function: 4.301, Average Loss: 4.268, avg. samples / sec: 65221.66
Iteration:   2720, Loss function: 3.398, Average Loss: 4.262, avg. samples / sec: 66183.40
Iteration:   2720, Loss function: 4.862, Average Loss: 4.276, avg. samples / sec: 66170.91
Iteration:   2720, Loss function: 4.356, Average Loss: 4.264, avg. samples / sec: 66106.66
Iteration:   2720, Loss function: 3.043, Average Loss: 4.278, avg. samples / sec: 66124.77
Iteration:   2720, Loss function: 5.449, Average Loss: 4.289, avg. samples / sec: 66235.00
Iteration:   2720, Loss function: 2.652, Average Loss: 4.240, avg. samples / sec: 66067.42
Iteration:   2720, Loss function: 4.159, Average Loss: 4.265, avg. samples / sec: 66199.29
Iteration:   2720, Loss function: 4.530, Average Loss: 4.255, avg. samples / sec: 66157.83
Iteration:   2720, Loss function: 4.324, Average Loss: 4.269, avg. samples / sec: 66114.84
Iteration:   2720, Loss function: 3.791, Average Loss: 4.272, avg. samples / sec: 66023.87
Iteration:   2720, Loss function: 3.126, Average Loss: 4.263, avg. samples / sec: 66057.60
Iteration:   2720, Loss function: 3.872, Average Loss: 4.260, avg. samples / sec: 66142.12
Iteration:   2720, Loss function: 3.228, Average Loss: 4.261, avg. samples / sec: 66294.70
Iteration:   2720, Loss function: 3.981, Average Loss: 4.286, avg. samples / sec: 66099.71
Iteration:   2720, Loss function: 3.349, Average Loss: 4.275, avg. samples / sec: 66201.21
Iteration:   2720, Loss function: 4.962, Average Loss: 4.271, avg. samples / sec: 66073.86
Iteration:   2720, Loss function: 3.524, Average Loss: 4.257, avg. samples / sec: 65937.65
Iteration:   2720, Loss function: 5.070, Average Loss: 4.281, avg. samples / sec: 66067.79
Iteration:   2720, Loss function: 4.846, Average Loss: 4.252, avg. samples / sec: 66063.43
Iteration:   2720, Loss function: 4.992, Average Loss: 4.284, avg. samples / sec: 66049.37
Iteration:   2720, Loss function: 4.577, Average Loss: 4.270, avg. samples / sec: 65997.13
Iteration:   2720, Loss function: 5.232, Average Loss: 4.285, avg. samples / sec: 66134.27
Iteration:   2720, Loss function: 4.588, Average Loss: 4.260, avg. samples / sec: 66027.27
Iteration:   2720, Loss function: 3.070, Average Loss: 4.296, avg. samples / sec: 66146.50
Iteration:   2720, Loss function: 3.912, Average Loss: 4.269, avg. samples / sec: 66116.24
Iteration:   2720, Loss function: 3.072, Average Loss: 4.291, avg. samples / sec: 66024.24
Iteration:   2720, Loss function: 5.398, Average Loss: 4.258, avg. samples / sec: 65923.99
Iteration:   2720, Loss function: 4.916, Average Loss: 4.257, avg. samples / sec: 65977.41
Iteration:   2720, Loss function: 4.817, Average Loss: 4.270, avg. samples / sec: 66014.22
Iteration:   2720, Loss function: 2.662, Average Loss: 4.273, avg. samples / sec: 65898.22
:::MLL 1558651596.997 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558651596.997 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 2.935, Average Loss: 4.282, avg. samples / sec: 65612.74
Iteration:   2740, Loss function: 4.652, Average Loss: 4.265, avg. samples / sec: 65658.35
Iteration:   2740, Loss function: 3.939, Average Loss: 4.291, avg. samples / sec: 65729.42
Iteration:   2740, Loss function: 4.108, Average Loss: 4.265, avg. samples / sec: 65651.53
Iteration:   2740, Loss function: 3.566, Average Loss: 4.269, avg. samples / sec: 65514.16
Iteration:   2740, Loss function: 4.309, Average Loss: 4.250, avg. samples / sec: 65748.47
Iteration:   2740, Loss function: 4.156, Average Loss: 4.246, avg. samples / sec: 65671.14
Iteration:   2740, Loss function: 3.419, Average Loss: 4.256, avg. samples / sec: 65487.67
Iteration:   2740, Loss function: 3.332, Average Loss: 4.232, avg. samples / sec: 65574.91
Iteration:   2740, Loss function: 3.384, Average Loss: 4.271, avg. samples / sec: 65770.50
Iteration:   2740, Loss function: 3.914, Average Loss: 4.263, avg. samples / sec: 65561.58
Iteration:   2740, Loss function: 4.312, Average Loss: 4.280, avg. samples / sec: 65647.95
Iteration:   2740, Loss function: 4.083, Average Loss: 4.271, avg. samples / sec: 65547.03
Iteration:   2740, Loss function: 4.484, Average Loss: 4.262, avg. samples / sec: 65617.35
Iteration:   2740, Loss function: 4.456, Average Loss: 4.262, avg. samples / sec: 65546.24
Iteration:   2740, Loss function: 3.360, Average Loss: 4.260, avg. samples / sec: 65634.43
Iteration:   2740, Loss function: 4.404, Average Loss: 4.277, avg. samples / sec: 65587.33
Iteration:   2740, Loss function: 3.739, Average Loss: 4.249, avg. samples / sec: 65571.55
Iteration:   2740, Loss function: 2.900, Average Loss: 4.258, avg. samples / sec: 65546.03
Iteration:   2740, Loss function: 4.884, Average Loss: 4.281, avg. samples / sec: 65594.35
Iteration:   2740, Loss function: 3.244, Average Loss: 4.263, avg. samples / sec: 65533.59
Iteration:   2740, Loss function: 3.668, Average Loss: 4.263, avg. samples / sec: 65714.47
Iteration:   2740, Loss function: 3.798, Average Loss: 4.279, avg. samples / sec: 65514.67
Iteration:   2740, Loss function: 4.075, Average Loss: 4.253, avg. samples / sec: 65508.58
Iteration:   2740, Loss function: 3.466, Average Loss: 4.252, avg. samples / sec: 65492.72
Iteration:   2740, Loss function: 3.285, Average Loss: 4.249, avg. samples / sec: 65576.50
Iteration:   2740, Loss function: 3.631, Average Loss: 4.253, avg. samples / sec: 65470.54
Iteration:   2740, Loss function: 4.077, Average Loss: 4.261, avg. samples / sec: 65542.86
Iteration:   2740, Loss function: 4.207, Average Loss: 4.279, avg. samples / sec: 65395.41
Iteration:   2740, Loss function: 3.298, Average Loss: 4.271, avg. samples / sec: 65345.41
Iteration:   2760, Loss function: 4.003, Average Loss: 4.274, avg. samples / sec: 66226.07
Iteration:   2760, Loss function: 4.353, Average Loss: 4.264, avg. samples / sec: 66226.35
Iteration:   2760, Loss function: 3.532, Average Loss: 4.265, avg. samples / sec: 66209.67
Iteration:   2760, Loss function: 4.139, Average Loss: 4.251, avg. samples / sec: 66186.91
Iteration:   2760, Loss function: 3.113, Average Loss: 4.266, avg. samples / sec: 66216.83
Iteration:   2760, Loss function: 3.842, Average Loss: 4.246, avg. samples / sec: 66153.08
Iteration:   2760, Loss function: 3.658, Average Loss: 4.257, avg. samples / sec: 66224.83
Iteration:   2760, Loss function: 4.833, Average Loss: 4.249, avg. samples / sec: 66318.41
Iteration:   2760, Loss function: 2.774, Average Loss: 4.287, avg. samples / sec: 66118.97
Iteration:   2760, Loss function: 3.857, Average Loss: 4.252, avg. samples / sec: 66296.14
Iteration:   2760, Loss function: 3.933, Average Loss: 4.244, avg. samples / sec: 66095.03
Iteration:   2760, Loss function: 4.746, Average Loss: 4.252, avg. samples / sec: 66235.19
Iteration:   2760, Loss function: 5.734, Average Loss: 4.251, avg. samples / sec: 66269.79
Iteration:   2760, Loss function: 3.542, Average Loss: 4.276, avg. samples / sec: 66139.42
Iteration:   2760, Loss function: 3.911, Average Loss: 4.273, avg. samples / sec: 66162.12
Iteration:   2760, Loss function: 3.780, Average Loss: 4.261, avg. samples / sec: 66144.79
Iteration:   2760, Loss function: 4.506, Average Loss: 4.270, avg. samples / sec: 66335.17
Iteration:   2760, Loss function: 4.371, Average Loss: 4.271, avg. samples / sec: 66200.87
Iteration:   2760, Loss function: 4.300, Average Loss: 4.259, avg. samples / sec: 66127.62
Iteration:   2760, Loss function: 3.691, Average Loss: 4.273, avg. samples / sec: 66092.05
Iteration:   2760, Loss function: 4.065, Average Loss: 4.228, avg. samples / sec: 66077.27
Iteration:   2760, Loss function: 3.527, Average Loss: 4.264, avg. samples / sec: 66040.08
Iteration:   2760, Loss function: 3.540, Average Loss: 4.257, avg. samples / sec: 66061.13
Iteration:   2760, Loss function: 3.718, Average Loss: 4.270, avg. samples / sec: 66191.39
Iteration:   2760, Loss function: 3.306, Average Loss: 4.242, avg. samples / sec: 66130.63
Iteration:   2760, Loss function: 3.782, Average Loss: 4.254, avg. samples / sec: 66139.95
Iteration:   2760, Loss function: 4.432, Average Loss: 4.252, avg. samples / sec: 66051.97
Iteration:   2760, Loss function: 3.715, Average Loss: 4.265, avg. samples / sec: 66250.76
Iteration:   2760, Loss function: 2.773, Average Loss: 4.255, avg. samples / sec: 66015.89
Iteration:   2760, Loss function: 4.700, Average Loss: 4.260, avg. samples / sec: 66047.42
Iteration:   2780, Loss function: 3.994, Average Loss: 4.260, avg. samples / sec: 65919.12
Iteration:   2780, Loss function: 4.777, Average Loss: 4.257, avg. samples / sec: 65999.17
Iteration:   2780, Loss function: 3.621, Average Loss: 4.244, avg. samples / sec: 65940.77
Iteration:   2780, Loss function: 3.955, Average Loss: 4.260, avg. samples / sec: 66001.02
Iteration:   2780, Loss function: 4.403, Average Loss: 4.264, avg. samples / sec: 65851.48
Iteration:   2780, Loss function: 4.235, Average Loss: 4.256, avg. samples / sec: 66162.05
Iteration:   2780, Loss function: 3.871, Average Loss: 4.239, avg. samples / sec: 65893.29
Iteration:   2780, Loss function: 4.196, Average Loss: 4.251, avg. samples / sec: 65864.59
Iteration:   2780, Loss function: 4.629, Average Loss: 4.229, avg. samples / sec: 65973.24
Iteration:   2780, Loss function: 3.740, Average Loss: 4.259, avg. samples / sec: 65971.45
Iteration:   2780, Loss function: 4.587, Average Loss: 4.287, avg. samples / sec: 65885.77
Iteration:   2780, Loss function: 3.295, Average Loss: 4.268, avg. samples / sec: 65973.15
Iteration:   2780, Loss function: 5.103, Average Loss: 4.253, avg. samples / sec: 65965.96
Iteration:   2780, Loss function: 4.186, Average Loss: 4.241, avg. samples / sec: 65887.01
Iteration:   2780, Loss function: 3.772, Average Loss: 4.245, avg. samples / sec: 65897.91
Iteration:   2780, Loss function: 4.745, Average Loss: 4.248, avg. samples / sec: 65872.32
Iteration:   2780, Loss function: 4.497, Average Loss: 4.259, avg. samples / sec: 65885.90
Iteration:   2780, Loss function: 4.558, Average Loss: 4.268, avg. samples / sec: 65730.43
Iteration:   2780, Loss function: 3.903, Average Loss: 4.273, avg. samples / sec: 65887.22
Iteration:   2780, Loss function: 4.105, Average Loss: 4.266, avg. samples / sec: 65758.71
Iteration:   2780, Loss function: 5.020, Average Loss: 4.267, avg. samples / sec: 65857.72
Iteration:   2780, Loss function: 4.939, Average Loss: 4.263, avg. samples / sec: 65861.91
Iteration:   2780, Loss function: 4.045, Average Loss: 4.249, avg. samples / sec: 65746.59
Iteration:   2780, Loss function: 3.804, Average Loss: 4.259, avg. samples / sec: 66034.51
Iteration:   2780, Loss function: 4.908, Average Loss: 4.262, avg. samples / sec: 65952.53
Iteration:   2780, Loss function: 5.248, Average Loss: 4.251, avg. samples / sec: 65925.87
Iteration:   2780, Loss function: 4.124, Average Loss: 4.268, avg. samples / sec: 65764.05
Iteration:   2780, Loss function: 4.211, Average Loss: 4.239, avg. samples / sec: 65830.44
Iteration:   2780, Loss function: 3.227, Average Loss: 4.252, avg. samples / sec: 65893.84
Iteration:   2780, Loss function: 3.940, Average Loss: 4.272, avg. samples / sec: 65693.36
:::MLL 1558651598.781 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558651598.782 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 2.613, Average Loss: 4.246, avg. samples / sec: 65798.84
Iteration:   2800, Loss function: 4.631, Average Loss: 4.250, avg. samples / sec: 65712.50
Iteration:   2800, Loss function: 4.832, Average Loss: 4.250, avg. samples / sec: 65758.87
Iteration:   2800, Loss function: 4.958, Average Loss: 4.255, avg. samples / sec: 65626.39
Iteration:   2800, Loss function: 4.781, Average Loss: 4.253, avg. samples / sec: 65665.81
Iteration:   2800, Loss function: 4.322, Average Loss: 4.227, avg. samples / sec: 65668.23
Iteration:   2800, Loss function: 4.314, Average Loss: 4.240, avg. samples / sec: 65671.44
Iteration:   2800, Loss function: 2.546, Average Loss: 4.259, avg. samples / sec: 65610.84
Iteration:   2800, Loss function: 3.769, Average Loss: 4.262, avg. samples / sec: 65742.85
Iteration:   2800, Loss function: 3.658, Average Loss: 4.259, avg. samples / sec: 65750.58
Iteration:   2800, Loss function: 3.469, Average Loss: 4.287, avg. samples / sec: 65646.82
Iteration:   2800, Loss function: 3.252, Average Loss: 4.247, avg. samples / sec: 65538.74
Iteration:   2800, Loss function: 5.319, Average Loss: 4.263, avg. samples / sec: 65786.22
Iteration:   2800, Loss function: 3.633, Average Loss: 4.263, avg. samples / sec: 65651.80
Iteration:   2800, Loss function: 3.068, Average Loss: 4.243, avg. samples / sec: 65627.31
Iteration:   2800, Loss function: 3.398, Average Loss: 4.236, avg. samples / sec: 65559.57
Iteration:   2800, Loss function: 4.705, Average Loss: 4.267, avg. samples / sec: 65822.01
Iteration:   2800, Loss function: 4.158, Average Loss: 4.256, avg. samples / sec: 65413.14
Iteration:   2800, Loss function: 4.359, Average Loss: 4.262, avg. samples / sec: 65671.26
Iteration:   2800, Loss function: 3.522, Average Loss: 4.255, avg. samples / sec: 65658.59
Iteration:   2800, Loss function: 4.363, Average Loss: 4.266, avg. samples / sec: 65626.24
Iteration:   2800, Loss function: 3.315, Average Loss: 4.236, avg. samples / sec: 65713.03
Iteration:   2800, Loss function: 4.649, Average Loss: 4.246, avg. samples / sec: 65685.89
Iteration:   2800, Loss function: 4.561, Average Loss: 4.237, avg. samples / sec: 65560.82
Iteration:   2800, Loss function: 4.375, Average Loss: 4.244, avg. samples / sec: 65484.08
Iteration:   2800, Loss function: 3.594, Average Loss: 4.249, avg. samples / sec: 65696.45
Iteration:   2800, Loss function: 2.701, Average Loss: 4.249, avg. samples / sec: 65573.08
Iteration:   2800, Loss function: 4.432, Average Loss: 4.256, avg. samples / sec: 65484.47
Iteration:   2800, Loss function: 4.301, Average Loss: 4.264, avg. samples / sec: 65570.09
Iteration:   2800, Loss function: 5.378, Average Loss: 4.264, avg. samples / sec: 65455.85
Iteration:   2820, Loss function: 4.331, Average Loss: 4.222, avg. samples / sec: 66009.40
Iteration:   2820, Loss function: 4.831, Average Loss: 4.247, avg. samples / sec: 65969.72
Iteration:   2820, Loss function: 4.809, Average Loss: 4.260, avg. samples / sec: 66027.18
Iteration:   2820, Loss function: 4.250, Average Loss: 4.244, avg. samples / sec: 65933.40
Iteration:   2820, Loss function: 3.878, Average Loss: 4.250, avg. samples / sec: 66067.17
Iteration:   2820, Loss function: 3.872, Average Loss: 4.237, avg. samples / sec: 65933.24
Iteration:   2820, Loss function: 3.527, Average Loss: 4.236, avg. samples / sec: 66068.01
Iteration:   2820, Loss function: 3.117, Average Loss: 4.256, avg. samples / sec: 65926.49
Iteration:   2820, Loss function: 3.861, Average Loss: 4.250, avg. samples / sec: 65888.21
Iteration:   2820, Loss function: 3.934, Average Loss: 4.261, avg. samples / sec: 65906.54
Iteration:   2820, Loss function: 4.348, Average Loss: 4.235, avg. samples / sec: 65965.00
Iteration:   2820, Loss function: 2.218, Average Loss: 4.256, avg. samples / sec: 66098.56
Iteration:   2820, Loss function: 4.532, Average Loss: 4.282, avg. samples / sec: 65890.49
Iteration:   2820, Loss function: 4.363, Average Loss: 4.244, avg. samples / sec: 65994.01
Iteration:   2820, Loss function: 4.799, Average Loss: 4.264, avg. samples / sec: 65850.55
Iteration:   2820, Loss function: 3.648, Average Loss: 4.228, avg. samples / sec: 65961.51
Iteration:   2820, Loss function: 4.303, Average Loss: 4.262, avg. samples / sec: 65948.55
Iteration:   2820, Loss function: 4.656, Average Loss: 4.245, avg. samples / sec: 65786.09
Iteration:   2820, Loss function: 4.371, Average Loss: 4.237, avg. samples / sec: 65891.01
Iteration:   2820, Loss function: 3.473, Average Loss: 4.260, avg. samples / sec: 65856.22
Iteration:   2820, Loss function: 4.236, Average Loss: 4.259, avg. samples / sec: 65927.48
Iteration:   2820, Loss function: 4.516, Average Loss: 4.255, avg. samples / sec: 65907.74
Iteration:   2820, Loss function: 3.907, Average Loss: 4.240, avg. samples / sec: 65747.64
Iteration:   2820, Loss function: 4.126, Average Loss: 4.261, avg. samples / sec: 65965.52
Iteration:   2820, Loss function: 2.529, Average Loss: 4.258, avg. samples / sec: 65846.09
Iteration:   2820, Loss function: 2.680, Average Loss: 4.241, avg. samples / sec: 65903.52
Iteration:   2820, Loss function: 3.463, Average Loss: 4.233, avg. samples / sec: 65860.09
Iteration:   2820, Loss function: 3.496, Average Loss: 4.238, avg. samples / sec: 65774.64
Iteration:   2820, Loss function: 3.933, Average Loss: 4.257, avg. samples / sec: 65819.77
Iteration:   2820, Loss function: 3.933, Average Loss: 4.242, avg. samples / sec: 65785.36
Iteration:   2840, Loss function: 4.139, Average Loss: 4.239, avg. samples / sec: 65834.10
Iteration:   2840, Loss function: 4.327, Average Loss: 4.230, avg. samples / sec: 66035.41
Iteration:   2840, Loss function: 2.646, Average Loss: 4.241, avg. samples / sec: 65853.48
Iteration:   2840, Loss function: 3.636, Average Loss: 4.237, avg. samples / sec: 65945.24
Iteration:   2840, Loss function: 3.675, Average Loss: 4.239, avg. samples / sec: 65774.67
Iteration:   2840, Loss function: 4.825, Average Loss: 4.228, avg. samples / sec: 65772.89
Iteration:   2840, Loss function: 4.093, Average Loss: 4.244, avg. samples / sec: 65776.64
Iteration:   2840, Loss function: 4.625, Average Loss: 4.237, avg. samples / sec: 65768.66
Iteration:   2840, Loss function: 3.674, Average Loss: 4.241, avg. samples / sec: 65875.12
Iteration:   2840, Loss function: 4.724, Average Loss: 4.255, avg. samples / sec: 65795.61
Iteration:   2840, Loss function: 3.835, Average Loss: 4.213, avg. samples / sec: 65667.98
Iteration:   2840, Loss function: 3.518, Average Loss: 4.256, avg. samples / sec: 65908.73
Iteration:   2840, Loss function: 4.889, Average Loss: 4.255, avg. samples / sec: 65978.00
Iteration:   2840, Loss function: 4.303, Average Loss: 4.254, avg. samples / sec: 65671.10
Iteration:   2840, Loss function: 4.924, Average Loss: 4.259, avg. samples / sec: 65829.36
Iteration:   2840, Loss function: 4.088, Average Loss: 4.251, avg. samples / sec: 65748.01
Iteration:   2840, Loss function: 3.697, Average Loss: 4.250, avg. samples / sec: 65716.30
Iteration:   2840, Loss function: 3.795, Average Loss: 4.220, avg. samples / sec: 65791.28
Iteration:   2840, Loss function: 4.170, Average Loss: 4.233, avg. samples / sec: 65726.82
Iteration:   2840, Loss function: 4.010, Average Loss: 4.220, avg. samples / sec: 65848.74
Iteration:   2840, Loss function: 5.238, Average Loss: 4.259, avg. samples / sec: 65754.57
Iteration:   2840, Loss function: 4.390, Average Loss: 4.250, avg. samples / sec: 65784.40
Iteration:   2840, Loss function: 4.104, Average Loss: 4.277, avg. samples / sec: 65718.36
Iteration:   2840, Loss function: 4.848, Average Loss: 4.239, avg. samples / sec: 65833.48
Iteration:   2840, Loss function: 3.510, Average Loss: 4.238, avg. samples / sec: 65910.42
Iteration:   2840, Loss function: 3.355, Average Loss: 4.238, avg. samples / sec: 65706.56
Iteration:   2840, Loss function: 2.419, Average Loss: 4.257, avg. samples / sec: 65730.22
Iteration:   2840, Loss function: 4.222, Average Loss: 4.229, avg. samples / sec: 65745.31
Iteration:   2840, Loss function: 3.781, Average Loss: 4.252, avg. samples / sec: 65736.63
Iteration:   2840, Loss function: 5.666, Average Loss: 4.257, avg. samples / sec: 65729.27
Iteration:   2860, Loss function: 4.651, Average Loss: 4.207, avg. samples / sec: 66060.92
Iteration:   2860, Loss function: 5.022, Average Loss: 4.241, avg. samples / sec: 65984.12
Iteration:   2860, Loss function: 3.150, Average Loss: 4.237, avg. samples / sec: 65941.82
Iteration:   2860, Loss function: 2.825, Average Loss: 4.251, avg. samples / sec: 66084.37
Iteration:   2860, Loss function: 5.998, Average Loss: 4.223, avg. samples / sec: 65934.54
Iteration:   2860, Loss function: 4.674, Average Loss: 4.242, avg. samples / sec: 65938.83
Iteration:   2860, Loss function: 3.854, Average Loss: 4.231, avg. samples / sec: 65896.09
Iteration:   2860, Loss function: 3.298, Average Loss: 4.249, avg. samples / sec: 65990.08
Iteration:   2860, Loss function: 4.356, Average Loss: 4.223, avg. samples / sec: 65824.13
Iteration:   2860, Loss function: 5.160, Average Loss: 4.234, avg. samples / sec: 66022.70
Iteration:   2860, Loss function: 3.903, Average Loss: 4.258, avg. samples / sec: 66104.33
Iteration:   2860, Loss function: 3.828, Average Loss: 4.230, avg. samples / sec: 65977.14
Iteration:   2860, Loss function: 3.622, Average Loss: 4.249, avg. samples / sec: 65987.21
Iteration:   2860, Loss function: 3.579, Average Loss: 4.231, avg. samples / sec: 65991.38
Iteration:   2860, Loss function: 4.867, Average Loss: 4.220, avg. samples / sec: 66017.13
Iteration:   2860, Loss function: 4.043, Average Loss: 4.237, avg. samples / sec: 65833.97
Iteration:   2860, Loss function: 4.296, Average Loss: 4.244, avg. samples / sec: 65925.59
Iteration:   2860, Loss function: 3.601, Average Loss: 4.252, avg. samples / sec: 65845.35
Iteration:   2860, Loss function: 3.602, Average Loss: 4.229, avg. samples / sec: 65801.18
Iteration:   2860, Loss function: 3.542, Average Loss: 4.249, avg. samples / sec: 65875.39
Iteration:   2860, Loss function: 4.186, Average Loss: 4.256, avg. samples / sec: 65897.39
Iteration:   2860, Loss function: 4.155, Average Loss: 4.211, avg. samples / sec: 65934.60
Iteration:   2860, Loss function: 3.169, Average Loss: 4.250, avg. samples / sec: 65838.89
Iteration:   2860, Loss function: 4.573, Average Loss: 4.271, avg. samples / sec: 65908.91
Iteration:   2860, Loss function: 3.488, Average Loss: 4.233, avg. samples / sec: 65934.63
Iteration:   2860, Loss function: 4.102, Average Loss: 4.214, avg. samples / sec: 65863.05
Iteration:   2860, Loss function: 3.654, Average Loss: 4.234, avg. samples / sec: 65684.57
Iteration:   2860, Loss function: 3.877, Average Loss: 4.249, avg. samples / sec: 65859.23
Iteration:   2860, Loss function: 4.353, Average Loss: 4.250, avg. samples / sec: 65934.29
Iteration:   2860, Loss function: 4.195, Average Loss: 4.254, avg. samples / sec: 65889.01
:::MLL 1558651600.568 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558651600.569 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 3.627, Average Loss: 4.237, avg. samples / sec: 65499.17
Iteration:   2880, Loss function: 3.735, Average Loss: 4.233, avg. samples / sec: 65695.78
Iteration:   2880, Loss function: 3.804, Average Loss: 4.229, avg. samples / sec: 65649.38
Iteration:   2880, Loss function: 4.752, Average Loss: 4.233, avg. samples / sec: 65560.51
Iteration:   2880, Loss function: 4.605, Average Loss: 4.208, avg. samples / sec: 65684.54
Iteration:   2880, Loss function: 3.800, Average Loss: 4.247, avg. samples / sec: 65624.47
Iteration:   2880, Loss function: 4.542, Average Loss: 4.237, avg. samples / sec: 65517.78
Iteration:   2880, Loss function: 3.626, Average Loss: 4.247, avg. samples / sec: 65664.43
Iteration:   2880, Loss function: 4.824, Average Loss: 4.231, avg. samples / sec: 65454.64
Iteration:   2880, Loss function: 3.606, Average Loss: 4.224, avg. samples / sec: 65543.56
Iteration:   2880, Loss function: 4.350, Average Loss: 4.248, avg. samples / sec: 65620.34
Iteration:   2880, Loss function: 4.953, Average Loss: 4.219, avg. samples / sec: 65472.55
Iteration:   2880, Loss function: 3.440, Average Loss: 4.228, avg. samples / sec: 65540.75
Iteration:   2880, Loss function: 4.529, Average Loss: 4.246, avg. samples / sec: 65579.34
Iteration:   2880, Loss function: 3.015, Average Loss: 4.202, avg. samples / sec: 65359.62
Iteration:   2880, Loss function: 3.308, Average Loss: 4.246, avg. samples / sec: 65490.26
Iteration:   2880, Loss function: 3.361, Average Loss: 4.243, avg. samples / sec: 65517.35
Iteration:   2880, Loss function: 2.530, Average Loss: 4.246, avg. samples / sec: 65622.70
Iteration:   2880, Loss function: 4.247, Average Loss: 4.229, avg. samples / sec: 65471.88
Iteration:   2880, Loss function: 4.548, Average Loss: 4.245, avg. samples / sec: 65578.18
Iteration:   2880, Loss function: 4.310, Average Loss: 4.239, avg. samples / sec: 65463.67
Iteration:   2880, Loss function: 3.801, Average Loss: 4.251, avg. samples / sec: 65515.65
Iteration:   2880, Loss function: 3.222, Average Loss: 4.209, avg. samples / sec: 65505.20
Iteration:   2880, Loss function: 4.016, Average Loss: 4.254, avg. samples / sec: 65441.78
Iteration:   2880, Loss function: 3.742, Average Loss: 4.249, avg. samples / sec: 65341.32
Iteration:   2880, Loss function: 3.673, Average Loss: 4.248, avg. samples / sec: 65433.40
Iteration:   2880, Loss function: 4.188, Average Loss: 4.225, avg. samples / sec: 65425.04
Iteration:   2880, Loss function: 5.272, Average Loss: 4.218, avg. samples / sec: 65399.11
Iteration:   2880, Loss function: 4.039, Average Loss: 4.267, avg. samples / sec: 65428.87
Iteration:   2880, Loss function: 3.944, Average Loss: 4.228, avg. samples / sec: 65415.23
Iteration:   2900, Loss function: 4.824, Average Loss: 4.218, avg. samples / sec: 66205.38
Iteration:   2900, Loss function: 3.872, Average Loss: 4.220, avg. samples / sec: 66192.82
Iteration:   2900, Loss function: 2.338, Average Loss: 4.239, avg. samples / sec: 66154.82
Iteration:   2900, Loss function: 5.371, Average Loss: 4.235, avg. samples / sec: 66138.73
Iteration:   2900, Loss function: 3.410, Average Loss: 4.196, avg. samples / sec: 66163.58
Iteration:   2900, Loss function: 5.333, Average Loss: 4.228, avg. samples / sec: 66094.01
Iteration:   2900, Loss function: 3.319, Average Loss: 4.239, avg. samples / sec: 66167.77
Iteration:   2900, Loss function: 5.498, Average Loss: 4.236, avg. samples / sec: 66037.67
Iteration:   2900, Loss function: 4.122, Average Loss: 4.209, avg. samples / sec: 66067.14
Iteration:   2900, Loss function: 5.240, Average Loss: 4.251, avg. samples / sec: 66221.81
Iteration:   2900, Loss function: 3.537, Average Loss: 4.234, avg. samples / sec: 66171.44
Iteration:   2900, Loss function: 4.279, Average Loss: 4.230, avg. samples / sec: 65989.18
Iteration:   2900, Loss function: 4.900, Average Loss: 4.249, avg. samples / sec: 66130.57
Iteration:   2900, Loss function: 5.682, Average Loss: 4.229, avg. samples / sec: 66021.68
Iteration:   2900, Loss function: 3.676, Average Loss: 4.251, avg. samples / sec: 66122.51
Iteration:   2900, Loss function: 4.449, Average Loss: 4.260, avg. samples / sec: 66207.15
Iteration:   2900, Loss function: 3.708, Average Loss: 4.226, avg. samples / sec: 66212.82
Iteration:   2900, Loss function: 5.124, Average Loss: 4.243, avg. samples / sec: 65977.66
Iteration:   2900, Loss function: 2.670, Average Loss: 4.238, avg. samples / sec: 66067.08
Iteration:   2900, Loss function: 3.640, Average Loss: 4.243, avg. samples / sec: 66106.50
Iteration:   2900, Loss function: 3.576, Average Loss: 4.209, avg. samples / sec: 66079.69
Iteration:   2900, Loss function: 4.579, Average Loss: 4.223, avg. samples / sec: 66058.32
Iteration:   2900, Loss function: 4.199, Average Loss: 4.212, avg. samples / sec: 66134.79
Iteration:   2900, Loss function: 3.879, Average Loss: 4.219, avg. samples / sec: 65936.20
Iteration:   2900, Loss function: 2.602, Average Loss: 4.235, avg. samples / sec: 66043.43
Iteration:   2900, Loss function: 4.079, Average Loss: 4.241, avg. samples / sec: 66019.91
Iteration:   2900, Loss function: 3.675, Average Loss: 4.246, avg. samples / sec: 65924.95
Iteration:   2900, Loss function: 3.832, Average Loss: 4.230, avg. samples / sec: 65886.24
Iteration:   2900, Loss function: 4.594, Average Loss: 4.239, avg. samples / sec: 65971.76
Iteration:   2900, Loss function: 3.752, Average Loss: 4.222, avg. samples / sec: 66036.31
Iteration:   2920, Loss function: 3.951, Average Loss: 4.213, avg. samples / sec: 66165.97
Iteration:   2920, Loss function: 4.575, Average Loss: 4.222, avg. samples / sec: 66065.97
Iteration:   2920, Loss function: 3.608, Average Loss: 4.231, avg. samples / sec: 65978.53
Iteration:   2920, Loss function: 3.210, Average Loss: 4.214, avg. samples / sec: 66131.60
Iteration:   2920, Loss function: 4.037, Average Loss: 4.214, avg. samples / sec: 65901.36
Iteration:   2920, Loss function: 3.121, Average Loss: 4.217, avg. samples / sec: 66199.78
Iteration:   2920, Loss function: 3.794, Average Loss: 4.192, avg. samples / sec: 65962.56
Iteration:   2920, Loss function: 3.521, Average Loss: 4.234, avg. samples / sec: 65920.75
Iteration:   2920, Loss function: 4.123, Average Loss: 4.229, avg. samples / sec: 66019.82
Iteration:   2920, Loss function: 3.880, Average Loss: 4.234, avg. samples / sec: 65967.72
Iteration:   2920, Loss function: 3.392, Average Loss: 4.219, avg. samples / sec: 66128.28
Iteration:   2920, Loss function: 3.971, Average Loss: 4.234, avg. samples / sec: 66024.12
Iteration:   2920, Loss function: 3.274, Average Loss: 4.202, avg. samples / sec: 65942.07
Iteration:   2920, Loss function: 3.706, Average Loss: 4.234, avg. samples / sec: 66039.84
Iteration:   2920, Loss function: 5.235, Average Loss: 4.259, avg. samples / sec: 66043.15
Iteration:   2920, Loss function: 3.292, Average Loss: 4.209, avg. samples / sec: 66037.98
Iteration:   2920, Loss function: 5.059, Average Loss: 4.231, avg. samples / sec: 66040.24
Iteration:   2920, Loss function: 4.264, Average Loss: 4.234, avg. samples / sec: 66037.21
Iteration:   2920, Loss function: 5.701, Average Loss: 4.220, avg. samples / sec: 65783.73
Iteration:   2920, Loss function: 3.631, Average Loss: 4.243, avg. samples / sec: 65941.79
Iteration:   2920, Loss function: 3.728, Average Loss: 4.220, avg. samples / sec: 65962.65
Iteration:   2920, Loss function: 3.390, Average Loss: 4.224, avg. samples / sec: 65835.08
Iteration:   2920, Loss function: 4.338, Average Loss: 4.205, avg. samples / sec: 65973.21
Iteration:   2920, Loss function: 3.943, Average Loss: 4.247, avg. samples / sec: 65934.60
Iteration:   2920, Loss function: 3.998, Average Loss: 4.243, avg. samples / sec: 65963.55
Iteration:   2920, Loss function: 4.081, Average Loss: 4.232, avg. samples / sec: 65805.54
Iteration:   2920, Loss function: 4.090, Average Loss: 4.234, avg. samples / sec: 65943.15
Iteration:   2920, Loss function: 4.726, Average Loss: 4.248, avg. samples / sec: 65758.84
Iteration:   2920, Loss function: 3.495, Average Loss: 4.246, avg. samples / sec: 65910.33
Iteration:   2920, Loss function: 3.798, Average Loss: 4.233, avg. samples / sec: 65678.05
:::MLL 1558651602.354 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558651602.355 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.462, Average Loss: 4.210, avg. samples / sec: 65692.35
Iteration:   2940, Loss function: 3.780, Average Loss: 4.213, avg. samples / sec: 65706.87
Iteration:   2940, Loss function: 3.681, Average Loss: 4.184, avg. samples / sec: 65648.10
Iteration:   2940, Loss function: 4.493, Average Loss: 4.227, avg. samples / sec: 65637.37
Iteration:   2940, Loss function: 4.704, Average Loss: 4.213, avg. samples / sec: 65717.16
Iteration:   2940, Loss function: 5.085, Average Loss: 4.226, avg. samples / sec: 65641.50
Iteration:   2940, Loss function: 3.948, Average Loss: 4.242, avg. samples / sec: 65728.32
Iteration:   2940, Loss function: 3.563, Average Loss: 4.236, avg. samples / sec: 65785.42
Iteration:   2940, Loss function: 6.283, Average Loss: 4.236, avg. samples / sec: 65810.95
Iteration:   2940, Loss function: 4.834, Average Loss: 4.231, avg. samples / sec: 65577.08
Iteration:   2940, Loss function: 3.933, Average Loss: 4.258, avg. samples / sec: 65589.35
Iteration:   2940, Loss function: 4.423, Average Loss: 4.241, avg. samples / sec: 65668.35
Iteration:   2940, Loss function: 4.271, Average Loss: 4.231, avg. samples / sec: 65586.42
Iteration:   2940, Loss function: 3.523, Average Loss: 4.218, avg. samples / sec: 65663.18
Iteration:   2940, Loss function: 3.962, Average Loss: 4.235, avg. samples / sec: 65598.66
Iteration:   2940, Loss function: 4.395, Average Loss: 4.245, avg. samples / sec: 65747.58
Iteration:   2940, Loss function: 3.854, Average Loss: 4.225, avg. samples / sec: 65662.11
Iteration:   2940, Loss function: 4.340, Average Loss: 4.209, avg. samples / sec: 65492.51
Iteration:   2940, Loss function: 4.071, Average Loss: 4.218, avg. samples / sec: 65623.86
Iteration:   2940, Loss function: 4.309, Average Loss: 4.213, avg. samples / sec: 65527.99
Iteration:   2940, Loss function: 3.895, Average Loss: 4.198, avg. samples / sec: 65520.19
Iteration:   2940, Loss function: 3.770, Average Loss: 4.227, avg. samples / sec: 65570.21
Iteration:   2940, Loss function: 4.690, Average Loss: 4.210, avg. samples / sec: 65438.53
Iteration:   2940, Loss function: 3.730, Average Loss: 4.228, avg. samples / sec: 65571.49
Iteration:   2940, Loss function: 3.934, Average Loss: 4.209, avg. samples / sec: 65543.13
Iteration:   2940, Loss function: 4.261, Average Loss: 4.241, avg. samples / sec: 65585.19
Iteration:   2940, Loss function: 4.709, Average Loss: 4.206, avg. samples / sec: 65579.98
Iteration:   2940, Loss function: 4.381, Average Loss: 4.215, avg. samples / sec: 65449.05
Iteration:   2940, Loss function: 3.447, Average Loss: 4.243, avg. samples / sec: 65683.81
Iteration:   2940, Loss function: 4.512, Average Loss: 4.228, avg. samples / sec: 65391.68
Iteration:   2960, Loss function: 4.132, Average Loss: 4.182, avg. samples / sec: 65842.22
Iteration:   2960, Loss function: 4.850, Average Loss: 4.191, avg. samples / sec: 65978.74
Iteration:   2960, Loss function: 3.497, Average Loss: 4.204, avg. samples / sec: 65934.20
Iteration:   2960, Loss function: 4.465, Average Loss: 4.208, avg. samples / sec: 65817.59
Iteration:   2960, Loss function: 3.861, Average Loss: 4.223, avg. samples / sec: 66057.91
Iteration:   2960, Loss function: 5.781, Average Loss: 4.212, avg. samples / sec: 65681.82
Iteration:   2960, Loss function: 4.036, Average Loss: 4.231, avg. samples / sec: 65865.17
Iteration:   2960, Loss function: 3.265, Average Loss: 4.221, avg. samples / sec: 65720.29
Iteration:   2960, Loss function: 3.911, Average Loss: 4.220, avg. samples / sec: 65881.68
Iteration:   2960, Loss function: 3.252, Average Loss: 4.232, avg. samples / sec: 65924.27
Iteration:   2960, Loss function: 3.861, Average Loss: 4.234, avg. samples / sec: 65764.54
Iteration:   2960, Loss function: 3.572, Average Loss: 4.235, avg. samples / sec: 65816.72
Iteration:   2960, Loss function: 4.224, Average Loss: 4.212, avg. samples / sec: 65840.68
Iteration:   2960, Loss function: 3.659, Average Loss: 4.214, avg. samples / sec: 65843.57
Iteration:   2960, Loss function: 4.758, Average Loss: 4.215, avg. samples / sec: 65797.30
Iteration:   2960, Loss function: 4.505, Average Loss: 4.242, avg. samples / sec: 65880.35
Iteration:   2960, Loss function: 4.005, Average Loss: 4.250, avg. samples / sec: 65772.92
Iteration:   2960, Loss function: 3.845, Average Loss: 4.228, avg. samples / sec: 65751.35
Iteration:   2960, Loss function: 4.105, Average Loss: 4.204, avg. samples / sec: 65853.14
Iteration:   2960, Loss function: 5.854, Average Loss: 4.210, avg. samples / sec: 65806.00
Iteration:   2960, Loss function: 3.655, Average Loss: 4.238, avg. samples / sec: 65685.58
Iteration:   2960, Loss function: 4.024, Average Loss: 4.242, avg. samples / sec: 65745.25
Iteration:   2960, Loss function: 3.800, Average Loss: 4.225, avg. samples / sec: 65642.72
Iteration:   2960, Loss function: 3.797, Average Loss: 4.218, avg. samples / sec: 65774.18
Iteration:   2960, Loss function: 2.957, Average Loss: 4.228, avg. samples / sec: 65668.96
Iteration:   2960, Loss function: 3.341, Average Loss: 4.212, avg. samples / sec: 65787.14
Iteration:   2960, Loss function: 4.651, Average Loss: 4.210, avg. samples / sec: 65480.06
Iteration:   2960, Loss function: 3.874, Average Loss: 4.222, avg. samples / sec: 65727.55
Iteration:   2960, Loss function: 3.669, Average Loss: 4.232, avg. samples / sec: 65608.25
Iteration:   2960, Loss function: 2.328, Average Loss: 4.208, avg. samples / sec: 65589.90
Iteration:   2980, Loss function: 3.680, Average Loss: 4.225, avg. samples / sec: 65930.93
Iteration:   2980, Loss function: 3.880, Average Loss: 4.197, avg. samples / sec: 65828.22
Iteration:   2980, Loss function: 3.556, Average Loss: 4.205, avg. samples / sec: 66214.68
Iteration:   2980, Loss function: 4.685, Average Loss: 4.206, avg. samples / sec: 66044.48
Iteration:   2980, Loss function: 5.660, Average Loss: 4.241, avg. samples / sec: 65940.52
Iteration:   2980, Loss function: 3.349, Average Loss: 4.215, avg. samples / sec: 65890.05
Iteration:   2980, Loss function: 4.296, Average Loss: 4.203, avg. samples / sec: 65826.04
Iteration:   2980, Loss function: 3.654, Average Loss: 4.216, avg. samples / sec: 65982.54
Iteration:   2980, Loss function: 3.089, Average Loss: 4.218, avg. samples / sec: 66039.22
Iteration:   2980, Loss function: 3.814, Average Loss: 4.183, avg. samples / sec: 65773.14
Iteration:   2980, Loss function: 3.769, Average Loss: 4.224, avg. samples / sec: 66084.93
Iteration:   2980, Loss function: 3.556, Average Loss: 4.209, avg. samples / sec: 65811.59
Iteration:   2980, Loss function: 4.217, Average Loss: 4.225, avg. samples / sec: 65883.40
Iteration:   2980, Loss function: 3.907, Average Loss: 4.213, avg. samples / sec: 65841.48
Iteration:   2980, Loss function: 4.247, Average Loss: 4.181, avg. samples / sec: 65722.77
Iteration:   2980, Loss function: 3.792, Average Loss: 4.199, avg. samples / sec: 65921.37
Iteration:   2980, Loss function: 4.184, Average Loss: 4.209, avg. samples / sec: 65996.45
Iteration:   2980, Loss function: 4.581, Average Loss: 4.218, avg. samples / sec: 65803.88
Iteration:   2980, Loss function: 3.051, Average Loss: 4.214, avg. samples / sec: 65925.53
Iteration:   2980, Loss function: 4.686, Average Loss: 4.232, avg. samples / sec: 65923.40
Iteration:   2980, Loss function: 3.651, Average Loss: 4.205, avg. samples / sec: 65842.95
Iteration:   2980, Loss function: 2.900, Average Loss: 4.212, avg. samples / sec: 65827.30
Iteration:   2980, Loss function: 4.302, Average Loss: 4.211, avg. samples / sec: 65821.52
Iteration:   2980, Loss function: 5.004, Average Loss: 4.223, avg. samples / sec: 65840.09
Iteration:   2980, Loss function: 4.761, Average Loss: 4.234, avg. samples / sec: 65833.85
Iteration:   2980, Loss function: 3.763, Average Loss: 4.229, avg. samples / sec: 65729.70
Iteration:   2980, Loss function: 2.281, Average Loss: 4.229, avg. samples / sec: 65744.29
Iteration:   2980, Loss function: 4.491, Average Loss: 4.220, avg. samples / sec: 65817.74
Iteration:   2980, Loss function: 4.162, Average Loss: 4.244, avg. samples / sec: 65742.79
Iteration:   2980, Loss function: 4.083, Average Loss: 4.208, avg. samples / sec: 65787.23
Iteration:   3000, Loss function: 2.893, Average Loss: 4.190, avg. samples / sec: 66117.60
Iteration:   3000, Loss function: 4.193, Average Loss: 4.177, avg. samples / sec: 66165.28
Iteration:   3000, Loss function: 2.918, Average Loss: 4.214, avg. samples / sec: 66191.95
Iteration:   3000, Loss function: 3.682, Average Loss: 4.210, avg. samples / sec: 66098.28
Iteration:   3000, Loss function: 4.266, Average Loss: 4.218, avg. samples / sec: 66014.81
Iteration:   3000, Loss function: 2.862, Average Loss: 4.200, avg. samples / sec: 66175.97
Iteration:   3000, Loss function: 4.165, Average Loss: 4.201, avg. samples / sec: 66124.89
Iteration:   3000, Loss function: 5.289, Average Loss: 4.204, avg. samples / sec: 66024.24
Iteration:   3000, Loss function: 3.390, Average Loss: 4.206, avg. samples / sec: 66075.82
Iteration:   3000, Loss function: 2.828, Average Loss: 4.227, avg. samples / sec: 66184.64
Iteration:   3000, Loss function: 3.815, Average Loss: 4.210, avg. samples / sec: 66036.00
Iteration:   3000, Loss function: 3.390, Average Loss: 4.196, avg. samples / sec: 66015.92
Iteration:   3000, Loss function: 4.624, Average Loss: 4.217, avg. samples / sec: 66215.99
Iteration:   3000, Loss function: 3.327, Average Loss: 4.196, avg. samples / sec: 65987.98
Iteration:   3000, Loss function: 3.721, Average Loss: 4.204, avg. samples / sec: 66032.84
Iteration:   3000, Loss function: 3.263, Average Loss: 4.221, avg. samples / sec: 66161.12
Iteration:   3000, Loss function: 3.217, Average Loss: 4.232, avg. samples / sec: 65966.23
Iteration:   3000, Loss function: 4.092, Average Loss: 4.208, avg. samples / sec: 66068.10
Iteration:   3000, Loss function: 3.432, Average Loss: 4.211, avg. samples / sec: 66018.58
Iteration:   3000, Loss function: 5.188, Average Loss: 4.229, avg. samples / sec: 66048.69
Iteration:   3000, Loss function: 3.325, Average Loss: 4.198, avg. samples / sec: 66045.59
Iteration:   3000, Loss function: 3.744, Average Loss: 4.216, avg. samples / sec: 65980.41
Iteration:   3000, Loss function: 3.557, Average Loss: 4.244, avg. samples / sec: 66123.68
Iteration:   3000, Loss function: 4.673, Average Loss: 4.181, avg. samples / sec: 65951.88
Iteration:   3000, Loss function: 2.596, Average Loss: 4.221, avg. samples / sec: 65932.22
Iteration:   3000, Loss function: 3.071, Average Loss: 4.220, avg. samples / sec: 66040.18
Iteration:   3000, Loss function: 2.839, Average Loss: 4.215, avg. samples / sec: 65914.12
Iteration:   3000, Loss function: 5.003, Average Loss: 4.196, avg. samples / sec: 65916.87
Iteration:   3000, Loss function: 3.837, Average Loss: 4.205, avg. samples / sec: 66033.93
Iteration:   3000, Loss function: 4.366, Average Loss: 4.214, avg. samples / sec: 65880.04
:::MLL 1558651604.141 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558651604.141 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 3.457, Average Loss: 4.169, avg. samples / sec: 65528.08
Iteration:   3020, Loss function: 4.787, Average Loss: 4.207, avg. samples / sec: 65533.53
Iteration:   3020, Loss function: 3.955, Average Loss: 4.205, avg. samples / sec: 65567.56
Iteration:   3020, Loss function: 4.385, Average Loss: 4.203, avg. samples / sec: 65524.15
Iteration:   3020, Loss function: 3.974, Average Loss: 4.189, avg. samples / sec: 65472.94
Iteration:   3020, Loss function: 3.349, Average Loss: 4.189, avg. samples / sec: 65714.86
Iteration:   3020, Loss function: 4.019, Average Loss: 4.210, avg. samples / sec: 65478.27
Iteration:   3020, Loss function: 2.761, Average Loss: 4.214, avg. samples / sec: 65564.42
Iteration:   3020, Loss function: 3.064, Average Loss: 4.213, avg. samples / sec: 65466.25
Iteration:   3020, Loss function: 4.562, Average Loss: 4.197, avg. samples / sec: 65473.46
Iteration:   3020, Loss function: 3.217, Average Loss: 4.182, avg. samples / sec: 65601.96
Iteration:   3020, Loss function: 3.576, Average Loss: 4.217, avg. samples / sec: 65621.14
Iteration:   3020, Loss function: 4.304, Average Loss: 4.197, avg. samples / sec: 65475.10
Iteration:   3020, Loss function: 4.312, Average Loss: 4.201, avg. samples / sec: 65518.15
Iteration:   3020, Loss function: 3.909, Average Loss: 4.198, avg. samples / sec: 65447.71
Iteration:   3020, Loss function: 4.743, Average Loss: 4.213, avg. samples / sec: 65511.08
Iteration:   3020, Loss function: 4.725, Average Loss: 4.216, avg. samples / sec: 65430.90
Iteration:   3020, Loss function: 3.932, Average Loss: 4.189, avg. samples / sec: 65497.50
Iteration:   3020, Loss function: 3.919, Average Loss: 4.213, avg. samples / sec: 65641.28
Iteration:   3020, Loss function: 3.213, Average Loss: 4.207, avg. samples / sec: 65467.35
Iteration:   3020, Loss function: 4.627, Average Loss: 4.216, avg. samples / sec: 65521.95
Iteration:   3020, Loss function: 3.462, Average Loss: 4.205, avg. samples / sec: 65529.42
Iteration:   3020, Loss function: 3.554, Average Loss: 4.199, avg. samples / sec: 65590.75
Iteration:   3020, Loss function: 4.619, Average Loss: 4.193, avg. samples / sec: 65417.90
Iteration:   3020, Loss function: 4.021, Average Loss: 4.200, avg. samples / sec: 65427.87
Iteration:   3020, Loss function: 4.645, Average Loss: 4.238, avg. samples / sec: 65461.78
Iteration:   3020, Loss function: 3.159, Average Loss: 4.224, avg. samples / sec: 65406.85
Iteration:   3020, Loss function: 4.011, Average Loss: 4.222, avg. samples / sec: 65330.38
Iteration:   3020, Loss function: 3.373, Average Loss: 4.209, avg. samples / sec: 65313.13
Iteration:   3020, Loss function: 4.977, Average Loss: 4.224, avg. samples / sec: 65339.23
Iteration:   3040, Loss function: 4.522, Average Loss: 4.189, avg. samples / sec: 66196.77
Iteration:   3040, Loss function: 4.854, Average Loss: 4.199, avg. samples / sec: 66096.77
Iteration:   3040, Loss function: 3.787, Average Loss: 4.194, avg. samples / sec: 66250.88
Iteration:   3040, Loss function: 4.823, Average Loss: 4.207, avg. samples / sec: 66093.45
Iteration:   3040, Loss function: 3.782, Average Loss: 4.194, avg. samples / sec: 66144.69
Iteration:   3040, Loss function: 3.355, Average Loss: 4.238, avg. samples / sec: 66246.71
Iteration:   3040, Loss function: 3.160, Average Loss: 4.210, avg. samples / sec: 66063.46
Iteration:   3040, Loss function: 3.426, Average Loss: 4.203, avg. samples / sec: 66267.74
Iteration:   3040, Loss function: 5.100, Average Loss: 4.215, avg. samples / sec: 66147.09
Iteration:   3040, Loss function: 3.515, Average Loss: 4.190, avg. samples / sec: 66174.73
Iteration:   3040, Loss function: 4.008, Average Loss: 4.203, avg. samples / sec: 66143.95
Iteration:   3040, Loss function: 4.742, Average Loss: 4.203, avg. samples / sec: 65978.43
Iteration:   3040, Loss function: 4.369, Average Loss: 4.209, avg. samples / sec: 65998.83
Iteration:   3040, Loss function: 3.910, Average Loss: 4.180, avg. samples / sec: 66047.39
Iteration:   3040, Loss function: 3.249, Average Loss: 4.161, avg. samples / sec: 65897.11
Iteration:   3040, Loss function: 4.752, Average Loss: 4.192, avg. samples / sec: 65978.09
Iteration:   3040, Loss function: 3.781, Average Loss: 4.203, avg. samples / sec: 65935.16
Iteration:   3040, Loss function: 3.914, Average Loss: 4.220, avg. samples / sec: 66176.66
Iteration:   3040, Loss function: 3.907, Average Loss: 4.218, avg. samples / sec: 66141.90
Iteration:   3040, Loss function: 4.314, Average Loss: 4.192, avg. samples / sec: 65973.95
Iteration:   3040, Loss function: 3.830, Average Loss: 4.192, avg. samples / sec: 66049.90
Iteration:   3040, Loss function: 2.952, Average Loss: 4.196, avg. samples / sec: 66104.24
Iteration:   3040, Loss function: 3.427, Average Loss: 4.202, avg. samples / sec: 66084.99
Iteration:   3040, Loss function: 4.442, Average Loss: 4.211, avg. samples / sec: 66002.01
Iteration:   3040, Loss function: 3.491, Average Loss: 4.189, avg. samples / sec: 65926.58
Iteration:   3040, Loss function: 4.165, Average Loss: 4.216, avg. samples / sec: 66069.74
Iteration:   3040, Loss function: 3.322, Average Loss: 4.207, avg. samples / sec: 66036.37
Iteration:   3040, Loss function: 3.672, Average Loss: 4.209, avg. samples / sec: 66003.83
Iteration:   3040, Loss function: 4.639, Average Loss: 4.225, avg. samples / sec: 66083.22
Iteration:   3040, Loss function: 3.905, Average Loss: 4.190, avg. samples / sec: 65934.35
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558651605.121 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.60 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.47s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.46s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=2.56s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.16890
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31250
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.16681
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04250
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.17499
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.26993
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.17859
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27850
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06786
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30798
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.42188
Current AP: 0.16890 AP goal: 0.23000
:::MLL 1558651608.796 eval_accuracy: {"value": 0.16889575610596175, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558651608.857 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558651608.864 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558651608.864 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 3.484, Average Loss: 4.188, avg. samples / sec: 7886.89
Iteration:   3060, Loss function: 4.510, Average Loss: 4.195, avg. samples / sec: 7887.96
Iteration:   3060, Loss function: 3.557, Average Loss: 4.204, avg. samples / sec: 7887.63
Iteration:   3060, Loss function: 2.077, Average Loss: 4.158, avg. samples / sec: 7887.69
Iteration:   3060, Loss function: 3.683, Average Loss: 4.190, avg. samples / sec: 7888.17
Iteration:   3060, Loss function: 4.173, Average Loss: 4.199, avg. samples / sec: 7888.23
Iteration:   3060, Loss function: 3.586, Average Loss: 4.197, avg. samples / sec: 7887.57
Iteration:   3060, Loss function: 4.308, Average Loss: 4.179, avg. samples / sec: 7885.63
Iteration:   3060, Loss function: 3.214, Average Loss: 4.190, avg. samples / sec: 7885.80
Iteration:   3060, Loss function: 5.013, Average Loss: 4.212, avg. samples / sec: 7887.39
Iteration:   3060, Loss function: 3.884, Average Loss: 4.194, avg. samples / sec: 7884.99
Iteration:   3060, Loss function: 5.149, Average Loss: 4.222, avg. samples / sec: 7889.24
Iteration:   3060, Loss function: 4.080, Average Loss: 4.202, avg. samples / sec: 7886.41
Iteration:   3060, Loss function: 4.452, Average Loss: 4.198, avg. samples / sec: 7886.77
Iteration:   3060, Loss function: 3.572, Average Loss: 4.186, avg. samples / sec: 7886.50
Iteration:   3060, Loss function: 3.941, Average Loss: 4.203, avg. samples / sec: 7884.79
Iteration:   3060, Loss function: 3.973, Average Loss: 4.207, avg. samples / sec: 7887.71
Iteration:   3060, Loss function: 5.326, Average Loss: 4.189, avg. samples / sec: 7888.75
Iteration:   3060, Loss function: 3.203, Average Loss: 4.188, avg. samples / sec: 7885.75
Iteration:   3060, Loss function: 3.380, Average Loss: 4.198, avg. samples / sec: 7887.07
Iteration:   3060, Loss function: 3.760, Average Loss: 4.205, avg. samples / sec: 7885.18
Iteration:   3060, Loss function: 3.430, Average Loss: 4.208, avg. samples / sec: 7885.45
Iteration:   3060, Loss function: 3.829, Average Loss: 4.211, avg. samples / sec: 7886.64
Iteration:   3060, Loss function: 4.486, Average Loss: 4.214, avg. samples / sec: 7886.06
Iteration:   3060, Loss function: 2.711, Average Loss: 4.183, avg. samples / sec: 7885.97
Iteration:   3060, Loss function: 3.569, Average Loss: 4.206, avg. samples / sec: 7886.55
Iteration:   3060, Loss function: 4.713, Average Loss: 4.188, avg. samples / sec: 7886.15
Iteration:   3060, Loss function: 3.317, Average Loss: 4.228, avg. samples / sec: 7884.53
Iteration:   3060, Loss function: 4.390, Average Loss: 4.191, avg. samples / sec: 7886.03
Iteration:   3060, Loss function: 3.735, Average Loss: 4.181, avg. samples / sec: 7884.88
:::MLL 1558651609.677 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558651609.677 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 4.917, Average Loss: 4.184, avg. samples / sec: 65932.07
Iteration:   3080, Loss function: 3.751, Average Loss: 4.183, avg. samples / sec: 65921.52
Iteration:   3080, Loss function: 2.913, Average Loss: 4.183, avg. samples / sec: 65815.96
Iteration:   3080, Loss function: 2.907, Average Loss: 4.187, avg. samples / sec: 65905.92
Iteration:   3080, Loss function: 3.557, Average Loss: 4.192, avg. samples / sec: 65838.53
Iteration:   3080, Loss function: 3.473, Average Loss: 4.152, avg. samples / sec: 65824.01
Iteration:   3080, Loss function: 2.703, Average Loss: 4.173, avg. samples / sec: 65948.11
Iteration:   3080, Loss function: 3.507, Average Loss: 4.191, avg. samples / sec: 65936.20
Iteration:   3080, Loss function: 3.826, Average Loss: 4.174, avg. samples / sec: 65780.90
Iteration:   3080, Loss function: 3.154, Average Loss: 4.214, avg. samples / sec: 65975.56
Iteration:   3080, Loss function: 3.309, Average Loss: 4.175, avg. samples / sec: 65901.79
Iteration:   3080, Loss function: 2.485, Average Loss: 4.206, avg. samples / sec: 65925.99
Iteration:   3080, Loss function: 3.396, Average Loss: 4.192, avg. samples / sec: 65782.99
Iteration:   3080, Loss function: 4.057, Average Loss: 4.195, avg. samples / sec: 65889.10
Iteration:   3080, Loss function: 3.404, Average Loss: 4.179, avg. samples / sec: 65916.16
Iteration:   3080, Loss function: 4.435, Average Loss: 4.195, avg. samples / sec: 65900.84
Iteration:   3080, Loss function: 4.247, Average Loss: 4.173, avg. samples / sec: 65726.23
Iteration:   3080, Loss function: 5.083, Average Loss: 4.176, avg. samples / sec: 65891.81
Iteration:   3080, Loss function: 3.525, Average Loss: 4.196, avg. samples / sec: 65821.86
Iteration:   3080, Loss function: 3.681, Average Loss: 4.195, avg. samples / sec: 65792.51
Iteration:   3080, Loss function: 4.151, Average Loss: 4.180, avg. samples / sec: 65694.46
Iteration:   3080, Loss function: 3.922, Average Loss: 4.184, avg. samples / sec: 65808.24
Iteration:   3080, Loss function: 3.330, Average Loss: 4.174, avg. samples / sec: 65762.15
Iteration:   3080, Loss function: 3.536, Average Loss: 4.185, avg. samples / sec: 65817.99
Iteration:   3080, Loss function: 4.715, Average Loss: 4.174, avg. samples / sec: 65765.40
Iteration:   3080, Loss function: 2.763, Average Loss: 4.199, avg. samples / sec: 65776.61
Iteration:   3080, Loss function: 4.334, Average Loss: 4.198, avg. samples / sec: 65707.33
Iteration:   3080, Loss function: 3.240, Average Loss: 4.205, avg. samples / sec: 65699.18
Iteration:   3080, Loss function: 2.907, Average Loss: 4.194, avg. samples / sec: 65611.48
Iteration:   3080, Loss function: 3.449, Average Loss: 4.179, avg. samples / sec: 65592.12
Iteration:   3100, Loss function: 2.925, Average Loss: 4.173, avg. samples / sec: 64961.99
Iteration:   3100, Loss function: 3.085, Average Loss: 4.179, avg. samples / sec: 65037.09
Iteration:   3100, Loss function: 2.690, Average Loss: 4.165, avg. samples / sec: 65150.65
Iteration:   3100, Loss function: 4.671, Average Loss: 4.168, avg. samples / sec: 65145.32
Iteration:   3100, Loss function: 4.137, Average Loss: 4.185, avg. samples / sec: 65258.93
Iteration:   3100, Loss function: 2.818, Average Loss: 4.174, avg. samples / sec: 64953.76
Iteration:   3100, Loss function: 3.731, Average Loss: 4.194, avg. samples / sec: 65190.52
Iteration:   3100, Loss function: 3.139, Average Loss: 4.163, avg. samples / sec: 65117.54
Iteration:   3100, Loss function: 2.861, Average Loss: 4.179, avg. samples / sec: 65016.03
Iteration:   3100, Loss function: 3.040, Average Loss: 4.167, avg. samples / sec: 64988.75
Iteration:   3100, Loss function: 5.264, Average Loss: 4.173, avg. samples / sec: 64927.96
Iteration:   3100, Loss function: 4.032, Average Loss: 4.163, avg. samples / sec: 64949.18
Iteration:   3100, Loss function: 3.477, Average Loss: 4.181, avg. samples / sec: 64974.15
Iteration:   3100, Loss function: 4.773, Average Loss: 4.177, avg. samples / sec: 65065.95
Iteration:   3100, Loss function: 4.249, Average Loss: 4.176, avg. samples / sec: 65068.29
Iteration:   3100, Loss function: 3.003, Average Loss: 4.167, avg. samples / sec: 65041.41
Iteration:   3100, Loss function: 4.328, Average Loss: 4.183, avg. samples / sec: 65031.99
Iteration:   3100, Loss function: 3.985, Average Loss: 4.168, avg. samples / sec: 65163.64
Iteration:   3100, Loss function: 4.033, Average Loss: 4.157, avg. samples / sec: 65009.19
Iteration:   3100, Loss function: 3.578, Average Loss: 4.143, avg. samples / sec: 64892.42
Iteration:   3100, Loss function: 2.468, Average Loss: 4.172, avg. samples / sec: 64856.40
Iteration:   3100, Loss function: 2.845, Average Loss: 4.184, avg. samples / sec: 65011.53
Iteration:   3100, Loss function: 3.693, Average Loss: 4.191, avg. samples / sec: 64914.30
Iteration:   3100, Loss function: 3.757, Average Loss: 4.186, avg. samples / sec: 64999.45
Iteration:   3100, Loss function: 3.803, Average Loss: 4.206, avg. samples / sec: 64852.91
Iteration:   3100, Loss function: 2.536, Average Loss: 4.186, avg. samples / sec: 65000.50
Iteration:   3100, Loss function: 3.333, Average Loss: 4.181, avg. samples / sec: 64828.24
Iteration:   3100, Loss function: 4.405, Average Loss: 4.186, avg. samples / sec: 64884.14
Iteration:   3100, Loss function: 3.354, Average Loss: 4.164, avg. samples / sec: 64855.36
Iteration:   3100, Loss function: 3.719, Average Loss: 4.162, avg. samples / sec: 64771.06
Iteration:   3120, Loss function: 4.375, Average Loss: 4.161, avg. samples / sec: 65689.75
Iteration:   3120, Loss function: 3.153, Average Loss: 4.130, avg. samples / sec: 65831.02
Iteration:   3120, Loss function: 4.074, Average Loss: 4.172, avg. samples / sec: 65875.36
Iteration:   3120, Loss function: 3.152, Average Loss: 4.166, avg. samples / sec: 65748.96
Iteration:   3120, Loss function: 2.982, Average Loss: 4.139, avg. samples / sec: 65798.72
Iteration:   3120, Loss function: 2.784, Average Loss: 4.166, avg. samples / sec: 65849.75
Iteration:   3120, Loss function: 4.309, Average Loss: 4.155, avg. samples / sec: 65890.33
Iteration:   3120, Loss function: 3.040, Average Loss: 4.168, avg. samples / sec: 65716.70
Iteration:   3120, Loss function: 4.923, Average Loss: 4.164, avg. samples / sec: 65679.22
Iteration:   3120, Loss function: 4.210, Average Loss: 4.162, avg. samples / sec: 65739.76
Iteration:   3120, Loss function: 3.304, Average Loss: 4.161, avg. samples / sec: 65626.98
Iteration:   3120, Loss function: 4.605, Average Loss: 4.171, avg. samples / sec: 65736.29
Iteration:   3120, Loss function: 3.489, Average Loss: 4.171, avg. samples / sec: 65779.09
Iteration:   3120, Loss function: 3.045, Average Loss: 4.170, avg. samples / sec: 65683.72
Iteration:   3120, Loss function: 6.827, Average Loss: 4.180, avg. samples / sec: 65593.83
Iteration:   3120, Loss function: 3.498, Average Loss: 4.180, avg. samples / sec: 65567.92
Iteration:   3120, Loss function: 2.932, Average Loss: 4.154, avg. samples / sec: 65653.21
Iteration:   3120, Loss function: 3.488, Average Loss: 4.151, avg. samples / sec: 65621.96
Iteration:   3120, Loss function: 3.753, Average Loss: 4.165, avg. samples / sec: 65656.14
Iteration:   3120, Loss function: 2.899, Average Loss: 4.151, avg. samples / sec: 65662.38
Iteration:   3120, Loss function: 3.324, Average Loss: 4.184, avg. samples / sec: 65662.57
Iteration:   3120, Loss function: 5.473, Average Loss: 4.169, avg. samples / sec: 65487.21
Iteration:   3120, Loss function: 3.463, Average Loss: 4.154, avg. samples / sec: 65762.18
Iteration:   3120, Loss function: 3.690, Average Loss: 4.161, avg. samples / sec: 65614.78
Iteration:   3120, Loss function: 3.880, Average Loss: 4.154, avg. samples / sec: 65518.33
Iteration:   3120, Loss function: 4.308, Average Loss: 4.153, avg. samples / sec: 65568.93
Iteration:   3120, Loss function: 2.938, Average Loss: 4.175, avg. samples / sec: 65650.76
Iteration:   3120, Loss function: 3.377, Average Loss: 4.155, avg. samples / sec: 65481.65
Iteration:   3120, Loss function: 5.020, Average Loss: 4.153, avg. samples / sec: 65517.29
Iteration:   3120, Loss function: 3.865, Average Loss: 4.191, avg. samples / sec: 65627.83
Iteration:   3140, Loss function: 5.095, Average Loss: 4.161, avg. samples / sec: 65686.93
Iteration:   3140, Loss function: 3.118, Average Loss: 4.143, avg. samples / sec: 65640.70
Iteration:   3140, Loss function: 4.374, Average Loss: 4.154, avg. samples / sec: 65500.21
Iteration:   3140, Loss function: 3.416, Average Loss: 4.156, avg. samples / sec: 65543.99
Iteration:   3140, Loss function: 2.050, Average Loss: 4.154, avg. samples / sec: 65581.59
Iteration:   3140, Loss function: 3.849, Average Loss: 4.112, avg. samples / sec: 65484.57
Iteration:   3140, Loss function: 5.390, Average Loss: 4.147, avg. samples / sec: 65617.75
Iteration:   3140, Loss function: 3.931, Average Loss: 4.155, avg. samples / sec: 65481.07
Iteration:   3140, Loss function: 3.048, Average Loss: 4.145, avg. samples / sec: 65531.31
Iteration:   3140, Loss function: 3.082, Average Loss: 4.149, avg. samples / sec: 65487.67
Iteration:   3140, Loss function: 3.135, Average Loss: 4.140, avg. samples / sec: 65674.87
Iteration:   3140, Loss function: 2.856, Average Loss: 4.140, avg. samples / sec: 65597.56
Iteration:   3140, Loss function: 2.094, Average Loss: 4.156, avg. samples / sec: 65499.30
Iteration:   3140, Loss function: 4.300, Average Loss: 4.144, avg. samples / sec: 65608.43
Iteration:   3140, Loss function: 3.804, Average Loss: 4.142, avg. samples / sec: 65604.43
Iteration:   3140, Loss function: 3.761, Average Loss: 4.142, avg. samples / sec: 65571.07
Iteration:   3140, Loss function: 2.731, Average Loss: 4.154, avg. samples / sec: 65507.58
Iteration:   3140, Loss function: 4.517, Average Loss: 4.154, avg. samples / sec: 65576.71
Iteration:   3140, Loss function: 3.417, Average Loss: 4.137, avg. samples / sec: 65593.19
Iteration:   3140, Loss function: 3.523, Average Loss: 4.165, avg. samples / sec: 65545.97
Iteration:   3140, Loss function: 3.553, Average Loss: 4.171, avg. samples / sec: 65520.46
Iteration:   3140, Loss function: 4.026, Average Loss: 4.155, avg. samples / sec: 65488.98
Iteration:   3140, Loss function: 2.914, Average Loss: 4.147, avg. samples / sec: 65562.74
Iteration:   3140, Loss function: 2.890, Average Loss: 4.153, avg. samples / sec: 65535.60
Iteration:   3140, Loss function: 3.993, Average Loss: 4.144, avg. samples / sec: 65608.49
Iteration:   3140, Loss function: 3.612, Average Loss: 4.128, avg. samples / sec: 65389.62
Iteration:   3140, Loss function: 3.534, Average Loss: 4.174, avg. samples / sec: 65591.94
Iteration:   3140, Loss function: 3.087, Average Loss: 4.156, avg. samples / sec: 65432.15
Iteration:   3140, Loss function: 4.254, Average Loss: 4.170, avg. samples / sec: 65477.93
Iteration:   3140, Loss function: 3.277, Average Loss: 4.160, avg. samples / sec: 65474.95
:::MLL 1558651611.475 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558651611.476 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 2.905, Average Loss: 4.141, avg. samples / sec: 65599.94
Iteration:   3160, Loss function: 3.450, Average Loss: 4.137, avg. samples / sec: 65541.76
Iteration:   3160, Loss function: 3.665, Average Loss: 4.131, avg. samples / sec: 65566.37
Iteration:   3160, Loss function: 2.947, Average Loss: 4.127, avg. samples / sec: 65437.95
Iteration:   3160, Loss function: 4.323, Average Loss: 4.130, avg. samples / sec: 65555.14
Iteration:   3160, Loss function: 4.119, Average Loss: 4.165, avg. samples / sec: 65599.73
Iteration:   3160, Loss function: 3.133, Average Loss: 4.141, avg. samples / sec: 65541.73
Iteration:   3160, Loss function: 4.666, Average Loss: 4.143, avg. samples / sec: 65554.53
Iteration:   3160, Loss function: 3.700, Average Loss: 4.139, avg. samples / sec: 65457.95
Iteration:   3160, Loss function: 3.480, Average Loss: 4.103, avg. samples / sec: 65436.83
Iteration:   3160, Loss function: 3.163, Average Loss: 4.136, avg. samples / sec: 65535.51
Iteration:   3160, Loss function: 4.569, Average Loss: 4.132, avg. samples / sec: 65461.30
Iteration:   3160, Loss function: 4.245, Average Loss: 4.144, avg. samples / sec: 65377.03
Iteration:   3160, Loss function: 3.281, Average Loss: 4.117, avg. samples / sec: 65548.59
Iteration:   3160, Loss function: 2.974, Average Loss: 4.128, avg. samples / sec: 65469.72
Iteration:   3160, Loss function: 3.620, Average Loss: 4.132, avg. samples / sec: 65444.06
Iteration:   3160, Loss function: 2.540, Average Loss: 4.146, avg. samples / sec: 65293.64
Iteration:   3160, Loss function: 3.263, Average Loss: 4.122, avg. samples / sec: 65491.17
Iteration:   3160, Loss function: 4.187, Average Loss: 4.155, avg. samples / sec: 65551.18
Iteration:   3160, Loss function: 4.113, Average Loss: 4.129, avg. samples / sec: 65461.78
Iteration:   3160, Loss function: 3.117, Average Loss: 4.135, avg. samples / sec: 65369.23
Iteration:   3160, Loss function: 3.100, Average Loss: 4.162, avg. samples / sec: 65455.88
Iteration:   3160, Loss function: 3.052, Average Loss: 4.145, avg. samples / sec: 65606.11
Iteration:   3160, Loss function: 3.866, Average Loss: 4.137, avg. samples / sec: 65298.27
Iteration:   3160, Loss function: 3.947, Average Loss: 4.147, avg. samples / sec: 65406.09
Iteration:   3160, Loss function: 2.940, Average Loss: 4.140, avg. samples / sec: 65447.34
Iteration:   3160, Loss function: 2.296, Average Loss: 4.139, avg. samples / sec: 65506.21
Iteration:   3160, Loss function: 3.611, Average Loss: 4.135, avg. samples / sec: 65345.62
Iteration:   3160, Loss function: 3.928, Average Loss: 4.140, avg. samples / sec: 65427.74
Iteration:   3160, Loss function: 2.569, Average Loss: 4.153, avg. samples / sec: 65394.26
Iteration:   3180, Loss function: 3.817, Average Loss: 4.128, avg. samples / sec: 65960.18
Iteration:   3180, Loss function: 4.482, Average Loss: 4.116, avg. samples / sec: 65890.18
Iteration:   3180, Loss function: 2.613, Average Loss: 4.106, avg. samples / sec: 65890.79
Iteration:   3180, Loss function: 5.841, Average Loss: 4.125, avg. samples / sec: 66000.80
Iteration:   3180, Loss function: 5.049, Average Loss: 4.123, avg. samples / sec: 65887.74
Iteration:   3180, Loss function: 3.817, Average Loss: 4.126, avg. samples / sec: 65937.65
Iteration:   3180, Loss function: 4.224, Average Loss: 4.091, avg. samples / sec: 65846.40
Iteration:   3180, Loss function: 4.176, Average Loss: 4.133, avg. samples / sec: 65950.77
Iteration:   3180, Loss function: 3.514, Average Loss: 4.133, avg. samples / sec: 65871.02
Iteration:   3180, Loss function: 3.738, Average Loss: 4.124, avg. samples / sec: 65793.19
Iteration:   3180, Loss function: 3.428, Average Loss: 4.118, avg. samples / sec: 65849.20
Iteration:   3180, Loss function: 4.229, Average Loss: 4.111, avg. samples / sec: 65862.03
Iteration:   3180, Loss function: 3.173, Average Loss: 4.127, avg. samples / sec: 65888.61
Iteration:   3180, Loss function: 3.049, Average Loss: 4.137, avg. samples / sec: 65843.69
Iteration:   3180, Loss function: 3.581, Average Loss: 4.131, avg. samples / sec: 65834.22
Iteration:   3180, Loss function: 4.328, Average Loss: 4.154, avg. samples / sec: 65759.42
Iteration:   3180, Loss function: 3.517, Average Loss: 4.119, avg. samples / sec: 65693.54
Iteration:   3180, Loss function: 4.646, Average Loss: 4.131, avg. samples / sec: 65878.17
Iteration:   3180, Loss function: 3.328, Average Loss: 4.130, avg. samples / sec: 65621.84
Iteration:   3180, Loss function: 2.892, Average Loss: 4.131, avg. samples / sec: 65870.28
Iteration:   3180, Loss function: 3.393, Average Loss: 4.122, avg. samples / sec: 65815.71
Iteration:   3180, Loss function: 3.502, Average Loss: 4.150, avg. samples / sec: 65797.73
Iteration:   3180, Loss function: 3.677, Average Loss: 4.147, avg. samples / sec: 65805.35
Iteration:   3180, Loss function: 2.305, Average Loss: 4.123, avg. samples / sec: 65667.40
Iteration:   3180, Loss function: 4.687, Average Loss: 4.129, avg. samples / sec: 65696.18
Iteration:   3180, Loss function: 4.344, Average Loss: 4.127, avg. samples / sec: 65837.14
Iteration:   3180, Loss function: 3.596, Average Loss: 4.124, avg. samples / sec: 65725.99
Iteration:   3180, Loss function: 4.177, Average Loss: 4.143, avg. samples / sec: 65832.22
Iteration:   3180, Loss function: 3.748, Average Loss: 4.107, avg. samples / sec: 65725.84
Iteration:   3180, Loss function: 2.920, Average Loss: 4.113, avg. samples / sec: 65558.99
Iteration:   3200, Loss function: 3.410, Average Loss: 4.109, avg. samples / sec: 65982.26
Iteration:   3200, Loss function: 3.119, Average Loss: 4.082, avg. samples / sec: 65957.40
Iteration:   3200, Loss function: 4.321, Average Loss: 4.094, avg. samples / sec: 65892.03
Iteration:   3200, Loss function: 3.516, Average Loss: 4.117, avg. samples / sec: 65935.28
Iteration:   3200, Loss function: 3.982, Average Loss: 4.125, avg. samples / sec: 65969.11
Iteration:   3200, Loss function: 2.706, Average Loss: 4.112, avg. samples / sec: 65875.18
Iteration:   3200, Loss function: 4.354, Average Loss: 4.119, avg. samples / sec: 66027.80
Iteration:   3200, Loss function: 4.146, Average Loss: 4.136, avg. samples / sec: 66004.73
Iteration:   3200, Loss function: 4.098, Average Loss: 4.112, avg. samples / sec: 65995.64
Iteration:   3200, Loss function: 4.263, Average Loss: 4.113, avg. samples / sec: 65824.41
Iteration:   3200, Loss function: 2.602, Average Loss: 4.116, avg. samples / sec: 65897.66
Iteration:   3200, Loss function: 2.812, Average Loss: 4.110, avg. samples / sec: 65952.25
Iteration:   3200, Loss function: 3.589, Average Loss: 4.104, avg. samples / sec: 65952.28
Iteration:   3200, Loss function: 2.817, Average Loss: 4.118, avg. samples / sec: 65930.84
Iteration:   3200, Loss function: 4.183, Average Loss: 4.095, avg. samples / sec: 65868.65
Iteration:   3200, Loss function: 3.032, Average Loss: 4.097, avg. samples / sec: 66014.16
Iteration:   3200, Loss function: 3.475, Average Loss: 4.101, avg. samples / sec: 65710.79
Iteration:   3200, Loss function: 2.682, Average Loss: 4.121, avg. samples / sec: 65787.60
Iteration:   3200, Loss function: 4.178, Average Loss: 4.138, avg. samples / sec: 65940.40
Iteration:   3200, Loss function: 2.532, Average Loss: 4.125, avg. samples / sec: 65974.57
Iteration:   3200, Loss function: 4.726, Average Loss: 4.116, avg. samples / sec: 65946.69
Iteration:   3200, Loss function: 2.804, Average Loss: 4.115, avg. samples / sec: 65671.99
Iteration:   3200, Loss function: 3.411, Average Loss: 4.117, avg. samples / sec: 65774.03
Iteration:   3200, Loss function: 3.546, Average Loss: 4.118, avg. samples / sec: 65825.33
Iteration:   3200, Loss function: 4.212, Average Loss: 4.141, avg. samples / sec: 65817.06
Iteration:   3200, Loss function: 3.923, Average Loss: 4.127, avg. samples / sec: 65826.04
Iteration:   3200, Loss function: 3.559, Average Loss: 4.100, avg. samples / sec: 65970.09
Iteration:   3200, Loss function: 2.756, Average Loss: 4.114, avg. samples / sec: 65798.07
Iteration:   3200, Loss function: 4.094, Average Loss: 4.105, avg. samples / sec: 65715.23
Iteration:   3200, Loss function: 3.498, Average Loss: 4.123, avg. samples / sec: 65728.10
:::MLL 1558651613.265 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558651613.265 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 3.172, Average Loss: 4.070, avg. samples / sec: 65497.50
Iteration:   3220, Loss function: 2.851, Average Loss: 4.082, avg. samples / sec: 65504.20
Iteration:   3220, Loss function: 3.795, Average Loss: 4.101, avg. samples / sec: 65559.17
Iteration:   3220, Loss function: 3.075, Average Loss: 4.104, avg. samples / sec: 65484.35
Iteration:   3220, Loss function: 4.355, Average Loss: 4.094, avg. samples / sec: 65589.07
Iteration:   3220, Loss function: 2.714, Average Loss: 4.115, avg. samples / sec: 65481.55
Iteration:   3220, Loss function: 2.814, Average Loss: 4.101, avg. samples / sec: 65691.68
Iteration:   3220, Loss function: 3.871, Average Loss: 4.095, avg. samples / sec: 65499.33
Iteration:   3220, Loss function: 3.237, Average Loss: 4.128, avg. samples / sec: 65476.38
Iteration:   3220, Loss function: 3.190, Average Loss: 4.097, avg. samples / sec: 65458.26
Iteration:   3220, Loss function: 3.682, Average Loss: 4.095, avg. samples / sec: 65394.01
Iteration:   3220, Loss function: 3.574, Average Loss: 4.108, avg. samples / sec: 65490.38
Iteration:   3220, Loss function: 4.011, Average Loss: 4.085, avg. samples / sec: 65507.21
Iteration:   3220, Loss function: 3.536, Average Loss: 4.100, avg. samples / sec: 65521.41
Iteration:   3220, Loss function: 3.515, Average Loss: 4.097, avg. samples / sec: 65467.10
Iteration:   3220, Loss function: 3.817, Average Loss: 4.104, avg. samples / sec: 65454.49
Iteration:   3220, Loss function: 3.725, Average Loss: 4.106, avg. samples / sec: 65417.60
Iteration:   3220, Loss function: 3.671, Average Loss: 4.083, avg. samples / sec: 65487.94
Iteration:   3220, Loss function: 3.661, Average Loss: 4.126, avg. samples / sec: 65477.32
Iteration:   3220, Loss function: 4.131, Average Loss: 4.096, avg. samples / sec: 65412.04
Iteration:   3220, Loss function: 3.293, Average Loss: 4.110, avg. samples / sec: 65494.67
Iteration:   3220, Loss function: 2.692, Average Loss: 4.134, avg. samples / sec: 65507.67
Iteration:   3220, Loss function: 3.301, Average Loss: 4.096, avg. samples / sec: 65605.35
Iteration:   3220, Loss function: 2.915, Average Loss: 4.107, avg. samples / sec: 65499.08
Iteration:   3220, Loss function: 3.204, Average Loss: 4.113, avg. samples / sec: 65409.04
Iteration:   3220, Loss function: 3.952, Average Loss: 4.116, avg. samples / sec: 65459.44
Iteration:   3220, Loss function: 3.731, Average Loss: 4.111, avg. samples / sec: 65396.05
Iteration:   3220, Loss function: 2.489, Average Loss: 4.103, avg. samples / sec: 65364.96
Iteration:   3220, Loss function: 4.253, Average Loss: 4.090, avg. samples / sec: 65434.49
Iteration:   3220, Loss function: 2.913, Average Loss: 4.110, avg. samples / sec: 65485.27
Iteration:   3240, Loss function: 4.387, Average Loss: 4.060, avg. samples / sec: 65869.17
Iteration:   3240, Loss function: 3.345, Average Loss: 4.087, avg. samples / sec: 66133.12
Iteration:   3240, Loss function: 3.043, Average Loss: 4.070, avg. samples / sec: 66005.19
Iteration:   3240, Loss function: 2.290, Average Loss: 4.084, avg. samples / sec: 65955.58
Iteration:   3240, Loss function: 3.967, Average Loss: 4.071, avg. samples / sec: 65873.05
Iteration:   3240, Loss function: 4.337, Average Loss: 4.086, avg. samples / sec: 65900.01
Iteration:   3240, Loss function: 4.042, Average Loss: 4.097, avg. samples / sec: 65943.49
Iteration:   3240, Loss function: 3.424, Average Loss: 4.091, avg. samples / sec: 65870.68
Iteration:   3240, Loss function: 3.554, Average Loss: 4.100, avg. samples / sec: 65892.00
Iteration:   3240, Loss function: 3.219, Average Loss: 4.116, avg. samples / sec: 65987.92
Iteration:   3240, Loss function: 3.012, Average Loss: 4.087, avg. samples / sec: 65984.21
Iteration:   3240, Loss function: 4.268, Average Loss: 4.086, avg. samples / sec: 65895.79
Iteration:   3240, Loss function: 2.409, Average Loss: 4.083, avg. samples / sec: 65956.05
Iteration:   3240, Loss function: 2.773, Average Loss: 4.090, avg. samples / sec: 65929.91
Iteration:   3240, Loss function: 2.471, Average Loss: 4.101, avg. samples / sec: 66019.94
Iteration:   3240, Loss function: 2.989, Average Loss: 4.120, avg. samples / sec: 65967.69
Iteration:   3240, Loss function: 3.986, Average Loss: 4.090, avg. samples / sec: 65907.28
Iteration:   3240, Loss function: 3.253, Average Loss: 4.086, avg. samples / sec: 65819.34
Iteration:   3240, Loss function: 3.721, Average Loss: 4.071, avg. samples / sec: 65886.70
Iteration:   3240, Loss function: 3.610, Average Loss: 4.100, avg. samples / sec: 66018.89
Iteration:   3240, Loss function: 2.775, Average Loss: 4.093, avg. samples / sec: 65881.74
Iteration:   3240, Loss function: 5.064, Average Loss: 4.117, avg. samples / sec: 65833.14
Iteration:   3240, Loss function: 3.447, Average Loss: 4.093, avg. samples / sec: 65914.59
Iteration:   3240, Loss function: 1.937, Average Loss: 4.092, avg. samples / sec: 65766.97
Iteration:   3240, Loss function: 3.500, Average Loss: 4.081, avg. samples / sec: 66006.80
Iteration:   3240, Loss function: 2.447, Average Loss: 4.103, avg. samples / sec: 65967.47
Iteration:   3240, Loss function: 2.453, Average Loss: 4.091, avg. samples / sec: 65904.44
Iteration:   3240, Loss function: 3.809, Average Loss: 4.085, avg. samples / sec: 65798.23
Iteration:   3240, Loss function: 2.608, Average Loss: 4.079, avg. samples / sec: 65801.08
Iteration:   3240, Loss function: 2.977, Average Loss: 4.097, avg. samples / sec: 65939.44
Iteration:   3260, Loss function: 3.748, Average Loss: 4.057, avg. samples / sec: 65646.05
Iteration:   3260, Loss function: 3.891, Average Loss: 4.076, avg. samples / sec: 65697.62
Iteration:   3260, Loss function: 3.146, Average Loss: 4.050, avg. samples / sec: 65591.39
Iteration:   3260, Loss function: 3.495, Average Loss: 4.072, avg. samples / sec: 65601.74
Iteration:   3260, Loss function: 3.133, Average Loss: 4.082, avg. samples / sec: 65623.06
Iteration:   3260, Loss function: 3.462, Average Loss: 4.084, avg. samples / sec: 65570.46
Iteration:   3260, Loss function: 3.798, Average Loss: 4.070, avg. samples / sec: 65581.81
Iteration:   3260, Loss function: 3.233, Average Loss: 4.075, avg. samples / sec: 65603.85
Iteration:   3260, Loss function: 2.832, Average Loss: 4.068, avg. samples / sec: 65717.10
Iteration:   3260, Loss function: 3.517, Average Loss: 4.085, avg. samples / sec: 65763.56
Iteration:   3260, Loss function: 3.296, Average Loss: 4.087, avg. samples / sec: 65604.06
Iteration:   3260, Loss function: 2.363, Average Loss: 4.104, avg. samples / sec: 65573.51
Iteration:   3260, Loss function: 3.580, Average Loss: 4.073, avg. samples / sec: 65580.40
Iteration:   3260, Loss function: 3.803, Average Loss: 4.057, avg. samples / sec: 65527.35
Iteration:   3260, Loss function: 3.586, Average Loss: 4.069, avg. samples / sec: 65653.15
Iteration:   3260, Loss function: 3.606, Average Loss: 4.109, avg. samples / sec: 65623.19
Iteration:   3260, Loss function: 3.453, Average Loss: 4.060, avg. samples / sec: 65595.18
Iteration:   3260, Loss function: 3.855, Average Loss: 4.106, avg. samples / sec: 65684.48
Iteration:   3260, Loss function: 4.150, Average Loss: 4.081, avg. samples / sec: 65604.40
Iteration:   3260, Loss function: 3.893, Average Loss: 4.077, avg. samples / sec: 65553.99
Iteration:   3260, Loss function: 3.440, Average Loss: 4.075, avg. samples / sec: 65495.00
Iteration:   3260, Loss function: 5.123, Average Loss: 4.076, avg. samples / sec: 65645.53
Iteration:   3260, Loss function: 3.842, Average Loss: 4.076, avg. samples / sec: 65627.98
Iteration:   3260, Loss function: 3.644, Average Loss: 4.092, avg. samples / sec: 65654.03
Iteration:   3260, Loss function: 3.045, Average Loss: 4.088, avg. samples / sec: 65486.36
Iteration:   3260, Loss function: 3.367, Average Loss: 4.082, avg. samples / sec: 65582.48
Iteration:   3260, Loss function: 4.030, Average Loss: 4.085, avg. samples / sec: 65669.18
Iteration:   3260, Loss function: 3.398, Average Loss: 4.088, avg. samples / sec: 65470.66
Iteration:   3260, Loss function: 3.404, Average Loss: 4.079, avg. samples / sec: 65448.62
Iteration:   3260, Loss function: 3.381, Average Loss: 4.085, avg. samples / sec: 65479.73
Iteration:   3280, Loss function: 3.285, Average Loss: 4.068, avg. samples / sec: 66070.05
Iteration:   3280, Loss function: 3.288, Average Loss: 4.048, avg. samples / sec: 66020.50
Iteration:   3280, Loss function: 3.472, Average Loss: 4.071, avg. samples / sec: 66111.06
Iteration:   3280, Loss function: 3.053, Average Loss: 4.071, avg. samples / sec: 66082.04
Iteration:   3280, Loss function: 2.577, Average Loss: 4.038, avg. samples / sec: 66004.30
Iteration:   3280, Loss function: 3.914, Average Loss: 4.059, avg. samples / sec: 65989.86
Iteration:   3280, Loss function: 4.029, Average Loss: 4.062, avg. samples / sec: 66080.09
Iteration:   3280, Loss function: 3.464, Average Loss: 4.077, avg. samples / sec: 66173.86
Iteration:   3280, Loss function: 2.984, Average Loss: 4.039, avg. samples / sec: 66071.73
Iteration:   3280, Loss function: 4.211, Average Loss: 4.077, avg. samples / sec: 65950.52
Iteration:   3280, Loss function: 3.405, Average Loss: 4.083, avg. samples / sec: 66231.52
Iteration:   3280, Loss function: 5.548, Average Loss: 4.064, avg. samples / sec: 66091.31
Iteration:   3280, Loss function: 3.662, Average Loss: 4.070, avg. samples / sec: 66159.32
Iteration:   3280, Loss function: 2.426, Average Loss: 4.094, avg. samples / sec: 66018.37
Iteration:   3280, Loss function: 4.165, Average Loss: 4.068, avg. samples / sec: 65927.72
Iteration:   3280, Loss function: 3.834, Average Loss: 4.066, avg. samples / sec: 66050.24
Iteration:   3280, Loss function: 3.097, Average Loss: 4.077, avg. samples / sec: 66105.11
Iteration:   3280, Loss function: 4.044, Average Loss: 4.063, avg. samples / sec: 66034.51
Iteration:   3280, Loss function: 4.181, Average Loss: 4.064, avg. samples / sec: 65968.43
Iteration:   3280, Loss function: 2.792, Average Loss: 4.047, avg. samples / sec: 65989.34
Iteration:   3280, Loss function: 2.373, Average Loss: 4.091, avg. samples / sec: 65888.76
Iteration:   3280, Loss function: 3.496, Average Loss: 4.075, avg. samples / sec: 66098.38
Iteration:   3280, Loss function: 3.249, Average Loss: 4.059, avg. samples / sec: 65925.90
Iteration:   3280, Loss function: 3.341, Average Loss: 4.067, avg. samples / sec: 65985.57
Iteration:   3280, Loss function: 3.700, Average Loss: 4.067, avg. samples / sec: 65901.09
Iteration:   3280, Loss function: 3.844, Average Loss: 4.098, avg. samples / sec: 65933.89
Iteration:   3280, Loss function: 2.935, Average Loss: 4.070, avg. samples / sec: 66015.24
Iteration:   3280, Loss function: 4.171, Average Loss: 4.081, avg. samples / sec: 65912.71
Iteration:   3280, Loss function: 2.862, Average Loss: 4.053, avg. samples / sec: 65905.40
Iteration:   3280, Loss function: 3.342, Average Loss: 4.064, avg. samples / sec: 65876.53
:::MLL 1558651615.053 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558651615.053 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 2.658, Average Loss: 4.027, avg. samples / sec: 65666.48
Iteration:   3300, Loss function: 2.796, Average Loss: 4.055, avg. samples / sec: 65643.30
Iteration:   3300, Loss function: 2.556, Average Loss: 4.057, avg. samples / sec: 65540.15
Iteration:   3300, Loss function: 3.798, Average Loss: 4.054, avg. samples / sec: 65501.91
Iteration:   3300, Loss function: 3.761, Average Loss: 4.057, avg. samples / sec: 65589.80
Iteration:   3300, Loss function: 3.104, Average Loss: 4.059, avg. samples / sec: 65641.59
Iteration:   3300, Loss function: 2.942, Average Loss: 4.054, avg. samples / sec: 65555.11
Iteration:   3300, Loss function: 3.044, Average Loss: 4.071, avg. samples / sec: 65538.38
Iteration:   3300, Loss function: 3.077, Average Loss: 4.043, avg. samples / sec: 65517.60
Iteration:   3300, Loss function: 3.435, Average Loss: 4.025, avg. samples / sec: 65519.70
Iteration:   3300, Loss function: 3.835, Average Loss: 4.043, avg. samples / sec: 65674.44
Iteration:   3300, Loss function: 2.388, Average Loss: 4.056, avg. samples / sec: 65555.85
Iteration:   3300, Loss function: 4.391, Average Loss: 4.071, avg. samples / sec: 65658.07
Iteration:   3300, Loss function: 3.006, Average Loss: 4.070, avg. samples / sec: 65477.32
Iteration:   3300, Loss function: 3.522, Average Loss: 4.066, avg. samples / sec: 65548.86
Iteration:   3300, Loss function: 3.198, Average Loss: 4.082, avg. samples / sec: 65501.88
Iteration:   3300, Loss function: 4.914, Average Loss: 4.085, avg. samples / sec: 65570.21
Iteration:   3300, Loss function: 3.833, Average Loss: 4.066, avg. samples / sec: 65465.13
Iteration:   3300, Loss function: 2.640, Average Loss: 4.040, avg. samples / sec: 65386.88
Iteration:   3300, Loss function: 2.598, Average Loss: 4.054, avg. samples / sec: 65520.64
Iteration:   3300, Loss function: 2.608, Average Loss: 4.052, avg. samples / sec: 65433.18
Iteration:   3300, Loss function: 3.611, Average Loss: 4.054, avg. samples / sec: 65590.38
Iteration:   3300, Loss function: 3.091, Average Loss: 4.058, avg. samples / sec: 65536.94
Iteration:   3300, Loss function: 3.524, Average Loss: 4.063, avg. samples / sec: 65349.38
Iteration:   3300, Loss function: 3.537, Average Loss: 4.049, avg. samples / sec: 65523.69
Iteration:   3300, Loss function: 4.854, Average Loss: 4.053, avg. samples / sec: 65579.49
Iteration:   3300, Loss function: 2.900, Average Loss: 4.085, avg. samples / sec: 65543.38
Iteration:   3300, Loss function: 4.111, Average Loss: 4.055, avg. samples / sec: 65436.25
Iteration:   3300, Loss function: 4.580, Average Loss: 4.038, avg. samples / sec: 65472.31
Iteration:   3300, Loss function: 3.912, Average Loss: 4.065, avg. samples / sec: 65478.48
Iteration:   3320, Loss function: 2.690, Average Loss: 4.038, avg. samples / sec: 66303.97
Iteration:   3320, Loss function: 3.661, Average Loss: 4.054, avg. samples / sec: 66212.82
Iteration:   3320, Loss function: 4.498, Average Loss: 4.031, avg. samples / sec: 66213.13
Iteration:   3320, Loss function: 3.715, Average Loss: 4.041, avg. samples / sec: 66209.67
Iteration:   3320, Loss function: 4.482, Average Loss: 4.024, avg. samples / sec: 65943.70
Iteration:   3320, Loss function: 4.342, Average Loss: 4.046, avg. samples / sec: 66229.53
Iteration:   3320, Loss function: 3.316, Average Loss: 4.042, avg. samples / sec: 66161.96
Iteration:   3320, Loss function: 3.679, Average Loss: 4.035, avg. samples / sec: 66188.22
Iteration:   3320, Loss function: 3.200, Average Loss: 4.043, avg. samples / sec: 66073.15
Iteration:   3320, Loss function: 3.659, Average Loss: 4.061, avg. samples / sec: 66087.16
Iteration:   3320, Loss function: 3.211, Average Loss: 4.039, avg. samples / sec: 66053.80
Iteration:   3320, Loss function: 3.441, Average Loss: 4.041, avg. samples / sec: 65989.93
Iteration:   3320, Loss function: 2.749, Average Loss: 4.031, avg. samples / sec: 66038.04
Iteration:   3320, Loss function: 2.838, Average Loss: 4.044, avg. samples / sec: 65975.81
Iteration:   3320, Loss function: 3.588, Average Loss: 4.065, avg. samples / sec: 66050.39
Iteration:   3320, Loss function: 4.795, Average Loss: 4.056, avg. samples / sec: 66057.36
Iteration:   3320, Loss function: 2.791, Average Loss: 4.049, avg. samples / sec: 66178.05
Iteration:   3320, Loss function: 3.814, Average Loss: 4.061, avg. samples / sec: 65984.89
Iteration:   3320, Loss function: 3.077, Average Loss: 4.045, avg. samples / sec: 65989.83
Iteration:   3320, Loss function: 2.652, Average Loss: 4.046, avg. samples / sec: 66139.95
Iteration:   3320, Loss function: 2.990, Average Loss: 4.046, avg. samples / sec: 66086.20
Iteration:   3320, Loss function: 3.608, Average Loss: 4.071, avg. samples / sec: 66034.82
Iteration:   3320, Loss function: 3.232, Average Loss: 4.053, avg. samples / sec: 66095.59
Iteration:   3320, Loss function: 3.320, Average Loss: 4.071, avg. samples / sec: 66025.08
Iteration:   3320, Loss function: 4.028, Average Loss: 4.010, avg. samples / sec: 65973.74
Iteration:   3320, Loss function: 3.124, Average Loss: 4.034, avg. samples / sec: 65981.40
Iteration:   3320, Loss function: 2.415, Average Loss: 4.073, avg. samples / sec: 66090.07
Iteration:   3320, Loss function: 3.009, Average Loss: 4.048, avg. samples / sec: 65934.79
Iteration:   3320, Loss function: 4.069, Average Loss: 4.041, avg. samples / sec: 65847.75
Iteration:   3320, Loss function: 3.747, Average Loss: 4.027, avg. samples / sec: 66018.58
Iteration:   3340, Loss function: 2.855, Average Loss: 4.058, avg. samples / sec: 66251.16
Iteration:   3340, Loss function: 2.834, Average Loss: 4.019, avg. samples / sec: 66081.30
Iteration:   3340, Loss function: 3.674, Average Loss: 4.030, avg. samples / sec: 66108.83
Iteration:   3340, Loss function: 3.649, Average Loss: 4.050, avg. samples / sec: 66089.14
Iteration:   3340, Loss function: 3.548, Average Loss: 4.033, avg. samples / sec: 66105.17
Iteration:   3340, Loss function: 3.105, Average Loss: 4.028, avg. samples / sec: 66088.95
Iteration:   3340, Loss function: 3.413, Average Loss: 4.031, avg. samples / sec: 66148.20
Iteration:   3340, Loss function: 3.194, Average Loss: 4.021, avg. samples / sec: 66099.90
Iteration:   3340, Loss function: 4.201, Average Loss: 4.033, avg. samples / sec: 66109.07
Iteration:   3340, Loss function: 1.963, Average Loss: 4.061, avg. samples / sec: 66163.79
Iteration:   3340, Loss function: 3.601, Average Loss: 4.021, avg. samples / sec: 66154.72
Iteration:   3340, Loss function: 4.064, Average Loss: 4.052, avg. samples / sec: 66104.64
Iteration:   3340, Loss function: 4.058, Average Loss: 4.026, avg. samples / sec: 66031.33
Iteration:   3340, Loss function: 3.329, Average Loss: 4.029, avg. samples / sec: 65843.48
Iteration:   3340, Loss function: 4.454, Average Loss: 4.023, avg. samples / sec: 65933.61
Iteration:   3340, Loss function: 3.070, Average Loss: 4.028, avg. samples / sec: 66184.46
Iteration:   3340, Loss function: 3.290, Average Loss: 4.042, avg. samples / sec: 66046.09
Iteration:   3340, Loss function: 3.249, Average Loss: 4.039, avg. samples / sec: 66056.89
Iteration:   3340, Loss function: 2.362, Average Loss: 4.025, avg. samples / sec: 66006.55
Iteration:   3340, Loss function: 3.076, Average Loss: 4.029, avg. samples / sec: 66092.08
Iteration:   3340, Loss function: 3.325, Average Loss: 4.034, avg. samples / sec: 66066.12
Iteration:   3340, Loss function: 3.988, Average Loss: 4.042, avg. samples / sec: 66097.42
Iteration:   3340, Loss function: 3.946, Average Loss: 4.030, avg. samples / sec: 65931.42
Iteration:   3340, Loss function: 3.700, Average Loss: 4.039, avg. samples / sec: 66118.35
Iteration:   3340, Loss function: 3.891, Average Loss: 4.044, avg. samples / sec: 65896.65
Iteration:   3340, Loss function: 2.420, Average Loss: 3.998, avg. samples / sec: 66066.86
Iteration:   3340, Loss function: 3.404, Average Loss: 4.015, avg. samples / sec: 66157.98
Iteration:   3340, Loss function: 2.817, Average Loss: 4.056, avg. samples / sec: 66011.16
Iteration:   3340, Loss function: 3.360, Average Loss: 4.032, avg. samples / sec: 65875.02
Iteration:   3340, Loss function: 3.218, Average Loss: 4.062, avg. samples / sec: 65978.31
:::MLL 1558651616.839 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558651616.840 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 4.111, Average Loss: 4.052, avg. samples / sec: 65581.62
Iteration:   3360, Loss function: 3.235, Average Loss: 4.009, avg. samples / sec: 65572.90
Iteration:   3360, Loss function: 3.948, Average Loss: 4.032, avg. samples / sec: 65611.73
Iteration:   3360, Loss function: 2.729, Average Loss: 4.016, avg. samples / sec: 65582.20
Iteration:   3360, Loss function: 1.727, Average Loss: 4.023, avg. samples / sec: 65516.07
Iteration:   3360, Loss function: 4.585, Average Loss: 4.019, avg. samples / sec: 65482.16
Iteration:   3360, Loss function: 3.064, Average Loss: 4.008, avg. samples / sec: 65437.83
Iteration:   3360, Loss function: 3.640, Average Loss: 4.012, avg. samples / sec: 65485.54
Iteration:   3360, Loss function: 4.619, Average Loss: 4.015, avg. samples / sec: 65518.18
Iteration:   3360, Loss function: 3.570, Average Loss: 4.015, avg. samples / sec: 65547.67
Iteration:   3360, Loss function: 3.744, Average Loss: 4.049, avg. samples / sec: 65614.97
Iteration:   3360, Loss function: 4.070, Average Loss: 4.029, avg. samples / sec: 65499.02
Iteration:   3360, Loss function: 3.472, Average Loss: 4.027, avg. samples / sec: 65496.28
Iteration:   3360, Loss function: 3.586, Average Loss: 4.005, avg. samples / sec: 65535.70
Iteration:   3360, Loss function: 3.466, Average Loss: 4.017, avg. samples / sec: 65348.32
Iteration:   3360, Loss function: 2.781, Average Loss: 4.027, avg. samples / sec: 65459.17
Iteration:   3360, Loss function: 3.555, Average Loss: 4.021, avg. samples / sec: 65378.45
Iteration:   3360, Loss function: 3.511, Average Loss: 4.025, avg. samples / sec: 65435.16
Iteration:   3360, Loss function: 2.874, Average Loss: 4.030, avg. samples / sec: 65456.19
Iteration:   3360, Loss function: 3.000, Average Loss: 4.014, avg. samples / sec: 65408.64
Iteration:   3360, Loss function: 2.529, Average Loss: 4.041, avg. samples / sec: 65334.72
Iteration:   3360, Loss function: 4.398, Average Loss: 4.048, avg. samples / sec: 65279.57
Iteration:   3360, Loss function: 3.632, Average Loss: 4.017, avg. samples / sec: 65411.07
Iteration:   3360, Loss function: 2.655, Average Loss: 3.992, avg. samples / sec: 65450.35
Iteration:   3360, Loss function: 3.941, Average Loss: 4.040, avg. samples / sec: 65369.11
Iteration:   3360, Loss function: 3.621, Average Loss: 4.028, avg. samples / sec: 65413.56
Iteration:   3360, Loss function: 2.995, Average Loss: 4.014, avg. samples / sec: 65318.09
Iteration:   3360, Loss function: 5.057, Average Loss: 4.044, avg. samples / sec: 65395.87
Iteration:   3360, Loss function: 2.797, Average Loss: 4.025, avg. samples / sec: 65411.92
Iteration:   3360, Loss function: 2.912, Average Loss: 4.009, avg. samples / sec: 65196.41
Iteration:   3380, Loss function: 3.963, Average Loss: 3.992, avg. samples / sec: 65861.23
Iteration:   3380, Loss function: 3.413, Average Loss: 4.000, avg. samples / sec: 65820.29
Iteration:   3380, Loss function: 3.987, Average Loss: 4.000, avg. samples / sec: 65804.12
Iteration:   3380, Loss function: 4.083, Average Loss: 4.033, avg. samples / sec: 65960.99
Iteration:   3380, Loss function: 2.841, Average Loss: 4.002, avg. samples / sec: 65814.94
Iteration:   3380, Loss function: 3.215, Average Loss: 4.009, avg. samples / sec: 65754.91
Iteration:   3380, Loss function: 3.475, Average Loss: 3.995, avg. samples / sec: 66111.71
Iteration:   3380, Loss function: 3.269, Average Loss: 4.020, avg. samples / sec: 65836.19
Iteration:   3380, Loss function: 2.308, Average Loss: 4.010, avg. samples / sec: 65780.41
Iteration:   3380, Loss function: 2.365, Average Loss: 4.012, avg. samples / sec: 65866.93
Iteration:   3380, Loss function: 2.346, Average Loss: 4.030, avg. samples / sec: 65860.37
Iteration:   3380, Loss function: 3.714, Average Loss: 4.010, avg. samples / sec: 65816.69
Iteration:   3380, Loss function: 3.672, Average Loss: 4.020, avg. samples / sec: 65926.09
Iteration:   3380, Loss function: 3.467, Average Loss: 4.033, avg. samples / sec: 65759.85
Iteration:   3380, Loss function: 3.932, Average Loss: 4.021, avg. samples / sec: 65760.86
Iteration:   3380, Loss function: 2.687, Average Loss: 4.017, avg. samples / sec: 65815.59
Iteration:   3380, Loss function: 2.853, Average Loss: 4.018, avg. samples / sec: 65676.12
Iteration:   3380, Loss function: 2.908, Average Loss: 4.003, avg. samples / sec: 65673.74
Iteration:   3380, Loss function: 2.906, Average Loss: 3.995, avg. samples / sec: 65749.39
Iteration:   3380, Loss function: 2.910, Average Loss: 4.008, avg. samples / sec: 65818.97
Iteration:   3380, Loss function: 3.110, Average Loss: 3.981, avg. samples / sec: 65837.20
Iteration:   3380, Loss function: 3.832, Average Loss: 4.035, avg. samples / sec: 65867.02
Iteration:   3380, Loss function: 3.961, Average Loss: 4.020, avg. samples / sec: 65818.72
Iteration:   3380, Loss function: 3.017, Average Loss: 4.022, avg. samples / sec: 65762.70
Iteration:   3380, Loss function: 4.257, Average Loss: 4.017, avg. samples / sec: 65751.04
Iteration:   3380, Loss function: 3.047, Average Loss: 4.001, avg. samples / sec: 65779.12
Iteration:   3380, Loss function: 3.279, Average Loss: 4.003, avg. samples / sec: 65784.34
Iteration:   3380, Loss function: 4.087, Average Loss: 4.041, avg. samples / sec: 65530.55
Iteration:   3380, Loss function: 3.406, Average Loss: 4.029, avg. samples / sec: 65716.03
Iteration:   3380, Loss function: 3.571, Average Loss: 4.004, avg. samples / sec: 65569.33
Iteration:   3400, Loss function: 3.976, Average Loss: 3.993, avg. samples / sec: 65861.48
Iteration:   3400, Loss function: 4.405, Average Loss: 3.998, avg. samples / sec: 65864.40
Iteration:   3400, Loss function: 4.156, Average Loss: 4.021, avg. samples / sec: 66073.74
Iteration:   3400, Loss function: 2.899, Average Loss: 3.991, avg. samples / sec: 65839.85
Iteration:   3400, Loss function: 3.588, Average Loss: 4.023, avg. samples / sec: 65817.16
Iteration:   3400, Loss function: 4.125, Average Loss: 3.992, avg. samples / sec: 65946.02
Iteration:   3400, Loss function: 3.317, Average Loss: 3.979, avg. samples / sec: 65750.80
Iteration:   3400, Loss function: 3.223, Average Loss: 3.982, avg. samples / sec: 65928.65
Iteration:   3400, Loss function: 3.742, Average Loss: 4.012, avg. samples / sec: 65942.44
Iteration:   3400, Loss function: 3.022, Average Loss: 3.998, avg. samples / sec: 65811.19
Iteration:   3400, Loss function: 3.426, Average Loss: 4.006, avg. samples / sec: 65861.26
Iteration:   3400, Loss function: 4.658, Average Loss: 4.003, avg. samples / sec: 65847.63
Iteration:   3400, Loss function: 4.260, Average Loss: 4.012, avg. samples / sec: 65778.02
Iteration:   3400, Loss function: 3.893, Average Loss: 4.024, avg. samples / sec: 65889.25
Iteration:   3400, Loss function: 3.926, Average Loss: 3.969, avg. samples / sec: 65887.87
Iteration:   3400, Loss function: 4.690, Average Loss: 3.989, avg. samples / sec: 65732.55
Iteration:   3400, Loss function: 3.481, Average Loss: 4.010, avg. samples / sec: 65825.58
Iteration:   3400, Loss function: 4.140, Average Loss: 4.031, avg. samples / sec: 65921.62
Iteration:   3400, Loss function: 2.155, Average Loss: 3.992, avg. samples / sec: 65866.56
Iteration:   3400, Loss function: 3.138, Average Loss: 4.017, avg. samples / sec: 65769.12
Iteration:   3400, Loss function: 4.068, Average Loss: 4.009, avg. samples / sec: 65857.17
Iteration:   3400, Loss function: 3.991, Average Loss: 4.019, avg. samples / sec: 65788.98
Iteration:   3400, Loss function: 4.918, Average Loss: 3.984, avg. samples / sec: 65699.27
Iteration:   3400, Loss function: 3.267, Average Loss: 4.000, avg. samples / sec: 65681.20
Iteration:   3400, Loss function: 4.242, Average Loss: 3.997, avg. samples / sec: 65782.26
Iteration:   3400, Loss function: 4.168, Average Loss: 4.013, avg. samples / sec: 65766.11
Iteration:   3400, Loss function: 3.720, Average Loss: 4.008, avg. samples / sec: 65786.86
Iteration:   3400, Loss function: 2.961, Average Loss: 3.996, avg. samples / sec: 65870.10
Iteration:   3400, Loss function: 3.454, Average Loss: 4.009, avg. samples / sec: 65728.38
Iteration:   3400, Loss function: 2.289, Average Loss: 3.987, avg. samples / sec: 65704.26
Iteration:   3420, Loss function: 4.559, Average Loss: 3.973, avg. samples / sec: 66145.41
Iteration:   3420, Loss function: 3.138, Average Loss: 4.012, avg. samples / sec: 66097.14
Iteration:   3420, Loss function: 2.599, Average Loss: 3.981, avg. samples / sec: 66031.42
Iteration:   3420, Loss function: 3.678, Average Loss: 3.990, avg. samples / sec: 66080.28
Iteration:   3420, Loss function: 2.841, Average Loss: 3.987, avg. samples / sec: 66111.65
Iteration:   3420, Loss function: 2.746, Average Loss: 4.000, avg. samples / sec: 66104.76
Iteration:   3420, Loss function: 2.890, Average Loss: 3.998, avg. samples / sec: 66131.01
Iteration:   3420, Loss function: 2.099, Average Loss: 3.980, avg. samples / sec: 66145.19
Iteration:   3420, Loss function: 3.791, Average Loss: 3.979, avg. samples / sec: 66077.46
Iteration:   3420, Loss function: 4.004, Average Loss: 3.996, avg. samples / sec: 66104.80
Iteration:   3420, Loss function: 2.611, Average Loss: 4.008, avg. samples / sec: 66023.44
Iteration:   3420, Loss function: 3.643, Average Loss: 4.009, avg. samples / sec: 66091.81
Iteration:   3420, Loss function: 4.246, Average Loss: 3.989, avg. samples / sec: 66111.74
Iteration:   3420, Loss function: 3.286, Average Loss: 3.982, avg. samples / sec: 65940.21
Iteration:   3420, Loss function: 2.430, Average Loss: 3.973, avg. samples / sec: 66245.68
Iteration:   3420, Loss function: 4.821, Average Loss: 4.006, avg. samples / sec: 66064.39
Iteration:   3420, Loss function: 2.455, Average Loss: 3.998, avg. samples / sec: 66152.52
Iteration:   3420, Loss function: 2.554, Average Loss: 3.979, avg. samples / sec: 66133.21
Iteration:   3420, Loss function: 3.757, Average Loss: 3.998, avg. samples / sec: 66094.66
Iteration:   3420, Loss function: 3.445, Average Loss: 4.001, avg. samples / sec: 66074.55
Iteration:   3420, Loss function: 2.515, Average Loss: 3.995, avg. samples / sec: 65977.66
Iteration:   3420, Loss function: 3.468, Average Loss: 4.008, avg. samples / sec: 65894.80
Iteration:   3420, Loss function: 3.372, Average Loss: 3.991, avg. samples / sec: 66077.15
Iteration:   3420, Loss function: 4.267, Average Loss: 3.975, avg. samples / sec: 66053.49
Iteration:   3420, Loss function: 3.359, Average Loss: 3.964, avg. samples / sec: 65969.26
Iteration:   3420, Loss function: 2.575, Average Loss: 3.997, avg. samples / sec: 65940.55
Iteration:   3420, Loss function: 3.640, Average Loss: 3.991, avg. samples / sec: 65966.20
Iteration:   3420, Loss function: 3.482, Average Loss: 4.017, avg. samples / sec: 65980.07
Iteration:   3420, Loss function: 3.001, Average Loss: 3.980, avg. samples / sec: 65879.21
Iteration:   3420, Loss function: 3.448, Average Loss: 3.974, avg. samples / sec: 65856.22
:::MLL 1558651618.608 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=2.49s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22344
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38246
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05553
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31717
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33324
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36156
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52060
Current AP: 0.22344 AP goal: 0.23000
:::MLL 1558651622.228 eval_accuracy: {"value": 0.2234391186243413, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558651622.303 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558651622.309 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558651622.310 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558651622.335 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558651622.335 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 2.900, Average Loss: 3.974, avg. samples / sec: 7958.87
Iteration:   3440, Loss function: 4.361, Average Loss: 3.999, avg. samples / sec: 7960.16
Iteration:   3440, Loss function: 3.401, Average Loss: 3.953, avg. samples / sec: 7960.98
Iteration:   3440, Loss function: 3.830, Average Loss: 3.992, avg. samples / sec: 7958.68
Iteration:   3440, Loss function: 3.614, Average Loss: 3.970, avg. samples / sec: 7959.18
Iteration:   3440, Loss function: 3.277, Average Loss: 3.978, avg. samples / sec: 7957.17
Iteration:   3440, Loss function: 2.695, Average Loss: 3.980, avg. samples / sec: 7958.45
Iteration:   3440, Loss function: 3.336, Average Loss: 3.964, avg. samples / sec: 7956.79
Iteration:   3440, Loss function: 4.917, Average Loss: 3.972, avg. samples / sec: 7958.33
Iteration:   3440, Loss function: 4.919, Average Loss: 3.994, avg. samples / sec: 7960.04
Iteration:   3440, Loss function: 4.278, Average Loss: 3.986, avg. samples / sec: 7958.95
Iteration:   3440, Loss function: 2.554, Average Loss: 3.966, avg. samples / sec: 7957.40
Iteration:   3440, Loss function: 2.766, Average Loss: 3.998, avg. samples / sec: 7958.83
Iteration:   3440, Loss function: 2.944, Average Loss: 3.989, avg. samples / sec: 7958.96
Iteration:   3440, Loss function: 3.386, Average Loss: 4.001, avg. samples / sec: 7956.43
Iteration:   3440, Loss function: 2.498, Average Loss: 3.990, avg. samples / sec: 7958.94
Iteration:   3440, Loss function: 3.484, Average Loss: 3.990, avg. samples / sec: 7958.77
Iteration:   3440, Loss function: 3.329, Average Loss: 3.991, avg. samples / sec: 7958.92
Iteration:   3440, Loss function: 3.605, Average Loss: 3.976, avg. samples / sec: 7957.86
Iteration:   3440, Loss function: 3.302, Average Loss: 3.966, avg. samples / sec: 7959.44
Iteration:   3440, Loss function: 3.697, Average Loss: 3.965, avg. samples / sec: 7958.45
Iteration:   3440, Loss function: 4.616, Average Loss: 3.967, avg. samples / sec: 7957.99
Iteration:   3440, Loss function: 3.007, Average Loss: 3.969, avg. samples / sec: 7958.78
Iteration:   3440, Loss function: 3.585, Average Loss: 3.984, avg. samples / sec: 7958.09
Iteration:   3440, Loss function: 2.366, Average Loss: 3.977, avg. samples / sec: 7958.04
Iteration:   3440, Loss function: 3.804, Average Loss: 3.959, avg. samples / sec: 7957.36
Iteration:   3440, Loss function: 3.337, Average Loss: 4.008, avg. samples / sec: 7958.09
Iteration:   3440, Loss function: 4.668, Average Loss: 3.984, avg. samples / sec: 7957.32
Iteration:   3440, Loss function: 4.657, Average Loss: 3.970, avg. samples / sec: 7956.54
Iteration:   3440, Loss function: 4.170, Average Loss: 3.987, avg. samples / sec: 7957.09
Iteration:   3460, Loss function: 3.256, Average Loss: 3.967, avg. samples / sec: 66078.88
Iteration:   3460, Loss function: 2.093, Average Loss: 3.981, avg. samples / sec: 66112.49
Iteration:   3460, Loss function: 4.613, Average Loss: 3.956, avg. samples / sec: 65990.95
Iteration:   3460, Loss function: 3.399, Average Loss: 3.963, avg. samples / sec: 66150.13
Iteration:   3460, Loss function: 3.490, Average Loss: 3.978, avg. samples / sec: 66162.30
Iteration:   3460, Loss function: 2.575, Average Loss: 3.976, avg. samples / sec: 66239.83
Iteration:   3460, Loss function: 3.502, Average Loss: 3.990, avg. samples / sec: 66053.46
Iteration:   3460, Loss function: 3.261, Average Loss: 3.986, avg. samples / sec: 66055.59
Iteration:   3460, Loss function: 2.789, Average Loss: 3.982, avg. samples / sec: 65998.21
Iteration:   3460, Loss function: 3.724, Average Loss: 3.967, avg. samples / sec: 66136.03
Iteration:   3460, Loss function: 2.987, Average Loss: 3.952, avg. samples / sec: 66086.16
Iteration:   3460, Loss function: 2.149, Average Loss: 3.977, avg. samples / sec: 65945.61
Iteration:   3460, Loss function: 3.690, Average Loss: 3.962, avg. samples / sec: 65973.03
Iteration:   3460, Loss function: 3.774, Average Loss: 3.994, avg. samples / sec: 66131.94
Iteration:   3460, Loss function: 2.482, Average Loss: 3.963, avg. samples / sec: 65901.36
Iteration:   3460, Loss function: 2.460, Average Loss: 3.976, avg. samples / sec: 66012.40
Iteration:   3460, Loss function: 4.222, Average Loss: 3.952, avg. samples / sec: 66046.21
Iteration:   3460, Loss function: 3.188, Average Loss: 3.968, avg. samples / sec: 65918.32
Iteration:   3460, Loss function: 4.333, Average Loss: 3.978, avg. samples / sec: 65939.57
Iteration:   3460, Loss function: 3.183, Average Loss: 3.985, avg. samples / sec: 65860.89
Iteration:   3460, Loss function: 3.605, Average Loss: 3.951, avg. samples / sec: 65908.85
Iteration:   3460, Loss function: 3.298, Average Loss: 3.962, avg. samples / sec: 66018.46
Iteration:   3460, Loss function: 3.563, Average Loss: 3.955, avg. samples / sec: 65890.30
Iteration:   3460, Loss function: 3.557, Average Loss: 3.976, avg. samples / sec: 65922.76
Iteration:   3460, Loss function: 3.245, Average Loss: 3.967, avg. samples / sec: 65984.30
Iteration:   3460, Loss function: 4.157, Average Loss: 3.963, avg. samples / sec: 66096.36
Iteration:   3460, Loss function: 3.788, Average Loss: 3.977, avg. samples / sec: 66023.31
Iteration:   3460, Loss function: 2.102, Average Loss: 3.984, avg. samples / sec: 65923.13
Iteration:   3460, Loss function: 4.513, Average Loss: 3.953, avg. samples / sec: 65974.29
Iteration:   3460, Loss function: 3.053, Average Loss: 3.942, avg. samples / sec: 65684.54
Iteration:   3480, Loss function: 3.419, Average Loss: 3.954, avg. samples / sec: 65983.10
Iteration:   3480, Loss function: 3.297, Average Loss: 3.944, avg. samples / sec: 65994.25
Iteration:   3480, Loss function: 3.848, Average Loss: 3.961, avg. samples / sec: 65872.84
Iteration:   3480, Loss function: 4.255, Average Loss: 3.978, avg. samples / sec: 65871.64
Iteration:   3480, Loss function: 4.133, Average Loss: 3.949, avg. samples / sec: 65919.33
Iteration:   3480, Loss function: 3.093, Average Loss: 3.945, avg. samples / sec: 65758.07
Iteration:   3480, Loss function: 3.264, Average Loss: 3.959, avg. samples / sec: 65867.76
Iteration:   3480, Loss function: 3.433, Average Loss: 3.973, avg. samples / sec: 65886.33
Iteration:   3480, Loss function: 4.044, Average Loss: 3.952, avg. samples / sec: 65697.65
Iteration:   3480, Loss function: 3.433, Average Loss: 3.966, avg. samples / sec: 65953.92
Iteration:   3480, Loss function: 2.789, Average Loss: 3.949, avg. samples / sec: 65840.99
Iteration:   3480, Loss function: 3.576, Average Loss: 3.940, avg. samples / sec: 65879.98
Iteration:   3480, Loss function: 2.985, Average Loss: 3.959, avg. samples / sec: 65910.49
Iteration:   3480, Loss function: 3.479, Average Loss: 3.950, avg. samples / sec: 65726.85
Iteration:   3480, Loss function: 4.817, Average Loss: 3.963, avg. samples / sec: 65820.29
Iteration:   3480, Loss function: 3.952, Average Loss: 3.979, avg. samples / sec: 65792.60
Iteration:   3480, Loss function: 2.845, Average Loss: 3.967, avg. samples / sec: 65751.32
Iteration:   3480, Loss function: 2.621, Average Loss: 3.975, avg. samples / sec: 65891.75
Iteration:   3480, Loss function: 4.558, Average Loss: 3.967, avg. samples / sec: 65743.25
Iteration:   3480, Loss function: 3.352, Average Loss: 3.969, avg. samples / sec: 65690.33
Iteration:   3480, Loss function: 2.896, Average Loss: 3.970, avg. samples / sec: 65792.85
Iteration:   3480, Loss function: 4.394, Average Loss: 3.969, avg. samples / sec: 65656.69
Iteration:   3480, Loss function: 3.799, Average Loss: 3.967, avg. samples / sec: 65822.60
Iteration:   3480, Loss function: 3.364, Average Loss: 3.944, avg. samples / sec: 65878.78
Iteration:   3480, Loss function: 2.904, Average Loss: 3.930, avg. samples / sec: 65933.80
Iteration:   3480, Loss function: 3.509, Average Loss: 3.942, avg. samples / sec: 65687.14
Iteration:   3480, Loss function: 3.315, Average Loss: 3.953, avg. samples / sec: 65685.67
Iteration:   3480, Loss function: 2.911, Average Loss: 3.977, avg. samples / sec: 65617.81
Iteration:   3480, Loss function: 4.142, Average Loss: 3.950, avg. samples / sec: 65722.43
Iteration:   3480, Loss function: 5.165, Average Loss: 3.967, avg. samples / sec: 65592.92
:::MLL 1558651624.128 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558651624.129 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 3.313, Average Loss: 3.935, avg. samples / sec: 65024.64
Iteration:   3500, Loss function: 4.500, Average Loss: 3.945, avg. samples / sec: 64925.66
Iteration:   3500, Loss function: 5.182, Average Loss: 3.939, avg. samples / sec: 65095.70
Iteration:   3500, Loss function: 3.715, Average Loss: 3.928, avg. samples / sec: 65050.06
Iteration:   3500, Loss function: 3.265, Average Loss: 3.955, avg. samples / sec: 65088.58
Iteration:   3500, Loss function: 3.040, Average Loss: 3.948, avg. samples / sec: 65181.84
Iteration:   3500, Loss function: 3.132, Average Loss: 3.956, avg. samples / sec: 65057.93
Iteration:   3500, Loss function: 4.460, Average Loss: 3.970, avg. samples / sec: 65020.98
Iteration:   3500, Loss function: 5.000, Average Loss: 3.960, avg. samples / sec: 65093.90
Iteration:   3500, Loss function: 3.431, Average Loss: 3.935, avg. samples / sec: 64968.64
Iteration:   3500, Loss function: 3.588, Average Loss: 3.941, avg. samples / sec: 64988.63
Iteration:   3500, Loss function: 4.038, Average Loss: 3.970, avg. samples / sec: 65019.84
Iteration:   3500, Loss function: 4.248, Average Loss: 3.948, avg. samples / sec: 65076.16
Iteration:   3500, Loss function: 3.271, Average Loss: 3.948, avg. samples / sec: 64959.21
Iteration:   3500, Loss function: 3.442, Average Loss: 3.948, avg. samples / sec: 64874.25
Iteration:   3500, Loss function: 2.943, Average Loss: 3.968, avg. samples / sec: 65103.40
Iteration:   3500, Loss function: 4.186, Average Loss: 3.943, avg. samples / sec: 64938.05
Iteration:   3500, Loss function: 3.780, Average Loss: 3.958, avg. samples / sec: 65130.60
Iteration:   3500, Loss function: 2.554, Average Loss: 3.958, avg. samples / sec: 65030.88
Iteration:   3500, Loss function: 4.259, Average Loss: 3.965, avg. samples / sec: 64917.62
Iteration:   3500, Loss function: 3.019, Average Loss: 3.965, avg. samples / sec: 64861.30
Iteration:   3500, Loss function: 4.548, Average Loss: 3.951, avg. samples / sec: 64930.45
Iteration:   3500, Loss function: 3.487, Average Loss: 3.934, avg. samples / sec: 65038.20
Iteration:   3500, Loss function: 3.053, Average Loss: 3.937, avg. samples / sec: 65008.86
Iteration:   3500, Loss function: 3.419, Average Loss: 3.922, avg. samples / sec: 65026.59
Iteration:   3500, Loss function: 2.702, Average Loss: 3.958, avg. samples / sec: 64960.32
Iteration:   3500, Loss function: 3.992, Average Loss: 3.952, avg. samples / sec: 64891.82
Iteration:   3500, Loss function: 3.319, Average Loss: 3.957, avg. samples / sec: 64965.35
Iteration:   3500, Loss function: 2.796, Average Loss: 3.956, avg. samples / sec: 64841.78
Iteration:   3500, Loss function: 3.413, Average Loss: 3.940, avg. samples / sec: 64833.93
Iteration:   3520, Loss function: 3.877, Average Loss: 3.954, avg. samples / sec: 65985.32
Iteration:   3520, Loss function: 3.818, Average Loss: 3.941, avg. samples / sec: 65876.41
Iteration:   3520, Loss function: 3.288, Average Loss: 3.944, avg. samples / sec: 65908.91
Iteration:   3520, Loss function: 3.218, Average Loss: 3.947, avg. samples / sec: 66046.43
Iteration:   3520, Loss function: 3.511, Average Loss: 3.932, avg. samples / sec: 65950.61
Iteration:   3520, Loss function: 3.034, Average Loss: 3.924, avg. samples / sec: 65927.81
Iteration:   3520, Loss function: 3.085, Average Loss: 3.921, avg. samples / sec: 65830.44
Iteration:   3520, Loss function: 3.542, Average Loss: 3.929, avg. samples / sec: 65790.58
Iteration:   3520, Loss function: 2.875, Average Loss: 3.949, avg. samples / sec: 65858.49
Iteration:   3520, Loss function: 2.976, Average Loss: 3.930, avg. samples / sec: 65937.59
Iteration:   3520, Loss function: 2.563, Average Loss: 3.930, avg. samples / sec: 65885.53
Iteration:   3520, Loss function: 2.895, Average Loss: 3.953, avg. samples / sec: 65909.28
Iteration:   3520, Loss function: 2.709, Average Loss: 3.930, avg. samples / sec: 66005.41
Iteration:   3520, Loss function: 3.806, Average Loss: 3.942, avg. samples / sec: 65884.05
Iteration:   3520, Loss function: 3.358, Average Loss: 3.925, avg. samples / sec: 65706.07
Iteration:   3520, Loss function: 4.342, Average Loss: 3.927, avg. samples / sec: 65907.28
Iteration:   3520, Loss function: 2.518, Average Loss: 3.935, avg. samples / sec: 65706.50
Iteration:   3520, Loss function: 2.990, Average Loss: 3.961, avg. samples / sec: 65807.72
Iteration:   3520, Loss function: 3.289, Average Loss: 3.942, avg. samples / sec: 65867.36
Iteration:   3520, Loss function: 3.612, Average Loss: 3.947, avg. samples / sec: 65903.34
Iteration:   3520, Loss function: 3.028, Average Loss: 3.947, avg. samples / sec: 65928.43
Iteration:   3520, Loss function: 2.856, Average Loss: 3.954, avg. samples / sec: 65842.03
Iteration:   3520, Loss function: 3.652, Average Loss: 3.948, avg. samples / sec: 65819.03
Iteration:   3520, Loss function: 3.514, Average Loss: 3.943, avg. samples / sec: 65803.69
Iteration:   3520, Loss function: 3.022, Average Loss: 3.947, avg. samples / sec: 65803.57
Iteration:   3520, Loss function: 2.461, Average Loss: 3.938, avg. samples / sec: 65805.60
Iteration:   3520, Loss function: 3.765, Average Loss: 3.912, avg. samples / sec: 65837.60
Iteration:   3520, Loss function: 2.866, Average Loss: 3.958, avg. samples / sec: 65782.56
Iteration:   3520, Loss function: 4.005, Average Loss: 3.942, avg. samples / sec: 65673.43
Iteration:   3520, Loss function: 2.819, Average Loss: 3.940, avg. samples / sec: 65796.20
Iteration:   3540, Loss function: 2.951, Average Loss: 3.916, avg. samples / sec: 65763.47
Iteration:   3540, Loss function: 2.136, Average Loss: 3.936, avg. samples / sec: 65614.66
Iteration:   3540, Loss function: 3.751, Average Loss: 3.934, avg. samples / sec: 65610.63
Iteration:   3540, Loss function: 3.238, Average Loss: 3.921, avg. samples / sec: 65727.52
Iteration:   3540, Loss function: 3.241, Average Loss: 3.920, avg. samples / sec: 65627.13
Iteration:   3540, Loss function: 3.549, Average Loss: 3.919, avg. samples / sec: 65617.41
Iteration:   3540, Loss function: 2.948, Average Loss: 3.936, avg. samples / sec: 65723.20
Iteration:   3540, Loss function: 3.489, Average Loss: 3.931, avg. samples / sec: 65748.83
Iteration:   3540, Loss function: 4.196, Average Loss: 3.923, avg. samples / sec: 65640.76
Iteration:   3540, Loss function: 5.040, Average Loss: 3.931, avg. samples / sec: 65812.21
Iteration:   3540, Loss function: 3.431, Average Loss: 3.950, avg. samples / sec: 65700.96
Iteration:   3540, Loss function: 2.883, Average Loss: 3.927, avg. samples / sec: 65646.54
Iteration:   3540, Loss function: 3.629, Average Loss: 3.916, avg. samples / sec: 65600.18
Iteration:   3540, Loss function: 3.147, Average Loss: 3.933, avg. samples / sec: 65654.83
Iteration:   3540, Loss function: 2.560, Average Loss: 3.916, avg. samples / sec: 65539.66
Iteration:   3540, Loss function: 3.427, Average Loss: 3.950, avg. samples / sec: 65611.00
Iteration:   3540, Loss function: 3.100, Average Loss: 3.936, avg. samples / sec: 65634.98
Iteration:   3540, Loss function: 2.223, Average Loss: 3.945, avg. samples / sec: 65481.52
Iteration:   3540, Loss function: 3.111, Average Loss: 3.932, avg. samples / sec: 65697.00
Iteration:   3540, Loss function: 2.665, Average Loss: 3.936, avg. samples / sec: 65604.28
Iteration:   3540, Loss function: 3.695, Average Loss: 3.928, avg. samples / sec: 65558.74
Iteration:   3540, Loss function: 2.659, Average Loss: 3.912, avg. samples / sec: 65486.73
Iteration:   3540, Loss function: 4.131, Average Loss: 3.921, avg. samples / sec: 65521.89
Iteration:   3540, Loss function: 3.722, Average Loss: 3.938, avg. samples / sec: 65437.95
Iteration:   3540, Loss function: 2.515, Average Loss: 3.945, avg. samples / sec: 65542.77
Iteration:   3540, Loss function: 3.015, Average Loss: 3.904, avg. samples / sec: 65597.16
Iteration:   3540, Loss function: 3.032, Average Loss: 3.934, avg. samples / sec: 65559.17
Iteration:   3540, Loss function: 3.816, Average Loss: 3.944, avg. samples / sec: 65437.28
Iteration:   3540, Loss function: 3.446, Average Loss: 3.939, avg. samples / sec: 65400.30
Iteration:   3540, Loss function: 3.584, Average Loss: 3.915, avg. samples / sec: 65370.66
:::MLL 1558651625.662 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558651625.663 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 4.159, Average Loss: 3.925, avg. samples / sec: 65833.17
Iteration:   3560, Loss function: 4.320, Average Loss: 3.911, avg. samples / sec: 65822.29
Iteration:   3560, Loss function: 2.725, Average Loss: 3.905, avg. samples / sec: 65734.11
Iteration:   3560, Loss function: 3.149, Average Loss: 3.922, avg. samples / sec: 65775.56
Iteration:   3560, Loss function: 2.410, Average Loss: 3.922, avg. samples / sec: 65799.82
Iteration:   3560, Loss function: 1.828, Average Loss: 3.908, avg. samples / sec: 65835.51
Iteration:   3560, Loss function: 4.092, Average Loss: 3.921, avg. samples / sec: 65850.62
Iteration:   3560, Loss function: 3.132, Average Loss: 3.928, avg. samples / sec: 65867.91
Iteration:   3560, Loss function: 3.144, Average Loss: 3.926, avg. samples / sec: 65874.56
Iteration:   3560, Loss function: 2.243, Average Loss: 3.923, avg. samples / sec: 65970.93
Iteration:   3560, Loss function: 3.186, Average Loss: 3.907, avg. samples / sec: 65809.47
Iteration:   3560, Loss function: 3.303, Average Loss: 3.939, avg. samples / sec: 65836.62
Iteration:   3560, Loss function: 3.405, Average Loss: 3.901, avg. samples / sec: 65706.84
Iteration:   3560, Loss function: 3.587, Average Loss: 3.909, avg. samples / sec: 65715.23
Iteration:   3560, Loss function: 2.934, Average Loss: 3.919, avg. samples / sec: 65813.68
Iteration:   3560, Loss function: 2.745, Average Loss: 3.941, avg. samples / sec: 65803.63
Iteration:   3560, Loss function: 3.262, Average Loss: 3.904, avg. samples / sec: 65817.06
Iteration:   3560, Loss function: 3.484, Average Loss: 3.924, avg. samples / sec: 65679.86
Iteration:   3560, Loss function: 3.622, Average Loss: 3.908, avg. samples / sec: 65991.32
Iteration:   3560, Loss function: 2.581, Average Loss: 3.892, avg. samples / sec: 65823.30
Iteration:   3560, Loss function: 3.568, Average Loss: 3.922, avg. samples / sec: 65652.11
Iteration:   3560, Loss function: 2.501, Average Loss: 3.930, avg. samples / sec: 65849.26
Iteration:   3560, Loss function: 2.253, Average Loss: 3.905, avg. samples / sec: 65769.12
Iteration:   3560, Loss function: 3.803, Average Loss: 3.928, avg. samples / sec: 65787.44
Iteration:   3560, Loss function: 2.981, Average Loss: 3.928, avg. samples / sec: 65761.38
Iteration:   3560, Loss function: 3.774, Average Loss: 3.935, avg. samples / sec: 65663.76
Iteration:   3560, Loss function: 4.635, Average Loss: 3.920, avg. samples / sec: 65624.93
Iteration:   3560, Loss function: 2.462, Average Loss: 3.911, avg. samples / sec: 65530.97
Iteration:   3560, Loss function: 3.416, Average Loss: 3.928, avg. samples / sec: 65655.38
Iteration:   3560, Loss function: 3.835, Average Loss: 3.925, avg. samples / sec: 65643.91
Iteration:   3580, Loss function: 3.138, Average Loss: 3.904, avg. samples / sec: 65885.40
Iteration:   3580, Loss function: 2.836, Average Loss: 3.915, avg. samples / sec: 66000.50
Iteration:   3580, Loss function: 4.974, Average Loss: 3.886, avg. samples / sec: 66079.32
Iteration:   3580, Loss function: 3.494, Average Loss: 3.892, avg. samples / sec: 65981.18
Iteration:   3580, Loss function: 3.024, Average Loss: 3.911, avg. samples / sec: 65931.36
Iteration:   3580, Loss function: 4.233, Average Loss: 3.902, avg. samples / sec: 65943.79
Iteration:   3580, Loss function: 3.938, Average Loss: 3.914, avg. samples / sec: 66094.04
Iteration:   3580, Loss function: 4.077, Average Loss: 3.929, avg. samples / sec: 65918.41
Iteration:   3580, Loss function: 3.628, Average Loss: 3.901, avg. samples / sec: 65964.35
Iteration:   3580, Loss function: 3.240, Average Loss: 3.896, avg. samples / sec: 65819.95
Iteration:   3580, Loss function: 2.899, Average Loss: 3.909, avg. samples / sec: 65953.58
Iteration:   3580, Loss function: 2.628, Average Loss: 3.924, avg. samples / sec: 65918.01
Iteration:   3580, Loss function: 3.561, Average Loss: 3.919, avg. samples / sec: 66027.71
Iteration:   3580, Loss function: 2.681, Average Loss: 3.898, avg. samples / sec: 66061.51
Iteration:   3580, Loss function: 3.993, Average Loss: 3.926, avg. samples / sec: 66018.49
Iteration:   3580, Loss function: 3.913, Average Loss: 3.902, avg. samples / sec: 65866.65
Iteration:   3580, Loss function: 3.880, Average Loss: 3.915, avg. samples / sec: 65739.08
Iteration:   3580, Loss function: 3.802, Average Loss: 3.916, avg. samples / sec: 65799.79
Iteration:   3580, Loss function: 4.004, Average Loss: 3.918, avg. samples / sec: 66024.52
Iteration:   3580, Loss function: 3.871, Average Loss: 3.910, avg. samples / sec: 66018.27
Iteration:   3580, Loss function: 2.508, Average Loss: 3.908, avg. samples / sec: 65882.05
Iteration:   3580, Loss function: 3.795, Average Loss: 3.915, avg. samples / sec: 65845.82
Iteration:   3580, Loss function: 4.196, Average Loss: 3.892, avg. samples / sec: 65891.60
Iteration:   3580, Loss function: 3.395, Average Loss: 3.890, avg. samples / sec: 65938.67
Iteration:   3580, Loss function: 3.307, Average Loss: 3.912, avg. samples / sec: 65925.99
Iteration:   3580, Loss function: 4.717, Average Loss: 3.901, avg. samples / sec: 65822.69
Iteration:   3580, Loss function: 2.851, Average Loss: 3.928, avg. samples / sec: 65922.69
Iteration:   3580, Loss function: 3.541, Average Loss: 3.917, avg. samples / sec: 65803.91
Iteration:   3580, Loss function: 2.743, Average Loss: 3.912, avg. samples / sec: 65772.52
Iteration:   3580, Loss function: 4.624, Average Loss: 3.916, avg. samples / sec: 65895.66
Iteration:   3600, Loss function: 3.107, Average Loss: 3.907, avg. samples / sec: 65737.67
Iteration:   3600, Loss function: 3.204, Average Loss: 3.907, avg. samples / sec: 65729.91
Iteration:   3600, Loss function: 4.946, Average Loss: 3.882, avg. samples / sec: 65724.64
Iteration:   3600, Loss function: 2.556, Average Loss: 3.893, avg. samples / sec: 65535.76
Iteration:   3600, Loss function: 2.807, Average Loss: 3.897, avg. samples / sec: 65680.44
Iteration:   3600, Loss function: 3.140, Average Loss: 3.896, avg. samples / sec: 65603.36
Iteration:   3600, Loss function: 3.219, Average Loss: 3.923, avg. samples / sec: 65633.12
Iteration:   3600, Loss function: 3.395, Average Loss: 3.888, avg. samples / sec: 65679.15
Iteration:   3600, Loss function: 2.804, Average Loss: 3.901, avg. samples / sec: 65511.81
Iteration:   3600, Loss function: 2.841, Average Loss: 3.882, avg. samples / sec: 65662.20
Iteration:   3600, Loss function: 2.666, Average Loss: 3.890, avg. samples / sec: 65574.24
Iteration:   3600, Loss function: 2.871, Average Loss: 3.907, avg. samples / sec: 65645.90
Iteration:   3600, Loss function: 4.127, Average Loss: 3.878, avg. samples / sec: 65505.26
Iteration:   3600, Loss function: 3.198, Average Loss: 3.904, avg. samples / sec: 65633.21
Iteration:   3600, Loss function: 3.465, Average Loss: 3.892, avg. samples / sec: 65575.92
Iteration:   3600, Loss function: 3.743, Average Loss: 3.908, avg. samples / sec: 65586.57
Iteration:   3600, Loss function: 3.513, Average Loss: 3.907, avg. samples / sec: 65672.51
Iteration:   3600, Loss function: 2.872, Average Loss: 3.901, avg. samples / sec: 65505.23
Iteration:   3600, Loss function: 3.478, Average Loss: 3.893, avg. samples / sec: 65521.65
Iteration:   3600, Loss function: 2.376, Average Loss: 3.912, avg. samples / sec: 65523.17
Iteration:   3600, Loss function: 3.657, Average Loss: 3.923, avg. samples / sec: 65471.09
Iteration:   3600, Loss function: 4.025, Average Loss: 3.883, avg. samples / sec: 65488.46
Iteration:   3600, Loss function: 3.748, Average Loss: 3.905, avg. samples / sec: 65502.95
Iteration:   3600, Loss function: 2.970, Average Loss: 3.919, avg. samples / sec: 65554.38
Iteration:   3600, Loss function: 2.266, Average Loss: 3.889, avg. samples / sec: 65486.39
Iteration:   3600, Loss function: 2.430, Average Loss: 3.903, avg. samples / sec: 65570.82
Iteration:   3600, Loss function: 4.412, Average Loss: 3.909, avg. samples / sec: 65490.87
Iteration:   3600, Loss function: 4.044, Average Loss: 3.874, avg. samples / sec: 65307.59
Iteration:   3600, Loss function: 2.899, Average Loss: 3.906, avg. samples / sec: 65464.03
Iteration:   3600, Loss function: 3.670, Average Loss: 3.906, avg. samples / sec: 65358.11
Iteration:   3620, Loss function: 2.519, Average Loss: 3.884, avg. samples / sec: 66122.41
Iteration:   3620, Loss function: 2.891, Average Loss: 3.873, avg. samples / sec: 66225.04
Iteration:   3620, Loss function: 2.781, Average Loss: 3.895, avg. samples / sec: 66110.81
Iteration:   3620, Loss function: 3.088, Average Loss: 3.880, avg. samples / sec: 66104.11
Iteration:   3620, Loss function: 3.818, Average Loss: 3.885, avg. samples / sec: 66073.37
Iteration:   3620, Loss function: 3.281, Average Loss: 3.895, avg. samples / sec: 65973.31
Iteration:   3620, Loss function: 3.712, Average Loss: 3.895, avg. samples / sec: 66225.04
Iteration:   3620, Loss function: 5.465, Average Loss: 3.886, avg. samples / sec: 66121.64
Iteration:   3620, Loss function: 3.201, Average Loss: 3.869, avg. samples / sec: 66096.49
Iteration:   3620, Loss function: 3.463, Average Loss: 3.896, avg. samples / sec: 65942.56
Iteration:   3620, Loss function: 4.138, Average Loss: 3.895, avg. samples / sec: 66264.81
Iteration:   3620, Loss function: 3.236, Average Loss: 3.890, avg. samples / sec: 66110.47
Iteration:   3620, Loss function: 3.849, Average Loss: 3.877, avg. samples / sec: 66021.21
Iteration:   3620, Loss function: 3.150, Average Loss: 3.898, avg. samples / sec: 66038.23
Iteration:   3620, Loss function: 3.511, Average Loss: 3.914, avg. samples / sec: 66171.03
Iteration:   3620, Loss function: 3.290, Average Loss: 3.891, avg. samples / sec: 66060.55
Iteration:   3620, Loss function: 3.036, Average Loss: 3.884, avg. samples / sec: 65987.79
Iteration:   3620, Loss function: 5.838, Average Loss: 3.872, avg. samples / sec: 65928.80
Iteration:   3620, Loss function: 4.069, Average Loss: 3.876, avg. samples / sec: 66011.84
Iteration:   3620, Loss function: 3.488, Average Loss: 3.917, avg. samples / sec: 66115.68
Iteration:   3620, Loss function: 4.607, Average Loss: 3.885, avg. samples / sec: 66072.35
Iteration:   3620, Loss function: 3.732, Average Loss: 3.912, avg. samples / sec: 65966.79
Iteration:   3620, Loss function: 3.531, Average Loss: 3.899, avg. samples / sec: 66064.54
Iteration:   3620, Loss function: 2.301, Average Loss: 3.879, avg. samples / sec: 66127.97
Iteration:   3620, Loss function: 3.569, Average Loss: 3.897, avg. samples / sec: 66090.44
Iteration:   3620, Loss function: 2.268, Average Loss: 3.903, avg. samples / sec: 66069.56
Iteration:   3620, Loss function: 3.248, Average Loss: 3.896, avg. samples / sec: 66019.88
Iteration:   3620, Loss function: 2.902, Average Loss: 3.869, avg. samples / sec: 66106.31
Iteration:   3620, Loss function: 3.662, Average Loss: 3.898, avg. samples / sec: 66107.65
Iteration:   3620, Loss function: 4.187, Average Loss: 3.897, avg. samples / sec: 66028.11
:::MLL 1558651627.449 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558651627.449 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 4.279, Average Loss: 3.873, avg. samples / sec: 65724.33
Iteration:   3640, Loss function: 2.946, Average Loss: 3.863, avg. samples / sec: 65740.09
Iteration:   3640, Loss function: 4.329, Average Loss: 3.871, avg. samples / sec: 65700.16
Iteration:   3640, Loss function: 3.001, Average Loss: 3.868, avg. samples / sec: 65767.92
Iteration:   3640, Loss function: 4.162, Average Loss: 3.868, avg. samples / sec: 65613.17
Iteration:   3640, Loss function: 4.601, Average Loss: 3.889, avg. samples / sec: 65689.84
Iteration:   3640, Loss function: 2.905, Average Loss: 3.880, avg. samples / sec: 65678.51
Iteration:   3640, Loss function: 3.036, Average Loss: 3.874, avg. samples / sec: 65694.46
Iteration:   3640, Loss function: 3.595, Average Loss: 3.909, avg. samples / sec: 65715.23
Iteration:   3640, Loss function: 3.722, Average Loss: 3.887, avg. samples / sec: 65631.50
Iteration:   3640, Loss function: 2.888, Average Loss: 3.879, avg. samples / sec: 65610.90
Iteration:   3640, Loss function: 3.086, Average Loss: 3.863, avg. samples / sec: 65782.72
Iteration:   3640, Loss function: 3.533, Average Loss: 3.867, avg. samples / sec: 65649.05
Iteration:   3640, Loss function: 3.162, Average Loss: 3.871, avg. samples / sec: 65664.31
Iteration:   3640, Loss function: 2.936, Average Loss: 3.886, avg. samples / sec: 65600.83
Iteration:   3640, Loss function: 1.851, Average Loss: 3.886, avg. samples / sec: 65617.38
Iteration:   3640, Loss function: 2.658, Average Loss: 3.863, avg. samples / sec: 65620.38
Iteration:   3640, Loss function: 4.324, Average Loss: 3.893, avg. samples / sec: 65684.33
Iteration:   3640, Loss function: 2.960, Average Loss: 3.883, avg. samples / sec: 65755.09
Iteration:   3640, Loss function: 3.144, Average Loss: 3.899, avg. samples / sec: 65634.65
Iteration:   3640, Loss function: 3.966, Average Loss: 3.881, avg. samples / sec: 65555.18
Iteration:   3640, Loss function: 4.270, Average Loss: 3.889, avg. samples / sec: 65624.87
Iteration:   3640, Loss function: 3.845, Average Loss: 3.880, avg. samples / sec: 65581.81
Iteration:   3640, Loss function: 3.974, Average Loss: 3.886, avg. samples / sec: 65702.92
Iteration:   3640, Loss function: 3.239, Average Loss: 3.885, avg. samples / sec: 65610.14
Iteration:   3640, Loss function: 3.077, Average Loss: 3.885, avg. samples / sec: 65478.94
Iteration:   3640, Loss function: 2.709, Average Loss: 3.889, avg. samples / sec: 65605.10
Iteration:   3640, Loss function: 3.219, Average Loss: 3.884, avg. samples / sec: 65483.29
Iteration:   3640, Loss function: 4.253, Average Loss: 3.908, avg. samples / sec: 65495.98
Iteration:   3640, Loss function: 3.162, Average Loss: 3.880, avg. samples / sec: 65525.70
Iteration:   3660, Loss function: 4.075, Average Loss: 3.858, avg. samples / sec: 66047.57
Iteration:   3660, Loss function: 3.649, Average Loss: 3.883, avg. samples / sec: 66082.48
Iteration:   3660, Loss function: 2.422, Average Loss: 3.874, avg. samples / sec: 66258.64
Iteration:   3660, Loss function: 2.444, Average Loss: 3.872, avg. samples / sec: 66122.57
Iteration:   3660, Loss function: 3.083, Average Loss: 3.872, avg. samples / sec: 66075.94
Iteration:   3660, Loss function: 2.420, Average Loss: 3.867, avg. samples / sec: 66180.45
Iteration:   3660, Loss function: 4.497, Average Loss: 3.874, avg. samples / sec: 66251.88
Iteration:   3660, Loss function: 2.919, Average Loss: 3.852, avg. samples / sec: 66123.47
Iteration:   3660, Loss function: 2.454, Average Loss: 3.876, avg. samples / sec: 66159.20
Iteration:   3660, Loss function: 2.620, Average Loss: 3.879, avg. samples / sec: 66116.83
Iteration:   3660, Loss function: 3.639, Average Loss: 3.873, avg. samples / sec: 66100.83
Iteration:   3660, Loss function: 4.109, Average Loss: 3.885, avg. samples / sec: 66147.24
Iteration:   3660, Loss function: 2.583, Average Loss: 3.870, avg. samples / sec: 66124.58
Iteration:   3660, Loss function: 3.604, Average Loss: 3.877, avg. samples / sec: 66070.70
Iteration:   3660, Loss function: 3.685, Average Loss: 3.897, avg. samples / sec: 65999.60
Iteration:   3660, Loss function: 3.337, Average Loss: 3.862, avg. samples / sec: 66062.71
Iteration:   3660, Loss function: 2.636, Average Loss: 3.861, avg. samples / sec: 66051.01
Iteration:   3660, Loss function: 3.531, Average Loss: 3.898, avg. samples / sec: 66159.82
Iteration:   3660, Loss function: 3.496, Average Loss: 3.876, avg. samples / sec: 66106.84
Iteration:   3660, Loss function: 3.993, Average Loss: 3.863, avg. samples / sec: 65963.86
Iteration:   3660, Loss function: 3.623, Average Loss: 3.874, avg. samples / sec: 66086.16
Iteration:   3660, Loss function: 4.011, Average Loss: 3.863, avg. samples / sec: 65816.51
Iteration:   3660, Loss function: 3.315, Average Loss: 3.879, avg. samples / sec: 66084.52
Iteration:   3660, Loss function: 2.268, Average Loss: 3.871, avg. samples / sec: 65979.95
Iteration:   3660, Loss function: 4.234, Average Loss: 3.882, avg. samples / sec: 66023.66
Iteration:   3660, Loss function: 4.181, Average Loss: 3.867, avg. samples / sec: 65869.11
Iteration:   3660, Loss function: 3.814, Average Loss: 3.862, avg. samples / sec: 65853.48
Iteration:   3660, Loss function: 2.657, Average Loss: 3.871, avg. samples / sec: 65926.03
Iteration:   3660, Loss function: 2.707, Average Loss: 3.891, avg. samples / sec: 65999.72
Iteration:   3660, Loss function: 3.410, Average Loss: 3.854, avg. samples / sec: 65910.86
Iteration:   3680, Loss function: 3.372, Average Loss: 3.855, avg. samples / sec: 66232.14
Iteration:   3680, Loss function: 4.719, Average Loss: 3.856, avg. samples / sec: 66148.05
Iteration:   3680, Loss function: 4.300, Average Loss: 3.855, avg. samples / sec: 66163.33
Iteration:   3680, Loss function: 3.212, Average Loss: 3.868, avg. samples / sec: 66071.54
Iteration:   3680, Loss function: 3.041, Average Loss: 3.869, avg. samples / sec: 65988.13
Iteration:   3680, Loss function: 4.144, Average Loss: 3.870, avg. samples / sec: 66078.39
Iteration:   3680, Loss function: 4.695, Average Loss: 3.873, avg. samples / sec: 66098.78
Iteration:   3680, Loss function: 3.115, Average Loss: 3.861, avg. samples / sec: 65983.10
Iteration:   3680, Loss function: 3.522, Average Loss: 3.848, avg. samples / sec: 65881.65
Iteration:   3680, Loss function: 3.154, Average Loss: 3.873, avg. samples / sec: 66052.28
Iteration:   3680, Loss function: 3.251, Average Loss: 3.888, avg. samples / sec: 66035.23
Iteration:   3680, Loss function: 3.706, Average Loss: 3.876, avg. samples / sec: 65956.91
Iteration:   3680, Loss function: 3.552, Average Loss: 3.866, avg. samples / sec: 65929.97
Iteration:   3680, Loss function: 2.046, Average Loss: 3.861, avg. samples / sec: 65886.08
Iteration:   3680, Loss function: 3.744, Average Loss: 3.866, avg. samples / sec: 65937.04
Iteration:   3680, Loss function: 3.012, Average Loss: 3.848, avg. samples / sec: 66116.70
Iteration:   3680, Loss function: 3.868, Average Loss: 3.859, avg. samples / sec: 66007.98
Iteration:   3680, Loss function: 3.049, Average Loss: 3.865, avg. samples / sec: 66035.04
Iteration:   3680, Loss function: 2.996, Average Loss: 3.847, avg. samples / sec: 65983.35
Iteration:   3680, Loss function: 2.988, Average Loss: 3.866, avg. samples / sec: 66000.28
Iteration:   3680, Loss function: 3.578, Average Loss: 3.874, avg. samples / sec: 65953.73
Iteration:   3680, Loss function: 3.509, Average Loss: 3.848, avg. samples / sec: 65985.14
Iteration:   3680, Loss function: 2.988, Average Loss: 3.868, avg. samples / sec: 65937.19
Iteration:   3680, Loss function: 3.273, Average Loss: 3.882, avg. samples / sec: 66058.75
Iteration:   3680, Loss function: 2.434, Average Loss: 3.887, avg. samples / sec: 65969.11
Iteration:   3680, Loss function: 3.149, Average Loss: 3.838, avg. samples / sec: 65898.90
Iteration:   3680, Loss function: 2.779, Average Loss: 3.858, avg. samples / sec: 65841.57
Iteration:   3680, Loss function: 4.199, Average Loss: 3.865, avg. samples / sec: 65947.47
Iteration:   3680, Loss function: 3.729, Average Loss: 3.864, avg. samples / sec: 65900.68
Iteration:   3680, Loss function: 3.561, Average Loss: 3.860, avg. samples / sec: 65788.95
:::MLL 1558651629.236 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558651629.236 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 3.570, Average Loss: 3.844, avg. samples / sec: 65658.41
Iteration:   3700, Loss function: 4.238, Average Loss: 3.864, avg. samples / sec: 65546.91
Iteration:   3700, Loss function: 3.257, Average Loss: 3.840, avg. samples / sec: 65400.33
Iteration:   3700, Loss function: 3.437, Average Loss: 3.847, avg. samples / sec: 65476.44
Iteration:   3700, Loss function: 4.621, Average Loss: 3.877, avg. samples / sec: 65595.54
Iteration:   3700, Loss function: 4.022, Average Loss: 3.853, avg. samples / sec: 65550.20
Iteration:   3700, Loss function: 2.778, Average Loss: 3.861, avg. samples / sec: 65446.13
Iteration:   3700, Loss function: 3.244, Average Loss: 3.840, avg. samples / sec: 65530.09
Iteration:   3700, Loss function: 3.891, Average Loss: 3.851, avg. samples / sec: 65596.00
Iteration:   3700, Loss function: 3.216, Average Loss: 3.865, avg. samples / sec: 65539.75
Iteration:   3700, Loss function: 3.147, Average Loss: 3.861, avg. samples / sec: 65477.90
Iteration:   3700, Loss function: 2.385, Average Loss: 3.858, avg. samples / sec: 65406.85
Iteration:   3700, Loss function: 3.550, Average Loss: 3.857, avg. samples / sec: 65485.24
Iteration:   3700, Loss function: 3.362, Average Loss: 3.858, avg. samples / sec: 65518.72
Iteration:   3700, Loss function: 3.093, Average Loss: 3.878, avg. samples / sec: 65443.57
Iteration:   3700, Loss function: 2.554, Average Loss: 3.867, avg. samples / sec: 65498.44
Iteration:   3700, Loss function: 2.348, Average Loss: 3.850, avg. samples / sec: 65494.76
Iteration:   3700, Loss function: 4.637, Average Loss: 3.840, avg. samples / sec: 65406.06
Iteration:   3700, Loss function: 3.645, Average Loss: 3.858, avg. samples / sec: 65444.06
Iteration:   3700, Loss function: 3.053, Average Loss: 3.844, avg. samples / sec: 65309.10
Iteration:   3700, Loss function: 3.177, Average Loss: 3.858, avg. samples / sec: 65370.87
Iteration:   3700, Loss function: 2.918, Average Loss: 3.852, avg. samples / sec: 65540.69
Iteration:   3700, Loss function: 2.335, Average Loss: 3.854, avg. samples / sec: 65431.09
Iteration:   3700, Loss function: 3.299, Average Loss: 3.855, avg. samples / sec: 65370.63
Iteration:   3700, Loss function: 3.387, Average Loss: 3.844, avg. samples / sec: 65338.90
Iteration:   3700, Loss function: 3.313, Average Loss: 3.832, avg. samples / sec: 65458.20
Iteration:   3700, Loss function: 3.186, Average Loss: 3.853, avg. samples / sec: 65510.81
Iteration:   3700, Loss function: 3.250, Average Loss: 3.850, avg. samples / sec: 65542.00
Iteration:   3700, Loss function: 3.717, Average Loss: 3.865, avg. samples / sec: 65311.52
Iteration:   3700, Loss function: 3.872, Average Loss: 3.842, avg. samples / sec: 65304.20
Iteration:   3720, Loss function: 3.241, Average Loss: 3.838, avg. samples / sec: 65998.95
Iteration:   3720, Loss function: 3.472, Average Loss: 3.831, avg. samples / sec: 66067.85
Iteration:   3720, Loss function: 4.072, Average Loss: 3.844, avg. samples / sec: 66092.30
Iteration:   3720, Loss function: 3.749, Average Loss: 3.858, avg. samples / sec: 66150.07
Iteration:   3720, Loss function: 4.018, Average Loss: 3.843, avg. samples / sec: 65937.01
Iteration:   3720, Loss function: 3.227, Average Loss: 3.840, avg. samples / sec: 65853.35
Iteration:   3720, Loss function: 3.104, Average Loss: 3.833, avg. samples / sec: 66006.06
Iteration:   3720, Loss function: 3.256, Average Loss: 3.841, avg. samples / sec: 65966.79
Iteration:   3720, Loss function: 2.492, Average Loss: 3.869, avg. samples / sec: 65880.72
Iteration:   3720, Loss function: 3.208, Average Loss: 3.848, avg. samples / sec: 65788.98
Iteration:   3720, Loss function: 3.266, Average Loss: 3.870, avg. samples / sec: 65937.35
Iteration:   3720, Loss function: 4.130, Average Loss: 3.854, avg. samples / sec: 65898.56
Iteration:   3720, Loss function: 4.016, Average Loss: 3.841, avg. samples / sec: 65972.60
Iteration:   3720, Loss function: 3.458, Average Loss: 3.848, avg. samples / sec: 65981.34
Iteration:   3720, Loss function: 3.705, Average Loss: 3.852, avg. samples / sec: 65922.97
Iteration:   3720, Loss function: 3.711, Average Loss: 3.836, avg. samples / sec: 65782.19
Iteration:   3720, Loss function: 3.883, Average Loss: 3.852, avg. samples / sec: 65868.74
Iteration:   3720, Loss function: 4.316, Average Loss: 3.822, avg. samples / sec: 65974.94
Iteration:   3720, Loss function: 2.399, Average Loss: 3.853, avg. samples / sec: 65883.99
Iteration:   3720, Loss function: 4.477, Average Loss: 3.836, avg. samples / sec: 65944.04
Iteration:   3720, Loss function: 3.698, Average Loss: 3.831, avg. samples / sec: 65825.89
Iteration:   3720, Loss function: 2.704, Average Loss: 3.835, avg. samples / sec: 66032.81
Iteration:   3720, Loss function: 2.906, Average Loss: 3.847, avg. samples / sec: 65768.38
Iteration:   3720, Loss function: 2.866, Average Loss: 3.861, avg. samples / sec: 65777.07
Iteration:   3720, Loss function: 2.969, Average Loss: 3.847, avg. samples / sec: 65873.15
Iteration:   3720, Loss function: 3.514, Average Loss: 3.853, avg. samples / sec: 65754.02
Iteration:   3720, Loss function: 3.597, Average Loss: 3.847, avg. samples / sec: 65770.40
Iteration:   3720, Loss function: 4.443, Average Loss: 3.853, avg. samples / sec: 65779.74
Iteration:   3720, Loss function: 3.413, Average Loss: 3.847, avg. samples / sec: 65810.95
Iteration:   3720, Loss function: 4.237, Average Loss: 3.843, avg. samples / sec: 65822.66
Iteration:   3740, Loss function: 2.218, Average Loss: 3.839, avg. samples / sec: 66329.34
Iteration:   3740, Loss function: 3.744, Average Loss: 3.864, avg. samples / sec: 66129.83
Iteration:   3740, Loss function: 3.292, Average Loss: 3.844, avg. samples / sec: 66274.31
Iteration:   3740, Loss function: 4.668, Average Loss: 3.834, avg. samples / sec: 66145.91
Iteration:   3740, Loss function: 2.627, Average Loss: 3.828, avg. samples / sec: 65878.81
Iteration:   3740, Loss function: 3.427, Average Loss: 3.832, avg. samples / sec: 66045.19
Iteration:   3740, Loss function: 2.981, Average Loss: 3.849, avg. samples / sec: 66135.88
Iteration:   3740, Loss function: 2.931, Average Loss: 3.823, avg. samples / sec: 65969.72
Iteration:   3740, Loss function: 2.893, Average Loss: 3.824, avg. samples / sec: 66141.99
Iteration:   3740, Loss function: 2.546, Average Loss: 3.834, avg. samples / sec: 65995.03
Iteration:   3740, Loss function: 3.891, Average Loss: 3.835, avg. samples / sec: 66047.30
Iteration:   3740, Loss function: 2.637, Average Loss: 3.821, avg. samples / sec: 66050.45
Iteration:   3740, Loss function: 4.727, Average Loss: 3.841, avg. samples / sec: 66045.65
Iteration:   3740, Loss function: 3.203, Average Loss: 3.838, avg. samples / sec: 66093.85
Iteration:   3740, Loss function: 4.958, Average Loss: 3.841, avg. samples / sec: 66214.37
Iteration:   3740, Loss function: 2.508, Average Loss: 3.827, avg. samples / sec: 66089.60
Iteration:   3740, Loss function: 2.876, Average Loss: 3.847, avg. samples / sec: 65978.71
Iteration:   3740, Loss function: 4.428, Average Loss: 3.840, avg. samples / sec: 66062.34
Iteration:   3740, Loss function: 4.151, Average Loss: 3.837, avg. samples / sec: 66115.25
Iteration:   3740, Loss function: 3.671, Average Loss: 3.842, avg. samples / sec: 66066.03
Iteration:   3740, Loss function: 4.168, Average Loss: 3.837, avg. samples / sec: 66211.98
Iteration:   3740, Loss function: 3.505, Average Loss: 3.838, avg. samples / sec: 66115.49
Iteration:   3740, Loss function: 3.787, Average Loss: 3.845, avg. samples / sec: 66102.13
Iteration:   3740, Loss function: 2.721, Average Loss: 3.821, avg. samples / sec: 66036.74
Iteration:   3740, Loss function: 3.574, Average Loss: 3.854, avg. samples / sec: 66098.10
Iteration:   3740, Loss function: 4.429, Average Loss: 3.830, avg. samples / sec: 65938.24
Iteration:   3740, Loss function: 3.008, Average Loss: 3.815, avg. samples / sec: 65980.50
Iteration:   3740, Loss function: 3.263, Average Loss: 3.862, avg. samples / sec: 65889.87
Iteration:   3740, Loss function: 1.921, Average Loss: 3.846, avg. samples / sec: 65843.17
Iteration:   3740, Loss function: 2.752, Average Loss: 3.828, avg. samples / sec: 65908.45
Iteration:   3760, Loss function: 2.311, Average Loss: 3.810, avg. samples / sec: 65898.28
Iteration:   3760, Loss function: 3.308, Average Loss: 3.832, avg. samples / sec: 65724.36
Iteration:   3760, Loss function: 2.890, Average Loss: 3.853, avg. samples / sec: 65727.92
Iteration:   3760, Loss function: 3.153, Average Loss: 3.817, avg. samples / sec: 65733.56
Iteration:   3760, Loss function: 2.662, Average Loss: 3.831, avg. samples / sec: 65770.40
Iteration:   3760, Loss function: 2.847, Average Loss: 3.832, avg. samples / sec: 65829.79
Iteration:   3760, Loss function: 3.178, Average Loss: 3.832, avg. samples / sec: 65781.76
Iteration:   3760, Loss function: 3.567, Average Loss: 3.828, avg. samples / sec: 65675.08
Iteration:   3760, Loss function: 2.165, Average Loss: 3.843, avg. samples / sec: 65694.19
Iteration:   3760, Loss function: 2.490, Average Loss: 3.833, avg. samples / sec: 65807.01
Iteration:   3760, Loss function: 3.732, Average Loss: 3.807, avg. samples / sec: 65685.61
Iteration:   3760, Loss function: 3.477, Average Loss: 3.827, avg. samples / sec: 65697.25
Iteration:   3760, Loss function: 3.312, Average Loss: 3.826, avg. samples / sec: 65670.40
Iteration:   3760, Loss function: 2.855, Average Loss: 3.825, avg. samples / sec: 65609.59
Iteration:   3760, Loss function: 4.392, Average Loss: 3.829, avg. samples / sec: 65706.44
Iteration:   3760, Loss function: 4.011, Average Loss: 3.835, avg. samples / sec: 65685.58
Iteration:   3760, Loss function: 2.901, Average Loss: 3.827, avg. samples / sec: 65685.40
Iteration:   3760, Loss function: 4.143, Average Loss: 3.825, avg. samples / sec: 65650.21
Iteration:   3760, Loss function: 3.490, Average Loss: 3.828, avg. samples / sec: 65713.39
Iteration:   3760, Loss function: 4.337, Average Loss: 3.818, avg. samples / sec: 65758.47
Iteration:   3760, Loss function: 3.167, Average Loss: 3.821, avg. samples / sec: 65881.62
Iteration:   3760, Loss function: 3.593, Average Loss: 3.847, avg. samples / sec: 65717.78
Iteration:   3760, Loss function: 3.149, Average Loss: 3.853, avg. samples / sec: 65763.35
Iteration:   3760, Loss function: 4.319, Average Loss: 3.822, avg. samples / sec: 65647.21
Iteration:   3760, Loss function: 4.037, Average Loss: 3.820, avg. samples / sec: 65595.06
Iteration:   3760, Loss function: 3.578, Average Loss: 3.823, avg. samples / sec: 65586.78
Iteration:   3760, Loss function: 2.674, Average Loss: 3.831, avg. samples / sec: 65608.89
Iteration:   3760, Loss function: 2.490, Average Loss: 3.811, avg. samples / sec: 65693.36
Iteration:   3760, Loss function: 3.848, Average Loss: 3.836, avg. samples / sec: 65780.14
Iteration:   3760, Loss function: 4.124, Average Loss: 3.800, avg. samples / sec: 65682.80
:::MLL 1558651631.024 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558651631.025 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 2.768, Average Loss: 3.795, avg. samples / sec: 64636.84
Iteration:   3780, Loss function: 3.463, Average Loss: 3.817, avg. samples / sec: 64640.96
Iteration:   3780, Loss function: 3.895, Average Loss: 3.819, avg. samples / sec: 64649.27
Iteration:   3780, Loss function: 2.477, Average Loss: 3.812, avg. samples / sec: 64683.06
Iteration:   3780, Loss function: 3.774, Average Loss: 3.843, avg. samples / sec: 64665.94
Iteration:   3780, Loss function: 3.108, Average Loss: 3.820, avg. samples / sec: 64537.92
Iteration:   3780, Loss function: 3.301, Average Loss: 3.806, avg. samples / sec: 64512.69
Iteration:   3780, Loss function: 2.776, Average Loss: 3.808, avg. samples / sec: 64626.85
Iteration:   3780, Loss function: 3.373, Average Loss: 3.822, avg. samples / sec: 64516.26
Iteration:   3780, Loss function: 2.252, Average Loss: 3.819, avg. samples / sec: 64618.41
Iteration:   3780, Loss function: 3.196, Average Loss: 3.817, avg. samples / sec: 64523.06
Iteration:   3780, Loss function: 2.394, Average Loss: 3.814, avg. samples / sec: 64575.24
Iteration:   3780, Loss function: 4.212, Average Loss: 3.827, avg. samples / sec: 64567.64
Iteration:   3780, Loss function: 3.316, Average Loss: 3.811, avg. samples / sec: 64588.76
Iteration:   3780, Loss function: 5.141, Average Loss: 3.827, avg. samples / sec: 64509.53
Iteration:   3780, Loss function: 3.296, Average Loss: 3.810, avg. samples / sec: 64604.37
Iteration:   3780, Loss function: 3.201, Average Loss: 3.825, avg. samples / sec: 64650.48
Iteration:   3780, Loss function: 3.630, Average Loss: 3.814, avg. samples / sec: 64594.24
Iteration:   3780, Loss function: 4.409, Average Loss: 3.821, avg. samples / sec: 64607.74
Iteration:   3780, Loss function: 2.475, Average Loss: 3.800, avg. samples / sec: 64608.28
Iteration:   3780, Loss function: 3.315, Average Loss: 3.847, avg. samples / sec: 64422.74
Iteration:   3780, Loss function: 3.589, Average Loss: 3.837, avg. samples / sec: 64509.53
Iteration:   3780, Loss function: 3.704, Average Loss: 3.801, avg. samples / sec: 64279.11
Iteration:   3780, Loss function: 3.659, Average Loss: 3.825, avg. samples / sec: 64368.78
Iteration:   3780, Loss function: 4.320, Average Loss: 3.818, avg. samples / sec: 64528.55
Iteration:   3780, Loss function: 3.920, Average Loss: 3.825, avg. samples / sec: 64526.78
Iteration:   3780, Loss function: 2.858, Average Loss: 3.843, avg. samples / sec: 64511.15
Iteration:   3780, Loss function: 2.582, Average Loss: 3.824, avg. samples / sec: 64385.60
Iteration:   3780, Loss function: 3.035, Average Loss: 3.814, avg. samples / sec: 64461.23
Iteration:   3780, Loss function: 4.607, Average Loss: 3.792, avg. samples / sec: 64516.03
Iteration:   3800, Loss function: 3.554, Average Loss: 3.819, avg. samples / sec: 66071.48
Iteration:   3800, Loss function: 4.917, Average Loss: 3.817, avg. samples / sec: 66092.52
Iteration:   3800, Loss function: 3.103, Average Loss: 3.797, avg. samples / sec: 65976.21
Iteration:   3800, Loss function: 2.943, Average Loss: 3.815, avg. samples / sec: 66018.12
Iteration:   3800, Loss function: 2.688, Average Loss: 3.784, avg. samples / sec: 65902.44
Iteration:   3800, Loss function: 2.861, Average Loss: 3.838, avg. samples / sec: 66034.85
Iteration:   3800, Loss function: 2.960, Average Loss: 3.803, avg. samples / sec: 66001.64
Iteration:   3800, Loss function: 2.922, Average Loss: 3.792, avg. samples / sec: 66020.13
Iteration:   3800, Loss function: 1.789, Average Loss: 3.818, avg. samples / sec: 66024.21
Iteration:   3800, Loss function: 3.445, Average Loss: 3.799, avg. samples / sec: 66000.90
Iteration:   3800, Loss function: 4.165, Average Loss: 3.830, avg. samples / sec: 66005.47
Iteration:   3800, Loss function: 2.481, Average Loss: 3.802, avg. samples / sec: 65953.58
Iteration:   3800, Loss function: 3.301, Average Loss: 3.810, avg. samples / sec: 65859.51
Iteration:   3800, Loss function: 3.180, Average Loss: 3.811, avg. samples / sec: 65925.96
Iteration:   3800, Loss function: 3.288, Average Loss: 3.802, avg. samples / sec: 65887.81
Iteration:   3800, Loss function: 2.947, Average Loss: 3.793, avg. samples / sec: 66016.73
Iteration:   3800, Loss function: 2.146, Average Loss: 3.806, avg. samples / sec: 65938.64
Iteration:   3800, Loss function: 3.540, Average Loss: 3.785, avg. samples / sec: 66115.71
Iteration:   3800, Loss function: 3.818, Average Loss: 3.820, avg. samples / sec: 65955.49
Iteration:   3800, Loss function: 3.185, Average Loss: 3.802, avg. samples / sec: 65969.51
Iteration:   3800, Loss function: 3.576, Average Loss: 3.813, avg. samples / sec: 65821.98
Iteration:   3800, Loss function: 2.824, Average Loss: 3.835, avg. samples / sec: 66002.16
Iteration:   3800, Loss function: 2.987, Average Loss: 3.812, avg. samples / sec: 65920.91
Iteration:   3800, Loss function: 3.028, Average Loss: 3.810, avg. samples / sec: 65969.79
Iteration:   3800, Loss function: 3.364, Average Loss: 3.815, avg. samples / sec: 65835.63
Iteration:   3800, Loss function: 3.818, Average Loss: 3.807, avg. samples / sec: 65888.79
Iteration:   3800, Loss function: 2.339, Average Loss: 3.814, avg. samples / sec: 65958.18
Iteration:   3800, Loss function: 3.768, Average Loss: 3.836, avg. samples / sec: 65764.88
Iteration:   3800, Loss function: 3.587, Average Loss: 3.806, avg. samples / sec: 65940.86
Iteration:   3800, Loss function: 2.564, Average Loss: 3.816, avg. samples / sec: 65791.68
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558651632.059 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=2.55s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22629
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23265
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05951
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23909
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21827
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31965
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10074
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52274
Current AP: 0.22629 AP goal: 0.23000
:::MLL 1558651635.811 eval_accuracy: {"value": 0.22629106308578978, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558651635.875 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558651635.882 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558651635.882 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 3.815, Average Loss: 3.821, avg. samples / sec: 7736.52
Iteration:   3820, Loss function: 5.072, Average Loss: 3.782, avg. samples / sec: 7736.23
Iteration:   3820, Loss function: 2.890, Average Loss: 3.803, avg. samples / sec: 7735.57
Iteration:   3820, Loss function: 3.887, Average Loss: 3.791, avg. samples / sec: 7735.19
Iteration:   3820, Loss function: 2.562, Average Loss: 3.808, avg. samples / sec: 7736.69
Iteration:   3820, Loss function: 2.065, Average Loss: 3.823, avg. samples / sec: 7736.76
Iteration:   3820, Loss function: 3.832, Average Loss: 3.807, avg. samples / sec: 7736.88
Iteration:   3820, Loss function: 4.242, Average Loss: 3.797, avg. samples / sec: 7735.42
Iteration:   3820, Loss function: 3.551, Average Loss: 3.804, avg. samples / sec: 7735.56
Iteration:   3820, Loss function: 4.539, Average Loss: 3.777, avg. samples / sec: 7734.72
Iteration:   3820, Loss function: 4.308, Average Loss: 3.806, avg. samples / sec: 7734.27
Iteration:   3820, Loss function: 3.214, Average Loss: 3.811, avg. samples / sec: 7734.07
Iteration:   3820, Loss function: 3.795, Average Loss: 3.775, avg. samples / sec: 7735.54
Iteration:   3820, Loss function: 2.557, Average Loss: 3.799, avg. samples / sec: 7736.31
Iteration:   3820, Loss function: 4.902, Average Loss: 3.805, avg. samples / sec: 7735.87
Iteration:   3820, Loss function: 2.391, Average Loss: 3.808, avg. samples / sec: 7738.21
Iteration:   3820, Loss function: 4.471, Average Loss: 3.810, avg. samples / sec: 7733.63
Iteration:   3820, Loss function: 3.873, Average Loss: 3.792, avg. samples / sec: 7734.18
Iteration:   3820, Loss function: 2.827, Average Loss: 3.785, avg. samples / sec: 7734.23
Iteration:   3820, Loss function: 2.510, Average Loss: 3.799, avg. samples / sec: 7735.64
Iteration:   3820, Loss function: 3.634, Average Loss: 3.799, avg. samples / sec: 7734.70
Iteration:   3820, Loss function: 4.106, Average Loss: 3.802, avg. samples / sec: 7734.45
Iteration:   3820, Loss function: 2.915, Average Loss: 3.792, avg. samples / sec: 7733.81
Iteration:   3820, Loss function: 3.916, Average Loss: 3.827, avg. samples / sec: 7733.51
Iteration:   3820, Loss function: 3.710, Average Loss: 3.812, avg. samples / sec: 7734.70
Iteration:   3820, Loss function: 2.643, Average Loss: 3.810, avg. samples / sec: 7733.53
Iteration:   3820, Loss function: 3.633, Average Loss: 3.827, avg. samples / sec: 7735.34
Iteration:   3820, Loss function: 2.132, Average Loss: 3.804, avg. samples / sec: 7734.58
Iteration:   3820, Loss function: 3.524, Average Loss: 3.800, avg. samples / sec: 7734.86
Iteration:   3820, Loss function: 3.282, Average Loss: 3.795, avg. samples / sec: 7732.90
:::MLL 1558651636.652 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558651636.652 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 4.450, Average Loss: 3.784, avg. samples / sec: 65724.12
Iteration:   3840, Loss function: 4.619, Average Loss: 3.767, avg. samples / sec: 65751.13
Iteration:   3840, Loss function: 3.960, Average Loss: 3.797, avg. samples / sec: 65666.79
Iteration:   3840, Loss function: 3.828, Average Loss: 3.775, avg. samples / sec: 65645.29
Iteration:   3840, Loss function: 3.853, Average Loss: 3.774, avg. samples / sec: 65691.09
Iteration:   3840, Loss function: 3.437, Average Loss: 3.799, avg. samples / sec: 65644.31
Iteration:   3840, Loss function: 2.442, Average Loss: 3.783, avg. samples / sec: 65715.54
Iteration:   3840, Loss function: 3.948, Average Loss: 3.797, avg. samples / sec: 65655.72
Iteration:   3840, Loss function: 3.344, Average Loss: 3.788, avg. samples / sec: 65717.32
Iteration:   3840, Loss function: 2.638, Average Loss: 3.795, avg. samples / sec: 65841.82
Iteration:   3840, Loss function: 3.344, Average Loss: 3.816, avg. samples / sec: 65730.19
Iteration:   3840, Loss function: 3.990, Average Loss: 3.787, avg. samples / sec: 65724.92
Iteration:   3840, Loss function: 4.297, Average Loss: 3.799, avg. samples / sec: 65735.31
Iteration:   3840, Loss function: 4.214, Average Loss: 3.795, avg. samples / sec: 65685.37
Iteration:   3840, Loss function: 3.324, Average Loss: 3.798, avg. samples / sec: 65598.51
Iteration:   3840, Loss function: 3.265, Average Loss: 3.812, avg. samples / sec: 65555.51
Iteration:   3840, Loss function: 3.090, Average Loss: 3.780, avg. samples / sec: 65635.38
Iteration:   3840, Loss function: 2.380, Average Loss: 3.812, avg. samples / sec: 65469.66
Iteration:   3840, Loss function: 3.397, Average Loss: 3.789, avg. samples / sec: 65758.41
Iteration:   3840, Loss function: 4.012, Average Loss: 3.795, avg. samples / sec: 65517.23
Iteration:   3840, Loss function: 5.844, Average Loss: 3.824, avg. samples / sec: 65692.75
Iteration:   3840, Loss function: 4.043, Average Loss: 3.789, avg. samples / sec: 65575.06
Iteration:   3840, Loss function: 4.039, Average Loss: 3.794, avg. samples / sec: 65523.26
Iteration:   3840, Loss function: 4.174, Average Loss: 3.775, avg. samples / sec: 65563.81
Iteration:   3840, Loss function: 3.244, Average Loss: 3.799, avg. samples / sec: 65557.95
Iteration:   3840, Loss function: 2.379, Average Loss: 3.795, avg. samples / sec: 65547.00
Iteration:   3840, Loss function: 3.254, Average Loss: 3.802, avg. samples / sec: 65509.07
Iteration:   3840, Loss function: 2.826, Average Loss: 3.804, avg. samples / sec: 65563.38
Iteration:   3840, Loss function: 3.601, Average Loss: 3.790, avg. samples / sec: 65665.60
Iteration:   3840, Loss function: 3.070, Average Loss: 3.798, avg. samples / sec: 65474.95
Iteration:   3860, Loss function: 3.428, Average Loss: 3.772, avg. samples / sec: 65405.58
Iteration:   3860, Loss function: 2.409, Average Loss: 3.785, avg. samples / sec: 65420.18
Iteration:   3860, Loss function: 3.436, Average Loss: 3.789, avg. samples / sec: 65275.64
Iteration:   3860, Loss function: 2.891, Average Loss: 3.798, avg. samples / sec: 65442.39
Iteration:   3860, Loss function: 4.438, Average Loss: 3.791, avg. samples / sec: 65261.56
Iteration:   3860, Loss function: 4.870, Average Loss: 3.792, avg. samples / sec: 65413.87
Iteration:   3860, Loss function: 3.289, Average Loss: 3.764, avg. samples / sec: 65208.77
Iteration:   3860, Loss function: 3.075, Average Loss: 3.779, avg. samples / sec: 65244.37
Iteration:   3860, Loss function: 2.689, Average Loss: 3.800, avg. samples / sec: 65321.91
Iteration:   3860, Loss function: 3.193, Average Loss: 3.793, avg. samples / sec: 65192.91
Iteration:   3860, Loss function: 3.800, Average Loss: 3.778, avg. samples / sec: 65114.35
Iteration:   3860, Loss function: 3.883, Average Loss: 3.760, avg. samples / sec: 65125.48
Iteration:   3860, Loss function: 3.252, Average Loss: 3.783, avg. samples / sec: 65252.34
Iteration:   3860, Loss function: 4.280, Average Loss: 3.789, avg. samples / sec: 65266.15
Iteration:   3860, Loss function: 4.167, Average Loss: 3.775, avg. samples / sec: 65158.67
Iteration:   3860, Loss function: 2.564, Average Loss: 3.804, avg. samples / sec: 65210.73
Iteration:   3860, Loss function: 2.925, Average Loss: 3.784, avg. samples / sec: 65319.60
Iteration:   3860, Loss function: 3.509, Average Loss: 3.793, avg. samples / sec: 65239.47
Iteration:   3860, Loss function: 3.081, Average Loss: 3.816, avg. samples / sec: 65295.67
Iteration:   3860, Loss function: 4.425, Average Loss: 3.807, avg. samples / sec: 65243.88
Iteration:   3860, Loss function: 4.609, Average Loss: 3.789, avg. samples / sec: 65288.31
Iteration:   3860, Loss function: 1.838, Average Loss: 3.787, avg. samples / sec: 65269.60
Iteration:   3860, Loss function: 2.469, Average Loss: 3.786, avg. samples / sec: 65345.71
Iteration:   3860, Loss function: 4.425, Average Loss: 3.785, avg. samples / sec: 65151.38
Iteration:   3860, Loss function: 3.529, Average Loss: 3.780, avg. samples / sec: 65123.77
Iteration:   3860, Loss function: 3.557, Average Loss: 3.789, avg. samples / sec: 65142.79
Iteration:   3860, Loss function: 2.929, Average Loss: 3.785, avg. samples / sec: 65299.08
Iteration:   3860, Loss function: 3.689, Average Loss: 3.798, avg. samples / sec: 65229.45
Iteration:   3860, Loss function: 3.289, Average Loss: 3.786, avg. samples / sec: 65169.90
Iteration:   3860, Loss function: 2.915, Average Loss: 3.766, avg. samples / sec: 65142.40
Iteration:   3880, Loss function: 3.468, Average Loss: 3.764, avg. samples / sec: 66092.74
Iteration:   3880, Loss function: 3.642, Average Loss: 3.784, avg. samples / sec: 66160.38
Iteration:   3880, Loss function: 4.045, Average Loss: 3.794, avg. samples / sec: 66080.06
Iteration:   3880, Loss function: 2.859, Average Loss: 3.798, avg. samples / sec: 66138.36
Iteration:   3880, Loss function: 3.189, Average Loss: 3.775, avg. samples / sec: 66019.33
Iteration:   3880, Loss function: 3.714, Average Loss: 3.773, avg. samples / sec: 66083.84
Iteration:   3880, Loss function: 2.866, Average Loss: 3.776, avg. samples / sec: 66070.49
Iteration:   3880, Loss function: 4.584, Average Loss: 3.784, avg. samples / sec: 65972.57
Iteration:   3880, Loss function: 5.257, Average Loss: 3.766, avg. samples / sec: 66082.20
Iteration:   3880, Loss function: 2.439, Average Loss: 3.784, avg. samples / sec: 66049.59
Iteration:   3880, Loss function: 2.845, Average Loss: 3.792, avg. samples / sec: 66066.09
Iteration:   3880, Loss function: 2.938, Average Loss: 3.751, avg. samples / sec: 66052.43
Iteration:   3880, Loss function: 3.762, Average Loss: 3.785, avg. samples / sec: 66001.58
Iteration:   3880, Loss function: 2.920, Average Loss: 3.777, avg. samples / sec: 66232.76
Iteration:   3880, Loss function: 2.170, Average Loss: 3.783, avg. samples / sec: 66072.25
Iteration:   3880, Loss function: 3.628, Average Loss: 3.760, avg. samples / sec: 65981.24
Iteration:   3880, Loss function: 4.247, Average Loss: 3.803, avg. samples / sec: 66029.90
Iteration:   3880, Loss function: 2.298, Average Loss: 3.756, avg. samples / sec: 66196.52
Iteration:   3880, Loss function: 3.361, Average Loss: 3.776, avg. samples / sec: 66017.13
Iteration:   3880, Loss function: 2.359, Average Loss: 3.788, avg. samples / sec: 66128.68
Iteration:   3880, Loss function: 2.905, Average Loss: 3.768, avg. samples / sec: 66049.96
Iteration:   3880, Loss function: 3.568, Average Loss: 3.784, avg. samples / sec: 65913.97
Iteration:   3880, Loss function: 3.132, Average Loss: 3.777, avg. samples / sec: 66097.73
Iteration:   3880, Loss function: 2.267, Average Loss: 3.774, avg. samples / sec: 66013.82
Iteration:   3880, Loss function: 3.087, Average Loss: 3.780, avg. samples / sec: 65869.45
Iteration:   3880, Loss function: 3.569, Average Loss: 3.773, avg. samples / sec: 65900.56
Iteration:   3880, Loss function: 2.652, Average Loss: 3.778, avg. samples / sec: 65970.99
Iteration:   3880, Loss function: 3.941, Average Loss: 3.780, avg. samples / sec: 66014.07
Iteration:   3880, Loss function: 2.659, Average Loss: 3.788, avg. samples / sec: 65821.00
Iteration:   3880, Loss function: 3.625, Average Loss: 3.767, avg. samples / sec: 65834.40
Iteration:   3900, Loss function: 3.662, Average Loss: 3.756, avg. samples / sec: 65915.45
Iteration:   3900, Loss function: 4.748, Average Loss: 3.768, avg. samples / sec: 65991.59
Iteration:   3900, Loss function: 2.050, Average Loss: 3.783, avg. samples / sec: 65927.01
Iteration:   3900, Loss function: 2.752, Average Loss: 3.758, avg. samples / sec: 66146.40
Iteration:   3900, Loss function: 2.695, Average Loss: 3.782, avg. samples / sec: 65948.15
Iteration:   3900, Loss function: 3.948, Average Loss: 3.772, avg. samples / sec: 65962.50
Iteration:   3900, Loss function: 3.131, Average Loss: 3.776, avg. samples / sec: 65950.83
Iteration:   3900, Loss function: 3.199, Average Loss: 3.766, avg. samples / sec: 65902.72
Iteration:   3900, Loss function: 2.318, Average Loss: 3.772, avg. samples / sec: 66037.92
Iteration:   3900, Loss function: 3.701, Average Loss: 3.778, avg. samples / sec: 65948.08
Iteration:   3900, Loss function: 3.112, Average Loss: 3.771, avg. samples / sec: 66012.46
Iteration:   3900, Loss function: 4.003, Average Loss: 3.770, avg. samples / sec: 65993.23
Iteration:   3900, Loss function: 3.220, Average Loss: 3.757, avg. samples / sec: 65912.83
Iteration:   3900, Loss function: 2.210, Average Loss: 3.757, avg. samples / sec: 65858.77
Iteration:   3900, Loss function: 2.915, Average Loss: 3.763, avg. samples / sec: 65897.66
Iteration:   3900, Loss function: 2.857, Average Loss: 3.745, avg. samples / sec: 65863.14
Iteration:   3900, Loss function: 3.260, Average Loss: 3.772, avg. samples / sec: 66015.15
Iteration:   3900, Loss function: 3.404, Average Loss: 3.768, avg. samples / sec: 65925.93
Iteration:   3900, Loss function: 3.421, Average Loss: 3.777, avg. samples / sec: 65953.08
Iteration:   3900, Loss function: 4.131, Average Loss: 3.787, avg. samples / sec: 65783.05
Iteration:   3900, Loss function: 2.381, Average Loss: 3.763, avg. samples / sec: 65976.95
Iteration:   3900, Loss function: 3.396, Average Loss: 3.779, avg. samples / sec: 66001.76
Iteration:   3900, Loss function: 3.501, Average Loss: 3.796, avg. samples / sec: 65874.16
Iteration:   3900, Loss function: 3.723, Average Loss: 3.780, avg. samples / sec: 65726.82
Iteration:   3900, Loss function: 3.265, Average Loss: 3.772, avg. samples / sec: 65945.12
Iteration:   3900, Loss function: 2.034, Average Loss: 3.770, avg. samples / sec: 65811.90
Iteration:   3900, Loss function: 2.282, Average Loss: 3.762, avg. samples / sec: 65842.34
Iteration:   3900, Loss function: 2.864, Average Loss: 3.767, avg. samples / sec: 65726.54
Iteration:   3900, Loss function: 3.146, Average Loss: 3.753, avg. samples / sec: 65778.75
Iteration:   3900, Loss function: 3.590, Average Loss: 3.783, avg. samples / sec: 65764.70
:::MLL 1558651638.442 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558651638.443 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 4.191, Average Loss: 3.749, avg. samples / sec: 65529.57
Iteration:   3920, Loss function: 2.466, Average Loss: 3.761, avg. samples / sec: 65627.28
Iteration:   3920, Loss function: 4.797, Average Loss: 3.754, avg. samples / sec: 65613.23
Iteration:   3920, Loss function: 2.596, Average Loss: 3.735, avg. samples / sec: 65521.10
Iteration:   3920, Loss function: 4.079, Average Loss: 3.759, avg. samples / sec: 65519.27
Iteration:   3920, Loss function: 3.816, Average Loss: 3.762, avg. samples / sec: 65497.44
Iteration:   3920, Loss function: 2.987, Average Loss: 3.759, avg. samples / sec: 65428.53
Iteration:   3920, Loss function: 2.738, Average Loss: 3.751, avg. samples / sec: 65408.31
Iteration:   3920, Loss function: 3.289, Average Loss: 3.770, avg. samples / sec: 65362.08
Iteration:   3920, Loss function: 2.203, Average Loss: 3.759, avg. samples / sec: 65445.91
Iteration:   3920, Loss function: 2.542, Average Loss: 3.750, avg. samples / sec: 65451.60
Iteration:   3920, Loss function: 4.055, Average Loss: 3.779, avg. samples / sec: 65505.32
Iteration:   3920, Loss function: 4.048, Average Loss: 3.772, avg. samples / sec: 65499.69
Iteration:   3920, Loss function: 4.453, Average Loss: 3.756, avg. samples / sec: 65489.47
Iteration:   3920, Loss function: 3.572, Average Loss: 3.765, avg. samples / sec: 65310.13
Iteration:   3920, Loss function: 2.753, Average Loss: 3.761, avg. samples / sec: 65371.17
Iteration:   3920, Loss function: 3.063, Average Loss: 3.774, avg. samples / sec: 65434.85
Iteration:   3920, Loss function: 3.503, Average Loss: 3.770, avg. samples / sec: 65368.78
Iteration:   3920, Loss function: 2.170, Average Loss: 3.755, avg. samples / sec: 65488.52
Iteration:   3920, Loss function: 3.176, Average Loss: 3.752, avg. samples / sec: 65409.89
Iteration:   3920, Loss function: 2.913, Average Loss: 3.761, avg. samples / sec: 65365.69
Iteration:   3920, Loss function: 3.097, Average Loss: 3.769, avg. samples / sec: 65481.40
Iteration:   3920, Loss function: 3.008, Average Loss: 3.769, avg. samples / sec: 65326.63
Iteration:   3920, Loss function: 2.972, Average Loss: 3.785, avg. samples / sec: 65444.00
Iteration:   3920, Loss function: 4.052, Average Loss: 3.770, avg. samples / sec: 65310.52
Iteration:   3920, Loss function: 2.361, Average Loss: 3.750, avg. samples / sec: 65554.93
Iteration:   3920, Loss function: 3.545, Average Loss: 3.779, avg. samples / sec: 65542.13
Iteration:   3920, Loss function: 2.802, Average Loss: 3.761, avg. samples / sec: 65275.19
Iteration:   3920, Loss function: 3.970, Average Loss: 3.766, avg. samples / sec: 65357.05
Iteration:   3920, Loss function: 3.334, Average Loss: 3.757, avg. samples / sec: 65299.99
Iteration:   3940, Loss function: 2.189, Average Loss: 3.757, avg. samples / sec: 66209.55
Iteration:   3940, Loss function: 2.833, Average Loss: 3.758, avg. samples / sec: 66118.32
Iteration:   3940, Loss function: 4.167, Average Loss: 3.759, avg. samples / sec: 66128.49
Iteration:   3940, Loss function: 2.721, Average Loss: 3.744, avg. samples / sec: 66093.45
Iteration:   3940, Loss function: 2.846, Average Loss: 3.740, avg. samples / sec: 65856.31
Iteration:   3940, Loss function: 3.624, Average Loss: 3.763, avg. samples / sec: 66113.91
Iteration:   3940, Loss function: 2.560, Average Loss: 3.752, avg. samples / sec: 66130.76
Iteration:   3940, Loss function: 2.277, Average Loss: 3.730, avg. samples / sec: 65999.69
Iteration:   3940, Loss function: 2.019, Average Loss: 3.741, avg. samples / sec: 66101.04
Iteration:   3940, Loss function: 3.256, Average Loss: 3.747, avg. samples / sec: 66088.02
Iteration:   3940, Loss function: 3.123, Average Loss: 3.749, avg. samples / sec: 66038.78
Iteration:   3940, Loss function: 4.826, Average Loss: 3.763, avg. samples / sec: 66111.31
Iteration:   3940, Loss function: 4.304, Average Loss: 3.755, avg. samples / sec: 66024.89
Iteration:   3940, Loss function: 3.680, Average Loss: 3.751, avg. samples / sec: 66163.95
Iteration:   3940, Loss function: 4.290, Average Loss: 3.761, avg. samples / sec: 66036.43
Iteration:   3940, Loss function: 3.513, Average Loss: 3.756, avg. samples / sec: 66142.86
Iteration:   3940, Loss function: 2.903, Average Loss: 3.761, avg. samples / sec: 66007.73
Iteration:   3940, Loss function: 3.506, Average Loss: 3.752, avg. samples / sec: 65978.90
Iteration:   3940, Loss function: 3.925, Average Loss: 3.756, avg. samples / sec: 66144.63
Iteration:   3940, Loss function: 2.631, Average Loss: 3.765, avg. samples / sec: 65984.40
Iteration:   3940, Loss function: 2.827, Average Loss: 3.743, avg. samples / sec: 66047.88
Iteration:   3940, Loss function: 3.362, Average Loss: 3.739, avg. samples / sec: 65935.71
Iteration:   3940, Loss function: 2.584, Average Loss: 3.771, avg. samples / sec: 66063.27
Iteration:   3940, Loss function: 2.392, Average Loss: 3.751, avg. samples / sec: 65882.85
Iteration:   3940, Loss function: 3.035, Average Loss: 3.777, avg. samples / sec: 66003.59
Iteration:   3940, Loss function: 2.689, Average Loss: 3.748, avg. samples / sec: 65865.39
Iteration:   3940, Loss function: 2.928, Average Loss: 3.746, avg. samples / sec: 65867.60
Iteration:   3940, Loss function: 3.247, Average Loss: 3.750, avg. samples / sec: 65844.89
Iteration:   3940, Loss function: 3.620, Average Loss: 3.753, avg. samples / sec: 65875.55
Iteration:   3940, Loss function: 3.495, Average Loss: 3.768, avg. samples / sec: 65851.63
Iteration:   3960, Loss function: 3.806, Average Loss: 3.735, avg. samples / sec: 65948.18
Iteration:   3960, Loss function: 3.147, Average Loss: 3.748, avg. samples / sec: 65960.95
Iteration:   3960, Loss function: 3.237, Average Loss: 3.736, avg. samples / sec: 65828.81
Iteration:   3960, Loss function: 3.184, Average Loss: 3.745, avg. samples / sec: 65945.86
Iteration:   3960, Loss function: 3.249, Average Loss: 3.751, avg. samples / sec: 65798.16
Iteration:   3960, Loss function: 5.794, Average Loss: 3.753, avg. samples / sec: 65899.05
Iteration:   3960, Loss function: 2.647, Average Loss: 3.731, avg. samples / sec: 65974.17
Iteration:   3960, Loss function: 2.862, Average Loss: 3.752, avg. samples / sec: 65780.93
Iteration:   3960, Loss function: 4.174, Average Loss: 3.754, avg. samples / sec: 65927.01
Iteration:   3960, Loss function: 2.991, Average Loss: 3.736, avg. samples / sec: 66001.27
Iteration:   3960, Loss function: 3.127, Average Loss: 3.738, avg. samples / sec: 65855.75
Iteration:   3960, Loss function: 5.169, Average Loss: 3.742, avg. samples / sec: 65997.16
Iteration:   3960, Loss function: 3.386, Average Loss: 3.752, avg. samples / sec: 65877.86
Iteration:   3960, Loss function: 3.988, Average Loss: 3.760, avg. samples / sec: 66023.35
Iteration:   3960, Loss function: 2.856, Average Loss: 3.724, avg. samples / sec: 65846.74
Iteration:   3960, Loss function: 3.084, Average Loss: 3.744, avg. samples / sec: 65934.20
Iteration:   3960, Loss function: 3.380, Average Loss: 3.738, avg. samples / sec: 65931.05
Iteration:   3960, Loss function: 3.656, Average Loss: 3.755, avg. samples / sec: 65853.20
Iteration:   3960, Loss function: 2.745, Average Loss: 3.736, avg. samples / sec: 65885.93
Iteration:   3960, Loss function: 2.366, Average Loss: 3.742, avg. samples / sec: 65775.07
Iteration:   3960, Loss function: 3.223, Average Loss: 3.733, avg. samples / sec: 65741.26
Iteration:   3960, Loss function: 3.021, Average Loss: 3.748, avg. samples / sec: 65767.06
Iteration:   3960, Loss function: 3.621, Average Loss: 3.744, avg. samples / sec: 65933.74
Iteration:   3960, Loss function: 3.131, Average Loss: 3.734, avg. samples / sec: 65784.04
Iteration:   3960, Loss function: 3.572, Average Loss: 3.751, avg. samples / sec: 65682.12
Iteration:   3960, Loss function: 4.460, Average Loss: 3.746, avg. samples / sec: 65804.99
Iteration:   3960, Loss function: 3.346, Average Loss: 3.756, avg. samples / sec: 65825.58
Iteration:   3960, Loss function: 3.710, Average Loss: 3.757, avg. samples / sec: 65807.14
Iteration:   3960, Loss function: 4.035, Average Loss: 3.769, avg. samples / sec: 65805.81
Iteration:   3960, Loss function: 2.578, Average Loss: 3.746, avg. samples / sec: 65634.40
:::MLL 1558651640.233 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558651640.234 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.200, Average Loss: 3.710, avg. samples / sec: 65367.99
Iteration:   3980, Loss function: 3.735, Average Loss: 3.738, avg. samples / sec: 65289.59
Iteration:   3980, Loss function: 3.195, Average Loss: 3.722, avg. samples / sec: 65309.65
Iteration:   3980, Loss function: 3.739, Average Loss: 3.740, avg. samples / sec: 65274.16
Iteration:   3980, Loss function: 4.718, Average Loss: 3.736, avg. samples / sec: 65356.56
Iteration:   3980, Loss function: 3.313, Average Loss: 3.728, avg. samples / sec: 65298.51
Iteration:   3980, Loss function: 2.723, Average Loss: 3.738, avg. samples / sec: 65352.50
Iteration:   3980, Loss function: 2.963, Average Loss: 3.728, avg. samples / sec: 65364.90
Iteration:   3980, Loss function: 3.658, Average Loss: 3.736, avg. samples / sec: 65309.31
Iteration:   3980, Loss function: 3.804, Average Loss: 3.729, avg. samples / sec: 65280.30
Iteration:   3980, Loss function: 3.454, Average Loss: 3.743, avg. samples / sec: 65282.96
Iteration:   3980, Loss function: 4.205, Average Loss: 3.738, avg. samples / sec: 65309.40
Iteration:   3980, Loss function: 3.785, Average Loss: 3.757, avg. samples / sec: 65255.85
Iteration:   3980, Loss function: 2.462, Average Loss: 3.726, avg. samples / sec: 65140.08
Iteration:   3980, Loss function: 2.716, Average Loss: 3.726, avg. samples / sec: 65296.15
Iteration:   3980, Loss function: 3.881, Average Loss: 3.752, avg. samples / sec: 65342.32
Iteration:   3980, Loss function: 3.352, Average Loss: 3.749, avg. samples / sec: 65211.61
Iteration:   3980, Loss function: 3.197, Average Loss: 3.747, avg. samples / sec: 65340.26
Iteration:   3980, Loss function: 2.744, Average Loss: 3.732, avg. samples / sec: 65227.49
Iteration:   3980, Loss function: 3.764, Average Loss: 3.747, avg. samples / sec: 65224.07
Iteration:   3980, Loss function: 4.926, Average Loss: 3.750, avg. samples / sec: 65139.27
Iteration:   3980, Loss function: 2.421, Average Loss: 3.735, avg. samples / sec: 65258.23
Iteration:   3980, Loss function: 3.861, Average Loss: 3.738, avg. samples / sec: 65417.81
Iteration:   3980, Loss function: 3.334, Average Loss: 3.745, avg. samples / sec: 65127.35
Iteration:   3980, Loss function: 3.013, Average Loss: 3.740, avg. samples / sec: 65091.58
Iteration:   3980, Loss function: 3.048, Average Loss: 3.741, avg. samples / sec: 65187.54
Iteration:   3980, Loss function: 3.191, Average Loss: 3.763, avg. samples / sec: 65233.31
Iteration:   3980, Loss function: 3.016, Average Loss: 3.742, avg. samples / sec: 65193.57
Iteration:   3980, Loss function: 3.516, Average Loss: 3.730, avg. samples / sec: 65096.48
Iteration:   3980, Loss function: 3.411, Average Loss: 3.729, avg. samples / sec: 65053.30
Iteration:   4000, Loss function: 3.637, Average Loss: 3.719, avg. samples / sec: 65813.84
Iteration:   4000, Loss function: 5.012, Average Loss: 3.752, avg. samples / sec: 65764.21
Iteration:   4000, Loss function: 3.127, Average Loss: 3.722, avg. samples / sec: 65651.56
Iteration:   4000, Loss function: 4.084, Average Loss: 3.723, avg. samples / sec: 65696.70
Iteration:   4000, Loss function: 4.541, Average Loss: 3.744, avg. samples / sec: 65788.21
Iteration:   4000, Loss function: 3.836, Average Loss: 3.750, avg. samples / sec: 65720.53
Iteration:   4000, Loss function: 2.846, Average Loss: 3.729, avg. samples / sec: 65789.56
Iteration:   4000, Loss function: 2.949, Average Loss: 3.737, avg. samples / sec: 65759.05
Iteration:   4000, Loss function: 3.266, Average Loss: 3.730, avg. samples / sec: 65642.02
Iteration:   4000, Loss function: 2.860, Average Loss: 3.703, avg. samples / sec: 65538.29
Iteration:   4000, Loss function: 3.840, Average Loss: 3.735, avg. samples / sec: 65827.79
Iteration:   4000, Loss function: 3.399, Average Loss: 3.739, avg. samples / sec: 65684.82
Iteration:   4000, Loss function: 3.300, Average Loss: 3.727, avg. samples / sec: 65553.83
Iteration:   4000, Loss function: 3.327, Average Loss: 3.735, avg. samples / sec: 65643.12
Iteration:   4000, Loss function: 2.773, Average Loss: 3.741, avg. samples / sec: 65675.82
Iteration:   4000, Loss function: 1.934, Average Loss: 3.729, avg. samples / sec: 65768.90
Iteration:   4000, Loss function: 3.117, Average Loss: 3.758, avg. samples / sec: 65821.15
Iteration:   4000, Loss function: 3.435, Average Loss: 3.729, avg. samples / sec: 65704.45
Iteration:   4000, Loss function: 2.433, Average Loss: 3.731, avg. samples / sec: 65544.93
Iteration:   4000, Loss function: 2.663, Average Loss: 3.713, avg. samples / sec: 65518.79
Iteration:   4000, Loss function: 3.483, Average Loss: 3.739, avg. samples / sec: 65709.04
Iteration:   4000, Loss function: 2.916, Average Loss: 3.716, avg. samples / sec: 65600.46
Iteration:   4000, Loss function: 3.333, Average Loss: 3.721, avg. samples / sec: 65627.22
Iteration:   4000, Loss function: 3.588, Average Loss: 3.731, avg. samples / sec: 65499.42
Iteration:   4000, Loss function: 3.166, Average Loss: 3.726, avg. samples / sec: 65504.96
Iteration:   4000, Loss function: 3.276, Average Loss: 3.718, avg. samples / sec: 65541.33
Iteration:   4000, Loss function: 3.434, Average Loss: 3.736, avg. samples / sec: 65525.03
Iteration:   4000, Loss function: 3.036, Average Loss: 3.721, avg. samples / sec: 65735.98
Iteration:   4000, Loss function: 3.547, Average Loss: 3.734, avg. samples / sec: 65686.10
Iteration:   4000, Loss function: 4.003, Average Loss: 3.722, avg. samples / sec: 65679.40
Iteration:   4020, Loss function: 4.201, Average Loss: 3.713, avg. samples / sec: 66092.86
Iteration:   4020, Loss function: 3.565, Average Loss: 3.730, avg. samples / sec: 66125.86
Iteration:   4020, Loss function: 3.368, Average Loss: 3.699, avg. samples / sec: 66108.64
Iteration:   4020, Loss function: 2.910, Average Loss: 3.723, avg. samples / sec: 66120.15
Iteration:   4020, Loss function: 2.560, Average Loss: 3.748, avg. samples / sec: 66111.40
Iteration:   4020, Loss function: 4.530, Average Loss: 3.744, avg. samples / sec: 66040.55
Iteration:   4020, Loss function: 4.021, Average Loss: 3.735, avg. samples / sec: 66021.40
Iteration:   4020, Loss function: 3.647, Average Loss: 3.710, avg. samples / sec: 66139.36
Iteration:   4020, Loss function: 3.983, Average Loss: 3.740, avg. samples / sec: 66085.24
Iteration:   4020, Loss function: 3.681, Average Loss: 3.733, avg. samples / sec: 66077.43
Iteration:   4020, Loss function: 3.116, Average Loss: 3.712, avg. samples / sec: 66192.23
Iteration:   4020, Loss function: 3.530, Average Loss: 3.729, avg. samples / sec: 66093.39
Iteration:   4020, Loss function: 4.419, Average Loss: 3.741, avg. samples / sec: 65953.82
Iteration:   4020, Loss function: 3.265, Average Loss: 3.727, avg. samples / sec: 66153.73
Iteration:   4020, Loss function: 4.310, Average Loss: 3.720, avg. samples / sec: 66076.56
Iteration:   4020, Loss function: 3.420, Average Loss: 3.708, avg. samples / sec: 66137.71
Iteration:   4020, Loss function: 3.143, Average Loss: 3.724, avg. samples / sec: 66131.29
Iteration:   4020, Loss function: 3.293, Average Loss: 3.728, avg. samples / sec: 66172.93
Iteration:   4020, Loss function: 3.823, Average Loss: 3.726, avg. samples / sec: 66025.42
Iteration:   4020, Loss function: 3.034, Average Loss: 3.732, avg. samples / sec: 66021.40
Iteration:   4020, Loss function: 2.242, Average Loss: 3.720, avg. samples / sec: 65999.66
Iteration:   4020, Loss function: 3.667, Average Loss: 3.712, avg. samples / sec: 65950.09
Iteration:   4020, Loss function: 2.912, Average Loss: 3.721, avg. samples / sec: 66106.59
Iteration:   4020, Loss function: 3.516, Average Loss: 3.721, avg. samples / sec: 66013.36
Iteration:   4020, Loss function: 3.457, Average Loss: 3.718, avg. samples / sec: 66198.32
Iteration:   4020, Loss function: 2.297, Average Loss: 3.714, avg. samples / sec: 65839.72
Iteration:   4020, Loss function: 3.178, Average Loss: 3.726, avg. samples / sec: 65985.60
Iteration:   4020, Loss function: 3.632, Average Loss: 3.709, avg. samples / sec: 66073.24
Iteration:   4020, Loss function: 2.239, Average Loss: 3.705, avg. samples / sec: 65985.51
Iteration:   4020, Loss function: 4.529, Average Loss: 3.728, avg. samples / sec: 65879.46
Iteration:   4040, Loss function: 4.112, Average Loss: 3.708, avg. samples / sec: 65268.51
Iteration:   4040, Loss function: 3.295, Average Loss: 3.716, avg. samples / sec: 65198.34
Iteration:   4040, Loss function: 2.994, Average Loss: 3.697, avg. samples / sec: 65100.60
Iteration:   4040, Loss function: 3.435, Average Loss: 3.717, avg. samples / sec: 65069.58
Iteration:   4040, Loss function: 2.988, Average Loss: 3.733, avg. samples / sec: 65134.66
Iteration:   4040, Loss function: 4.292, Average Loss: 3.713, avg. samples / sec: 65153.12
Iteration:   4040, Loss function: 3.269, Average Loss: 3.713, avg. samples / sec: 65117.96
Iteration:   4040, Loss function: 4.287, Average Loss: 3.717, avg. samples / sec: 65124.31
Iteration:   4040, Loss function: 3.906, Average Loss: 3.725, avg. samples / sec: 65138.13
Iteration:   4040, Loss function: 2.939, Average Loss: 3.705, avg. samples / sec: 65139.15
Iteration:   4040, Loss function: 3.269, Average Loss: 3.698, avg. samples / sec: 65209.86
Iteration:   4040, Loss function: 3.298, Average Loss: 3.702, avg. samples / sec: 65141.86
Iteration:   4040, Loss function: 3.027, Average Loss: 3.723, avg. samples / sec: 65073.76
Iteration:   4040, Loss function: 3.075, Average Loss: 3.720, avg. samples / sec: 65128.01
Iteration:   4040, Loss function: 2.367, Average Loss: 3.720, avg. samples / sec: 64970.38
Iteration:   4040, Loss function: 3.315, Average Loss: 3.727, avg. samples / sec: 65045.56
Iteration:   4040, Loss function: 4.964, Average Loss: 3.719, avg. samples / sec: 65072.83
Iteration:   4040, Loss function: 2.990, Average Loss: 3.707, avg. samples / sec: 65085.27
Iteration:   4040, Loss function: 2.834, Average Loss: 3.707, avg. samples / sec: 64904.19
Iteration:   4040, Loss function: 4.096, Average Loss: 3.726, avg. samples / sec: 65030.25
Iteration:   4040, Loss function: 3.002, Average Loss: 3.726, avg. samples / sec: 65000.92
Iteration:   4040, Loss function: 3.346, Average Loss: 3.714, avg. samples / sec: 65049.91
Iteration:   4040, Loss function: 3.131, Average Loss: 3.696, avg. samples / sec: 65015.76
Iteration:   4040, Loss function: 2.993, Average Loss: 3.709, avg. samples / sec: 64969.57
Iteration:   4040, Loss function: 3.801, Average Loss: 3.741, avg. samples / sec: 64975.95
Iteration:   4040, Loss function: 3.046, Average Loss: 3.723, avg. samples / sec: 65021.22
Iteration:   4040, Loss function: 3.818, Average Loss: 3.724, avg. samples / sec: 65200.72
Iteration:   4040, Loss function: 2.136, Average Loss: 3.699, avg. samples / sec: 64953.46
Iteration:   4040, Loss function: 3.255, Average Loss: 3.738, avg. samples / sec: 64906.14
Iteration:   4040, Loss function: 3.089, Average Loss: 3.714, avg. samples / sec: 64969.72
:::MLL 1558651642.029 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558651642.029 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 2.821, Average Loss: 3.690, avg. samples / sec: 65278.88
Iteration:   4060, Loss function: 1.445, Average Loss: 3.735, avg. samples / sec: 65384.00
Iteration:   4060, Loss function: 3.265, Average Loss: 3.701, avg. samples / sec: 65379.94
Iteration:   4060, Loss function: 4.151, Average Loss: 3.727, avg. samples / sec: 65255.12
Iteration:   4060, Loss function: 4.073, Average Loss: 3.717, avg. samples / sec: 65301.26
Iteration:   4060, Loss function: 2.987, Average Loss: 3.693, avg. samples / sec: 65252.40
Iteration:   4060, Loss function: 3.698, Average Loss: 3.714, avg. samples / sec: 65314.73
Iteration:   4060, Loss function: 3.874, Average Loss: 3.700, avg. samples / sec: 65154.96
Iteration:   4060, Loss function: 2.277, Average Loss: 3.716, avg. samples / sec: 65262.40
Iteration:   4060, Loss function: 3.910, Average Loss: 3.728, avg. samples / sec: 65321.97
Iteration:   4060, Loss function: 3.264, Average Loss: 3.687, avg. samples / sec: 65354.89
Iteration:   4060, Loss function: 3.572, Average Loss: 3.705, avg. samples / sec: 65166.11
Iteration:   4060, Loss function: 2.826, Average Loss: 3.696, avg. samples / sec: 65305.47
Iteration:   4060, Loss function: 3.342, Average Loss: 3.716, avg. samples / sec: 65349.98
Iteration:   4060, Loss function: 3.465, Average Loss: 3.712, avg. samples / sec: 65245.54
Iteration:   4060, Loss function: 3.835, Average Loss: 3.708, avg. samples / sec: 65220.87
Iteration:   4060, Loss function: 3.410, Average Loss: 3.706, avg. samples / sec: 65395.99
Iteration:   4060, Loss function: 3.230, Average Loss: 3.704, avg. samples / sec: 65328.81
Iteration:   4060, Loss function: 5.195, Average Loss: 3.713, avg. samples / sec: 65247.93
Iteration:   4060, Loss function: 3.246, Average Loss: 3.708, avg. samples / sec: 65198.88
Iteration:   4060, Loss function: 2.948, Average Loss: 3.723, avg. samples / sec: 65278.91
Iteration:   4060, Loss function: 2.295, Average Loss: 3.720, avg. samples / sec: 65335.56
Iteration:   4060, Loss function: 4.242, Average Loss: 3.733, avg. samples / sec: 65329.99
Iteration:   4060, Loss function: 4.781, Average Loss: 3.712, avg. samples / sec: 65255.33
Iteration:   4060, Loss function: 2.359, Average Loss: 3.704, avg. samples / sec: 65169.42
Iteration:   4060, Loss function: 3.070, Average Loss: 3.693, avg. samples / sec: 65319.48
Iteration:   4060, Loss function: 3.038, Average Loss: 3.688, avg. samples / sec: 65146.29
Iteration:   4060, Loss function: 3.432, Average Loss: 3.710, avg. samples / sec: 65125.27
Iteration:   4060, Loss function: 3.147, Average Loss: 3.714, avg. samples / sec: 65162.85
Iteration:   4060, Loss function: 3.397, Average Loss: 3.697, avg. samples / sec: 65104.03
Iteration:   4080, Loss function: 4.449, Average Loss: 3.701, avg. samples / sec: 66277.06
Iteration:   4080, Loss function: 4.429, Average Loss: 3.711, avg. samples / sec: 66125.24
Iteration:   4080, Loss function: 3.787, Average Loss: 3.694, avg. samples / sec: 66303.62
Iteration:   4080, Loss function: 3.358, Average Loss: 3.687, avg. samples / sec: 66034.70
Iteration:   4080, Loss function: 2.557, Average Loss: 3.697, avg. samples / sec: 66049.28
Iteration:   4080, Loss function: 2.418, Average Loss: 3.694, avg. samples / sec: 66091.06
Iteration:   4080, Loss function: 3.465, Average Loss: 3.705, avg. samples / sec: 66169.11
Iteration:   4080, Loss function: 2.725, Average Loss: 3.680, avg. samples / sec: 66077.98
Iteration:   4080, Loss function: 2.124, Average Loss: 3.695, avg. samples / sec: 66080.80
Iteration:   4080, Loss function: 4.059, Average Loss: 3.704, avg. samples / sec: 66068.82
Iteration:   4080, Loss function: 3.681, Average Loss: 3.702, avg. samples / sec: 66108.21
Iteration:   4080, Loss function: 5.059, Average Loss: 3.705, avg. samples / sec: 66080.84
Iteration:   4080, Loss function: 2.648, Average Loss: 3.705, avg. samples / sec: 66053.86
Iteration:   4080, Loss function: 2.919, Average Loss: 3.700, avg. samples / sec: 66067.39
Iteration:   4080, Loss function: 3.699, Average Loss: 3.729, avg. samples / sec: 66113.91
Iteration:   4080, Loss function: 4.704, Average Loss: 3.688, avg. samples / sec: 66038.01
Iteration:   4080, Loss function: 3.656, Average Loss: 3.712, avg. samples / sec: 66009.92
Iteration:   4080, Loss function: 2.998, Average Loss: 3.696, avg. samples / sec: 66046.65
Iteration:   4080, Loss function: 4.399, Average Loss: 3.721, avg. samples / sec: 65959.94
Iteration:   4080, Loss function: 3.801, Average Loss: 3.682, avg. samples / sec: 66092.02
Iteration:   4080, Loss function: 4.213, Average Loss: 3.710, avg. samples / sec: 66100.08
Iteration:   4080, Loss function: 2.297, Average Loss: 3.722, avg. samples / sec: 65916.07
Iteration:   4080, Loss function: 1.390, Average Loss: 3.717, avg. samples / sec: 66020.81
Iteration:   4080, Loss function: 3.395, Average Loss: 3.699, avg. samples / sec: 65962.59
Iteration:   4080, Loss function: 3.570, Average Loss: 3.710, avg. samples / sec: 65988.07
Iteration:   4080, Loss function: 4.981, Average Loss: 3.690, avg. samples / sec: 66011.63
Iteration:   4080, Loss function: 2.381, Average Loss: 3.718, avg. samples / sec: 65922.82
Iteration:   4080, Loss function: 3.654, Average Loss: 3.697, avg. samples / sec: 65989.18
Iteration:   4080, Loss function: 3.145, Average Loss: 3.685, avg. samples / sec: 65904.57
Iteration:   4080, Loss function: 3.182, Average Loss: 3.702, avg. samples / sec: 65933.80
Iteration:   4100, Loss function: 3.218, Average Loss: 3.694, avg. samples / sec: 65984.09
Iteration:   4100, Loss function: 3.743, Average Loss: 3.705, avg. samples / sec: 65868.00
Iteration:   4100, Loss function: 3.786, Average Loss: 3.687, avg. samples / sec: 65889.87
Iteration:   4100, Loss function: 3.406, Average Loss: 3.718, avg. samples / sec: 65961.39
Iteration:   4100, Loss function: 3.251, Average Loss: 3.685, avg. samples / sec: 65898.34
Iteration:   4100, Loss function: 3.782, Average Loss: 3.697, avg. samples / sec: 66025.39
Iteration:   4100, Loss function: 3.281, Average Loss: 3.691, avg. samples / sec: 65912.64
Iteration:   4100, Loss function: 4.053, Average Loss: 3.704, avg. samples / sec: 65947.87
Iteration:   4100, Loss function: 3.391, Average Loss: 3.712, avg. samples / sec: 65975.50
Iteration:   4100, Loss function: 3.258, Average Loss: 3.685, avg. samples / sec: 65878.17
Iteration:   4100, Loss function: 3.230, Average Loss: 3.693, avg. samples / sec: 65749.72
Iteration:   4100, Loss function: 3.196, Average Loss: 3.712, avg. samples / sec: 65870.62
Iteration:   4100, Loss function: 3.409, Average Loss: 3.701, avg. samples / sec: 65819.49
Iteration:   4100, Loss function: 4.438, Average Loss: 3.714, avg. samples / sec: 65882.42
Iteration:   4100, Loss function: 3.952, Average Loss: 3.679, avg. samples / sec: 65761.84
Iteration:   4100, Loss function: 3.168, Average Loss: 3.672, avg. samples / sec: 65784.68
Iteration:   4100, Loss function: 2.685, Average Loss: 3.693, avg. samples / sec: 65766.20
Iteration:   4100, Loss function: 3.938, Average Loss: 3.691, avg. samples / sec: 65759.02
Iteration:   4100, Loss function: 3.598, Average Loss: 3.698, avg. samples / sec: 65814.48
Iteration:   4100, Loss function: 3.786, Average Loss: 3.703, avg. samples / sec: 65900.68
Iteration:   4100, Loss function: 3.132, Average Loss: 3.690, avg. samples / sec: 65787.44
Iteration:   4100, Loss function: 2.539, Average Loss: 3.681, avg. samples / sec: 65880.97
Iteration:   4100, Loss function: 3.136, Average Loss: 3.685, avg. samples / sec: 65910.39
Iteration:   4100, Loss function: 2.860, Average Loss: 3.699, avg. samples / sec: 65769.51
Iteration:   4100, Loss function: 3.380, Average Loss: 3.685, avg. samples / sec: 65656.82
Iteration:   4100, Loss function: 3.570, Average Loss: 3.698, avg. samples / sec: 65853.11
Iteration:   4100, Loss function: 2.766, Average Loss: 3.711, avg. samples / sec: 65850.46
Iteration:   4100, Loss function: 3.537, Average Loss: 3.681, avg. samples / sec: 65776.18
Iteration:   4100, Loss function: 3.856, Average Loss: 3.681, avg. samples / sec: 65855.48
Iteration:   4100, Loss function: 2.533, Average Loss: 3.709, avg. samples / sec: 65754.29
:::MLL 1558651643.815 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558651643.816 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 3.163, Average Loss: 3.683, avg. samples / sec: 65749.78
Iteration:   4120, Loss function: 3.930, Average Loss: 3.685, avg. samples / sec: 65863.23
Iteration:   4120, Loss function: 3.546, Average Loss: 3.691, avg. samples / sec: 65774.70
Iteration:   4120, Loss function: 3.704, Average Loss: 3.710, avg. samples / sec: 65796.01
Iteration:   4120, Loss function: 2.702, Average Loss: 3.672, avg. samples / sec: 65789.56
Iteration:   4120, Loss function: 3.288, Average Loss: 3.681, avg. samples / sec: 65715.69
Iteration:   4120, Loss function: 3.387, Average Loss: 3.702, avg. samples / sec: 65915.88
Iteration:   4120, Loss function: 3.108, Average Loss: 3.679, avg. samples / sec: 65833.39
Iteration:   4120, Loss function: 3.958, Average Loss: 3.679, avg. samples / sec: 65630.80
Iteration:   4120, Loss function: 3.363, Average Loss: 3.685, avg. samples / sec: 65579.85
Iteration:   4120, Loss function: 3.554, Average Loss: 3.710, avg. samples / sec: 65686.78
Iteration:   4120, Loss function: 3.608, Average Loss: 3.696, avg. samples / sec: 65644.80
Iteration:   4120, Loss function: 3.187, Average Loss: 3.669, avg. samples / sec: 65827.33
Iteration:   4120, Loss function: 3.668, Average Loss: 3.695, avg. samples / sec: 65721.85
Iteration:   4120, Loss function: 3.119, Average Loss: 3.690, avg. samples / sec: 65786.25
Iteration:   4120, Loss function: 2.530, Average Loss: 3.693, avg. samples / sec: 65647.43
Iteration:   4120, Loss function: 2.854, Average Loss: 3.685, avg. samples / sec: 65689.65
Iteration:   4120, Loss function: 4.190, Average Loss: 3.711, avg. samples / sec: 65631.99
Iteration:   4120, Loss function: 3.550, Average Loss: 3.699, avg. samples / sec: 65543.96
Iteration:   4120, Loss function: 4.304, Average Loss: 3.666, avg. samples / sec: 65651.01
Iteration:   4120, Loss function: 2.531, Average Loss: 3.694, avg. samples / sec: 65608.16
Iteration:   4120, Loss function: 2.708, Average Loss: 3.697, avg. samples / sec: 65672.33
Iteration:   4120, Loss function: 3.478, Average Loss: 3.681, avg. samples / sec: 65632.72
Iteration:   4120, Loss function: 3.445, Average Loss: 3.682, avg. samples / sec: 65560.02
Iteration:   4120, Loss function: 3.692, Average Loss: 3.702, avg. samples / sec: 65703.34
Iteration:   4120, Loss function: 2.235, Average Loss: 3.680, avg. samples / sec: 65657.83
Iteration:   4120, Loss function: 3.040, Average Loss: 3.713, avg. samples / sec: 65489.40
Iteration:   4120, Loss function: 2.879, Average Loss: 3.691, avg. samples / sec: 65647.70
Iteration:   4120, Loss function: 3.828, Average Loss: 3.677, avg. samples / sec: 65685.98
Iteration:   4120, Loss function: 4.404, Average Loss: 3.683, avg. samples / sec: 65606.60
Iteration:   4140, Loss function: 4.652, Average Loss: 3.683, avg. samples / sec: 66013.11
Iteration:   4140, Loss function: 3.227, Average Loss: 3.700, avg. samples / sec: 65914.68
Iteration:   4140, Loss function: 3.594, Average Loss: 3.667, avg. samples / sec: 65938.02
Iteration:   4140, Loss function: 4.468, Average Loss: 3.694, avg. samples / sec: 66005.23
Iteration:   4140, Loss function: 4.145, Average Loss: 3.681, avg. samples / sec: 66069.68
Iteration:   4140, Loss function: 2.867, Average Loss: 3.673, avg. samples / sec: 66116.67
Iteration:   4140, Loss function: 3.393, Average Loss: 3.687, avg. samples / sec: 65971.36
Iteration:   4140, Loss function: 2.922, Average Loss: 3.681, avg. samples / sec: 65851.88
Iteration:   4140, Loss function: 3.737, Average Loss: 3.692, avg. samples / sec: 66028.94
Iteration:   4140, Loss function: 3.302, Average Loss: 3.668, avg. samples / sec: 65856.59
Iteration:   4140, Loss function: 3.566, Average Loss: 3.671, avg. samples / sec: 66043.40
Iteration:   4140, Loss function: 3.316, Average Loss: 3.678, avg. samples / sec: 65905.03
Iteration:   4140, Loss function: 2.514, Average Loss: 3.661, avg. samples / sec: 65979.73
Iteration:   4140, Loss function: 2.957, Average Loss: 3.685, avg. samples / sec: 65998.76
Iteration:   4140, Loss function: 4.611, Average Loss: 3.673, avg. samples / sec: 65876.63
Iteration:   4140, Loss function: 2.537, Average Loss: 3.692, avg. samples / sec: 65889.13
Iteration:   4140, Loss function: 2.929, Average Loss: 3.700, avg. samples / sec: 65895.60
Iteration:   4140, Loss function: 3.694, Average Loss: 3.706, avg. samples / sec: 65926.09
Iteration:   4140, Loss function: 3.402, Average Loss: 3.674, avg. samples / sec: 65748.99
Iteration:   4140, Loss function: 3.574, Average Loss: 3.705, avg. samples / sec: 65989.43
Iteration:   4140, Loss function: 2.981, Average Loss: 3.669, avg. samples / sec: 66027.40
Iteration:   4140, Loss function: 4.272, Average Loss: 3.689, avg. samples / sec: 65893.01
Iteration:   4140, Loss function: 3.419, Average Loss: 3.674, avg. samples / sec: 65719.77
Iteration:   4140, Loss function: 4.290, Average Loss: 3.686, avg. samples / sec: 65956.91
Iteration:   4140, Loss function: 3.088, Average Loss: 3.690, avg. samples / sec: 65863.30
Iteration:   4140, Loss function: 3.935, Average Loss: 3.695, avg. samples / sec: 65935.43
Iteration:   4140, Loss function: 3.981, Average Loss: 3.665, avg. samples / sec: 65830.41
Iteration:   4140, Loss function: 4.100, Average Loss: 3.672, avg. samples / sec: 65904.88
Iteration:   4140, Loss function: 3.744, Average Loss: 3.697, avg. samples / sec: 65743.86
Iteration:   4140, Loss function: 2.863, Average Loss: 3.675, avg. samples / sec: 65796.84
Iteration:   4160, Loss function: 3.843, Average Loss: 3.673, avg. samples / sec: 66037.27
Iteration:   4160, Loss function: 3.316, Average Loss: 3.655, avg. samples / sec: 66070.95
Iteration:   4160, Loss function: 3.550, Average Loss: 3.682, avg. samples / sec: 66074.27
Iteration:   4160, Loss function: 3.227, Average Loss: 3.678, avg. samples / sec: 66012.15
Iteration:   4160, Loss function: 3.626, Average Loss: 3.673, avg. samples / sec: 66040.30
Iteration:   4160, Loss function: 3.288, Average Loss: 3.692, avg. samples / sec: 66025.33
Iteration:   4160, Loss function: 2.452, Average Loss: 3.678, avg. samples / sec: 65897.33
Iteration:   4160, Loss function: 3.776, Average Loss: 3.671, avg. samples / sec: 66053.61
Iteration:   4160, Loss function: 2.149, Average Loss: 3.691, avg. samples / sec: 65957.65
Iteration:   4160, Loss function: 2.985, Average Loss: 3.657, avg. samples / sec: 65981.55
Iteration:   4160, Loss function: 4.010, Average Loss: 3.694, avg. samples / sec: 66114.32
Iteration:   4160, Loss function: 3.113, Average Loss: 3.684, avg. samples / sec: 66011.38
Iteration:   4160, Loss function: 3.452, Average Loss: 3.686, avg. samples / sec: 66045.81
Iteration:   4160, Loss function: 3.199, Average Loss: 3.698, avg. samples / sec: 66009.31
Iteration:   4160, Loss function: 3.640, Average Loss: 3.678, avg. samples / sec: 65921.74
Iteration:   4160, Loss function: 1.894, Average Loss: 3.694, avg. samples / sec: 65851.38
Iteration:   4160, Loss function: 3.693, Average Loss: 3.658, avg. samples / sec: 66039.06
Iteration:   4160, Loss function: 4.102, Average Loss: 3.686, avg. samples / sec: 65897.76
Iteration:   4160, Loss function: 2.749, Average Loss: 3.670, avg. samples / sec: 66087.40
Iteration:   4160, Loss function: 2.995, Average Loss: 3.670, avg. samples / sec: 65914.65
Iteration:   4160, Loss function: 4.384, Average Loss: 3.682, avg. samples / sec: 66009.99
Iteration:   4160, Loss function: 3.335, Average Loss: 3.665, avg. samples / sec: 65911.26
Iteration:   4160, Loss function: 3.276, Average Loss: 3.684, avg. samples / sec: 66005.16
Iteration:   4160, Loss function: 3.448, Average Loss: 3.661, avg. samples / sec: 65847.08
Iteration:   4160, Loss function: 4.747, Average Loss: 3.671, avg. samples / sec: 65856.52
Iteration:   4160, Loss function: 3.362, Average Loss: 3.668, avg. samples / sec: 65986.84
Iteration:   4160, Loss function: 3.747, Average Loss: 3.665, avg. samples / sec: 65968.06
Iteration:   4160, Loss function: 3.001, Average Loss: 3.663, avg. samples / sec: 65854.52
Iteration:   4160, Loss function: 3.274, Average Loss: 3.698, avg. samples / sec: 65894.40
Iteration:   4160, Loss function: 3.392, Average Loss: 3.669, avg. samples / sec: 65768.04
Iteration:   4180, Loss function: 3.095, Average Loss: 3.687, avg. samples / sec: 65722.92
Iteration:   4180, Loss function: 3.578, Average Loss: 3.689, avg. samples / sec: 65592.34
Iteration:   4180, Loss function: 3.859, Average Loss: 3.677, avg. samples / sec: 65565.39
Iteration:   4180, Loss function: 3.791, Average Loss: 3.657, avg. samples / sec: 65688.83
Iteration:   4180, Loss function: 3.839, Average Loss: 3.683, avg. samples / sec: 65592.31
Iteration:   4180, Loss function: 3.888, Average Loss: 3.691, avg. samples / sec: 65705.67
Iteration:   4180, Loss function: 3.961, Average Loss: 3.648, avg. samples / sec: 65488.70
Iteration:   4180, Loss function: 3.238, Average Loss: 3.677, avg. samples / sec: 65563.29
Iteration:   4180, Loss function: 3.521, Average Loss: 3.648, avg. samples / sec: 65533.32
Iteration:   4180, Loss function: 3.262, Average Loss: 3.663, avg. samples / sec: 65635.90
Iteration:   4180, Loss function: 2.676, Average Loss: 3.664, avg. samples / sec: 65584.43
Iteration:   4180, Loss function: 3.502, Average Loss: 3.667, avg. samples / sec: 65491.26
Iteration:   4180, Loss function: 3.975, Average Loss: 3.660, avg. samples / sec: 65584.92
Iteration:   4180, Loss function: 3.984, Average Loss: 3.671, avg. samples / sec: 65537.55
Iteration:   4180, Loss function: 5.046, Average Loss: 3.677, avg. samples / sec: 65534.54
Iteration:   4180, Loss function: 2.568, Average Loss: 3.676, avg. samples / sec: 65541.67
Iteration:   4180, Loss function: 2.298, Average Loss: 3.670, avg. samples / sec: 65455.19
Iteration:   4180, Loss function: 4.364, Average Loss: 3.652, avg. samples / sec: 65599.60
Iteration:   4180, Loss function: 3.748, Average Loss: 3.661, avg. samples / sec: 65586.35
Iteration:   4180, Loss function: 2.883, Average Loss: 3.668, avg. samples / sec: 65380.51
Iteration:   4180, Loss function: 3.095, Average Loss: 3.663, avg. samples / sec: 65510.71
Iteration:   4180, Loss function: 3.461, Average Loss: 3.670, avg. samples / sec: 65414.59
Iteration:   4180, Loss function: 4.135, Average Loss: 3.657, avg. samples / sec: 65521.28
Iteration:   4180, Loss function: 2.895, Average Loss: 3.682, avg. samples / sec: 65471.03
Iteration:   4180, Loss function: 2.883, Average Loss: 3.686, avg. samples / sec: 65432.33
Iteration:   4180, Loss function: 2.586, Average Loss: 3.689, avg. samples / sec: 65459.32
Iteration:   4180, Loss function: 4.070, Average Loss: 3.676, avg. samples / sec: 65475.17
Iteration:   4180, Loss function: 3.052, Average Loss: 3.671, avg. samples / sec: 65379.76
Iteration:   4180, Loss function: 2.544, Average Loss: 3.649, avg. samples / sec: 65448.47
Iteration:   4180, Loss function: 4.217, Average Loss: 3.659, avg. samples / sec: 65550.11
:::MLL 1558651645.605 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558651645.605 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558651645.658 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=2.52s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23028
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39195
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23664
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06093
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10148
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53091
Current AP: 0.23028 AP goal: 0.23000
:::MLL 1558651649.404 eval_accuracy: {"value": 0.23027727561365893, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558651649.484 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558651649.491 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558651650.125 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,162,nvidia,2019-05-23 10:44:54 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
ENDING TIMING RUN AT 2019-05-23 10:47:36 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:44:53 PM
