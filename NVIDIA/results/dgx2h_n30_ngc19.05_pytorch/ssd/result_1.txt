Beginning trial 2 of 5
Gathering sys log on circe-n001
:::MLL 1558651323.868 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558651323.868 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558651323.869 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558651323.869 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558651323.869 submission_platform: {"value": "30xNVIDIA DGX-2H", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558651323.870 submission_entry: {"value": "{'hardware': 'NVIDIA DGX-2H', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.1 LTS / NVIDIA DGX Server 4.0.4 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) Platinum 8174 CPU @ 3.10GHz', 'num_cores': '48', 'num_vcpus': '96', 'accelerator': 'Tesla V100-SXM3-32GB-H', 'num_accelerators': '8', 'sys_mem_size': '1510 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '2x 894.3G + 8x 3.5T', 'cpu_accel_interconnect': 'UPI', 'network_card': 'Mellanox Technologies MT27800 Family [ConnectX-5]', 'num_network_cards': '10', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558651323.870 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558651323.870 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558651326.521 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.515 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.480 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.490 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.493 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.506 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.529 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.520 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.523 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.530 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.529 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.545 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.544 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.514 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.538 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.569 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.541 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.534 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.547 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.525 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.519 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.539 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.531 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.567 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.564 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.549 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.548 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.567 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.555 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651326.552 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node circe-n001
+ pids+=($!)
+ set +x
Launching on node circe-n002
+ pids+=($!)
+ set +x
Launching on node circe-n003
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n001
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n002
+ pids+=($!)
+ set +x
Launching on node circe-n004
+ srun --mem=0 -N 1 -n 1 -w circe-n001 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n002 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n003
Launching on node circe-n005
+ srun --mem=0 -N 1 -n 1 -w circe-n003 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n004
+ pids+=($!)
+ set +x
Launching on node circe-n006
+ srun --mem=0 -N 1 -n 1 -w circe-n004 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n005
+ set +x
Launching on node circe-n007
+ srun --mem=0 -N 1 -n 1 -w circe-n005 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n008
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n006
+ pids+=($!)
+ set +x
Launching on node circe-n009
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n007
+ srun --mem=0 -N 1 -n 1 -w circe-n006 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n010
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n008
+ srun --mem=0 -N 1 -n 1 -w circe-n007 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n011
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n009
+ srun --mem=0 -N 1 -n 1 -w circe-n008 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n012
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n010
+ srun --mem=0 -N 1 -n 1 -w circe-n009 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n013
+ srun --mem=0 -N 1 -n 1 -w circe-n010 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n011
+ pids+=($!)
+ set +x
Launching on node circe-n014
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n012
+ srun --mem=0 -N 1 -n 1 -w circe-n011 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n015
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n013
+ srun --mem=0 -N 1 -n 1 -w circe-n012 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n016
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n014
+ srun --mem=0 -N 1 -n 1 -w circe-n013 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n017
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n014 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n015
+ pids+=($!)
+ set +x
Launching on node circe-n018
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n016
+ srun --mem=0 -N 1 -n 1 -w circe-n015 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n019
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n017
+ srun --mem=0 -N 1 -n 1 -w circe-n016 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n020
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n018
+ srun --mem=0 -N 1 -n 1 -w circe-n017 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n021
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n019
+ srun --mem=0 -N 1 -n 1 -w circe-n018 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n022
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n019 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n020
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n021
+ set +x
Launching on node circe-n023
+ srun --mem=0 -N 1 -n 1 -w circe-n020 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n021 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n024
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n022
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w circe-n022 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
Launching on node circe-n025
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n023
+ pids+=($!)
+ set +x
Launching on node circe-n026
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n023 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n024
+ pids+=($!)
+ set +x
Launching on node circe-n027
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n025
+ srun --mem=0 -N 1 -n 1 -w circe-n024 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n028
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n026
+ srun --mem=0 -N 1 -n 1 -w circe-n025 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node circe-n029
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n027
+ srun --mem=0 -N 1 -n 1 -w circe-n026 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n030
+ srun --mem=0 -N 1 -n 1 -w circe-n027 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n028
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n029
+ srun --mem=0 -N 1 -n 1 -w circe-n028 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n030
+ srun --mem=0 -N 1 -n 1 -w circe-n029 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n030 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
+ TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
+ TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
running benchmark
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ echo 'running benchmark'
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:42:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558651330.122 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.122 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.122 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.122 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.155 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.155 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.183 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.183 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.183 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.183 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.183 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.184 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.184 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.184 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.179 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.179 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.179 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.179 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.179 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.179 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.179 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.179 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.199 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.199 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.199 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.199 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.199 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.199 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.199 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.200 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.153 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.154 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.181 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.181 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.181 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.181 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.174 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.175 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.175 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.175 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651330.175 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.197 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.194 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.185 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.185 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.185 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.185 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.185 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.185 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.185 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.185 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.188 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.188 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.188 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.188 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.207 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.188 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.188 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.188 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.188 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.221 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.221 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.221 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.221 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.221 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.221 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.221 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.221 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.195 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.196 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.196 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.196 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.196 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.206 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.207 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.207 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.207 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.207 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.258 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.251 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.251 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.252 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.241 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.242 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.242 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.242 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.242 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.223 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.223 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.223 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.223 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.224 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.270 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651330.270 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.270 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.270 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651330.270 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651330.270 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558651330.271 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.271 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.272 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.272 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.272 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.272 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.273 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.273 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.273 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.273 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.269 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.269 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.269 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.269 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.269 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.269 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.269 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.269 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.257 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.257 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.257 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.257 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.257 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.257 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.255 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.256 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.288 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.288 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.288 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.288 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.289 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.289 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651330.289 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651330.290 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
0 Using seed = 3751970860
2 Using seed = 3751970862
1 Using seed = 3751970861
:::MLL 1558651344.120 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
4 Using seed = 3751970864
3 Using seed = 3751970863
13 Using seed = 3751970873
15 Using seed = 3751970875
14 Using seed = 3751970874
12 Using seed = 3751970872
10 Using seed = 3751970870
9 Using seed = 3751970869
11 Using seed = 3751970871
8 Using seed = 3751970868
17 Using seed = 3751970877
22 Using seed = 3751970882
19 Using seed = 3751970879
18 Using seed = 3751970878
16 Using seed = 3751970876
21 Using seed = 3751970881
20 Using seed = 3751970880
23 Using seed = 3751970883
31 Using seed = 3751970891
24 Using seed = 3751970884
29 Using seed = 3751970889
30 Using seed = 3751970890
25 Using seed = 3751970885
26 Using seed = 3751970886
27 Using seed = 3751970887
28 Using seed = 3751970888
38 Using seed = 3751970898
39 Using seed = 3751970899
35 Using seed = 3751970895
36 Using seed = 3751970896
34 Using seed = 3751970894
32 Using seed = 3751970892
33 Using seed = 3751970893
37 Using seed = 3751970897
46 Using seed = 3751970906
42 Using seed = 3751970902
44 Using seed = 3751970904
40 Using seed = 3751970900
47 Using seed = 3751970907
41 Using seed = 3751970901
45 Using seed = 3751970905
43 Using seed = 3751970903
51 Using seed = 3751970911
48 Using seed = 3751970908
50 Using seed = 3751970910
49 Using seed = 3751970909
54 Using seed = 3751970914
55 Using seed = 3751970915
53 Using seed = 3751970913
52 Using seed = 3751970912
57 Using seed = 3751970917
63 Using seed = 3751970923
56 Using seed = 3751970916
59 Using seed = 3751970919
58 Using seed = 3751970918
62 Using seed = 3751970922
61 Using seed = 3751970921
60 Using seed = 3751970920
65 Using seed = 3751970925
71 Using seed = 3751970931
64 Using seed = 3751970924
67 Using seed = 3751970927
66 Using seed = 3751970926
68 Using seed = 3751970928
69 Using seed = 3751970929
70 Using seed = 3751970930
78 Using seed = 3751970938
79 Using seed = 3751970939
76 Using seed = 3751970936
75 Using seed = 3751970935
77 Using seed = 3751970937
73 Using seed = 3751970933
74 Using seed = 3751970934
72 Using seed = 3751970932
81 Using seed = 3751970941
83 Using seed = 3751970943
80 Using seed = 3751970940
87 Using seed = 3751970947
82 Using seed = 3751970942
85 Using seed = 3751970945
86 Using seed = 3751970946
84 Using seed = 3751970944
95 Using seed = 3751970955
88 Using seed = 3751970948
93 Using seed = 3751970953
91 Using seed = 3751970951
94 Using seed = 3751970954
92 Using seed = 3751970952
89 Using seed = 3751970949
90 Using seed = 3751970950
98 Using seed = 3751970958
96 Using seed = 3751970956
99 Using seed = 3751970959
100 Using seed = 3751970960
101 Using seed = 3751970961
102 Using seed = 3751970962
103 Using seed = 3751970963
97 Using seed = 3751970957
110 Using seed = 3751970970
111 Using seed = 3751970971
109 Using seed = 3751970969
107 Using seed = 3751970967
105 Using seed = 3751970965
106 Using seed = 3751970966
104 Using seed = 3751970964
108 Using seed = 3751970968
112 Using seed = 3751970972
115 Using seed = 3751970975
113 Using seed = 3751970973
114 Using seed = 3751970974
119 Using seed = 3751970979
118 Using seed = 3751970978
117 Using seed = 3751970977
116 Using seed = 3751970976
127 Using seed = 3751970987
125 Using seed = 3751970985
120 Using seed = 3751970980
126 Using seed = 3751970986
122 Using seed = 3751970982
123 Using seed = 3751970983
121 Using seed = 3751970981
124 Using seed = 3751970984
129 Using seed = 3751970989
134 Using seed = 3751970994
133 Using seed = 3751970993
130 Using seed = 3751970990
128 Using seed = 3751970988
131 Using seed = 3751970991
135 Using seed = 3751970995
132 Using seed = 3751970992
136 Using seed = 3751970996
137 Using seed = 3751970997
139 Using seed = 3751970999
138 Using seed = 3751970998
143 Using seed = 3751971003
142 Using seed = 3751971002
141 Using seed = 3751971001
140 Using seed = 3751971000
145 Using seed = 3751971005
147 Using seed = 3751971007
149 Using seed = 3751971009
148 Using seed = 3751971008
151 Using seed = 3751971011
144 Using seed = 3751971004
146 Using seed = 3751971006
150 Using seed = 3751971010
158 Using seed = 3751971018
159 Using seed = 3751971019
156 Using seed = 3751971016
153 Using seed = 3751971013
157 Using seed = 3751971017
152 Using seed = 3751971012
155 Using seed = 3751971015
154 Using seed = 3751971014
163 Using seed = 3751971023
161 Using seed = 3751971021
160 Using seed = 3751971020
162 Using seed = 3751971022
165 Using seed = 3751971025
166 Using seed = 3751971026
167 Using seed = 3751971027
164 Using seed = 3751971024
175 Using seed = 3751971035
171 Using seed = 3751971031
173 Using seed = 3751971033
172 Using seed = 3751971032
174 Using seed = 3751971034
169 Using seed = 3751971029
168 Using seed = 3751971028
170 Using seed = 3751971030
178 Using seed = 3751971038
177 Using seed = 3751971037
183 Using seed = 3751971043
179 Using seed = 3751971039
176 Using seed = 3751971036
182 Using seed = 3751971042
181 Using seed = 3751971041
180 Using seed = 3751971040
189 Using seed = 3751971049
184 Using seed = 3751971044
191 Using seed = 3751971051
190 Using seed = 3751971050
185 Using seed = 3751971045
187 Using seed = 3751971047
188 Using seed = 3751971048
186 Using seed = 3751971046
193 Using seed = 3751971053
199 Using seed = 3751971059
194 Using seed = 3751971054
195 Using seed = 3751971055
192 Using seed = 3751971052
198 Using seed = 3751971058
197 Using seed = 3751971057
196 Using seed = 3751971056
207 Using seed = 3751971067
205 Using seed = 3751971065
204 Using seed = 3751971064
206 Using seed = 3751971066
202 Using seed = 3751971062
200 Using seed = 3751971060
203 Using seed = 3751971063
201 Using seed = 3751971061
215 Using seed = 3751971075
214 Using seed = 3751971074
213 Using seed = 3751971073
209 Using seed = 3751971069
208 Using seed = 3751971068
211 Using seed = 3751971071
210 Using seed = 3751971070
212 Using seed = 3751971072
223 Using seed = 3751971083
218 Using seed = 3751971078
222 Using seed = 3751971082
220 Using seed = 3751971080
219 Using seed = 3751971079
217 Using seed = 3751971077
221 Using seed = 3751971081
216 Using seed = 3751971076
224 Using seed = 3751971084
227 Using seed = 3751971087
226 Using seed = 3751971086
230 Using seed = 3751971090
231 Using seed = 3751971091
229 Using seed = 3751971089
228 Using seed = 3751971088
225 Using seed = 3751971085
239 Using seed = 3751971099
237 Using seed = 3751971097
238 Using seed = 3751971098
234 Using seed = 3751971094
233 Using seed = 3751971093
235 Using seed = 3751971095
232 Using seed = 3751971092
236 Using seed = 3751971096
5 Using seed = 3751970865
7 Using seed = 3751970867
6 Using seed = 3751970866
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651346.136 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558651346.137 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651346.154 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1558651346.154 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651346.154 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558651346.154 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558651349.978 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558651349.979 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.45s)
creating index...
Done (t=0.46s)
creating index...
time_check a: 1558651351.636404753
time_check a: 1558651351.621723890
time_check a: 1558651351.629361153
time_check a: 1558651351.619113207
time_check a: 1558651351.638091564
time_check a: 1558651351.620905161
time_check a: 1558651351.628542662
time_check a: 1558651351.636584282
time_check a: 1558651351.613712549
time_check a: 1558651351.648850918
time_check a: 1558651351.634607077
time_check a: 1558651351.624171019
time_check a: 1558651351.622745752
time_check a: 1558651351.640429020
time_check a: 1558651351.648971796
time_check a: 1558651351.621345758
time_check a: 1558651351.652215719
time_check a: 1558651351.644258022
time_check a: 1558651351.645233154
time_check a: 1558651351.658431530
time_check a: 1558651351.641251326
time_check a: 1558651351.653671503
time_check a: 1558651351.662563562
time_check a: 1558651351.678397894
time_check a: 1558651351.657704592
time_check a: 1558651351.629236698
time_check a: 1558651351.678138733
time_check a: 1558651351.670980453
time_check a: 1558651351.630240440
time_check a: 1558651351.735377312
time_check b: 1558651355.442152023
time_check b: 1558651355.486689091
time_check b: 1558651355.468921900
time_check b: 1558651355.467905760
time_check b: 1558651355.485893488
time_check b: 1558651355.505359411
time_check b: 1558651355.504616499
time_check b: 1558651355.532160759
time_check b: 1558651355.534538984
time_check b: 1558651355.531710863
time_check b: 1558651355.555373430
time_check b: 1558651355.514775991
time_check b: 1558651355.521254539
time_check b: 1558651355.528912306
time_check b: 1558651355.521427870
time_check b: 1558651355.520110369
time_check b: 1558651355.544083595
time_check b: 1558651355.573872089
time_check b: 1558651355.574695826
time_check b: 1558651355.598352909
time_check b: 1558651355.586726189
time_check b: 1558651355.561271191
time_check b: 1558651355.581772804
time_check b: 1558651355.579296827
time_check b: 1558651355.563679934
time_check b: 1558651355.575514078
time_check b: 1558651355.572085857
time_check b: 1558651355.602986097
time_check b: 1558651355.623345375
time_check b: 1558651355.647402525
:::MLL 1558651356.293 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558651356.294 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.979, Average Loss: 0.023, avg. samples / sec: 176.24
Iteration:      0, Loss function: 22.669, Average Loss: 0.023, avg. samples / sec: 176.86
Iteration:      0, Loss function: 22.354, Average Loss: 0.022, avg. samples / sec: 177.99
Iteration:      0, Loss function: 22.713, Average Loss: 0.023, avg. samples / sec: 175.94
Iteration:      0, Loss function: 22.354, Average Loss: 0.022, avg. samples / sec: 175.49
Iteration:      0, Loss function: 23.345, Average Loss: 0.023, avg. samples / sec: 176.28
Iteration:      0, Loss function: 22.883, Average Loss: 0.023, avg. samples / sec: 178.28
Iteration:      0, Loss function: 22.562, Average Loss: 0.023, avg. samples / sec: 178.60
Iteration:      0, Loss function: 23.560, Average Loss: 0.024, avg. samples / sec: 177.17
Iteration:      0, Loss function: 23.752, Average Loss: 0.024, avg. samples / sec: 177.04
Iteration:      0, Loss function: 22.431, Average Loss: 0.022, avg. samples / sec: 177.77
Iteration:      0, Loss function: 22.468, Average Loss: 0.022, avg. samples / sec: 177.08
Iteration:      0, Loss function: 22.445, Average Loss: 0.022, avg. samples / sec: 178.34
Iteration:      0, Loss function: 22.339, Average Loss: 0.022, avg. samples / sec: 176.51
Iteration:      0, Loss function: 22.108, Average Loss: 0.022, avg. samples / sec: 179.44
Iteration:      0, Loss function: 22.240, Average Loss: 0.022, avg. samples / sec: 177.43
Iteration:      0, Loss function: 22.820, Average Loss: 0.023, avg. samples / sec: 178.06
Iteration:      0, Loss function: 22.115, Average Loss: 0.022, avg. samples / sec: 175.73
Iteration:      0, Loss function: 22.390, Average Loss: 0.022, avg. samples / sec: 176.99
Iteration:      0, Loss function: 21.921, Average Loss: 0.022, avg. samples / sec: 177.61
Iteration:      0, Loss function: 22.233, Average Loss: 0.022, avg. samples / sec: 175.53
Iteration:      0, Loss function: 22.444, Average Loss: 0.022, avg. samples / sec: 178.06
Iteration:      0, Loss function: 22.048, Average Loss: 0.022, avg. samples / sec: 176.31
Iteration:      0, Loss function: 22.526, Average Loss: 0.023, avg. samples / sec: 174.67
Iteration:      0, Loss function: 22.611, Average Loss: 0.023, avg. samples / sec: 176.74
Iteration:      0, Loss function: 22.539, Average Loss: 0.023, avg. samples / sec: 176.70
Iteration:      0, Loss function: 22.645, Average Loss: 0.023, avg. samples / sec: 177.44
Iteration:      0, Loss function: 22.923, Average Loss: 0.023, avg. samples / sec: 176.57
Iteration:      0, Loss function: 22.988, Average Loss: 0.023, avg. samples / sec: 176.91
Iteration:      0, Loss function: 22.296, Average Loss: 0.022, avg. samples / sec: 179.74
Iteration:     20, Loss function: 20.994, Average Loss: 0.441, avg. samples / sec: 42614.70
Iteration:     20, Loss function: 20.774, Average Loss: 0.443, avg. samples / sec: 42678.78
Iteration:     20, Loss function: 21.467, Average Loss: 0.444, avg. samples / sec: 42082.29
Iteration:     20, Loss function: 21.162, Average Loss: 0.448, avg. samples / sec: 42297.39
Iteration:     20, Loss function: 20.805, Average Loss: 0.441, avg. samples / sec: 42201.28
Iteration:     20, Loss function: 20.565, Average Loss: 0.444, avg. samples / sec: 41674.68
Iteration:     20, Loss function: 20.390, Average Loss: 0.443, avg. samples / sec: 42281.84
Iteration:     20, Loss function: 22.319, Average Loss: 0.445, avg. samples / sec: 43122.62
Iteration:     20, Loss function: 20.191, Average Loss: 0.445, avg. samples / sec: 42737.53
Iteration:     20, Loss function: 20.748, Average Loss: 0.451, avg. samples / sec: 43043.77
Iteration:     20, Loss function: 20.329, Average Loss: 0.440, avg. samples / sec: 42519.65
Iteration:     20, Loss function: 20.895, Average Loss: 0.444, avg. samples / sec: 42219.53
Iteration:     20, Loss function: 21.467, Average Loss: 0.442, avg. samples / sec: 42113.22
Iteration:     20, Loss function: 20.743, Average Loss: 0.441, avg. samples / sec: 42314.63
Iteration:     20, Loss function: 20.310, Average Loss: 0.443, avg. samples / sec: 42435.63
Iteration:     20, Loss function: 20.735, Average Loss: 0.442, avg. samples / sec: 42207.69
Iteration:     20, Loss function: 21.937, Average Loss: 0.443, avg. samples / sec: 42264.88
Iteration:     20, Loss function: 20.779, Average Loss: 0.442, avg. samples / sec: 42174.98
Iteration:     20, Loss function: 20.537, Average Loss: 0.440, avg. samples / sec: 42434.02
Iteration:     20, Loss function: 20.317, Average Loss: 0.442, avg. samples / sec: 42380.35
Iteration:     20, Loss function: 20.470, Average Loss: 0.443, avg. samples / sec: 42322.39
Iteration:     20, Loss function: 20.509, Average Loss: 0.440, avg. samples / sec: 42508.77
Iteration:     20, Loss function: 20.305, Average Loss: 0.443, avg. samples / sec: 42310.91
Iteration:     20, Loss function: 20.366, Average Loss: 0.446, avg. samples / sec: 42070.04
Iteration:     20, Loss function: 20.393, Average Loss: 0.442, avg. samples / sec: 42312.51
Iteration:     20, Loss function: 20.547, Average Loss: 0.440, avg. samples / sec: 42343.72
Iteration:     20, Loss function: 20.499, Average Loss: 0.439, avg. samples / sec: 42223.15
Iteration:     20, Loss function: 20.395, Average Loss: 0.440, avg. samples / sec: 42347.19
Iteration:     20, Loss function: 20.736, Average Loss: 0.444, avg. samples / sec: 42198.29
Iteration:     20, Loss function: 20.181, Average Loss: 0.440, avg. samples / sec: 41650.29
Iteration:     40, Loss function: 16.693, Average Loss: 0.822, avg. samples / sec: 63830.35
Iteration:     40, Loss function: 17.464, Average Loss: 0.829, avg. samples / sec: 63726.85
Iteration:     40, Loss function: 17.157, Average Loss: 0.829, avg. samples / sec: 63394.63
Iteration:     40, Loss function: 17.327, Average Loss: 0.832, avg. samples / sec: 63337.22
Iteration:     40, Loss function: 17.321, Average Loss: 0.825, avg. samples / sec: 64407.70
Iteration:     40, Loss function: 16.976, Average Loss: 0.826, avg. samples / sec: 63359.83
Iteration:     40, Loss function: 17.403, Average Loss: 0.825, avg. samples / sec: 63550.29
Iteration:     40, Loss function: 17.006, Average Loss: 0.825, avg. samples / sec: 63665.67
Iteration:     40, Loss function: 17.648, Average Loss: 0.822, avg. samples / sec: 63636.52
Iteration:     40, Loss function: 16.448, Average Loss: 0.826, avg. samples / sec: 63672.09
Iteration:     40, Loss function: 16.750, Average Loss: 0.826, avg. samples / sec: 63855.00
Iteration:     40, Loss function: 18.493, Average Loss: 0.828, avg. samples / sec: 63097.71
Iteration:     40, Loss function: 17.053, Average Loss: 0.828, avg. samples / sec: 63602.23
Iteration:     40, Loss function: 17.063, Average Loss: 0.826, avg. samples / sec: 63489.37
Iteration:     40, Loss function: 16.721, Average Loss: 0.827, avg. samples / sec: 63410.69
Iteration:     40, Loss function: 18.099, Average Loss: 0.829, avg. samples / sec: 63238.49
Iteration:     40, Loss function: 18.258, Average Loss: 0.832, avg. samples / sec: 63546.99
Iteration:     40, Loss function: 17.195, Average Loss: 0.828, avg. samples / sec: 63409.04
Iteration:     40, Loss function: 17.288, Average Loss: 0.828, avg. samples / sec: 63102.97
Iteration:     40, Loss function: 16.617, Average Loss: 0.827, avg. samples / sec: 63393.78
Iteration:     40, Loss function: 17.908, Average Loss: 0.830, avg. samples / sec: 63540.32
Iteration:     40, Loss function: 16.423, Average Loss: 0.823, avg. samples / sec: 63308.34
Iteration:     40, Loss function: 16.650, Average Loss: 0.820, avg. samples / sec: 63292.22
Iteration:     40, Loss function: 17.269, Average Loss: 0.837, avg. samples / sec: 63135.11
Iteration:     40, Loss function: 17.302, Average Loss: 0.827, avg. samples / sec: 62913.63
Iteration:     40, Loss function: 17.386, Average Loss: 0.823, avg. samples / sec: 62992.85
Iteration:     40, Loss function: 17.295, Average Loss: 0.821, avg. samples / sec: 63453.09
Iteration:     40, Loss function: 17.377, Average Loss: 0.830, avg. samples / sec: 62910.26
Iteration:     40, Loss function: 17.308, Average Loss: 0.824, avg. samples / sec: 63047.04
Iteration:     40, Loss function: 16.664, Average Loss: 0.827, avg. samples / sec: 62512.58
Iteration:     60, Loss function: 10.150, Average Loss: 1.079, avg. samples / sec: 64160.30
Iteration:     60, Loss function: 12.764, Average Loss: 1.070, avg. samples / sec: 64008.01
Iteration:     60, Loss function: 12.718, Average Loss: 1.084, avg. samples / sec: 64004.20
Iteration:     60, Loss function: 11.279, Average Loss: 1.074, avg. samples / sec: 64110.62
Iteration:     60, Loss function: 12.114, Average Loss: 1.082, avg. samples / sec: 64190.64
Iteration:     60, Loss function: 12.464, Average Loss: 1.080, avg. samples / sec: 64874.85
Iteration:     60, Loss function: 10.799, Average Loss: 1.070, avg. samples / sec: 64190.64
Iteration:     60, Loss function: 11.382, Average Loss: 1.082, avg. samples / sec: 64144.24
Iteration:     60, Loss function: 11.329, Average Loss: 1.069, avg. samples / sec: 63980.96
Iteration:     60, Loss function: 9.211, Average Loss: 1.066, avg. samples / sec: 64159.48
Iteration:     60, Loss function: 12.415, Average Loss: 1.079, avg. samples / sec: 64276.24
Iteration:     60, Loss function: 10.246, Average Loss: 1.077, avg. samples / sec: 63906.28
Iteration:     60, Loss function: 10.895, Average Loss: 1.077, avg. samples / sec: 64040.04
Iteration:     60, Loss function: 11.464, Average Loss: 1.064, avg. samples / sec: 64274.72
Iteration:     60, Loss function: 9.960, Average Loss: 1.069, avg. samples / sec: 63942.64
Iteration:     60, Loss function: 12.367, Average Loss: 1.092, avg. samples / sec: 64170.79
Iteration:     60, Loss function: 10.964, Average Loss: 1.075, avg. samples / sec: 64577.67
Iteration:     60, Loss function: 10.365, Average Loss: 1.085, avg. samples / sec: 63987.26
Iteration:     60, Loss function: 11.328, Average Loss: 1.077, avg. samples / sec: 63947.37
Iteration:     60, Loss function: 11.869, Average Loss: 1.070, avg. samples / sec: 63892.23
Iteration:     60, Loss function: 10.193, Average Loss: 1.071, avg. samples / sec: 63706.11
Iteration:     60, Loss function: 11.732, Average Loss: 1.077, avg. samples / sec: 63827.17
Iteration:     60, Loss function: 12.147, Average Loss: 1.079, avg. samples / sec: 63867.27
Iteration:     60, Loss function: 11.135, Average Loss: 1.084, avg. samples / sec: 63959.27
Iteration:     60, Loss function: 11.564, Average Loss: 1.080, avg. samples / sec: 63879.08
Iteration:     60, Loss function: 10.932, Average Loss: 1.083, avg. samples / sec: 63945.95
Iteration:     60, Loss function: 11.016, Average Loss: 1.073, avg. samples / sec: 64111.35
Iteration:     60, Loss function: 12.052, Average Loss: 1.074, avg. samples / sec: 63708.21
Iteration:     60, Loss function: 9.678, Average Loss: 1.082, avg. samples / sec: 63688.23
Iteration:     60, Loss function: 10.949, Average Loss: 1.080, avg. samples / sec: 64307.65
:::MLL 1558651359.073 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558651359.073 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 10.119, Average Loss: 1.273, avg. samples / sec: 64482.43
Iteration:     80, Loss function: 10.252, Average Loss: 1.280, avg. samples / sec: 64551.34
Iteration:     80, Loss function: 10.246, Average Loss: 1.266, avg. samples / sec: 64234.79
Iteration:     80, Loss function: 10.766, Average Loss: 1.279, avg. samples / sec: 64438.35
Iteration:     80, Loss function: 9.699, Average Loss: 1.267, avg. samples / sec: 64044.34
Iteration:     80, Loss function: 9.520, Average Loss: 1.261, avg. samples / sec: 64140.68
Iteration:     80, Loss function: 9.290, Average Loss: 1.273, avg. samples / sec: 64107.62
Iteration:     80, Loss function: 9.705, Average Loss: 1.273, avg. samples / sec: 64068.57
Iteration:     80, Loss function: 9.642, Average Loss: 1.261, avg. samples / sec: 64115.70
Iteration:     80, Loss function: 9.460, Average Loss: 1.265, avg. samples / sec: 64271.46
Iteration:     80, Loss function: 10.494, Average Loss: 1.267, avg. samples / sec: 64144.01
Iteration:     80, Loss function: 11.146, Average Loss: 1.272, avg. samples / sec: 64259.07
Iteration:     80, Loss function: 10.428, Average Loss: 1.277, avg. samples / sec: 64268.94
Iteration:     80, Loss function: 9.438, Average Loss: 1.267, avg. samples / sec: 64326.88
Iteration:     80, Loss function: 9.527, Average Loss: 1.272, avg. samples / sec: 63870.16
Iteration:     80, Loss function: 10.233, Average Loss: 1.277, avg. samples / sec: 64239.47
Iteration:     80, Loss function: 10.592, Average Loss: 1.279, avg. samples / sec: 64137.38
Iteration:     80, Loss function: 9.194, Average Loss: 1.265, avg. samples / sec: 64235.20
Iteration:     80, Loss function: 10.714, Average Loss: 1.259, avg. samples / sec: 63940.32
Iteration:     80, Loss function: 9.399, Average Loss: 1.273, avg. samples / sec: 64040.88
Iteration:     80, Loss function: 9.877, Average Loss: 1.281, avg. samples / sec: 64135.80
Iteration:     80, Loss function: 10.116, Average Loss: 1.270, avg. samples / sec: 63984.53
Iteration:     80, Loss function: 9.866, Average Loss: 1.274, avg. samples / sec: 63942.06
Iteration:     80, Loss function: 9.502, Average Loss: 1.271, avg. samples / sec: 63895.50
Iteration:     80, Loss function: 9.551, Average Loss: 1.266, avg. samples / sec: 64076.20
Iteration:     80, Loss function: 10.194, Average Loss: 1.278, avg. samples / sec: 63773.62
Iteration:     80, Loss function: 10.199, Average Loss: 1.267, avg. samples / sec: 63886.03
Iteration:     80, Loss function: 10.321, Average Loss: 1.270, avg. samples / sec: 63751.32
Iteration:     80, Loss function: 9.930, Average Loss: 1.274, avg. samples / sec: 63543.96
Iteration:     80, Loss function: 9.192, Average Loss: 1.287, avg. samples / sec: 63657.22
Iteration:    100, Loss function: 9.783, Average Loss: 1.442, avg. samples / sec: 65063.03
Iteration:    100, Loss function: 9.776, Average Loss: 1.437, avg. samples / sec: 64965.08
Iteration:    100, Loss function: 9.351, Average Loss: 1.425, avg. samples / sec: 64886.80
Iteration:    100, Loss function: 9.194, Average Loss: 1.438, avg. samples / sec: 64728.64
Iteration:    100, Loss function: 9.318, Average Loss: 1.429, avg. samples / sec: 64961.42
Iteration:    100, Loss function: 10.384, Average Loss: 1.426, avg. samples / sec: 64708.96
Iteration:    100, Loss function: 9.303, Average Loss: 1.432, avg. samples / sec: 64617.13
Iteration:    100, Loss function: 9.289, Average Loss: 1.438, avg. samples / sec: 64765.05
Iteration:    100, Loss function: 8.506, Average Loss: 1.448, avg. samples / sec: 65268.66
Iteration:    100, Loss function: 9.426, Average Loss: 1.441, avg. samples / sec: 64885.49
Iteration:    100, Loss function: 8.835, Average Loss: 1.439, avg. samples / sec: 64706.76
Iteration:    100, Loss function: 9.392, Average Loss: 1.435, avg. samples / sec: 64737.11
Iteration:    100, Loss function: 9.770, Average Loss: 1.442, avg. samples / sec: 65169.42
Iteration:    100, Loss function: 9.631, Average Loss: 1.447, avg. samples / sec: 64509.80
Iteration:    100, Loss function: 10.364, Average Loss: 1.441, avg. samples / sec: 64652.65
Iteration:    100, Loss function: 10.855, Average Loss: 1.438, avg. samples / sec: 64420.50
Iteration:    100, Loss function: 10.680, Average Loss: 1.449, avg. samples / sec: 64740.23
Iteration:    100, Loss function: 8.579, Average Loss: 1.445, avg. samples / sec: 64605.32
Iteration:    100, Loss function: 10.316, Average Loss: 1.440, avg. samples / sec: 64525.83
Iteration:    100, Loss function: 10.167, Average Loss: 1.453, avg. samples / sec: 64555.51
Iteration:    100, Loss function: 8.852, Average Loss: 1.434, avg. samples / sec: 64423.51
Iteration:    100, Loss function: 9.771, Average Loss: 1.430, avg. samples / sec: 64446.58
Iteration:    100, Loss function: 9.676, Average Loss: 1.424, avg. samples / sec: 64412.26
Iteration:    100, Loss function: 8.781, Average Loss: 1.441, avg. samples / sec: 64598.21
Iteration:    100, Loss function: 9.581, Average Loss: 1.428, avg. samples / sec: 64403.52
Iteration:    100, Loss function: 10.124, Average Loss: 1.444, avg. samples / sec: 64662.59
Iteration:    100, Loss function: 9.077, Average Loss: 1.433, avg. samples / sec: 64421.03
Iteration:    100, Loss function: 10.288, Average Loss: 1.437, avg. samples / sec: 64628.45
Iteration:    100, Loss function: 10.347, Average Loss: 1.448, avg. samples / sec: 64207.48
Iteration:    100, Loss function: 10.040, Average Loss: 1.437, avg. samples / sec: 64439.95
Iteration:    120, Loss function: 10.051, Average Loss: 1.583, avg. samples / sec: 64842.02
Iteration:    120, Loss function: 8.538, Average Loss: 1.589, avg. samples / sec: 64991.56
Iteration:    120, Loss function: 9.158, Average Loss: 1.600, avg. samples / sec: 65148.57
Iteration:    120, Loss function: 8.874, Average Loss: 1.579, avg. samples / sec: 64772.97
Iteration:    120, Loss function: 8.764, Average Loss: 1.611, avg. samples / sec: 65038.47
Iteration:    120, Loss function: 9.482, Average Loss: 1.601, avg. samples / sec: 64779.28
Iteration:    120, Loss function: 9.612, Average Loss: 1.599, avg. samples / sec: 64636.81
Iteration:    120, Loss function: 9.695, Average Loss: 1.588, avg. samples / sec: 65066.52
Iteration:    120, Loss function: 9.205, Average Loss: 1.595, avg. samples / sec: 64819.80
Iteration:    120, Loss function: 9.584, Average Loss: 1.600, avg. samples / sec: 64845.30
Iteration:    120, Loss function: 9.453, Average Loss: 1.588, avg. samples / sec: 64750.20
Iteration:    120, Loss function: 9.473, Average Loss: 1.590, avg. samples / sec: 64959.93
Iteration:    120, Loss function: 9.785, Average Loss: 1.598, avg. samples / sec: 64814.05
Iteration:    120, Loss function: 9.256, Average Loss: 1.601, avg. samples / sec: 65191.04
Iteration:    120, Loss function: 8.730, Average Loss: 1.597, avg. samples / sec: 64685.11
Iteration:    120, Loss function: 9.344, Average Loss: 1.604, avg. samples / sec: 64739.31
Iteration:    120, Loss function: 9.813, Average Loss: 1.592, avg. samples / sec: 65018.79
Iteration:    120, Loss function: 9.521, Average Loss: 1.592, avg. samples / sec: 64622.44
Iteration:    120, Loss function: 9.831, Average Loss: 1.594, avg. samples / sec: 65234.76
Iteration:    120, Loss function: 9.699, Average Loss: 1.590, avg. samples / sec: 64738.03
Iteration:    120, Loss function: 8.644, Average Loss: 1.606, avg. samples / sec: 64737.83
Iteration:    120, Loss function: 10.848, Average Loss: 1.593, avg. samples / sec: 65000.20
Iteration:    120, Loss function: 9.077, Average Loss: 1.599, avg. samples / sec: 64740.56
Iteration:    120, Loss function: 9.233, Average Loss: 1.601, avg. samples / sec: 64590.04
Iteration:    120, Loss function: 9.699, Average Loss: 1.587, avg. samples / sec: 64818.79
Iteration:    120, Loss function: 9.382, Average Loss: 1.597, avg. samples / sec: 64804.30
Iteration:    120, Loss function: 8.632, Average Loss: 1.606, avg. samples / sec: 64661.22
Iteration:    120, Loss function: 8.175, Average Loss: 1.606, avg. samples / sec: 64679.32
Iteration:    120, Loss function: 9.418, Average Loss: 1.583, avg. samples / sec: 64763.86
Iteration:    120, Loss function: 9.619, Average Loss: 1.585, avg. samples / sec: 64279.85
:::MLL 1558651360.898 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558651360.899 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 8.842, Average Loss: 1.730, avg. samples / sec: 64285.92
Iteration:    140, Loss function: 9.051, Average Loss: 1.737, avg. samples / sec: 64253.44
Iteration:    140, Loss function: 9.990, Average Loss: 1.727, avg. samples / sec: 64168.86
Iteration:    140, Loss function: 7.694, Average Loss: 1.739, avg. samples / sec: 64196.86
Iteration:    140, Loss function: 8.995, Average Loss: 1.745, avg. samples / sec: 64242.55
Iteration:    140, Loss function: 9.008, Average Loss: 1.741, avg. samples / sec: 64208.59
Iteration:    140, Loss function: 8.144, Average Loss: 1.728, avg. samples / sec: 64071.95
Iteration:    140, Loss function: 9.019, Average Loss: 1.732, avg. samples / sec: 64070.02
Iteration:    140, Loss function: 9.053, Average Loss: 1.748, avg. samples / sec: 64273.02
Iteration:    140, Loss function: 9.253, Average Loss: 1.740, avg. samples / sec: 64227.76
Iteration:    140, Loss function: 8.622, Average Loss: 1.736, avg. samples / sec: 64239.79
Iteration:    140, Loss function: 8.855, Average Loss: 1.734, avg. samples / sec: 64603.30
Iteration:    140, Loss function: 8.565, Average Loss: 1.731, avg. samples / sec: 64107.15
Iteration:    140, Loss function: 8.488, Average Loss: 1.741, avg. samples / sec: 64108.35
Iteration:    140, Loss function: 8.965, Average Loss: 1.758, avg. samples / sec: 64068.19
Iteration:    140, Loss function: 9.024, Average Loss: 1.745, avg. samples / sec: 64114.74
Iteration:    140, Loss function: 8.741, Average Loss: 1.746, avg. samples / sec: 64292.57
Iteration:    140, Loss function: 7.691, Average Loss: 1.757, avg. samples / sec: 64301.52
Iteration:    140, Loss function: 9.459, Average Loss: 1.734, avg. samples / sec: 64276.74
Iteration:    140, Loss function: 9.137, Average Loss: 1.739, avg. samples / sec: 64142.98
Iteration:    140, Loss function: 9.263, Average Loss: 1.726, avg. samples / sec: 64316.75
Iteration:    140, Loss function: 9.413, Average Loss: 1.744, avg. samples / sec: 63928.37
Iteration:    140, Loss function: 8.491, Average Loss: 1.749, avg. samples / sec: 64034.68
Iteration:    140, Loss function: 8.066, Average Loss: 1.741, avg. samples / sec: 63979.27
Iteration:    140, Loss function: 9.043, Average Loss: 1.745, avg. samples / sec: 63990.49
Iteration:    140, Loss function: 8.768, Average Loss: 1.743, avg. samples / sec: 64171.40
Iteration:    140, Loss function: 8.991, Average Loss: 1.739, avg. samples / sec: 64001.73
Iteration:    140, Loss function: 8.634, Average Loss: 1.741, avg. samples / sec: 64134.49
Iteration:    140, Loss function: 8.430, Average Loss: 1.737, avg. samples / sec: 63942.72
Iteration:    140, Loss function: 8.506, Average Loss: 1.753, avg. samples / sec: 64030.20
Iteration:    160, Loss function: 8.658, Average Loss: 1.874, avg. samples / sec: 65207.02
Iteration:    160, Loss function: 8.014, Average Loss: 1.881, avg. samples / sec: 65100.24
Iteration:    160, Loss function: 7.610, Average Loss: 1.878, avg. samples / sec: 65283.39
Iteration:    160, Loss function: 7.869, Average Loss: 1.866, avg. samples / sec: 65124.37
Iteration:    160, Loss function: 8.856, Average Loss: 1.869, avg. samples / sec: 65019.21
Iteration:    160, Loss function: 8.530, Average Loss: 1.874, avg. samples / sec: 65396.20
Iteration:    160, Loss function: 8.027, Average Loss: 1.871, avg. samples / sec: 65088.82
Iteration:    160, Loss function: 8.885, Average Loss: 1.878, avg. samples / sec: 65221.09
Iteration:    160, Loss function: 8.699, Average Loss: 1.878, avg. samples / sec: 65043.85
Iteration:    160, Loss function: 9.041, Average Loss: 1.881, avg. samples / sec: 65229.45
Iteration:    160, Loss function: 7.450, Average Loss: 1.868, avg. samples / sec: 65060.09
Iteration:    160, Loss function: 8.318, Average Loss: 1.872, avg. samples / sec: 64972.60
Iteration:    160, Loss function: 8.872, Average Loss: 1.867, avg. samples / sec: 65042.13
Iteration:    160, Loss function: 8.767, Average Loss: 1.877, avg. samples / sec: 65274.04
Iteration:    160, Loss function: 8.651, Average Loss: 1.876, avg. samples / sec: 65020.44
Iteration:    160, Loss function: 8.143, Average Loss: 1.876, avg. samples / sec: 64944.69
Iteration:    160, Loss function: 8.263, Average Loss: 1.863, avg. samples / sec: 65121.18
Iteration:    160, Loss function: 9.184, Average Loss: 1.879, avg. samples / sec: 65197.34
Iteration:    160, Loss function: 8.445, Average Loss: 1.883, avg. samples / sec: 65109.57
Iteration:    160, Loss function: 8.358, Average Loss: 1.880, avg. samples / sec: 64906.67
Iteration:    160, Loss function: 9.449, Average Loss: 1.885, avg. samples / sec: 64970.26
Iteration:    160, Loss function: 8.344, Average Loss: 1.892, avg. samples / sec: 64963.94
Iteration:    160, Loss function: 8.070, Average Loss: 1.878, avg. samples / sec: 65021.31
Iteration:    160, Loss function: 8.604, Average Loss: 1.870, avg. samples / sec: 64950.08
Iteration:    160, Loss function: 7.486, Average Loss: 1.872, avg. samples / sec: 64801.20
Iteration:    160, Loss function: 8.624, Average Loss: 1.865, avg. samples / sec: 64692.92
Iteration:    160, Loss function: 8.656, Average Loss: 1.887, avg. samples / sec: 64877.27
Iteration:    160, Loss function: 8.326, Average Loss: 1.892, avg. samples / sec: 65134.66
Iteration:    160, Loss function: 8.535, Average Loss: 1.900, avg. samples / sec: 64769.75
Iteration:    160, Loss function: 7.414, Average Loss: 1.877, avg. samples / sec: 64900.16
Iteration:    180, Loss function: 8.547, Average Loss: 2.001, avg. samples / sec: 65384.43
Iteration:    180, Loss function: 8.266, Average Loss: 2.012, avg. samples / sec: 65540.88
Iteration:    180, Loss function: 9.027, Average Loss: 2.020, avg. samples / sec: 65569.94
Iteration:    180, Loss function: 8.322, Average Loss: 1.999, avg. samples / sec: 65655.20
Iteration:    180, Loss function: 8.490, Average Loss: 2.011, avg. samples / sec: 65630.31
Iteration:    180, Loss function: 8.171, Average Loss: 2.000, avg. samples / sec: 65365.26
Iteration:    180, Loss function: 8.632, Average Loss: 2.011, avg. samples / sec: 65349.23
Iteration:    180, Loss function: 8.615, Average Loss: 2.013, avg. samples / sec: 65480.88
Iteration:    180, Loss function: 8.877, Average Loss: 2.006, avg. samples / sec: 65600.03
Iteration:    180, Loss function: 8.647, Average Loss: 2.009, avg. samples / sec: 65402.18
Iteration:    180, Loss function: 8.373, Average Loss: 2.010, avg. samples / sec: 65198.73
Iteration:    180, Loss function: 8.966, Average Loss: 2.008, avg. samples / sec: 65302.11
Iteration:    180, Loss function: 9.597, Average Loss: 2.026, avg. samples / sec: 65637.49
Iteration:    180, Loss function: 9.978, Average Loss: 2.017, avg. samples / sec: 65428.53
Iteration:    180, Loss function: 8.791, Average Loss: 2.006, avg. samples / sec: 65371.17
Iteration:    180, Loss function: 8.912, Average Loss: 2.009, avg. samples / sec: 65290.01
Iteration:    180, Loss function: 9.113, Average Loss: 2.002, avg. samples / sec: 65297.30
Iteration:    180, Loss function: 8.648, Average Loss: 2.010, avg. samples / sec: 65230.38
Iteration:    180, Loss function: 10.143, Average Loss: 2.038, avg. samples / sec: 65584.00
Iteration:    180, Loss function: 9.031, Average Loss: 2.000, avg. samples / sec: 65239.50
Iteration:    180, Loss function: 9.557, Average Loss: 2.003, avg. samples / sec: 65204.07
Iteration:    180, Loss function: 8.464, Average Loss: 2.012, avg. samples / sec: 65109.21
Iteration:    180, Loss function: 9.938, Average Loss: 1.996, avg. samples / sec: 65279.27
Iteration:    180, Loss function: 8.890, Average Loss: 2.014, avg. samples / sec: 65501.79
Iteration:    180, Loss function: 8.523, Average Loss: 2.017, avg. samples / sec: 65444.27
Iteration:    180, Loss function: 9.777, Average Loss: 1.997, avg. samples / sec: 65131.59
Iteration:    180, Loss function: 8.831, Average Loss: 2.000, avg. samples / sec: 65405.94
Iteration:    180, Loss function: 9.056, Average Loss: 2.009, avg. samples / sec: 65154.75
Iteration:    180, Loss function: 8.691, Average Loss: 2.011, avg. samples / sec: 65009.55
Iteration:    180, Loss function: 9.091, Average Loss: 2.025, avg. samples / sec: 65101.51
Iteration:    200, Loss function: 7.817, Average Loss: 2.136, avg. samples / sec: 65482.16
Iteration:    200, Loss function: 9.091, Average Loss: 2.142, avg. samples / sec: 65373.63
Iteration:    200, Loss function: 8.281, Average Loss: 2.135, avg. samples / sec: 65612.62
Iteration:    200, Loss function: 8.281, Average Loss: 2.140, avg. samples / sec: 65361.44
Iteration:    200, Loss function: 8.680, Average Loss: 2.129, avg. samples / sec: 65319.06
Iteration:    200, Loss function: 7.400, Average Loss: 2.134, avg. samples / sec: 65464.49
Iteration:    200, Loss function: 8.546, Average Loss: 2.131, avg. samples / sec: 65320.39
Iteration:    200, Loss function: 8.210, Average Loss: 2.167, avg. samples / sec: 65458.50
Iteration:    200, Loss function: 7.613, Average Loss: 2.135, avg. samples / sec: 65385.88
Iteration:    200, Loss function: 7.370, Average Loss: 2.137, avg. samples / sec: 65282.33
Iteration:    200, Loss function: 9.205, Average Loss: 2.144, avg. samples / sec: 65278.40
Iteration:    200, Loss function: 8.002, Average Loss: 2.129, avg. samples / sec: 65408.13
Iteration:    200, Loss function: 8.270, Average Loss: 2.144, avg. samples / sec: 65491.81
Iteration:    200, Loss function: 8.256, Average Loss: 2.135, avg. samples / sec: 65311.43
Iteration:    200, Loss function: 7.146, Average Loss: 2.126, avg. samples / sec: 65435.89
Iteration:    200, Loss function: 7.492, Average Loss: 2.130, avg. samples / sec: 65307.13
Iteration:    200, Loss function: 8.287, Average Loss: 2.134, avg. samples / sec: 65273.23
Iteration:    200, Loss function: 8.194, Average Loss: 2.147, avg. samples / sec: 65210.73
Iteration:    200, Loss function: 8.350, Average Loss: 2.141, avg. samples / sec: 65415.41
Iteration:    200, Loss function: 9.135, Average Loss: 2.144, avg. samples / sec: 65429.29
Iteration:    200, Loss function: 8.472, Average Loss: 2.139, avg. samples / sec: 65486.85
Iteration:    200, Loss function: 7.404, Average Loss: 2.125, avg. samples / sec: 65163.79
Iteration:    200, Loss function: 8.593, Average Loss: 2.130, avg. samples / sec: 65359.44
Iteration:    200, Loss function: 7.813, Average Loss: 2.157, avg. samples / sec: 65671.29
Iteration:    200, Loss function: 9.421, Average Loss: 2.127, avg. samples / sec: 65143.39
Iteration:    200, Loss function: 8.462, Average Loss: 2.148, avg. samples / sec: 65207.11
Iteration:    200, Loss function: 7.821, Average Loss: 2.128, avg. samples / sec: 65346.59
Iteration:    200, Loss function: 8.456, Average Loss: 2.137, avg. samples / sec: 65175.27
Iteration:    200, Loss function: 8.673, Average Loss: 2.145, avg. samples / sec: 65298.42
Iteration:    200, Loss function: 7.932, Average Loss: 2.157, avg. samples / sec: 65014.44
:::MLL 1558651362.699 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558651362.700 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 8.409, Average Loss: 2.257, avg. samples / sec: 65535.70
Iteration:    220, Loss function: 8.255, Average Loss: 2.257, avg. samples / sec: 65732.92
Iteration:    220, Loss function: 8.389, Average Loss: 2.249, avg. samples / sec: 65641.46
Iteration:    220, Loss function: 9.115, Average Loss: 2.255, avg. samples / sec: 65562.07
Iteration:    220, Loss function: 9.214, Average Loss: 2.253, avg. samples / sec: 65521.34
Iteration:    220, Loss function: 8.798, Average Loss: 2.251, avg. samples / sec: 65660.06
Iteration:    220, Loss function: 8.004, Average Loss: 2.245, avg. samples / sec: 65521.71
Iteration:    220, Loss function: 7.888, Average Loss: 2.241, avg. samples / sec: 65566.25
Iteration:    220, Loss function: 8.539, Average Loss: 2.241, avg. samples / sec: 65603.97
Iteration:    220, Loss function: 8.398, Average Loss: 2.254, avg. samples / sec: 65571.13
Iteration:    220, Loss function: 8.441, Average Loss: 2.261, avg. samples / sec: 65531.06
Iteration:    220, Loss function: 8.354, Average Loss: 2.251, avg. samples / sec: 65356.08
Iteration:    220, Loss function: 8.259, Average Loss: 2.260, avg. samples / sec: 65549.69
Iteration:    220, Loss function: 8.840, Average Loss: 2.248, avg. samples / sec: 65463.27
Iteration:    220, Loss function: 8.075, Average Loss: 2.274, avg. samples / sec: 65823.33
Iteration:    220, Loss function: 8.445, Average Loss: 2.269, avg. samples / sec: 65523.11
Iteration:    220, Loss function: 9.144, Average Loss: 2.256, avg. samples / sec: 65636.02
Iteration:    220, Loss function: 9.112, Average Loss: 2.249, avg. samples / sec: 65593.65
Iteration:    220, Loss function: 7.449, Average Loss: 2.259, avg. samples / sec: 65392.89
Iteration:    220, Loss function: 9.533, Average Loss: 2.254, avg. samples / sec: 65433.64
Iteration:    220, Loss function: 8.974, Average Loss: 2.264, avg. samples / sec: 65604.61
Iteration:    220, Loss function: 7.704, Average Loss: 2.251, avg. samples / sec: 65334.47
Iteration:    220, Loss function: 7.961, Average Loss: 2.274, avg. samples / sec: 65526.58
Iteration:    220, Loss function: 9.425, Average Loss: 2.290, avg. samples / sec: 65387.37
Iteration:    220, Loss function: 7.949, Average Loss: 2.245, avg. samples / sec: 65542.71
Iteration:    220, Loss function: 8.575, Average Loss: 2.250, avg. samples / sec: 65397.87
Iteration:    220, Loss function: 8.956, Average Loss: 2.258, avg. samples / sec: 65643.64
Iteration:    220, Loss function: 8.028, Average Loss: 2.245, avg. samples / sec: 65354.95
Iteration:    220, Loss function: 8.198, Average Loss: 2.257, avg. samples / sec: 65280.21
Iteration:    220, Loss function: 7.920, Average Loss: 2.262, avg. samples / sec: 65334.50
Iteration:    240, Loss function: 7.404, Average Loss: 2.358, avg. samples / sec: 65275.34
Iteration:    240, Loss function: 7.576, Average Loss: 2.378, avg. samples / sec: 65259.23
Iteration:    240, Loss function: 7.020, Average Loss: 2.403, avg. samples / sec: 65330.23
Iteration:    240, Loss function: 8.449, Average Loss: 2.369, avg. samples / sec: 65388.07
Iteration:    240, Loss function: 8.031, Average Loss: 2.374, avg. samples / sec: 65096.18
Iteration:    240, Loss function: 8.531, Average Loss: 2.387, avg. samples / sec: 65234.85
Iteration:    240, Loss function: 8.201, Average Loss: 2.371, avg. samples / sec: 65196.13
Iteration:    240, Loss function: 8.284, Average Loss: 2.375, avg. samples / sec: 65419.33
Iteration:    240, Loss function: 8.388, Average Loss: 2.363, avg. samples / sec: 65235.61
Iteration:    240, Loss function: 8.142, Average Loss: 2.370, avg. samples / sec: 65098.86
Iteration:    240, Loss function: 7.780, Average Loss: 2.374, avg. samples / sec: 65356.23
Iteration:    240, Loss function: 8.199, Average Loss: 2.371, avg. samples / sec: 65237.63
Iteration:    240, Loss function: 8.052, Average Loss: 2.387, avg. samples / sec: 65223.95
Iteration:    240, Loss function: 8.277, Average Loss: 2.369, avg. samples / sec: 65082.38
Iteration:    240, Loss function: 7.274, Average Loss: 2.376, avg. samples / sec: 65166.11
Iteration:    240, Loss function: 7.994, Average Loss: 2.373, avg. samples / sec: 65127.17
Iteration:    240, Loss function: 8.560, Average Loss: 2.370, avg. samples / sec: 65119.07
Iteration:    240, Loss function: 8.992, Average Loss: 2.377, avg. samples / sec: 65165.63
Iteration:    240, Loss function: 8.069, Average Loss: 2.370, avg. samples / sec: 65057.36
Iteration:    240, Loss function: 7.870, Average Loss: 2.364, avg. samples / sec: 65047.51
Iteration:    240, Loss function: 7.460, Average Loss: 2.390, avg. samples / sec: 65135.27
Iteration:    240, Loss function: 7.910, Average Loss: 2.382, avg. samples / sec: 64942.39
Iteration:    240, Loss function: 8.317, Average Loss: 2.361, avg. samples / sec: 65042.31
Iteration:    240, Loss function: 7.143, Average Loss: 2.392, avg. samples / sec: 65138.01
Iteration:    240, Loss function: 7.685, Average Loss: 2.368, avg. samples / sec: 65142.43
Iteration:    240, Loss function: 8.626, Average Loss: 2.366, avg. samples / sec: 65163.27
Iteration:    240, Loss function: 6.758, Average Loss: 2.363, avg. samples / sec: 65222.84
Iteration:    240, Loss function: 7.295, Average Loss: 2.371, avg. samples / sec: 64939.78
Iteration:    240, Loss function: 7.487, Average Loss: 2.380, avg. samples / sec: 65217.83
Iteration:    240, Loss function: 7.770, Average Loss: 2.375, avg. samples / sec: 64996.18
Iteration:    260, Loss function: 8.200, Average Loss: 2.494, avg. samples / sec: 65257.30
Iteration:    260, Loss function: 7.962, Average Loss: 2.474, avg. samples / sec: 65146.23
Iteration:    260, Loss function: 7.538, Average Loss: 2.468, avg. samples / sec: 64982.18
Iteration:    260, Loss function: 7.306, Average Loss: 2.479, avg. samples / sec: 65183.80
Iteration:    260, Loss function: 7.160, Average Loss: 2.479, avg. samples / sec: 65110.83
Iteration:    260, Loss function: 6.980, Average Loss: 2.482, avg. samples / sec: 64999.36
Iteration:    260, Loss function: 7.490, Average Loss: 2.488, avg. samples / sec: 65283.48
Iteration:    260, Loss function: 7.525, Average Loss: 2.492, avg. samples / sec: 65080.79
Iteration:    260, Loss function: 7.568, Average Loss: 2.480, avg. samples / sec: 65012.10
Iteration:    260, Loss function: 7.309, Average Loss: 2.469, avg. samples / sec: 65014.41
Iteration:    260, Loss function: 7.181, Average Loss: 2.477, avg. samples / sec: 65106.20
Iteration:    260, Loss function: 8.275, Average Loss: 2.468, avg. samples / sec: 65199.75
Iteration:    260, Loss function: 7.470, Average Loss: 2.491, avg. samples / sec: 65013.84
Iteration:    260, Loss function: 6.980, Average Loss: 2.479, avg. samples / sec: 65056.70
Iteration:    260, Loss function: 7.718, Average Loss: 2.475, avg. samples / sec: 65032.65
Iteration:    260, Loss function: 7.905, Average Loss: 2.467, avg. samples / sec: 65108.03
Iteration:    260, Loss function: 7.294, Average Loss: 2.481, avg. samples / sec: 65257.27
Iteration:    260, Loss function: 7.044, Average Loss: 2.478, avg. samples / sec: 65208.29
Iteration:    260, Loss function: 7.406, Average Loss: 2.478, avg. samples / sec: 65017.62
Iteration:    260, Loss function: 7.003, Average Loss: 2.474, avg. samples / sec: 65143.21
Iteration:    260, Loss function: 6.751, Average Loss: 2.493, avg. samples / sec: 65096.51
Iteration:    260, Loss function: 8.528, Average Loss: 2.497, avg. samples / sec: 65017.47
Iteration:    260, Loss function: 7.338, Average Loss: 2.481, avg. samples / sec: 64997.29
Iteration:    260, Loss function: 8.617, Average Loss: 2.482, avg. samples / sec: 64951.43
Iteration:    260, Loss function: 7.937, Average Loss: 2.468, avg. samples / sec: 65090.95
Iteration:    260, Loss function: 7.109, Average Loss: 2.479, avg. samples / sec: 64975.74
Iteration:    260, Loss function: 7.337, Average Loss: 2.511, avg. samples / sec: 64858.25
Iteration:    260, Loss function: 7.682, Average Loss: 2.484, avg. samples / sec: 64904.64
Iteration:    260, Loss function: 8.600, Average Loss: 2.468, avg. samples / sec: 64957.59
Iteration:    260, Loss function: 6.232, Average Loss: 2.468, avg. samples / sec: 64746.27
:::MLL 1558651364.504 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558651364.505 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 8.396, Average Loss: 2.574, avg. samples / sec: 65154.69
Iteration:    280, Loss function: 7.863, Average Loss: 2.585, avg. samples / sec: 65213.00
Iteration:    280, Loss function: 8.134, Average Loss: 2.570, avg. samples / sec: 65432.39
Iteration:    280, Loss function: 8.006, Average Loss: 2.586, avg. samples / sec: 65195.44
Iteration:    280, Loss function: 8.135, Average Loss: 2.604, avg. samples / sec: 65309.13
Iteration:    280, Loss function: 9.329, Average Loss: 2.581, avg. samples / sec: 65200.69
Iteration:    280, Loss function: 7.650, Average Loss: 2.590, avg. samples / sec: 65145.38
Iteration:    280, Loss function: 7.546, Average Loss: 2.577, avg. samples / sec: 65209.47
Iteration:    280, Loss function: 7.997, Average Loss: 2.584, avg. samples / sec: 65091.55
Iteration:    280, Loss function: 8.250, Average Loss: 2.599, avg. samples / sec: 65045.02
Iteration:    280, Loss function: 7.321, Average Loss: 2.582, avg. samples / sec: 65137.22
Iteration:    280, Loss function: 10.257, Average Loss: 2.576, avg. samples / sec: 65150.11
Iteration:    280, Loss function: 7.449, Average Loss: 2.582, avg. samples / sec: 65214.93
Iteration:    280, Loss function: 8.563, Average Loss: 2.582, avg. samples / sec: 65125.72
Iteration:    280, Loss function: 7.439, Average Loss: 2.575, avg. samples / sec: 65397.38
Iteration:    280, Loss function: 8.113, Average Loss: 2.589, avg. samples / sec: 65293.70
Iteration:    280, Loss function: 7.540, Average Loss: 2.593, avg. samples / sec: 65092.09
Iteration:    280, Loss function: 7.809, Average Loss: 2.584, avg. samples / sec: 65091.07
Iteration:    280, Loss function: 7.889, Average Loss: 2.574, avg. samples / sec: 64977.87
Iteration:    280, Loss function: 7.639, Average Loss: 2.572, avg. samples / sec: 65165.78
Iteration:    280, Loss function: 7.852, Average Loss: 2.570, avg. samples / sec: 65019.54
Iteration:    280, Loss function: 8.617, Average Loss: 2.586, avg. samples / sec: 65063.73
Iteration:    280, Loss function: 8.479, Average Loss: 2.596, avg. samples / sec: 65111.19
Iteration:    280, Loss function: 8.294, Average Loss: 2.619, avg. samples / sec: 65137.97
Iteration:    280, Loss function: 8.944, Average Loss: 2.594, avg. samples / sec: 64973.08
Iteration:    280, Loss function: 8.564, Average Loss: 2.585, avg. samples / sec: 65097.93
Iteration:    280, Loss function: 7.968, Average Loss: 2.587, avg. samples / sec: 64888.20
Iteration:    280, Loss function: 8.569, Average Loss: 2.586, avg. samples / sec: 65057.72
Iteration:    280, Loss function: 7.158, Average Loss: 2.575, avg. samples / sec: 64929.07
Iteration:    280, Loss function: 7.957, Average Loss: 2.583, avg. samples / sec: 64873.93
Iteration:    300, Loss function: 7.920, Average Loss: 2.679, avg. samples / sec: 66114.69
Iteration:    300, Loss function: 7.744, Average Loss: 2.680, avg. samples / sec: 66060.27
Iteration:    300, Loss function: 7.167, Average Loss: 2.676, avg. samples / sec: 65952.10
Iteration:    300, Loss function: 8.493, Average Loss: 2.684, avg. samples / sec: 65960.65
Iteration:    300, Loss function: 7.822, Average Loss: 2.683, avg. samples / sec: 66024.71
Iteration:    300, Loss function: 7.897, Average Loss: 2.706, avg. samples / sec: 65912.06
Iteration:    300, Loss function: 7.369, Average Loss: 2.698, avg. samples / sec: 65974.08
Iteration:    300, Loss function: 6.591, Average Loss: 2.692, avg. samples / sec: 66119.62
Iteration:    300, Loss function: 7.049, Average Loss: 2.719, avg. samples / sec: 66134.67
Iteration:    300, Loss function: 6.391, Average Loss: 2.684, avg. samples / sec: 65887.07
Iteration:    300, Loss function: 8.407, Average Loss: 2.679, avg. samples / sec: 65929.66
Iteration:    300, Loss function: 7.150, Average Loss: 2.681, avg. samples / sec: 65927.97
Iteration:    300, Loss function: 7.482, Average Loss: 2.692, avg. samples / sec: 66005.13
Iteration:    300, Loss function: 7.998, Average Loss: 2.686, avg. samples / sec: 66151.87
Iteration:    300, Loss function: 6.949, Average Loss: 2.683, avg. samples / sec: 66149.35
Iteration:    300, Loss function: 6.704, Average Loss: 2.676, avg. samples / sec: 65918.35
Iteration:    300, Loss function: 8.596, Average Loss: 2.674, avg. samples / sec: 66038.07
Iteration:    300, Loss function: 8.257, Average Loss: 2.686, avg. samples / sec: 66109.14
Iteration:    300, Loss function: 7.389, Average Loss: 2.675, avg. samples / sec: 66140.01
Iteration:    300, Loss function: 6.592, Average Loss: 2.668, avg. samples / sec: 66024.65
Iteration:    300, Loss function: 8.380, Average Loss: 2.682, avg. samples / sec: 66152.46
Iteration:    300, Loss function: 8.337, Average Loss: 2.688, avg. samples / sec: 66017.16
Iteration:    300, Loss function: 8.011, Average Loss: 2.671, avg. samples / sec: 65797.37
Iteration:    300, Loss function: 8.052, Average Loss: 2.683, avg. samples / sec: 65937.69
Iteration:    300, Loss function: 6.965, Average Loss: 2.686, avg. samples / sec: 65830.59
Iteration:    300, Loss function: 7.233, Average Loss: 2.671, avg. samples / sec: 65938.12
Iteration:    300, Loss function: 7.236, Average Loss: 2.679, avg. samples / sec: 65866.19
Iteration:    300, Loss function: 6.086, Average Loss: 2.670, avg. samples / sec: 65860.06
Iteration:    300, Loss function: 7.587, Average Loss: 2.690, avg. samples / sec: 65863.45
Iteration:    300, Loss function: 7.555, Average Loss: 2.692, avg. samples / sec: 65856.92
Iteration:    320, Loss function: 7.768, Average Loss: 2.769, avg. samples / sec: 65579.00
Iteration:    320, Loss function: 7.509, Average Loss: 2.774, avg. samples / sec: 65620.38
Iteration:    320, Loss function: 7.737, Average Loss: 2.763, avg. samples / sec: 65596.73
Iteration:    320, Loss function: 6.513, Average Loss: 2.778, avg. samples / sec: 65535.45
Iteration:    320, Loss function: 7.069, Average Loss: 2.771, avg. samples / sec: 65542.37
Iteration:    320, Loss function: 7.303, Average Loss: 2.780, avg. samples / sec: 65647.15
Iteration:    320, Loss function: 7.564, Average Loss: 2.781, avg. samples / sec: 65562.01
Iteration:    320, Loss function: 7.098, Average Loss: 2.766, avg. samples / sec: 65560.85
Iteration:    320, Loss function: 7.205, Average Loss: 2.771, avg. samples / sec: 65465.95
Iteration:    320, Loss function: 6.777, Average Loss: 2.768, avg. samples / sec: 65561.55
Iteration:    320, Loss function: 8.259, Average Loss: 2.761, avg. samples / sec: 65653.27
Iteration:    320, Loss function: 6.962, Average Loss: 2.771, avg. samples / sec: 65439.20
Iteration:    320, Loss function: 6.440, Average Loss: 2.796, avg. samples / sec: 65474.68
Iteration:    320, Loss function: 6.232, Average Loss: 2.770, avg. samples / sec: 65412.47
Iteration:    320, Loss function: 7.707, Average Loss: 2.811, avg. samples / sec: 65480.12
Iteration:    320, Loss function: 6.364, Average Loss: 2.771, avg. samples / sec: 65488.37
Iteration:    320, Loss function: 6.304, Average Loss: 2.773, avg. samples / sec: 65495.19
Iteration:    320, Loss function: 8.971, Average Loss: 2.783, avg. samples / sec: 65635.14
Iteration:    320, Loss function: 7.084, Average Loss: 2.769, avg. samples / sec: 65469.36
Iteration:    320, Loss function: 7.410, Average Loss: 2.766, avg. samples / sec: 65567.13
Iteration:    320, Loss function: 8.368, Average Loss: 2.788, avg. samples / sec: 65421.00
Iteration:    320, Loss function: 6.436, Average Loss: 2.770, avg. samples / sec: 65576.07
Iteration:    320, Loss function: 5.874, Average Loss: 2.770, avg. samples / sec: 65330.63
Iteration:    320, Loss function: 7.965, Average Loss: 2.778, avg. samples / sec: 65512.69
Iteration:    320, Loss function: 7.234, Average Loss: 2.785, avg. samples / sec: 65650.55
Iteration:    320, Loss function: 7.714, Average Loss: 2.763, avg. samples / sec: 65475.77
Iteration:    320, Loss function: 6.299, Average Loss: 2.772, avg. samples / sec: 65361.02
Iteration:    320, Loss function: 6.458, Average Loss: 2.760, avg. samples / sec: 65496.01
Iteration:    320, Loss function: 7.150, Average Loss: 2.777, avg. samples / sec: 65497.32
Iteration:    320, Loss function: 7.016, Average Loss: 2.760, avg. samples / sec: 65402.00
Iteration:    340, Loss function: 6.268, Average Loss: 2.871, avg. samples / sec: 66162.40
Iteration:    340, Loss function: 7.382, Average Loss: 2.856, avg. samples / sec: 66206.28
Iteration:    340, Loss function: 7.664, Average Loss: 2.859, avg. samples / sec: 66189.24
Iteration:    340, Loss function: 5.877, Average Loss: 2.861, avg. samples / sec: 66142.99
Iteration:    340, Loss function: 7.560, Average Loss: 2.853, avg. samples / sec: 66058.75
Iteration:    340, Loss function: 6.266, Average Loss: 2.861, avg. samples / sec: 66064.23
Iteration:    340, Loss function: 7.432, Average Loss: 2.862, avg. samples / sec: 66230.68
Iteration:    340, Loss function: 6.906, Average Loss: 2.859, avg. samples / sec: 66108.92
Iteration:    340, Loss function: 7.553, Average Loss: 2.873, avg. samples / sec: 66085.82
Iteration:    340, Loss function: 7.374, Average Loss: 2.882, avg. samples / sec: 66137.34
Iteration:    340, Loss function: 7.456, Average Loss: 2.855, avg. samples / sec: 66216.83
Iteration:    340, Loss function: 7.265, Average Loss: 2.880, avg. samples / sec: 66191.08
Iteration:    340, Loss function: 6.778, Average Loss: 2.850, avg. samples / sec: 66200.25
Iteration:    340, Loss function: 8.090, Average Loss: 2.861, avg. samples / sec: 66035.47
Iteration:    340, Loss function: 8.227, Average Loss: 2.858, avg. samples / sec: 66057.67
Iteration:    340, Loss function: 7.333, Average Loss: 2.865, avg. samples / sec: 66079.47
Iteration:    340, Loss function: 6.620, Average Loss: 2.862, avg. samples / sec: 66077.43
Iteration:    340, Loss function: 7.390, Average Loss: 2.856, avg. samples / sec: 65972.44
Iteration:    340, Loss function: 7.067, Average Loss: 2.858, avg. samples / sec: 65971.85
Iteration:    340, Loss function: 7.285, Average Loss: 2.877, avg. samples / sec: 66060.42
Iteration:    340, Loss function: 7.676, Average Loss: 2.905, avg. samples / sec: 65998.30
Iteration:    340, Loss function: 8.184, Average Loss: 2.866, avg. samples / sec: 65945.86
Iteration:    340, Loss function: 7.004, Average Loss: 2.850, avg. samples / sec: 66128.12
Iteration:    340, Loss function: 8.169, Average Loss: 2.854, avg. samples / sec: 66035.07
Iteration:    340, Loss function: 7.079, Average Loss: 2.860, avg. samples / sec: 65980.38
Iteration:    340, Loss function: 7.391, Average Loss: 2.861, avg. samples / sec: 66024.12
Iteration:    340, Loss function: 7.774, Average Loss: 2.868, avg. samples / sec: 65939.23
Iteration:    340, Loss function: 7.889, Average Loss: 2.864, avg. samples / sec: 65814.20
Iteration:    340, Loss function: 7.374, Average Loss: 2.876, avg. samples / sec: 65919.30
Iteration:    340, Loss function: 7.271, Average Loss: 2.870, avg. samples / sec: 66006.25
:::MLL 1558651366.291 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558651366.291 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 6.002, Average Loss: 2.942, avg. samples / sec: 66181.94
Iteration:    360, Loss function: 7.401, Average Loss: 2.950, avg. samples / sec: 66286.10
Iteration:    360, Loss function: 7.904, Average Loss: 2.946, avg. samples / sec: 66174.64
Iteration:    360, Loss function: 6.371, Average Loss: 2.943, avg. samples / sec: 66140.41
Iteration:    360, Loss function: 5.990, Average Loss: 2.955, avg. samples / sec: 66225.29
Iteration:    360, Loss function: 6.920, Average Loss: 2.939, avg. samples / sec: 65917.88
Iteration:    360, Loss function: 7.820, Average Loss: 2.968, avg. samples / sec: 65955.95
Iteration:    360, Loss function: 5.993, Average Loss: 2.945, avg. samples / sec: 66103.86
Iteration:    360, Loss function: 7.131, Average Loss: 2.942, avg. samples / sec: 65985.11
Iteration:    360, Loss function: 6.540, Average Loss: 2.941, avg. samples / sec: 65933.40
Iteration:    360, Loss function: 7.161, Average Loss: 2.958, avg. samples / sec: 65935.93
Iteration:    360, Loss function: 6.200, Average Loss: 2.935, avg. samples / sec: 66089.85
Iteration:    360, Loss function: 6.718, Average Loss: 2.964, avg. samples / sec: 65930.03
Iteration:    360, Loss function: 6.943, Average Loss: 2.938, avg. samples / sec: 65911.10
Iteration:    360, Loss function: 7.115, Average Loss: 2.933, avg. samples / sec: 66063.36
Iteration:    360, Loss function: 6.336, Average Loss: 2.944, avg. samples / sec: 66072.44
Iteration:    360, Loss function: 7.316, Average Loss: 2.948, avg. samples / sec: 65885.68
Iteration:    360, Loss function: 5.234, Average Loss: 2.947, avg. samples / sec: 66113.97
Iteration:    360, Loss function: 7.046, Average Loss: 2.941, avg. samples / sec: 65885.93
Iteration:    360, Loss function: 8.527, Average Loss: 2.944, avg. samples / sec: 65830.99
Iteration:    360, Loss function: 8.117, Average Loss: 2.954, avg. samples / sec: 65814.97
Iteration:    360, Loss function: 7.256, Average Loss: 2.940, avg. samples / sec: 65866.40
Iteration:    360, Loss function: 6.053, Average Loss: 2.941, avg. samples / sec: 65929.66
Iteration:    360, Loss function: 6.382, Average Loss: 2.943, avg. samples / sec: 65830.65
Iteration:    360, Loss function: 6.891, Average Loss: 2.926, avg. samples / sec: 65881.31
Iteration:    360, Loss function: 7.812, Average Loss: 2.958, avg. samples / sec: 66071.48
Iteration:    360, Loss function: 8.091, Average Loss: 2.950, avg. samples / sec: 65911.35
Iteration:    360, Loss function: 6.475, Average Loss: 2.962, avg. samples / sec: 65947.47
Iteration:    360, Loss function: 7.406, Average Loss: 2.950, avg. samples / sec: 65911.41
Iteration:    360, Loss function: 7.115, Average Loss: 2.993, avg. samples / sec: 65284.81
Iteration:    380, Loss function: 6.369, Average Loss: 3.014, avg. samples / sec: 65088.88
Iteration:    380, Loss function: 6.707, Average Loss: 3.027, avg. samples / sec: 65186.88
Iteration:    380, Loss function: 7.119, Average Loss: 3.022, avg. samples / sec: 65056.67
Iteration:    380, Loss function: 6.752, Average Loss: 3.015, avg. samples / sec: 65030.88
Iteration:    380, Loss function: 5.941, Average Loss: 3.026, avg. samples / sec: 65147.52
Iteration:    380, Loss function: 6.520, Average Loss: 3.019, avg. samples / sec: 65053.60
Iteration:    380, Loss function: 6.108, Average Loss: 3.017, avg. samples / sec: 64984.34
Iteration:    380, Loss function: 7.417, Average Loss: 3.025, avg. samples / sec: 64916.72
Iteration:    380, Loss function: 6.724, Average Loss: 3.020, avg. samples / sec: 64980.62
Iteration:    380, Loss function: 7.756, Average Loss: 3.030, avg. samples / sec: 65005.23
Iteration:    380, Loss function: 6.700, Average Loss: 3.022, avg. samples / sec: 65013.15
Iteration:    380, Loss function: 6.395, Average Loss: 3.024, avg. samples / sec: 64847.54
Iteration:    380, Loss function: 6.282, Average Loss: 3.026, avg. samples / sec: 64982.15
Iteration:    380, Loss function: 6.549, Average Loss: 3.070, avg. samples / sec: 65732.61
Iteration:    380, Loss function: 7.070, Average Loss: 3.045, avg. samples / sec: 64936.70
Iteration:    380, Loss function: 7.205, Average Loss: 3.030, avg. samples / sec: 64801.74
Iteration:    380, Loss function: 6.183, Average Loss: 3.044, avg. samples / sec: 64915.88
Iteration:    380, Loss function: 6.515, Average Loss: 3.022, avg. samples / sec: 64934.25
Iteration:    380, Loss function: 7.043, Average Loss: 3.026, avg. samples / sec: 64907.30
Iteration:    380, Loss function: 6.840, Average Loss: 3.009, avg. samples / sec: 64911.49
Iteration:    380, Loss function: 6.293, Average Loss: 3.015, avg. samples / sec: 64966.70
Iteration:    380, Loss function: 6.498, Average Loss: 3.038, avg. samples / sec: 64999.87
Iteration:    380, Loss function: 6.905, Average Loss: 3.007, avg. samples / sec: 64981.19
Iteration:    380, Loss function: 7.365, Average Loss: 3.032, avg. samples / sec: 65023.35
Iteration:    380, Loss function: 5.875, Average Loss: 3.022, avg. samples / sec: 64871.12
Iteration:    380, Loss function: 6.602, Average Loss: 3.033, avg. samples / sec: 64780.41
Iteration:    380, Loss function: 6.586, Average Loss: 3.045, avg. samples / sec: 64919.86
Iteration:    380, Loss function: 7.314, Average Loss: 3.032, avg. samples / sec: 64840.32
Iteration:    380, Loss function: 6.328, Average Loss: 3.041, avg. samples / sec: 64778.32
Iteration:    380, Loss function: 7.208, Average Loss: 3.023, avg. samples / sec: 64552.73
Iteration:    400, Loss function: 6.527, Average Loss: 3.093, avg. samples / sec: 66353.32
Iteration:    400, Loss function: 7.308, Average Loss: 3.103, avg. samples / sec: 66398.62
Iteration:    400, Loss function: 7.303, Average Loss: 3.104, avg. samples / sec: 66519.09
Iteration:    400, Loss function: 8.275, Average Loss: 3.096, avg. samples / sec: 66382.39
Iteration:    400, Loss function: 6.052, Average Loss: 3.087, avg. samples / sec: 66361.41
Iteration:    400, Loss function: 6.771, Average Loss: 3.096, avg. samples / sec: 66116.15
Iteration:    400, Loss function: 7.188, Average Loss: 3.095, avg. samples / sec: 66353.98
Iteration:    400, Loss function: 6.460, Average Loss: 3.089, avg. samples / sec: 66103.86
Iteration:    400, Loss function: 7.448, Average Loss: 3.096, avg. samples / sec: 66577.48
Iteration:    400, Loss function: 6.718, Average Loss: 3.118, avg. samples / sec: 66275.00
Iteration:    400, Loss function: 7.455, Average Loss: 3.098, avg. samples / sec: 66210.48
Iteration:    400, Loss function: 6.146, Average Loss: 3.109, avg. samples / sec: 66373.13
Iteration:    400, Loss function: 6.367, Average Loss: 3.101, avg. samples / sec: 66182.72
Iteration:    400, Loss function: 6.590, Average Loss: 3.090, avg. samples / sec: 66147.15
Iteration:    400, Loss function: 6.633, Average Loss: 3.095, avg. samples / sec: 66260.98
Iteration:    400, Loss function: 5.735, Average Loss: 3.096, avg. samples / sec: 66200.03
Iteration:    400, Loss function: 6.575, Average Loss: 3.095, avg. samples / sec: 66139.60
Iteration:    400, Loss function: 7.622, Average Loss: 3.119, avg. samples / sec: 66372.23
Iteration:    400, Loss function: 6.061, Average Loss: 3.102, avg. samples / sec: 66178.05
Iteration:    400, Loss function: 7.378, Average Loss: 3.095, avg. samples / sec: 66166.65
Iteration:    400, Loss function: 6.687, Average Loss: 3.095, avg. samples / sec: 66167.58
Iteration:    400, Loss function: 6.981, Average Loss: 3.082, avg. samples / sec: 66243.22
Iteration:    400, Loss function: 7.457, Average Loss: 3.100, avg. samples / sec: 66128.09
Iteration:    400, Loss function: 7.324, Average Loss: 3.101, avg. samples / sec: 66165.00
Iteration:    400, Loss function: 6.474, Average Loss: 3.103, avg. samples / sec: 66205.51
Iteration:    400, Loss function: 6.800, Average Loss: 3.148, avg. samples / sec: 66143.17
Iteration:    400, Loss function: 7.535, Average Loss: 3.119, avg. samples / sec: 66150.07
Iteration:    400, Loss function: 6.552, Average Loss: 3.115, avg. samples / sec: 66159.13
Iteration:    400, Loss function: 5.995, Average Loss: 3.078, avg. samples / sec: 66159.57
Iteration:    400, Loss function: 7.048, Average Loss: 3.121, avg. samples / sec: 66183.31
:::MLL 1558651368.077 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558651368.078 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 6.080, Average Loss: 3.167, avg. samples / sec: 66272.94
Iteration:    420, Loss function: 7.757, Average Loss: 3.175, avg. samples / sec: 66257.77
Iteration:    420, Loss function: 6.365, Average Loss: 3.193, avg. samples / sec: 66203.17
Iteration:    420, Loss function: 6.760, Average Loss: 3.164, avg. samples / sec: 66194.22
Iteration:    420, Loss function: 7.123, Average Loss: 3.177, avg. samples / sec: 66279.24
Iteration:    420, Loss function: 6.249, Average Loss: 3.170, avg. samples / sec: 66203.02
Iteration:    420, Loss function: 6.793, Average Loss: 3.172, avg. samples / sec: 66153.02
Iteration:    420, Loss function: 6.636, Average Loss: 3.176, avg. samples / sec: 66025.88
Iteration:    420, Loss function: 6.946, Average Loss: 3.187, avg. samples / sec: 66296.07
Iteration:    420, Loss function: 7.130, Average Loss: 3.194, avg. samples / sec: 66269.23
Iteration:    420, Loss function: 7.908, Average Loss: 3.171, avg. samples / sec: 66161.59
Iteration:    420, Loss function: 6.103, Average Loss: 3.168, avg. samples / sec: 66180.42
Iteration:    420, Loss function: 6.053, Average Loss: 3.191, avg. samples / sec: 66100.39
Iteration:    420, Loss function: 7.926, Average Loss: 3.151, avg. samples / sec: 66259.01
Iteration:    420, Loss function: 6.165, Average Loss: 3.171, avg. samples / sec: 66072.22
Iteration:    420, Loss function: 7.965, Average Loss: 3.163, avg. samples / sec: 66067.27
Iteration:    420, Loss function: 6.562, Average Loss: 3.165, avg. samples / sec: 65988.75
Iteration:    420, Loss function: 6.711, Average Loss: 3.175, avg. samples / sec: 65967.38
Iteration:    420, Loss function: 7.857, Average Loss: 3.167, avg. samples / sec: 66097.73
Iteration:    420, Loss function: 6.285, Average Loss: 3.224, avg. samples / sec: 66163.14
Iteration:    420, Loss function: 6.972, Average Loss: 3.172, avg. samples / sec: 66025.08
Iteration:    420, Loss function: 6.836, Average Loss: 3.168, avg. samples / sec: 65902.35
Iteration:    420, Loss function: 5.843, Average Loss: 3.176, avg. samples / sec: 66056.06
Iteration:    420, Loss function: 6.233, Average Loss: 3.169, avg. samples / sec: 65980.16
Iteration:    420, Loss function: 7.406, Average Loss: 3.171, avg. samples / sec: 65996.97
Iteration:    420, Loss function: 6.635, Average Loss: 3.158, avg. samples / sec: 65844.62
Iteration:    420, Loss function: 6.865, Average Loss: 3.151, avg. samples / sec: 65903.06
Iteration:    420, Loss function: 7.379, Average Loss: 3.197, avg. samples / sec: 66080.62
Iteration:    420, Loss function: 7.163, Average Loss: 3.169, avg. samples / sec: 65920.23
Iteration:    420, Loss function: 6.305, Average Loss: 3.184, avg. samples / sec: 65677.07
Iteration:    440, Loss function: 6.438, Average Loss: 3.247, avg. samples / sec: 66238.65
Iteration:    440, Loss function: 5.489, Average Loss: 3.234, avg. samples / sec: 66222.87
Iteration:    440, Loss function: 6.522, Average Loss: 3.234, avg. samples / sec: 66219.78
Iteration:    440, Loss function: 5.807, Average Loss: 3.225, avg. samples / sec: 66330.62
Iteration:    440, Loss function: 5.201, Average Loss: 3.247, avg. samples / sec: 66067.24
Iteration:    440, Loss function: 5.666, Average Loss: 3.235, avg. samples / sec: 66139.67
Iteration:    440, Loss function: 6.373, Average Loss: 3.241, avg. samples / sec: 66089.60
Iteration:    440, Loss function: 8.273, Average Loss: 3.243, avg. samples / sec: 66262.72
Iteration:    440, Loss function: 7.636, Average Loss: 3.244, avg. samples / sec: 65967.81
Iteration:    440, Loss function: 6.268, Average Loss: 3.238, avg. samples / sec: 65998.76
Iteration:    440, Loss function: 5.519, Average Loss: 3.234, avg. samples / sec: 66056.61
Iteration:    440, Loss function: 7.195, Average Loss: 3.251, avg. samples / sec: 66087.75
Iteration:    440, Loss function: 6.831, Average Loss: 3.264, avg. samples / sec: 66006.25
Iteration:    440, Loss function: 7.403, Average Loss: 3.252, avg. samples / sec: 65954.50
Iteration:    440, Loss function: 6.865, Average Loss: 3.240, avg. samples / sec: 66024.83
Iteration:    440, Loss function: 5.759, Average Loss: 3.238, avg. samples / sec: 65954.38
Iteration:    440, Loss function: 6.128, Average Loss: 3.263, avg. samples / sec: 65972.04
Iteration:    440, Loss function: 7.447, Average Loss: 3.263, avg. samples / sec: 66012.52
Iteration:    440, Loss function: 6.898, Average Loss: 3.240, avg. samples / sec: 66261.01
Iteration:    440, Loss function: 7.348, Average Loss: 3.220, avg. samples / sec: 66239.67
Iteration:    440, Loss function: 6.265, Average Loss: 3.241, avg. samples / sec: 65835.48
Iteration:    440, Loss function: 6.600, Average Loss: 3.222, avg. samples / sec: 65973.52
Iteration:    440, Loss function: 6.578, Average Loss: 3.253, avg. samples / sec: 66395.52
Iteration:    440, Loss function: 6.357, Average Loss: 3.297, avg. samples / sec: 65988.23
Iteration:    440, Loss function: 5.909, Average Loss: 3.261, avg. samples / sec: 65896.80
Iteration:    440, Loss function: 6.062, Average Loss: 3.243, avg. samples / sec: 65955.58
Iteration:    440, Loss function: 7.348, Average Loss: 3.267, avg. samples / sec: 66141.40
Iteration:    440, Loss function: 7.084, Average Loss: 3.246, avg. samples / sec: 65853.23
Iteration:    440, Loss function: 6.692, Average Loss: 3.237, avg. samples / sec: 65809.87
Iteration:    440, Loss function: 6.152, Average Loss: 3.239, avg. samples / sec: 65788.64
Iteration:    460, Loss function: 6.736, Average Loss: 3.329, avg. samples / sec: 66309.67
Iteration:    460, Loss function: 6.235, Average Loss: 3.312, avg. samples / sec: 66233.76
Iteration:    460, Loss function: 6.366, Average Loss: 3.312, avg. samples / sec: 66196.43
Iteration:    460, Loss function: 7.761, Average Loss: 3.308, avg. samples / sec: 66161.56
Iteration:    460, Loss function: 6.200, Average Loss: 3.314, avg. samples / sec: 66375.48
Iteration:    460, Loss function: 5.615, Average Loss: 3.306, avg. samples / sec: 66143.73
Iteration:    460, Loss function: 6.079, Average Loss: 3.300, avg. samples / sec: 66110.63
Iteration:    460, Loss function: 6.607, Average Loss: 3.314, avg. samples / sec: 66101.76
Iteration:    460, Loss function: 6.893, Average Loss: 3.303, avg. samples / sec: 66343.42
Iteration:    460, Loss function: 6.350, Average Loss: 3.301, avg. samples / sec: 66052.43
Iteration:    460, Loss function: 6.570, Average Loss: 3.289, avg. samples / sec: 66229.56
Iteration:    460, Loss function: 6.173, Average Loss: 3.312, avg. samples / sec: 66169.42
Iteration:    460, Loss function: 7.152, Average Loss: 3.314, avg. samples / sec: 66141.34
Iteration:    460, Loss function: 6.510, Average Loss: 3.307, avg. samples / sec: 66415.24
Iteration:    460, Loss function: 6.327, Average Loss: 3.294, avg. samples / sec: 66033.49
Iteration:    460, Loss function: 6.985, Average Loss: 3.300, avg. samples / sec: 66111.37
Iteration:    460, Loss function: 5.972, Average Loss: 3.330, avg. samples / sec: 66151.77
Iteration:    460, Loss function: 5.663, Average Loss: 3.300, avg. samples / sec: 66122.60
Iteration:    460, Loss function: 5.506, Average Loss: 3.308, avg. samples / sec: 66144.17
Iteration:    460, Loss function: 6.365, Average Loss: 3.363, avg. samples / sec: 66180.20
Iteration:    460, Loss function: 6.337, Average Loss: 3.284, avg. samples / sec: 66130.32
Iteration:    460, Loss function: 6.866, Average Loss: 3.335, avg. samples / sec: 66060.98
Iteration:    460, Loss function: 5.992, Average Loss: 3.304, avg. samples / sec: 66084.00
Iteration:    460, Loss function: 6.585, Average Loss: 3.305, avg. samples / sec: 66188.44
Iteration:    460, Loss function: 5.787, Average Loss: 3.296, avg. samples / sec: 66018.37
Iteration:    460, Loss function: 5.254, Average Loss: 3.331, avg. samples / sec: 66192.69
Iteration:    460, Loss function: 6.638, Average Loss: 3.317, avg. samples / sec: 65912.52
Iteration:    460, Loss function: 5.942, Average Loss: 3.306, avg. samples / sec: 66084.18
Iteration:    460, Loss function: 6.714, Average Loss: 3.328, avg. samples / sec: 66104.64
Iteration:    460, Loss function: 5.693, Average Loss: 3.323, avg. samples / sec: 66012.34
Iteration:    480, Loss function: 5.963, Average Loss: 3.376, avg. samples / sec: 66245.40
Iteration:    480, Loss function: 7.374, Average Loss: 3.373, avg. samples / sec: 66251.85
Iteration:    480, Loss function: 6.043, Average Loss: 3.363, avg. samples / sec: 66235.25
Iteration:    480, Loss function: 6.096, Average Loss: 3.379, avg. samples / sec: 66224.23
Iteration:    480, Loss function: 6.294, Average Loss: 3.360, avg. samples / sec: 66287.28
Iteration:    480, Loss function: 7.299, Average Loss: 3.368, avg. samples / sec: 66129.42
Iteration:    480, Loss function: 6.348, Average Loss: 3.396, avg. samples / sec: 66272.82
Iteration:    480, Loss function: 7.537, Average Loss: 3.363, avg. samples / sec: 66147.64
Iteration:    480, Loss function: 6.441, Average Loss: 3.392, avg. samples / sec: 66061.04
Iteration:    480, Loss function: 7.363, Average Loss: 3.359, avg. samples / sec: 66190.49
Iteration:    480, Loss function: 7.291, Average Loss: 3.380, avg. samples / sec: 66092.55
Iteration:    480, Loss function: 6.593, Average Loss: 3.369, avg. samples / sec: 66242.63
Iteration:    480, Loss function: 6.979, Average Loss: 3.380, avg. samples / sec: 66032.44
Iteration:    480, Loss function: 8.069, Average Loss: 3.397, avg. samples / sec: 66168.24
Iteration:    480, Loss function: 6.262, Average Loss: 3.365, avg. samples / sec: 66258.67
Iteration:    480, Loss function: 6.577, Average Loss: 3.381, avg. samples / sec: 66249.39
Iteration:    480, Loss function: 6.192, Average Loss: 3.425, avg. samples / sec: 66182.81
Iteration:    480, Loss function: 6.692, Average Loss: 3.394, avg. samples / sec: 66256.55
Iteration:    480, Loss function: 6.805, Average Loss: 3.389, avg. samples / sec: 66318.75
Iteration:    480, Loss function: 6.383, Average Loss: 3.345, avg. samples / sec: 66187.38
Iteration:    480, Loss function: 6.800, Average Loss: 3.372, avg. samples / sec: 66232.92
Iteration:    480, Loss function: 5.927, Average Loss: 3.367, avg. samples / sec: 66176.53
Iteration:    480, Loss function: 5.870, Average Loss: 3.368, avg. samples / sec: 66139.76
Iteration:    480, Loss function: 8.007, Average Loss: 3.351, avg. samples / sec: 66076.22
Iteration:    480, Loss function: 6.145, Average Loss: 3.368, avg. samples / sec: 66110.72
Iteration:    480, Loss function: 7.283, Average Loss: 3.378, avg. samples / sec: 66014.81
Iteration:    480, Loss function: 6.138, Average Loss: 3.367, avg. samples / sec: 66034.54
Iteration:    480, Loss function: 6.559, Average Loss: 3.368, avg. samples / sec: 66007.67
Iteration:    480, Loss function: 7.629, Average Loss: 3.370, avg. samples / sec: 66026.13
Iteration:    480, Loss function: 6.039, Average Loss: 3.392, avg. samples / sec: 66097.14
:::MLL 1558651369.857 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558651369.857 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 5.610, Average Loss: 3.410, avg. samples / sec: 66082.54
Iteration:    500, Loss function: 6.131, Average Loss: 3.433, avg. samples / sec: 66063.49
Iteration:    500, Loss function: 7.537, Average Loss: 3.455, avg. samples / sec: 65934.20
Iteration:    500, Loss function: 5.857, Average Loss: 3.435, avg. samples / sec: 66044.79
Iteration:    500, Loss function: 6.826, Average Loss: 3.433, avg. samples / sec: 65838.46
Iteration:    500, Loss function: 7.167, Average Loss: 3.425, avg. samples / sec: 65858.65
Iteration:    500, Loss function: 6.391, Average Loss: 3.430, avg. samples / sec: 65936.45
Iteration:    500, Loss function: 5.834, Average Loss: 3.439, avg. samples / sec: 65996.32
Iteration:    500, Loss function: 5.826, Average Loss: 3.443, avg. samples / sec: 65883.40
Iteration:    500, Loss function: 6.326, Average Loss: 3.424, avg. samples / sec: 65813.19
Iteration:    500, Loss function: 5.956, Average Loss: 3.424, avg. samples / sec: 65855.48
Iteration:    500, Loss function: 6.310, Average Loss: 3.429, avg. samples / sec: 65842.31
Iteration:    500, Loss function: 5.984, Average Loss: 3.489, avg. samples / sec: 65927.41
Iteration:    500, Loss function: 6.503, Average Loss: 3.453, avg. samples / sec: 65839.88
Iteration:    500, Loss function: 7.232, Average Loss: 3.440, avg. samples / sec: 65808.09
Iteration:    500, Loss function: 6.775, Average Loss: 3.408, avg. samples / sec: 65892.95
Iteration:    500, Loss function: 6.748, Average Loss: 3.429, avg. samples / sec: 65942.44
Iteration:    500, Loss function: 7.823, Average Loss: 3.428, avg. samples / sec: 65904.63
Iteration:    500, Loss function: 5.217, Average Loss: 3.444, avg. samples / sec: 65871.91
Iteration:    500, Loss function: 5.614, Average Loss: 3.455, avg. samples / sec: 65876.81
Iteration:    500, Loss function: 6.059, Average Loss: 3.459, avg. samples / sec: 65838.13
Iteration:    500, Loss function: 6.138, Average Loss: 3.429, avg. samples / sec: 65887.87
Iteration:    500, Loss function: 6.276, Average Loss: 3.440, avg. samples / sec: 65660.33
Iteration:    500, Loss function: 5.271, Average Loss: 3.442, avg. samples / sec: 65750.89
Iteration:    500, Loss function: 5.403, Average Loss: 3.432, avg. samples / sec: 65733.53
Iteration:    500, Loss function: 5.776, Average Loss: 3.454, avg. samples / sec: 65798.01
Iteration:    500, Loss function: 5.866, Average Loss: 3.456, avg. samples / sec: 65918.69
Iteration:    500, Loss function: 6.434, Average Loss: 3.427, avg. samples / sec: 65676.46
Iteration:    500, Loss function: 5.833, Average Loss: 3.432, avg. samples / sec: 65811.07
Iteration:    500, Loss function: 5.860, Average Loss: 3.433, avg. samples / sec: 65784.96
Iteration:    520, Loss function: 5.761, Average Loss: 3.519, avg. samples / sec: 65742.15
Iteration:    520, Loss function: 5.255, Average Loss: 3.501, avg. samples / sec: 65660.06
Iteration:    520, Loss function: 5.890, Average Loss: 3.495, avg. samples / sec: 65801.11
Iteration:    520, Loss function: 6.074, Average Loss: 3.486, avg. samples / sec: 65646.02
Iteration:    520, Loss function: 6.817, Average Loss: 3.482, avg. samples / sec: 65631.87
Iteration:    520, Loss function: 6.124, Average Loss: 3.504, avg. samples / sec: 65563.56
Iteration:    520, Loss function: 6.180, Average Loss: 3.481, avg. samples / sec: 65578.27
Iteration:    520, Loss function: 6.463, Average Loss: 3.485, avg. samples / sec: 65627.98
Iteration:    520, Loss function: 5.944, Average Loss: 3.488, avg. samples / sec: 65546.03
Iteration:    520, Loss function: 6.315, Average Loss: 3.513, avg. samples / sec: 65670.34
Iteration:    520, Loss function: 5.778, Average Loss: 3.541, avg. samples / sec: 65618.18
Iteration:    520, Loss function: 6.656, Average Loss: 3.485, avg. samples / sec: 65800.87
Iteration:    520, Loss function: 5.985, Average Loss: 3.492, avg. samples / sec: 65573.08
Iteration:    520, Loss function: 6.586, Average Loss: 3.499, avg. samples / sec: 65616.22
Iteration:    520, Loss function: 5.949, Average Loss: 3.501, avg. samples / sec: 65739.36
Iteration:    520, Loss function: 5.742, Average Loss: 3.485, avg. samples / sec: 65524.24
Iteration:    520, Loss function: 6.986, Average Loss: 3.509, avg. samples / sec: 65581.20
Iteration:    520, Loss function: 5.472, Average Loss: 3.502, avg. samples / sec: 65606.93
Iteration:    520, Loss function: 5.496, Average Loss: 3.485, avg. samples / sec: 65574.42
Iteration:    520, Loss function: 6.007, Average Loss: 3.488, avg. samples / sec: 65512.21
Iteration:    520, Loss function: 5.721, Average Loss: 3.481, avg. samples / sec: 65562.37
Iteration:    520, Loss function: 6.154, Average Loss: 3.498, avg. samples / sec: 65717.65
Iteration:    520, Loss function: 6.310, Average Loss: 3.491, avg. samples / sec: 65664.19
Iteration:    520, Loss function: 6.552, Average Loss: 3.462, avg. samples / sec: 65552.83
Iteration:    520, Loss function: 6.818, Average Loss: 3.486, avg. samples / sec: 65753.34
Iteration:    520, Loss function: 6.378, Average Loss: 3.468, avg. samples / sec: 65373.36
Iteration:    520, Loss function: 6.405, Average Loss: 3.486, avg. samples / sec: 65536.43
Iteration:    520, Loss function: 5.844, Average Loss: 3.487, avg. samples / sec: 65340.17
Iteration:    520, Loss function: 5.630, Average Loss: 3.510, avg. samples / sec: 65575.31
Iteration:    520, Loss function: 5.372, Average Loss: 3.507, avg. samples / sec: 65554.53
Iteration:    540, Loss function: 5.828, Average Loss: 3.538, avg. samples / sec: 66241.14
Iteration:    540, Loss function: 5.681, Average Loss: 3.539, avg. samples / sec: 66099.43
Iteration:    540, Loss function: 6.840, Average Loss: 3.522, avg. samples / sec: 66241.98
Iteration:    540, Loss function: 5.009, Average Loss: 3.541, avg. samples / sec: 66056.77
Iteration:    540, Loss function: 6.484, Average Loss: 3.542, avg. samples / sec: 66171.75
Iteration:    540, Loss function: 6.221, Average Loss: 3.553, avg. samples / sec: 66056.09
Iteration:    540, Loss function: 5.351, Average Loss: 3.564, avg. samples / sec: 66101.42
Iteration:    540, Loss function: 6.635, Average Loss: 3.537, avg. samples / sec: 66080.90
Iteration:    540, Loss function: 5.791, Average Loss: 3.550, avg. samples / sec: 66069.09
Iteration:    540, Loss function: 6.203, Average Loss: 3.537, avg. samples / sec: 66216.33
Iteration:    540, Loss function: 6.330, Average Loss: 3.543, avg. samples / sec: 66059.86
Iteration:    540, Loss function: 6.071, Average Loss: 3.549, avg. samples / sec: 66156.84
Iteration:    540, Loss function: 6.079, Average Loss: 3.538, avg. samples / sec: 66034.17
Iteration:    540, Loss function: 5.136, Average Loss: 3.546, avg. samples / sec: 66056.15
Iteration:    540, Loss function: 6.135, Average Loss: 3.590, avg. samples / sec: 66049.31
Iteration:    540, Loss function: 5.807, Average Loss: 3.536, avg. samples / sec: 66031.11
Iteration:    540, Loss function: 5.860, Average Loss: 3.539, avg. samples / sec: 66187.35
Iteration:    540, Loss function: 6.231, Average Loss: 3.542, avg. samples / sec: 66148.14
Iteration:    540, Loss function: 6.430, Average Loss: 3.576, avg. samples / sec: 65952.47
Iteration:    540, Loss function: 6.351, Average Loss: 3.534, avg. samples / sec: 65989.00
Iteration:    540, Loss function: 6.143, Average Loss: 3.536, avg. samples / sec: 66082.69
Iteration:    540, Loss function: 6.822, Average Loss: 3.567, avg. samples / sec: 66008.66
Iteration:    540, Loss function: 6.021, Average Loss: 3.511, avg. samples / sec: 66115.12
Iteration:    540, Loss function: 6.748, Average Loss: 3.548, avg. samples / sec: 65947.10
Iteration:    540, Loss function: 6.197, Average Loss: 3.560, avg. samples / sec: 66008.97
Iteration:    540, Loss function: 5.423, Average Loss: 3.531, avg. samples / sec: 66049.37
Iteration:    540, Loss function: 5.947, Average Loss: 3.551, avg. samples / sec: 65958.39
Iteration:    540, Loss function: 5.204, Average Loss: 3.565, avg. samples / sec: 66115.43
Iteration:    540, Loss function: 5.125, Average Loss: 3.556, avg. samples / sec: 66143.36
Iteration:    540, Loss function: 6.640, Average Loss: 3.546, avg. samples / sec: 65930.68
:::MLL 1558651371.642 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558651371.643 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 5.236, Average Loss: 3.627, avg. samples / sec: 66195.21
Iteration:    560, Loss function: 6.705, Average Loss: 3.601, avg. samples / sec: 66147.52
Iteration:    560, Loss function: 5.754, Average Loss: 3.607, avg. samples / sec: 66249.92
Iteration:    560, Loss function: 5.115, Average Loss: 3.588, avg. samples / sec: 66005.53
Iteration:    560, Loss function: 5.161, Average Loss: 3.597, avg. samples / sec: 66177.40
Iteration:    560, Loss function: 5.258, Average Loss: 3.591, avg. samples / sec: 65996.01
Iteration:    560, Loss function: 5.471, Average Loss: 3.595, avg. samples / sec: 66029.41
Iteration:    560, Loss function: 6.137, Average Loss: 3.590, avg. samples / sec: 66002.97
Iteration:    560, Loss function: 7.078, Average Loss: 3.573, avg. samples / sec: 65954.94
Iteration:    560, Loss function: 5.483, Average Loss: 3.590, avg. samples / sec: 66036.31
Iteration:    560, Loss function: 6.401, Average Loss: 3.585, avg. samples / sec: 66007.51
Iteration:    560, Loss function: 5.088, Average Loss: 3.613, avg. samples / sec: 65998.64
Iteration:    560, Loss function: 5.189, Average Loss: 3.605, avg. samples / sec: 65967.10
Iteration:    560, Loss function: 7.115, Average Loss: 3.585, avg. samples / sec: 65973.74
Iteration:    560, Loss function: 5.668, Average Loss: 3.614, avg. samples / sec: 66022.82
Iteration:    560, Loss function: 4.915, Average Loss: 3.594, avg. samples / sec: 66211.35
Iteration:    560, Loss function: 5.831, Average Loss: 3.616, avg. samples / sec: 66120.15
Iteration:    560, Loss function: 5.659, Average Loss: 3.638, avg. samples / sec: 65976.39
Iteration:    560, Loss function: 5.288, Average Loss: 3.593, avg. samples / sec: 65965.93
Iteration:    560, Loss function: 6.164, Average Loss: 3.585, avg. samples / sec: 65811.65
Iteration:    560, Loss function: 4.418, Average Loss: 3.584, avg. samples / sec: 65992.27
Iteration:    560, Loss function: 5.249, Average Loss: 3.602, avg. samples / sec: 65946.20
Iteration:    560, Loss function: 5.331, Average Loss: 3.600, avg. samples / sec: 66002.44
Iteration:    560, Loss function: 6.831, Average Loss: 3.562, avg. samples / sec: 65998.08
Iteration:    560, Loss function: 5.179, Average Loss: 3.585, avg. samples / sec: 65960.06
Iteration:    560, Loss function: 6.863, Average Loss: 3.593, avg. samples / sec: 65947.77
Iteration:    560, Loss function: 5.518, Average Loss: 3.588, avg. samples / sec: 65901.95
Iteration:    560, Loss function: 6.174, Average Loss: 3.586, avg. samples / sec: 65883.52
Iteration:    560, Loss function: 6.041, Average Loss: 3.578, avg. samples / sec: 65921.95
Iteration:    560, Loss function: 5.109, Average Loss: 3.606, avg. samples / sec: 65796.51
Iteration:    580, Loss function: 5.433, Average Loss: 3.639, avg. samples / sec: 66126.01
Iteration:    580, Loss function: 5.939, Average Loss: 3.634, avg. samples / sec: 66210.51
Iteration:    580, Loss function: 6.562, Average Loss: 3.637, avg. samples / sec: 66137.43
Iteration:    580, Loss function: 6.117, Average Loss: 3.662, avg. samples / sec: 66160.16
Iteration:    580, Loss function: 6.651, Average Loss: 3.675, avg. samples / sec: 65989.03
Iteration:    580, Loss function: 6.156, Average Loss: 3.655, avg. samples / sec: 66177.53
Iteration:    580, Loss function: 7.021, Average Loss: 3.637, avg. samples / sec: 66113.54
Iteration:    580, Loss function: 6.352, Average Loss: 3.633, avg. samples / sec: 66032.26
Iteration:    580, Loss function: 5.992, Average Loss: 3.630, avg. samples / sec: 66156.77
Iteration:    580, Loss function: 5.823, Average Loss: 3.645, avg. samples / sec: 65954.10
Iteration:    580, Loss function: 5.940, Average Loss: 3.643, avg. samples / sec: 66149.10
Iteration:    580, Loss function: 7.052, Average Loss: 3.653, avg. samples / sec: 66089.05
Iteration:    580, Loss function: 5.519, Average Loss: 3.639, avg. samples / sec: 66245.34
Iteration:    580, Loss function: 6.522, Average Loss: 3.624, avg. samples / sec: 66253.75
Iteration:    580, Loss function: 6.344, Average Loss: 3.640, avg. samples / sec: 65985.69
Iteration:    580, Loss function: 5.505, Average Loss: 3.662, avg. samples / sec: 66072.66
Iteration:    580, Loss function: 6.400, Average Loss: 3.634, avg. samples / sec: 66049.55
Iteration:    580, Loss function: 5.460, Average Loss: 3.622, avg. samples / sec: 66004.24
Iteration:    580, Loss function: 5.795, Average Loss: 3.632, avg. samples / sec: 66099.40
Iteration:    580, Loss function: 6.537, Average Loss: 3.644, avg. samples / sec: 65956.20
Iteration:    580, Loss function: 6.615, Average Loss: 3.684, avg. samples / sec: 66036.77
Iteration:    580, Loss function: 5.776, Average Loss: 3.662, avg. samples / sec: 66016.02
Iteration:    580, Loss function: 5.269, Average Loss: 3.654, avg. samples / sec: 65854.65
Iteration:    580, Loss function: 6.118, Average Loss: 3.654, avg. samples / sec: 66341.36
Iteration:    580, Loss function: 7.408, Average Loss: 3.637, avg. samples / sec: 66099.49
Iteration:    580, Loss function: 5.532, Average Loss: 3.644, avg. samples / sec: 65988.66
Iteration:    580, Loss function: 5.946, Average Loss: 3.643, avg. samples / sec: 65965.93
Iteration:    580, Loss function: 6.285, Average Loss: 3.608, avg. samples / sec: 66010.76
Iteration:    580, Loss function: 5.661, Average Loss: 3.641, avg. samples / sec: 65921.74
Iteration:    580, Loss function: 5.805, Average Loss: 3.634, avg. samples / sec: 65674.20
Iteration:    600, Loss function: 5.787, Average Loss: 3.725, avg. samples / sec: 66217.11
Iteration:    600, Loss function: 5.659, Average Loss: 3.688, avg. samples / sec: 66162.55
Iteration:    600, Loss function: 6.322, Average Loss: 3.693, avg. samples / sec: 66221.62
Iteration:    600, Loss function: 6.750, Average Loss: 3.683, avg. samples / sec: 66284.85
Iteration:    600, Loss function: 7.442, Average Loss: 3.685, avg. samples / sec: 66169.42
Iteration:    600, Loss function: 5.687, Average Loss: 3.702, avg. samples / sec: 66147.71
Iteration:    600, Loss function: 6.082, Average Loss: 3.691, avg. samples / sec: 66391.89
Iteration:    600, Loss function: 6.960, Average Loss: 3.658, avg. samples / sec: 66307.80
Iteration:    600, Loss function: 4.789, Average Loss: 3.681, avg. samples / sec: 66080.93
Iteration:    600, Loss function: 7.163, Average Loss: 3.691, avg. samples / sec: 66130.79
Iteration:    600, Loss function: 5.445, Average Loss: 3.686, avg. samples / sec: 66213.94
Iteration:    600, Loss function: 7.168, Average Loss: 3.691, avg. samples / sec: 66069.62
Iteration:    600, Loss function: 6.642, Average Loss: 3.735, avg. samples / sec: 66234.41
Iteration:    600, Loss function: 5.715, Average Loss: 3.702, avg. samples / sec: 66151.93
Iteration:    600, Loss function: 6.434, Average Loss: 3.674, avg. samples / sec: 66192.07
Iteration:    600, Loss function: 5.213, Average Loss: 3.676, avg. samples / sec: 66152.27
Iteration:    600, Loss function: 5.477, Average Loss: 3.687, avg. samples / sec: 66112.61
Iteration:    600, Loss function: 5.313, Average Loss: 3.695, avg. samples / sec: 66188.56
Iteration:    600, Loss function: 6.558, Average Loss: 3.686, avg. samples / sec: 66208.03
Iteration:    600, Loss function: 7.013, Average Loss: 3.711, avg. samples / sec: 66166.81
Iteration:    600, Loss function: 6.190, Average Loss: 3.703, avg. samples / sec: 66195.68
Iteration:    600, Loss function: 6.199, Average Loss: 3.685, avg. samples / sec: 66068.04
Iteration:    600, Loss function: 5.934, Average Loss: 3.685, avg. samples / sec: 66141.96
Iteration:    600, Loss function: 5.946, Average Loss: 3.709, avg. samples / sec: 66193.44
Iteration:    600, Loss function: 5.305, Average Loss: 3.687, avg. samples / sec: 66198.35
Iteration:    600, Loss function: 7.277, Average Loss: 3.688, avg. samples / sec: 66092.39
Iteration:    600, Loss function: 5.971, Average Loss: 3.704, avg. samples / sec: 66155.47
Iteration:    600, Loss function: 5.924, Average Loss: 3.710, avg. samples / sec: 65961.79
Iteration:    600, Loss function: 6.217, Average Loss: 3.683, avg. samples / sec: 66505.22
Iteration:    600, Loss function: 7.242, Average Loss: 3.691, avg. samples / sec: 66016.57
Iteration:    620, Loss function: 6.425, Average Loss: 3.739, avg. samples / sec: 66381.48
Iteration:    620, Loss function: 4.969, Average Loss: 3.723, avg. samples / sec: 66299.47
Iteration:    620, Loss function: 6.866, Average Loss: 3.741, avg. samples / sec: 66375.38
Iteration:    620, Loss function: 5.545, Average Loss: 3.751, avg. samples / sec: 66463.16
Iteration:    620, Loss function: 6.137, Average Loss: 3.734, avg. samples / sec: 66274.31
Iteration:    620, Loss function: 6.800, Average Loss: 3.743, avg. samples / sec: 66605.80
Iteration:    620, Loss function: 5.535, Average Loss: 3.750, avg. samples / sec: 66390.64
Iteration:    620, Loss function: 6.341, Average Loss: 3.749, avg. samples / sec: 66324.15
Iteration:    620, Loss function: 5.541, Average Loss: 3.731, avg. samples / sec: 66257.99
Iteration:    620, Loss function: 5.048, Average Loss: 3.731, avg. samples / sec: 66293.80
Iteration:    620, Loss function: 5.771, Average Loss: 3.723, avg. samples / sec: 66290.27
Iteration:    620, Loss function: 5.630, Average Loss: 3.767, avg. samples / sec: 66152.18
Iteration:    620, Loss function: 5.920, Average Loss: 3.734, avg. samples / sec: 66170.22
Iteration:    620, Loss function: 5.472, Average Loss: 3.729, avg. samples / sec: 66301.06
Iteration:    620, Loss function: 8.121, Average Loss: 3.785, avg. samples / sec: 66255.62
Iteration:    620, Loss function: 5.075, Average Loss: 3.727, avg. samples / sec: 66268.48
Iteration:    620, Loss function: 6.277, Average Loss: 3.740, avg. samples / sec: 66259.67
Iteration:    620, Loss function: 6.187, Average Loss: 3.758, avg. samples / sec: 66248.36
Iteration:    620, Loss function: 5.933, Average Loss: 3.732, avg. samples / sec: 66278.30
Iteration:    620, Loss function: 7.519, Average Loss: 3.751, avg. samples / sec: 66164.32
Iteration:    620, Loss function: 6.148, Average Loss: 3.730, avg. samples / sec: 66278.77
Iteration:    620, Loss function: 6.321, Average Loss: 3.720, avg. samples / sec: 66233.95
Iteration:    620, Loss function: 5.504, Average Loss: 3.731, avg. samples / sec: 66270.60
Iteration:    620, Loss function: 6.933, Average Loss: 3.726, avg. samples / sec: 66295.82
Iteration:    620, Loss function: 5.439, Average Loss: 3.759, avg. samples / sec: 66173.24
Iteration:    620, Loss function: 5.945, Average Loss: 3.745, avg. samples / sec: 66198.60
Iteration:    620, Loss function: 6.466, Average Loss: 3.737, avg. samples / sec: 66063.21
Iteration:    620, Loss function: 4.807, Average Loss: 3.734, avg. samples / sec: 66162.46
Iteration:    620, Loss function: 5.714, Average Loss: 3.703, avg. samples / sec: 66056.49
Iteration:    620, Loss function: 4.675, Average Loss: 3.720, avg. samples / sec: 66082.29
:::MLL 1558651373.422 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558651373.422 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 5.422, Average Loss: 3.759, avg. samples / sec: 65896.40
Iteration:    640, Loss function: 4.728, Average Loss: 3.809, avg. samples / sec: 65897.73
Iteration:    640, Loss function: 5.607, Average Loss: 3.780, avg. samples / sec: 65931.42
Iteration:    640, Loss function: 4.467, Average Loss: 3.784, avg. samples / sec: 65773.60
Iteration:    640, Loss function: 4.696, Average Loss: 3.777, avg. samples / sec: 65717.81
Iteration:    640, Loss function: 6.854, Average Loss: 3.763, avg. samples / sec: 65746.38
Iteration:    640, Loss function: 5.082, Average Loss: 3.755, avg. samples / sec: 66032.38
Iteration:    640, Loss function: 5.257, Average Loss: 3.773, avg. samples / sec: 65780.17
Iteration:    640, Loss function: 5.250, Average Loss: 3.790, avg. samples / sec: 65892.52
Iteration:    640, Loss function: 5.453, Average Loss: 3.774, avg. samples / sec: 65990.48
Iteration:    640, Loss function: 5.817, Average Loss: 3.791, avg. samples / sec: 65771.23
Iteration:    640, Loss function: 4.525, Average Loss: 3.759, avg. samples / sec: 65864.00
Iteration:    640, Loss function: 5.029, Average Loss: 3.770, avg. samples / sec: 65860.28
Iteration:    640, Loss function: 5.060, Average Loss: 3.746, avg. samples / sec: 66002.01
Iteration:    640, Loss function: 6.053, Average Loss: 3.773, avg. samples / sec: 65716.79
Iteration:    640, Loss function: 5.806, Average Loss: 3.777, avg. samples / sec: 65767.27
Iteration:    640, Loss function: 6.040, Average Loss: 3.773, avg. samples / sec: 65800.78
Iteration:    640, Loss function: 5.072, Average Loss: 3.772, avg. samples / sec: 65812.02
Iteration:    640, Loss function: 4.977, Average Loss: 3.777, avg. samples / sec: 65953.30
Iteration:    640, Loss function: 5.199, Average Loss: 3.819, avg. samples / sec: 65802.10
Iteration:    640, Loss function: 5.654, Average Loss: 3.797, avg. samples / sec: 65927.51
Iteration:    640, Loss function: 5.361, Average Loss: 3.797, avg. samples / sec: 65677.99
Iteration:    640, Loss function: 5.313, Average Loss: 3.774, avg. samples / sec: 65789.10
Iteration:    640, Loss function: 4.897, Average Loss: 3.782, avg. samples / sec: 65628.29
Iteration:    640, Loss function: 4.568, Average Loss: 3.768, avg. samples / sec: 65715.42
Iteration:    640, Loss function: 5.751, Average Loss: 3.764, avg. samples / sec: 65822.53
Iteration:    640, Loss function: 5.927, Average Loss: 3.799, avg. samples / sec: 65752.85
Iteration:    640, Loss function: 5.864, Average Loss: 3.790, avg. samples / sec: 65845.91
Iteration:    640, Loss function: 4.723, Average Loss: 3.789, avg. samples / sec: 65588.13
Iteration:    640, Loss function: 6.186, Average Loss: 3.775, avg. samples / sec: 65686.87
Iteration:    660, Loss function: 5.089, Average Loss: 3.820, avg. samples / sec: 65910.86
Iteration:    660, Loss function: 6.747, Average Loss: 3.814, avg. samples / sec: 65818.05
Iteration:    660, Loss function: 5.697, Average Loss: 3.814, avg. samples / sec: 65792.30
Iteration:    660, Loss function: 5.951, Average Loss: 3.816, avg. samples / sec: 65815.34
Iteration:    660, Loss function: 4.575, Average Loss: 3.813, avg. samples / sec: 65813.44
Iteration:    660, Loss function: 6.693, Average Loss: 3.845, avg. samples / sec: 65832.13
Iteration:    660, Loss function: 6.167, Average Loss: 3.827, avg. samples / sec: 65925.72
Iteration:    660, Loss function: 6.611, Average Loss: 3.812, avg. samples / sec: 65783.73
Iteration:    660, Loss function: 5.297, Average Loss: 3.784, avg. samples / sec: 65747.24
Iteration:    660, Loss function: 6.439, Average Loss: 3.817, avg. samples / sec: 65815.96
Iteration:    660, Loss function: 6.595, Average Loss: 3.836, avg. samples / sec: 65699.42
Iteration:    660, Loss function: 5.115, Average Loss: 3.810, avg. samples / sec: 65761.44
Iteration:    660, Loss function: 6.698, Average Loss: 3.813, avg. samples / sec: 65708.98
Iteration:    660, Loss function: 5.782, Average Loss: 3.817, avg. samples / sec: 65631.01
Iteration:    660, Loss function: 5.345, Average Loss: 3.810, avg. samples / sec: 65815.71
Iteration:    660, Loss function: 5.068, Average Loss: 3.826, avg. samples / sec: 65663.27
Iteration:    660, Loss function: 5.849, Average Loss: 3.794, avg. samples / sec: 65673.31
Iteration:    660, Loss function: 6.404, Average Loss: 3.807, avg. samples / sec: 65580.77
Iteration:    660, Loss function: 5.272, Average Loss: 3.847, avg. samples / sec: 65590.78
Iteration:    660, Loss function: 6.136, Average Loss: 3.801, avg. samples / sec: 65646.20
Iteration:    660, Loss function: 5.293, Average Loss: 3.830, avg. samples / sec: 65631.47
Iteration:    660, Loss function: 6.411, Average Loss: 3.814, avg. samples / sec: 65809.16
Iteration:    660, Loss function: 6.177, Average Loss: 3.817, avg. samples / sec: 65622.03
Iteration:    660, Loss function: 5.260, Average Loss: 3.819, avg. samples / sec: 65643.76
Iteration:    660, Loss function: 5.042, Average Loss: 3.853, avg. samples / sec: 65641.01
Iteration:    660, Loss function: 5.353, Average Loss: 3.805, avg. samples / sec: 65699.73
Iteration:    660, Loss function: 6.942, Average Loss: 3.806, avg. samples / sec: 65564.05
Iteration:    660, Loss function: 6.644, Average Loss: 3.841, avg. samples / sec: 65657.55
Iteration:    660, Loss function: 6.304, Average Loss: 3.836, avg. samples / sec: 65566.28
Iteration:    660, Loss function: 5.065, Average Loss: 3.834, avg. samples / sec: 65583.88
Iteration:    680, Loss function: 5.531, Average Loss: 3.849, avg. samples / sec: 66364.23
Iteration:    680, Loss function: 6.283, Average Loss: 3.874, avg. samples / sec: 66431.20
Iteration:    680, Loss function: 5.942, Average Loss: 3.854, avg. samples / sec: 66439.91
Iteration:    680, Loss function: 4.897, Average Loss: 3.852, avg. samples / sec: 66382.11
Iteration:    680, Loss function: 5.735, Average Loss: 3.857, avg. samples / sec: 66315.23
Iteration:    680, Loss function: 4.679, Average Loss: 3.856, avg. samples / sec: 66292.80
Iteration:    680, Loss function: 4.049, Average Loss: 3.892, avg. samples / sec: 66511.65
Iteration:    680, Loss function: 5.044, Average Loss: 3.843, avg. samples / sec: 66399.03
Iteration:    680, Loss function: 4.631, Average Loss: 3.855, avg. samples / sec: 66436.06
Iteration:    680, Loss function: 5.270, Average Loss: 3.867, avg. samples / sec: 66450.40
Iteration:    680, Loss function: 4.764, Average Loss: 3.846, avg. samples / sec: 66360.57
Iteration:    680, Loss function: 5.241, Average Loss: 3.844, avg. samples / sec: 66362.32
Iteration:    680, Loss function: 4.579, Average Loss: 3.878, avg. samples / sec: 66366.04
Iteration:    680, Loss function: 5.231, Average Loss: 3.855, avg. samples / sec: 66249.61
Iteration:    680, Loss function: 4.665, Average Loss: 3.845, avg. samples / sec: 66290.74
Iteration:    680, Loss function: 6.598, Average Loss: 3.870, avg. samples / sec: 66461.75
Iteration:    680, Loss function: 4.799, Average Loss: 3.834, avg. samples / sec: 66301.69
Iteration:    680, Loss function: 7.247, Average Loss: 3.843, avg. samples / sec: 66407.10
Iteration:    680, Loss function: 5.885, Average Loss: 3.880, avg. samples / sec: 66209.05
Iteration:    680, Loss function: 6.047, Average Loss: 3.840, avg. samples / sec: 66355.26
Iteration:    680, Loss function: 6.490, Average Loss: 3.852, avg. samples / sec: 66156.59
Iteration:    680, Loss function: 6.678, Average Loss: 3.864, avg. samples / sec: 66247.05
Iteration:    680, Loss function: 6.422, Average Loss: 3.868, avg. samples / sec: 66486.36
Iteration:    680, Loss function: 5.512, Average Loss: 3.855, avg. samples / sec: 66209.70
Iteration:    680, Loss function: 5.358, Average Loss: 3.876, avg. samples / sec: 66363.10
Iteration:    680, Loss function: 8.289, Average Loss: 3.867, avg. samples / sec: 66112.33
Iteration:    680, Loss function: 4.545, Average Loss: 3.848, avg. samples / sec: 66244.06
Iteration:    680, Loss function: 4.348, Average Loss: 3.826, avg. samples / sec: 66102.72
Iteration:    680, Loss function: 4.793, Average Loss: 3.839, avg. samples / sec: 66257.08
Iteration:    680, Loss function: 6.190, Average Loss: 3.856, avg. samples / sec: 66200.03
:::MLL 1558651375.203 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558651375.204 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 5.598, Average Loss: 3.875, avg. samples / sec: 66297.17
Iteration:    700, Loss function: 6.431, Average Loss: 3.863, avg. samples / sec: 66383.86
Iteration:    700, Loss function: 5.518, Average Loss: 3.896, avg. samples / sec: 66156.96
Iteration:    700, Loss function: 7.192, Average Loss: 3.897, avg. samples / sec: 66060.82
Iteration:    700, Loss function: 6.500, Average Loss: 3.915, avg. samples / sec: 66275.34
Iteration:    700, Loss function: 5.574, Average Loss: 3.920, avg. samples / sec: 66186.41
Iteration:    700, Loss function: 6.905, Average Loss: 3.886, avg. samples / sec: 65952.31
Iteration:    700, Loss function: 6.459, Average Loss: 3.917, avg. samples / sec: 66081.80
Iteration:    700, Loss function: 7.719, Average Loss: 3.909, avg. samples / sec: 66260.10
Iteration:    700, Loss function: 6.140, Average Loss: 3.911, avg. samples / sec: 65978.00
Iteration:    700, Loss function: 6.318, Average Loss: 3.937, avg. samples / sec: 66002.69
Iteration:    700, Loss function: 6.781, Average Loss: 3.876, avg. samples / sec: 66130.57
Iteration:    700, Loss function: 5.832, Average Loss: 3.881, avg. samples / sec: 66265.68
Iteration:    700, Loss function: 5.438, Average Loss: 3.898, avg. samples / sec: 66309.49
Iteration:    700, Loss function: 5.849, Average Loss: 3.888, avg. samples / sec: 65972.23
Iteration:    700, Loss function: 6.380, Average Loss: 3.892, avg. samples / sec: 66041.35
Iteration:    700, Loss function: 6.155, Average Loss: 3.878, avg. samples / sec: 66107.46
Iteration:    700, Loss function: 6.094, Average Loss: 3.888, avg. samples / sec: 65952.31
Iteration:    700, Loss function: 5.433, Average Loss: 3.888, avg. samples / sec: 66196.30
Iteration:    700, Loss function: 6.310, Average Loss: 3.888, avg. samples / sec: 65975.50
Iteration:    700, Loss function: 6.221, Average Loss: 3.904, avg. samples / sec: 65973.55
Iteration:    700, Loss function: 7.322, Average Loss: 3.880, avg. samples / sec: 65990.17
Iteration:    700, Loss function: 7.605, Average Loss: 3.897, avg. samples / sec: 65917.88
Iteration:    700, Loss function: 5.949, Average Loss: 3.885, avg. samples / sec: 66030.15
Iteration:    700, Loss function: 7.209, Average Loss: 3.895, avg. samples / sec: 66057.33
Iteration:    700, Loss function: 7.275, Average Loss: 3.913, avg. samples / sec: 66050.33
Iteration:    700, Loss function: 5.643, Average Loss: 3.898, avg. samples / sec: 66077.58
Iteration:    700, Loss function: 6.634, Average Loss: 3.882, avg. samples / sec: 65897.45
Iteration:    700, Loss function: 7.157, Average Loss: 3.898, avg. samples / sec: 65985.60
Iteration:    700, Loss function: 7.175, Average Loss: 3.906, avg. samples / sec: 65857.26
Iteration:    720, Loss function: 5.683, Average Loss: 3.926, avg. samples / sec: 66230.30
Iteration:    720, Loss function: 6.236, Average Loss: 3.937, avg. samples / sec: 66110.87
Iteration:    720, Loss function: 3.841, Average Loss: 3.952, avg. samples / sec: 66067.05
Iteration:    720, Loss function: 5.590, Average Loss: 3.927, avg. samples / sec: 66158.61
Iteration:    720, Loss function: 5.011, Average Loss: 3.932, avg. samples / sec: 66014.04
Iteration:    720, Loss function: 4.603, Average Loss: 3.932, avg. samples / sec: 66171.84
Iteration:    720, Loss function: 7.017, Average Loss: 3.962, avg. samples / sec: 66103.40
Iteration:    720, Loss function: 4.650, Average Loss: 3.933, avg. samples / sec: 66217.51
Iteration:    720, Loss function: 6.867, Average Loss: 3.920, avg. samples / sec: 66098.87
Iteration:    720, Loss function: 6.452, Average Loss: 3.931, avg. samples / sec: 66088.43
Iteration:    720, Loss function: 5.518, Average Loss: 3.954, avg. samples / sec: 66016.88
Iteration:    720, Loss function: 5.470, Average Loss: 3.914, avg. samples / sec: 65894.31
Iteration:    720, Loss function: 6.165, Average Loss: 3.944, avg. samples / sec: 66095.15
Iteration:    720, Loss function: 6.142, Average Loss: 3.932, avg. samples / sec: 66106.35
Iteration:    720, Loss function: 5.219, Average Loss: 3.920, avg. samples / sec: 66083.31
Iteration:    720, Loss function: 6.159, Average Loss: 3.916, avg. samples / sec: 66152.33
Iteration:    720, Loss function: 4.309, Average Loss: 3.919, avg. samples / sec: 65987.92
Iteration:    720, Loss function: 5.184, Average Loss: 3.925, avg. samples / sec: 65999.48
Iteration:    720, Loss function: 6.149, Average Loss: 3.913, avg. samples / sec: 65995.95
Iteration:    720, Loss function: 5.356, Average Loss: 3.947, avg. samples / sec: 65972.75
Iteration:    720, Loss function: 4.763, Average Loss: 3.945, avg. samples / sec: 66046.86
Iteration:    720, Loss function: 5.180, Average Loss: 3.918, avg. samples / sec: 66027.83
Iteration:    720, Loss function: 6.751, Average Loss: 3.934, avg. samples / sec: 65995.30
Iteration:    720, Loss function: 5.976, Average Loss: 3.941, avg. samples / sec: 65927.26
Iteration:    720, Loss function: 6.365, Average Loss: 3.935, avg. samples / sec: 66125.55
Iteration:    720, Loss function: 5.668, Average Loss: 3.970, avg. samples / sec: 65930.59
Iteration:    720, Loss function: 5.600, Average Loss: 3.923, avg. samples / sec: 65928.52
Iteration:    720, Loss function: 4.860, Average Loss: 3.937, avg. samples / sec: 66242.69
Iteration:    720, Loss function: 4.619, Average Loss: 3.935, avg. samples / sec: 65918.66
Iteration:    720, Loss function: 4.810, Average Loss: 3.900, avg. samples / sec: 65755.09
Iteration:    740, Loss function: 4.951, Average Loss: 3.974, avg. samples / sec: 66395.43
Iteration:    740, Loss function: 5.308, Average Loss: 3.968, avg. samples / sec: 66452.60
Iteration:    740, Loss function: 6.007, Average Loss: 3.951, avg. samples / sec: 66370.29
Iteration:    740, Loss function: 5.686, Average Loss: 3.954, avg. samples / sec: 66177.37
Iteration:    740, Loss function: 5.747, Average Loss: 3.969, avg. samples / sec: 66201.34
Iteration:    740, Loss function: 5.573, Average Loss: 3.982, avg. samples / sec: 66274.56
Iteration:    740, Loss function: 7.366, Average Loss: 3.959, avg. samples / sec: 66252.81
Iteration:    740, Loss function: 7.226, Average Loss: 3.963, avg. samples / sec: 66288.12
Iteration:    740, Loss function: 6.644, Average Loss: 3.952, avg. samples / sec: 66279.39
Iteration:    740, Loss function: 6.110, Average Loss: 3.966, avg. samples / sec: 66266.77
Iteration:    740, Loss function: 6.616, Average Loss: 3.949, avg. samples / sec: 66328.56
Iteration:    740, Loss function: 6.464, Average Loss: 3.972, avg. samples / sec: 66413.92
Iteration:    740, Loss function: 6.057, Average Loss: 3.949, avg. samples / sec: 66298.32
Iteration:    740, Loss function: 5.221, Average Loss: 3.961, avg. samples / sec: 66272.16
Iteration:    740, Loss function: 5.575, Average Loss: 3.951, avg. samples / sec: 66315.23
Iteration:    740, Loss function: 6.099, Average Loss: 3.958, avg. samples / sec: 66326.12
Iteration:    740, Loss function: 5.992, Average Loss: 3.942, avg. samples / sec: 66307.58
Iteration:    740, Loss function: 5.766, Average Loss: 3.980, avg. samples / sec: 66312.70
Iteration:    740, Loss function: 6.040, Average Loss: 3.964, avg. samples / sec: 66347.01
Iteration:    740, Loss function: 5.183, Average Loss: 4.001, avg. samples / sec: 66361.01
Iteration:    740, Loss function: 5.346, Average Loss: 3.963, avg. samples / sec: 66231.36
Iteration:    740, Loss function: 6.171, Average Loss: 3.929, avg. samples / sec: 66400.40
Iteration:    740, Loss function: 5.596, Average Loss: 3.948, avg. samples / sec: 66308.71
Iteration:    740, Loss function: 7.698, Average Loss: 3.969, avg. samples / sec: 66368.70
Iteration:    740, Loss function: 6.887, Average Loss: 3.958, avg. samples / sec: 66338.77
Iteration:    740, Loss function: 5.453, Average Loss: 3.990, avg. samples / sec: 66171.71
Iteration:    740, Loss function: 4.781, Average Loss: 3.969, avg. samples / sec: 66313.82
Iteration:    740, Loss function: 7.270, Average Loss: 3.994, avg. samples / sec: 66101.85
Iteration:    740, Loss function: 6.001, Average Loss: 3.970, avg. samples / sec: 66210.11
Iteration:    740, Loss function: 5.026, Average Loss: 3.964, avg. samples / sec: 66060.73
Iteration:    760, Loss function: 5.432, Average Loss: 4.017, avg. samples / sec: 66349.13
Iteration:    760, Loss function: 5.842, Average Loss: 4.010, avg. samples / sec: 66497.09
Iteration:    760, Loss function: 6.195, Average Loss: 3.977, avg. samples / sec: 66493.01
Iteration:    760, Loss function: 5.849, Average Loss: 4.022, avg. samples / sec: 66320.94
Iteration:    760, Loss function: 5.637, Average Loss: 4.031, avg. samples / sec: 66454.32
Iteration:    760, Loss function: 6.493, Average Loss: 4.004, avg. samples / sec: 66347.01
Iteration:    760, Loss function: 4.763, Average Loss: 4.008, avg. samples / sec: 66510.49
Iteration:    760, Loss function: 6.359, Average Loss: 4.012, avg. samples / sec: 66320.57
Iteration:    760, Loss function: 5.922, Average Loss: 4.014, avg. samples / sec: 66328.56
Iteration:    760, Loss function: 5.294, Average Loss: 3.985, avg. samples / sec: 66341.05
Iteration:    760, Loss function: 6.241, Average Loss: 4.016, avg. samples / sec: 66349.48
Iteration:    760, Loss function: 4.663, Average Loss: 4.009, avg. samples / sec: 66228.53
Iteration:    760, Loss function: 4.322, Average Loss: 4.014, avg. samples / sec: 66247.74
Iteration:    760, Loss function: 6.075, Average Loss: 4.003, avg. samples / sec: 66242.63
Iteration:    760, Loss function: 5.522, Average Loss: 4.040, avg. samples / sec: 66335.17
Iteration:    760, Loss function: 5.295, Average Loss: 3.994, avg. samples / sec: 66250.07
Iteration:    760, Loss function: 6.284, Average Loss: 4.005, avg. samples / sec: 66454.41
Iteration:    760, Loss function: 5.849, Average Loss: 4.033, avg. samples / sec: 66371.10
Iteration:    760, Loss function: 6.725, Average Loss: 3.990, avg. samples / sec: 66254.00
Iteration:    760, Loss function: 6.581, Average Loss: 4.003, avg. samples / sec: 66300.60
Iteration:    760, Loss function: 5.126, Average Loss: 3.987, avg. samples / sec: 66235.35
Iteration:    760, Loss function: 5.097, Average Loss: 4.000, avg. samples / sec: 66209.95
Iteration:    760, Loss function: 6.033, Average Loss: 4.012, avg. samples / sec: 66358.35
Iteration:    760, Loss function: 5.254, Average Loss: 3.995, avg. samples / sec: 66253.31
Iteration:    760, Loss function: 5.819, Average Loss: 4.003, avg. samples / sec: 66229.68
Iteration:    760, Loss function: 6.169, Average Loss: 3.992, avg. samples / sec: 66298.69
Iteration:    760, Loss function: 6.980, Average Loss: 4.003, avg. samples / sec: 66178.86
Iteration:    760, Loss function: 4.850, Average Loss: 3.995, avg. samples / sec: 66285.53
Iteration:    760, Loss function: 5.515, Average Loss: 4.011, avg. samples / sec: 66274.44
Iteration:    760, Loss function: 6.035, Average Loss: 3.997, avg. samples / sec: 66219.88
:::MLL 1558651376.981 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558651376.981 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 5.119, Average Loss: 4.040, avg. samples / sec: 65933.37
Iteration:    780, Loss function: 5.237, Average Loss: 4.025, avg. samples / sec: 66033.55
Iteration:    780, Loss function: 4.989, Average Loss: 4.061, avg. samples / sec: 65921.15
Iteration:    780, Loss function: 5.555, Average Loss: 4.063, avg. samples / sec: 66006.96
Iteration:    780, Loss function: 5.857, Average Loss: 4.030, avg. samples / sec: 65967.04
Iteration:    780, Loss function: 4.953, Average Loss: 4.049, avg. samples / sec: 65876.41
Iteration:    780, Loss function: 4.064, Average Loss: 4.042, avg. samples / sec: 65907.50
Iteration:    780, Loss function: 5.294, Average Loss: 4.024, avg. samples / sec: 66037.27
Iteration:    780, Loss function: 5.362, Average Loss: 4.007, avg. samples / sec: 65805.78
Iteration:    780, Loss function: 4.538, Average Loss: 4.030, avg. samples / sec: 65991.87
Iteration:    780, Loss function: 4.962, Average Loss: 4.014, avg. samples / sec: 65973.77
Iteration:    780, Loss function: 4.586, Average Loss: 4.036, avg. samples / sec: 65798.35
Iteration:    780, Loss function: 3.914, Average Loss: 4.018, avg. samples / sec: 65899.24
Iteration:    780, Loss function: 4.974, Average Loss: 4.022, avg. samples / sec: 65991.90
Iteration:    780, Loss function: 4.956, Average Loss: 4.033, avg. samples / sec: 65962.99
Iteration:    780, Loss function: 6.281, Average Loss: 4.038, avg. samples / sec: 65909.96
Iteration:    780, Loss function: 6.000, Average Loss: 4.046, avg. samples / sec: 65753.47
Iteration:    780, Loss function: 4.201, Average Loss: 4.043, avg. samples / sec: 65834.53
Iteration:    780, Loss function: 5.234, Average Loss: 4.072, avg. samples / sec: 65883.71
Iteration:    780, Loss function: 6.042, Average Loss: 4.047, avg. samples / sec: 65868.34
Iteration:    780, Loss function: 5.410, Average Loss: 4.035, avg. samples / sec: 65861.11
Iteration:    780, Loss function: 4.993, Average Loss: 4.031, avg. samples / sec: 65892.21
Iteration:    780, Loss function: 6.135, Average Loss: 4.047, avg. samples / sec: 65939.63
Iteration:    780, Loss function: 5.951, Average Loss: 4.023, avg. samples / sec: 65862.13
Iteration:    780, Loss function: 5.056, Average Loss: 4.036, avg. samples / sec: 65776.05
Iteration:    780, Loss function: 5.536, Average Loss: 4.022, avg. samples / sec: 65847.17
Iteration:    780, Loss function: 4.647, Average Loss: 4.018, avg. samples / sec: 65857.94
Iteration:    780, Loss function: 5.371, Average Loss: 4.049, avg. samples / sec: 65835.63
Iteration:    780, Loss function: 5.036, Average Loss: 4.021, avg. samples / sec: 65876.23
Iteration:    780, Loss function: 5.436, Average Loss: 4.047, avg. samples / sec: 65763.35
Iteration:    800, Loss function: 5.732, Average Loss: 4.086, avg. samples / sec: 66292.52
Iteration:    800, Loss function: 5.426, Average Loss: 4.055, avg. samples / sec: 66309.42
Iteration:    800, Loss function: 5.014, Average Loss: 4.078, avg. samples / sec: 66251.60
Iteration:    800, Loss function: 5.187, Average Loss: 4.064, avg. samples / sec: 66251.01
Iteration:    800, Loss function: 4.901, Average Loss: 4.066, avg. samples / sec: 66278.61
Iteration:    800, Loss function: 5.107, Average Loss: 4.088, avg. samples / sec: 66187.94
Iteration:    800, Loss function: 5.226, Average Loss: 4.041, avg. samples / sec: 66317.79
Iteration:    800, Loss function: 4.281, Average Loss: 4.062, avg. samples / sec: 66183.31
Iteration:    800, Loss function: 5.522, Average Loss: 4.049, avg. samples / sec: 66102.41
Iteration:    800, Loss function: 4.655, Average Loss: 4.061, avg. samples / sec: 66183.15
Iteration:    800, Loss function: 6.443, Average Loss: 4.046, avg. samples / sec: 66329.27
Iteration:    800, Loss function: 5.452, Average Loss: 4.051, avg. samples / sec: 66287.03
Iteration:    800, Loss function: 5.622, Average Loss: 4.052, avg. samples / sec: 66248.49
Iteration:    800, Loss function: 5.585, Average Loss: 4.075, avg. samples / sec: 66333.46
Iteration:    800, Loss function: 3.975, Average Loss: 4.068, avg. samples / sec: 66233.35
Iteration:    800, Loss function: 4.422, Average Loss: 4.052, avg. samples / sec: 66153.36
Iteration:    800, Loss function: 5.352, Average Loss: 4.049, avg. samples / sec: 66151.71
Iteration:    800, Loss function: 5.435, Average Loss: 4.071, avg. samples / sec: 66297.35
Iteration:    800, Loss function: 6.347, Average Loss: 4.045, avg. samples / sec: 66280.45
Iteration:    800, Loss function: 4.530, Average Loss: 4.061, avg. samples / sec: 66145.78
Iteration:    800, Loss function: 5.707, Average Loss: 4.044, avg. samples / sec: 66145.84
Iteration:    800, Loss function: 5.425, Average Loss: 4.072, avg. samples / sec: 66201.49
Iteration:    800, Loss function: 5.122, Average Loss: 4.066, avg. samples / sec: 66027.34
Iteration:    800, Loss function: 4.644, Average Loss: 4.029, avg. samples / sec: 66100.42
Iteration:    800, Loss function: 5.448, Average Loss: 4.069, avg. samples / sec: 66138.64
Iteration:    800, Loss function: 6.471, Average Loss: 4.100, avg. samples / sec: 66150.47
Iteration:    800, Loss function: 5.250, Average Loss: 4.068, avg. samples / sec: 66132.68
Iteration:    800, Loss function: 5.543, Average Loss: 4.063, avg. samples / sec: 66133.99
Iteration:    800, Loss function: 4.669, Average Loss: 4.039, avg. samples / sec: 66049.49
Iteration:    800, Loss function: 5.850, Average Loss: 4.061, avg. samples / sec: 66046.95
Iteration:    820, Loss function: 5.669, Average Loss: 4.056, avg. samples / sec: 66517.15
Iteration:    820, Loss function: 6.133, Average Loss: 4.078, avg. samples / sec: 66423.63
Iteration:    820, Loss function: 5.327, Average Loss: 4.082, avg. samples / sec: 66437.56
Iteration:    820, Loss function: 4.866, Average Loss: 4.088, avg. samples / sec: 66384.08
Iteration:    820, Loss function: 5.018, Average Loss: 4.092, avg. samples / sec: 66440.47
Iteration:    820, Loss function: 4.425, Average Loss: 4.059, avg. samples / sec: 66541.83
Iteration:    820, Loss function: 5.193, Average Loss: 4.086, avg. samples / sec: 66390.83
Iteration:    820, Loss function: 4.854, Average Loss: 4.085, avg. samples / sec: 66501.08
Iteration:    820, Loss function: 4.508, Average Loss: 4.088, avg. samples / sec: 66469.80
Iteration:    820, Loss function: 5.142, Average Loss: 4.102, avg. samples / sec: 66296.89
Iteration:    820, Loss function: 4.611, Average Loss: 4.073, avg. samples / sec: 66397.93
Iteration:    820, Loss function: 4.827, Average Loss: 4.078, avg. samples / sec: 66254.12
Iteration:    820, Loss function: 5.592, Average Loss: 4.096, avg. samples / sec: 66256.86
Iteration:    820, Loss function: 5.096, Average Loss: 4.083, avg. samples / sec: 66408.35
Iteration:    820, Loss function: 5.884, Average Loss: 4.106, avg. samples / sec: 66196.49
Iteration:    820, Loss function: 5.435, Average Loss: 4.094, avg. samples / sec: 66442.20
Iteration:    820, Loss function: 4.974, Average Loss: 4.073, avg. samples / sec: 66373.32
Iteration:    820, Loss function: 5.377, Average Loss: 4.114, avg. samples / sec: 66278.77
Iteration:    820, Loss function: 4.470, Average Loss: 4.098, avg. samples / sec: 66402.97
Iteration:    820, Loss function: 5.983, Average Loss: 4.084, avg. samples / sec: 66564.08
Iteration:    820, Loss function: 5.004, Average Loss: 4.065, avg. samples / sec: 66304.43
Iteration:    820, Loss function: 5.431, Average Loss: 4.082, avg. samples / sec: 66329.06
Iteration:    820, Loss function: 5.995, Average Loss: 4.083, avg. samples / sec: 66429.76
Iteration:    820, Loss function: 4.743, Average Loss: 4.100, avg. samples / sec: 66294.58
Iteration:    820, Loss function: 4.936, Average Loss: 4.069, avg. samples / sec: 66259.61
Iteration:    820, Loss function: 4.856, Average Loss: 4.082, avg. samples / sec: 66236.90
Iteration:    820, Loss function: 4.928, Average Loss: 4.069, avg. samples / sec: 66281.11
Iteration:    820, Loss function: 4.971, Average Loss: 4.094, avg. samples / sec: 66239.39
Iteration:    820, Loss function: 5.090, Average Loss: 4.121, avg. samples / sec: 66283.54
Iteration:    820, Loss function: 4.881, Average Loss: 4.075, avg. samples / sec: 66194.12
:::MLL 1558651378.758 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558651378.758 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 4.819, Average Loss: 4.105, avg. samples / sec: 66334.43
Iteration:    840, Loss function: 6.766, Average Loss: 4.111, avg. samples / sec: 66223.39
Iteration:    840, Loss function: 5.357, Average Loss: 4.091, avg. samples / sec: 66395.93
Iteration:    840, Loss function: 5.590, Average Loss: 4.102, avg. samples / sec: 66284.51
Iteration:    840, Loss function: 5.597, Average Loss: 4.078, avg. samples / sec: 66161.21
Iteration:    840, Loss function: 4.888, Average Loss: 4.122, avg. samples / sec: 66222.02
Iteration:    840, Loss function: 4.776, Average Loss: 4.080, avg. samples / sec: 66160.90
Iteration:    840, Loss function: 5.569, Average Loss: 4.102, avg. samples / sec: 66141.03
Iteration:    840, Loss function: 4.475, Average Loss: 4.122, avg. samples / sec: 66273.56
Iteration:    840, Loss function: 5.639, Average Loss: 4.116, avg. samples / sec: 66146.81
Iteration:    840, Loss function: 6.085, Average Loss: 4.101, avg. samples / sec: 66196.55
Iteration:    840, Loss function: 5.943, Average Loss: 4.100, avg. samples / sec: 66189.74
Iteration:    840, Loss function: 5.693, Average Loss: 4.142, avg. samples / sec: 66205.60
Iteration:    840, Loss function: 4.783, Average Loss: 4.117, avg. samples / sec: 66162.30
Iteration:    840, Loss function: 4.415, Average Loss: 4.119, avg. samples / sec: 66214.34
Iteration:    840, Loss function: 4.879, Average Loss: 4.128, avg. samples / sec: 66191.98
Iteration:    840, Loss function: 5.936, Average Loss: 4.103, avg. samples / sec: 66211.26
Iteration:    840, Loss function: 5.170, Average Loss: 4.148, avg. samples / sec: 66342.08
Iteration:    840, Loss function: 5.002, Average Loss: 4.110, avg. samples / sec: 66168.27
Iteration:    840, Loss function: 5.413, Average Loss: 4.124, avg. samples / sec: 66120.77
Iteration:    840, Loss function: 5.204, Average Loss: 4.114, avg. samples / sec: 66070.12
Iteration:    840, Loss function: 5.024, Average Loss: 4.108, avg. samples / sec: 66180.70
Iteration:    840, Loss function: 4.793, Average Loss: 4.102, avg. samples / sec: 66313.29
Iteration:    840, Loss function: 4.769, Average Loss: 4.110, avg. samples / sec: 66084.37
Iteration:    840, Loss function: 4.921, Average Loss: 4.122, avg. samples / sec: 66144.01
Iteration:    840, Loss function: 5.633, Average Loss: 4.100, avg. samples / sec: 66125.86
Iteration:    840, Loss function: 5.735, Average Loss: 4.097, avg. samples / sec: 66233.60
Iteration:    840, Loss function: 5.612, Average Loss: 4.086, avg. samples / sec: 66084.49
Iteration:    840, Loss function: 5.186, Average Loss: 4.105, avg. samples / sec: 66155.10
Iteration:    840, Loss function: 4.978, Average Loss: 4.116, avg. samples / sec: 66175.07
Iteration:    860, Loss function: 4.662, Average Loss: 4.132, avg. samples / sec: 66465.01
Iteration:    860, Loss function: 5.393, Average Loss: 4.137, avg. samples / sec: 66570.25
Iteration:    860, Loss function: 5.170, Average Loss: 4.122, avg. samples / sec: 66485.42
Iteration:    860, Loss function: 4.720, Average Loss: 4.143, avg. samples / sec: 66537.43
Iteration:    860, Loss function: 3.962, Average Loss: 4.160, avg. samples / sec: 66495.84
Iteration:    860, Loss function: 4.146, Average Loss: 4.134, avg. samples / sec: 66467.36
Iteration:    860, Loss function: 3.853, Average Loss: 4.140, avg. samples / sec: 66535.96
Iteration:    860, Loss function: 5.184, Average Loss: 4.101, avg. samples / sec: 66421.15
Iteration:    860, Loss function: 6.241, Average Loss: 4.127, avg. samples / sec: 66538.31
Iteration:    860, Loss function: 5.130, Average Loss: 4.121, avg. samples / sec: 66478.24
Iteration:    860, Loss function: 4.521, Average Loss: 4.127, avg. samples / sec: 66618.65
Iteration:    860, Loss function: 4.127, Average Loss: 4.094, avg. samples / sec: 66417.74
Iteration:    860, Loss function: 6.043, Average Loss: 4.152, avg. samples / sec: 66437.75
Iteration:    860, Loss function: 5.975, Average Loss: 4.129, avg. samples / sec: 66206.03
Iteration:    860, Loss function: 5.161, Average Loss: 4.128, avg. samples / sec: 66379.04
Iteration:    860, Loss function: 5.126, Average Loss: 4.145, avg. samples / sec: 66409.07
Iteration:    860, Loss function: 4.694, Average Loss: 4.171, avg. samples / sec: 66423.50
Iteration:    860, Loss function: 6.692, Average Loss: 4.148, avg. samples / sec: 66467.61
Iteration:    860, Loss function: 5.323, Average Loss: 4.144, avg. samples / sec: 66365.04
Iteration:    860, Loss function: 5.718, Average Loss: 4.110, avg. samples / sec: 66315.32
Iteration:    860, Loss function: 5.236, Average Loss: 4.125, avg. samples / sec: 66352.20
Iteration:    860, Loss function: 5.319, Average Loss: 4.137, avg. samples / sec: 66358.01
Iteration:    860, Loss function: 5.329, Average Loss: 4.139, avg. samples / sec: 66526.47
Iteration:    860, Loss function: 5.082, Average Loss: 4.125, avg. samples / sec: 66323.16
Iteration:    860, Loss function: 4.715, Average Loss: 4.120, avg. samples / sec: 66409.04
Iteration:    860, Loss function: 5.516, Average Loss: 4.131, avg. samples / sec: 66336.83
Iteration:    860, Loss function: 6.015, Average Loss: 4.135, avg. samples / sec: 66273.78
Iteration:    860, Loss function: 6.003, Average Loss: 4.138, avg. samples / sec: 66273.25
Iteration:    860, Loss function: 5.528, Average Loss: 4.128, avg. samples / sec: 66307.27
Iteration:    860, Loss function: 4.448, Average Loss: 4.104, avg. samples / sec: 66354.51
Iteration:    880, Loss function: 5.200, Average Loss: 4.160, avg. samples / sec: 66718.81
Iteration:    880, Loss function: 4.638, Average Loss: 4.162, avg. samples / sec: 66699.24
Iteration:    880, Loss function: 4.496, Average Loss: 4.158, avg. samples / sec: 66601.27
Iteration:    880, Loss function: 5.168, Average Loss: 4.159, avg. samples / sec: 66761.64
Iteration:    880, Loss function: 4.028, Average Loss: 4.115, avg. samples / sec: 66711.58
Iteration:    880, Loss function: 5.583, Average Loss: 4.167, avg. samples / sec: 66704.63
Iteration:    880, Loss function: 3.867, Average Loss: 4.146, avg. samples / sec: 66615.25
Iteration:    880, Loss function: 5.741, Average Loss: 4.181, avg. samples / sec: 66628.00
Iteration:    880, Loss function: 4.685, Average Loss: 4.168, avg. samples / sec: 66600.17
Iteration:    880, Loss function: 5.003, Average Loss: 4.143, avg. samples / sec: 66759.46
Iteration:    880, Loss function: 4.725, Average Loss: 4.154, avg. samples / sec: 66564.30
Iteration:    880, Loss function: 4.251, Average Loss: 4.165, avg. samples / sec: 66700.94
Iteration:    880, Loss function: 4.273, Average Loss: 4.167, avg. samples / sec: 66714.68
Iteration:    880, Loss function: 4.921, Average Loss: 4.160, avg. samples / sec: 66824.70
Iteration:    880, Loss function: 4.740, Average Loss: 4.147, avg. samples / sec: 66686.26
Iteration:    880, Loss function: 5.759, Average Loss: 4.125, avg. samples / sec: 66589.15
Iteration:    880, Loss function: 4.549, Average Loss: 4.152, avg. samples / sec: 66629.48
Iteration:    880, Loss function: 4.730, Average Loss: 4.151, avg. samples / sec: 66741.82
Iteration:    880, Loss function: 5.809, Average Loss: 4.135, avg. samples / sec: 66812.98
Iteration:    880, Loss function: 6.617, Average Loss: 4.135, avg. samples / sec: 66647.88
Iteration:    880, Loss function: 5.667, Average Loss: 4.148, avg. samples / sec: 66559.84
Iteration:    880, Loss function: 5.483, Average Loss: 4.156, avg. samples / sec: 66706.62
Iteration:    880, Loss function: 5.622, Average Loss: 4.147, avg. samples / sec: 66530.96
Iteration:    880, Loss function: 5.465, Average Loss: 4.177, avg. samples / sec: 66575.34
Iteration:    880, Loss function: 6.072, Average Loss: 4.157, avg. samples / sec: 66753.16
Iteration:    880, Loss function: 5.595, Average Loss: 4.192, avg. samples / sec: 66588.24
Iteration:    880, Loss function: 3.995, Average Loss: 4.144, avg. samples / sec: 66523.27
Iteration:    880, Loss function: 6.135, Average Loss: 4.147, avg. samples / sec: 66607.72
Iteration:    880, Loss function: 5.689, Average Loss: 4.155, avg. samples / sec: 66471.69
Iteration:    880, Loss function: 5.562, Average Loss: 4.162, avg. samples / sec: 66490.69
Iteration:    900, Loss function: 4.025, Average Loss: 4.179, avg. samples / sec: 66406.38
Iteration:    900, Loss function: 6.284, Average Loss: 4.200, avg. samples / sec: 66542.37
Iteration:    900, Loss function: 5.847, Average Loss: 4.182, avg. samples / sec: 66348.39
Iteration:    900, Loss function: 5.869, Average Loss: 4.184, avg. samples / sec: 66326.90
Iteration:    900, Loss function: 4.843, Average Loss: 4.190, avg. samples / sec: 66397.06
Iteration:    900, Loss function: 4.522, Average Loss: 4.168, avg. samples / sec: 66488.78
Iteration:    900, Loss function: 4.769, Average Loss: 4.172, avg. samples / sec: 66349.63
Iteration:    900, Loss function: 4.864, Average Loss: 4.174, avg. samples / sec: 66457.58
Iteration:    900, Loss function: 7.120, Average Loss: 4.208, avg. samples / sec: 66478.24
Iteration:    900, Loss function: 5.398, Average Loss: 4.164, avg. samples / sec: 66378.70
Iteration:    900, Loss function: 5.013, Average Loss: 4.176, avg. samples / sec: 66384.73
Iteration:    900, Loss function: 5.126, Average Loss: 4.170, avg. samples / sec: 66333.24
Iteration:    900, Loss function: 6.027, Average Loss: 4.186, avg. samples / sec: 66339.20
Iteration:    900, Loss function: 5.015, Average Loss: 4.175, avg. samples / sec: 66203.80
Iteration:    900, Loss function: 5.619, Average Loss: 4.158, avg. samples / sec: 66372.13
Iteration:    900, Loss function: 5.709, Average Loss: 4.135, avg. samples / sec: 66271.73
Iteration:    900, Loss function: 6.026, Average Loss: 4.168, avg. samples / sec: 66371.70
Iteration:    900, Loss function: 5.250, Average Loss: 4.179, avg. samples / sec: 66429.26
Iteration:    900, Loss function: 4.216, Average Loss: 4.198, avg. samples / sec: 66260.48
Iteration:    900, Loss function: 4.568, Average Loss: 4.171, avg. samples / sec: 66493.42
Iteration:    900, Loss function: 4.714, Average Loss: 4.147, avg. samples / sec: 66305.59
Iteration:    900, Loss function: 3.504, Average Loss: 4.168, avg. samples / sec: 66336.83
Iteration:    900, Loss function: 4.869, Average Loss: 4.148, avg. samples / sec: 66325.47
Iteration:    900, Loss function: 5.082, Average Loss: 4.169, avg. samples / sec: 66248.21
Iteration:    900, Loss function: 5.089, Average Loss: 4.179, avg. samples / sec: 66248.55
Iteration:    900, Loss function: 4.395, Average Loss: 4.187, avg. samples / sec: 66253.22
Iteration:    900, Loss function: 4.856, Average Loss: 4.164, avg. samples / sec: 66402.87
Iteration:    900, Loss function: 3.122, Average Loss: 4.160, avg. samples / sec: 66350.10
Iteration:    900, Loss function: 4.800, Average Loss: 4.190, avg. samples / sec: 66133.83
Iteration:    900, Loss function: 5.268, Average Loss: 4.184, avg. samples / sec: 66370.76
:::MLL 1558651380.528 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558651380.529 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 3.943, Average Loss: 4.203, avg. samples / sec: 66267.36
Iteration:    920, Loss function: 5.393, Average Loss: 4.191, avg. samples / sec: 66271.88
Iteration:    920, Loss function: 5.251, Average Loss: 4.188, avg. samples / sec: 66223.55
Iteration:    920, Loss function: 5.356, Average Loss: 4.202, avg. samples / sec: 66264.43
Iteration:    920, Loss function: 5.304, Average Loss: 4.197, avg. samples / sec: 66202.68
Iteration:    920, Loss function: 5.193, Average Loss: 4.197, avg. samples / sec: 66082.23
Iteration:    920, Loss function: 5.821, Average Loss: 4.201, avg. samples / sec: 66133.92
Iteration:    920, Loss function: 5.608, Average Loss: 4.169, avg. samples / sec: 66277.90
Iteration:    920, Loss function: 5.596, Average Loss: 4.175, avg. samples / sec: 66207.09
Iteration:    920, Loss function: 4.140, Average Loss: 4.188, avg. samples / sec: 66195.83
Iteration:    920, Loss function: 4.303, Average Loss: 4.216, avg. samples / sec: 66193.97
Iteration:    920, Loss function: 5.240, Average Loss: 4.206, avg. samples / sec: 66094.84
Iteration:    920, Loss function: 5.212, Average Loss: 4.156, avg. samples / sec: 66167.58
Iteration:    920, Loss function: 3.500, Average Loss: 4.207, avg. samples / sec: 66304.87
Iteration:    920, Loss function: 5.335, Average Loss: 4.223, avg. samples / sec: 66016.14
Iteration:    920, Loss function: 5.357, Average Loss: 4.177, avg. samples / sec: 66236.50
Iteration:    920, Loss function: 5.013, Average Loss: 4.166, avg. samples / sec: 66193.19
Iteration:    920, Loss function: 5.285, Average Loss: 4.189, avg. samples / sec: 66076.06
Iteration:    920, Loss function: 5.978, Average Loss: 4.195, avg. samples / sec: 66060.48
Iteration:    920, Loss function: 3.299, Average Loss: 4.185, avg. samples / sec: 66199.57
Iteration:    920, Loss function: 4.553, Average Loss: 4.191, avg. samples / sec: 66120.92
Iteration:    920, Loss function: 4.330, Average Loss: 4.185, avg. samples / sec: 66171.87
Iteration:    920, Loss function: 3.856, Average Loss: 4.195, avg. samples / sec: 66105.63
Iteration:    920, Loss function: 4.816, Average Loss: 4.203, avg. samples / sec: 66182.03
Iteration:    920, Loss function: 4.900, Average Loss: 4.225, avg. samples / sec: 66028.57
Iteration:    920, Loss function: 4.268, Average Loss: 4.204, avg. samples / sec: 66266.49
Iteration:    920, Loss function: 4.990, Average Loss: 4.180, avg. samples / sec: 66051.69
Iteration:    920, Loss function: 5.254, Average Loss: 4.192, avg. samples / sec: 66069.81
Iteration:    920, Loss function: 4.800, Average Loss: 4.186, avg. samples / sec: 66077.55
Iteration:    920, Loss function: 4.643, Average Loss: 4.200, avg. samples / sec: 66065.78
Iteration:    940, Loss function: 5.815, Average Loss: 4.197, avg. samples / sec: 66425.25
Iteration:    940, Loss function: 4.788, Average Loss: 4.223, avg. samples / sec: 66407.16
Iteration:    940, Loss function: 5.804, Average Loss: 4.214, avg. samples / sec: 66284.47
Iteration:    940, Loss function: 5.119, Average Loss: 4.207, avg. samples / sec: 66416.05
Iteration:    940, Loss function: 4.925, Average Loss: 4.243, avg. samples / sec: 66378.64
Iteration:    940, Loss function: 4.892, Average Loss: 4.194, avg. samples / sec: 66304.00
Iteration:    940, Loss function: 5.794, Average Loss: 4.210, avg. samples / sec: 66464.66
Iteration:    940, Loss function: 5.591, Average Loss: 4.218, avg. samples / sec: 66408.04
Iteration:    940, Loss function: 6.133, Average Loss: 4.216, avg. samples / sec: 66244.25
Iteration:    940, Loss function: 4.678, Average Loss: 4.210, avg. samples / sec: 66179.42
Iteration:    940, Loss function: 4.700, Average Loss: 4.225, avg. samples / sec: 66368.19
Iteration:    940, Loss function: 4.957, Average Loss: 4.208, avg. samples / sec: 66272.50
Iteration:    940, Loss function: 6.992, Average Loss: 4.248, avg. samples / sec: 66396.77
Iteration:    940, Loss function: 4.868, Average Loss: 4.225, avg. samples / sec: 66173.14
Iteration:    940, Loss function: 6.481, Average Loss: 4.177, avg. samples / sec: 66269.51
Iteration:    940, Loss function: 5.736, Average Loss: 4.210, avg. samples / sec: 66430.45
Iteration:    940, Loss function: 5.578, Average Loss: 4.223, avg. samples / sec: 66095.31
Iteration:    940, Loss function: 5.193, Average Loss: 4.203, avg. samples / sec: 66371.45
Iteration:    940, Loss function: 4.775, Average Loss: 4.209, avg. samples / sec: 66309.21
Iteration:    940, Loss function: 4.552, Average Loss: 4.219, avg. samples / sec: 66433.49
Iteration:    940, Loss function: 5.529, Average Loss: 4.201, avg. samples / sec: 66291.86
Iteration:    940, Loss function: 3.579, Average Loss: 4.187, avg. samples / sec: 66269.79
Iteration:    940, Loss function: 4.391, Average Loss: 4.210, avg. samples / sec: 66277.68
Iteration:    940, Loss function: 6.185, Average Loss: 4.231, avg. samples / sec: 66247.52
Iteration:    940, Loss function: 4.888, Average Loss: 4.219, avg. samples / sec: 66282.54
Iteration:    940, Loss function: 6.362, Average Loss: 4.234, avg. samples / sec: 66216.11
Iteration:    940, Loss function: 4.795, Average Loss: 4.222, avg. samples / sec: 66166.99
Iteration:    940, Loss function: 4.049, Average Loss: 4.224, avg. samples / sec: 66318.91
Iteration:    940, Loss function: 4.833, Average Loss: 4.194, avg. samples / sec: 66178.30
Iteration:    940, Loss function: 5.522, Average Loss: 4.215, avg. samples / sec: 66121.88
Iteration:    960, Loss function: 5.932, Average Loss: 4.236, avg. samples / sec: 66670.40
Iteration:    960, Loss function: 5.944, Average Loss: 4.193, avg. samples / sec: 66670.99
Iteration:    960, Loss function: 4.662, Average Loss: 4.225, avg. samples / sec: 66639.59
Iteration:    960, Loss function: 5.338, Average Loss: 4.230, avg. samples / sec: 66653.43
Iteration:    960, Loss function: 6.305, Average Loss: 4.243, avg. samples / sec: 66639.28
Iteration:    960, Loss function: 4.344, Average Loss: 4.238, avg. samples / sec: 66669.45
Iteration:    960, Loss function: 5.601, Average Loss: 4.239, avg. samples / sec: 66695.70
Iteration:    960, Loss function: 4.637, Average Loss: 4.231, avg. samples / sec: 66724.63
Iteration:    960, Loss function: 5.727, Average Loss: 4.230, avg. samples / sec: 66519.19
Iteration:    960, Loss function: 5.798, Average Loss: 4.231, avg. samples / sec: 66564.84
Iteration:    960, Loss function: 5.636, Average Loss: 4.226, avg. samples / sec: 66533.88
Iteration:    960, Loss function: 5.030, Average Loss: 4.220, avg. samples / sec: 66451.50
Iteration:    960, Loss function: 3.844, Average Loss: 4.251, avg. samples / sec: 66626.74
Iteration:    960, Loss function: 4.649, Average Loss: 4.263, avg. samples / sec: 66543.18
Iteration:    960, Loss function: 5.461, Average Loss: 4.206, avg. samples / sec: 66609.20
Iteration:    960, Loss function: 6.038, Average Loss: 4.241, avg. samples / sec: 66422.87
Iteration:    960, Loss function: 6.954, Average Loss: 4.232, avg. samples / sec: 66498.79
Iteration:    960, Loss function: 5.482, Average Loss: 4.211, avg. samples / sec: 66462.31
Iteration:    960, Loss function: 6.207, Average Loss: 4.217, avg. samples / sec: 66595.79
Iteration:    960, Loss function: 4.983, Average Loss: 4.226, avg. samples / sec: 66439.09
Iteration:    960, Loss function: 5.196, Average Loss: 4.247, avg. samples / sec: 66503.15
Iteration:    960, Loss function: 5.337, Average Loss: 4.263, avg. samples / sec: 66419.74
Iteration:    960, Loss function: 5.138, Average Loss: 4.231, avg. samples / sec: 66562.61
Iteration:    960, Loss function: 5.195, Average Loss: 4.250, avg. samples / sec: 66474.54
Iteration:    960, Loss function: 5.116, Average Loss: 4.220, avg. samples / sec: 66512.41
Iteration:    960, Loss function: 3.822, Average Loss: 4.227, avg. samples / sec: 66476.92
Iteration:    960, Loss function: 5.824, Average Loss: 4.222, avg. samples / sec: 66446.21
Iteration:    960, Loss function: 4.921, Average Loss: 4.242, avg. samples / sec: 66492.76
Iteration:    960, Loss function: 3.974, Average Loss: 4.248, avg. samples / sec: 66456.86
Iteration:    960, Loss function: 6.339, Average Loss: 4.239, avg. samples / sec: 66444.01
:::MLL 1558651382.316 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558651382.316 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 4.638, Average Loss: 4.250, avg. samples / sec: 64459.66
Iteration:    980, Loss function: 4.264, Average Loss: 4.241, avg. samples / sec: 64529.20
Iteration:    980, Loss function: 4.409, Average Loss: 4.234, avg. samples / sec: 64520.72
Iteration:    980, Loss function: 4.670, Average Loss: 4.249, avg. samples / sec: 64407.73
Iteration:    980, Loss function: 5.178, Average Loss: 4.271, avg. samples / sec: 64522.91
Iteration:    980, Loss function: 4.943, Average Loss: 4.207, avg. samples / sec: 64385.60
Iteration:    980, Loss function: 5.820, Average Loss: 4.230, avg. samples / sec: 64464.41
Iteration:    980, Loss function: 4.317, Average Loss: 4.257, avg. samples / sec: 64351.96
Iteration:    980, Loss function: 6.022, Average Loss: 4.256, avg. samples / sec: 64410.67
Iteration:    980, Loss function: 6.179, Average Loss: 4.249, avg. samples / sec: 64439.95
Iteration:    980, Loss function: 4.425, Average Loss: 4.250, avg. samples / sec: 64325.56
Iteration:    980, Loss function: 5.169, Average Loss: 4.264, avg. samples / sec: 64419.30
Iteration:    980, Loss function: 4.429, Average Loss: 4.240, avg. samples / sec: 64364.22
Iteration:    980, Loss function: 4.138, Average Loss: 4.244, avg. samples / sec: 64343.68
Iteration:    980, Loss function: 3.798, Average Loss: 4.264, avg. samples / sec: 64507.99
Iteration:    980, Loss function: 6.391, Average Loss: 4.254, avg. samples / sec: 64288.91
Iteration:    980, Loss function: 4.384, Average Loss: 4.242, avg. samples / sec: 64458.60
Iteration:    980, Loss function: 5.635, Average Loss: 4.244, avg. samples / sec: 64453.24
Iteration:    980, Loss function: 5.196, Average Loss: 4.242, avg. samples / sec: 64250.51
Iteration:    980, Loss function: 5.061, Average Loss: 4.259, avg. samples / sec: 64500.88
Iteration:    980, Loss function: 5.225, Average Loss: 4.240, avg. samples / sec: 64241.52
Iteration:    980, Loss function: 5.254, Average Loss: 4.246, avg. samples / sec: 64323.91
Iteration:    980, Loss function: 4.019, Average Loss: 4.224, avg. samples / sec: 64331.49
Iteration:    980, Loss function: 5.220, Average Loss: 4.278, avg. samples / sec: 64310.44
Iteration:    980, Loss function: 3.595, Average Loss: 4.236, avg. samples / sec: 64358.87
Iteration:    980, Loss function: 4.897, Average Loss: 4.248, avg. samples / sec: 64189.93
Iteration:    980, Loss function: 5.254, Average Loss: 4.235, avg. samples / sec: 64251.62
Iteration:    980, Loss function: 5.861, Average Loss: 4.270, avg. samples / sec: 64272.75
Iteration:    980, Loss function: 4.454, Average Loss: 4.265, avg. samples / sec: 64318.72
Iteration:    980, Loss function: 4.221, Average Loss: 4.258, avg. samples / sec: 64225.51
Iteration:   1000, Loss function: 5.192, Average Loss: 4.261, avg. samples / sec: 66446.55
Iteration:   1000, Loss function: 4.981, Average Loss: 4.269, avg. samples / sec: 66433.55
Iteration:   1000, Loss function: 3.888, Average Loss: 4.270, avg. samples / sec: 66393.05
Iteration:   1000, Loss function: 4.267, Average Loss: 4.258, avg. samples / sec: 66476.64
Iteration:   1000, Loss function: 5.373, Average Loss: 4.264, avg. samples / sec: 66524.87
Iteration:   1000, Loss function: 4.306, Average Loss: 4.261, avg. samples / sec: 66453.07
Iteration:   1000, Loss function: 4.761, Average Loss: 4.266, avg. samples / sec: 66298.04
Iteration:   1000, Loss function: 6.631, Average Loss: 4.222, avg. samples / sec: 66299.85
Iteration:   1000, Loss function: 4.815, Average Loss: 4.258, avg. samples / sec: 66416.55
Iteration:   1000, Loss function: 6.366, Average Loss: 4.296, avg. samples / sec: 66460.12
Iteration:   1000, Loss function: 5.388, Average Loss: 4.287, avg. samples / sec: 66271.16
Iteration:   1000, Loss function: 4.896, Average Loss: 4.244, avg. samples / sec: 66294.27
Iteration:   1000, Loss function: 5.484, Average Loss: 4.268, avg. samples / sec: 66387.89
Iteration:   1000, Loss function: 6.208, Average Loss: 4.259, avg. samples / sec: 66220.97
Iteration:   1000, Loss function: 5.920, Average Loss: 4.283, avg. samples / sec: 66455.57
Iteration:   1000, Loss function: 4.104, Average Loss: 4.245, avg. samples / sec: 66215.86
Iteration:   1000, Loss function: 4.461, Average Loss: 4.257, avg. samples / sec: 66307.90
Iteration:   1000, Loss function: 5.054, Average Loss: 4.267, avg. samples / sec: 66111.28
Iteration:   1000, Loss function: 5.771, Average Loss: 4.265, avg. samples / sec: 66292.64
Iteration:   1000, Loss function: 2.996, Average Loss: 4.237, avg. samples / sec: 66369.57
Iteration:   1000, Loss function: 4.113, Average Loss: 4.268, avg. samples / sec: 66283.26
Iteration:   1000, Loss function: 4.574, Average Loss: 4.276, avg. samples / sec: 66298.10
Iteration:   1000, Loss function: 4.295, Average Loss: 4.260, avg. samples / sec: 66308.30
Iteration:   1000, Loss function: 4.732, Average Loss: 4.251, avg. samples / sec: 66324.53
Iteration:   1000, Loss function: 5.130, Average Loss: 4.273, avg. samples / sec: 66417.74
Iteration:   1000, Loss function: 5.987, Average Loss: 4.251, avg. samples / sec: 66380.57
Iteration:   1000, Loss function: 4.698, Average Loss: 4.279, avg. samples / sec: 66223.15
Iteration:   1000, Loss function: 5.726, Average Loss: 4.246, avg. samples / sec: 66300.85
Iteration:   1000, Loss function: 5.762, Average Loss: 4.277, avg. samples / sec: 66214.50
Iteration:   1000, Loss function: 6.011, Average Loss: 4.272, avg. samples / sec: 66419.18
Iteration:   1020, Loss function: 4.943, Average Loss: 4.282, avg. samples / sec: 66271.32
Iteration:   1020, Loss function: 4.230, Average Loss: 4.235, avg. samples / sec: 66297.35
Iteration:   1020, Loss function: 5.149, Average Loss: 4.287, avg. samples / sec: 66373.41
Iteration:   1020, Loss function: 4.521, Average Loss: 4.281, avg. samples / sec: 66341.92
Iteration:   1020, Loss function: 4.028, Average Loss: 4.287, avg. samples / sec: 66561.98
Iteration:   1020, Loss function: 4.785, Average Loss: 4.281, avg. samples / sec: 66261.66
Iteration:   1020, Loss function: 5.258, Average Loss: 4.261, avg. samples / sec: 66292.55
Iteration:   1020, Loss function: 4.416, Average Loss: 4.299, avg. samples / sec: 66455.48
Iteration:   1020, Loss function: 4.655, Average Loss: 4.278, avg. samples / sec: 66314.82
Iteration:   1020, Loss function: 5.842, Average Loss: 4.285, avg. samples / sec: 66180.76
Iteration:   1020, Loss function: 5.567, Average Loss: 4.278, avg. samples / sec: 66272.04
Iteration:   1020, Loss function: 5.427, Average Loss: 4.273, avg. samples / sec: 66220.94
Iteration:   1020, Loss function: 4.972, Average Loss: 4.286, avg. samples / sec: 66244.90
Iteration:   1020, Loss function: 5.518, Average Loss: 4.309, avg. samples / sec: 66250.29
Iteration:   1020, Loss function: 5.842, Average Loss: 4.277, avg. samples / sec: 66313.17
Iteration:   1020, Loss function: 5.281, Average Loss: 4.300, avg. samples / sec: 66227.94
Iteration:   1020, Loss function: 6.446, Average Loss: 4.291, avg. samples / sec: 66129.58
Iteration:   1020, Loss function: 5.522, Average Loss: 4.289, avg. samples / sec: 66299.32
Iteration:   1020, Loss function: 5.524, Average Loss: 4.262, avg. samples / sec: 66233.66
Iteration:   1020, Loss function: 5.860, Average Loss: 4.255, avg. samples / sec: 66253.09
Iteration:   1020, Loss function: 4.056, Average Loss: 4.267, avg. samples / sec: 66254.96
Iteration:   1020, Loss function: 4.871, Average Loss: 4.264, avg. samples / sec: 66359.04
Iteration:   1020, Loss function: 4.553, Average Loss: 4.274, avg. samples / sec: 66109.48
Iteration:   1020, Loss function: 4.566, Average Loss: 4.279, avg. samples / sec: 66141.12
Iteration:   1020, Loss function: 4.071, Average Loss: 4.316, avg. samples / sec: 66114.97
Iteration:   1020, Loss function: 4.487, Average Loss: 4.282, avg. samples / sec: 66112.70
Iteration:   1020, Loss function: 5.471, Average Loss: 4.289, avg. samples / sec: 66170.41
Iteration:   1020, Loss function: 4.859, Average Loss: 4.293, avg. samples / sec: 66148.86
Iteration:   1020, Loss function: 4.369, Average Loss: 4.269, avg. samples / sec: 66160.03
Iteration:   1020, Loss function: 4.652, Average Loss: 4.298, avg. samples / sec: 66251.16
Iteration:   1040, Loss function: 5.160, Average Loss: 4.303, avg. samples / sec: 66815.01
Iteration:   1040, Loss function: 4.825, Average Loss: 4.315, avg. samples / sec: 66573.68
Iteration:   1040, Loss function: 4.911, Average Loss: 4.294, avg. samples / sec: 66504.34
Iteration:   1040, Loss function: 5.596, Average Loss: 4.303, avg. samples / sec: 66594.91
Iteration:   1040, Loss function: 5.048, Average Loss: 4.301, avg. samples / sec: 66494.99
Iteration:   1040, Loss function: 5.500, Average Loss: 4.249, avg. samples / sec: 66438.53
Iteration:   1040, Loss function: 4.527, Average Loss: 4.289, avg. samples / sec: 66471.62
Iteration:   1040, Loss function: 6.174, Average Loss: 4.296, avg. samples / sec: 66433.08
Iteration:   1040, Loss function: 5.498, Average Loss: 4.310, avg. samples / sec: 66639.63
Iteration:   1040, Loss function: 4.806, Average Loss: 4.316, avg. samples / sec: 66530.71
Iteration:   1040, Loss function: 4.243, Average Loss: 4.283, avg. samples / sec: 66517.08
Iteration:   1040, Loss function: 5.013, Average Loss: 4.301, avg. samples / sec: 66378.79
Iteration:   1040, Loss function: 3.813, Average Loss: 4.269, avg. samples / sec: 66514.60
Iteration:   1040, Loss function: 5.331, Average Loss: 4.332, avg. samples / sec: 66549.88
Iteration:   1040, Loss function: 3.684, Average Loss: 4.290, avg. samples / sec: 66463.75
Iteration:   1040, Loss function: 5.174, Average Loss: 4.296, avg. samples / sec: 66533.82
Iteration:   1040, Loss function: 5.149, Average Loss: 4.283, avg. samples / sec: 66624.31
Iteration:   1040, Loss function: 5.457, Average Loss: 4.285, avg. samples / sec: 66491.38
Iteration:   1040, Loss function: 5.672, Average Loss: 4.281, avg. samples / sec: 66476.98
Iteration:   1040, Loss function: 4.044, Average Loss: 4.281, avg. samples / sec: 66356.45
Iteration:   1040, Loss function: 6.051, Average Loss: 4.302, avg. samples / sec: 66415.27
Iteration:   1040, Loss function: 4.089, Average Loss: 4.290, avg. samples / sec: 66523.21
Iteration:   1040, Loss function: 5.387, Average Loss: 4.304, avg. samples / sec: 66526.28
Iteration:   1040, Loss function: 4.989, Average Loss: 4.296, avg. samples / sec: 66308.61
Iteration:   1040, Loss function: 4.805, Average Loss: 4.294, avg. samples / sec: 66377.14
Iteration:   1040, Loss function: 5.384, Average Loss: 4.312, avg. samples / sec: 66353.88
Iteration:   1040, Loss function: 5.144, Average Loss: 4.304, avg. samples / sec: 66438.44
Iteration:   1040, Loss function: 3.895, Average Loss: 4.274, avg. samples / sec: 66463.72
Iteration:   1040, Loss function: 5.048, Average Loss: 4.296, avg. samples / sec: 66288.68
Iteration:   1040, Loss function: 6.828, Average Loss: 4.299, avg. samples / sec: 66327.46
:::MLL 1558651384.090 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558651384.090 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 4.582, Average Loss: 4.315, avg. samples / sec: 66184.58
Iteration:   1060, Loss function: 6.609, Average Loss: 4.315, avg. samples / sec: 66105.82
Iteration:   1060, Loss function: 6.121, Average Loss: 4.336, avg. samples / sec: 66069.78
Iteration:   1060, Loss function: 5.565, Average Loss: 4.315, avg. samples / sec: 66154.63
Iteration:   1060, Loss function: 6.007, Average Loss: 4.297, avg. samples / sec: 66205.41
Iteration:   1060, Loss function: 6.372, Average Loss: 4.318, avg. samples / sec: 66194.19
Iteration:   1060, Loss function: 5.402, Average Loss: 4.315, avg. samples / sec: 66154.57
Iteration:   1060, Loss function: 5.878, Average Loss: 4.318, avg. samples / sec: 66115.65
Iteration:   1060, Loss function: 5.768, Average Loss: 4.293, avg. samples / sec: 66164.13
Iteration:   1060, Loss function: 4.532, Average Loss: 4.322, avg. samples / sec: 65944.10
Iteration:   1060, Loss function: 4.525, Average Loss: 4.338, avg. samples / sec: 66076.53
Iteration:   1060, Loss function: 5.967, Average Loss: 4.309, avg. samples / sec: 66073.21
Iteration:   1060, Loss function: 6.255, Average Loss: 4.318, avg. samples / sec: 66131.16
Iteration:   1060, Loss function: 4.254, Average Loss: 4.299, avg. samples / sec: 66096.70
Iteration:   1060, Loss function: 5.205, Average Loss: 4.322, avg. samples / sec: 66203.30
Iteration:   1060, Loss function: 5.499, Average Loss: 4.324, avg. samples / sec: 65966.61
Iteration:   1060, Loss function: 4.555, Average Loss: 4.310, avg. samples / sec: 66106.69
Iteration:   1060, Loss function: 4.844, Average Loss: 4.316, avg. samples / sec: 66125.51
Iteration:   1060, Loss function: 5.530, Average Loss: 4.302, avg. samples / sec: 66104.24
Iteration:   1060, Loss function: 4.032, Average Loss: 4.351, avg. samples / sec: 66070.08
Iteration:   1060, Loss function: 5.734, Average Loss: 4.307, avg. samples / sec: 66072.13
Iteration:   1060, Loss function: 4.883, Average Loss: 4.327, avg. samples / sec: 66106.10
Iteration:   1060, Loss function: 5.914, Average Loss: 4.329, avg. samples / sec: 66101.69
Iteration:   1060, Loss function: 5.699, Average Loss: 4.301, avg. samples / sec: 66032.41
Iteration:   1060, Loss function: 5.316, Average Loss: 4.324, avg. samples / sec: 66078.98
Iteration:   1060, Loss function: 4.394, Average Loss: 4.268, avg. samples / sec: 65969.11
Iteration:   1060, Loss function: 5.660, Average Loss: 4.331, avg. samples / sec: 65959.47
Iteration:   1060, Loss function: 5.295, Average Loss: 4.318, avg. samples / sec: 66069.50
Iteration:   1060, Loss function: 5.561, Average Loss: 4.284, avg. samples / sec: 65942.13
Iteration:   1060, Loss function: 5.494, Average Loss: 4.306, avg. samples / sec: 65848.06
Iteration:   1080, Loss function: 5.458, Average Loss: 4.352, avg. samples / sec: 66573.27
Iteration:   1080, Loss function: 4.280, Average Loss: 4.319, avg. samples / sec: 66604.64
Iteration:   1080, Loss function: 5.428, Average Loss: 4.322, avg. samples / sec: 66840.48
Iteration:   1080, Loss function: 4.971, Average Loss: 4.327, avg. samples / sec: 66544.79
Iteration:   1080, Loss function: 4.322, Average Loss: 4.333, avg. samples / sec: 66503.62
Iteration:   1080, Loss function: 4.685, Average Loss: 4.327, avg. samples / sec: 66415.77
Iteration:   1080, Loss function: 4.088, Average Loss: 4.343, avg. samples / sec: 66550.98
Iteration:   1080, Loss function: 4.797, Average Loss: 4.308, avg. samples / sec: 66477.61
Iteration:   1080, Loss function: 4.472, Average Loss: 4.324, avg. samples / sec: 66364.01
Iteration:   1080, Loss function: 4.113, Average Loss: 4.332, avg. samples / sec: 66614.68
Iteration:   1080, Loss function: 5.454, Average Loss: 4.311, avg. samples / sec: 66538.50
Iteration:   1080, Loss function: 4.227, Average Loss: 4.323, avg. samples / sec: 66464.88
Iteration:   1080, Loss function: 5.305, Average Loss: 4.343, avg. samples / sec: 66506.82
Iteration:   1080, Loss function: 4.855, Average Loss: 4.300, avg. samples / sec: 66612.13
Iteration:   1080, Loss function: 5.931, Average Loss: 4.318, avg. samples / sec: 66449.75
Iteration:   1080, Loss function: 3.554, Average Loss: 4.319, avg. samples / sec: 66462.81
Iteration:   1080, Loss function: 5.401, Average Loss: 4.333, avg. samples / sec: 66437.65
Iteration:   1080, Loss function: 4.598, Average Loss: 4.329, avg. samples / sec: 66367.16
Iteration:   1080, Loss function: 5.011, Average Loss: 4.278, avg. samples / sec: 66493.23
Iteration:   1080, Loss function: 5.275, Average Loss: 4.334, avg. samples / sec: 66253.94
Iteration:   1080, Loss function: 4.842, Average Loss: 4.340, avg. samples / sec: 66518.59
Iteration:   1080, Loss function: 6.343, Average Loss: 4.346, avg. samples / sec: 66438.25
Iteration:   1080, Loss function: 4.852, Average Loss: 4.322, avg. samples / sec: 66414.89
Iteration:   1080, Loss function: 4.128, Average Loss: 4.329, avg. samples / sec: 66322.59
Iteration:   1080, Loss function: 4.463, Average Loss: 4.366, avg. samples / sec: 66413.20
Iteration:   1080, Loss function: 5.694, Average Loss: 4.337, avg. samples / sec: 66364.98
Iteration:   1080, Loss function: 5.342, Average Loss: 4.349, avg. samples / sec: 66265.34
Iteration:   1080, Loss function: 4.381, Average Loss: 4.318, avg. samples / sec: 66382.73
Iteration:   1080, Loss function: 4.541, Average Loss: 4.306, avg. samples / sec: 66170.04
Iteration:   1080, Loss function: 5.346, Average Loss: 4.341, avg. samples / sec: 66259.04
Iteration:   1100, Loss function: 4.498, Average Loss: 4.340, avg. samples / sec: 66632.54
Iteration:   1100, Loss function: 4.351, Average Loss: 4.347, avg. samples / sec: 66648.86
Iteration:   1100, Loss function: 5.812, Average Loss: 4.364, avg. samples / sec: 66649.27
Iteration:   1100, Loss function: 4.193, Average Loss: 4.321, avg. samples / sec: 66537.06
Iteration:   1100, Loss function: 4.847, Average Loss: 4.332, avg. samples / sec: 66556.13
Iteration:   1100, Loss function: 3.524, Average Loss: 4.355, avg. samples / sec: 66631.56
Iteration:   1100, Loss function: 5.075, Average Loss: 4.339, avg. samples / sec: 66643.47
Iteration:   1100, Loss function: 4.575, Average Loss: 4.338, avg. samples / sec: 66472.06
Iteration:   1100, Loss function: 4.709, Average Loss: 4.289, avg. samples / sec: 66582.48
Iteration:   1100, Loss function: 5.097, Average Loss: 4.358, avg. samples / sec: 66415.20
Iteration:   1100, Loss function: 5.206, Average Loss: 4.316, avg. samples / sec: 66535.89
Iteration:   1100, Loss function: 4.576, Average Loss: 4.342, avg. samples / sec: 66435.21
Iteration:   1100, Loss function: 5.142, Average Loss: 4.333, avg. samples / sec: 66467.95
Iteration:   1100, Loss function: 5.949, Average Loss: 4.344, avg. samples / sec: 66449.87
Iteration:   1100, Loss function: 4.079, Average Loss: 4.342, avg. samples / sec: 66546.55
Iteration:   1100, Loss function: 4.010, Average Loss: 4.332, avg. samples / sec: 66489.69
Iteration:   1100, Loss function: 5.991, Average Loss: 4.329, avg. samples / sec: 66525.31
Iteration:   1100, Loss function: 4.977, Average Loss: 4.330, avg. samples / sec: 66526.13
Iteration:   1100, Loss function: 5.408, Average Loss: 4.331, avg. samples / sec: 66385.30
Iteration:   1100, Loss function: 4.651, Average Loss: 4.375, avg. samples / sec: 66563.14
Iteration:   1100, Loss function: 3.771, Average Loss: 4.351, avg. samples / sec: 66732.71
Iteration:   1100, Loss function: 4.706, Average Loss: 4.358, avg. samples / sec: 66437.09
Iteration:   1100, Loss function: 4.917, Average Loss: 4.352, avg. samples / sec: 66479.87
Iteration:   1100, Loss function: 6.150, Average Loss: 4.353, avg. samples / sec: 66520.47
Iteration:   1100, Loss function: 4.647, Average Loss: 4.358, avg. samples / sec: 66362.48
Iteration:   1100, Loss function: 5.462, Average Loss: 4.337, avg. samples / sec: 66466.61
Iteration:   1100, Loss function: 4.436, Average Loss: 4.328, avg. samples / sec: 66504.37
Iteration:   1100, Loss function: 4.358, Average Loss: 4.322, avg. samples / sec: 66284.10
Iteration:   1100, Loss function: 4.916, Average Loss: 4.349, avg. samples / sec: 66288.56
Iteration:   1100, Loss function: 4.310, Average Loss: 4.320, avg. samples / sec: 66521.17
:::MLL 1558651385.861 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558651385.862 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 3.987, Average Loss: 4.345, avg. samples / sec: 66427.98
Iteration:   1120, Loss function: 4.327, Average Loss: 4.377, avg. samples / sec: 66407.72
Iteration:   1120, Loss function: 4.875, Average Loss: 4.343, avg. samples / sec: 66441.88
Iteration:   1120, Loss function: 5.055, Average Loss: 4.362, avg. samples / sec: 66278.12
Iteration:   1120, Loss function: 6.116, Average Loss: 4.340, avg. samples / sec: 66317.94
Iteration:   1120, Loss function: 3.714, Average Loss: 4.329, avg. samples / sec: 66278.21
Iteration:   1120, Loss function: 5.239, Average Loss: 4.364, avg. samples / sec: 66282.01
Iteration:   1120, Loss function: 4.953, Average Loss: 4.342, avg. samples / sec: 66239.33
Iteration:   1120, Loss function: 4.339, Average Loss: 4.385, avg. samples / sec: 66335.92
Iteration:   1120, Loss function: 5.034, Average Loss: 4.298, avg. samples / sec: 66251.04
Iteration:   1120, Loss function: 7.046, Average Loss: 4.336, avg. samples / sec: 66295.51
Iteration:   1120, Loss function: 3.422, Average Loss: 4.343, avg. samples / sec: 66281.05
Iteration:   1120, Loss function: 5.471, Average Loss: 4.368, avg. samples / sec: 66377.14
Iteration:   1120, Loss function: 4.811, Average Loss: 4.349, avg. samples / sec: 66273.38
Iteration:   1120, Loss function: 3.536, Average Loss: 4.355, avg. samples / sec: 66274.16
Iteration:   1120, Loss function: 4.557, Average Loss: 4.362, avg. samples / sec: 66363.73
Iteration:   1120, Loss function: 5.553, Average Loss: 4.356, avg. samples / sec: 66271.07
Iteration:   1120, Loss function: 4.391, Average Loss: 4.348, avg. samples / sec: 66213.75
Iteration:   1120, Loss function: 3.896, Average Loss: 4.339, avg. samples / sec: 66275.09
Iteration:   1120, Loss function: 4.140, Average Loss: 4.349, avg. samples / sec: 66167.80
Iteration:   1120, Loss function: 4.614, Average Loss: 4.336, avg. samples / sec: 66381.36
Iteration:   1120, Loss function: 4.014, Average Loss: 4.325, avg. samples / sec: 66214.46
Iteration:   1120, Loss function: 4.816, Average Loss: 4.361, avg. samples / sec: 66163.39
Iteration:   1120, Loss function: 5.026, Average Loss: 4.330, avg. samples / sec: 66410.45
Iteration:   1120, Loss function: 3.974, Average Loss: 4.372, avg. samples / sec: 66281.05
Iteration:   1120, Loss function: 5.758, Average Loss: 4.361, avg. samples / sec: 66271.41
Iteration:   1120, Loss function: 4.477, Average Loss: 4.335, avg. samples / sec: 66379.79
Iteration:   1120, Loss function: 4.134, Average Loss: 4.356, avg. samples / sec: 66366.38
Iteration:   1120, Loss function: 3.605, Average Loss: 4.360, avg. samples / sec: 66198.42
Iteration:   1120, Loss function: 5.342, Average Loss: 4.347, avg. samples / sec: 66225.63
Iteration:   1140, Loss function: 4.719, Average Loss: 4.373, avg. samples / sec: 66382.83
Iteration:   1140, Loss function: 5.625, Average Loss: 4.362, avg. samples / sec: 66355.57
Iteration:   1140, Loss function: 4.874, Average Loss: 4.364, avg. samples / sec: 66338.86
Iteration:   1140, Loss function: 5.361, Average Loss: 4.362, avg. samples / sec: 66357.51
Iteration:   1140, Loss function: 5.351, Average Loss: 4.373, avg. samples / sec: 66276.99
Iteration:   1140, Loss function: 5.700, Average Loss: 4.308, avg. samples / sec: 66338.36
Iteration:   1140, Loss function: 4.469, Average Loss: 4.356, avg. samples / sec: 66297.17
Iteration:   1140, Loss function: 5.506, Average Loss: 4.354, avg. samples / sec: 66306.55
Iteration:   1140, Loss function: 4.074, Average Loss: 4.384, avg. samples / sec: 66144.94
Iteration:   1140, Loss function: 5.498, Average Loss: 4.345, avg. samples / sec: 66406.66
Iteration:   1140, Loss function: 4.426, Average Loss: 4.348, avg. samples / sec: 66262.00
Iteration:   1140, Loss function: 3.960, Average Loss: 4.370, avg. samples / sec: 66393.40
Iteration:   1140, Loss function: 5.413, Average Loss: 4.356, avg. samples / sec: 66153.45
Iteration:   1140, Loss function: 5.295, Average Loss: 4.383, avg. samples / sec: 66284.79
Iteration:   1140, Loss function: 6.434, Average Loss: 4.393, avg. samples / sec: 66263.09
Iteration:   1140, Loss function: 5.393, Average Loss: 4.379, avg. samples / sec: 66257.14
Iteration:   1140, Loss function: 4.568, Average Loss: 4.385, avg. samples / sec: 66343.01
Iteration:   1140, Loss function: 6.357, Average Loss: 4.354, avg. samples / sec: 66080.65
Iteration:   1140, Loss function: 4.021, Average Loss: 4.356, avg. samples / sec: 66268.52
Iteration:   1140, Loss function: 5.358, Average Loss: 4.359, avg. samples / sec: 66395.96
Iteration:   1140, Loss function: 5.148, Average Loss: 4.349, avg. samples / sec: 66212.82
Iteration:   1140, Loss function: 5.562, Average Loss: 4.371, avg. samples / sec: 66226.76
Iteration:   1140, Loss function: 4.183, Average Loss: 4.346, avg. samples / sec: 66235.75
Iteration:   1140, Loss function: 4.635, Average Loss: 4.336, avg. samples / sec: 66169.79
Iteration:   1140, Loss function: 4.377, Average Loss: 4.369, avg. samples / sec: 66311.42
Iteration:   1140, Loss function: 4.604, Average Loss: 4.341, avg. samples / sec: 66212.82
Iteration:   1140, Loss function: 4.788, Average Loss: 4.342, avg. samples / sec: 66198.14
Iteration:   1140, Loss function: 4.196, Average Loss: 4.358, avg. samples / sec: 66129.30
Iteration:   1140, Loss function: 5.714, Average Loss: 4.352, avg. samples / sec: 66094.13
Iteration:   1140, Loss function: 4.278, Average Loss: 4.363, avg. samples / sec: 66171.37
Iteration:   1160, Loss function: 6.489, Average Loss: 4.387, avg. samples / sec: 66588.21
Iteration:   1160, Loss function: 5.232, Average Loss: 4.372, avg. samples / sec: 66645.46
Iteration:   1160, Loss function: 4.470, Average Loss: 4.371, avg. samples / sec: 66534.61
Iteration:   1160, Loss function: 4.359, Average Loss: 4.352, avg. samples / sec: 66637.70
Iteration:   1160, Loss function: 4.590, Average Loss: 4.393, avg. samples / sec: 66544.03
Iteration:   1160, Loss function: 4.925, Average Loss: 4.395, avg. samples / sec: 66494.83
Iteration:   1160, Loss function: 4.973, Average Loss: 4.376, avg. samples / sec: 66465.26
Iteration:   1160, Loss function: 4.858, Average Loss: 4.375, avg. samples / sec: 66445.58
Iteration:   1160, Loss function: 5.189, Average Loss: 4.350, avg. samples / sec: 66652.20
Iteration:   1160, Loss function: 5.203, Average Loss: 4.366, avg. samples / sec: 66508.07
Iteration:   1160, Loss function: 5.498, Average Loss: 4.362, avg. samples / sec: 66552.01
Iteration:   1160, Loss function: 4.260, Average Loss: 4.361, avg. samples / sec: 66522.86
Iteration:   1160, Loss function: 5.646, Average Loss: 4.367, avg. samples / sec: 66449.50
Iteration:   1160, Loss function: 4.800, Average Loss: 4.359, avg. samples / sec: 66429.86
Iteration:   1160, Loss function: 4.665, Average Loss: 4.388, avg. samples / sec: 66413.64
Iteration:   1160, Loss function: 4.636, Average Loss: 4.361, avg. samples / sec: 66415.11
Iteration:   1160, Loss function: 5.357, Average Loss: 4.404, avg. samples / sec: 66441.54
Iteration:   1160, Loss function: 5.039, Average Loss: 4.369, avg. samples / sec: 66392.30
Iteration:   1160, Loss function: 5.511, Average Loss: 4.324, avg. samples / sec: 66368.29
Iteration:   1160, Loss function: 5.325, Average Loss: 4.363, avg. samples / sec: 66408.76
Iteration:   1160, Loss function: 5.085, Average Loss: 4.383, avg. samples / sec: 66467.95
Iteration:   1160, Loss function: 5.272, Average Loss: 4.399, avg. samples / sec: 66405.88
Iteration:   1160, Loss function: 5.395, Average Loss: 4.380, avg. samples / sec: 66382.04
Iteration:   1160, Loss function: 5.872, Average Loss: 4.370, avg. samples / sec: 66414.05
Iteration:   1160, Loss function: 4.944, Average Loss: 4.354, avg. samples / sec: 66488.40
Iteration:   1160, Loss function: 5.501, Average Loss: 4.399, avg. samples / sec: 66352.95
Iteration:   1160, Loss function: 5.511, Average Loss: 4.368, avg. samples / sec: 66515.04
Iteration:   1160, Loss function: 4.104, Average Loss: 4.384, avg. samples / sec: 66462.09
Iteration:   1160, Loss function: 4.207, Average Loss: 4.372, avg. samples / sec: 66576.07
Iteration:   1160, Loss function: 4.693, Average Loss: 4.363, avg. samples / sec: 66445.11
Iteration:   1180, Loss function: 5.302, Average Loss: 4.379, avg. samples / sec: 66562.07
Iteration:   1180, Loss function: 5.966, Average Loss: 4.403, avg. samples / sec: 66583.33
Iteration:   1180, Loss function: 4.731, Average Loss: 4.369, avg. samples / sec: 66630.68
Iteration:   1180, Loss function: 5.000, Average Loss: 4.400, avg. samples / sec: 66425.47
Iteration:   1180, Loss function: 5.261, Average Loss: 4.409, avg. samples / sec: 66688.50
Iteration:   1180, Loss function: 4.187, Average Loss: 4.364, avg. samples / sec: 66512.25
Iteration:   1180, Loss function: 4.486, Average Loss: 4.384, avg. samples / sec: 66693.11
Iteration:   1180, Loss function: 5.404, Average Loss: 4.402, avg. samples / sec: 66610.46
Iteration:   1180, Loss function: 5.426, Average Loss: 4.380, avg. samples / sec: 66597.62
Iteration:   1180, Loss function: 3.986, Average Loss: 4.409, avg. samples / sec: 66669.89
Iteration:   1180, Loss function: 5.239, Average Loss: 4.385, avg. samples / sec: 66490.44
Iteration:   1180, Loss function: 4.951, Average Loss: 4.376, avg. samples / sec: 66536.87
Iteration:   1180, Loss function: 3.583, Average Loss: 4.372, avg. samples / sec: 66526.97
Iteration:   1180, Loss function: 4.933, Average Loss: 4.382, avg. samples / sec: 66382.39
Iteration:   1180, Loss function: 5.430, Average Loss: 4.388, avg. samples / sec: 66462.97
Iteration:   1180, Loss function: 7.048, Average Loss: 4.374, avg. samples / sec: 66534.26
Iteration:   1180, Loss function: 4.901, Average Loss: 4.340, avg. samples / sec: 66539.10
Iteration:   1180, Loss function: 3.904, Average Loss: 4.373, avg. samples / sec: 66716.29
Iteration:   1180, Loss function: 4.295, Average Loss: 4.388, avg. samples / sec: 66568.23
Iteration:   1180, Loss function: 5.137, Average Loss: 4.416, avg. samples / sec: 66500.39
Iteration:   1180, Loss function: 4.750, Average Loss: 4.356, avg. samples / sec: 66440.41
Iteration:   1180, Loss function: 4.548, Average Loss: 4.382, avg. samples / sec: 66417.30
Iteration:   1180, Loss function: 4.279, Average Loss: 4.368, avg. samples / sec: 66482.75
Iteration:   1180, Loss function: 3.958, Average Loss: 4.376, avg. samples / sec: 66551.01
Iteration:   1180, Loss function: 5.119, Average Loss: 4.365, avg. samples / sec: 66518.62
Iteration:   1180, Loss function: 4.969, Average Loss: 4.397, avg. samples / sec: 66533.79
Iteration:   1180, Loss function: 4.255, Average Loss: 4.386, avg. samples / sec: 66544.28
Iteration:   1180, Loss function: 3.679, Average Loss: 4.396, avg. samples / sec: 66477.77
Iteration:   1180, Loss function: 4.545, Average Loss: 4.372, avg. samples / sec: 66386.58
Iteration:   1180, Loss function: 4.638, Average Loss: 4.400, avg. samples / sec: 66265.59
:::MLL 1558651387.638 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558651387.638 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 5.392, Average Loss: 4.415, avg. samples / sec: 65439.96
Iteration:   1200, Loss function: 5.447, Average Loss: 4.389, avg. samples / sec: 65439.05
Iteration:   1200, Loss function: 5.095, Average Loss: 4.380, avg. samples / sec: 65555.05
Iteration:   1200, Loss function: 6.174, Average Loss: 4.388, avg. samples / sec: 65307.80
Iteration:   1200, Loss function: 4.987, Average Loss: 4.393, avg. samples / sec: 65530.97
Iteration:   1200, Loss function: 4.222, Average Loss: 4.399, avg. samples / sec: 65480.34
Iteration:   1200, Loss function: 5.011, Average Loss: 4.387, avg. samples / sec: 65524.63
Iteration:   1200, Loss function: 4.911, Average Loss: 4.412, avg. samples / sec: 65626.00
Iteration:   1200, Loss function: 5.833, Average Loss: 4.386, avg. samples / sec: 65465.31
Iteration:   1200, Loss function: 4.054, Average Loss: 4.404, avg. samples / sec: 65336.26
Iteration:   1200, Loss function: 5.824, Average Loss: 4.390, avg. samples / sec: 65430.33
Iteration:   1200, Loss function: 4.687, Average Loss: 4.377, avg. samples / sec: 65313.76
Iteration:   1200, Loss function: 5.874, Average Loss: 4.353, avg. samples / sec: 65409.16
Iteration:   1200, Loss function: 4.300, Average Loss: 4.368, avg. samples / sec: 65435.64
Iteration:   1200, Loss function: 5.751, Average Loss: 4.379, avg. samples / sec: 65505.05
Iteration:   1200, Loss function: 5.212, Average Loss: 4.405, avg. samples / sec: 65502.58
Iteration:   1200, Loss function: 4.269, Average Loss: 4.389, avg. samples / sec: 65374.90
Iteration:   1200, Loss function: 5.524, Average Loss: 4.396, avg. samples / sec: 65343.71
Iteration:   1200, Loss function: 4.845, Average Loss: 4.369, avg. samples / sec: 65293.82
Iteration:   1200, Loss function: 5.268, Average Loss: 4.394, avg. samples / sec: 65271.02
Iteration:   1200, Loss function: 4.726, Average Loss: 4.425, avg. samples / sec: 65372.45
Iteration:   1200, Loss function: 5.686, Average Loss: 4.414, avg. samples / sec: 65263.61
Iteration:   1200, Loss function: 4.107, Average Loss: 4.413, avg. samples / sec: 65246.15
Iteration:   1200, Loss function: 5.498, Average Loss: 4.396, avg. samples / sec: 65361.02
Iteration:   1200, Loss function: 5.952, Average Loss: 4.376, avg. samples / sec: 65378.57
Iteration:   1200, Loss function: 4.540, Average Loss: 4.381, avg. samples / sec: 65318.51
Iteration:   1200, Loss function: 5.439, Average Loss: 4.410, avg. samples / sec: 65365.35
Iteration:   1200, Loss function: 3.450, Average Loss: 4.414, avg. samples / sec: 65202.38
Iteration:   1200, Loss function: 4.989, Average Loss: 4.378, avg. samples / sec: 65242.34
Iteration:   1200, Loss function: 4.701, Average Loss: 4.398, avg. samples / sec: 65303.74
Iteration:   1220, Loss function: 5.144, Average Loss: 4.400, avg. samples / sec: 66399.87
Iteration:   1220, Loss function: 5.188, Average Loss: 4.379, avg. samples / sec: 66408.23
Iteration:   1220, Loss function: 5.588, Average Loss: 4.402, avg. samples / sec: 66327.49
Iteration:   1220, Loss function: 5.672, Average Loss: 4.399, avg. samples / sec: 66401.00
Iteration:   1220, Loss function: 4.580, Average Loss: 4.399, avg. samples / sec: 66330.34
Iteration:   1220, Loss function: 4.842, Average Loss: 4.391, avg. samples / sec: 66346.89
Iteration:   1220, Loss function: 5.527, Average Loss: 4.403, avg. samples / sec: 66333.71
Iteration:   1220, Loss function: 6.611, Average Loss: 4.404, avg. samples / sec: 66367.41
Iteration:   1220, Loss function: 4.995, Average Loss: 4.376, avg. samples / sec: 66366.26
Iteration:   1220, Loss function: 3.579, Average Loss: 4.361, avg. samples / sec: 66349.48
Iteration:   1220, Loss function: 5.199, Average Loss: 4.388, avg. samples / sec: 66303.22
Iteration:   1220, Loss function: 4.461, Average Loss: 4.392, avg. samples / sec: 66457.64
Iteration:   1220, Loss function: 4.042, Average Loss: 4.409, avg. samples / sec: 66247.21
Iteration:   1220, Loss function: 3.508, Average Loss: 4.403, avg. samples / sec: 66512.03
Iteration:   1220, Loss function: 3.166, Average Loss: 4.389, avg. samples / sec: 66465.29
Iteration:   1220, Loss function: 3.982, Average Loss: 4.419, avg. samples / sec: 66379.14
Iteration:   1220, Loss function: 4.553, Average Loss: 4.422, avg. samples / sec: 66439.66
Iteration:   1220, Loss function: 5.125, Average Loss: 4.394, avg. samples / sec: 66207.65
Iteration:   1220, Loss function: 3.526, Average Loss: 4.435, avg. samples / sec: 66342.48
Iteration:   1220, Loss function: 4.951, Average Loss: 4.392, avg. samples / sec: 66226.97
Iteration:   1220, Loss function: 4.193, Average Loss: 4.401, avg. samples / sec: 66319.72
Iteration:   1220, Loss function: 3.878, Average Loss: 4.419, avg. samples / sec: 66090.60
Iteration:   1220, Loss function: 3.896, Average Loss: 4.395, avg. samples / sec: 66199.10
Iteration:   1220, Loss function: 5.253, Average Loss: 4.413, avg. samples / sec: 66217.58
Iteration:   1220, Loss function: 5.048, Average Loss: 4.385, avg. samples / sec: 66360.19
Iteration:   1220, Loss function: 4.883, Average Loss: 4.416, avg. samples / sec: 66184.70
Iteration:   1220, Loss function: 5.436, Average Loss: 4.411, avg. samples / sec: 66226.16
Iteration:   1220, Loss function: 3.803, Average Loss: 4.425, avg. samples / sec: 66372.26
Iteration:   1220, Loss function: 4.860, Average Loss: 4.423, avg. samples / sec: 66268.33
Iteration:   1220, Loss function: 4.848, Average Loss: 4.400, avg. samples / sec: 66130.79
Iteration:   1240, Loss function: 4.723, Average Loss: 4.400, avg. samples / sec: 66530.18
Iteration:   1240, Loss function: 5.020, Average Loss: 4.403, avg. samples / sec: 66472.56
Iteration:   1240, Loss function: 5.247, Average Loss: 4.420, avg. samples / sec: 66512.72
Iteration:   1240, Loss function: 5.067, Average Loss: 4.398, avg. samples / sec: 66532.16
Iteration:   1240, Loss function: 6.488, Average Loss: 4.415, avg. samples / sec: 66426.16
Iteration:   1240, Loss function: 4.249, Average Loss: 4.391, avg. samples / sec: 66405.47
Iteration:   1240, Loss function: 4.904, Average Loss: 4.423, avg. samples / sec: 66542.21
Iteration:   1240, Loss function: 5.105, Average Loss: 4.406, avg. samples / sec: 66393.18
Iteration:   1240, Loss function: 4.251, Average Loss: 4.406, avg. samples / sec: 66302.25
Iteration:   1240, Loss function: 6.212, Average Loss: 4.407, avg. samples / sec: 66531.53
Iteration:   1240, Loss function: 4.063, Average Loss: 4.424, avg. samples / sec: 66460.06
Iteration:   1240, Loss function: 4.782, Average Loss: 4.415, avg. samples / sec: 66521.35
Iteration:   1240, Loss function: 4.820, Average Loss: 4.362, avg. samples / sec: 66415.96
Iteration:   1240, Loss function: 6.564, Average Loss: 4.431, avg. samples / sec: 66519.28
Iteration:   1240, Loss function: 4.974, Average Loss: 4.412, avg. samples / sec: 66385.55
Iteration:   1240, Loss function: 4.748, Average Loss: 4.404, avg. samples / sec: 66632.03
Iteration:   1240, Loss function: 5.726, Average Loss: 4.400, avg. samples / sec: 66396.77
Iteration:   1240, Loss function: 4.669, Average Loss: 4.392, avg. samples / sec: 66476.42
Iteration:   1240, Loss function: 4.168, Average Loss: 4.412, avg. samples / sec: 66360.91
Iteration:   1240, Loss function: 5.157, Average Loss: 4.433, avg. samples / sec: 66509.80
Iteration:   1240, Loss function: 4.404, Average Loss: 4.385, avg. samples / sec: 66356.76
Iteration:   1240, Loss function: 5.338, Average Loss: 4.417, avg. samples / sec: 66454.85
Iteration:   1240, Loss function: 4.990, Average Loss: 4.411, avg. samples / sec: 66303.53
Iteration:   1240, Loss function: 5.618, Average Loss: 4.416, avg. samples / sec: 66462.59
Iteration:   1240, Loss function: 3.283, Average Loss: 4.399, avg. samples / sec: 66398.03
Iteration:   1240, Loss function: 5.716, Average Loss: 4.434, avg. samples / sec: 66457.67
Iteration:   1240, Loss function: 4.632, Average Loss: 4.444, avg. samples / sec: 66381.42
Iteration:   1240, Loss function: 4.941, Average Loss: 4.411, avg. samples / sec: 66336.89
Iteration:   1240, Loss function: 5.510, Average Loss: 4.396, avg. samples / sec: 66336.61
Iteration:   1240, Loss function: 5.046, Average Loss: 4.428, avg. samples / sec: 66327.24
:::MLL 1558651389.414 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558651389.415 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 4.749, Average Loss: 4.438, avg. samples / sec: 66208.90
Iteration:   1260, Loss function: 4.624, Average Loss: 4.453, avg. samples / sec: 66294.73
Iteration:   1260, Loss function: 5.614, Average Loss: 4.371, avg. samples / sec: 66160.03
Iteration:   1260, Loss function: 4.558, Average Loss: 4.427, avg. samples / sec: 66084.37
Iteration:   1260, Loss function: 5.482, Average Loss: 4.426, avg. samples / sec: 66149.69
Iteration:   1260, Loss function: 4.581, Average Loss: 4.430, avg. samples / sec: 66053.70
Iteration:   1260, Loss function: 4.254, Average Loss: 4.411, avg. samples / sec: 66067.73
Iteration:   1260, Loss function: 3.400, Average Loss: 4.424, avg. samples / sec: 66106.44
Iteration:   1260, Loss function: 4.428, Average Loss: 4.403, avg. samples / sec: 66042.56
Iteration:   1260, Loss function: 4.192, Average Loss: 4.433, avg. samples / sec: 66149.23
Iteration:   1260, Loss function: 4.195, Average Loss: 4.421, avg. samples / sec: 66053.42
Iteration:   1260, Loss function: 4.118, Average Loss: 4.412, avg. samples / sec: 66150.72
Iteration:   1260, Loss function: 5.702, Average Loss: 4.449, avg. samples / sec: 66164.97
Iteration:   1260, Loss function: 5.267, Average Loss: 4.415, avg. samples / sec: 65983.35
Iteration:   1260, Loss function: 4.424, Average Loss: 4.397, avg. samples / sec: 66084.15
Iteration:   1260, Loss function: 5.184, Average Loss: 4.415, avg. samples / sec: 65956.54
Iteration:   1260, Loss function: 5.361, Average Loss: 4.432, avg. samples / sec: 66060.82
Iteration:   1260, Loss function: 4.899, Average Loss: 4.436, avg. samples / sec: 65982.63
Iteration:   1260, Loss function: 5.343, Average Loss: 4.413, avg. samples / sec: 65968.33
Iteration:   1260, Loss function: 6.028, Average Loss: 4.414, avg. samples / sec: 66002.16
Iteration:   1260, Loss function: 6.258, Average Loss: 4.421, avg. samples / sec: 65957.96
Iteration:   1260, Loss function: 5.140, Average Loss: 4.409, avg. samples / sec: 65996.38
Iteration:   1260, Loss function: 4.149, Average Loss: 4.441, avg. samples / sec: 66084.89
Iteration:   1260, Loss function: 4.629, Average Loss: 4.426, avg. samples / sec: 66073.55
Iteration:   1260, Loss function: 5.523, Average Loss: 4.428, avg. samples / sec: 66031.98
Iteration:   1260, Loss function: 4.898, Average Loss: 4.433, avg. samples / sec: 65947.74
Iteration:   1260, Loss function: 5.380, Average Loss: 4.426, avg. samples / sec: 65951.57
Iteration:   1260, Loss function: 4.914, Average Loss: 4.411, avg. samples / sec: 66036.80
Iteration:   1260, Loss function: 5.117, Average Loss: 4.447, avg. samples / sec: 65961.23
Iteration:   1260, Loss function: 4.555, Average Loss: 4.406, avg. samples / sec: 65798.20
Iteration:   1280, Loss function: 4.831, Average Loss: 4.446, avg. samples / sec: 66475.73
Iteration:   1280, Loss function: 4.888, Average Loss: 4.447, avg. samples / sec: 66245.78
Iteration:   1280, Loss function: 4.952, Average Loss: 4.415, avg. samples / sec: 66535.89
Iteration:   1280, Loss function: 4.222, Average Loss: 4.433, avg. samples / sec: 66477.83
Iteration:   1280, Loss function: 3.874, Average Loss: 4.425, avg. samples / sec: 66259.14
Iteration:   1280, Loss function: 5.606, Average Loss: 4.434, avg. samples / sec: 66267.71
Iteration:   1280, Loss function: 3.789, Average Loss: 4.438, avg. samples / sec: 66272.94
Iteration:   1280, Loss function: 3.355, Average Loss: 4.427, avg. samples / sec: 66396.49
Iteration:   1280, Loss function: 5.541, Average Loss: 4.408, avg. samples / sec: 66322.97
Iteration:   1280, Loss function: 5.224, Average Loss: 4.420, avg. samples / sec: 66306.62
Iteration:   1280, Loss function: 3.902, Average Loss: 4.429, avg. samples / sec: 66454.07
Iteration:   1280, Loss function: 4.419, Average Loss: 4.428, avg. samples / sec: 66278.96
Iteration:   1280, Loss function: 4.114, Average Loss: 4.379, avg. samples / sec: 66181.19
Iteration:   1280, Loss function: 5.865, Average Loss: 4.422, avg. samples / sec: 66332.86
Iteration:   1280, Loss function: 4.037, Average Loss: 4.442, avg. samples / sec: 66251.57
Iteration:   1280, Loss function: 3.503, Average Loss: 4.454, avg. samples / sec: 66259.42
Iteration:   1280, Loss function: 4.947, Average Loss: 4.432, avg. samples / sec: 66373.23
Iteration:   1280, Loss function: 4.597, Average Loss: 4.411, avg. samples / sec: 66223.99
Iteration:   1280, Loss function: 5.171, Average Loss: 4.450, avg. samples / sec: 66344.14
Iteration:   1280, Loss function: 5.151, Average Loss: 4.448, avg. samples / sec: 66277.74
Iteration:   1280, Loss function: 6.079, Average Loss: 4.424, avg. samples / sec: 66313.39
Iteration:   1280, Loss function: 5.013, Average Loss: 4.431, avg. samples / sec: 66323.59
Iteration:   1280, Loss function: 4.308, Average Loss: 4.451, avg. samples / sec: 66376.54
Iteration:   1280, Loss function: 4.733, Average Loss: 4.416, avg. samples / sec: 66136.47
Iteration:   1280, Loss function: 5.741, Average Loss: 4.429, avg. samples / sec: 66146.68
Iteration:   1280, Loss function: 5.220, Average Loss: 4.421, avg. samples / sec: 66269.23
Iteration:   1280, Loss function: 4.230, Average Loss: 4.462, avg. samples / sec: 66061.10
Iteration:   1280, Loss function: 4.424, Average Loss: 4.427, avg. samples / sec: 66221.81
Iteration:   1280, Loss function: 3.700, Average Loss: 4.412, avg. samples / sec: 66455.39
Iteration:   1280, Loss function: 4.900, Average Loss: 4.419, avg. samples / sec: 66096.18
Iteration:   1300, Loss function: 3.912, Average Loss: 4.414, avg. samples / sec: 66631.62
Iteration:   1300, Loss function: 5.647, Average Loss: 4.386, avg. samples / sec: 66585.72
Iteration:   1300, Loss function: 3.849, Average Loss: 4.447, avg. samples / sec: 66455.01
Iteration:   1300, Loss function: 3.357, Average Loss: 4.426, avg. samples / sec: 66493.51
Iteration:   1300, Loss function: 4.921, Average Loss: 4.454, avg. samples / sec: 66605.83
Iteration:   1300, Loss function: 4.131, Average Loss: 4.450, avg. samples / sec: 66390.11
Iteration:   1300, Loss function: 4.108, Average Loss: 4.426, avg. samples / sec: 66501.42
Iteration:   1300, Loss function: 3.161, Average Loss: 4.453, avg. samples / sec: 66565.12
Iteration:   1300, Loss function: 4.628, Average Loss: 4.432, avg. samples / sec: 66478.80
Iteration:   1300, Loss function: 4.690, Average Loss: 4.419, avg. samples / sec: 66575.53
Iteration:   1300, Loss function: 5.786, Average Loss: 4.432, avg. samples / sec: 66460.59
Iteration:   1300, Loss function: 3.281, Average Loss: 4.412, avg. samples / sec: 66470.15
Iteration:   1300, Loss function: 5.841, Average Loss: 4.425, avg. samples / sec: 66585.38
Iteration:   1300, Loss function: 4.682, Average Loss: 4.444, avg. samples / sec: 66472.41
Iteration:   1300, Loss function: 4.503, Average Loss: 4.421, avg. samples / sec: 66350.38
Iteration:   1300, Loss function: 6.356, Average Loss: 4.432, avg. samples / sec: 66580.63
Iteration:   1300, Loss function: 4.502, Average Loss: 4.428, avg. samples / sec: 66632.85
Iteration:   1300, Loss function: 4.863, Average Loss: 4.461, avg. samples / sec: 66466.95
Iteration:   1300, Loss function: 4.907, Average Loss: 4.434, avg. samples / sec: 66479.02
Iteration:   1300, Loss function: 4.531, Average Loss: 4.434, avg. samples / sec: 66408.54
Iteration:   1300, Loss function: 4.565, Average Loss: 4.436, avg. samples / sec: 66445.80
Iteration:   1300, Loss function: 4.204, Average Loss: 4.442, avg. samples / sec: 66358.13
Iteration:   1300, Loss function: 4.869, Average Loss: 4.437, avg. samples / sec: 66490.94
Iteration:   1300, Loss function: 5.300, Average Loss: 4.437, avg. samples / sec: 66387.64
Iteration:   1300, Loss function: 4.653, Average Loss: 4.455, avg. samples / sec: 66443.73
Iteration:   1300, Loss function: 4.466, Average Loss: 4.436, avg. samples / sec: 66503.71
Iteration:   1300, Loss function: 4.970, Average Loss: 4.468, avg. samples / sec: 66493.48
Iteration:   1300, Loss function: 4.086, Average Loss: 4.441, avg. samples / sec: 66324.59
Iteration:   1300, Loss function: 4.391, Average Loss: 4.412, avg. samples / sec: 66508.64
Iteration:   1300, Loss function: 4.491, Average Loss: 4.440, avg. samples / sec: 66297.35
Iteration:   1320, Loss function: 4.142, Average Loss: 4.452, avg. samples / sec: 66367.79
Iteration:   1320, Loss function: 3.904, Average Loss: 4.435, avg. samples / sec: 66466.73
Iteration:   1320, Loss function: 3.529, Average Loss: 4.431, avg. samples / sec: 66325.72
Iteration:   1320, Loss function: 5.090, Average Loss: 4.446, avg. samples / sec: 66405.88
Iteration:   1320, Loss function: 4.592, Average Loss: 4.436, avg. samples / sec: 66406.63
Iteration:   1320, Loss function: 4.000, Average Loss: 4.416, avg. samples / sec: 66251.32
Iteration:   1320, Loss function: 4.685, Average Loss: 4.440, avg. samples / sec: 66439.75
Iteration:   1320, Loss function: 3.968, Average Loss: 4.422, avg. samples / sec: 66351.54
Iteration:   1320, Loss function: 5.653, Average Loss: 4.434, avg. samples / sec: 66326.90
Iteration:   1320, Loss function: 4.979, Average Loss: 4.438, avg. samples / sec: 66389.46
Iteration:   1320, Loss function: 4.562, Average Loss: 4.398, avg. samples / sec: 66243.29
Iteration:   1320, Loss function: 4.474, Average Loss: 4.434, avg. samples / sec: 66334.83
Iteration:   1320, Loss function: 4.599, Average Loss: 4.460, avg. samples / sec: 66301.91
Iteration:   1320, Loss function: 5.008, Average Loss: 4.472, avg. samples / sec: 66433.61
Iteration:   1320, Loss function: 4.899, Average Loss: 4.440, avg. samples / sec: 66304.59
Iteration:   1320, Loss function: 4.442, Average Loss: 4.455, avg. samples / sec: 66283.38
Iteration:   1320, Loss function: 3.926, Average Loss: 4.441, avg. samples / sec: 66359.04
Iteration:   1320, Loss function: 4.715, Average Loss: 4.427, avg. samples / sec: 66282.20
Iteration:   1320, Loss function: 4.146, Average Loss: 4.445, avg. samples / sec: 66348.70
Iteration:   1320, Loss function: 4.607, Average Loss: 4.456, avg. samples / sec: 66343.86
Iteration:   1320, Loss function: 5.416, Average Loss: 4.464, avg. samples / sec: 66214.62
Iteration:   1320, Loss function: 4.504, Average Loss: 4.445, avg. samples / sec: 66386.92
Iteration:   1320, Loss function: 4.796, Average Loss: 4.451, avg. samples / sec: 66332.33
Iteration:   1320, Loss function: 5.382, Average Loss: 4.444, avg. samples / sec: 66348.98
Iteration:   1320, Loss function: 6.013, Average Loss: 4.447, avg. samples / sec: 66388.33
Iteration:   1320, Loss function: 5.343, Average Loss: 4.413, avg. samples / sec: 66356.29
Iteration:   1320, Loss function: 4.729, Average Loss: 4.428, avg. samples / sec: 66264.71
Iteration:   1320, Loss function: 6.077, Average Loss: 4.464, avg. samples / sec: 66286.63
Iteration:   1320, Loss function: 4.598, Average Loss: 4.419, avg. samples / sec: 66208.71
Iteration:   1320, Loss function: 4.187, Average Loss: 4.435, avg. samples / sec: 66273.32
:::MLL 1558651391.187 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558651391.188 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 5.513, Average Loss: 4.463, avg. samples / sec: 66397.46
Iteration:   1340, Loss function: 4.066, Average Loss: 4.400, avg. samples / sec: 66313.04
Iteration:   1340, Loss function: 4.578, Average Loss: 4.470, avg. samples / sec: 66353.13
Iteration:   1340, Loss function: 4.580, Average Loss: 4.437, avg. samples / sec: 66202.89
Iteration:   1340, Loss function: 4.443, Average Loss: 4.419, avg. samples / sec: 66197.86
Iteration:   1340, Loss function: 4.150, Average Loss: 4.453, avg. samples / sec: 66290.74
Iteration:   1340, Loss function: 3.875, Average Loss: 4.461, avg. samples / sec: 66284.01
Iteration:   1340, Loss function: 5.085, Average Loss: 4.451, avg. samples / sec: 66277.02
Iteration:   1340, Loss function: 4.073, Average Loss: 4.441, avg. samples / sec: 66242.76
Iteration:   1340, Loss function: 3.852, Average Loss: 4.446, avg. samples / sec: 66193.07
Iteration:   1340, Loss function: 3.970, Average Loss: 4.438, avg. samples / sec: 66201.68
Iteration:   1340, Loss function: 6.022, Average Loss: 4.455, avg. samples / sec: 66081.98
Iteration:   1340, Loss function: 4.356, Average Loss: 4.428, avg. samples / sec: 66172.06
Iteration:   1340, Loss function: 4.655, Average Loss: 4.437, avg. samples / sec: 66290.55
Iteration:   1340, Loss function: 3.739, Average Loss: 4.467, avg. samples / sec: 66286.59
Iteration:   1340, Loss function: 4.709, Average Loss: 4.432, avg. samples / sec: 66232.20
Iteration:   1340, Loss function: 4.620, Average Loss: 4.475, avg. samples / sec: 66186.97
Iteration:   1340, Loss function: 4.328, Average Loss: 4.441, avg. samples / sec: 66131.13
Iteration:   1340, Loss function: 4.288, Average Loss: 4.437, avg. samples / sec: 66107.21
Iteration:   1340, Loss function: 3.337, Average Loss: 4.450, avg. samples / sec: 66228.28
Iteration:   1340, Loss function: 3.747, Average Loss: 4.448, avg. samples / sec: 66198.66
Iteration:   1340, Loss function: 4.746, Average Loss: 4.418, avg. samples / sec: 66242.91
Iteration:   1340, Loss function: 4.814, Average Loss: 4.441, avg. samples / sec: 66108.89
Iteration:   1340, Loss function: 4.571, Average Loss: 4.459, avg. samples / sec: 66171.59
Iteration:   1340, Loss function: 4.993, Average Loss: 4.443, avg. samples / sec: 66231.36
Iteration:   1340, Loss function: 4.845, Average Loss: 4.423, avg. samples / sec: 66211.54
Iteration:   1340, Loss function: 3.039, Average Loss: 4.446, avg. samples / sec: 66139.91
Iteration:   1340, Loss function: 6.412, Average Loss: 4.453, avg. samples / sec: 66025.14
Iteration:   1340, Loss function: 4.927, Average Loss: 4.444, avg. samples / sec: 66046.43
Iteration:   1340, Loss function: 4.662, Average Loss: 4.453, avg. samples / sec: 66116.58
Iteration:   1360, Loss function: 4.196, Average Loss: 4.420, avg. samples / sec: 66461.37
Iteration:   1360, Loss function: 3.826, Average Loss: 4.443, avg. samples / sec: 66513.76
Iteration:   1360, Loss function: 5.952, Average Loss: 4.456, avg. samples / sec: 66416.11
Iteration:   1360, Loss function: 5.015, Average Loss: 4.448, avg. samples / sec: 66388.70
Iteration:   1360, Loss function: 3.363, Average Loss: 4.475, avg. samples / sec: 66418.33
Iteration:   1360, Loss function: 5.552, Average Loss: 4.459, avg. samples / sec: 66515.80
Iteration:   1360, Loss function: 5.457, Average Loss: 4.435, avg. samples / sec: 66408.85
Iteration:   1360, Loss function: 5.963, Average Loss: 4.442, avg. samples / sec: 66373.95
Iteration:   1360, Loss function: 5.107, Average Loss: 4.442, avg. samples / sec: 66303.50
Iteration:   1360, Loss function: 4.713, Average Loss: 4.470, avg. samples / sec: 66392.86
Iteration:   1360, Loss function: 3.548, Average Loss: 4.452, avg. samples / sec: 66325.09
Iteration:   1360, Loss function: 4.900, Average Loss: 4.444, avg. samples / sec: 66361.85
Iteration:   1360, Loss function: 3.907, Average Loss: 4.463, avg. samples / sec: 66141.40
Iteration:   1360, Loss function: 4.100, Average Loss: 4.441, avg. samples / sec: 66352.57
Iteration:   1360, Loss function: 3.420, Average Loss: 4.448, avg. samples / sec: 66369.60
Iteration:   1360, Loss function: 4.612, Average Loss: 4.427, avg. samples / sec: 66434.96
Iteration:   1360, Loss function: 4.276, Average Loss: 4.466, avg. samples / sec: 66381.11
Iteration:   1360, Loss function: 4.454, Average Loss: 4.404, avg. samples / sec: 66196.11
Iteration:   1360, Loss function: 4.597, Average Loss: 4.454, avg. samples / sec: 66318.22
Iteration:   1360, Loss function: 4.440, Average Loss: 4.445, avg. samples / sec: 66456.55
Iteration:   1360, Loss function: 5.331, Average Loss: 4.456, avg. samples / sec: 66466.83
Iteration:   1360, Loss function: 4.938, Average Loss: 4.458, avg. samples / sec: 66262.91
Iteration:   1360, Loss function: 3.760, Average Loss: 4.474, avg. samples / sec: 66196.08
Iteration:   1360, Loss function: 4.894, Average Loss: 4.446, avg. samples / sec: 66371.29
Iteration:   1360, Loss function: 3.525, Average Loss: 4.420, avg. samples / sec: 66316.26
Iteration:   1360, Loss function: 4.446, Average Loss: 4.451, avg. samples / sec: 66204.35
Iteration:   1360, Loss function: 4.356, Average Loss: 4.449, avg. samples / sec: 66325.12
Iteration:   1360, Loss function: 3.910, Average Loss: 4.451, avg. samples / sec: 66233.54
Iteration:   1360, Loss function: 4.160, Average Loss: 4.432, avg. samples / sec: 66163.14
Iteration:   1360, Loss function: 5.293, Average Loss: 4.445, avg. samples / sec: 66122.04
Iteration:   1380, Loss function: 4.777, Average Loss: 4.410, avg. samples / sec: 66609.83
Iteration:   1380, Loss function: 4.094, Average Loss: 4.467, avg. samples / sec: 66510.68
Iteration:   1380, Loss function: 5.499, Average Loss: 4.443, avg. samples / sec: 66570.15
Iteration:   1380, Loss function: 3.526, Average Loss: 4.426, avg. samples / sec: 66384.51
Iteration:   1380, Loss function: 4.891, Average Loss: 4.451, avg. samples / sec: 66552.17
Iteration:   1380, Loss function: 3.915, Average Loss: 4.437, avg. samples / sec: 66721.47
Iteration:   1380, Loss function: 4.024, Average Loss: 4.460, avg. samples / sec: 66582.29
Iteration:   1380, Loss function: 3.906, Average Loss: 4.449, avg. samples / sec: 66489.34
Iteration:   1380, Loss function: 4.994, Average Loss: 4.447, avg. samples / sec: 66494.58
Iteration:   1380, Loss function: 4.921, Average Loss: 4.465, avg. samples / sec: 66414.20
Iteration:   1380, Loss function: 4.656, Average Loss: 4.446, avg. samples / sec: 66389.64
Iteration:   1380, Loss function: 4.488, Average Loss: 4.443, avg. samples / sec: 66452.32
Iteration:   1380, Loss function: 5.676, Average Loss: 4.479, avg. samples / sec: 66440.41
Iteration:   1380, Loss function: 3.846, Average Loss: 4.457, avg. samples / sec: 66497.22
Iteration:   1380, Loss function: 3.966, Average Loss: 4.449, avg. samples / sec: 66434.24
Iteration:   1380, Loss function: 4.187, Average Loss: 4.459, avg. samples / sec: 66497.34
Iteration:   1380, Loss function: 4.096, Average Loss: 4.453, avg. samples / sec: 66554.59
Iteration:   1380, Loss function: 4.737, Average Loss: 4.455, avg. samples / sec: 66578.14
Iteration:   1380, Loss function: 4.962, Average Loss: 4.476, avg. samples / sec: 66517.68
Iteration:   1380, Loss function: 3.659, Average Loss: 4.449, avg. samples / sec: 66698.32
Iteration:   1380, Loss function: 5.088, Average Loss: 4.445, avg. samples / sec: 66479.56
Iteration:   1380, Loss function: 4.666, Average Loss: 4.451, avg. samples / sec: 66369.48
Iteration:   1380, Loss function: 4.923, Average Loss: 4.466, avg. samples / sec: 66428.42
Iteration:   1380, Loss function: 5.059, Average Loss: 4.458, avg. samples / sec: 66496.49
Iteration:   1380, Loss function: 4.544, Average Loss: 4.427, avg. samples / sec: 66497.94
Iteration:   1380, Loss function: 3.499, Average Loss: 4.451, avg. samples / sec: 66547.02
Iteration:   1380, Loss function: 5.132, Average Loss: 4.453, avg. samples / sec: 66471.28
Iteration:   1380, Loss function: 3.333, Average Loss: 4.468, avg. samples / sec: 66394.58
Iteration:   1380, Loss function: 4.574, Average Loss: 4.468, avg. samples / sec: 66303.15
Iteration:   1380, Loss function: 4.562, Average Loss: 4.438, avg. samples / sec: 66299.97
:::MLL 1558651392.961 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558651392.962 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 3.191, Average Loss: 4.409, avg. samples / sec: 66125.86
Iteration:   1400, Loss function: 4.533, Average Loss: 4.465, avg. samples / sec: 66110.04
Iteration:   1400, Loss function: 4.621, Average Loss: 4.442, avg. samples / sec: 66071.73
Iteration:   1400, Loss function: 6.199, Average Loss: 4.436, avg. samples / sec: 66093.73
Iteration:   1400, Loss function: 5.600, Average Loss: 4.459, avg. samples / sec: 66151.03
Iteration:   1400, Loss function: 4.689, Average Loss: 4.480, avg. samples / sec: 66177.06
Iteration:   1400, Loss function: 4.171, Average Loss: 4.457, avg. samples / sec: 66097.51
Iteration:   1400, Loss function: 3.906, Average Loss: 4.453, avg. samples / sec: 66101.11
Iteration:   1400, Loss function: 3.838, Average Loss: 4.449, avg. samples / sec: 66074.73
Iteration:   1400, Loss function: 4.936, Average Loss: 4.445, avg. samples / sec: 66018.64
Iteration:   1400, Loss function: 4.285, Average Loss: 4.454, avg. samples / sec: 66094.41
Iteration:   1400, Loss function: 5.605, Average Loss: 4.471, avg. samples / sec: 66105.35
Iteration:   1400, Loss function: 5.211, Average Loss: 4.466, avg. samples / sec: 66011.53
Iteration:   1400, Loss function: 3.865, Average Loss: 4.452, avg. samples / sec: 66139.36
Iteration:   1400, Loss function: 4.216, Average Loss: 4.479, avg. samples / sec: 66027.49
Iteration:   1400, Loss function: 3.695, Average Loss: 4.458, avg. samples / sec: 66060.27
Iteration:   1400, Loss function: 5.809, Average Loss: 4.454, avg. samples / sec: 65965.03
Iteration:   1400, Loss function: 4.425, Average Loss: 4.452, avg. samples / sec: 66077.18
Iteration:   1400, Loss function: 4.656, Average Loss: 4.453, avg. samples / sec: 65990.42
Iteration:   1400, Loss function: 4.545, Average Loss: 4.457, avg. samples / sec: 65976.58
Iteration:   1400, Loss function: 3.950, Average Loss: 4.470, avg. samples / sec: 65912.34
Iteration:   1400, Loss function: 5.706, Average Loss: 4.470, avg. samples / sec: 66077.43
Iteration:   1400, Loss function: 4.878, Average Loss: 4.448, avg. samples / sec: 65964.54
Iteration:   1400, Loss function: 4.836, Average Loss: 4.442, avg. samples / sec: 66155.75
Iteration:   1400, Loss function: 4.389, Average Loss: 4.447, avg. samples / sec: 65986.19
Iteration:   1400, Loss function: 3.895, Average Loss: 4.430, avg. samples / sec: 66016.23
Iteration:   1400, Loss function: 5.044, Average Loss: 4.456, avg. samples / sec: 65959.01
Iteration:   1400, Loss function: 4.849, Average Loss: 4.452, avg. samples / sec: 65950.98
Iteration:   1400, Loss function: 5.101, Average Loss: 4.474, avg. samples / sec: 66009.65
Iteration:   1400, Loss function: 3.479, Average Loss: 4.455, avg. samples / sec: 65924.36
Iteration:   1420, Loss function: 4.826, Average Loss: 4.443, avg. samples / sec: 66268.08
Iteration:   1420, Loss function: 3.058, Average Loss: 4.449, avg. samples / sec: 66459.21
Iteration:   1420, Loss function: 5.194, Average Loss: 4.444, avg. samples / sec: 66434.11
Iteration:   1420, Loss function: 4.107, Average Loss: 4.454, avg. samples / sec: 66380.89
Iteration:   1420, Loss function: 3.948, Average Loss: 4.469, avg. samples / sec: 66344.32
Iteration:   1420, Loss function: 5.063, Average Loss: 4.456, avg. samples / sec: 66308.11
Iteration:   1420, Loss function: 5.269, Average Loss: 4.456, avg. samples / sec: 66276.31
Iteration:   1420, Loss function: 4.612, Average Loss: 4.415, avg. samples / sec: 66141.90
Iteration:   1420, Loss function: 4.350, Average Loss: 4.462, avg. samples / sec: 66224.79
Iteration:   1420, Loss function: 4.206, Average Loss: 4.459, avg. samples / sec: 66537.34
Iteration:   1420, Loss function: 4.187, Average Loss: 4.449, avg. samples / sec: 66258.36
Iteration:   1420, Loss function: 3.547, Average Loss: 4.476, avg. samples / sec: 66195.65
Iteration:   1420, Loss function: 4.412, Average Loss: 4.450, avg. samples / sec: 66356.85
Iteration:   1420, Loss function: 5.047, Average Loss: 4.457, avg. samples / sec: 66301.16
Iteration:   1420, Loss function: 4.319, Average Loss: 4.451, avg. samples / sec: 66390.52
Iteration:   1420, Loss function: 3.408, Average Loss: 4.470, avg. samples / sec: 66314.95
Iteration:   1420, Loss function: 5.738, Average Loss: 4.461, avg. samples / sec: 66191.98
Iteration:   1420, Loss function: 4.545, Average Loss: 4.472, avg. samples / sec: 66245.37
Iteration:   1420, Loss function: 3.237, Average Loss: 4.449, avg. samples / sec: 66234.29
Iteration:   1420, Loss function: 5.865, Average Loss: 4.445, avg. samples / sec: 66121.17
Iteration:   1420, Loss function: 4.084, Average Loss: 4.475, avg. samples / sec: 66410.48
Iteration:   1420, Loss function: 4.481, Average Loss: 4.455, avg. samples / sec: 66340.58
Iteration:   1420, Loss function: 3.788, Average Loss: 4.450, avg. samples / sec: 66230.80
Iteration:   1420, Loss function: 3.839, Average Loss: 4.478, avg. samples / sec: 66203.20
Iteration:   1420, Loss function: 4.859, Average Loss: 4.456, avg. samples / sec: 66182.28
Iteration:   1420, Loss function: 5.029, Average Loss: 4.432, avg. samples / sec: 66236.40
Iteration:   1420, Loss function: 5.014, Average Loss: 4.468, avg. samples / sec: 66009.77
Iteration:   1420, Loss function: 5.494, Average Loss: 4.472, avg. samples / sec: 66190.52
Iteration:   1420, Loss function: 4.604, Average Loss: 4.450, avg. samples / sec: 66079.87
Iteration:   1420, Loss function: 4.031, Average Loss: 4.454, avg. samples / sec: 66110.41
Iteration:   1440, Loss function: 4.645, Average Loss: 4.473, avg. samples / sec: 66578.55
Iteration:   1440, Loss function: 4.972, Average Loss: 4.467, avg. samples / sec: 66442.67
Iteration:   1440, Loss function: 3.421, Average Loss: 4.449, avg. samples / sec: 66562.04
Iteration:   1440, Loss function: 4.014, Average Loss: 4.475, avg. samples / sec: 66425.82
Iteration:   1440, Loss function: 5.053, Average Loss: 4.465, avg. samples / sec: 66501.67
Iteration:   1440, Loss function: 4.418, Average Loss: 4.457, avg. samples / sec: 66442.92
Iteration:   1440, Loss function: 4.611, Average Loss: 4.452, avg. samples / sec: 66519.38
Iteration:   1440, Loss function: 3.824, Average Loss: 4.461, avg. samples / sec: 66395.93
Iteration:   1440, Loss function: 5.440, Average Loss: 4.463, avg. samples / sec: 66353.66
Iteration:   1440, Loss function: 4.636, Average Loss: 4.479, avg. samples / sec: 66419.90
Iteration:   1440, Loss function: 5.189, Average Loss: 4.485, avg. samples / sec: 66390.52
Iteration:   1440, Loss function: 4.113, Average Loss: 4.461, avg. samples / sec: 66400.28
Iteration:   1440, Loss function: 4.078, Average Loss: 4.455, avg. samples / sec: 66325.25
Iteration:   1440, Loss function: 4.307, Average Loss: 4.481, avg. samples / sec: 66468.39
Iteration:   1440, Loss function: 4.273, Average Loss: 4.456, avg. samples / sec: 66406.60
Iteration:   1440, Loss function: 3.265, Average Loss: 4.423, avg. samples / sec: 66315.07
Iteration:   1440, Loss function: 5.463, Average Loss: 4.466, avg. samples / sec: 66450.09
Iteration:   1440, Loss function: 4.559, Average Loss: 4.480, avg. samples / sec: 66498.28
Iteration:   1440, Loss function: 3.979, Average Loss: 4.448, avg. samples / sec: 66320.28
Iteration:   1440, Loss function: 4.741, Average Loss: 4.460, avg. samples / sec: 66244.50
Iteration:   1440, Loss function: 4.411, Average Loss: 4.467, avg. samples / sec: 66467.48
Iteration:   1440, Loss function: 4.503, Average Loss: 4.442, avg. samples / sec: 66202.15
Iteration:   1440, Loss function: 4.613, Average Loss: 4.459, avg. samples / sec: 66510.15
Iteration:   1440, Loss function: 3.226, Average Loss: 4.453, avg. samples / sec: 66477.61
Iteration:   1440, Loss function: 4.343, Average Loss: 4.453, avg. samples / sec: 66365.32
Iteration:   1440, Loss function: 4.038, Average Loss: 4.454, avg. samples / sec: 66327.84
Iteration:   1440, Loss function: 5.389, Average Loss: 4.475, avg. samples / sec: 66326.90
Iteration:   1440, Loss function: 4.912, Average Loss: 4.458, avg. samples / sec: 66169.29
Iteration:   1440, Loss function: 5.340, Average Loss: 4.446, avg. samples / sec: 66143.48
Iteration:   1440, Loss function: 4.606, Average Loss: 4.446, avg. samples / sec: 66300.88
Iteration:   1460, Loss function: 3.318, Average Loss: 4.449, avg. samples / sec: 66415.92
Iteration:   1460, Loss function: 6.616, Average Loss: 4.459, avg. samples / sec: 66424.63
Iteration:   1460, Loss function: 4.355, Average Loss: 4.462, avg. samples / sec: 66553.96
Iteration:   1460, Loss function: 4.689, Average Loss: 4.470, avg. samples / sec: 66347.17
Iteration:   1460, Loss function: 4.453, Average Loss: 4.423, avg. samples / sec: 66474.26
Iteration:   1460, Loss function: 4.614, Average Loss: 4.462, avg. samples / sec: 66348.82
Iteration:   1460, Loss function: 3.941, Average Loss: 4.462, avg. samples / sec: 66444.45
Iteration:   1460, Loss function: 4.435, Average Loss: 4.477, avg. samples / sec: 66263.06
Iteration:   1460, Loss function: 4.091, Average Loss: 4.453, avg. samples / sec: 66513.03
Iteration:   1460, Loss function: 3.959, Average Loss: 4.443, avg. samples / sec: 66516.24
Iteration:   1460, Loss function: 4.103, Average Loss: 4.468, avg. samples / sec: 66315.48
Iteration:   1460, Loss function: 4.310, Average Loss: 4.487, avg. samples / sec: 66470.81
Iteration:   1460, Loss function: 4.198, Average Loss: 4.475, avg. samples / sec: 66310.42
Iteration:   1460, Loss function: 5.016, Average Loss: 4.478, avg. samples / sec: 66381.11
Iteration:   1460, Loss function: 4.066, Average Loss: 4.460, avg. samples / sec: 66333.96
Iteration:   1460, Loss function: 3.712, Average Loss: 4.447, avg. samples / sec: 66591.04
Iteration:   1460, Loss function: 4.387, Average Loss: 4.467, avg. samples / sec: 66343.54
Iteration:   1460, Loss function: 3.742, Average Loss: 4.459, avg. samples / sec: 66326.93
Iteration:   1460, Loss function: 5.622, Average Loss: 4.473, avg. samples / sec: 66420.49
Iteration:   1460, Loss function: 4.022, Average Loss: 4.484, avg. samples / sec: 66283.04
Iteration:   1460, Loss function: 3.855, Average Loss: 4.472, avg. samples / sec: 66348.17
Iteration:   1460, Loss function: 5.125, Average Loss: 4.455, avg. samples / sec: 66460.43
Iteration:   1460, Loss function: 3.576, Average Loss: 4.448, avg. samples / sec: 66330.83
Iteration:   1460, Loss function: 5.190, Average Loss: 4.466, avg. samples / sec: 66351.07
Iteration:   1460, Loss function: 4.053, Average Loss: 4.483, avg. samples / sec: 66274.56
Iteration:   1460, Loss function: 4.641, Average Loss: 4.461, avg. samples / sec: 66367.98
Iteration:   1460, Loss function: 4.635, Average Loss: 4.452, avg. samples / sec: 66231.05
Iteration:   1460, Loss function: 5.509, Average Loss: 4.457, avg. samples / sec: 66325.00
Iteration:   1460, Loss function: 3.772, Average Loss: 4.478, avg. samples / sec: 66333.21
Iteration:   1460, Loss function: 4.559, Average Loss: 4.455, avg. samples / sec: 66298.82
:::MLL 1558651394.736 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558651394.736 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.118, Average Loss: 4.460, avg. samples / sec: 66176.28
Iteration:   1480, Loss function: 4.928, Average Loss: 4.473, avg. samples / sec: 66228.40
Iteration:   1480, Loss function: 4.178, Average Loss: 4.463, avg. samples / sec: 66190.70
Iteration:   1480, Loss function: 4.293, Average Loss: 4.481, avg. samples / sec: 66302.75
Iteration:   1480, Loss function: 4.564, Average Loss: 4.464, avg. samples / sec: 66175.07
Iteration:   1480, Loss function: 4.310, Average Loss: 4.463, avg. samples / sec: 66168.08
Iteration:   1480, Loss function: 4.327, Average Loss: 4.446, avg. samples / sec: 66142.80
Iteration:   1480, Loss function: 3.293, Average Loss: 4.479, avg. samples / sec: 66159.38
Iteration:   1480, Loss function: 5.860, Average Loss: 4.474, avg. samples / sec: 66108.64
Iteration:   1480, Loss function: 5.048, Average Loss: 4.468, avg. samples / sec: 66286.35
Iteration:   1480, Loss function: 5.036, Average Loss: 4.474, avg. samples / sec: 66106.31
Iteration:   1480, Loss function: 5.016, Average Loss: 4.462, avg. samples / sec: 66135.23
Iteration:   1480, Loss function: 4.211, Average Loss: 4.442, avg. samples / sec: 66233.98
Iteration:   1480, Loss function: 4.326, Average Loss: 4.469, avg. samples / sec: 66169.14
Iteration:   1480, Loss function: 4.597, Average Loss: 4.477, avg. samples / sec: 66306.21
Iteration:   1480, Loss function: 4.502, Average Loss: 4.449, avg. samples / sec: 66162.52
Iteration:   1480, Loss function: 4.395, Average Loss: 4.460, avg. samples / sec: 65997.22
Iteration:   1480, Loss function: 5.425, Average Loss: 4.465, avg. samples / sec: 66165.13
Iteration:   1480, Loss function: 4.761, Average Loss: 4.452, avg. samples / sec: 65983.59
Iteration:   1480, Loss function: 4.178, Average Loss: 4.457, avg. samples / sec: 66284.60
Iteration:   1480, Loss function: 4.440, Average Loss: 4.472, avg. samples / sec: 66145.01
Iteration:   1480, Loss function: 4.147, Average Loss: 4.458, avg. samples / sec: 66258.14
Iteration:   1480, Loss function: 3.630, Average Loss: 4.450, avg. samples / sec: 66174.23
Iteration:   1480, Loss function: 5.110, Average Loss: 4.464, avg. samples / sec: 66039.19
Iteration:   1480, Loss function: 4.991, Average Loss: 4.459, avg. samples / sec: 66212.26
Iteration:   1480, Loss function: 3.579, Average Loss: 4.420, avg. samples / sec: 66018.80
Iteration:   1480, Loss function: 3.821, Average Loss: 4.485, avg. samples / sec: 66005.69
Iteration:   1480, Loss function: 4.970, Average Loss: 4.472, avg. samples / sec: 66095.84
Iteration:   1480, Loss function: 3.994, Average Loss: 4.488, avg. samples / sec: 66056.52
Iteration:   1480, Loss function: 5.233, Average Loss: 4.457, avg. samples / sec: 66069.00
Iteration:   1500, Loss function: 3.398, Average Loss: 4.465, avg. samples / sec: 66690.27
Iteration:   1500, Loss function: 4.584, Average Loss: 4.471, avg. samples / sec: 66657.59
Iteration:   1500, Loss function: 5.044, Average Loss: 4.455, avg. samples / sec: 66674.27
Iteration:   1500, Loss function: 4.345, Average Loss: 4.482, avg. samples / sec: 66647.73
Iteration:   1500, Loss function: 5.261, Average Loss: 4.485, avg. samples / sec: 66590.35
Iteration:   1500, Loss function: 4.359, Average Loss: 4.466, avg. samples / sec: 66569.02
Iteration:   1500, Loss function: 4.682, Average Loss: 4.485, avg. samples / sec: 66515.86
Iteration:   1500, Loss function: 4.835, Average Loss: 4.474, avg. samples / sec: 66599.00
Iteration:   1500, Loss function: 5.851, Average Loss: 4.456, avg. samples / sec: 66602.97
Iteration:   1500, Loss function: 4.165, Average Loss: 4.478, avg. samples / sec: 66741.03
Iteration:   1500, Loss function: 4.557, Average Loss: 4.473, avg. samples / sec: 66452.66
Iteration:   1500, Loss function: 4.343, Average Loss: 4.472, avg. samples / sec: 66537.28
Iteration:   1500, Loss function: 5.335, Average Loss: 4.486, avg. samples / sec: 66660.24
Iteration:   1500, Loss function: 3.410, Average Loss: 4.461, avg. samples / sec: 66615.59
Iteration:   1500, Loss function: 5.486, Average Loss: 4.471, avg. samples / sec: 66624.57
Iteration:   1500, Loss function: 4.337, Average Loss: 4.424, avg. samples / sec: 66631.40
Iteration:   1500, Loss function: 3.774, Average Loss: 4.496, avg. samples / sec: 66763.98
Iteration:   1500, Loss function: 3.220, Average Loss: 4.443, avg. samples / sec: 66556.60
Iteration:   1500, Loss function: 4.455, Average Loss: 4.476, avg. samples / sec: 66526.19
Iteration:   1500, Loss function: 6.890, Average Loss: 4.473, avg. samples / sec: 66472.56
Iteration:   1500, Loss function: 4.255, Average Loss: 4.466, avg. samples / sec: 66553.99
Iteration:   1500, Loss function: 4.339, Average Loss: 4.475, avg. samples / sec: 66560.00
Iteration:   1500, Loss function: 4.292, Average Loss: 4.476, avg. samples / sec: 66395.40
Iteration:   1500, Loss function: 4.378, Average Loss: 4.459, avg. samples / sec: 66529.02
Iteration:   1500, Loss function: 4.286, Average Loss: 4.470, avg. samples / sec: 66357.57
Iteration:   1500, Loss function: 5.084, Average Loss: 4.454, avg. samples / sec: 66449.78
Iteration:   1500, Loss function: 4.413, Average Loss: 4.464, avg. samples / sec: 66408.13
Iteration:   1500, Loss function: 4.735, Average Loss: 4.467, avg. samples / sec: 66512.34
Iteration:   1500, Loss function: 4.408, Average Loss: 4.451, avg. samples / sec: 66511.84
Iteration:   1500, Loss function: 4.478, Average Loss: 4.456, avg. samples / sec: 66631.06
Iteration:   1520, Loss function: 4.862, Average Loss: 4.465, avg. samples / sec: 66616.95
Iteration:   1520, Loss function: 4.571, Average Loss: 4.478, avg. samples / sec: 66599.00
Iteration:   1520, Loss function: 4.007, Average Loss: 4.473, avg. samples / sec: 66706.21
Iteration:   1520, Loss function: 4.730, Average Loss: 4.487, avg. samples / sec: 66570.15
Iteration:   1520, Loss function: 5.294, Average Loss: 4.459, avg. samples / sec: 66529.49
Iteration:   1520, Loss function: 3.838, Average Loss: 4.470, avg. samples / sec: 66678.00
Iteration:   1520, Loss function: 2.354, Average Loss: 4.477, avg. samples / sec: 66574.68
Iteration:   1520, Loss function: 6.090, Average Loss: 4.475, avg. samples / sec: 66714.36
Iteration:   1520, Loss function: 3.092, Average Loss: 4.477, avg. samples / sec: 66559.21
Iteration:   1520, Loss function: 3.623, Average Loss: 4.460, avg. samples / sec: 66681.28
Iteration:   1520, Loss function: 4.045, Average Loss: 4.445, avg. samples / sec: 66600.95
Iteration:   1520, Loss function: 5.666, Average Loss: 4.477, avg. samples / sec: 66642.37
Iteration:   1520, Loss function: 3.899, Average Loss: 4.468, avg. samples / sec: 66479.52
Iteration:   1520, Loss function: 4.469, Average Loss: 4.463, avg. samples / sec: 66625.64
Iteration:   1520, Loss function: 4.793, Average Loss: 4.464, avg. samples / sec: 66545.92
Iteration:   1520, Loss function: 3.712, Average Loss: 4.471, avg. samples / sec: 66543.03
Iteration:   1520, Loss function: 4.003, Average Loss: 4.476, avg. samples / sec: 66597.55
Iteration:   1520, Loss function: 4.053, Average Loss: 4.459, avg. samples / sec: 66518.81
Iteration:   1520, Loss function: 3.425, Average Loss: 4.488, avg. samples / sec: 66538.85
Iteration:   1520, Loss function: 4.002, Average Loss: 4.470, avg. samples / sec: 66522.17
Iteration:   1520, Loss function: 5.064, Average Loss: 4.473, avg. samples / sec: 66582.64
Iteration:   1520, Loss function: 4.711, Average Loss: 4.452, avg. samples / sec: 66578.93
Iteration:   1520, Loss function: 5.036, Average Loss: 4.470, avg. samples / sec: 66428.45
Iteration:   1520, Loss function: 4.443, Average Loss: 4.468, avg. samples / sec: 66551.64
Iteration:   1520, Loss function: 3.673, Average Loss: 4.460, avg. samples / sec: 66671.56
Iteration:   1520, Loss function: 4.902, Average Loss: 4.457, avg. samples / sec: 66586.82
Iteration:   1520, Loss function: 3.601, Average Loss: 4.424, avg. samples / sec: 66485.95
Iteration:   1520, Loss function: 4.252, Average Loss: 4.495, avg. samples / sec: 66486.24
Iteration:   1520, Loss function: 5.406, Average Loss: 4.471, avg. samples / sec: 66432.46
Iteration:   1520, Loss function: 3.692, Average Loss: 4.482, avg. samples / sec: 66336.83
:::MLL 1558651396.505 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558651396.506 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.570, Average Loss: 4.428, avg. samples / sec: 66659.80
Iteration:   1540, Loss function: 3.820, Average Loss: 4.469, avg. samples / sec: 66422.62
Iteration:   1540, Loss function: 5.119, Average Loss: 4.480, avg. samples / sec: 66353.51
Iteration:   1540, Loss function: 3.811, Average Loss: 4.495, avg. samples / sec: 66530.56
Iteration:   1540, Loss function: 4.398, Average Loss: 4.466, avg. samples / sec: 66448.24
Iteration:   1540, Loss function: 3.792, Average Loss: 4.476, avg. samples / sec: 66356.10
Iteration:   1540, Loss function: 4.814, Average Loss: 4.458, avg. samples / sec: 66350.38
Iteration:   1540, Loss function: 4.350, Average Loss: 4.469, avg. samples / sec: 66418.15
Iteration:   1540, Loss function: 4.535, Average Loss: 4.477, avg. samples / sec: 66402.41
Iteration:   1540, Loss function: 4.179, Average Loss: 4.469, avg. samples / sec: 66386.80
Iteration:   1540, Loss function: 4.163, Average Loss: 4.451, avg. samples / sec: 66297.95
Iteration:   1540, Loss function: 5.232, Average Loss: 4.480, avg. samples / sec: 66350.67
Iteration:   1540, Loss function: 4.829, Average Loss: 4.471, avg. samples / sec: 66316.54
Iteration:   1540, Loss function: 3.570, Average Loss: 4.455, avg. samples / sec: 66365.51
Iteration:   1540, Loss function: 4.489, Average Loss: 4.444, avg. samples / sec: 66318.85
Iteration:   1540, Loss function: 5.005, Average Loss: 4.475, avg. samples / sec: 66362.07
Iteration:   1540, Loss function: 3.980, Average Loss: 4.455, avg. samples / sec: 66424.16
Iteration:   1540, Loss function: 4.316, Average Loss: 4.463, avg. samples / sec: 66347.23
Iteration:   1540, Loss function: 3.945, Average Loss: 4.478, avg. samples / sec: 66486.99
Iteration:   1540, Loss function: 5.070, Average Loss: 4.477, avg. samples / sec: 66253.87
Iteration:   1540, Loss function: 4.304, Average Loss: 4.463, avg. samples / sec: 66125.73
Iteration:   1540, Loss function: 4.372, Average Loss: 4.451, avg. samples / sec: 66345.89
Iteration:   1540, Loss function: 5.160, Average Loss: 4.487, avg. samples / sec: 66284.04
Iteration:   1540, Loss function: 4.741, Average Loss: 4.470, avg. samples / sec: 66208.37
Iteration:   1540, Loss function: 4.642, Average Loss: 4.460, avg. samples / sec: 66310.58
Iteration:   1540, Loss function: 3.789, Average Loss: 4.469, avg. samples / sec: 66384.73
Iteration:   1540, Loss function: 4.956, Average Loss: 4.460, avg. samples / sec: 66264.90
Iteration:   1540, Loss function: 5.292, Average Loss: 4.488, avg. samples / sec: 66149.29
Iteration:   1540, Loss function: 5.257, Average Loss: 4.475, avg. samples / sec: 66217.51
Iteration:   1540, Loss function: 5.023, Average Loss: 4.463, avg. samples / sec: 66250.73
Iteration:   1560, Loss function: 5.650, Average Loss: 4.453, avg. samples / sec: 66541.52
Iteration:   1560, Loss function: 4.156, Average Loss: 4.477, avg. samples / sec: 66430.98
Iteration:   1560, Loss function: 3.601, Average Loss: 4.478, avg. samples / sec: 66517.02
Iteration:   1560, Loss function: 4.379, Average Loss: 4.465, avg. samples / sec: 66498.47
Iteration:   1560, Loss function: 3.070, Average Loss: 4.466, avg. samples / sec: 66343.08
Iteration:   1560, Loss function: 4.427, Average Loss: 4.474, avg. samples / sec: 66618.99
Iteration:   1560, Loss function: 4.895, Average Loss: 4.485, avg. samples / sec: 66536.87
Iteration:   1560, Loss function: 3.331, Average Loss: 4.464, avg. samples / sec: 66532.53
Iteration:   1560, Loss function: 4.124, Average Loss: 4.473, avg. samples / sec: 66462.34
Iteration:   1560, Loss function: 4.432, Average Loss: 4.457, avg. samples / sec: 66532.09
Iteration:   1560, Loss function: 4.376, Average Loss: 4.434, avg. samples / sec: 66216.42
Iteration:   1560, Loss function: 4.708, Average Loss: 4.462, avg. samples / sec: 66450.15
Iteration:   1560, Loss function: 5.079, Average Loss: 4.453, avg. samples / sec: 66424.13
Iteration:   1560, Loss function: 4.846, Average Loss: 4.464, avg. samples / sec: 66582.32
Iteration:   1560, Loss function: 3.543, Average Loss: 4.445, avg. samples / sec: 66413.61
Iteration:   1560, Loss function: 4.768, Average Loss: 4.476, avg. samples / sec: 66541.96
Iteration:   1560, Loss function: 3.294, Average Loss: 4.476, avg. samples / sec: 66425.10
Iteration:   1560, Loss function: 3.601, Average Loss: 4.447, avg. samples / sec: 66424.88
Iteration:   1560, Loss function: 4.662, Average Loss: 4.456, avg. samples / sec: 66343.39
Iteration:   1560, Loss function: 5.180, Average Loss: 4.470, avg. samples / sec: 66496.24
Iteration:   1560, Loss function: 4.428, Average Loss: 4.483, avg. samples / sec: 66339.05
Iteration:   1560, Loss function: 4.591, Average Loss: 4.459, avg. samples / sec: 66376.07
Iteration:   1560, Loss function: 5.587, Average Loss: 4.492, avg. samples / sec: 66500.67
Iteration:   1560, Loss function: 4.162, Average Loss: 4.472, avg. samples / sec: 66299.13
Iteration:   1560, Loss function: 4.832, Average Loss: 4.470, avg. samples / sec: 66331.68
Iteration:   1560, Loss function: 3.928, Average Loss: 4.463, avg. samples / sec: 66417.05
Iteration:   1560, Loss function: 5.087, Average Loss: 4.473, avg. samples / sec: 66333.49
Iteration:   1560, Loss function: 4.731, Average Loss: 4.464, avg. samples / sec: 66205.01
Iteration:   1560, Loss function: 3.614, Average Loss: 4.485, avg. samples / sec: 66362.63
Iteration:   1560, Loss function: 4.434, Average Loss: 4.492, avg. samples / sec: 66165.69
Iteration:   1580, Loss function: 5.051, Average Loss: 4.462, avg. samples / sec: 66766.57
Iteration:   1580, Loss function: 5.558, Average Loss: 4.474, avg. samples / sec: 66700.78
Iteration:   1580, Loss function: 4.451, Average Loss: 4.482, avg. samples / sec: 66598.97
Iteration:   1580, Loss function: 4.284, Average Loss: 4.484, avg. samples / sec: 66595.26
Iteration:   1580, Loss function: 4.871, Average Loss: 4.426, avg. samples / sec: 66649.11
Iteration:   1580, Loss function: 4.098, Average Loss: 4.473, avg. samples / sec: 66704.22
Iteration:   1580, Loss function: 4.934, Average Loss: 4.466, avg. samples / sec: 66561.38
Iteration:   1580, Loss function: 4.603, Average Loss: 4.476, avg. samples / sec: 66677.65
Iteration:   1580, Loss function: 4.848, Average Loss: 4.465, avg. samples / sec: 66600.23
Iteration:   1580, Loss function: 6.472, Average Loss: 4.479, avg. samples / sec: 66585.47
Iteration:   1580, Loss function: 3.552, Average Loss: 4.464, avg. samples / sec: 66738.81
Iteration:   1580, Loss function: 5.004, Average Loss: 4.489, avg. samples / sec: 66650.12
Iteration:   1580, Loss function: 4.003, Average Loss: 4.457, avg. samples / sec: 66458.18
Iteration:   1580, Loss function: 3.847, Average Loss: 4.458, avg. samples / sec: 66638.43
Iteration:   1580, Loss function: 4.605, Average Loss: 4.465, avg. samples / sec: 66578.49
Iteration:   1580, Loss function: 4.827, Average Loss: 4.450, avg. samples / sec: 66619.40
Iteration:   1580, Loss function: 3.566, Average Loss: 4.456, avg. samples / sec: 66544.25
Iteration:   1580, Loss function: 3.554, Average Loss: 4.466, avg. samples / sec: 66581.44
Iteration:   1580, Loss function: 5.305, Average Loss: 4.459, avg. samples / sec: 66639.06
Iteration:   1580, Loss function: 3.932, Average Loss: 4.445, avg. samples / sec: 66552.80
Iteration:   1580, Loss function: 3.448, Average Loss: 4.484, avg. samples / sec: 66677.78
Iteration:   1580, Loss function: 3.794, Average Loss: 4.461, avg. samples / sec: 66415.17
Iteration:   1580, Loss function: 5.201, Average Loss: 4.471, avg. samples / sec: 66581.63
Iteration:   1580, Loss function: 5.565, Average Loss: 4.456, avg. samples / sec: 66518.15
Iteration:   1580, Loss function: 4.357, Average Loss: 4.469, avg. samples / sec: 66573.42
Iteration:   1580, Loss function: 5.300, Average Loss: 4.479, avg. samples / sec: 66557.80
Iteration:   1580, Loss function: 4.185, Average Loss: 4.454, avg. samples / sec: 66516.61
Iteration:   1580, Loss function: 4.886, Average Loss: 4.478, avg. samples / sec: 66491.19
Iteration:   1580, Loss function: 3.702, Average Loss: 4.489, avg. samples / sec: 66584.68
Iteration:   1580, Loss function: 4.145, Average Loss: 4.486, avg. samples / sec: 66327.87
Iteration:   1600, Loss function: 3.722, Average Loss: 4.481, avg. samples / sec: 66433.93
Iteration:   1600, Loss function: 3.801, Average Loss: 4.476, avg. samples / sec: 66525.97
Iteration:   1600, Loss function: 3.933, Average Loss: 4.482, avg. samples / sec: 66355.26
Iteration:   1600, Loss function: 5.628, Average Loss: 4.478, avg. samples / sec: 66393.65
Iteration:   1600, Loss function: 4.735, Average Loss: 4.470, avg. samples / sec: 66539.57
Iteration:   1600, Loss function: 3.768, Average Loss: 4.459, avg. samples / sec: 66527.57
Iteration:   1600, Loss function: 4.848, Average Loss: 4.428, avg. samples / sec: 66363.85
Iteration:   1600, Loss function: 5.971, Average Loss: 4.475, avg. samples / sec: 66225.42
Iteration:   1600, Loss function: 4.602, Average Loss: 4.470, avg. samples / sec: 66376.85
Iteration:   1600, Loss function: 4.029, Average Loss: 4.465, avg. samples / sec: 66412.86
Iteration:   1600, Loss function: 3.799, Average Loss: 4.467, avg. samples / sec: 66455.95
Iteration:   1600, Loss function: 3.932, Average Loss: 4.456, avg. samples / sec: 66528.67
Iteration:   1600, Loss function: 3.591, Average Loss: 4.481, avg. samples / sec: 66505.00
Iteration:   1600, Loss function: 4.271, Average Loss: 4.463, avg. samples / sec: 66195.77
Iteration:   1600, Loss function: 3.860, Average Loss: 4.454, avg. samples / sec: 66373.79
Iteration:   1600, Loss function: 4.517, Average Loss: 4.485, avg. samples / sec: 66387.80
Iteration:   1600, Loss function: 4.068, Average Loss: 4.456, avg. samples / sec: 66388.33
Iteration:   1600, Loss function: 4.761, Average Loss: 4.461, avg. samples / sec: 66356.16
Iteration:   1600, Loss function: 4.617, Average Loss: 4.487, avg. samples / sec: 66491.41
Iteration:   1600, Loss function: 4.827, Average Loss: 4.487, avg. samples / sec: 66386.55
Iteration:   1600, Loss function: 4.325, Average Loss: 4.446, avg. samples / sec: 66360.91
Iteration:   1600, Loss function: 3.970, Average Loss: 4.470, avg. samples / sec: 66283.82
Iteration:   1600, Loss function: 6.021, Average Loss: 4.477, avg. samples / sec: 66420.06
Iteration:   1600, Loss function: 4.917, Average Loss: 4.471, avg. samples / sec: 66375.45
Iteration:   1600, Loss function: 4.103, Average Loss: 4.480, avg. samples / sec: 66457.17
Iteration:   1600, Loss function: 5.080, Average Loss: 4.473, avg. samples / sec: 66221.81
Iteration:   1600, Loss function: 4.114, Average Loss: 4.457, avg. samples / sec: 66358.51
Iteration:   1600, Loss function: 4.091, Average Loss: 4.448, avg. samples / sec: 66267.77
Iteration:   1600, Loss function: 3.527, Average Loss: 4.456, avg. samples / sec: 66274.25
Iteration:   1600, Loss function: 4.276, Average Loss: 4.464, avg. samples / sec: 66234.10
:::MLL 1558651398.283 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558651398.284 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 3.834, Average Loss: 4.461, avg. samples / sec: 65287.17
Iteration:   1620, Loss function: 3.857, Average Loss: 4.468, avg. samples / sec: 65337.96
Iteration:   1620, Loss function: 4.394, Average Loss: 4.466, avg. samples / sec: 65187.21
Iteration:   1620, Loss function: 4.164, Average Loss: 4.473, avg. samples / sec: 65048.62
Iteration:   1620, Loss function: 4.270, Average Loss: 4.467, avg. samples / sec: 65142.76
Iteration:   1620, Loss function: 4.782, Average Loss: 4.458, avg. samples / sec: 65140.50
Iteration:   1620, Loss function: 4.801, Average Loss: 4.479, avg. samples / sec: 65045.50
Iteration:   1620, Loss function: 4.134, Average Loss: 4.482, avg. samples / sec: 65106.05
Iteration:   1620, Loss function: 3.854, Average Loss: 4.482, avg. samples / sec: 65238.14
Iteration:   1620, Loss function: 4.498, Average Loss: 4.434, avg. samples / sec: 65126.81
Iteration:   1620, Loss function: 4.235, Average Loss: 4.465, avg. samples / sec: 65246.21
Iteration:   1620, Loss function: 4.349, Average Loss: 4.448, avg. samples / sec: 65233.58
Iteration:   1620, Loss function: 4.175, Average Loss: 4.476, avg. samples / sec: 65103.43
Iteration:   1620, Loss function: 4.743, Average Loss: 4.451, avg. samples / sec: 65164.06
Iteration:   1620, Loss function: 4.184, Average Loss: 4.455, avg. samples / sec: 65303.41
Iteration:   1620, Loss function: 6.001, Average Loss: 4.454, avg. samples / sec: 65150.71
Iteration:   1620, Loss function: 3.944, Average Loss: 4.456, avg. samples / sec: 65230.87
Iteration:   1620, Loss function: 5.105, Average Loss: 4.488, avg. samples / sec: 65210.61
Iteration:   1620, Loss function: 3.495, Average Loss: 4.481, avg. samples / sec: 65124.46
Iteration:   1620, Loss function: 4.512, Average Loss: 4.475, avg. samples / sec: 65245.91
Iteration:   1620, Loss function: 5.066, Average Loss: 4.480, avg. samples / sec: 65083.71
Iteration:   1620, Loss function: 5.146, Average Loss: 4.468, avg. samples / sec: 65038.74
Iteration:   1620, Loss function: 4.129, Average Loss: 4.461, avg. samples / sec: 65064.27
Iteration:   1620, Loss function: 4.407, Average Loss: 4.466, avg. samples / sec: 65063.42
Iteration:   1620, Loss function: 4.964, Average Loss: 4.460, avg. samples / sec: 65198.76
Iteration:   1620, Loss function: 4.398, Average Loss: 4.480, avg. samples / sec: 65101.39
Iteration:   1620, Loss function: 5.116, Average Loss: 4.462, avg. samples / sec: 65078.99
Iteration:   1620, Loss function: 4.295, Average Loss: 4.483, avg. samples / sec: 65073.97
Iteration:   1620, Loss function: 3.906, Average Loss: 4.455, avg. samples / sec: 64934.22
Iteration:   1620, Loss function: 5.521, Average Loss: 4.448, avg. samples / sec: 65069.64
Iteration:   1640, Loss function: 4.194, Average Loss: 4.450, avg. samples / sec: 66652.52
Iteration:   1640, Loss function: 3.952, Average Loss: 4.465, avg. samples / sec: 66728.95
Iteration:   1640, Loss function: 5.530, Average Loss: 4.466, avg. samples / sec: 66513.29
Iteration:   1640, Loss function: 5.057, Average Loss: 4.481, avg. samples / sec: 66548.34
Iteration:   1640, Loss function: 4.656, Average Loss: 4.473, avg. samples / sec: 66554.72
Iteration:   1640, Loss function: 3.706, Average Loss: 4.465, avg. samples / sec: 66496.84
Iteration:   1640, Loss function: 4.426, Average Loss: 4.462, avg. samples / sec: 66420.31
Iteration:   1640, Loss function: 4.362, Average Loss: 4.463, avg. samples / sec: 66536.40
Iteration:   1640, Loss function: 6.164, Average Loss: 4.463, avg. samples / sec: 66557.26
Iteration:   1640, Loss function: 3.039, Average Loss: 4.481, avg. samples / sec: 66698.67
Iteration:   1640, Loss function: 4.898, Average Loss: 4.484, avg. samples / sec: 66522.58
Iteration:   1640, Loss function: 4.309, Average Loss: 4.484, avg. samples / sec: 66551.35
Iteration:   1640, Loss function: 4.464, Average Loss: 4.470, avg. samples / sec: 66611.78
Iteration:   1640, Loss function: 3.724, Average Loss: 4.457, avg. samples / sec: 66745.55
Iteration:   1640, Loss function: 3.634, Average Loss: 4.479, avg. samples / sec: 66554.65
Iteration:   1640, Loss function: 4.112, Average Loss: 4.477, avg. samples / sec: 66491.98
Iteration:   1640, Loss function: 4.131, Average Loss: 4.478, avg. samples / sec: 66676.48
Iteration:   1640, Loss function: 4.055, Average Loss: 4.456, avg. samples / sec: 66484.42
Iteration:   1640, Loss function: 3.661, Average Loss: 4.462, avg. samples / sec: 66581.26
Iteration:   1640, Loss function: 4.489, Average Loss: 4.484, avg. samples / sec: 66417.80
Iteration:   1640, Loss function: 5.040, Average Loss: 4.451, avg. samples / sec: 66432.11
Iteration:   1640, Loss function: 5.288, Average Loss: 4.455, avg. samples / sec: 66434.71
Iteration:   1640, Loss function: 5.505, Average Loss: 4.438, avg. samples / sec: 66407.60
Iteration:   1640, Loss function: 3.660, Average Loss: 4.475, avg. samples / sec: 66450.50
Iteration:   1640, Loss function: 3.630, Average Loss: 4.465, avg. samples / sec: 66346.85
Iteration:   1640, Loss function: 4.166, Average Loss: 4.456, avg. samples / sec: 66381.86
Iteration:   1640, Loss function: 4.616, Average Loss: 4.449, avg. samples / sec: 66614.21
Iteration:   1640, Loss function: 3.934, Average Loss: 4.463, avg. samples / sec: 66454.20
Iteration:   1640, Loss function: 3.730, Average Loss: 4.459, avg. samples / sec: 66553.65
Iteration:   1640, Loss function: 3.907, Average Loss: 4.481, avg. samples / sec: 66376.17
Iteration:   1660, Loss function: 4.796, Average Loss: 4.433, avg. samples / sec: 66702.14
Iteration:   1660, Loss function: 4.820, Average Loss: 4.476, avg. samples / sec: 66609.51
Iteration:   1660, Loss function: 5.748, Average Loss: 4.464, avg. samples / sec: 66500.20
Iteration:   1660, Loss function: 3.963, Average Loss: 4.472, avg. samples / sec: 66406.54
Iteration:   1660, Loss function: 4.499, Average Loss: 4.477, avg. samples / sec: 66548.31
Iteration:   1660, Loss function: 3.319, Average Loss: 4.462, avg. samples / sec: 66335.99
Iteration:   1660, Loss function: 4.923, Average Loss: 4.450, avg. samples / sec: 66552.67
Iteration:   1660, Loss function: 4.591, Average Loss: 4.464, avg. samples / sec: 66387.42
Iteration:   1660, Loss function: 3.801, Average Loss: 4.450, avg. samples / sec: 66305.21
Iteration:   1660, Loss function: 3.829, Average Loss: 4.467, avg. samples / sec: 66372.07
Iteration:   1660, Loss function: 3.506, Average Loss: 4.485, avg. samples / sec: 66367.85
Iteration:   1660, Loss function: 4.506, Average Loss: 4.467, avg. samples / sec: 66360.51
Iteration:   1660, Loss function: 5.218, Average Loss: 4.460, avg. samples / sec: 66372.66
Iteration:   1660, Loss function: 4.973, Average Loss: 4.477, avg. samples / sec: 66526.25
Iteration:   1660, Loss function: 3.919, Average Loss: 4.477, avg. samples / sec: 66405.78
Iteration:   1660, Loss function: 4.290, Average Loss: 4.463, avg. samples / sec: 66559.75
Iteration:   1660, Loss function: 5.584, Average Loss: 4.477, avg. samples / sec: 66407.91
Iteration:   1660, Loss function: 4.786, Average Loss: 4.481, avg. samples / sec: 66364.63
Iteration:   1660, Loss function: 3.479, Average Loss: 4.453, avg. samples / sec: 66368.07
Iteration:   1660, Loss function: 2.803, Average Loss: 4.454, avg. samples / sec: 66463.06
Iteration:   1660, Loss function: 3.501, Average Loss: 4.466, avg. samples / sec: 66356.45
Iteration:   1660, Loss function: 3.930, Average Loss: 4.456, avg. samples / sec: 66412.86
Iteration:   1660, Loss function: 4.155, Average Loss: 4.481, avg. samples / sec: 66320.03
Iteration:   1660, Loss function: 4.365, Average Loss: 4.474, avg. samples / sec: 66379.67
Iteration:   1660, Loss function: 3.593, Average Loss: 4.469, avg. samples / sec: 66454.60
Iteration:   1660, Loss function: 3.900, Average Loss: 4.455, avg. samples / sec: 66450.40
Iteration:   1660, Loss function: 4.047, Average Loss: 4.483, avg. samples / sec: 66488.09
Iteration:   1660, Loss function: 5.111, Average Loss: 4.463, avg. samples / sec: 66330.55
Iteration:   1660, Loss function: 4.755, Average Loss: 4.459, avg. samples / sec: 66373.76
Iteration:   1660, Loss function: 4.244, Average Loss: 4.460, avg. samples / sec: 66368.13
:::MLL 1558651400.057 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558651400.057 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 3.706, Average Loss: 4.479, avg. samples / sec: 66358.73
Iteration:   1680, Loss function: 4.542, Average Loss: 4.458, avg. samples / sec: 66243.91
Iteration:   1680, Loss function: 3.470, Average Loss: 4.471, avg. samples / sec: 66296.17
Iteration:   1680, Loss function: 3.501, Average Loss: 4.463, avg. samples / sec: 66129.70
Iteration:   1680, Loss function: 5.485, Average Loss: 4.464, avg. samples / sec: 66237.15
Iteration:   1680, Loss function: 4.393, Average Loss: 4.481, avg. samples / sec: 66365.19
Iteration:   1680, Loss function: 3.241, Average Loss: 4.472, avg. samples / sec: 66092.64
Iteration:   1680, Loss function: 3.827, Average Loss: 4.484, avg. samples / sec: 66220.50
Iteration:   1680, Loss function: 4.327, Average Loss: 4.475, avg. samples / sec: 66195.80
Iteration:   1680, Loss function: 3.931, Average Loss: 4.471, avg. samples / sec: 66128.15
Iteration:   1680, Loss function: 4.286, Average Loss: 4.449, avg. samples / sec: 66369.60
Iteration:   1680, Loss function: 4.897, Average Loss: 4.463, avg. samples / sec: 66172.52
Iteration:   1680, Loss function: 5.647, Average Loss: 4.456, avg. samples / sec: 66230.46
Iteration:   1680, Loss function: 3.781, Average Loss: 4.446, avg. samples / sec: 66160.94
Iteration:   1680, Loss function: 4.457, Average Loss: 4.451, avg. samples / sec: 66249.64
Iteration:   1680, Loss function: 5.201, Average Loss: 4.474, avg. samples / sec: 66158.45
Iteration:   1680, Loss function: 5.296, Average Loss: 4.484, avg. samples / sec: 66242.63
Iteration:   1680, Loss function: 4.056, Average Loss: 4.463, avg. samples / sec: 66190.58
Iteration:   1680, Loss function: 3.322, Average Loss: 4.456, avg. samples / sec: 66303.56
Iteration:   1680, Loss function: 3.986, Average Loss: 4.460, avg. samples / sec: 66112.92
Iteration:   1680, Loss function: 3.985, Average Loss: 4.459, avg. samples / sec: 66242.57
Iteration:   1680, Loss function: 4.044, Average Loss: 4.449, avg. samples / sec: 66041.20
Iteration:   1680, Loss function: 3.566, Average Loss: 4.452, avg. samples / sec: 66125.98
Iteration:   1680, Loss function: 2.402, Average Loss: 4.468, avg. samples / sec: 66026.07
Iteration:   1680, Loss function: 4.039, Average Loss: 4.468, avg. samples / sec: 66155.72
Iteration:   1680, Loss function: 3.758, Average Loss: 4.463, avg. samples / sec: 66063.52
Iteration:   1680, Loss function: 4.595, Average Loss: 4.459, avg. samples / sec: 66073.62
Iteration:   1680, Loss function: 3.767, Average Loss: 4.450, avg. samples / sec: 66156.28
Iteration:   1680, Loss function: 3.665, Average Loss: 4.462, avg. samples / sec: 66062.22
Iteration:   1680, Loss function: 5.855, Average Loss: 4.430, avg. samples / sec: 65799.33
Iteration:   1700, Loss function: 4.746, Average Loss: 4.482, avg. samples / sec: 66611.37
Iteration:   1700, Loss function: 3.270, Average Loss: 4.426, avg. samples / sec: 66812.79
Iteration:   1700, Loss function: 3.459, Average Loss: 4.461, avg. samples / sec: 66788.60
Iteration:   1700, Loss function: 4.576, Average Loss: 4.460, avg. samples / sec: 66447.71
Iteration:   1700, Loss function: 4.875, Average Loss: 4.478, avg. samples / sec: 66518.94
Iteration:   1700, Loss function: 3.581, Average Loss: 4.472, avg. samples / sec: 66451.09
Iteration:   1700, Loss function: 5.000, Average Loss: 4.456, avg. samples / sec: 66397.31
Iteration:   1700, Loss function: 2.863, Average Loss: 4.474, avg. samples / sec: 66354.01
Iteration:   1700, Loss function: 3.147, Average Loss: 4.456, avg. samples / sec: 66556.98
Iteration:   1700, Loss function: 4.255, Average Loss: 4.470, avg. samples / sec: 66614.14
Iteration:   1700, Loss function: 4.582, Average Loss: 4.449, avg. samples / sec: 66488.12
Iteration:   1700, Loss function: 4.163, Average Loss: 4.483, avg. samples / sec: 66500.92
Iteration:   1700, Loss function: 5.592, Average Loss: 4.464, avg. samples / sec: 66591.98
Iteration:   1700, Loss function: 3.627, Average Loss: 4.481, avg. samples / sec: 66443.86
Iteration:   1700, Loss function: 5.909, Average Loss: 4.464, avg. samples / sec: 66396.05
Iteration:   1700, Loss function: 4.421, Average Loss: 4.439, avg. samples / sec: 66476.86
Iteration:   1700, Loss function: 4.049, Average Loss: 4.454, avg. samples / sec: 66538.22
Iteration:   1700, Loss function: 3.706, Average Loss: 4.464, avg. samples / sec: 66435.09
Iteration:   1700, Loss function: 3.837, Average Loss: 4.443, avg. samples / sec: 66427.57
Iteration:   1700, Loss function: 4.071, Average Loss: 4.458, avg. samples / sec: 66542.08
Iteration:   1700, Loss function: 3.863, Average Loss: 4.452, avg. samples / sec: 66502.86
Iteration:   1700, Loss function: 3.763, Average Loss: 4.445, avg. samples / sec: 66508.26
Iteration:   1700, Loss function: 4.401, Average Loss: 4.459, avg. samples / sec: 66538.09
Iteration:   1700, Loss function: 4.170, Average Loss: 4.457, avg. samples / sec: 66422.09
Iteration:   1700, Loss function: 5.222, Average Loss: 4.446, avg. samples / sec: 66528.76
Iteration:   1700, Loss function: 4.313, Average Loss: 4.452, avg. samples / sec: 66491.10
Iteration:   1700, Loss function: 4.594, Average Loss: 4.474, avg. samples / sec: 66295.33
Iteration:   1700, Loss function: 4.662, Average Loss: 4.462, avg. samples / sec: 66485.92
Iteration:   1700, Loss function: 4.468, Average Loss: 4.473, avg. samples / sec: 66366.19
Iteration:   1700, Loss function: 3.897, Average Loss: 4.449, avg. samples / sec: 66347.60
Iteration:   1720, Loss function: 3.000, Average Loss: 4.461, avg. samples / sec: 66788.31
Iteration:   1720, Loss function: 5.053, Average Loss: 4.442, avg. samples / sec: 66831.20
Iteration:   1720, Loss function: 3.759, Average Loss: 4.461, avg. samples / sec: 66815.77
Iteration:   1720, Loss function: 4.084, Average Loss: 4.478, avg. samples / sec: 66571.35
Iteration:   1720, Loss function: 3.528, Average Loss: 4.455, avg. samples / sec: 66684.59
Iteration:   1720, Loss function: 5.049, Average Loss: 4.428, avg. samples / sec: 66584.81
Iteration:   1720, Loss function: 4.467, Average Loss: 4.459, avg. samples / sec: 66672.48
Iteration:   1720, Loss function: 3.799, Average Loss: 4.449, avg. samples / sec: 66721.06
Iteration:   1720, Loss function: 4.936, Average Loss: 4.480, avg. samples / sec: 66672.82
Iteration:   1720, Loss function: 6.147, Average Loss: 4.476, avg. samples / sec: 66827.55
Iteration:   1720, Loss function: 3.583, Average Loss: 4.471, avg. samples / sec: 66640.07
Iteration:   1720, Loss function: 4.568, Average Loss: 4.464, avg. samples / sec: 66662.32
Iteration:   1720, Loss function: 3.892, Average Loss: 4.471, avg. samples / sec: 66620.35
Iteration:   1720, Loss function: 3.571, Average Loss: 4.465, avg. samples / sec: 66667.52
Iteration:   1720, Loss function: 3.623, Average Loss: 4.461, avg. samples / sec: 66676.23
Iteration:   1720, Loss function: 4.152, Average Loss: 4.477, avg. samples / sec: 66577.23
Iteration:   1720, Loss function: 4.732, Average Loss: 4.460, avg. samples / sec: 66734.52
Iteration:   1720, Loss function: 4.380, Average Loss: 4.444, avg. samples / sec: 66665.22
Iteration:   1720, Loss function: 5.510, Average Loss: 4.446, avg. samples / sec: 66649.87
Iteration:   1720, Loss function: 5.084, Average Loss: 4.471, avg. samples / sec: 66573.77
Iteration:   1720, Loss function: 3.703, Average Loss: 4.455, avg. samples / sec: 66496.53
Iteration:   1720, Loss function: 4.635, Average Loss: 4.456, avg. samples / sec: 66592.05
Iteration:   1720, Loss function: 3.195, Average Loss: 4.442, avg. samples / sec: 66673.80
Iteration:   1720, Loss function: 4.393, Average Loss: 4.447, avg. samples / sec: 66667.18
Iteration:   1720, Loss function: 5.013, Average Loss: 4.454, avg. samples / sec: 66593.40
Iteration:   1720, Loss function: 5.302, Average Loss: 4.448, avg. samples / sec: 66610.08
Iteration:   1720, Loss function: 4.297, Average Loss: 4.472, avg. samples / sec: 66639.47
Iteration:   1720, Loss function: 4.218, Average Loss: 4.458, avg. samples / sec: 66600.92
Iteration:   1720, Loss function: 3.517, Average Loss: 4.442, avg. samples / sec: 66670.84
Iteration:   1720, Loss function: 5.020, Average Loss: 4.478, avg. samples / sec: 66500.01
Iteration:   1740, Loss function: 5.036, Average Loss: 4.459, avg. samples / sec: 66384.36
Iteration:   1740, Loss function: 5.279, Average Loss: 4.446, avg. samples / sec: 66660.24
Iteration:   1740, Loss function: 5.054, Average Loss: 4.479, avg. samples / sec: 66461.03
Iteration:   1740, Loss function: 2.615, Average Loss: 4.458, avg. samples / sec: 66507.79
Iteration:   1740, Loss function: 3.541, Average Loss: 4.470, avg. samples / sec: 66627.34
Iteration:   1740, Loss function: 3.460, Average Loss: 4.456, avg. samples / sec: 66435.77
Iteration:   1740, Loss function: 4.836, Average Loss: 4.445, avg. samples / sec: 66546.70
Iteration:   1740, Loss function: 6.178, Average Loss: 4.472, avg. samples / sec: 66476.36
Iteration:   1740, Loss function: 4.203, Average Loss: 4.460, avg. samples / sec: 66590.88
Iteration:   1740, Loss function: 3.707, Average Loss: 4.479, avg. samples / sec: 66507.42
Iteration:   1740, Loss function: 3.935, Average Loss: 4.472, avg. samples / sec: 66460.90
Iteration:   1740, Loss function: 4.185, Average Loss: 4.448, avg. samples / sec: 66506.69
Iteration:   1740, Loss function: 4.023, Average Loss: 4.472, avg. samples / sec: 66502.90
Iteration:   1740, Loss function: 3.495, Average Loss: 4.462, avg. samples / sec: 66434.93
Iteration:   1740, Loss function: 4.694, Average Loss: 4.443, avg. samples / sec: 66558.80
Iteration:   1740, Loss function: 3.825, Average Loss: 4.474, avg. samples / sec: 66414.33
Iteration:   1740, Loss function: 4.897, Average Loss: 4.457, avg. samples / sec: 66457.23
Iteration:   1740, Loss function: 5.441, Average Loss: 4.441, avg. samples / sec: 66258.02
Iteration:   1740, Loss function: 4.191, Average Loss: 4.454, avg. samples / sec: 66454.63
Iteration:   1740, Loss function: 4.766, Average Loss: 4.477, avg. samples / sec: 66571.51
Iteration:   1740, Loss function: 6.081, Average Loss: 4.467, avg. samples / sec: 66308.93
Iteration:   1740, Loss function: 4.757, Average Loss: 4.447, avg. samples / sec: 66372.35
Iteration:   1740, Loss function: 5.642, Average Loss: 4.447, avg. samples / sec: 66492.57
Iteration:   1740, Loss function: 5.749, Average Loss: 4.445, avg. samples / sec: 66469.96
Iteration:   1740, Loss function: 5.842, Average Loss: 4.459, avg. samples / sec: 66460.81
Iteration:   1740, Loss function: 5.342, Average Loss: 4.454, avg. samples / sec: 66444.58
Iteration:   1740, Loss function: 3.750, Average Loss: 4.430, avg. samples / sec: 66304.12
Iteration:   1740, Loss function: 5.038, Average Loss: 4.467, avg. samples / sec: 66351.85
Iteration:   1740, Loss function: 3.688, Average Loss: 4.476, avg. samples / sec: 66343.36
Iteration:   1740, Loss function: 4.521, Average Loss: 4.457, avg. samples / sec: 66387.92
:::MLL 1558651401.827 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558651401.828 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 5.243, Average Loss: 4.469, avg. samples / sec: 66040.58
Iteration:   1760, Loss function: 5.030, Average Loss: 4.452, avg. samples / sec: 65959.97
Iteration:   1760, Loss function: 4.562, Average Loss: 4.474, avg. samples / sec: 65968.12
Iteration:   1760, Loss function: 5.179, Average Loss: 4.445, avg. samples / sec: 65935.59
Iteration:   1760, Loss function: 4.777, Average Loss: 4.458, avg. samples / sec: 66041.91
Iteration:   1760, Loss function: 4.687, Average Loss: 4.457, avg. samples / sec: 65985.76
Iteration:   1760, Loss function: 3.054, Average Loss: 4.468, avg. samples / sec: 65982.33
Iteration:   1760, Loss function: 4.698, Average Loss: 4.461, avg. samples / sec: 66111.18
Iteration:   1760, Loss function: 4.202, Average Loss: 4.438, avg. samples / sec: 66014.90
Iteration:   1760, Loss function: 4.544, Average Loss: 4.441, avg. samples / sec: 66008.41
Iteration:   1760, Loss function: 4.139, Average Loss: 4.442, avg. samples / sec: 66043.09
Iteration:   1760, Loss function: 4.130, Average Loss: 4.468, avg. samples / sec: 65977.32
Iteration:   1760, Loss function: 4.608, Average Loss: 4.432, avg. samples / sec: 66073.31
Iteration:   1760, Loss function: 5.873, Average Loss: 4.447, avg. samples / sec: 66013.33
Iteration:   1760, Loss function: 3.847, Average Loss: 4.477, avg. samples / sec: 66010.76
Iteration:   1760, Loss function: 4.397, Average Loss: 4.471, avg. samples / sec: 65928.96
Iteration:   1760, Loss function: 4.440, Average Loss: 4.454, avg. samples / sec: 65919.46
Iteration:   1760, Loss function: 4.230, Average Loss: 4.472, avg. samples / sec: 65970.40
Iteration:   1760, Loss function: 4.713, Average Loss: 4.471, avg. samples / sec: 65975.90
Iteration:   1760, Loss function: 4.680, Average Loss: 4.479, avg. samples / sec: 66032.84
Iteration:   1760, Loss function: 4.581, Average Loss: 4.459, avg. samples / sec: 65991.66
Iteration:   1760, Loss function: 4.842, Average Loss: 4.448, avg. samples / sec: 65980.13
Iteration:   1760, Loss function: 3.606, Average Loss: 4.462, avg. samples / sec: 65969.32
Iteration:   1760, Loss function: 3.807, Average Loss: 4.454, avg. samples / sec: 65997.44
Iteration:   1760, Loss function: 4.977, Average Loss: 4.452, avg. samples / sec: 66055.44
Iteration:   1760, Loss function: 4.056, Average Loss: 4.455, avg. samples / sec: 65923.40
Iteration:   1760, Loss function: 5.259, Average Loss: 4.457, avg. samples / sec: 65809.63
Iteration:   1760, Loss function: 4.428, Average Loss: 4.448, avg. samples / sec: 65885.83
Iteration:   1760, Loss function: 4.130, Average Loss: 4.447, avg. samples / sec: 65936.36
Iteration:   1760, Loss function: 4.019, Average Loss: 4.446, avg. samples / sec: 65825.61
Iteration:   1780, Loss function: 4.552, Average Loss: 4.455, avg. samples / sec: 66700.97
Iteration:   1780, Loss function: 3.589, Average Loss: 4.472, avg. samples / sec: 66635.18
Iteration:   1780, Loss function: 4.583, Average Loss: 4.457, avg. samples / sec: 66616.50
Iteration:   1780, Loss function: 4.294, Average Loss: 4.470, avg. samples / sec: 66542.43
Iteration:   1780, Loss function: 5.138, Average Loss: 4.469, avg. samples / sec: 66673.23
Iteration:   1780, Loss function: 3.438, Average Loss: 4.462, avg. samples / sec: 66776.03
Iteration:   1780, Loss function: 5.261, Average Loss: 4.431, avg. samples / sec: 66676.17
Iteration:   1780, Loss function: 4.642, Average Loss: 4.474, avg. samples / sec: 66701.45
Iteration:   1780, Loss function: 4.271, Average Loss: 4.471, avg. samples / sec: 66626.46
Iteration:   1780, Loss function: 4.653, Average Loss: 4.456, avg. samples / sec: 66726.90
Iteration:   1780, Loss function: 3.312, Average Loss: 4.444, avg. samples / sec: 66763.76
Iteration:   1780, Loss function: 4.832, Average Loss: 4.443, avg. samples / sec: 66600.54
Iteration:   1780, Loss function: 5.541, Average Loss: 4.473, avg. samples / sec: 66658.70
Iteration:   1780, Loss function: 3.902, Average Loss: 4.448, avg. samples / sec: 66676.67
Iteration:   1780, Loss function: 4.815, Average Loss: 4.461, avg. samples / sec: 66584.18
Iteration:   1780, Loss function: 4.972, Average Loss: 4.460, avg. samples / sec: 66659.07
Iteration:   1780, Loss function: 4.413, Average Loss: 4.448, avg. samples / sec: 66707.57
Iteration:   1780, Loss function: 3.349, Average Loss: 4.458, avg. samples / sec: 66677.21
Iteration:   1780, Loss function: 3.649, Average Loss: 4.445, avg. samples / sec: 66691.66
Iteration:   1780, Loss function: 4.949, Average Loss: 4.441, avg. samples / sec: 66599.98
Iteration:   1780, Loss function: 4.323, Average Loss: 4.476, avg. samples / sec: 66628.16
Iteration:   1780, Loss function: 4.373, Average Loss: 4.445, avg. samples / sec: 66516.61
Iteration:   1780, Loss function: 3.843, Average Loss: 4.453, avg. samples / sec: 66651.95
Iteration:   1780, Loss function: 5.438, Average Loss: 4.456, avg. samples / sec: 66510.96
Iteration:   1780, Loss function: 4.444, Average Loss: 4.468, avg. samples / sec: 66584.68
Iteration:   1780, Loss function: 3.974, Average Loss: 4.456, avg. samples / sec: 66575.81
Iteration:   1780, Loss function: 3.968, Average Loss: 4.449, avg. samples / sec: 66599.91
Iteration:   1780, Loss function: 3.915, Average Loss: 4.432, avg. samples / sec: 66519.28
Iteration:   1780, Loss function: 4.207, Average Loss: 4.444, avg. samples / sec: 66538.91
Iteration:   1780, Loss function: 4.282, Average Loss: 4.478, avg. samples / sec: 66508.23
Iteration:   1800, Loss function: 3.689, Average Loss: 4.460, avg. samples / sec: 66279.02
Iteration:   1800, Loss function: 3.910, Average Loss: 4.466, avg. samples / sec: 66404.75
Iteration:   1800, Loss function: 5.059, Average Loss: 4.469, avg. samples / sec: 66289.46
Iteration:   1800, Loss function: 4.941, Average Loss: 4.454, avg. samples / sec: 66192.13
Iteration:   1800, Loss function: 4.145, Average Loss: 4.475, avg. samples / sec: 66217.86
Iteration:   1800, Loss function: 5.065, Average Loss: 4.453, avg. samples / sec: 66343.14
Iteration:   1800, Loss function: 3.891, Average Loss: 4.478, avg. samples / sec: 66225.26
Iteration:   1800, Loss function: 4.033, Average Loss: 4.454, avg. samples / sec: 66324.37
Iteration:   1800, Loss function: 4.227, Average Loss: 4.456, avg. samples / sec: 66263.62
Iteration:   1800, Loss function: 3.935, Average Loss: 4.466, avg. samples / sec: 66189.83
Iteration:   1800, Loss function: 4.145, Average Loss: 4.465, avg. samples / sec: 66193.56
Iteration:   1800, Loss function: 4.795, Average Loss: 4.442, avg. samples / sec: 66249.79
Iteration:   1800, Loss function: 3.612, Average Loss: 4.464, avg. samples / sec: 66205.63
Iteration:   1800, Loss function: 4.259, Average Loss: 4.445, avg. samples / sec: 66265.31
Iteration:   1800, Loss function: 4.272, Average Loss: 4.452, avg. samples / sec: 66292.89
Iteration:   1800, Loss function: 4.688, Average Loss: 4.449, avg. samples / sec: 66229.96
Iteration:   1800, Loss function: 4.084, Average Loss: 4.479, avg. samples / sec: 66368.29
Iteration:   1800, Loss function: 3.177, Average Loss: 4.452, avg. samples / sec: 66297.76
Iteration:   1800, Loss function: 3.877, Average Loss: 4.441, avg. samples / sec: 66202.99
Iteration:   1800, Loss function: 3.296, Average Loss: 4.458, avg. samples / sec: 66222.46
Iteration:   1800, Loss function: 4.841, Average Loss: 4.433, avg. samples / sec: 66293.61
Iteration:   1800, Loss function: 3.129, Average Loss: 4.450, avg. samples / sec: 66187.91
Iteration:   1800, Loss function: 3.947, Average Loss: 4.428, avg. samples / sec: 66151.28
Iteration:   1800, Loss function: 4.046, Average Loss: 4.459, avg. samples / sec: 66217.67
Iteration:   1800, Loss function: 4.019, Average Loss: 4.442, avg. samples / sec: 66305.65
Iteration:   1800, Loss function: 4.351, Average Loss: 4.440, avg. samples / sec: 66218.51
Iteration:   1800, Loss function: 3.634, Average Loss: 4.468, avg. samples / sec: 66205.41
Iteration:   1800, Loss function: 3.423, Average Loss: 4.472, avg. samples / sec: 66151.53
Iteration:   1800, Loss function: 2.909, Average Loss: 4.447, avg. samples / sec: 66154.07
Iteration:   1800, Loss function: 3.883, Average Loss: 4.446, avg. samples / sec: 66078.54
:::MLL 1558651403.601 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558651403.602 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 3.853, Average Loss: 4.461, avg. samples / sec: 66144.69
Iteration:   1820, Loss function: 3.905, Average Loss: 4.462, avg. samples / sec: 66276.93
Iteration:   1820, Loss function: 4.404, Average Loss: 4.476, avg. samples / sec: 66226.44
Iteration:   1820, Loss function: 4.888, Average Loss: 4.456, avg. samples / sec: 66237.81
Iteration:   1820, Loss function: 3.849, Average Loss: 4.463, avg. samples / sec: 66074.64
Iteration:   1820, Loss function: 4.572, Average Loss: 4.428, avg. samples / sec: 66224.70
Iteration:   1820, Loss function: 5.226, Average Loss: 4.453, avg. samples / sec: 66108.42
Iteration:   1820, Loss function: 4.619, Average Loss: 4.462, avg. samples / sec: 66167.27
Iteration:   1820, Loss function: 5.245, Average Loss: 4.478, avg. samples / sec: 66142.30
Iteration:   1820, Loss function: 4.408, Average Loss: 4.454, avg. samples / sec: 66149.41
Iteration:   1820, Loss function: 4.395, Average Loss: 4.447, avg. samples / sec: 66168.27
Iteration:   1820, Loss function: 5.025, Average Loss: 4.461, avg. samples / sec: 66141.50
Iteration:   1820, Loss function: 3.173, Average Loss: 4.466, avg. samples / sec: 66068.23
Iteration:   1820, Loss function: 4.353, Average Loss: 4.437, avg. samples / sec: 66161.49
Iteration:   1820, Loss function: 4.100, Average Loss: 4.455, avg. samples / sec: 65984.30
Iteration:   1820, Loss function: 4.012, Average Loss: 4.438, avg. samples / sec: 66126.32
Iteration:   1820, Loss function: 5.029, Average Loss: 4.445, avg. samples / sec: 66115.56
Iteration:   1820, Loss function: 5.478, Average Loss: 4.455, avg. samples / sec: 66034.02
Iteration:   1820, Loss function: 4.810, Average Loss: 4.466, avg. samples / sec: 66091.87
Iteration:   1820, Loss function: 3.249, Average Loss: 4.438, avg. samples / sec: 66103.96
Iteration:   1820, Loss function: 5.532, Average Loss: 4.444, avg. samples / sec: 66226.38
Iteration:   1820, Loss function: 6.150, Average Loss: 4.451, avg. samples / sec: 66079.22
Iteration:   1820, Loss function: 4.920, Average Loss: 4.453, avg. samples / sec: 66033.68
Iteration:   1820, Loss function: 3.508, Average Loss: 4.468, avg. samples / sec: 66122.26
Iteration:   1820, Loss function: 3.666, Average Loss: 4.448, avg. samples / sec: 66058.60
Iteration:   1820, Loss function: 4.090, Average Loss: 4.429, avg. samples / sec: 66073.03
Iteration:   1820, Loss function: 4.393, Average Loss: 4.439, avg. samples / sec: 66148.82
Iteration:   1820, Loss function: 4.229, Average Loss: 4.445, avg. samples / sec: 66024.99
Iteration:   1820, Loss function: 3.842, Average Loss: 4.455, avg. samples / sec: 66039.59
Iteration:   1820, Loss function: 4.161, Average Loss: 4.435, avg. samples / sec: 66036.62
Iteration:   1840, Loss function: 4.271, Average Loss: 4.465, avg. samples / sec: 66255.28
Iteration:   1840, Loss function: 4.495, Average Loss: 4.458, avg. samples / sec: 66214.03
Iteration:   1840, Loss function: 4.550, Average Loss: 4.449, avg. samples / sec: 66138.58
Iteration:   1840, Loss function: 4.675, Average Loss: 4.459, avg. samples / sec: 66100.42
Iteration:   1840, Loss function: 3.840, Average Loss: 4.422, avg. samples / sec: 66127.97
Iteration:   1840, Loss function: 2.897, Average Loss: 4.450, avg. samples / sec: 66234.35
Iteration:   1840, Loss function: 4.273, Average Loss: 4.435, avg. samples / sec: 66220.50
Iteration:   1840, Loss function: 4.300, Average Loss: 4.439, avg. samples / sec: 66268.27
Iteration:   1840, Loss function: 4.537, Average Loss: 4.451, avg. samples / sec: 66263.00
Iteration:   1840, Loss function: 4.249, Average Loss: 4.469, avg. samples / sec: 66120.83
Iteration:   1840, Loss function: 5.461, Average Loss: 4.462, avg. samples / sec: 66090.97
Iteration:   1840, Loss function: 4.008, Average Loss: 4.444, avg. samples / sec: 66102.16
Iteration:   1840, Loss function: 4.328, Average Loss: 4.459, avg. samples / sec: 65998.80
Iteration:   1840, Loss function: 4.181, Average Loss: 4.441, avg. samples / sec: 66207.22
Iteration:   1840, Loss function: 3.791, Average Loss: 4.452, avg. samples / sec: 66129.11
Iteration:   1840, Loss function: 4.411, Average Loss: 4.443, avg. samples / sec: 66110.94
Iteration:   1840, Loss function: 4.655, Average Loss: 4.453, avg. samples / sec: 66166.43
Iteration:   1840, Loss function: 4.317, Average Loss: 4.441, avg. samples / sec: 66093.01
Iteration:   1840, Loss function: 4.335, Average Loss: 4.459, avg. samples / sec: 66048.04
Iteration:   1840, Loss function: 4.505, Average Loss: 4.460, avg. samples / sec: 66022.76
Iteration:   1840, Loss function: 4.853, Average Loss: 4.463, avg. samples / sec: 66138.55
Iteration:   1840, Loss function: 4.716, Average Loss: 4.450, avg. samples / sec: 66001.98
Iteration:   1840, Loss function: 6.050, Average Loss: 4.438, avg. samples / sec: 66140.07
Iteration:   1840, Loss function: 4.511, Average Loss: 4.431, avg. samples / sec: 66074.33
Iteration:   1840, Loss function: 5.071, Average Loss: 4.430, avg. samples / sec: 66166.09
Iteration:   1840, Loss function: 3.935, Average Loss: 4.450, avg. samples / sec: 66011.35
Iteration:   1840, Loss function: 4.410, Average Loss: 4.472, avg. samples / sec: 65985.04
Iteration:   1840, Loss function: 5.727, Average Loss: 4.426, avg. samples / sec: 66083.31
Iteration:   1840, Loss function: 4.444, Average Loss: 4.441, avg. samples / sec: 66043.98
Iteration:   1840, Loss function: 3.604, Average Loss: 4.470, avg. samples / sec: 65871.76
Iteration:   1860, Loss function: 5.406, Average Loss: 4.467, avg. samples / sec: 66552.27
Iteration:   1860, Loss function: 3.807, Average Loss: 4.443, avg. samples / sec: 66688.79
Iteration:   1860, Loss function: 4.154, Average Loss: 4.458, avg. samples / sec: 66600.92
Iteration:   1860, Loss function: 4.241, Average Loss: 4.465, avg. samples / sec: 66622.80
Iteration:   1860, Loss function: 3.158, Average Loss: 4.449, avg. samples / sec: 66569.30
Iteration:   1860, Loss function: 3.797, Average Loss: 4.442, avg. samples / sec: 66498.63
Iteration:   1860, Loss function: 5.093, Average Loss: 4.452, avg. samples / sec: 66486.39
Iteration:   1860, Loss function: 2.793, Average Loss: 4.422, avg. samples / sec: 66605.17
Iteration:   1860, Loss function: 4.512, Average Loss: 4.461, avg. samples / sec: 66340.45
Iteration:   1860, Loss function: 4.709, Average Loss: 4.453, avg. samples / sec: 66474.44
Iteration:   1860, Loss function: 4.810, Average Loss: 4.457, avg. samples / sec: 66335.71
Iteration:   1860, Loss function: 4.664, Average Loss: 4.453, avg. samples / sec: 66492.70
Iteration:   1860, Loss function: 4.299, Average Loss: 4.419, avg. samples / sec: 66379.95
Iteration:   1860, Loss function: 4.993, Average Loss: 4.450, avg. samples / sec: 66462.72
Iteration:   1860, Loss function: 3.009, Average Loss: 4.431, avg. samples / sec: 66508.07
Iteration:   1860, Loss function: 3.530, Average Loss: 4.467, avg. samples / sec: 66607.06
Iteration:   1860, Loss function: 3.080, Average Loss: 4.455, avg. samples / sec: 66344.14
Iteration:   1860, Loss function: 4.683, Average Loss: 4.426, avg. samples / sec: 66494.42
Iteration:   1860, Loss function: 4.754, Average Loss: 4.461, avg. samples / sec: 66468.33
Iteration:   1860, Loss function: 5.314, Average Loss: 4.440, avg. samples / sec: 66312.17
Iteration:   1860, Loss function: 4.376, Average Loss: 4.444, avg. samples / sec: 66361.57
Iteration:   1860, Loss function: 5.376, Average Loss: 4.427, avg. samples / sec: 66458.43
Iteration:   1860, Loss function: 4.595, Average Loss: 4.456, avg. samples / sec: 66376.70
Iteration:   1860, Loss function: 4.584, Average Loss: 4.440, avg. samples / sec: 66342.98
Iteration:   1860, Loss function: 2.902, Average Loss: 4.444, avg. samples / sec: 66334.74
Iteration:   1860, Loss function: 4.979, Average Loss: 4.446, avg. samples / sec: 66393.40
Iteration:   1860, Loss function: 4.791, Average Loss: 4.448, avg. samples / sec: 66413.80
Iteration:   1860, Loss function: 5.302, Average Loss: 4.443, avg. samples / sec: 66385.20
Iteration:   1860, Loss function: 5.510, Average Loss: 4.435, avg. samples / sec: 66334.83
Iteration:   1860, Loss function: 3.237, Average Loss: 4.433, avg. samples / sec: 66278.55
Iteration:   1880, Loss function: 4.153, Average Loss: 4.455, avg. samples / sec: 66718.81
Iteration:   1880, Loss function: 4.648, Average Loss: 4.447, avg. samples / sec: 66660.37
Iteration:   1880, Loss function: 5.683, Average Loss: 4.458, avg. samples / sec: 66589.97
Iteration:   1880, Loss function: 4.478, Average Loss: 4.442, avg. samples / sec: 66580.34
Iteration:   1880, Loss function: 3.822, Average Loss: 4.417, avg. samples / sec: 66646.78
Iteration:   1880, Loss function: 4.992, Average Loss: 4.429, avg. samples / sec: 66695.98
Iteration:   1880, Loss function: 4.802, Average Loss: 4.443, avg. samples / sec: 66674.56
Iteration:   1880, Loss function: 5.453, Average Loss: 4.452, avg. samples / sec: 66634.80
Iteration:   1880, Loss function: 5.250, Average Loss: 4.450, avg. samples / sec: 66546.36
Iteration:   1880, Loss function: 4.196, Average Loss: 4.440, avg. samples / sec: 66619.40
Iteration:   1880, Loss function: 3.686, Average Loss: 4.421, avg. samples / sec: 66506.82
Iteration:   1880, Loss function: 4.073, Average Loss: 4.430, avg. samples / sec: 66645.17
Iteration:   1880, Loss function: 5.905, Average Loss: 4.463, avg. samples / sec: 66443.42
Iteration:   1880, Loss function: 4.648, Average Loss: 4.464, avg. samples / sec: 66391.64
Iteration:   1880, Loss function: 3.329, Average Loss: 4.439, avg. samples / sec: 66596.33
Iteration:   1880, Loss function: 4.218, Average Loss: 4.444, avg. samples / sec: 66566.69
Iteration:   1880, Loss function: 3.519, Average Loss: 4.436, avg. samples / sec: 66460.34
Iteration:   1880, Loss function: 4.748, Average Loss: 4.443, avg. samples / sec: 66570.31
Iteration:   1880, Loss function: 3.245, Average Loss: 4.445, avg. samples / sec: 66516.99
Iteration:   1880, Loss function: 5.246, Average Loss: 4.455, avg. samples / sec: 66473.85
Iteration:   1880, Loss function: 3.880, Average Loss: 4.436, avg. samples / sec: 66388.58
Iteration:   1880, Loss function: 3.421, Average Loss: 4.439, avg. samples / sec: 66539.26
Iteration:   1880, Loss function: 6.119, Average Loss: 4.447, avg. samples / sec: 66493.42
Iteration:   1880, Loss function: 3.594, Average Loss: 4.429, avg. samples / sec: 66476.45
Iteration:   1880, Loss function: 3.946, Average Loss: 4.457, avg. samples / sec: 66489.50
Iteration:   1880, Loss function: 3.914, Average Loss: 4.456, avg. samples / sec: 66484.76
Iteration:   1880, Loss function: 3.881, Average Loss: 4.420, avg. samples / sec: 66467.52
Iteration:   1880, Loss function: 4.284, Average Loss: 4.449, avg. samples / sec: 66418.62
Iteration:   1880, Loss function: 4.377, Average Loss: 4.433, avg. samples / sec: 66550.47
Iteration:   1880, Loss function: 4.597, Average Loss: 4.442, avg. samples / sec: 66517.46
:::MLL 1558651405.375 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558651405.375 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 4.045, Average Loss: 4.453, avg. samples / sec: 66110.78
Iteration:   1900, Loss function: 4.218, Average Loss: 4.443, avg. samples / sec: 66338.55
Iteration:   1900, Loss function: 4.965, Average Loss: 4.446, avg. samples / sec: 66044.01
Iteration:   1900, Loss function: 3.758, Average Loss: 4.415, avg. samples / sec: 66121.14
Iteration:   1900, Loss function: 3.807, Average Loss: 4.445, avg. samples / sec: 66167.12
Iteration:   1900, Loss function: 4.432, Average Loss: 4.448, avg. samples / sec: 66031.20
Iteration:   1900, Loss function: 3.428, Average Loss: 4.432, avg. samples / sec: 66234.23
Iteration:   1900, Loss function: 3.732, Average Loss: 4.437, avg. samples / sec: 66211.32
Iteration:   1900, Loss function: 4.596, Average Loss: 4.444, avg. samples / sec: 66145.38
Iteration:   1900, Loss function: 3.946, Average Loss: 4.429, avg. samples / sec: 66170.85
Iteration:   1900, Loss function: 3.633, Average Loss: 4.446, avg. samples / sec: 66208.09
Iteration:   1900, Loss function: 3.953, Average Loss: 4.441, avg. samples / sec: 66192.76
Iteration:   1900, Loss function: 4.951, Average Loss: 4.433, avg. samples / sec: 66134.64
Iteration:   1900, Loss function: 3.772, Average Loss: 4.448, avg. samples / sec: 66122.32
Iteration:   1900, Loss function: 4.044, Average Loss: 4.435, avg. samples / sec: 66154.04
Iteration:   1900, Loss function: 3.840, Average Loss: 4.448, avg. samples / sec: 66167.43
Iteration:   1900, Loss function: 4.444, Average Loss: 4.446, avg. samples / sec: 66018.21
Iteration:   1900, Loss function: 3.854, Average Loss: 4.439, avg. samples / sec: 66161.65
Iteration:   1900, Loss function: 5.132, Average Loss: 4.431, avg. samples / sec: 66162.27
Iteration:   1900, Loss function: 3.024, Average Loss: 4.461, avg. samples / sec: 66108.98
Iteration:   1900, Loss function: 4.272, Average Loss: 4.455, avg. samples / sec: 66189.24
Iteration:   1900, Loss function: 3.830, Average Loss: 4.416, avg. samples / sec: 66081.14
Iteration:   1900, Loss function: 5.374, Average Loss: 4.425, avg. samples / sec: 66193.53
Iteration:   1900, Loss function: 4.306, Average Loss: 4.422, avg. samples / sec: 65971.21
Iteration:   1900, Loss function: 3.220, Average Loss: 4.441, avg. samples / sec: 66115.93
Iteration:   1900, Loss function: 5.447, Average Loss: 4.458, avg. samples / sec: 66095.22
Iteration:   1900, Loss function: 3.190, Average Loss: 4.456, avg. samples / sec: 66119.31
Iteration:   1900, Loss function: 4.049, Average Loss: 4.434, avg. samples / sec: 66132.65
Iteration:   1900, Loss function: 3.202, Average Loss: 4.422, avg. samples / sec: 66022.11
Iteration:   1900, Loss function: 4.086, Average Loss: 4.411, avg. samples / sec: 66047.42
Iteration:   1920, Loss function: 4.682, Average Loss: 4.440, avg. samples / sec: 66543.97
Iteration:   1920, Loss function: 4.376, Average Loss: 4.412, avg. samples / sec: 66476.45
Iteration:   1920, Loss function: 4.434, Average Loss: 4.441, avg. samples / sec: 66547.08
Iteration:   1920, Loss function: 4.395, Average Loss: 4.438, avg. samples / sec: 66609.89
Iteration:   1920, Loss function: 5.495, Average Loss: 4.444, avg. samples / sec: 66546.39
Iteration:   1920, Loss function: 3.464, Average Loss: 4.430, avg. samples / sec: 66526.16
Iteration:   1920, Loss function: 3.573, Average Loss: 4.452, avg. samples / sec: 66384.92
Iteration:   1920, Loss function: 5.371, Average Loss: 4.406, avg. samples / sec: 66703.75
Iteration:   1920, Loss function: 5.382, Average Loss: 4.429, avg. samples / sec: 66449.75
Iteration:   1920, Loss function: 3.910, Average Loss: 4.446, avg. samples / sec: 66418.46
Iteration:   1920, Loss function: 4.882, Average Loss: 4.444, avg. samples / sec: 66436.93
Iteration:   1920, Loss function: 3.929, Average Loss: 4.423, avg. samples / sec: 66550.51
Iteration:   1920, Loss function: 3.318, Average Loss: 4.439, avg. samples / sec: 66425.38
Iteration:   1920, Loss function: 3.603, Average Loss: 4.421, avg. samples / sec: 66602.72
Iteration:   1920, Loss function: 3.419, Average Loss: 4.439, avg. samples / sec: 66427.91
Iteration:   1920, Loss function: 4.154, Average Loss: 4.438, avg. samples / sec: 66421.12
Iteration:   1920, Loss function: 3.222, Average Loss: 4.442, avg. samples / sec: 66435.15
Iteration:   1920, Loss function: 5.760, Average Loss: 4.433, avg. samples / sec: 66480.09
Iteration:   1920, Loss function: 4.001, Average Loss: 4.447, avg. samples / sec: 66425.97
Iteration:   1920, Loss function: 5.162, Average Loss: 4.455, avg. samples / sec: 66468.08
Iteration:   1920, Loss function: 4.025, Average Loss: 4.428, avg. samples / sec: 66544.31
Iteration:   1920, Loss function: 4.253, Average Loss: 4.418, avg. samples / sec: 66460.09
Iteration:   1920, Loss function: 5.916, Average Loss: 4.418, avg. samples / sec: 66474.76
Iteration:   1920, Loss function: 4.942, Average Loss: 4.433, avg. samples / sec: 66407.38
Iteration:   1920, Loss function: 3.856, Average Loss: 4.457, avg. samples / sec: 66443.86
Iteration:   1920, Loss function: 3.751, Average Loss: 4.440, avg. samples / sec: 66379.14
Iteration:   1920, Loss function: 4.509, Average Loss: 4.433, avg. samples / sec: 66390.99
Iteration:   1920, Loss function: 4.042, Average Loss: 4.421, avg. samples / sec: 66324.47
Iteration:   1920, Loss function: 4.662, Average Loss: 4.454, avg. samples / sec: 66438.97
Iteration:   1920, Loss function: 4.073, Average Loss: 4.456, avg. samples / sec: 66279.36
Iteration:   1940, Loss function: 4.079, Average Loss: 4.452, avg. samples / sec: 66889.69
Iteration:   1940, Loss function: 4.302, Average Loss: 4.427, avg. samples / sec: 66712.65
Iteration:   1940, Loss function: 4.272, Average Loss: 4.445, avg. samples / sec: 66528.76
Iteration:   1940, Loss function: 3.953, Average Loss: 4.403, avg. samples / sec: 66548.02
Iteration:   1940, Loss function: 3.587, Average Loss: 4.437, avg. samples / sec: 66397.81
Iteration:   1940, Loss function: 5.073, Average Loss: 4.457, avg. samples / sec: 66644.98
Iteration:   1940, Loss function: 3.549, Average Loss: 4.442, avg. samples / sec: 66609.04
Iteration:   1940, Loss function: 5.235, Average Loss: 4.451, avg. samples / sec: 66503.90
Iteration:   1940, Loss function: 3.176, Average Loss: 4.443, avg. samples / sec: 66504.28
Iteration:   1940, Loss function: 4.859, Average Loss: 4.421, avg. samples / sec: 66507.95
Iteration:   1940, Loss function: 5.256, Average Loss: 4.413, avg. samples / sec: 66426.85
Iteration:   1940, Loss function: 4.065, Average Loss: 4.438, avg. samples / sec: 66435.56
Iteration:   1940, Loss function: 4.676, Average Loss: 4.444, avg. samples / sec: 66473.41
Iteration:   1940, Loss function: 4.679, Average Loss: 4.419, avg. samples / sec: 66557.92
Iteration:   1940, Loss function: 3.963, Average Loss: 4.433, avg. samples / sec: 66462.19
Iteration:   1940, Loss function: 4.396, Average Loss: 4.445, avg. samples / sec: 66393.80
Iteration:   1940, Loss function: 4.761, Average Loss: 4.429, avg. samples / sec: 66562.89
Iteration:   1940, Loss function: 4.474, Average Loss: 4.418, avg. samples / sec: 66452.72
Iteration:   1940, Loss function: 4.496, Average Loss: 4.432, avg. samples / sec: 66511.59
Iteration:   1940, Loss function: 4.289, Average Loss: 4.439, avg. samples / sec: 66450.34
Iteration:   1940, Loss function: 5.370, Average Loss: 4.457, avg. samples / sec: 66591.95
Iteration:   1940, Loss function: 3.855, Average Loss: 4.432, avg. samples / sec: 66388.92
Iteration:   1940, Loss function: 5.372, Average Loss: 4.438, avg. samples / sec: 66478.74
Iteration:   1940, Loss function: 3.259, Average Loss: 4.438, avg. samples / sec: 66464.69
Iteration:   1940, Loss function: 4.047, Average Loss: 4.416, avg. samples / sec: 66565.28
Iteration:   1940, Loss function: 2.824, Average Loss: 4.451, avg. samples / sec: 66479.37
Iteration:   1940, Loss function: 3.927, Average Loss: 4.433, avg. samples / sec: 66500.42
Iteration:   1940, Loss function: 5.830, Average Loss: 4.422, avg. samples / sec: 66472.63
Iteration:   1940, Loss function: 4.978, Average Loss: 4.445, avg. samples / sec: 66369.23
Iteration:   1940, Loss function: 3.675, Average Loss: 4.427, avg. samples / sec: 66383.42
:::MLL 1558651407.146 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558651407.147 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 3.545, Average Loss: 4.411, avg. samples / sec: 66428.57
Iteration:   1960, Loss function: 3.631, Average Loss: 4.439, avg. samples / sec: 66369.70
Iteration:   1960, Loss function: 4.833, Average Loss: 4.446, avg. samples / sec: 66542.30
Iteration:   1960, Loss function: 5.017, Average Loss: 4.451, avg. samples / sec: 66220.50
Iteration:   1960, Loss function: 4.582, Average Loss: 4.438, avg. samples / sec: 66298.76
Iteration:   1960, Loss function: 4.069, Average Loss: 4.451, avg. samples / sec: 66305.59
Iteration:   1960, Loss function: 3.722, Average Loss: 4.441, avg. samples / sec: 66296.32
Iteration:   1960, Loss function: 4.944, Average Loss: 4.435, avg. samples / sec: 66311.95
Iteration:   1960, Loss function: 4.843, Average Loss: 4.436, avg. samples / sec: 66208.83
Iteration:   1960, Loss function: 4.111, Average Loss: 4.443, avg. samples / sec: 66320.38
Iteration:   1960, Loss function: 3.607, Average Loss: 4.423, avg. samples / sec: 66323.87
Iteration:   1960, Loss function: 4.897, Average Loss: 4.439, avg. samples / sec: 66274.37
Iteration:   1960, Loss function: 3.741, Average Loss: 4.429, avg. samples / sec: 66285.10
Iteration:   1960, Loss function: 3.957, Average Loss: 4.440, avg. samples / sec: 66318.72
Iteration:   1960, Loss function: 4.210, Average Loss: 4.418, avg. samples / sec: 66261.72
Iteration:   1960, Loss function: 4.689, Average Loss: 4.413, avg. samples / sec: 66315.92
Iteration:   1960, Loss function: 5.150, Average Loss: 4.438, avg. samples / sec: 66271.45
Iteration:   1960, Loss function: 4.446, Average Loss: 4.444, avg. samples / sec: 66185.64
Iteration:   1960, Loss function: 5.766, Average Loss: 4.458, avg. samples / sec: 66277.65
Iteration:   1960, Loss function: 3.741, Average Loss: 4.430, avg. samples / sec: 66301.88
Iteration:   1960, Loss function: 5.226, Average Loss: 4.397, avg. samples / sec: 66142.03
Iteration:   1960, Loss function: 5.491, Average Loss: 4.434, avg. samples / sec: 66276.34
Iteration:   1960, Loss function: 3.744, Average Loss: 4.444, avg. samples / sec: 66261.44
Iteration:   1960, Loss function: 3.793, Average Loss: 4.416, avg. samples / sec: 66167.33
Iteration:   1960, Loss function: 5.429, Average Loss: 4.429, avg. samples / sec: 66209.36
Iteration:   1960, Loss function: 4.458, Average Loss: 4.422, avg. samples / sec: 66029.19
Iteration:   1960, Loss function: 4.275, Average Loss: 4.417, avg. samples / sec: 66172.55
Iteration:   1960, Loss function: 3.704, Average Loss: 4.412, avg. samples / sec: 66212.16
Iteration:   1960, Loss function: 4.340, Average Loss: 4.423, avg. samples / sec: 66278.49
Iteration:   1960, Loss function: 4.053, Average Loss: 4.425, avg. samples / sec: 66135.88
Iteration:   1980, Loss function: 4.885, Average Loss: 4.438, avg. samples / sec: 66428.89
Iteration:   1980, Loss function: 3.803, Average Loss: 4.406, avg. samples / sec: 66160.47
Iteration:   1980, Loss function: 3.166, Average Loss: 4.430, avg. samples / sec: 66326.68
Iteration:   1980, Loss function: 4.598, Average Loss: 4.438, avg. samples / sec: 66206.38
Iteration:   1980, Loss function: 5.004, Average Loss: 4.436, avg. samples / sec: 66293.49
Iteration:   1980, Loss function: 4.613, Average Loss: 4.435, avg. samples / sec: 66238.80
Iteration:   1980, Loss function: 3.776, Average Loss: 4.432, avg. samples / sec: 66338.42
Iteration:   1980, Loss function: 4.400, Average Loss: 4.427, avg. samples / sec: 66330.71
Iteration:   1980, Loss function: 4.434, Average Loss: 4.437, avg. samples / sec: 66123.87
Iteration:   1980, Loss function: 3.801, Average Loss: 4.419, avg. samples / sec: 66242.10
Iteration:   1980, Loss function: 3.761, Average Loss: 4.444, avg. samples / sec: 66170.25
Iteration:   1980, Loss function: 3.868, Average Loss: 4.440, avg. samples / sec: 66222.21
Iteration:   1980, Loss function: 3.539, Average Loss: 4.428, avg. samples / sec: 66221.43
Iteration:   1980, Loss function: 3.796, Average Loss: 4.417, avg. samples / sec: 66428.32
Iteration:   1980, Loss function: 3.571, Average Loss: 4.437, avg. samples / sec: 66243.04
Iteration:   1980, Loss function: 2.880, Average Loss: 4.444, avg. samples / sec: 66161.31
Iteration:   1980, Loss function: 3.046, Average Loss: 4.400, avg. samples / sec: 66300.22
Iteration:   1980, Loss function: 3.194, Average Loss: 4.435, avg. samples / sec: 66302.90
Iteration:   1980, Loss function: 5.767, Average Loss: 4.433, avg. samples / sec: 66151.34
Iteration:   1980, Loss function: 5.021, Average Loss: 4.415, avg. samples / sec: 66350.85
Iteration:   1980, Loss function: 3.921, Average Loss: 4.412, avg. samples / sec: 66228.34
Iteration:   1980, Loss function: 3.767, Average Loss: 4.426, avg. samples / sec: 66332.18
Iteration:   1980, Loss function: 3.328, Average Loss: 4.437, avg. samples / sec: 66304.40
Iteration:   1980, Loss function: 4.657, Average Loss: 4.428, avg. samples / sec: 66204.14
Iteration:   1980, Loss function: 4.330, Average Loss: 4.410, avg. samples / sec: 66220.81
Iteration:   1980, Loss function: 4.908, Average Loss: 4.421, avg. samples / sec: 66376.51
Iteration:   1980, Loss function: 3.837, Average Loss: 4.405, avg. samples / sec: 66363.57
Iteration:   1980, Loss function: 3.124, Average Loss: 4.454, avg. samples / sec: 66171.84
Iteration:   1980, Loss function: 4.739, Average Loss: 4.418, avg. samples / sec: 66253.03
Iteration:   1980, Loss function: 3.872, Average Loss: 4.411, avg. samples / sec: 66186.35
Iteration:   2000, Loss function: 4.329, Average Loss: 4.436, avg. samples / sec: 65957.28
Iteration:   2000, Loss function: 4.529, Average Loss: 4.440, avg. samples / sec: 65944.75
Iteration:   2000, Loss function: 5.043, Average Loss: 4.417, avg. samples / sec: 65939.41
Iteration:   2000, Loss function: 3.556, Average Loss: 4.409, avg. samples / sec: 66117.67
Iteration:   2000, Loss function: 4.930, Average Loss: 4.425, avg. samples / sec: 65822.38
Iteration:   2000, Loss function: 3.484, Average Loss: 4.421, avg. samples / sec: 65878.20
Iteration:   2000, Loss function: 3.019, Average Loss: 4.415, avg. samples / sec: 65944.75
Iteration:   2000, Loss function: 4.602, Average Loss: 4.429, avg. samples / sec: 65854.68
Iteration:   2000, Loss function: 3.282, Average Loss: 4.400, avg. samples / sec: 65823.64
Iteration:   2000, Loss function: 4.220, Average Loss: 4.430, avg. samples / sec: 65849.94
Iteration:   2000, Loss function: 3.632, Average Loss: 4.417, avg. samples / sec: 65951.14
Iteration:   2000, Loss function: 4.691, Average Loss: 4.431, avg. samples / sec: 65866.37
Iteration:   2000, Loss function: 4.671, Average Loss: 4.420, avg. samples / sec: 65886.73
Iteration:   2000, Loss function: 4.079, Average Loss: 4.423, avg. samples / sec: 65859.23
Iteration:   2000, Loss function: 3.910, Average Loss: 4.399, avg. samples / sec: 65915.45
Iteration:   2000, Loss function: 3.148, Average Loss: 4.413, avg. samples / sec: 65982.05
Iteration:   2000, Loss function: 4.217, Average Loss: 4.434, avg. samples / sec: 65885.43
Iteration:   2000, Loss function: 4.314, Average Loss: 4.403, avg. samples / sec: 65840.92
Iteration:   2000, Loss function: 4.053, Average Loss: 4.423, avg. samples / sec: 65864.31
Iteration:   2000, Loss function: 4.284, Average Loss: 4.437, avg. samples / sec: 65794.69
Iteration:   2000, Loss function: 3.867, Average Loss: 4.440, avg. samples / sec: 65746.59
Iteration:   2000, Loss function: 3.498, Average Loss: 4.425, avg. samples / sec: 65770.68
Iteration:   2000, Loss function: 2.900, Average Loss: 4.438, avg. samples / sec: 65777.07
Iteration:   2000, Loss function: 4.901, Average Loss: 4.416, avg. samples / sec: 65778.11
Iteration:   2000, Loss function: 3.851, Average Loss: 4.398, avg. samples / sec: 65771.02
Iteration:   2000, Loss function: 4.450, Average Loss: 4.405, avg. samples / sec: 65812.67
Iteration:   2000, Loss function: 5.606, Average Loss: 4.412, avg. samples / sec: 65785.20
Iteration:   2000, Loss function: 4.425, Average Loss: 4.431, avg. samples / sec: 65716.33
Iteration:   2000, Loss function: 3.957, Average Loss: 4.452, avg. samples / sec: 65799.02
Iteration:   2000, Loss function: 4.043, Average Loss: 4.425, avg. samples / sec: 65665.87
Iteration:   2020, Loss function: 5.305, Average Loss: 4.401, avg. samples / sec: 66519.94
Iteration:   2020, Loss function: 4.262, Average Loss: 4.419, avg. samples / sec: 66475.54
Iteration:   2020, Loss function: 4.149, Average Loss: 4.427, avg. samples / sec: 66438.56
Iteration:   2020, Loss function: 4.226, Average Loss: 4.416, avg. samples / sec: 66360.10
Iteration:   2020, Loss function: 4.454, Average Loss: 4.414, avg. samples / sec: 66386.80
Iteration:   2020, Loss function: 4.699, Average Loss: 4.426, avg. samples / sec: 66549.19
Iteration:   2020, Loss function: 5.024, Average Loss: 4.430, avg. samples / sec: 66368.32
Iteration:   2020, Loss function: 3.823, Average Loss: 4.429, avg. samples / sec: 66155.94
Iteration:   2020, Loss function: 3.417, Average Loss: 4.417, avg. samples / sec: 66429.61
Iteration:   2020, Loss function: 3.797, Average Loss: 4.422, avg. samples / sec: 66441.38
Iteration:   2020, Loss function: 5.393, Average Loss: 4.425, avg. samples / sec: 66571.76
Iteration:   2020, Loss function: 4.260, Average Loss: 4.399, avg. samples / sec: 66375.95
Iteration:   2020, Loss function: 3.798, Average Loss: 4.437, avg. samples / sec: 66439.75
Iteration:   2020, Loss function: 4.977, Average Loss: 4.418, avg. samples / sec: 66333.93
Iteration:   2020, Loss function: 3.791, Average Loss: 4.416, avg. samples / sec: 66297.48
Iteration:   2020, Loss function: 4.465, Average Loss: 4.448, avg. samples / sec: 66533.63
Iteration:   2020, Loss function: 4.549, Average Loss: 4.428, avg. samples / sec: 66297.23
Iteration:   2020, Loss function: 2.515, Average Loss: 4.419, avg. samples / sec: 66324.78
Iteration:   2020, Loss function: 4.780, Average Loss: 4.424, avg. samples / sec: 66278.43
Iteration:   2020, Loss function: 4.832, Average Loss: 4.405, avg. samples / sec: 66436.28
Iteration:   2020, Loss function: 5.650, Average Loss: 4.408, avg. samples / sec: 66245.90
Iteration:   2020, Loss function: 4.777, Average Loss: 4.440, avg. samples / sec: 66251.16
Iteration:   2020, Loss function: 3.882, Average Loss: 4.419, avg. samples / sec: 66408.13
Iteration:   2020, Loss function: 4.998, Average Loss: 4.435, avg. samples / sec: 66374.76
Iteration:   2020, Loss function: 5.006, Average Loss: 4.443, avg. samples / sec: 66369.70
Iteration:   2020, Loss function: 5.220, Average Loss: 4.409, avg. samples / sec: 66389.99
Iteration:   2020, Loss function: 6.103, Average Loss: 4.408, avg. samples / sec: 66332.27
Iteration:   2020, Loss function: 4.082, Average Loss: 4.398, avg. samples / sec: 66362.41
Iteration:   2020, Loss function: 5.160, Average Loss: 4.441, avg. samples / sec: 66249.14
Iteration:   2020, Loss function: 4.336, Average Loss: 4.412, avg. samples / sec: 66241.07
:::MLL 1558651408.926 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558651408.926 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 5.183, Average Loss: 4.395, avg. samples / sec: 66171.09
Iteration:   2040, Loss function: 4.110, Average Loss: 4.410, avg. samples / sec: 65960.15
Iteration:   2040, Loss function: 3.719, Average Loss: 4.426, avg. samples / sec: 65897.54
Iteration:   2040, Loss function: 4.324, Average Loss: 4.439, avg. samples / sec: 66076.50
Iteration:   2040, Loss function: 4.080, Average Loss: 4.394, avg. samples / sec: 65806.40
Iteration:   2040, Loss function: 5.020, Average Loss: 4.431, avg. samples / sec: 65957.78
Iteration:   2040, Loss function: 4.435, Average Loss: 4.415, avg. samples / sec: 65859.88
Iteration:   2040, Loss function: 3.118, Average Loss: 4.423, avg. samples / sec: 66014.84
Iteration:   2040, Loss function: 3.872, Average Loss: 4.421, avg. samples / sec: 66007.79
Iteration:   2040, Loss function: 5.095, Average Loss: 4.431, avg. samples / sec: 66018.37
Iteration:   2040, Loss function: 4.769, Average Loss: 4.412, avg. samples / sec: 65991.93
Iteration:   2040, Loss function: 5.130, Average Loss: 4.435, avg. samples / sec: 66011.04
Iteration:   2040, Loss function: 4.873, Average Loss: 4.424, avg. samples / sec: 65918.35
Iteration:   2040, Loss function: 4.127, Average Loss: 4.422, avg. samples / sec: 65949.87
Iteration:   2040, Loss function: 4.943, Average Loss: 4.416, avg. samples / sec: 65979.33
Iteration:   2040, Loss function: 3.191, Average Loss: 4.409, avg. samples / sec: 65844.12
Iteration:   2040, Loss function: 4.489, Average Loss: 4.401, avg. samples / sec: 65993.97
Iteration:   2040, Loss function: 4.332, Average Loss: 4.409, avg. samples / sec: 65939.32
Iteration:   2040, Loss function: 4.020, Average Loss: 4.428, avg. samples / sec: 65873.45
Iteration:   2040, Loss function: 5.775, Average Loss: 4.401, avg. samples / sec: 65974.63
Iteration:   2040, Loss function: 3.740, Average Loss: 4.394, avg. samples / sec: 65869.21
Iteration:   2040, Loss function: 4.965, Average Loss: 4.419, avg. samples / sec: 65864.71
Iteration:   2040, Loss function: 3.424, Average Loss: 4.407, avg. samples / sec: 65879.67
Iteration:   2040, Loss function: 5.500, Average Loss: 4.406, avg. samples / sec: 65972.53
Iteration:   2040, Loss function: 3.329, Average Loss: 4.401, avg. samples / sec: 65873.58
Iteration:   2040, Loss function: 4.705, Average Loss: 4.451, avg. samples / sec: 65846.98
Iteration:   2040, Loss function: 3.896, Average Loss: 4.415, avg. samples / sec: 65819.92
Iteration:   2040, Loss function: 5.628, Average Loss: 4.412, avg. samples / sec: 65799.36
Iteration:   2040, Loss function: 4.629, Average Loss: 4.439, avg. samples / sec: 65925.72
Iteration:   2040, Loss function: 4.651, Average Loss: 4.432, avg. samples / sec: 65694.77
Iteration:   2060, Loss function: 4.915, Average Loss: 4.420, avg. samples / sec: 66856.62
Iteration:   2060, Loss function: 5.542, Average Loss: 4.390, avg. samples / sec: 66652.93
Iteration:   2060, Loss function: 4.599, Average Loss: 4.417, avg. samples / sec: 66706.28
Iteration:   2060, Loss function: 5.125, Average Loss: 4.397, avg. samples / sec: 66763.25
Iteration:   2060, Loss function: 4.187, Average Loss: 4.436, avg. samples / sec: 66697.18
Iteration:   2060, Loss function: 4.692, Average Loss: 4.410, avg. samples / sec: 66833.26
Iteration:   2060, Loss function: 3.334, Average Loss: 4.431, avg. samples / sec: 66657.40
Iteration:   2060, Loss function: 4.407, Average Loss: 4.412, avg. samples / sec: 66656.77
Iteration:   2060, Loss function: 3.916, Average Loss: 4.410, avg. samples / sec: 66650.47
Iteration:   2060, Loss function: 4.967, Average Loss: 4.402, avg. samples / sec: 66685.82
Iteration:   2060, Loss function: 6.024, Average Loss: 4.439, avg. samples / sec: 66622.96
Iteration:   2060, Loss function: 5.031, Average Loss: 4.428, avg. samples / sec: 66912.81
Iteration:   2060, Loss function: 3.487, Average Loss: 4.410, avg. samples / sec: 66777.52
Iteration:   2060, Loss function: 4.339, Average Loss: 4.417, avg. samples / sec: 66618.05
Iteration:   2060, Loss function: 4.908, Average Loss: 4.404, avg. samples / sec: 66570.72
Iteration:   2060, Loss function: 3.402, Average Loss: 4.403, avg. samples / sec: 66742.13
Iteration:   2060, Loss function: 3.906, Average Loss: 4.415, avg. samples / sec: 66633.14
Iteration:   2060, Loss function: 3.739, Average Loss: 4.444, avg. samples / sec: 66739.76
Iteration:   2060, Loss function: 4.097, Average Loss: 4.402, avg. samples / sec: 66679.89
Iteration:   2060, Loss function: 3.209, Average Loss: 4.417, avg. samples / sec: 66595.60
Iteration:   2060, Loss function: 5.132, Average Loss: 4.419, avg. samples / sec: 66608.44
Iteration:   2060, Loss function: 4.613, Average Loss: 4.432, avg. samples / sec: 66764.04
Iteration:   2060, Loss function: 3.215, Average Loss: 4.396, avg. samples / sec: 66652.67
Iteration:   2060, Loss function: 3.402, Average Loss: 4.395, avg. samples / sec: 66546.23
Iteration:   2060, Loss function: 3.779, Average Loss: 4.429, avg. samples / sec: 66569.87
Iteration:   2060, Loss function: 4.831, Average Loss: 4.400, avg. samples / sec: 66672.79
Iteration:   2060, Loss function: 4.161, Average Loss: 4.426, avg. samples / sec: 66529.17
Iteration:   2060, Loss function: 3.971, Average Loss: 4.411, avg. samples / sec: 66646.15
Iteration:   2060, Loss function: 3.703, Average Loss: 4.389, avg. samples / sec: 66517.21
Iteration:   2060, Loss function: 4.665, Average Loss: 4.407, avg. samples / sec: 66544.16
Iteration:   2080, Loss function: 3.076, Average Loss: 4.409, avg. samples / sec: 66477.93
Iteration:   2080, Loss function: 3.363, Average Loss: 4.392, avg. samples / sec: 66597.65
Iteration:   2080, Loss function: 5.190, Average Loss: 4.412, avg. samples / sec: 66503.05
Iteration:   2080, Loss function: 4.177, Average Loss: 4.435, avg. samples / sec: 66473.19
Iteration:   2080, Loss function: 3.870, Average Loss: 4.410, avg. samples / sec: 66593.34
Iteration:   2080, Loss function: 3.782, Average Loss: 4.422, avg. samples / sec: 66565.03
Iteration:   2080, Loss function: 4.098, Average Loss: 4.397, avg. samples / sec: 66474.60
Iteration:   2080, Loss function: 4.323, Average Loss: 4.381, avg. samples / sec: 66355.70
Iteration:   2080, Loss function: 4.015, Average Loss: 4.410, avg. samples / sec: 66502.74
Iteration:   2080, Loss function: 3.154, Average Loss: 4.413, avg. samples / sec: 66290.15
Iteration:   2080, Loss function: 4.226, Average Loss: 4.398, avg. samples / sec: 66649.46
Iteration:   2080, Loss function: 4.208, Average Loss: 4.425, avg. samples / sec: 66387.08
Iteration:   2080, Loss function: 3.603, Average Loss: 4.420, avg. samples / sec: 66455.39
Iteration:   2080, Loss function: 3.661, Average Loss: 4.408, avg. samples / sec: 66377.98
Iteration:   2080, Loss function: 4.258, Average Loss: 4.398, avg. samples / sec: 66430.04
Iteration:   2080, Loss function: 3.556, Average Loss: 4.416, avg. samples / sec: 66429.04
Iteration:   2080, Loss function: 3.732, Average Loss: 4.413, avg. samples / sec: 66432.89
Iteration:   2080, Loss function: 3.858, Average Loss: 4.407, avg. samples / sec: 66365.13
Iteration:   2080, Loss function: 3.945, Average Loss: 4.419, avg. samples / sec: 66473.82
Iteration:   2080, Loss function: 3.968, Average Loss: 4.390, avg. samples / sec: 66315.29
Iteration:   2080, Loss function: 3.430, Average Loss: 4.394, avg. samples / sec: 66456.17
Iteration:   2080, Loss function: 4.632, Average Loss: 4.399, avg. samples / sec: 66418.77
Iteration:   2080, Loss function: 6.175, Average Loss: 4.401, avg. samples / sec: 66476.48
Iteration:   2080, Loss function: 4.190, Average Loss: 4.441, avg. samples / sec: 66411.04
Iteration:   2080, Loss function: 3.303, Average Loss: 4.386, avg. samples / sec: 66537.56
Iteration:   2080, Loss function: 4.193, Average Loss: 4.428, avg. samples / sec: 66361.13
Iteration:   2080, Loss function: 4.565, Average Loss: 4.426, avg. samples / sec: 66281.23
Iteration:   2080, Loss function: 5.087, Average Loss: 4.432, avg. samples / sec: 66219.94
Iteration:   2080, Loss function: 5.408, Average Loss: 4.406, avg. samples / sec: 66294.89
Iteration:   2080, Loss function: 4.181, Average Loss: 4.407, avg. samples / sec: 66210.23
:::MLL 1558651410.696 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558651410.697 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 4.411, Average Loss: 4.407, avg. samples / sec: 66479.12
Iteration:   2100, Loss function: 3.493, Average Loss: 4.419, avg. samples / sec: 66428.07
Iteration:   2100, Loss function: 4.136, Average Loss: 4.423, avg. samples / sec: 66553.59
Iteration:   2100, Loss function: 5.292, Average Loss: 4.407, avg. samples / sec: 66326.43
Iteration:   2100, Loss function: 4.336, Average Loss: 4.384, avg. samples / sec: 66296.20
Iteration:   2100, Loss function: 3.511, Average Loss: 4.407, avg. samples / sec: 66383.95
Iteration:   2100, Loss function: 4.744, Average Loss: 4.405, avg. samples / sec: 66380.82
Iteration:   2100, Loss function: 2.591, Average Loss: 4.394, avg. samples / sec: 66389.71
Iteration:   2100, Loss function: 3.823, Average Loss: 4.426, avg. samples / sec: 66295.64
Iteration:   2100, Loss function: 4.467, Average Loss: 4.397, avg. samples / sec: 66369.98
Iteration:   2100, Loss function: 4.053, Average Loss: 4.399, avg. samples / sec: 66492.98
Iteration:   2100, Loss function: 4.232, Average Loss: 4.387, avg. samples / sec: 66287.97
Iteration:   2100, Loss function: 3.373, Average Loss: 4.412, avg. samples / sec: 66236.03
Iteration:   2100, Loss function: 4.305, Average Loss: 4.394, avg. samples / sec: 66389.46
Iteration:   2100, Loss function: 4.462, Average Loss: 4.374, avg. samples / sec: 66294.17
Iteration:   2100, Loss function: 4.442, Average Loss: 4.404, avg. samples / sec: 66171.34
Iteration:   2100, Loss function: 5.322, Average Loss: 4.380, avg. samples / sec: 66415.14
Iteration:   2100, Loss function: 5.242, Average Loss: 4.390, avg. samples / sec: 66337.64
Iteration:   2100, Loss function: 4.117, Average Loss: 4.386, avg. samples / sec: 66316.91
Iteration:   2100, Loss function: 3.923, Average Loss: 4.434, avg. samples / sec: 66341.70
Iteration:   2100, Loss function: 4.080, Average Loss: 4.422, avg. samples / sec: 66393.08
Iteration:   2100, Loss function: 3.710, Average Loss: 4.407, avg. samples / sec: 66242.66
Iteration:   2100, Loss function: 5.209, Average Loss: 4.405, avg. samples / sec: 66273.60
Iteration:   2100, Loss function: 4.070, Average Loss: 4.399, avg. samples / sec: 66481.28
Iteration:   2100, Loss function: 4.261, Average Loss: 4.403, avg. samples / sec: 66278.21
Iteration:   2100, Loss function: 4.684, Average Loss: 4.411, avg. samples / sec: 66293.14
Iteration:   2100, Loss function: 4.158, Average Loss: 4.411, avg. samples / sec: 66134.02
Iteration:   2100, Loss function: 5.282, Average Loss: 4.420, avg. samples / sec: 66358.41
Iteration:   2100, Loss function: 4.935, Average Loss: 4.417, avg. samples / sec: 66225.51
Iteration:   2100, Loss function: 6.964, Average Loss: 4.405, avg. samples / sec: 66178.80
Iteration:   2120, Loss function: 4.601, Average Loss: 4.400, avg. samples / sec: 66256.02
Iteration:   2120, Loss function: 4.661, Average Loss: 4.377, avg. samples / sec: 66235.59
Iteration:   2120, Loss function: 3.840, Average Loss: 4.396, avg. samples / sec: 66243.16
Iteration:   2120, Loss function: 4.853, Average Loss: 4.413, avg. samples / sec: 66245.96
Iteration:   2120, Loss function: 4.712, Average Loss: 4.418, avg. samples / sec: 66174.36
Iteration:   2120, Loss function: 5.896, Average Loss: 4.415, avg. samples / sec: 66373.51
Iteration:   2120, Loss function: 4.341, Average Loss: 4.415, avg. samples / sec: 66157.08
Iteration:   2120, Loss function: 5.403, Average Loss: 4.405, avg. samples / sec: 66302.34
Iteration:   2120, Loss function: 4.779, Average Loss: 4.399, avg. samples / sec: 66092.86
Iteration:   2120, Loss function: 4.453, Average Loss: 4.407, avg. samples / sec: 66276.46
Iteration:   2120, Loss function: 3.634, Average Loss: 4.401, avg. samples / sec: 66375.42
Iteration:   2120, Loss function: 4.065, Average Loss: 4.390, avg. samples / sec: 66185.48
Iteration:   2120, Loss function: 4.647, Average Loss: 4.391, avg. samples / sec: 66167.55
Iteration:   2120, Loss function: 4.348, Average Loss: 4.387, avg. samples / sec: 66147.83
Iteration:   2120, Loss function: 4.296, Average Loss: 4.371, avg. samples / sec: 66214.78
Iteration:   2120, Loss function: 4.202, Average Loss: 4.403, avg. samples / sec: 66125.08
Iteration:   2120, Loss function: 4.671, Average Loss: 4.385, avg. samples / sec: 66157.18
Iteration:   2120, Loss function: 4.717, Average Loss: 4.397, avg. samples / sec: 66244.00
Iteration:   2120, Loss function: 4.674, Average Loss: 4.416, avg. samples / sec: 66293.92
Iteration:   2120, Loss function: 4.366, Average Loss: 4.395, avg. samples / sec: 66235.75
Iteration:   2120, Loss function: 4.042, Average Loss: 4.429, avg. samples / sec: 66205.54
Iteration:   2120, Loss function: 2.973, Average Loss: 4.372, avg. samples / sec: 66161.56
Iteration:   2120, Loss function: 3.764, Average Loss: 4.385, avg. samples / sec: 66170.32
Iteration:   2120, Loss function: 3.628, Average Loss: 4.425, avg. samples / sec: 66112.86
Iteration:   2120, Loss function: 3.919, Average Loss: 4.388, avg. samples / sec: 66115.56
Iteration:   2120, Loss function: 3.698, Average Loss: 4.399, avg. samples / sec: 66151.53
Iteration:   2120, Loss function: 4.006, Average Loss: 4.386, avg. samples / sec: 66123.22
Iteration:   2120, Loss function: 5.058, Average Loss: 4.407, avg. samples / sec: 66182.47
Iteration:   2120, Loss function: 5.339, Average Loss: 4.398, avg. samples / sec: 66067.48
Iteration:   2120, Loss function: 3.901, Average Loss: 4.416, avg. samples / sec: 66077.92
Iteration:   2140, Loss function: 4.666, Average Loss: 4.385, avg. samples / sec: 66324.34
Iteration:   2140, Loss function: 4.024, Average Loss: 4.421, avg. samples / sec: 66369.13
Iteration:   2140, Loss function: 3.606, Average Loss: 4.400, avg. samples / sec: 66207.53
Iteration:   2140, Loss function: 3.900, Average Loss: 4.393, avg. samples / sec: 66454.88
Iteration:   2140, Loss function: 3.163, Average Loss: 4.410, avg. samples / sec: 66253.25
Iteration:   2140, Loss function: 4.398, Average Loss: 4.388, avg. samples / sec: 66200.03
Iteration:   2140, Loss function: 4.853, Average Loss: 4.381, avg. samples / sec: 66293.74
Iteration:   2140, Loss function: 4.302, Average Loss: 4.393, avg. samples / sec: 66270.39
Iteration:   2140, Loss function: 4.260, Average Loss: 4.404, avg. samples / sec: 66249.11
Iteration:   2140, Loss function: 4.634, Average Loss: 4.407, avg. samples / sec: 66191.39
Iteration:   2140, Loss function: 2.577, Average Loss: 4.407, avg. samples / sec: 66194.09
Iteration:   2140, Loss function: 4.616, Average Loss: 4.404, avg. samples / sec: 66353.70
Iteration:   2140, Loss function: 4.148, Average Loss: 4.378, avg. samples / sec: 66115.96
Iteration:   2140, Loss function: 4.269, Average Loss: 4.409, avg. samples / sec: 66166.68
Iteration:   2140, Loss function: 4.183, Average Loss: 4.385, avg. samples / sec: 66216.58
Iteration:   2140, Loss function: 4.265, Average Loss: 4.384, avg. samples / sec: 66337.27
Iteration:   2140, Loss function: 6.016, Average Loss: 4.411, avg. samples / sec: 66394.90
Iteration:   2140, Loss function: 4.499, Average Loss: 4.426, avg. samples / sec: 66243.10
Iteration:   2140, Loss function: 4.011, Average Loss: 4.383, avg. samples / sec: 66264.81
Iteration:   2140, Loss function: 4.108, Average Loss: 4.370, avg. samples / sec: 66226.88
Iteration:   2140, Loss function: 4.290, Average Loss: 4.399, avg. samples / sec: 66285.29
Iteration:   2140, Loss function: 3.708, Average Loss: 4.394, avg. samples / sec: 66166.93
Iteration:   2140, Loss function: 3.469, Average Loss: 4.371, avg. samples / sec: 66195.90
Iteration:   2140, Loss function: 4.665, Average Loss: 4.392, avg. samples / sec: 66145.75
Iteration:   2140, Loss function: 3.934, Average Loss: 4.400, avg. samples / sec: 66106.22
Iteration:   2140, Loss function: 5.531, Average Loss: 4.361, avg. samples / sec: 66130.57
Iteration:   2140, Loss function: 4.311, Average Loss: 4.394, avg. samples / sec: 66140.44
Iteration:   2140, Loss function: 3.858, Average Loss: 4.390, avg. samples / sec: 66125.17
Iteration:   2140, Loss function: 3.953, Average Loss: 4.378, avg. samples / sec: 66077.46
Iteration:   2140, Loss function: 4.003, Average Loss: 4.413, avg. samples / sec: 66009.71
Iteration:   2160, Loss function: 4.179, Average Loss: 4.379, avg. samples / sec: 66673.42
Iteration:   2160, Loss function: 4.135, Average Loss: 4.395, avg. samples / sec: 66641.36
Iteration:   2160, Loss function: 3.721, Average Loss: 4.408, avg. samples / sec: 66542.96
Iteration:   2160, Loss function: 3.674, Average Loss: 4.396, avg. samples / sec: 66651.60
Iteration:   2160, Loss function: 2.951, Average Loss: 4.383, avg. samples / sec: 66497.06
Iteration:   2160, Loss function: 4.655, Average Loss: 4.396, avg. samples / sec: 66516.33
Iteration:   2160, Loss function: 4.586, Average Loss: 4.395, avg. samples / sec: 66669.48
Iteration:   2160, Loss function: 4.536, Average Loss: 4.399, avg. samples / sec: 66675.32
Iteration:   2160, Loss function: 4.205, Average Loss: 4.380, avg. samples / sec: 66521.82
Iteration:   2160, Loss function: 3.943, Average Loss: 4.408, avg. samples / sec: 66535.74
Iteration:   2160, Loss function: 3.970, Average Loss: 4.401, avg. samples / sec: 66594.72
Iteration:   2160, Loss function: 5.256, Average Loss: 4.406, avg. samples / sec: 66558.17
Iteration:   2160, Loss function: 4.744, Average Loss: 4.411, avg. samples / sec: 66541.17
Iteration:   2160, Loss function: 5.340, Average Loss: 4.369, avg. samples / sec: 66596.99
Iteration:   2160, Loss function: 5.177, Average Loss: 4.410, avg. samples / sec: 66558.14
Iteration:   2160, Loss function: 5.341, Average Loss: 4.381, avg. samples / sec: 66563.08
Iteration:   2160, Loss function: 4.138, Average Loss: 4.383, avg. samples / sec: 66471.25
Iteration:   2160, Loss function: 3.384, Average Loss: 4.391, avg. samples / sec: 66447.08
Iteration:   2160, Loss function: 3.521, Average Loss: 4.411, avg. samples / sec: 66769.96
Iteration:   2160, Loss function: 4.517, Average Loss: 4.400, avg. samples / sec: 66563.74
Iteration:   2160, Loss function: 5.321, Average Loss: 4.369, avg. samples / sec: 66543.78
Iteration:   2160, Loss function: 3.853, Average Loss: 4.357, avg. samples / sec: 66581.85
Iteration:   2160, Loss function: 3.777, Average Loss: 4.383, avg. samples / sec: 66492.26
Iteration:   2160, Loss function: 3.247, Average Loss: 4.382, avg. samples / sec: 66482.47
Iteration:   2160, Loss function: 3.852, Average Loss: 4.425, avg. samples / sec: 66375.79
Iteration:   2160, Loss function: 4.548, Average Loss: 4.391, avg. samples / sec: 66605.58
Iteration:   2160, Loss function: 3.993, Average Loss: 4.392, avg. samples / sec: 66554.47
Iteration:   2160, Loss function: 3.835, Average Loss: 4.424, avg. samples / sec: 66466.36
Iteration:   2160, Loss function: 4.940, Average Loss: 4.414, avg. samples / sec: 66443.79
Iteration:   2160, Loss function: 4.092, Average Loss: 4.371, avg. samples / sec: 66617.76
:::MLL 1558651412.471 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558651412.471 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 3.974, Average Loss: 4.397, avg. samples / sec: 66287.90
Iteration:   2180, Loss function: 4.137, Average Loss: 4.377, avg. samples / sec: 66258.39
Iteration:   2180, Loss function: 5.598, Average Loss: 4.409, avg. samples / sec: 66276.68
Iteration:   2180, Loss function: 3.906, Average Loss: 4.391, avg. samples / sec: 66271.63
Iteration:   2180, Loss function: 3.024, Average Loss: 4.393, avg. samples / sec: 66178.52
Iteration:   2180, Loss function: 4.915, Average Loss: 4.401, avg. samples / sec: 66252.19
Iteration:   2180, Loss function: 4.327, Average Loss: 4.405, avg. samples / sec: 66270.11
Iteration:   2180, Loss function: 5.415, Average Loss: 4.392, avg. samples / sec: 66203.67
Iteration:   2180, Loss function: 4.901, Average Loss: 4.374, avg. samples / sec: 66320.94
Iteration:   2180, Loss function: 4.378, Average Loss: 4.406, avg. samples / sec: 66260.10
Iteration:   2180, Loss function: 4.178, Average Loss: 4.387, avg. samples / sec: 66255.18
Iteration:   2180, Loss function: 3.545, Average Loss: 4.399, avg. samples / sec: 66205.91
Iteration:   2180, Loss function: 3.289, Average Loss: 4.368, avg. samples / sec: 66334.77
Iteration:   2180, Loss function: 3.812, Average Loss: 4.375, avg. samples / sec: 66285.53
Iteration:   2180, Loss function: 5.045, Average Loss: 4.365, avg. samples / sec: 66265.31
Iteration:   2180, Loss function: 3.257, Average Loss: 4.373, avg. samples / sec: 66091.28
Iteration:   2180, Loss function: 4.115, Average Loss: 4.418, avg. samples / sec: 66272.85
Iteration:   2180, Loss function: 4.755, Average Loss: 4.365, avg. samples / sec: 66176.62
Iteration:   2180, Loss function: 5.294, Average Loss: 4.387, avg. samples / sec: 66263.34
Iteration:   2180, Loss function: 3.385, Average Loss: 4.409, avg. samples / sec: 66138.67
Iteration:   2180, Loss function: 3.756, Average Loss: 4.391, avg. samples / sec: 66109.01
Iteration:   2180, Loss function: 4.052, Average Loss: 4.417, avg. samples / sec: 66273.03
Iteration:   2180, Loss function: 4.564, Average Loss: 4.375, avg. samples / sec: 66168.20
Iteration:   2180, Loss function: 3.797, Average Loss: 4.417, avg. samples / sec: 66276.93
Iteration:   2180, Loss function: 4.385, Average Loss: 4.378, avg. samples / sec: 66118.29
Iteration:   2180, Loss function: 4.385, Average Loss: 4.355, avg. samples / sec: 66223.67
Iteration:   2180, Loss function: 4.186, Average Loss: 4.398, avg. samples / sec: 66173.08
Iteration:   2180, Loss function: 4.511, Average Loss: 4.399, avg. samples / sec: 66073.24
Iteration:   2180, Loss function: 4.666, Average Loss: 4.392, avg. samples / sec: 66206.28
Iteration:   2180, Loss function: 4.503, Average Loss: 4.382, avg. samples / sec: 66142.18
Iteration:   2200, Loss function: 5.128, Average Loss: 4.383, avg. samples / sec: 66494.20
Iteration:   2200, Loss function: 2.809, Average Loss: 4.367, avg. samples / sec: 66389.30
Iteration:   2200, Loss function: 4.020, Average Loss: 4.373, avg. samples / sec: 66340.30
Iteration:   2200, Loss function: 3.995, Average Loss: 4.376, avg. samples / sec: 66461.40
Iteration:   2200, Loss function: 5.205, Average Loss: 4.386, avg. samples / sec: 66414.86
Iteration:   2200, Loss function: 3.934, Average Loss: 4.410, avg. samples / sec: 66361.69
Iteration:   2200, Loss function: 4.157, Average Loss: 4.387, avg. samples / sec: 66264.93
Iteration:   2200, Loss function: 3.719, Average Loss: 4.365, avg. samples / sec: 66352.41
Iteration:   2200, Loss function: 3.966, Average Loss: 4.367, avg. samples / sec: 66354.38
Iteration:   2200, Loss function: 4.879, Average Loss: 4.393, avg. samples / sec: 66206.19
Iteration:   2200, Loss function: 5.024, Average Loss: 4.398, avg. samples / sec: 66268.58
Iteration:   2200, Loss function: 3.316, Average Loss: 4.388, avg. samples / sec: 66235.35
Iteration:   2200, Loss function: 4.011, Average Loss: 4.402, avg. samples / sec: 66273.13
Iteration:   2200, Loss function: 3.303, Average Loss: 4.375, avg. samples / sec: 66208.93
Iteration:   2200, Loss function: 4.417, Average Loss: 4.364, avg. samples / sec: 66326.81
Iteration:   2200, Loss function: 5.022, Average Loss: 4.393, avg. samples / sec: 66372.51
Iteration:   2200, Loss function: 4.221, Average Loss: 4.392, avg. samples / sec: 66373.70
Iteration:   2200, Loss function: 3.968, Average Loss: 4.383, avg. samples / sec: 66210.70
Iteration:   2200, Loss function: 3.503, Average Loss: 4.368, avg. samples / sec: 66315.04
Iteration:   2200, Loss function: 4.190, Average Loss: 4.392, avg. samples / sec: 66216.95
Iteration:   2200, Loss function: 4.221, Average Loss: 4.401, avg. samples / sec: 66154.13
Iteration:   2200, Loss function: 3.440, Average Loss: 4.410, avg. samples / sec: 66267.36
Iteration:   2200, Loss function: 3.417, Average Loss: 4.392, avg. samples / sec: 66142.89
Iteration:   2200, Loss function: 3.831, Average Loss: 4.411, avg. samples / sec: 66254.03
Iteration:   2200, Loss function: 4.206, Average Loss: 4.410, avg. samples / sec: 66255.21
Iteration:   2200, Loss function: 4.091, Average Loss: 4.361, avg. samples / sec: 66178.49
Iteration:   2200, Loss function: 4.009, Average Loss: 4.393, avg. samples / sec: 66258.92
Iteration:   2200, Loss function: 3.433, Average Loss: 4.380, avg. samples / sec: 66138.64
Iteration:   2200, Loss function: 4.099, Average Loss: 4.349, avg. samples / sec: 66214.68
Iteration:   2200, Loss function: 3.181, Average Loss: 4.370, avg. samples / sec: 66207.28
Iteration:   2220, Loss function: 4.853, Average Loss: 4.362, avg. samples / sec: 66433.58
Iteration:   2220, Loss function: 3.683, Average Loss: 4.377, avg. samples / sec: 66415.05
Iteration:   2220, Loss function: 3.725, Average Loss: 4.377, avg. samples / sec: 66503.40
Iteration:   2220, Loss function: 3.940, Average Loss: 4.395, avg. samples / sec: 66465.95
Iteration:   2220, Loss function: 4.629, Average Loss: 4.388, avg. samples / sec: 66484.76
Iteration:   2220, Loss function: 3.509, Average Loss: 4.386, avg. samples / sec: 66486.68
Iteration:   2220, Loss function: 2.411, Average Loss: 4.357, avg. samples / sec: 66296.20
Iteration:   2220, Loss function: 3.324, Average Loss: 4.378, avg. samples / sec: 66483.44
Iteration:   2220, Loss function: 5.243, Average Loss: 4.398, avg. samples / sec: 66334.39
Iteration:   2220, Loss function: 5.186, Average Loss: 4.392, avg. samples / sec: 66311.20
Iteration:   2220, Loss function: 3.929, Average Loss: 4.389, avg. samples / sec: 66404.47
Iteration:   2220, Loss function: 4.524, Average Loss: 4.377, avg. samples / sec: 66275.81
Iteration:   2220, Loss function: 4.636, Average Loss: 4.367, avg. samples / sec: 66244.53
Iteration:   2220, Loss function: 3.768, Average Loss: 4.372, avg. samples / sec: 66309.61
Iteration:   2220, Loss function: 3.665, Average Loss: 4.388, avg. samples / sec: 66293.98
Iteration:   2220, Loss function: 5.058, Average Loss: 4.357, avg. samples / sec: 66441.32
Iteration:   2220, Loss function: 2.849, Average Loss: 4.366, avg. samples / sec: 66349.73
Iteration:   2220, Loss function: 4.701, Average Loss: 4.381, avg. samples / sec: 66280.23
Iteration:   2220, Loss function: 4.030, Average Loss: 4.399, avg. samples / sec: 66361.82
Iteration:   2220, Loss function: 3.843, Average Loss: 4.403, avg. samples / sec: 66228.31
Iteration:   2220, Loss function: 4.388, Average Loss: 4.390, avg. samples / sec: 66248.95
Iteration:   2220, Loss function: 4.468, Average Loss: 4.408, avg. samples / sec: 66349.20
Iteration:   2220, Loss function: 5.358, Average Loss: 4.383, avg. samples / sec: 66170.32
Iteration:   2220, Loss function: 4.888, Average Loss: 4.395, avg. samples / sec: 66246.52
Iteration:   2220, Loss function: 3.653, Average Loss: 4.363, avg. samples / sec: 66394.87
Iteration:   2220, Loss function: 3.253, Average Loss: 4.360, avg. samples / sec: 66121.45
Iteration:   2220, Loss function: 5.055, Average Loss: 4.343, avg. samples / sec: 66352.63
Iteration:   2220, Loss function: 4.281, Average Loss: 4.412, avg. samples / sec: 66293.77
Iteration:   2220, Loss function: 5.213, Average Loss: 4.360, avg. samples / sec: 66204.60
Iteration:   2220, Loss function: 4.648, Average Loss: 4.377, avg. samples / sec: 66024.00
:::MLL 1558651414.246 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558651414.246 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 4.594, Average Loss: 4.353, avg. samples / sec: 66246.59
Iteration:   2240, Loss function: 3.523, Average Loss: 4.388, avg. samples / sec: 66143.79
Iteration:   2240, Loss function: 4.191, Average Loss: 4.384, avg. samples / sec: 66137.31
Iteration:   2240, Loss function: 4.094, Average Loss: 4.385, avg. samples / sec: 66172.77
Iteration:   2240, Loss function: 4.475, Average Loss: 4.356, avg. samples / sec: 66231.55
Iteration:   2240, Loss function: 4.603, Average Loss: 4.400, avg. samples / sec: 66248.61
Iteration:   2240, Loss function: 3.473, Average Loss: 4.370, avg. samples / sec: 66051.69
Iteration:   2240, Loss function: 3.307, Average Loss: 4.407, avg. samples / sec: 66301.84
Iteration:   2240, Loss function: 2.681, Average Loss: 4.394, avg. samples / sec: 66125.20
Iteration:   2240, Loss function: 3.648, Average Loss: 4.357, avg. samples / sec: 66287.47
Iteration:   2240, Loss function: 4.396, Average Loss: 4.337, avg. samples / sec: 66267.36
Iteration:   2240, Loss function: 4.049, Average Loss: 4.381, avg. samples / sec: 66224.20
Iteration:   2240, Loss function: 3.773, Average Loss: 4.393, avg. samples / sec: 66217.26
Iteration:   2240, Loss function: 4.481, Average Loss: 4.396, avg. samples / sec: 66204.29
Iteration:   2240, Loss function: 3.704, Average Loss: 4.355, avg. samples / sec: 66224.76
Iteration:   2240, Loss function: 4.354, Average Loss: 4.349, avg. samples / sec: 66137.21
Iteration:   2240, Loss function: 4.076, Average Loss: 4.374, avg. samples / sec: 66107.18
Iteration:   2240, Loss function: 3.600, Average Loss: 4.375, avg. samples / sec: 66211.17
Iteration:   2240, Loss function: 4.602, Average Loss: 4.374, avg. samples / sec: 65973.31
Iteration:   2240, Loss function: 5.276, Average Loss: 4.387, avg. samples / sec: 66090.22
Iteration:   2240, Loss function: 5.557, Average Loss: 4.374, avg. samples / sec: 66242.23
Iteration:   2240, Loss function: 3.894, Average Loss: 4.365, avg. samples / sec: 65929.05
Iteration:   2240, Loss function: 3.376, Average Loss: 4.375, avg. samples / sec: 66042.53
Iteration:   2240, Loss function: 3.669, Average Loss: 4.381, avg. samples / sec: 66041.48
Iteration:   2240, Loss function: 3.973, Average Loss: 4.359, avg. samples / sec: 66057.70
Iteration:   2240, Loss function: 4.590, Average Loss: 4.372, avg. samples / sec: 66047.82
Iteration:   2240, Loss function: 3.452, Average Loss: 4.355, avg. samples / sec: 66129.55
Iteration:   2240, Loss function: 4.388, Average Loss: 4.381, avg. samples / sec: 66056.58
Iteration:   2240, Loss function: 5.373, Average Loss: 4.402, avg. samples / sec: 66115.40
Iteration:   2240, Loss function: 2.382, Average Loss: 4.377, avg. samples / sec: 66038.54
Iteration:   2260, Loss function: 4.382, Average Loss: 4.368, avg. samples / sec: 66639.12
Iteration:   2260, Loss function: 4.367, Average Loss: 4.385, avg. samples / sec: 66457.61
Iteration:   2260, Loss function: 3.550, Average Loss: 4.360, avg. samples / sec: 66583.99
Iteration:   2260, Loss function: 4.520, Average Loss: 4.401, avg. samples / sec: 66619.53
Iteration:   2260, Loss function: 4.816, Average Loss: 4.363, avg. samples / sec: 66457.36
Iteration:   2260, Loss function: 3.838, Average Loss: 4.382, avg. samples / sec: 66483.48
Iteration:   2260, Loss function: 4.884, Average Loss: 4.395, avg. samples / sec: 66406.35
Iteration:   2260, Loss function: 4.554, Average Loss: 4.375, avg. samples / sec: 66489.97
Iteration:   2260, Loss function: 3.639, Average Loss: 4.364, avg. samples / sec: 66480.72
Iteration:   2260, Loss function: 3.657, Average Loss: 4.354, avg. samples / sec: 66495.49
Iteration:   2260, Loss function: 4.827, Average Loss: 4.347, avg. samples / sec: 66450.31
Iteration:   2260, Loss function: 3.707, Average Loss: 4.391, avg. samples / sec: 66453.32
Iteration:   2260, Loss function: 4.276, Average Loss: 4.392, avg. samples / sec: 66416.36
Iteration:   2260, Loss function: 4.518, Average Loss: 4.357, avg. samples / sec: 66511.37
Iteration:   2260, Loss function: 4.906, Average Loss: 4.377, avg. samples / sec: 66362.10
Iteration:   2260, Loss function: 4.844, Average Loss: 4.353, avg. samples / sec: 66407.94
Iteration:   2260, Loss function: 5.143, Average Loss: 4.374, avg. samples / sec: 66485.58
Iteration:   2260, Loss function: 3.597, Average Loss: 4.339, avg. samples / sec: 66408.60
Iteration:   2260, Loss function: 4.292, Average Loss: 4.384, avg. samples / sec: 66342.42
Iteration:   2260, Loss function: 2.592, Average Loss: 4.348, avg. samples / sec: 66264.96
Iteration:   2260, Loss function: 5.069, Average Loss: 4.379, avg. samples / sec: 66492.95
Iteration:   2260, Loss function: 5.438, Average Loss: 4.374, avg. samples / sec: 66379.79
Iteration:   2260, Loss function: 4.957, Average Loss: 4.378, avg. samples / sec: 66409.23
Iteration:   2260, Loss function: 5.062, Average Loss: 4.385, avg. samples / sec: 66379.98
Iteration:   2260, Loss function: 3.685, Average Loss: 4.383, avg. samples / sec: 66512.34
Iteration:   2260, Loss function: 3.737, Average Loss: 4.355, avg. samples / sec: 66256.43
Iteration:   2260, Loss function: 6.213, Average Loss: 4.369, avg. samples / sec: 66374.70
Iteration:   2260, Loss function: 3.988, Average Loss: 4.351, avg. samples / sec: 66424.44
Iteration:   2260, Loss function: 3.228, Average Loss: 4.390, avg. samples / sec: 66316.07
Iteration:   2260, Loss function: 4.316, Average Loss: 4.403, avg. samples / sec: 66256.68
Iteration:   2280, Loss function: 4.219, Average Loss: 4.371, avg. samples / sec: 66285.25
Iteration:   2280, Loss function: 3.397, Average Loss: 4.357, avg. samples / sec: 66184.02
Iteration:   2280, Loss function: 5.356, Average Loss: 4.394, avg. samples / sec: 66380.48
Iteration:   2280, Loss function: 3.346, Average Loss: 4.390, avg. samples / sec: 66207.68
Iteration:   2280, Loss function: 4.561, Average Loss: 4.374, avg. samples / sec: 66182.09
Iteration:   2280, Loss function: 4.325, Average Loss: 4.365, avg. samples / sec: 66119.53
Iteration:   2280, Loss function: 3.914, Average Loss: 4.361, avg. samples / sec: 66320.07
Iteration:   2280, Loss function: 3.181, Average Loss: 4.355, avg. samples / sec: 66110.04
Iteration:   2280, Loss function: 4.356, Average Loss: 4.368, avg. samples / sec: 66295.26
Iteration:   2280, Loss function: 4.761, Average Loss: 4.352, avg. samples / sec: 66202.89
Iteration:   2280, Loss function: 5.106, Average Loss: 4.392, avg. samples / sec: 66195.59
Iteration:   2280, Loss function: 3.528, Average Loss: 4.387, avg. samples / sec: 66093.63
Iteration:   2280, Loss function: 4.702, Average Loss: 4.356, avg. samples / sec: 66191.89
Iteration:   2280, Loss function: 4.051, Average Loss: 4.345, avg. samples / sec: 66216.11
Iteration:   2280, Loss function: 4.385, Average Loss: 4.374, avg. samples / sec: 66235.94
Iteration:   2280, Loss function: 3.526, Average Loss: 4.339, avg. samples / sec: 66186.85
Iteration:   2280, Loss function: 4.780, Average Loss: 4.375, avg. samples / sec: 66135.85
Iteration:   2280, Loss function: 4.244, Average Loss: 4.350, avg. samples / sec: 66261.16
Iteration:   2280, Loss function: 4.533, Average Loss: 4.342, avg. samples / sec: 66145.16
Iteration:   2280, Loss function: 2.903, Average Loss: 4.400, avg. samples / sec: 66087.40
Iteration:   2280, Loss function: 6.113, Average Loss: 4.379, avg. samples / sec: 66158.79
Iteration:   2280, Loss function: 3.770, Average Loss: 4.382, avg. samples / sec: 66236.47
Iteration:   2280, Loss function: 3.593, Average Loss: 4.372, avg. samples / sec: 66233.82
Iteration:   2280, Loss function: 3.238, Average Loss: 4.361, avg. samples / sec: 66102.72
Iteration:   2280, Loss function: 4.423, Average Loss: 4.385, avg. samples / sec: 66211.79
Iteration:   2280, Loss function: 4.327, Average Loss: 4.384, avg. samples / sec: 66223.46
Iteration:   2280, Loss function: 4.166, Average Loss: 4.380, avg. samples / sec: 66131.10
Iteration:   2280, Loss function: 4.475, Average Loss: 4.351, avg. samples / sec: 66064.66
Iteration:   2280, Loss function: 4.046, Average Loss: 4.356, avg. samples / sec: 66195.34
Iteration:   2280, Loss function: 3.358, Average Loss: 4.386, avg. samples / sec: 66017.16
:::MLL 1558651415.425 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.43s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.42s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.45s)
DONE (t=0.46s)
DONE (t=0.49s)
DONE (t=2.77s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.15685
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.29166
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.15322
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03623
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.15807
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.25506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.17136
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26028
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06829
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26782
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.40392
Current AP: 0.15685 AP goal: 0.23000
:::MLL 1558651419.441 eval_accuracy: {"value": 0.15684566633683214, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558651419.509 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558651419.515 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558651419.515 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 4.416, Average Loss: 4.366, avg. samples / sec: 7211.11
Iteration:   2300, Loss function: 4.467, Average Loss: 4.369, avg. samples / sec: 7211.59
Iteration:   2300, Loss function: 3.007, Average Loss: 4.354, avg. samples / sec: 7210.17
Iteration:   2300, Loss function: 5.051, Average Loss: 4.380, avg. samples / sec: 7211.79
Iteration:   2300, Loss function: 3.342, Average Loss: 4.400, avg. samples / sec: 7211.19
Iteration:   2300, Loss function: 3.154, Average Loss: 4.348, avg. samples / sec: 7210.75
Iteration:   2300, Loss function: 4.124, Average Loss: 4.354, avg. samples / sec: 7209.86
Iteration:   2300, Loss function: 3.598, Average Loss: 4.382, avg. samples / sec: 7209.89
Iteration:   2300, Loss function: 3.774, Average Loss: 4.381, avg. samples / sec: 7210.52
Iteration:   2300, Loss function: 4.620, Average Loss: 4.384, avg. samples / sec: 7210.84
Iteration:   2300, Loss function: 4.159, Average Loss: 4.346, avg. samples / sec: 7209.01
Iteration:   2300, Loss function: 3.177, Average Loss: 4.353, avg. samples / sec: 7209.71
Iteration:   2300, Loss function: 3.585, Average Loss: 4.362, avg. samples / sec: 7209.34
Iteration:   2300, Loss function: 3.814, Average Loss: 4.369, avg. samples / sec: 7209.73
Iteration:   2300, Loss function: 4.143, Average Loss: 4.386, avg. samples / sec: 7208.86
Iteration:   2300, Loss function: 3.705, Average Loss: 4.372, avg. samples / sec: 7209.72
Iteration:   2300, Loss function: 3.834, Average Loss: 4.358, avg. samples / sec: 7209.24
Iteration:   2300, Loss function: 4.552, Average Loss: 4.386, avg. samples / sec: 7208.79
Iteration:   2300, Loss function: 3.802, Average Loss: 4.368, avg. samples / sec: 7208.21
Iteration:   2300, Loss function: 4.994, Average Loss: 4.350, avg. samples / sec: 7210.25
Iteration:   2300, Loss function: 4.151, Average Loss: 4.332, avg. samples / sec: 7209.23
Iteration:   2300, Loss function: 6.011, Average Loss: 4.390, avg. samples / sec: 7209.04
Iteration:   2300, Loss function: 3.819, Average Loss: 4.352, avg. samples / sec: 7210.02
Iteration:   2300, Loss function: 3.218, Average Loss: 4.351, avg. samples / sec: 7209.34
Iteration:   2300, Loss function: 3.556, Average Loss: 4.349, avg. samples / sec: 7208.56
Iteration:   2300, Loss function: 3.084, Average Loss: 4.378, avg. samples / sec: 7209.45
Iteration:   2300, Loss function: 3.129, Average Loss: 4.370, avg. samples / sec: 7208.81
Iteration:   2300, Loss function: 4.212, Average Loss: 4.344, avg. samples / sec: 7208.45
Iteration:   2300, Loss function: 3.547, Average Loss: 4.377, avg. samples / sec: 7210.04
Iteration:   2300, Loss function: 5.020, Average Loss: 4.341, avg. samples / sec: 7208.29
:::MLL 1558651420.177 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558651420.178 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 4.843, Average Loss: 4.342, avg. samples / sec: 65309.89
Iteration:   2320, Loss function: 4.357, Average Loss: 4.386, avg. samples / sec: 65380.06
Iteration:   2320, Loss function: 4.648, Average Loss: 4.367, avg. samples / sec: 65206.00
Iteration:   2320, Loss function: 3.685, Average Loss: 4.369, avg. samples / sec: 65349.08
Iteration:   2320, Loss function: 3.754, Average Loss: 4.346, avg. samples / sec: 65389.55
Iteration:   2320, Loss function: 3.738, Average Loss: 4.370, avg. samples / sec: 65410.86
Iteration:   2320, Loss function: 3.348, Average Loss: 4.334, avg. samples / sec: 65448.71
Iteration:   2320, Loss function: 3.708, Average Loss: 4.350, avg. samples / sec: 65308.16
Iteration:   2320, Loss function: 3.369, Average Loss: 4.347, avg. samples / sec: 65281.87
Iteration:   2320, Loss function: 3.545, Average Loss: 4.362, avg. samples / sec: 65103.34
Iteration:   2320, Loss function: 3.673, Average Loss: 4.347, avg. samples / sec: 65172.83
Iteration:   2320, Loss function: 4.451, Average Loss: 4.373, avg. samples / sec: 65266.06
Iteration:   2320, Loss function: 4.511, Average Loss: 4.342, avg. samples / sec: 65258.38
Iteration:   2320, Loss function: 4.516, Average Loss: 4.376, avg. samples / sec: 65368.90
Iteration:   2320, Loss function: 3.940, Average Loss: 4.380, avg. samples / sec: 65231.92
Iteration:   2320, Loss function: 3.455, Average Loss: 4.356, avg. samples / sec: 65237.54
Iteration:   2320, Loss function: 5.119, Average Loss: 4.347, avg. samples / sec: 65326.63
Iteration:   2320, Loss function: 3.932, Average Loss: 4.379, avg. samples / sec: 65257.36
Iteration:   2320, Loss function: 4.469, Average Loss: 4.382, avg. samples / sec: 65250.35
Iteration:   2320, Loss function: 3.784, Average Loss: 4.329, avg. samples / sec: 65281.12
Iteration:   2320, Loss function: 4.639, Average Loss: 4.382, avg. samples / sec: 65200.63
Iteration:   2320, Loss function: 4.161, Average Loss: 4.374, avg. samples / sec: 65146.20
Iteration:   2320, Loss function: 3.884, Average Loss: 4.374, avg. samples / sec: 65192.39
Iteration:   2320, Loss function: 4.797, Average Loss: 4.344, avg. samples / sec: 65268.45
Iteration:   2320, Loss function: 4.519, Average Loss: 4.392, avg. samples / sec: 65129.12
Iteration:   2320, Loss function: 5.237, Average Loss: 4.344, avg. samples / sec: 65338.08
Iteration:   2320, Loss function: 4.052, Average Loss: 4.363, avg. samples / sec: 65252.73
Iteration:   2320, Loss function: 4.649, Average Loss: 4.342, avg. samples / sec: 65153.79
Iteration:   2320, Loss function: 4.833, Average Loss: 4.348, avg. samples / sec: 65225.73
Iteration:   2320, Loss function: 4.245, Average Loss: 4.373, avg. samples / sec: 65265.76
Iteration:   2340, Loss function: 4.500, Average Loss: 4.369, avg. samples / sec: 66118.41
Iteration:   2340, Loss function: 3.451, Average Loss: 4.376, avg. samples / sec: 66120.58
Iteration:   2340, Loss function: 4.493, Average Loss: 4.372, avg. samples / sec: 66086.82
Iteration:   2340, Loss function: 4.807, Average Loss: 4.344, avg. samples / sec: 66074.86
Iteration:   2340, Loss function: 4.170, Average Loss: 4.339, avg. samples / sec: 66111.28
Iteration:   2340, Loss function: 3.968, Average Loss: 4.385, avg. samples / sec: 66112.67
Iteration:   2340, Loss function: 5.155, Average Loss: 4.347, avg. samples / sec: 66080.65
Iteration:   2340, Loss function: 3.142, Average Loss: 4.384, avg. samples / sec: 65965.65
Iteration:   2340, Loss function: 5.047, Average Loss: 4.351, avg. samples / sec: 66033.06
Iteration:   2340, Loss function: 4.059, Average Loss: 4.335, avg. samples / sec: 65944.44
Iteration:   2340, Loss function: 4.508, Average Loss: 4.366, avg. samples / sec: 66072.87
Iteration:   2340, Loss function: 4.820, Average Loss: 4.375, avg. samples / sec: 66032.44
Iteration:   2340, Loss function: 3.448, Average Loss: 4.358, avg. samples / sec: 65948.98
Iteration:   2340, Loss function: 4.318, Average Loss: 4.375, avg. samples / sec: 66061.94
Iteration:   2340, Loss function: 3.376, Average Loss: 4.364, avg. samples / sec: 65950.37
Iteration:   2340, Loss function: 3.831, Average Loss: 4.333, avg. samples / sec: 65954.81
Iteration:   2340, Loss function: 4.992, Average Loss: 4.345, avg. samples / sec: 65982.88
Iteration:   2340, Loss function: 4.474, Average Loss: 4.371, avg. samples / sec: 65996.14
Iteration:   2340, Loss function: 3.189, Average Loss: 4.343, avg. samples / sec: 65966.30
Iteration:   2340, Loss function: 3.119, Average Loss: 4.365, avg. samples / sec: 65920.07
Iteration:   2340, Loss function: 3.081, Average Loss: 4.342, avg. samples / sec: 65927.01
Iteration:   2340, Loss function: 5.424, Average Loss: 4.357, avg. samples / sec: 65986.47
Iteration:   2340, Loss function: 4.420, Average Loss: 4.339, avg. samples / sec: 66015.71
Iteration:   2340, Loss function: 3.267, Average Loss: 4.379, avg. samples / sec: 65950.74
Iteration:   2340, Loss function: 3.902, Average Loss: 4.364, avg. samples / sec: 66049.55
Iteration:   2340, Loss function: 4.072, Average Loss: 4.339, avg. samples / sec: 65951.97
Iteration:   2340, Loss function: 3.539, Average Loss: 4.329, avg. samples / sec: 65942.87
Iteration:   2340, Loss function: 3.189, Average Loss: 4.350, avg. samples / sec: 65925.62
Iteration:   2340, Loss function: 4.507, Average Loss: 4.341, avg. samples / sec: 66004.58
Iteration:   2340, Loss function: 3.945, Average Loss: 4.336, avg. samples / sec: 65805.66
Iteration:   2360, Loss function: 3.795, Average Loss: 4.354, avg. samples / sec: 66183.37
Iteration:   2360, Loss function: 4.805, Average Loss: 4.369, avg. samples / sec: 65978.43
Iteration:   2360, Loss function: 3.299, Average Loss: 4.368, avg. samples / sec: 65968.46
Iteration:   2360, Loss function: 4.076, Average Loss: 4.350, avg. samples / sec: 66037.48
Iteration:   2360, Loss function: 3.794, Average Loss: 4.331, avg. samples / sec: 66034.30
Iteration:   2360, Loss function: 4.172, Average Loss: 4.333, avg. samples / sec: 65963.58
Iteration:   2360, Loss function: 4.380, Average Loss: 4.367, avg. samples / sec: 65934.38
Iteration:   2360, Loss function: 3.755, Average Loss: 4.359, avg. samples / sec: 65983.69
Iteration:   2360, Loss function: 3.808, Average Loss: 4.360, avg. samples / sec: 65999.88
Iteration:   2360, Loss function: 3.825, Average Loss: 4.334, avg. samples / sec: 66061.60
Iteration:   2360, Loss function: 4.693, Average Loss: 4.339, avg. samples / sec: 66002.57
Iteration:   2360, Loss function: 5.350, Average Loss: 4.359, avg. samples / sec: 66047.57
Iteration:   2360, Loss function: 3.516, Average Loss: 4.343, avg. samples / sec: 65921.68
Iteration:   2360, Loss function: 3.705, Average Loss: 4.361, avg. samples / sec: 65962.62
Iteration:   2360, Loss function: 4.741, Average Loss: 4.330, avg. samples / sec: 65916.47
Iteration:   2360, Loss function: 5.054, Average Loss: 4.370, avg. samples / sec: 65936.02
Iteration:   2360, Loss function: 3.453, Average Loss: 4.381, avg. samples / sec: 65855.14
Iteration:   2360, Loss function: 3.782, Average Loss: 4.371, avg. samples / sec: 65988.10
Iteration:   2360, Loss function: 3.441, Average Loss: 4.349, avg. samples / sec: 65848.95
Iteration:   2360, Loss function: 4.300, Average Loss: 4.376, avg. samples / sec: 65868.65
Iteration:   2360, Loss function: 4.131, Average Loss: 4.331, avg. samples / sec: 65949.41
Iteration:   2360, Loss function: 4.328, Average Loss: 4.339, avg. samples / sec: 65910.52
Iteration:   2360, Loss function: 4.461, Average Loss: 4.346, avg. samples / sec: 65980.69
Iteration:   2360, Loss function: 2.992, Average Loss: 4.339, avg. samples / sec: 65917.73
Iteration:   2360, Loss function: 3.375, Average Loss: 4.330, avg. samples / sec: 65970.65
Iteration:   2360, Loss function: 3.897, Average Loss: 4.370, avg. samples / sec: 65773.72
Iteration:   2360, Loss function: 5.225, Average Loss: 4.372, avg. samples / sec: 65766.75
Iteration:   2360, Loss function: 4.968, Average Loss: 4.335, avg. samples / sec: 65888.70
Iteration:   2360, Loss function: 2.978, Average Loss: 4.334, avg. samples / sec: 65676.67
Iteration:   2360, Loss function: 3.700, Average Loss: 4.334, avg. samples / sec: 65893.41
:::MLL 1558651421.966 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558651421.966 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 3.840, Average Loss: 4.333, avg. samples / sec: 65693.08
Iteration:   2380, Loss function: 3.824, Average Loss: 4.339, avg. samples / sec: 65748.53
Iteration:   2380, Loss function: 4.236, Average Loss: 4.364, avg. samples / sec: 65564.14
Iteration:   2380, Loss function: 3.659, Average Loss: 4.335, avg. samples / sec: 65741.47
Iteration:   2380, Loss function: 2.771, Average Loss: 4.363, avg. samples / sec: 65541.21
Iteration:   2380, Loss function: 3.659, Average Loss: 4.362, avg. samples / sec: 65583.27
Iteration:   2380, Loss function: 4.545, Average Loss: 4.379, avg. samples / sec: 65636.97
Iteration:   2380, Loss function: 2.869, Average Loss: 4.330, avg. samples / sec: 65740.77
Iteration:   2380, Loss function: 4.352, Average Loss: 4.356, avg. samples / sec: 65511.87
Iteration:   2380, Loss function: 3.989, Average Loss: 4.371, avg. samples / sec: 65741.60
Iteration:   2380, Loss function: 4.343, Average Loss: 4.329, avg. samples / sec: 65759.79
Iteration:   2380, Loss function: 4.204, Average Loss: 4.344, avg. samples / sec: 65468.26
Iteration:   2380, Loss function: 5.075, Average Loss: 4.336, avg. samples / sec: 65557.49
Iteration:   2380, Loss function: 4.954, Average Loss: 4.348, avg. samples / sec: 65383.40
Iteration:   2380, Loss function: 4.374, Average Loss: 4.366, avg. samples / sec: 65593.01
Iteration:   2380, Loss function: 4.334, Average Loss: 4.331, avg. samples / sec: 65607.24
Iteration:   2380, Loss function: 3.190, Average Loss: 4.329, avg. samples / sec: 65436.89
Iteration:   2380, Loss function: 4.081, Average Loss: 4.362, avg. samples / sec: 65480.12
Iteration:   2380, Loss function: 4.266, Average Loss: 4.356, avg. samples / sec: 65700.31
Iteration:   2380, Loss function: 3.609, Average Loss: 4.341, avg. samples / sec: 65555.88
Iteration:   2380, Loss function: 4.376, Average Loss: 4.326, avg. samples / sec: 65510.29
Iteration:   2380, Loss function: 3.924, Average Loss: 4.325, avg. samples / sec: 65556.64
Iteration:   2380, Loss function: 4.242, Average Loss: 4.335, avg. samples / sec: 65527.35
Iteration:   2380, Loss function: 4.245, Average Loss: 4.352, avg. samples / sec: 65471.94
Iteration:   2380, Loss function: 3.350, Average Loss: 4.357, avg. samples / sec: 65420.91
Iteration:   2380, Loss function: 4.676, Average Loss: 4.376, avg. samples / sec: 65479.15
Iteration:   2380, Loss function: 4.143, Average Loss: 4.329, avg. samples / sec: 65621.84
Iteration:   2380, Loss function: 4.858, Average Loss: 4.364, avg. samples / sec: 65430.90
Iteration:   2380, Loss function: 3.677, Average Loss: 4.329, avg. samples / sec: 65309.77
Iteration:   2380, Loss function: 3.688, Average Loss: 4.330, avg. samples / sec: 65305.56
Iteration:   2400, Loss function: 3.272, Average Loss: 4.326, avg. samples / sec: 65731.63
Iteration:   2400, Loss function: 2.998, Average Loss: 4.360, avg. samples / sec: 65801.39
Iteration:   2400, Loss function: 3.558, Average Loss: 4.357, avg. samples / sec: 65685.55
Iteration:   2400, Loss function: 4.393, Average Loss: 4.337, avg. samples / sec: 65799.30
Iteration:   2400, Loss function: 4.239, Average Loss: 4.373, avg. samples / sec: 65917.67
Iteration:   2400, Loss function: 4.578, Average Loss: 4.367, avg. samples / sec: 65743.19
Iteration:   2400, Loss function: 4.475, Average Loss: 4.360, avg. samples / sec: 65652.08
Iteration:   2400, Loss function: 3.096, Average Loss: 4.329, avg. samples / sec: 65702.55
Iteration:   2400, Loss function: 5.004, Average Loss: 4.321, avg. samples / sec: 65818.26
Iteration:   2400, Loss function: 4.044, Average Loss: 4.326, avg. samples / sec: 65732.79
Iteration:   2400, Loss function: 4.074, Average Loss: 4.320, avg. samples / sec: 65818.20
Iteration:   2400, Loss function: 3.868, Average Loss: 4.324, avg. samples / sec: 65853.97
Iteration:   2400, Loss function: 3.239, Average Loss: 4.324, avg. samples / sec: 65702.15
Iteration:   2400, Loss function: 4.157, Average Loss: 4.325, avg. samples / sec: 65876.29
Iteration:   2400, Loss function: 3.522, Average Loss: 4.354, avg. samples / sec: 65616.40
Iteration:   2400, Loss function: 5.486, Average Loss: 4.341, avg. samples / sec: 65551.73
Iteration:   2400, Loss function: 3.836, Average Loss: 4.349, avg. samples / sec: 65809.47
Iteration:   2400, Loss function: 3.638, Average Loss: 4.338, avg. samples / sec: 65766.81
Iteration:   2400, Loss function: 3.074, Average Loss: 4.367, avg. samples / sec: 65843.17
Iteration:   2400, Loss function: 4.293, Average Loss: 4.360, avg. samples / sec: 65687.63
Iteration:   2400, Loss function: 3.534, Average Loss: 4.346, avg. samples / sec: 65793.19
Iteration:   2400, Loss function: 4.929, Average Loss: 4.348, avg. samples / sec: 65663.15
Iteration:   2400, Loss function: 4.827, Average Loss: 4.354, avg. samples / sec: 65645.10
Iteration:   2400, Loss function: 3.713, Average Loss: 4.345, avg. samples / sec: 65642.99
Iteration:   2400, Loss function: 3.514, Average Loss: 4.326, avg. samples / sec: 65842.74
Iteration:   2400, Loss function: 2.707, Average Loss: 4.329, avg. samples / sec: 65431.97
Iteration:   2400, Loss function: 2.491, Average Loss: 4.326, avg. samples / sec: 65614.05
Iteration:   2400, Loss function: 5.423, Average Loss: 4.374, avg. samples / sec: 65467.10
Iteration:   2400, Loss function: 3.071, Average Loss: 4.334, avg. samples / sec: 65503.47
Iteration:   2400, Loss function: 3.918, Average Loss: 4.352, avg. samples / sec: 65489.07
Iteration:   2420, Loss function: 4.853, Average Loss: 4.345, avg. samples / sec: 66172.86
Iteration:   2420, Loss function: 4.686, Average Loss: 4.323, avg. samples / sec: 66144.35
Iteration:   2420, Loss function: 4.409, Average Loss: 4.349, avg. samples / sec: 66121.17
Iteration:   2420, Loss function: 3.423, Average Loss: 4.368, avg. samples / sec: 66291.58
Iteration:   2420, Loss function: 3.893, Average Loss: 4.320, avg. samples / sec: 65964.01
Iteration:   2420, Loss function: 4.079, Average Loss: 4.365, avg. samples / sec: 66005.94
Iteration:   2420, Loss function: 4.897, Average Loss: 4.341, avg. samples / sec: 66091.50
Iteration:   2420, Loss function: 4.359, Average Loss: 4.329, avg. samples / sec: 66256.40
Iteration:   2420, Loss function: 6.085, Average Loss: 4.354, avg. samples / sec: 65985.45
Iteration:   2420, Loss function: 3.614, Average Loss: 4.325, avg. samples / sec: 66157.27
Iteration:   2420, Loss function: 3.553, Average Loss: 4.317, avg. samples / sec: 66033.00
Iteration:   2420, Loss function: 3.722, Average Loss: 4.355, avg. samples / sec: 66066.86
Iteration:   2420, Loss function: 4.581, Average Loss: 4.321, avg. samples / sec: 66021.64
Iteration:   2420, Loss function: 4.104, Average Loss: 4.355, avg. samples / sec: 65943.61
Iteration:   2420, Loss function: 4.303, Average Loss: 4.334, avg. samples / sec: 65915.97
Iteration:   2420, Loss function: 3.904, Average Loss: 4.343, avg. samples / sec: 66061.23
Iteration:   2420, Loss function: 4.257, Average Loss: 4.325, avg. samples / sec: 65982.70
Iteration:   2420, Loss function: 3.493, Average Loss: 4.334, avg. samples / sec: 66009.37
Iteration:   2420, Loss function: 4.930, Average Loss: 4.321, avg. samples / sec: 65971.82
Iteration:   2420, Loss function: 4.062, Average Loss: 4.341, avg. samples / sec: 65978.46
Iteration:   2420, Loss function: 4.759, Average Loss: 4.358, avg. samples / sec: 65902.60
Iteration:   2420, Loss function: 5.077, Average Loss: 4.316, avg. samples / sec: 65932.32
Iteration:   2420, Loss function: 4.303, Average Loss: 4.346, avg. samples / sec: 66182.25
Iteration:   2420, Loss function: 5.749, Average Loss: 4.344, avg. samples / sec: 65966.08
Iteration:   2420, Loss function: 5.149, Average Loss: 4.347, avg. samples / sec: 65949.90
Iteration:   2420, Loss function: 4.496, Average Loss: 4.327, avg. samples / sec: 66087.68
Iteration:   2420, Loss function: 4.554, Average Loss: 4.322, avg. samples / sec: 65873.02
Iteration:   2420, Loss function: 4.490, Average Loss: 4.323, avg. samples / sec: 65959.94
Iteration:   2420, Loss function: 3.913, Average Loss: 4.360, avg. samples / sec: 65798.07
Iteration:   2420, Loss function: 4.607, Average Loss: 4.365, avg. samples / sec: 65849.29
Iteration:   2440, Loss function: 4.305, Average Loss: 4.362, avg. samples / sec: 65702.15
Iteration:   2440, Loss function: 3.698, Average Loss: 4.310, avg. samples / sec: 65809.53
Iteration:   2440, Loss function: 4.613, Average Loss: 4.338, avg. samples / sec: 65693.73
Iteration:   2440, Loss function: 5.691, Average Loss: 4.355, avg. samples / sec: 65687.51
Iteration:   2440, Loss function: 4.091, Average Loss: 4.314, avg. samples / sec: 65631.53
Iteration:   2440, Loss function: 4.257, Average Loss: 4.338, avg. samples / sec: 65728.99
Iteration:   2440, Loss function: 4.479, Average Loss: 4.341, avg. samples / sec: 65754.85
Iteration:   2440, Loss function: 4.320, Average Loss: 4.333, avg. samples / sec: 65765.71
Iteration:   2440, Loss function: 3.991, Average Loss: 4.312, avg. samples / sec: 65656.60
Iteration:   2440, Loss function: 4.640, Average Loss: 4.327, avg. samples / sec: 65784.90
Iteration:   2440, Loss function: 2.690, Average Loss: 4.321, avg. samples / sec: 65645.81
Iteration:   2440, Loss function: 4.340, Average Loss: 4.362, avg. samples / sec: 65858.56
Iteration:   2440, Loss function: 4.088, Average Loss: 4.344, avg. samples / sec: 65561.70
Iteration:   2440, Loss function: 4.517, Average Loss: 4.352, avg. samples / sec: 65715.08
Iteration:   2440, Loss function: 4.392, Average Loss: 4.352, avg. samples / sec: 65810.24
Iteration:   2440, Loss function: 4.481, Average Loss: 4.324, avg. samples / sec: 65662.32
Iteration:   2440, Loss function: 6.465, Average Loss: 4.363, avg. samples / sec: 65571.07
Iteration:   2440, Loss function: 4.174, Average Loss: 4.321, avg. samples / sec: 65520.67
Iteration:   2440, Loss function: 2.951, Average Loss: 4.327, avg. samples / sec: 65644.00
Iteration:   2440, Loss function: 4.195, Average Loss: 4.352, avg. samples / sec: 65610.87
Iteration:   2440, Loss function: 3.490, Average Loss: 4.351, avg. samples / sec: 65614.75
Iteration:   2440, Loss function: 4.743, Average Loss: 4.325, avg. samples / sec: 65567.47
Iteration:   2440, Loss function: 3.343, Average Loss: 4.319, avg. samples / sec: 65758.59
Iteration:   2440, Loss function: 3.336, Average Loss: 4.338, avg. samples / sec: 65685.71
Iteration:   2440, Loss function: 3.564, Average Loss: 4.339, avg. samples / sec: 65719.37
Iteration:   2440, Loss function: 4.294, Average Loss: 4.331, avg. samples / sec: 65618.51
Iteration:   2440, Loss function: 4.123, Average Loss: 4.317, avg. samples / sec: 65561.64
Iteration:   2440, Loss function: 5.183, Average Loss: 4.320, avg. samples / sec: 65513.42
Iteration:   2440, Loss function: 4.677, Average Loss: 4.321, avg. samples / sec: 65636.51
Iteration:   2440, Loss function: 5.347, Average Loss: 4.341, avg. samples / sec: 65399.17
:::MLL 1558651423.757 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558651423.757 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.858, Average Loss: 4.349, avg. samples / sec: 65143.64
Iteration:   2460, Loss function: 3.404, Average Loss: 4.305, avg. samples / sec: 65156.56
Iteration:   2460, Loss function: 3.902, Average Loss: 4.332, avg. samples / sec: 65222.87
Iteration:   2460, Loss function: 3.605, Average Loss: 4.321, avg. samples / sec: 65147.61
Iteration:   2460, Loss function: 3.901, Average Loss: 4.363, avg. samples / sec: 65047.87
Iteration:   2460, Loss function: 3.779, Average Loss: 4.313, avg. samples / sec: 65297.69
Iteration:   2460, Loss function: 4.876, Average Loss: 4.306, avg. samples / sec: 65083.47
Iteration:   2460, Loss function: 5.368, Average Loss: 4.319, avg. samples / sec: 65190.89
Iteration:   2460, Loss function: 3.780, Average Loss: 4.350, avg. samples / sec: 65165.81
Iteration:   2460, Loss function: 3.404, Average Loss: 4.340, avg. samples / sec: 65284.87
Iteration:   2460, Loss function: 3.898, Average Loss: 4.338, avg. samples / sec: 65115.16
Iteration:   2460, Loss function: 5.004, Average Loss: 4.330, avg. samples / sec: 65063.58
Iteration:   2460, Loss function: 3.742, Average Loss: 4.339, avg. samples / sec: 65142.67
Iteration:   2460, Loss function: 3.320, Average Loss: 4.356, avg. samples / sec: 65139.75
Iteration:   2460, Loss function: 3.703, Average Loss: 4.342, avg. samples / sec: 65147.10
Iteration:   2460, Loss function: 4.217, Average Loss: 4.322, avg. samples / sec: 65260.50
Iteration:   2460, Loss function: 2.979, Average Loss: 4.352, avg. samples / sec: 65137.46
Iteration:   2460, Loss function: 3.498, Average Loss: 4.333, avg. samples / sec: 65163.40
Iteration:   2460, Loss function: 3.174, Average Loss: 4.355, avg. samples / sec: 65101.93
Iteration:   2460, Loss function: 4.121, Average Loss: 4.324, avg. samples / sec: 65158.06
Iteration:   2460, Loss function: 3.541, Average Loss: 4.317, avg. samples / sec: 65198.49
Iteration:   2460, Loss function: 5.402, Average Loss: 4.321, avg. samples / sec: 65105.02
Iteration:   2460, Loss function: 3.403, Average Loss: 4.330, avg. samples / sec: 64983.71
Iteration:   2460, Loss function: 3.603, Average Loss: 4.308, avg. samples / sec: 65019.27
Iteration:   2460, Loss function: 4.848, Average Loss: 4.318, avg. samples / sec: 65017.11
Iteration:   2460, Loss function: 4.231, Average Loss: 4.316, avg. samples / sec: 65024.91
Iteration:   2460, Loss function: 4.808, Average Loss: 4.344, avg. samples / sec: 65042.43
Iteration:   2460, Loss function: 4.866, Average Loss: 4.324, avg. samples / sec: 65047.00
Iteration:   2460, Loss function: 5.776, Average Loss: 4.329, avg. samples / sec: 64955.26
Iteration:   2460, Loss function: 4.721, Average Loss: 4.321, avg. samples / sec: 65005.74
Iteration:   2480, Loss function: 3.981, Average Loss: 4.346, avg. samples / sec: 65839.17
Iteration:   2480, Loss function: 3.543, Average Loss: 4.300, avg. samples / sec: 65770.62
Iteration:   2480, Loss function: 4.556, Average Loss: 4.344, avg. samples / sec: 65749.05
Iteration:   2480, Loss function: 3.525, Average Loss: 4.326, avg. samples / sec: 65810.42
Iteration:   2480, Loss function: 4.032, Average Loss: 4.342, avg. samples / sec: 65795.71
Iteration:   2480, Loss function: 3.007, Average Loss: 4.313, avg. samples / sec: 65898.03
Iteration:   2480, Loss function: 4.007, Average Loss: 4.323, avg. samples / sec: 65906.17
Iteration:   2480, Loss function: 3.757, Average Loss: 4.307, avg. samples / sec: 65852.34
Iteration:   2480, Loss function: 5.191, Average Loss: 4.309, avg. samples / sec: 65721.91
Iteration:   2480, Loss function: 4.512, Average Loss: 4.347, avg. samples / sec: 65752.09
Iteration:   2480, Loss function: 5.274, Average Loss: 4.348, avg. samples / sec: 65752.79
Iteration:   2480, Loss function: 3.422, Average Loss: 4.311, avg. samples / sec: 65717.87
Iteration:   2480, Loss function: 3.602, Average Loss: 4.323, avg. samples / sec: 65685.89
Iteration:   2480, Loss function: 4.842, Average Loss: 4.337, avg. samples / sec: 65724.92
Iteration:   2480, Loss function: 3.975, Average Loss: 4.335, avg. samples / sec: 65709.04
Iteration:   2480, Loss function: 3.772, Average Loss: 4.315, avg. samples / sec: 65780.84
Iteration:   2480, Loss function: 4.772, Average Loss: 4.358, avg. samples / sec: 65675.42
Iteration:   2480, Loss function: 2.922, Average Loss: 4.338, avg. samples / sec: 65810.49
Iteration:   2480, Loss function: 4.016, Average Loss: 4.323, avg. samples / sec: 65772.52
Iteration:   2480, Loss function: 4.910, Average Loss: 4.304, avg. samples / sec: 65759.66
Iteration:   2480, Loss function: 3.955, Average Loss: 4.310, avg. samples / sec: 65726.45
Iteration:   2480, Loss function: 3.533, Average Loss: 4.325, avg. samples / sec: 65655.84
Iteration:   2480, Loss function: 3.832, Average Loss: 4.311, avg. samples / sec: 65692.26
Iteration:   2480, Loss function: 4.126, Average Loss: 4.299, avg. samples / sec: 65584.25
Iteration:   2480, Loss function: 4.047, Average Loss: 4.329, avg. samples / sec: 65577.11
Iteration:   2480, Loss function: 3.686, Average Loss: 4.346, avg. samples / sec: 65622.06
Iteration:   2480, Loss function: 4.913, Average Loss: 4.332, avg. samples / sec: 65584.83
Iteration:   2480, Loss function: 3.674, Average Loss: 4.312, avg. samples / sec: 65709.56
Iteration:   2480, Loss function: 3.917, Average Loss: 4.318, avg. samples / sec: 65605.22
Iteration:   2480, Loss function: 4.253, Average Loss: 4.319, avg. samples / sec: 65714.80
Iteration:   2500, Loss function: 3.430, Average Loss: 4.336, avg. samples / sec: 65944.01
Iteration:   2500, Loss function: 3.920, Average Loss: 4.317, avg. samples / sec: 65971.61
Iteration:   2500, Loss function: 4.123, Average Loss: 4.343, avg. samples / sec: 65712.54
Iteration:   2500, Loss function: 3.313, Average Loss: 4.311, avg. samples / sec: 65971.33
Iteration:   2500, Loss function: 3.650, Average Loss: 4.316, avg. samples / sec: 65794.48
Iteration:   2500, Loss function: 3.602, Average Loss: 4.312, avg. samples / sec: 65786.71
Iteration:   2500, Loss function: 3.193, Average Loss: 4.320, avg. samples / sec: 65919.43
Iteration:   2500, Loss function: 4.154, Average Loss: 4.358, avg. samples / sec: 65853.42
Iteration:   2500, Loss function: 4.223, Average Loss: 4.343, avg. samples / sec: 65784.80
Iteration:   2500, Loss function: 3.869, Average Loss: 4.334, avg. samples / sec: 65793.53
Iteration:   2500, Loss function: 3.923, Average Loss: 4.324, avg. samples / sec: 65686.10
Iteration:   2500, Loss function: 3.185, Average Loss: 4.308, avg. samples / sec: 65938.80
Iteration:   2500, Loss function: 3.916, Average Loss: 4.301, avg. samples / sec: 65848.09
Iteration:   2500, Loss function: 2.997, Average Loss: 4.341, avg. samples / sec: 65832.90
Iteration:   2500, Loss function: 3.485, Average Loss: 4.317, avg. samples / sec: 65796.94
Iteration:   2500, Loss function: 4.459, Average Loss: 4.299, avg. samples / sec: 65655.93
Iteration:   2500, Loss function: 3.966, Average Loss: 4.325, avg. samples / sec: 65895.75
Iteration:   2500, Loss function: 4.422, Average Loss: 4.341, avg. samples / sec: 65661.68
Iteration:   2500, Loss function: 5.267, Average Loss: 4.290, avg. samples / sec: 65866.03
Iteration:   2500, Loss function: 3.088, Average Loss: 4.303, avg. samples / sec: 65725.90
Iteration:   2500, Loss function: 3.837, Average Loss: 4.337, avg. samples / sec: 65698.90
Iteration:   2500, Loss function: 4.758, Average Loss: 4.311, avg. samples / sec: 65748.01
Iteration:   2500, Loss function: 3.884, Average Loss: 4.319, avg. samples / sec: 65894.58
Iteration:   2500, Loss function: 5.616, Average Loss: 4.309, avg. samples / sec: 65844.00
Iteration:   2500, Loss function: 4.917, Average Loss: 4.317, avg. samples / sec: 65732.70
Iteration:   2500, Loss function: 4.054, Average Loss: 4.341, avg. samples / sec: 65691.92
Iteration:   2500, Loss function: 3.554, Average Loss: 4.301, avg. samples / sec: 65767.70
Iteration:   2500, Loss function: 4.181, Average Loss: 4.320, avg. samples / sec: 65807.04
Iteration:   2500, Loss function: 3.993, Average Loss: 4.309, avg. samples / sec: 65672.42
Iteration:   2500, Loss function: 4.426, Average Loss: 4.337, avg. samples / sec: 65793.19
:::MLL 1558651425.549 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558651425.549 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 4.557, Average Loss: 4.305, avg. samples / sec: 65613.90
Iteration:   2520, Loss function: 4.018, Average Loss: 4.317, avg. samples / sec: 65623.31
Iteration:   2520, Loss function: 3.524, Average Loss: 4.308, avg. samples / sec: 65445.76
Iteration:   2520, Loss function: 3.684, Average Loss: 4.303, avg. samples / sec: 65620.86
Iteration:   2520, Loss function: 3.971, Average Loss: 4.340, avg. samples / sec: 65501.03
Iteration:   2520, Loss function: 3.135, Average Loss: 4.316, avg. samples / sec: 65502.77
Iteration:   2520, Loss function: 3.568, Average Loss: 4.315, avg. samples / sec: 65508.31
Iteration:   2520, Loss function: 4.262, Average Loss: 4.317, avg. samples / sec: 65550.36
Iteration:   2520, Loss function: 5.200, Average Loss: 4.354, avg. samples / sec: 65479.48
Iteration:   2520, Loss function: 3.879, Average Loss: 4.291, avg. samples / sec: 65511.90
Iteration:   2520, Loss function: 3.501, Average Loss: 4.305, avg. samples / sec: 65497.93
Iteration:   2520, Loss function: 4.742, Average Loss: 4.334, avg. samples / sec: 65532.95
Iteration:   2520, Loss function: 2.689, Average Loss: 4.292, avg. samples / sec: 65493.51
Iteration:   2520, Loss function: 3.603, Average Loss: 4.331, avg. samples / sec: 65487.03
Iteration:   2520, Loss function: 3.957, Average Loss: 4.334, avg. samples / sec: 65536.49
Iteration:   2520, Loss function: 4.201, Average Loss: 4.343, avg. samples / sec: 65424.56
Iteration:   2520, Loss function: 3.864, Average Loss: 4.298, avg. samples / sec: 65536.40
Iteration:   2520, Loss function: 3.536, Average Loss: 4.306, avg. samples / sec: 65494.40
Iteration:   2520, Loss function: 4.982, Average Loss: 4.331, avg. samples / sec: 65433.79
Iteration:   2520, Loss function: 3.591, Average Loss: 4.311, avg. samples / sec: 65431.15
Iteration:   2520, Loss function: 3.488, Average Loss: 4.312, avg. samples / sec: 65476.14
Iteration:   2520, Loss function: 4.499, Average Loss: 4.318, avg. samples / sec: 65464.70
Iteration:   2520, Loss function: 3.001, Average Loss: 4.296, avg. samples / sec: 65463.12
Iteration:   2520, Loss function: 3.768, Average Loss: 4.331, avg. samples / sec: 65255.64
Iteration:   2520, Loss function: 3.485, Average Loss: 4.302, avg. samples / sec: 65486.67
Iteration:   2520, Loss function: 5.929, Average Loss: 4.316, avg. samples / sec: 65480.67
Iteration:   2520, Loss function: 3.620, Average Loss: 4.329, avg. samples / sec: 65395.23
Iteration:   2520, Loss function: 4.706, Average Loss: 4.308, avg. samples / sec: 65306.62
Iteration:   2520, Loss function: 5.253, Average Loss: 4.330, avg. samples / sec: 65445.94
Iteration:   2520, Loss function: 4.299, Average Loss: 4.282, avg. samples / sec: 65256.54
Iteration:   2540, Loss function: 2.852, Average Loss: 4.335, avg. samples / sec: 65811.81
Iteration:   2540, Loss function: 3.522, Average Loss: 4.328, avg. samples / sec: 65896.49
Iteration:   2540, Loss function: 5.061, Average Loss: 4.307, avg. samples / sec: 65904.07
Iteration:   2540, Loss function: 3.805, Average Loss: 4.314, avg. samples / sec: 65793.65
Iteration:   2540, Loss function: 4.539, Average Loss: 4.342, avg. samples / sec: 65854.59
Iteration:   2540, Loss function: 4.386, Average Loss: 4.294, avg. samples / sec: 65836.31
Iteration:   2540, Loss function: 2.896, Average Loss: 4.327, avg. samples / sec: 65797.95
Iteration:   2540, Loss function: 2.680, Average Loss: 4.303, avg. samples / sec: 65919.83
Iteration:   2540, Loss function: 4.432, Average Loss: 4.327, avg. samples / sec: 65824.81
Iteration:   2540, Loss function: 2.881, Average Loss: 4.323, avg. samples / sec: 65838.83
Iteration:   2540, Loss function: 4.467, Average Loss: 4.300, avg. samples / sec: 65685.18
Iteration:   2540, Loss function: 4.511, Average Loss: 4.312, avg. samples / sec: 65716.09
Iteration:   2540, Loss function: 4.479, Average Loss: 4.299, avg. samples / sec: 65609.41
Iteration:   2540, Loss function: 4.152, Average Loss: 4.309, avg. samples / sec: 65846.71
Iteration:   2540, Loss function: 4.040, Average Loss: 4.326, avg. samples / sec: 65850.25
Iteration:   2540, Loss function: 4.342, Average Loss: 4.287, avg. samples / sec: 65736.96
Iteration:   2540, Loss function: 3.860, Average Loss: 4.308, avg. samples / sec: 65645.53
Iteration:   2540, Loss function: 3.256, Average Loss: 4.295, avg. samples / sec: 65798.35
Iteration:   2540, Loss function: 4.558, Average Loss: 4.328, avg. samples / sec: 65819.52
Iteration:   2540, Loss function: 3.552, Average Loss: 4.300, avg. samples / sec: 65711.98
Iteration:   2540, Loss function: 3.353, Average Loss: 4.314, avg. samples / sec: 65669.27
Iteration:   2540, Loss function: 5.305, Average Loss: 4.347, avg. samples / sec: 65697.83
Iteration:   2540, Loss function: 4.184, Average Loss: 4.297, avg. samples / sec: 65759.76
Iteration:   2540, Loss function: 4.244, Average Loss: 4.314, avg. samples / sec: 65758.31
Iteration:   2540, Loss function: 3.114, Average Loss: 4.324, avg. samples / sec: 65875.61
Iteration:   2540, Loss function: 3.290, Average Loss: 4.308, avg. samples / sec: 65535.97
Iteration:   2540, Loss function: 3.494, Average Loss: 4.301, avg. samples / sec: 65719.98
Iteration:   2540, Loss function: 3.658, Average Loss: 4.298, avg. samples / sec: 65778.11
Iteration:   2540, Loss function: 4.233, Average Loss: 4.281, avg. samples / sec: 65929.60
Iteration:   2540, Loss function: 3.613, Average Loss: 4.303, avg. samples / sec: 65726.42
Iteration:   2560, Loss function: 3.879, Average Loss: 4.329, avg. samples / sec: 65995.03
Iteration:   2560, Loss function: 2.885, Average Loss: 4.317, avg. samples / sec: 65987.92
Iteration:   2560, Loss function: 4.555, Average Loss: 4.302, avg. samples / sec: 66103.71
Iteration:   2560, Loss function: 4.327, Average Loss: 4.335, avg. samples / sec: 65954.13
Iteration:   2560, Loss function: 3.992, Average Loss: 4.304, avg. samples / sec: 65919.73
Iteration:   2560, Loss function: 4.059, Average Loss: 4.289, avg. samples / sec: 65931.55
Iteration:   2560, Loss function: 4.020, Average Loss: 4.295, avg. samples / sec: 66091.65
Iteration:   2560, Loss function: 4.432, Average Loss: 4.318, avg. samples / sec: 65921.40
Iteration:   2560, Loss function: 5.573, Average Loss: 4.323, avg. samples / sec: 65989.31
Iteration:   2560, Loss function: 4.251, Average Loss: 4.309, avg. samples / sec: 65944.07
Iteration:   2560, Loss function: 4.777, Average Loss: 4.306, avg. samples / sec: 65874.19
Iteration:   2560, Loss function: 4.554, Average Loss: 4.325, avg. samples / sec: 65900.81
Iteration:   2560, Loss function: 4.690, Average Loss: 4.306, avg. samples / sec: 65926.43
Iteration:   2560, Loss function: 5.140, Average Loss: 4.294, avg. samples / sec: 66023.38
Iteration:   2560, Loss function: 4.075, Average Loss: 4.315, avg. samples / sec: 65997.84
Iteration:   2560, Loss function: 3.039, Average Loss: 4.341, avg. samples / sec: 65953.95
Iteration:   2560, Loss function: 3.193, Average Loss: 4.289, avg. samples / sec: 65966.79
Iteration:   2560, Loss function: 3.879, Average Loss: 4.324, avg. samples / sec: 65825.06
Iteration:   2560, Loss function: 3.812, Average Loss: 4.295, avg. samples / sec: 66036.06
Iteration:   2560, Loss function: 3.549, Average Loss: 4.309, avg. samples / sec: 65906.94
Iteration:   2560, Loss function: 3.349, Average Loss: 4.281, avg. samples / sec: 65880.08
Iteration:   2560, Loss function: 3.065, Average Loss: 4.292, avg. samples / sec: 65907.90
Iteration:   2560, Loss function: 4.972, Average Loss: 4.303, avg. samples / sec: 65885.43
Iteration:   2560, Loss function: 3.760, Average Loss: 4.318, avg. samples / sec: 65865.94
Iteration:   2560, Loss function: 4.489, Average Loss: 4.275, avg. samples / sec: 65945.86
Iteration:   2560, Loss function: 5.399, Average Loss: 4.298, avg. samples / sec: 65804.95
Iteration:   2560, Loss function: 4.330, Average Loss: 4.311, avg. samples / sec: 65897.23
Iteration:   2560, Loss function: 4.365, Average Loss: 4.297, avg. samples / sec: 65813.10
Iteration:   2560, Loss function: 4.437, Average Loss: 4.299, avg. samples / sec: 65823.52
Iteration:   2560, Loss function: 3.011, Average Loss: 4.292, avg. samples / sec: 65847.88
Iteration:   2580, Loss function: 3.949, Average Loss: 4.323, avg. samples / sec: 65955.95
Iteration:   2580, Loss function: 3.692, Average Loss: 4.312, avg. samples / sec: 66078.33
Iteration:   2580, Loss function: 4.192, Average Loss: 4.282, avg. samples / sec: 66222.09
Iteration:   2580, Loss function: 5.204, Average Loss: 4.300, avg. samples / sec: 66096.18
Iteration:   2580, Loss function: 3.572, Average Loss: 4.283, avg. samples / sec: 66000.62
Iteration:   2580, Loss function: 3.505, Average Loss: 4.303, avg. samples / sec: 66056.06
Iteration:   2580, Loss function: 3.683, Average Loss: 4.295, avg. samples / sec: 66157.08
Iteration:   2580, Loss function: 3.312, Average Loss: 4.294, avg. samples / sec: 66103.28
Iteration:   2580, Loss function: 4.125, Average Loss: 4.283, avg. samples / sec: 66025.94
Iteration:   2580, Loss function: 4.631, Average Loss: 4.318, avg. samples / sec: 66045.47
Iteration:   2580, Loss function: 4.586, Average Loss: 4.298, avg. samples / sec: 65937.35
Iteration:   2580, Loss function: 5.322, Average Loss: 4.293, avg. samples / sec: 65962.31
Iteration:   2580, Loss function: 4.215, Average Loss: 4.305, avg. samples / sec: 66116.27
Iteration:   2580, Loss function: 4.385, Average Loss: 4.287, avg. samples / sec: 66021.00
Iteration:   2580, Loss function: 3.279, Average Loss: 4.324, avg. samples / sec: 65960.18
Iteration:   2580, Loss function: 3.371, Average Loss: 4.317, avg. samples / sec: 65957.87
Iteration:   2580, Loss function: 4.796, Average Loss: 4.305, avg. samples / sec: 65937.50
Iteration:   2580, Loss function: 3.746, Average Loss: 4.288, avg. samples / sec: 66027.95
Iteration:   2580, Loss function: 3.971, Average Loss: 4.334, avg. samples / sec: 65976.02
Iteration:   2580, Loss function: 2.933, Average Loss: 4.305, avg. samples / sec: 66027.27
Iteration:   2580, Loss function: 4.531, Average Loss: 4.314, avg. samples / sec: 65959.50
Iteration:   2580, Loss function: 4.655, Average Loss: 4.302, avg. samples / sec: 65903.18
Iteration:   2580, Loss function: 4.470, Average Loss: 4.298, avg. samples / sec: 66065.41
Iteration:   2580, Loss function: 3.860, Average Loss: 4.293, avg. samples / sec: 66027.06
Iteration:   2580, Loss function: 3.071, Average Loss: 4.276, avg. samples / sec: 65996.69
Iteration:   2580, Loss function: 3.126, Average Loss: 4.327, avg. samples / sec: 65879.06
Iteration:   2580, Loss function: 3.731, Average Loss: 4.314, avg. samples / sec: 65829.21
Iteration:   2580, Loss function: 3.562, Average Loss: 4.264, avg. samples / sec: 66001.30
Iteration:   2580, Loss function: 2.999, Average Loss: 4.316, avg. samples / sec: 65946.39
Iteration:   2580, Loss function: 3.915, Average Loss: 4.295, avg. samples / sec: 65878.50
:::MLL 1558651427.337 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558651427.338 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 5.568, Average Loss: 4.280, avg. samples / sec: 65128.82
Iteration:   2600, Loss function: 3.345, Average Loss: 4.323, avg. samples / sec: 65174.06
Iteration:   2600, Loss function: 3.315, Average Loss: 4.308, avg. samples / sec: 65029.98
Iteration:   2600, Loss function: 3.271, Average Loss: 4.288, avg. samples / sec: 65066.25
Iteration:   2600, Loss function: 3.517, Average Loss: 4.290, avg. samples / sec: 65221.81
Iteration:   2600, Loss function: 3.886, Average Loss: 4.319, avg. samples / sec: 65136.26
Iteration:   2600, Loss function: 4.652, Average Loss: 4.319, avg. samples / sec: 64942.48
Iteration:   2600, Loss function: 2.874, Average Loss: 4.287, avg. samples / sec: 65048.38
Iteration:   2600, Loss function: 4.619, Average Loss: 4.278, avg. samples / sec: 65088.70
Iteration:   2600, Loss function: 4.831, Average Loss: 4.314, avg. samples / sec: 65187.75
Iteration:   2600, Loss function: 5.084, Average Loss: 4.304, avg. samples / sec: 65080.10
Iteration:   2600, Loss function: 3.783, Average Loss: 4.264, avg. samples / sec: 65120.31
Iteration:   2600, Loss function: 4.710, Average Loss: 4.329, avg. samples / sec: 65074.48
Iteration:   2600, Loss function: 6.960, Average Loss: 4.309, avg. samples / sec: 65112.30
Iteration:   2600, Loss function: 4.274, Average Loss: 4.291, avg. samples / sec: 65069.04
Iteration:   2600, Loss function: 4.573, Average Loss: 4.293, avg. samples / sec: 65065.41
Iteration:   2600, Loss function: 4.888, Average Loss: 4.292, avg. samples / sec: 64933.20
Iteration:   2600, Loss function: 3.631, Average Loss: 4.272, avg. samples / sec: 65058.77
Iteration:   2600, Loss function: 4.799, Average Loss: 4.302, avg. samples / sec: 64997.14
Iteration:   2600, Loss function: 3.256, Average Loss: 4.299, avg. samples / sec: 64911.13
Iteration:   2600, Loss function: 4.519, Average Loss: 4.301, avg. samples / sec: 65021.28
Iteration:   2600, Loss function: 3.498, Average Loss: 4.288, avg. samples / sec: 64986.86
Iteration:   2600, Loss function: 3.522, Average Loss: 4.310, avg. samples / sec: 65015.55
Iteration:   2600, Loss function: 3.781, Average Loss: 4.285, avg. samples / sec: 64984.67
Iteration:   2600, Loss function: 5.645, Average Loss: 4.312, avg. samples / sec: 64972.78
Iteration:   2600, Loss function: 3.143, Average Loss: 4.297, avg. samples / sec: 64988.60
Iteration:   2600, Loss function: 2.917, Average Loss: 4.307, avg. samples / sec: 64930.51
Iteration:   2600, Loss function: 3.983, Average Loss: 4.290, avg. samples / sec: 64915.04
Iteration:   2600, Loss function: 4.657, Average Loss: 4.276, avg. samples / sec: 64819.56
Iteration:   2600, Loss function: 4.003, Average Loss: 4.282, avg. samples / sec: 64884.38
Iteration:   2620, Loss function: 3.467, Average Loss: 4.276, avg. samples / sec: 66108.61
Iteration:   2620, Loss function: 3.481, Average Loss: 4.301, avg. samples / sec: 66155.78
Iteration:   2620, Loss function: 2.555, Average Loss: 4.312, avg. samples / sec: 66184.70
Iteration:   2620, Loss function: 4.293, Average Loss: 4.293, avg. samples / sec: 66329.96
Iteration:   2620, Loss function: 3.261, Average Loss: 4.296, avg. samples / sec: 66260.76
Iteration:   2620, Loss function: 3.387, Average Loss: 4.315, avg. samples / sec: 66154.48
Iteration:   2620, Loss function: 3.132, Average Loss: 4.294, avg. samples / sec: 66172.43
Iteration:   2620, Loss function: 4.542, Average Loss: 4.269, avg. samples / sec: 66188.12
Iteration:   2620, Loss function: 3.897, Average Loss: 4.299, avg. samples / sec: 66135.48
Iteration:   2620, Loss function: 4.132, Average Loss: 4.276, avg. samples / sec: 66116.58
Iteration:   2620, Loss function: 3.116, Average Loss: 4.284, avg. samples / sec: 66042.00
Iteration:   2620, Loss function: 4.174, Average Loss: 4.322, avg. samples / sec: 66125.82
Iteration:   2620, Loss function: 3.677, Average Loss: 4.303, avg. samples / sec: 66126.07
Iteration:   2620, Loss function: 3.179, Average Loss: 4.293, avg. samples / sec: 66168.70
Iteration:   2620, Loss function: 4.004, Average Loss: 4.305, avg. samples / sec: 66189.74
Iteration:   2620, Loss function: 3.963, Average Loss: 4.310, avg. samples / sec: 66069.87
Iteration:   2620, Loss function: 3.425, Average Loss: 4.281, avg. samples / sec: 66063.61
Iteration:   2620, Loss function: 3.647, Average Loss: 4.284, avg. samples / sec: 66124.12
Iteration:   2620, Loss function: 4.251, Average Loss: 4.310, avg. samples / sec: 66152.71
Iteration:   2620, Loss function: 4.512, Average Loss: 4.296, avg. samples / sec: 66150.03
Iteration:   2620, Loss function: 4.198, Average Loss: 4.264, avg. samples / sec: 66066.06
Iteration:   2620, Loss function: 2.510, Average Loss: 4.294, avg. samples / sec: 66080.87
Iteration:   2620, Loss function: 5.194, Average Loss: 4.294, avg. samples / sec: 66044.63
Iteration:   2620, Loss function: 4.322, Average Loss: 4.317, avg. samples / sec: 65897.88
Iteration:   2620, Loss function: 3.765, Average Loss: 4.303, avg. samples / sec: 66097.04
Iteration:   2620, Loss function: 4.111, Average Loss: 4.273, avg. samples / sec: 66138.36
Iteration:   2620, Loss function: 6.135, Average Loss: 4.278, avg. samples / sec: 66148.86
Iteration:   2620, Loss function: 4.540, Average Loss: 4.283, avg. samples / sec: 66069.19
Iteration:   2620, Loss function: 3.925, Average Loss: 4.290, avg. samples / sec: 65873.30
Iteration:   2620, Loss function: 4.746, Average Loss: 4.296, avg. samples / sec: 65968.24
Iteration:   2640, Loss function: 3.912, Average Loss: 4.288, avg. samples / sec: 65864.65
Iteration:   2640, Loss function: 3.822, Average Loss: 4.280, avg. samples / sec: 65852.34
Iteration:   2640, Loss function: 3.237, Average Loss: 4.295, avg. samples / sec: 65716.12
Iteration:   2640, Loss function: 3.796, Average Loss: 4.292, avg. samples / sec: 66017.56
Iteration:   2640, Loss function: 4.519, Average Loss: 4.292, avg. samples / sec: 65701.54
Iteration:   2640, Loss function: 4.594, Average Loss: 4.295, avg. samples / sec: 65794.75
Iteration:   2640, Loss function: 3.677, Average Loss: 4.271, avg. samples / sec: 65788.40
Iteration:   2640, Loss function: 4.488, Average Loss: 4.311, avg. samples / sec: 65718.63
Iteration:   2640, Loss function: 4.626, Average Loss: 4.291, avg. samples / sec: 65855.05
Iteration:   2640, Loss function: 3.201, Average Loss: 4.314, avg. samples / sec: 65772.03
Iteration:   2640, Loss function: 4.016, Average Loss: 4.308, avg. samples / sec: 65669.42
Iteration:   2640, Loss function: 4.903, Average Loss: 4.273, avg. samples / sec: 65904.81
Iteration:   2640, Loss function: 3.356, Average Loss: 4.306, avg. samples / sec: 65828.47
Iteration:   2640, Loss function: 4.389, Average Loss: 4.314, avg. samples / sec: 65884.85
Iteration:   2640, Loss function: 3.379, Average Loss: 4.288, avg. samples / sec: 65882.97
Iteration:   2640, Loss function: 3.594, Average Loss: 4.283, avg. samples / sec: 65824.26
Iteration:   2640, Loss function: 4.146, Average Loss: 4.288, avg. samples / sec: 65778.82
Iteration:   2640, Loss function: 4.447, Average Loss: 4.279, avg. samples / sec: 65800.93
Iteration:   2640, Loss function: 4.191, Average Loss: 4.271, avg. samples / sec: 65611.42
Iteration:   2640, Loss function: 4.699, Average Loss: 4.280, avg. samples / sec: 65882.72
Iteration:   2640, Loss function: 3.893, Average Loss: 4.286, avg. samples / sec: 65909.31
Iteration:   2640, Loss function: 3.384, Average Loss: 4.282, avg. samples / sec: 65810.92
Iteration:   2640, Loss function: 4.627, Average Loss: 4.272, avg. samples / sec: 65822.60
Iteration:   2640, Loss function: 3.290, Average Loss: 4.260, avg. samples / sec: 65779.43
Iteration:   2640, Loss function: 3.687, Average Loss: 4.298, avg. samples / sec: 65810.21
Iteration:   2640, Loss function: 3.238, Average Loss: 4.261, avg. samples / sec: 65650.12
Iteration:   2640, Loss function: 5.197, Average Loss: 4.293, avg. samples / sec: 65681.33
Iteration:   2640, Loss function: 5.571, Average Loss: 4.306, avg. samples / sec: 65621.66
Iteration:   2640, Loss function: 4.236, Average Loss: 4.293, avg. samples / sec: 65514.86
Iteration:   2640, Loss function: 3.581, Average Loss: 4.297, avg. samples / sec: 65445.31
:::MLL 1558651429.128 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558651429.129 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 3.994, Average Loss: 4.287, avg. samples / sec: 65499.88
Iteration:   2660, Loss function: 4.209, Average Loss: 4.283, avg. samples / sec: 65490.59
Iteration:   2660, Loss function: 3.690, Average Loss: 4.288, avg. samples / sec: 65443.00
Iteration:   2660, Loss function: 4.035, Average Loss: 4.272, avg. samples / sec: 65454.21
Iteration:   2660, Loss function: 3.329, Average Loss: 4.287, avg. samples / sec: 65290.40
Iteration:   2660, Loss function: 3.495, Average Loss: 4.266, avg. samples / sec: 65473.04
Iteration:   2660, Loss function: 3.135, Average Loss: 4.299, avg. samples / sec: 65427.26
Iteration:   2660, Loss function: 3.825, Average Loss: 4.270, avg. samples / sec: 65409.43
Iteration:   2660, Loss function: 4.356, Average Loss: 4.294, avg. samples / sec: 65769.98
Iteration:   2660, Loss function: 3.818, Average Loss: 4.275, avg. samples / sec: 65316.73
Iteration:   2660, Loss function: 4.089, Average Loss: 4.270, avg. samples / sec: 65370.11
Iteration:   2660, Loss function: 3.952, Average Loss: 4.309, avg. samples / sec: 65379.06
Iteration:   2660, Loss function: 3.241, Average Loss: 4.261, avg. samples / sec: 65364.78
Iteration:   2660, Loss function: 4.807, Average Loss: 4.284, avg. samples / sec: 65288.31
Iteration:   2660, Loss function: 3.464, Average Loss: 4.288, avg. samples / sec: 65456.19
Iteration:   2660, Loss function: 4.092, Average Loss: 4.303, avg. samples / sec: 65340.96
Iteration:   2660, Loss function: 3.063, Average Loss: 4.298, avg. samples / sec: 65337.29
Iteration:   2660, Loss function: 3.175, Average Loss: 4.257, avg. samples / sec: 65457.98
Iteration:   2660, Loss function: 4.020, Average Loss: 4.289, avg. samples / sec: 65291.04
Iteration:   2660, Loss function: 4.495, Average Loss: 4.268, avg. samples / sec: 65339.41
Iteration:   2660, Loss function: 5.683, Average Loss: 4.290, avg. samples / sec: 65390.16
Iteration:   2660, Loss function: 3.691, Average Loss: 4.316, avg. samples / sec: 65323.36
Iteration:   2660, Loss function: 3.865, Average Loss: 4.302, avg. samples / sec: 65499.48
Iteration:   2660, Loss function: 4.075, Average Loss: 4.275, avg. samples / sec: 65311.89
Iteration:   2660, Loss function: 4.519, Average Loss: 4.256, avg. samples / sec: 65368.32
Iteration:   2660, Loss function: 2.499, Average Loss: 4.285, avg. samples / sec: 65446.98
Iteration:   2660, Loss function: 3.774, Average Loss: 4.276, avg. samples / sec: 65295.30
Iteration:   2660, Loss function: 4.347, Average Loss: 4.281, avg. samples / sec: 65248.35
Iteration:   2660, Loss function: 4.576, Average Loss: 4.283, avg. samples / sec: 65145.77
Iteration:   2660, Loss function: 3.780, Average Loss: 4.278, avg. samples / sec: 65254.46
Iteration:   2680, Loss function: 3.892, Average Loss: 4.292, avg. samples / sec: 64934.73
Iteration:   2680, Loss function: 5.292, Average Loss: 4.282, avg. samples / sec: 64697.67
Iteration:   2680, Loss function: 3.414, Average Loss: 4.273, avg. samples / sec: 64939.78
Iteration:   2680, Loss function: 2.978, Average Loss: 4.302, avg. samples / sec: 64797.83
Iteration:   2680, Loss function: 4.289, Average Loss: 4.263, avg. samples / sec: 64750.76
Iteration:   2680, Loss function: 4.202, Average Loss: 4.296, avg. samples / sec: 64775.53
Iteration:   2680, Loss function: 3.230, Average Loss: 4.281, avg. samples / sec: 64665.67
Iteration:   2680, Loss function: 4.006, Average Loss: 4.279, avg. samples / sec: 64919.47
Iteration:   2680, Loss function: 2.950, Average Loss: 4.279, avg. samples / sec: 64632.69
Iteration:   2680, Loss function: 4.173, Average Loss: 4.280, avg. samples / sec: 64784.97
Iteration:   2680, Loss function: 4.187, Average Loss: 4.281, avg. samples / sec: 64673.00
Iteration:   2680, Loss function: 4.818, Average Loss: 4.289, avg. samples / sec: 64666.03
Iteration:   2680, Loss function: 4.302, Average Loss: 4.257, avg. samples / sec: 64718.06
Iteration:   2680, Loss function: 4.361, Average Loss: 4.268, avg. samples / sec: 64673.60
Iteration:   2680, Loss function: 2.946, Average Loss: 4.263, avg. samples / sec: 64653.66
Iteration:   2680, Loss function: 5.224, Average Loss: 4.282, avg. samples / sec: 64697.97
Iteration:   2680, Loss function: 3.924, Average Loss: 4.289, avg. samples / sec: 64651.76
Iteration:   2680, Loss function: 4.888, Average Loss: 4.297, avg. samples / sec: 64732.32
Iteration:   2680, Loss function: 5.035, Average Loss: 4.277, avg. samples / sec: 64783.09
Iteration:   2680, Loss function: 3.153, Average Loss: 4.250, avg. samples / sec: 64735.42
Iteration:   2680, Loss function: 4.779, Average Loss: 4.283, avg. samples / sec: 64719.99
Iteration:   2680, Loss function: 4.420, Average Loss: 4.310, avg. samples / sec: 64719.66
Iteration:   2680, Loss function: 3.236, Average Loss: 4.264, avg. samples / sec: 64705.34
Iteration:   2680, Loss function: 3.929, Average Loss: 4.250, avg. samples / sec: 64665.91
Iteration:   2680, Loss function: 3.607, Average Loss: 4.263, avg. samples / sec: 64637.64
Iteration:   2680, Loss function: 4.571, Average Loss: 4.266, avg. samples / sec: 64590.69
Iteration:   2680, Loss function: 5.034, Average Loss: 4.273, avg. samples / sec: 64775.88
Iteration:   2680, Loss function: 3.155, Average Loss: 4.270, avg. samples / sec: 64675.38
Iteration:   2680, Loss function: 3.929, Average Loss: 4.281, avg. samples / sec: 64620.16
Iteration:   2680, Loss function: 3.839, Average Loss: 4.273, avg. samples / sec: 64724.48
Iteration:   2700, Loss function: 4.552, Average Loss: 4.287, avg. samples / sec: 62872.65
Iteration:   2700, Loss function: 4.124, Average Loss: 4.284, avg. samples / sec: 63072.35
Iteration:   2700, Loss function: 3.950, Average Loss: 4.298, avg. samples / sec: 62972.89
Iteration:   2700, Loss function: 5.451, Average Loss: 4.262, avg. samples / sec: 62963.95
Iteration:   2700, Loss function: 3.286, Average Loss: 4.296, avg. samples / sec: 62920.37
Iteration:   2700, Loss function: 3.511, Average Loss: 4.257, avg. samples / sec: 62994.57
Iteration:   2700, Loss function: 4.584, Average Loss: 4.263, avg. samples / sec: 63007.69
Iteration:   2700, Loss function: 3.559, Average Loss: 4.274, avg. samples / sec: 63033.17
Iteration:   2700, Loss function: 3.105, Average Loss: 4.290, avg. samples / sec: 63025.28
Iteration:   2700, Loss function: 4.911, Average Loss: 4.261, avg. samples / sec: 63018.57
Iteration:   2700, Loss function: 5.735, Average Loss: 4.263, avg. samples / sec: 63062.98
Iteration:   2700, Loss function: 3.543, Average Loss: 4.281, avg. samples / sec: 63054.35
Iteration:   2700, Loss function: 3.966, Average Loss: 4.266, avg. samples / sec: 62850.70
Iteration:   2700, Loss function: 4.131, Average Loss: 4.284, avg. samples / sec: 62952.25
Iteration:   2700, Loss function: 3.901, Average Loss: 4.253, avg. samples / sec: 62987.36
Iteration:   2700, Loss function: 3.519, Average Loss: 4.275, avg. samples / sec: 62884.83
Iteration:   2700, Loss function: 4.724, Average Loss: 4.283, avg. samples / sec: 62809.30
Iteration:   2700, Loss function: 4.416, Average Loss: 4.276, avg. samples / sec: 62950.17
Iteration:   2700, Loss function: 4.430, Average Loss: 4.269, avg. samples / sec: 63026.57
Iteration:   2700, Loss function: 3.804, Average Loss: 4.273, avg. samples / sec: 62877.17
Iteration:   2700, Loss function: 3.221, Average Loss: 4.267, avg. samples / sec: 63039.82
Iteration:   2700, Loss function: 4.595, Average Loss: 4.280, avg. samples / sec: 62879.41
Iteration:   2700, Loss function: 4.381, Average Loss: 4.271, avg. samples / sec: 62888.06
Iteration:   2700, Loss function: 4.551, Average Loss: 4.250, avg. samples / sec: 62957.70
Iteration:   2700, Loss function: 4.750, Average Loss: 4.271, avg. samples / sec: 62901.84
Iteration:   2700, Loss function: 3.991, Average Loss: 4.261, avg. samples / sec: 62935.58
Iteration:   2700, Loss function: 2.765, Average Loss: 4.309, avg. samples / sec: 62895.52
Iteration:   2700, Loss function: 3.651, Average Loss: 4.279, avg. samples / sec: 62876.95
Iteration:   2700, Loss function: 5.003, Average Loss: 4.265, avg. samples / sec: 62805.35
Iteration:   2700, Loss function: 3.871, Average Loss: 4.283, avg. samples / sec: 62776.73
Iteration:   2720, Loss function: 3.524, Average Loss: 4.282, avg. samples / sec: 65626.39
Iteration:   2720, Loss function: 3.914, Average Loss: 4.278, avg. samples / sec: 65637.18
Iteration:   2720, Loss function: 4.499, Average Loss: 4.256, avg. samples / sec: 65630.25
Iteration:   2720, Loss function: 4.223, Average Loss: 4.296, avg. samples / sec: 65613.99
Iteration:   2720, Loss function: 3.556, Average Loss: 4.298, avg. samples / sec: 65801.08
Iteration:   2720, Loss function: 4.725, Average Loss: 4.278, avg. samples / sec: 65681.20
Iteration:   2720, Loss function: 2.578, Average Loss: 4.261, avg. samples / sec: 65698.96
Iteration:   2720, Loss function: 3.780, Average Loss: 4.264, avg. samples / sec: 65669.76
Iteration:   2720, Loss function: 4.487, Average Loss: 4.273, avg. samples / sec: 65697.46
Iteration:   2720, Loss function: 2.963, Average Loss: 4.265, avg. samples / sec: 65701.17
Iteration:   2720, Loss function: 4.350, Average Loss: 4.277, avg. samples / sec: 65646.45
Iteration:   2720, Loss function: 4.833, Average Loss: 4.262, avg. samples / sec: 65868.68
Iteration:   2720, Loss function: 3.400, Average Loss: 4.258, avg. samples / sec: 65614.94
Iteration:   2720, Loss function: 3.795, Average Loss: 4.259, avg. samples / sec: 65710.11
Iteration:   2720, Loss function: 4.527, Average Loss: 4.270, avg. samples / sec: 65649.54
Iteration:   2720, Loss function: 4.827, Average Loss: 4.265, avg. samples / sec: 65672.51
Iteration:   2720, Loss function: 3.982, Average Loss: 4.280, avg. samples / sec: 65643.27
Iteration:   2720, Loss function: 4.483, Average Loss: 4.273, avg. samples / sec: 65567.38
Iteration:   2720, Loss function: 4.698, Average Loss: 4.297, avg. samples / sec: 65526.98
Iteration:   2720, Loss function: 5.357, Average Loss: 4.281, avg. samples / sec: 65824.35
Iteration:   2720, Loss function: 3.379, Average Loss: 4.282, avg. samples / sec: 65546.76
Iteration:   2720, Loss function: 3.829, Average Loss: 4.263, avg. samples / sec: 65610.45
Iteration:   2720, Loss function: 4.144, Average Loss: 4.272, avg. samples / sec: 65582.72
Iteration:   2720, Loss function: 4.582, Average Loss: 4.270, avg. samples / sec: 65617.01
Iteration:   2720, Loss function: 2.944, Average Loss: 4.250, avg. samples / sec: 65506.15
Iteration:   2720, Loss function: 3.064, Average Loss: 4.254, avg. samples / sec: 65558.47
Iteration:   2720, Loss function: 4.893, Average Loss: 4.246, avg. samples / sec: 65578.66
Iteration:   2720, Loss function: 3.938, Average Loss: 4.258, avg. samples / sec: 65501.52
Iteration:   2720, Loss function: 3.854, Average Loss: 4.259, avg. samples / sec: 65518.63
Iteration:   2720, Loss function: 4.059, Average Loss: 4.275, avg. samples / sec: 65562.98
:::MLL 1558651430.950 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558651430.951 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 3.619, Average Loss: 4.275, avg. samples / sec: 65678.14
Iteration:   2740, Loss function: 2.680, Average Loss: 4.254, avg. samples / sec: 65595.60
Iteration:   2740, Loss function: 4.604, Average Loss: 4.252, avg. samples / sec: 65592.70
Iteration:   2740, Loss function: 4.010, Average Loss: 4.280, avg. samples / sec: 65659.57
Iteration:   2740, Loss function: 4.165, Average Loss: 4.274, avg. samples / sec: 65496.98
Iteration:   2740, Loss function: 4.156, Average Loss: 4.275, avg. samples / sec: 65722.00
Iteration:   2740, Loss function: 4.311, Average Loss: 4.294, avg. samples / sec: 65623.00
Iteration:   2740, Loss function: 3.639, Average Loss: 4.291, avg. samples / sec: 65501.91
Iteration:   2740, Loss function: 4.238, Average Loss: 4.269, avg. samples / sec: 65570.76
Iteration:   2740, Loss function: 3.859, Average Loss: 4.259, avg. samples / sec: 65544.78
Iteration:   2740, Loss function: 3.391, Average Loss: 4.265, avg. samples / sec: 65654.16
Iteration:   2740, Loss function: 3.697, Average Loss: 4.287, avg. samples / sec: 65496.40
Iteration:   2740, Loss function: 3.783, Average Loss: 4.247, avg. samples / sec: 65640.30
Iteration:   2740, Loss function: 3.836, Average Loss: 4.272, avg. samples / sec: 65447.22
Iteration:   2740, Loss function: 3.662, Average Loss: 4.258, avg. samples / sec: 65491.87
Iteration:   2740, Loss function: 3.754, Average Loss: 4.247, avg. samples / sec: 65640.24
Iteration:   2740, Loss function: 3.788, Average Loss: 4.259, avg. samples / sec: 65585.68
Iteration:   2740, Loss function: 3.745, Average Loss: 4.241, avg. samples / sec: 65599.85
Iteration:   2740, Loss function: 3.153, Average Loss: 4.271, avg. samples / sec: 65498.78
Iteration:   2740, Loss function: 4.276, Average Loss: 4.262, avg. samples / sec: 65521.19
Iteration:   2740, Loss function: 4.268, Average Loss: 4.266, avg. samples / sec: 65534.48
Iteration:   2740, Loss function: 5.330, Average Loss: 4.274, avg. samples / sec: 65431.24
Iteration:   2740, Loss function: 3.447, Average Loss: 4.260, avg. samples / sec: 65496.34
Iteration:   2740, Loss function: 3.928, Average Loss: 4.272, avg. samples / sec: 65550.02
Iteration:   2740, Loss function: 2.983, Average Loss: 4.252, avg. samples / sec: 65444.12
Iteration:   2740, Loss function: 4.581, Average Loss: 4.249, avg. samples / sec: 65451.39
Iteration:   2740, Loss function: 3.948, Average Loss: 4.253, avg. samples / sec: 65381.79
Iteration:   2740, Loss function: 3.369, Average Loss: 4.250, avg. samples / sec: 65531.28
Iteration:   2740, Loss function: 3.132, Average Loss: 4.247, avg. samples / sec: 65469.08
Iteration:   2740, Loss function: 4.976, Average Loss: 4.276, avg. samples / sec: 65356.68
Iteration:   2760, Loss function: 3.479, Average Loss: 4.253, avg. samples / sec: 66095.12
Iteration:   2760, Loss function: 3.692, Average Loss: 4.248, avg. samples / sec: 65953.27
Iteration:   2760, Loss function: 2.288, Average Loss: 4.284, avg. samples / sec: 66040.83
Iteration:   2760, Loss function: 4.733, Average Loss: 4.270, avg. samples / sec: 65876.72
Iteration:   2760, Loss function: 3.765, Average Loss: 4.244, avg. samples / sec: 66149.04
Iteration:   2760, Loss function: 4.013, Average Loss: 4.253, avg. samples / sec: 66054.82
Iteration:   2760, Loss function: 3.783, Average Loss: 4.269, avg. samples / sec: 65941.17
Iteration:   2760, Loss function: 4.163, Average Loss: 4.262, avg. samples / sec: 66027.12
Iteration:   2760, Loss function: 4.478, Average Loss: 4.245, avg. samples / sec: 66085.33
Iteration:   2760, Loss function: 5.501, Average Loss: 4.251, avg. samples / sec: 66064.85
Iteration:   2760, Loss function: 4.716, Average Loss: 4.270, avg. samples / sec: 66051.54
Iteration:   2760, Loss function: 4.221, Average Loss: 4.261, avg. samples / sec: 65948.92
Iteration:   2760, Loss function: 3.921, Average Loss: 4.272, avg. samples / sec: 66029.41
Iteration:   2760, Loss function: 3.735, Average Loss: 4.268, avg. samples / sec: 65972.97
Iteration:   2760, Loss function: 3.608, Average Loss: 4.284, avg. samples / sec: 65952.25
Iteration:   2760, Loss function: 4.276, Average Loss: 4.244, avg. samples / sec: 65955.92
Iteration:   2760, Loss function: 4.544, Average Loss: 4.275, avg. samples / sec: 65929.85
Iteration:   2760, Loss function: 3.537, Average Loss: 4.255, avg. samples / sec: 65928.59
Iteration:   2760, Loss function: 3.934, Average Loss: 4.247, avg. samples / sec: 66061.23
Iteration:   2760, Loss function: 3.544, Average Loss: 4.258, avg. samples / sec: 65972.94
Iteration:   2760, Loss function: 4.066, Average Loss: 4.280, avg. samples / sec: 65840.09
Iteration:   2760, Loss function: 3.349, Average Loss: 4.249, avg. samples / sec: 65856.09
Iteration:   2760, Loss function: 3.603, Average Loss: 4.243, avg. samples / sec: 65898.74
Iteration:   2760, Loss function: 4.722, Average Loss: 4.246, avg. samples / sec: 65849.20
Iteration:   2760, Loss function: 4.143, Average Loss: 4.266, avg. samples / sec: 66108.83
Iteration:   2760, Loss function: 3.969, Average Loss: 4.239, avg. samples / sec: 66047.98
Iteration:   2760, Loss function: 2.667, Average Loss: 4.251, avg. samples / sec: 65858.37
Iteration:   2760, Loss function: 4.215, Average Loss: 4.253, avg. samples / sec: 65827.79
Iteration:   2760, Loss function: 3.743, Average Loss: 4.288, avg. samples / sec: 65805.29
Iteration:   2760, Loss function: 3.770, Average Loss: 4.256, avg. samples / sec: 65837.63
Iteration:   2780, Loss function: 3.565, Average Loss: 4.243, avg. samples / sec: 65834.83
Iteration:   2780, Loss function: 3.871, Average Loss: 4.250, avg. samples / sec: 65839.23
Iteration:   2780, Loss function: 4.105, Average Loss: 4.267, avg. samples / sec: 65866.93
Iteration:   2780, Loss function: 5.202, Average Loss: 4.278, avg. samples / sec: 65749.05
Iteration:   2780, Loss function: 3.599, Average Loss: 4.277, avg. samples / sec: 65841.39
Iteration:   2780, Loss function: 5.288, Average Loss: 4.261, avg. samples / sec: 65788.03
Iteration:   2780, Loss function: 4.459, Average Loss: 4.266, avg. samples / sec: 65896.77
Iteration:   2780, Loss function: 3.941, Average Loss: 4.253, avg. samples / sec: 65671.04
Iteration:   2780, Loss function: 4.670, Average Loss: 4.245, avg. samples / sec: 65916.37
Iteration:   2780, Loss function: 4.401, Average Loss: 4.255, avg. samples / sec: 65793.43
Iteration:   2780, Loss function: 4.391, Average Loss: 4.272, avg. samples / sec: 65789.75
Iteration:   2780, Loss function: 4.899, Average Loss: 4.248, avg. samples / sec: 65790.30
Iteration:   2780, Loss function: 5.041, Average Loss: 4.260, avg. samples / sec: 65743.99
Iteration:   2780, Loss function: 4.449, Average Loss: 4.265, avg. samples / sec: 65770.93
Iteration:   2780, Loss function: 4.626, Average Loss: 4.249, avg. samples / sec: 65872.35
Iteration:   2780, Loss function: 4.053, Average Loss: 4.240, avg. samples / sec: 65761.04
Iteration:   2780, Loss function: 4.309, Average Loss: 4.239, avg. samples / sec: 65841.11
Iteration:   2780, Loss function: 5.417, Average Loss: 4.267, avg. samples / sec: 65677.01
Iteration:   2780, Loss function: 2.973, Average Loss: 4.257, avg. samples / sec: 65731.38
Iteration:   2780, Loss function: 4.277, Average Loss: 4.289, avg. samples / sec: 65853.32
Iteration:   2780, Loss function: 3.668, Average Loss: 4.255, avg. samples / sec: 65779.71
Iteration:   2780, Loss function: 3.731, Average Loss: 4.246, avg. samples / sec: 65796.08
Iteration:   2780, Loss function: 3.988, Average Loss: 4.271, avg. samples / sec: 65717.87
Iteration:   2780, Loss function: 5.169, Average Loss: 4.278, avg. samples / sec: 65738.22
Iteration:   2780, Loss function: 4.750, Average Loss: 4.244, avg. samples / sec: 65585.59
Iteration:   2780, Loss function: 5.042, Average Loss: 4.245, avg. samples / sec: 65739.63
Iteration:   2780, Loss function: 3.433, Average Loss: 4.242, avg. samples / sec: 65591.12
Iteration:   2780, Loss function: 4.602, Average Loss: 4.241, avg. samples / sec: 65590.05
Iteration:   2780, Loss function: 3.608, Average Loss: 4.246, avg. samples / sec: 65719.43
Iteration:   2780, Loss function: 3.593, Average Loss: 4.245, avg. samples / sec: 65750.06
:::MLL 1558651432.739 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558651432.740 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 5.145, Average Loss: 4.267, avg. samples / sec: 65660.61
Iteration:   2800, Loss function: 3.851, Average Loss: 4.279, avg. samples / sec: 65569.94
Iteration:   2800, Loss function: 3.912, Average Loss: 4.258, avg. samples / sec: 65586.05
Iteration:   2800, Loss function: 4.635, Average Loss: 4.256, avg. samples / sec: 65663.49
Iteration:   2800, Loss function: 4.241, Average Loss: 4.262, avg. samples / sec: 65635.99
Iteration:   2800, Loss function: 4.516, Average Loss: 4.244, avg. samples / sec: 65732.15
Iteration:   2800, Loss function: 3.744, Average Loss: 4.238, avg. samples / sec: 65400.78
Iteration:   2800, Loss function: 4.534, Average Loss: 4.262, avg. samples / sec: 65539.11
Iteration:   2800, Loss function: 4.289, Average Loss: 4.262, avg. samples / sec: 65549.35
Iteration:   2800, Loss function: 4.961, Average Loss: 4.244, avg. samples / sec: 65592.52
Iteration:   2800, Loss function: 2.656, Average Loss: 4.250, avg. samples / sec: 65533.14
Iteration:   2800, Loss function: 3.415, Average Loss: 4.272, avg. samples / sec: 65621.90
Iteration:   2800, Loss function: 5.368, Average Loss: 4.264, avg. samples / sec: 65585.71
Iteration:   2800, Loss function: 5.325, Average Loss: 4.282, avg. samples / sec: 65553.25
Iteration:   2800, Loss function: 3.520, Average Loss: 4.240, avg. samples / sec: 65521.92
Iteration:   2800, Loss function: 4.422, Average Loss: 4.241, avg. samples / sec: 65673.58
Iteration:   2800, Loss function: 2.410, Average Loss: 4.257, avg. samples / sec: 65411.92
Iteration:   2800, Loss function: 3.159, Average Loss: 4.246, avg. samples / sec: 65518.82
Iteration:   2800, Loss function: 4.019, Average Loss: 4.243, avg. samples / sec: 65658.50
Iteration:   2800, Loss function: 4.257, Average Loss: 4.254, avg. samples / sec: 65492.42
Iteration:   2800, Loss function: 4.098, Average Loss: 4.273, avg. samples / sec: 65439.08
Iteration:   2800, Loss function: 3.695, Average Loss: 4.241, avg. samples / sec: 65667.92
Iteration:   2800, Loss function: 3.121, Average Loss: 4.242, avg. samples / sec: 65555.82
Iteration:   2800, Loss function: 4.748, Average Loss: 4.238, avg. samples / sec: 65452.60
Iteration:   2800, Loss function: 5.541, Average Loss: 4.258, avg. samples / sec: 65429.72
Iteration:   2800, Loss function: 3.454, Average Loss: 4.240, avg. samples / sec: 65581.23
Iteration:   2800, Loss function: 4.572, Average Loss: 4.245, avg. samples / sec: 65389.31
Iteration:   2800, Loss function: 3.892, Average Loss: 4.232, avg. samples / sec: 65414.05
Iteration:   2800, Loss function: 3.508, Average Loss: 4.251, avg. samples / sec: 65407.67
Iteration:   2800, Loss function: 4.581, Average Loss: 4.247, avg. samples / sec: 65238.99
Iteration:   2820, Loss function: 4.143, Average Loss: 4.234, avg. samples / sec: 65984.49
Iteration:   2820, Loss function: 4.534, Average Loss: 4.260, avg. samples / sec: 65708.03
Iteration:   2820, Loss function: 3.620, Average Loss: 4.282, avg. samples / sec: 65857.23
Iteration:   2820, Loss function: 3.970, Average Loss: 4.232, avg. samples / sec: 65766.08
Iteration:   2820, Loss function: 4.368, Average Loss: 4.261, avg. samples / sec: 65683.65
Iteration:   2820, Loss function: 4.252, Average Loss: 4.259, avg. samples / sec: 65790.95
Iteration:   2820, Loss function: 3.647, Average Loss: 4.249, avg. samples / sec: 65673.46
Iteration:   2820, Loss function: 4.889, Average Loss: 4.236, avg. samples / sec: 65793.25
Iteration:   2820, Loss function: 3.676, Average Loss: 4.258, avg. samples / sec: 65743.53
Iteration:   2820, Loss function: 4.728, Average Loss: 4.255, avg. samples / sec: 65861.45
Iteration:   2820, Loss function: 3.539, Average Loss: 4.236, avg. samples / sec: 65759.11
Iteration:   2820, Loss function: 4.048, Average Loss: 4.246, avg. samples / sec: 65721.39
Iteration:   2820, Loss function: 3.769, Average Loss: 4.240, avg. samples / sec: 65677.87
Iteration:   2820, Loss function: 4.474, Average Loss: 4.238, avg. samples / sec: 65855.23
Iteration:   2820, Loss function: 3.954, Average Loss: 4.244, avg. samples / sec: 65721.05
Iteration:   2820, Loss function: 2.647, Average Loss: 4.250, avg. samples / sec: 65749.05
Iteration:   2820, Loss function: 3.691, Average Loss: 4.253, avg. samples / sec: 65724.33
Iteration:   2820, Loss function: 3.725, Average Loss: 4.241, avg. samples / sec: 65869.85
Iteration:   2820, Loss function: 2.161, Average Loss: 4.266, avg. samples / sec: 65726.91
Iteration:   2820, Loss function: 3.179, Average Loss: 4.242, avg. samples / sec: 65785.91
Iteration:   2820, Loss function: 4.014, Average Loss: 4.260, avg. samples / sec: 65659.14
Iteration:   2820, Loss function: 4.434, Average Loss: 4.251, avg. samples / sec: 65839.94
Iteration:   2820, Loss function: 4.511, Average Loss: 4.267, avg. samples / sec: 65673.98
Iteration:   2820, Loss function: 3.959, Average Loss: 4.275, avg. samples / sec: 65563.10
Iteration:   2820, Loss function: 4.367, Average Loss: 4.258, avg. samples / sec: 65565.24
Iteration:   2820, Loss function: 3.824, Average Loss: 4.241, avg. samples / sec: 65670.37
Iteration:   2820, Loss function: 3.722, Average Loss: 4.227, avg. samples / sec: 65694.55
Iteration:   2820, Loss function: 3.986, Average Loss: 4.223, avg. samples / sec: 65730.40
Iteration:   2820, Loss function: 3.929, Average Loss: 4.245, avg. samples / sec: 65590.02
Iteration:   2820, Loss function: 3.153, Average Loss: 4.238, avg. samples / sec: 65652.41
Iteration:   2840, Loss function: 4.417, Average Loss: 4.256, avg. samples / sec: 66137.24
Iteration:   2840, Loss function: 4.475, Average Loss: 4.274, avg. samples / sec: 66024.55
Iteration:   2840, Loss function: 5.784, Average Loss: 4.264, avg. samples / sec: 66161.15
Iteration:   2840, Loss function: 3.092, Average Loss: 4.254, avg. samples / sec: 66198.29
Iteration:   2840, Loss function: 3.145, Average Loss: 4.244, avg. samples / sec: 66088.15
Iteration:   2840, Loss function: 4.535, Average Loss: 4.254, avg. samples / sec: 66063.36
Iteration:   2840, Loss function: 4.081, Average Loss: 4.236, avg. samples / sec: 66130.39
Iteration:   2840, Loss function: 4.981, Average Loss: 4.248, avg. samples / sec: 66088.37
Iteration:   2840, Loss function: 3.696, Average Loss: 4.255, avg. samples / sec: 65962.84
Iteration:   2840, Loss function: 4.116, Average Loss: 4.227, avg. samples / sec: 65922.79
Iteration:   2840, Loss function: 2.930, Average Loss: 4.240, avg. samples / sec: 66047.33
Iteration:   2840, Loss function: 3.985, Average Loss: 4.228, avg. samples / sec: 66184.18
Iteration:   2840, Loss function: 2.618, Average Loss: 4.263, avg. samples / sec: 66112.42
Iteration:   2840, Loss function: 2.987, Average Loss: 4.233, avg. samples / sec: 66067.58
Iteration:   2840, Loss function: 3.461, Average Loss: 4.238, avg. samples / sec: 66014.07
Iteration:   2840, Loss function: 4.595, Average Loss: 4.227, avg. samples / sec: 65989.65
Iteration:   2840, Loss function: 3.838, Average Loss: 4.274, avg. samples / sec: 66088.71
Iteration:   2840, Loss function: 3.670, Average Loss: 4.216, avg. samples / sec: 66162.83
Iteration:   2840, Loss function: 3.699, Average Loss: 4.238, avg. samples / sec: 66145.19
Iteration:   2840, Loss function: 4.956, Average Loss: 4.246, avg. samples / sec: 65938.80
Iteration:   2840, Loss function: 4.188, Average Loss: 4.228, avg. samples / sec: 66152.71
Iteration:   2840, Loss function: 4.631, Average Loss: 4.228, avg. samples / sec: 65887.59
Iteration:   2840, Loss function: 4.438, Average Loss: 4.248, avg. samples / sec: 66024.99
Iteration:   2840, Loss function: 3.585, Average Loss: 4.235, avg. samples / sec: 65947.13
Iteration:   2840, Loss function: 4.346, Average Loss: 4.242, avg. samples / sec: 66042.34
Iteration:   2840, Loss function: 3.817, Average Loss: 4.256, avg. samples / sec: 65973.46
Iteration:   2840, Loss function: 3.518, Average Loss: 4.234, avg. samples / sec: 65899.21
Iteration:   2840, Loss function: 3.299, Average Loss: 4.237, avg. samples / sec: 65862.80
Iteration:   2840, Loss function: 4.809, Average Loss: 4.249, avg. samples / sec: 65943.05
Iteration:   2840, Loss function: 4.797, Average Loss: 4.253, avg. samples / sec: 65837.82
Iteration:   2860, Loss function: 3.669, Average Loss: 4.270, avg. samples / sec: 66181.01
Iteration:   2860, Loss function: 4.342, Average Loss: 4.251, avg. samples / sec: 66215.86
Iteration:   2860, Loss function: 3.698, Average Loss: 4.271, avg. samples / sec: 66269.08
Iteration:   2860, Loss function: 3.234, Average Loss: 4.249, avg. samples / sec: 66061.23
Iteration:   2860, Loss function: 3.106, Average Loss: 4.236, avg. samples / sec: 66223.43
Iteration:   2860, Loss function: 3.582, Average Loss: 4.238, avg. samples / sec: 66339.73
Iteration:   2860, Loss function: 3.721, Average Loss: 4.239, avg. samples / sec: 66272.88
Iteration:   2860, Loss function: 6.071, Average Loss: 4.249, avg. samples / sec: 66094.04
Iteration:   2860, Loss function: 3.620, Average Loss: 4.247, avg. samples / sec: 66132.50
Iteration:   2860, Loss function: 5.188, Average Loss: 4.217, avg. samples / sec: 66140.41
Iteration:   2860, Loss function: 5.961, Average Loss: 4.240, avg. samples / sec: 66074.89
Iteration:   2860, Loss function: 4.735, Average Loss: 4.234, avg. samples / sec: 66243.29
Iteration:   2860, Loss function: 3.075, Average Loss: 4.227, avg. samples / sec: 66211.26
Iteration:   2860, Loss function: 4.971, Average Loss: 4.221, avg. samples / sec: 66213.10
Iteration:   2860, Loss function: 3.551, Average Loss: 4.249, avg. samples / sec: 66261.41
Iteration:   2860, Loss function: 4.212, Average Loss: 4.260, avg. samples / sec: 66127.10
Iteration:   2860, Loss function: 3.428, Average Loss: 4.225, avg. samples / sec: 66193.04
Iteration:   2860, Loss function: 3.579, Average Loss: 4.236, avg. samples / sec: 66097.08
Iteration:   2860, Loss function: 3.995, Average Loss: 4.230, avg. samples / sec: 66227.22
Iteration:   2860, Loss function: 5.594, Average Loss: 4.248, avg. samples / sec: 66178.33
Iteration:   2860, Loss function: 3.217, Average Loss: 4.232, avg. samples / sec: 66054.20
Iteration:   2860, Loss function: 4.470, Average Loss: 4.243, avg. samples / sec: 66180.26
Iteration:   2860, Loss function: 3.112, Average Loss: 4.241, avg. samples / sec: 66210.02
Iteration:   2860, Loss function: 4.067, Average Loss: 4.264, avg. samples / sec: 65966.11
Iteration:   2860, Loss function: 3.518, Average Loss: 4.225, avg. samples / sec: 66058.78
Iteration:   2860, Loss function: 3.959, Average Loss: 4.209, avg. samples / sec: 66081.14
Iteration:   2860, Loss function: 4.396, Average Loss: 4.249, avg. samples / sec: 66218.07
Iteration:   2860, Loss function: 4.871, Average Loss: 4.222, avg. samples / sec: 66073.90
Iteration:   2860, Loss function: 3.227, Average Loss: 4.252, avg. samples / sec: 65998.30
Iteration:   2860, Loss function: 3.719, Average Loss: 4.220, avg. samples / sec: 65990.95
:::MLL 1558651434.525 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558651434.526 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 3.927, Average Loss: 4.242, avg. samples / sec: 65523.45
Iteration:   2880, Loss function: 4.422, Average Loss: 4.222, avg. samples / sec: 65658.22
Iteration:   2880, Loss function: 4.063, Average Loss: 4.221, avg. samples / sec: 65693.82
Iteration:   2880, Loss function: 3.217, Average Loss: 4.221, avg. samples / sec: 65696.02
Iteration:   2880, Loss function: 4.551, Average Loss: 4.224, avg. samples / sec: 65641.25
Iteration:   2880, Loss function: 4.681, Average Loss: 4.232, avg. samples / sec: 65534.87
Iteration:   2880, Loss function: 2.189, Average Loss: 4.222, avg. samples / sec: 65617.20
Iteration:   2880, Loss function: 3.904, Average Loss: 4.265, avg. samples / sec: 65454.73
Iteration:   2880, Loss function: 5.425, Average Loss: 4.201, avg. samples / sec: 65660.73
Iteration:   2880, Loss function: 3.585, Average Loss: 4.242, avg. samples / sec: 65531.34
Iteration:   2880, Loss function: 3.831, Average Loss: 4.259, avg. samples / sec: 65632.48
Iteration:   2880, Loss function: 4.903, Average Loss: 4.249, avg. samples / sec: 65653.02
Iteration:   2880, Loss function: 4.148, Average Loss: 4.268, avg. samples / sec: 65447.86
Iteration:   2880, Loss function: 3.213, Average Loss: 4.215, avg. samples / sec: 65544.35
Iteration:   2880, Loss function: 4.192, Average Loss: 4.229, avg. samples / sec: 65488.10
Iteration:   2880, Loss function: 4.246, Average Loss: 4.232, avg. samples / sec: 65544.81
Iteration:   2880, Loss function: 2.871, Average Loss: 4.244, avg. samples / sec: 65555.39
Iteration:   2880, Loss function: 3.878, Average Loss: 4.238, avg. samples / sec: 65490.44
Iteration:   2880, Loss function: 3.567, Average Loss: 4.242, avg. samples / sec: 65570.24
Iteration:   2880, Loss function: 3.547, Average Loss: 4.240, avg. samples / sec: 65488.83
Iteration:   2880, Loss function: 5.038, Average Loss: 4.221, avg. samples / sec: 65625.75
Iteration:   2880, Loss function: 4.176, Average Loss: 4.244, avg. samples / sec: 65451.72
Iteration:   2880, Loss function: 3.354, Average Loss: 4.244, avg. samples / sec: 65387.70
Iteration:   2880, Loss function: 4.215, Average Loss: 4.236, avg. samples / sec: 65523.78
Iteration:   2880, Loss function: 3.316, Average Loss: 4.243, avg. samples / sec: 65533.71
Iteration:   2880, Loss function: 5.814, Average Loss: 4.232, avg. samples / sec: 65390.62
Iteration:   2880, Loss function: 4.095, Average Loss: 4.228, avg. samples / sec: 65434.03
Iteration:   2880, Loss function: 4.287, Average Loss: 4.230, avg. samples / sec: 65409.28
Iteration:   2880, Loss function: 4.340, Average Loss: 4.215, avg. samples / sec: 65377.15
Iteration:   2880, Loss function: 3.031, Average Loss: 4.251, avg. samples / sec: 65365.66
Iteration:   2900, Loss function: 4.983, Average Loss: 4.243, avg. samples / sec: 66058.29
Iteration:   2900, Loss function: 3.484, Average Loss: 4.237, avg. samples / sec: 65881.52
Iteration:   2900, Loss function: 5.160, Average Loss: 4.239, avg. samples / sec: 66037.30
Iteration:   2900, Loss function: 3.845, Average Loss: 4.253, avg. samples / sec: 65972.94
Iteration:   2900, Loss function: 3.708, Average Loss: 4.227, avg. samples / sec: 65921.21
Iteration:   2900, Loss function: 4.925, Average Loss: 4.265, avg. samples / sec: 65955.74
Iteration:   2900, Loss function: 4.452, Average Loss: 4.235, avg. samples / sec: 65953.73
Iteration:   2900, Loss function: 3.898, Average Loss: 4.228, avg. samples / sec: 66039.22
Iteration:   2900, Loss function: 3.818, Average Loss: 4.263, avg. samples / sec: 65895.14
Iteration:   2900, Loss function: 2.182, Average Loss: 4.223, avg. samples / sec: 66018.24
Iteration:   2900, Loss function: 3.537, Average Loss: 4.220, avg. samples / sec: 65853.42
Iteration:   2900, Loss function: 3.787, Average Loss: 4.235, avg. samples / sec: 65963.27
Iteration:   2900, Loss function: 4.202, Average Loss: 4.228, avg. samples / sec: 66075.48
Iteration:   2900, Loss function: 3.791, Average Loss: 4.247, avg. samples / sec: 66098.22
Iteration:   2900, Loss function: 4.462, Average Loss: 4.249, avg. samples / sec: 65876.23
Iteration:   2900, Loss function: 4.943, Average Loss: 4.229, avg. samples / sec: 65868.87
Iteration:   2900, Loss function: 3.380, Average Loss: 4.203, avg. samples / sec: 65813.87
Iteration:   2900, Loss function: 4.075, Average Loss: 4.211, avg. samples / sec: 66004.95
Iteration:   2900, Loss function: 2.065, Average Loss: 4.221, avg. samples / sec: 65784.01
Iteration:   2900, Loss function: 5.266, Average Loss: 4.220, avg. samples / sec: 65749.82
Iteration:   2900, Loss function: 4.373, Average Loss: 4.237, avg. samples / sec: 65869.73
Iteration:   2900, Loss function: 2.820, Average Loss: 4.214, avg. samples / sec: 65792.94
Iteration:   2900, Loss function: 4.564, Average Loss: 4.219, avg. samples / sec: 65891.56
Iteration:   2900, Loss function: 2.642, Average Loss: 4.228, avg. samples / sec: 65944.38
Iteration:   2900, Loss function: 3.903, Average Loss: 4.227, avg. samples / sec: 65790.61
Iteration:   2900, Loss function: 4.540, Average Loss: 4.237, avg. samples / sec: 65847.08
Iteration:   2900, Loss function: 5.057, Average Loss: 4.244, avg. samples / sec: 65860.31
Iteration:   2900, Loss function: 3.766, Average Loss: 4.214, avg. samples / sec: 65775.07
Iteration:   2900, Loss function: 4.213, Average Loss: 4.219, avg. samples / sec: 65707.39
Iteration:   2900, Loss function: 4.300, Average Loss: 4.243, avg. samples / sec: 65795.03
Iteration:   2920, Loss function: 3.592, Average Loss: 4.228, avg. samples / sec: 65998.67
Iteration:   2920, Loss function: 3.973, Average Loss: 4.215, avg. samples / sec: 66028.42
Iteration:   2920, Loss function: 4.439, Average Loss: 4.262, avg. samples / sec: 65996.72
Iteration:   2920, Loss function: 4.189, Average Loss: 4.233, avg. samples / sec: 66117.42
Iteration:   2920, Loss function: 5.139, Average Loss: 4.228, avg. samples / sec: 66028.64
Iteration:   2920, Loss function: 3.791, Average Loss: 4.214, avg. samples / sec: 66125.76
Iteration:   2920, Loss function: 4.900, Average Loss: 4.251, avg. samples / sec: 65887.50
Iteration:   2920, Loss function: 3.981, Average Loss: 4.242, avg. samples / sec: 65882.82
Iteration:   2920, Loss function: 2.812, Average Loss: 4.195, avg. samples / sec: 66016.60
Iteration:   2920, Loss function: 3.376, Average Loss: 4.223, avg. samples / sec: 65899.11
Iteration:   2920, Loss function: 3.192, Average Loss: 4.245, avg. samples / sec: 65969.29
Iteration:   2920, Loss function: 4.265, Average Loss: 4.263, avg. samples / sec: 65885.80
Iteration:   2920, Loss function: 3.386, Average Loss: 4.233, avg. samples / sec: 65856.15
Iteration:   2920, Loss function: 3.402, Average Loss: 4.239, avg. samples / sec: 66072.38
Iteration:   2920, Loss function: 3.721, Average Loss: 4.208, avg. samples / sec: 65992.06
Iteration:   2920, Loss function: 4.227, Average Loss: 4.212, avg. samples / sec: 65987.42
Iteration:   2920, Loss function: 2.628, Average Loss: 4.230, avg. samples / sec: 65912.74
Iteration:   2920, Loss function: 4.204, Average Loss: 4.241, avg. samples / sec: 65932.29
Iteration:   2920, Loss function: 4.396, Average Loss: 4.216, avg. samples / sec: 65984.77
Iteration:   2920, Loss function: 4.179, Average Loss: 4.217, avg. samples / sec: 65891.47
Iteration:   2920, Loss function: 3.795, Average Loss: 4.239, avg. samples / sec: 66066.43
Iteration:   2920, Loss function: 3.029, Average Loss: 4.221, avg. samples / sec: 65994.87
Iteration:   2920, Loss function: 2.971, Average Loss: 4.237, avg. samples / sec: 65801.21
Iteration:   2920, Loss function: 4.600, Average Loss: 4.208, avg. samples / sec: 65950.27
Iteration:   2920, Loss function: 3.347, Average Loss: 4.220, avg. samples / sec: 65873.24
Iteration:   2920, Loss function: 5.132, Average Loss: 4.213, avg. samples / sec: 66006.15
Iteration:   2920, Loss function: 3.699, Average Loss: 4.220, avg. samples / sec: 65947.65
Iteration:   2920, Loss function: 4.645, Average Loss: 4.219, avg. samples / sec: 65833.70
Iteration:   2920, Loss function: 2.805, Average Loss: 4.212, avg. samples / sec: 65904.29
Iteration:   2920, Loss function: 4.288, Average Loss: 4.231, avg. samples / sec: 65856.46
:::MLL 1558651436.311 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558651436.312 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 4.829, Average Loss: 4.215, avg. samples / sec: 65860.00
Iteration:   2940, Loss function: 4.350, Average Loss: 4.217, avg. samples / sec: 65818.51
Iteration:   2940, Loss function: 3.034, Average Loss: 4.257, avg. samples / sec: 65799.45
Iteration:   2940, Loss function: 4.331, Average Loss: 4.258, avg. samples / sec: 65738.13
Iteration:   2940, Loss function: 4.148, Average Loss: 4.226, avg. samples / sec: 65671.07
Iteration:   2940, Loss function: 3.543, Average Loss: 4.237, avg. samples / sec: 65762.39
Iteration:   2940, Loss function: 4.116, Average Loss: 4.225, avg. samples / sec: 65750.15
Iteration:   2940, Loss function: 4.382, Average Loss: 4.237, avg. samples / sec: 65819.52
Iteration:   2940, Loss function: 4.354, Average Loss: 4.204, avg. samples / sec: 65654.77
Iteration:   2940, Loss function: 3.310, Average Loss: 4.231, avg. samples / sec: 65687.51
Iteration:   2940, Loss function: 4.623, Average Loss: 4.223, avg. samples / sec: 65670.80
Iteration:   2940, Loss function: 2.628, Average Loss: 4.199, avg. samples / sec: 65783.58
Iteration:   2940, Loss function: 3.668, Average Loss: 4.244, avg. samples / sec: 65689.65
Iteration:   2940, Loss function: 5.032, Average Loss: 4.244, avg. samples / sec: 65695.20
Iteration:   2940, Loss function: 2.871, Average Loss: 4.236, avg. samples / sec: 65755.64
Iteration:   2940, Loss function: 4.163, Average Loss: 4.226, avg. samples / sec: 65701.41
Iteration:   2940, Loss function: 4.917, Average Loss: 4.213, avg. samples / sec: 65746.96
Iteration:   2940, Loss function: 3.889, Average Loss: 4.233, avg. samples / sec: 65707.36
Iteration:   2940, Loss function: 4.627, Average Loss: 4.217, avg. samples / sec: 65739.05
Iteration:   2940, Loss function: 3.605, Average Loss: 4.204, avg. samples / sec: 65798.13
Iteration:   2940, Loss function: 4.110, Average Loss: 4.210, avg. samples / sec: 65739.30
Iteration:   2940, Loss function: 3.334, Average Loss: 4.214, avg. samples / sec: 65711.37
Iteration:   2940, Loss function: 3.165, Average Loss: 4.207, avg. samples / sec: 65608.67
Iteration:   2940, Loss function: 4.760, Average Loss: 4.219, avg. samples / sec: 65700.34
Iteration:   2940, Loss function: 4.606, Average Loss: 4.192, avg. samples / sec: 65629.42
Iteration:   2940, Loss function: 3.837, Average Loss: 4.204, avg. samples / sec: 65656.05
Iteration:   2940, Loss function: 3.671, Average Loss: 4.232, avg. samples / sec: 65642.99
Iteration:   2940, Loss function: 4.037, Average Loss: 4.227, avg. samples / sec: 65737.61
Iteration:   2940, Loss function: 3.699, Average Loss: 4.215, avg. samples / sec: 65605.25
Iteration:   2940, Loss function: 3.908, Average Loss: 4.214, avg. samples / sec: 65566.58
Iteration:   2960, Loss function: 3.699, Average Loss: 4.233, avg. samples / sec: 65916.93
Iteration:   2960, Loss function: 3.971, Average Loss: 4.234, avg. samples / sec: 65891.13
Iteration:   2960, Loss function: 4.394, Average Loss: 4.241, avg. samples / sec: 65954.69
Iteration:   2960, Loss function: 3.696, Average Loss: 4.199, avg. samples / sec: 65909.53
Iteration:   2960, Loss function: 3.816, Average Loss: 4.214, avg. samples / sec: 65968.12
Iteration:   2960, Loss function: 4.382, Average Loss: 4.198, avg. samples / sec: 65980.78
Iteration:   2960, Loss function: 2.799, Average Loss: 4.223, avg. samples / sec: 65857.45
Iteration:   2960, Loss function: 3.015, Average Loss: 4.201, avg. samples / sec: 65940.65
Iteration:   2960, Loss function: 3.570, Average Loss: 4.250, avg. samples / sec: 65786.98
Iteration:   2960, Loss function: 3.591, Average Loss: 4.253, avg. samples / sec: 65792.97
Iteration:   2960, Loss function: 4.023, Average Loss: 4.211, avg. samples / sec: 65753.56
Iteration:   2960, Loss function: 3.278, Average Loss: 4.239, avg. samples / sec: 65875.21
Iteration:   2960, Loss function: 4.070, Average Loss: 4.199, avg. samples / sec: 65827.15
Iteration:   2960, Loss function: 4.243, Average Loss: 4.209, avg. samples / sec: 65910.52
Iteration:   2960, Loss function: 4.309, Average Loss: 4.231, avg. samples / sec: 65884.94
Iteration:   2960, Loss function: 3.979, Average Loss: 4.216, avg. samples / sec: 65877.92
Iteration:   2960, Loss function: 4.337, Average Loss: 4.227, avg. samples / sec: 65873.92
Iteration:   2960, Loss function: 3.778, Average Loss: 4.211, avg. samples / sec: 65700.10
Iteration:   2960, Loss function: 3.943, Average Loss: 4.204, avg. samples / sec: 65908.88
Iteration:   2960, Loss function: 4.306, Average Loss: 4.220, avg. samples / sec: 65811.78
Iteration:   2960, Loss function: 3.870, Average Loss: 4.222, avg. samples / sec: 65849.20
Iteration:   2960, Loss function: 3.862, Average Loss: 4.215, avg. samples / sec: 65849.17
Iteration:   2960, Loss function: 3.846, Average Loss: 4.208, avg. samples / sec: 65998.42
Iteration:   2960, Loss function: 3.949, Average Loss: 4.182, avg. samples / sec: 65867.67
Iteration:   2960, Loss function: 4.711, Average Loss: 4.204, avg. samples / sec: 65837.20
Iteration:   2960, Loss function: 3.602, Average Loss: 4.227, avg. samples / sec: 65855.20
Iteration:   2960, Loss function: 3.710, Average Loss: 4.220, avg. samples / sec: 65918.81
Iteration:   2960, Loss function: 3.308, Average Loss: 4.216, avg. samples / sec: 65727.22
Iteration:   2960, Loss function: 2.291, Average Loss: 4.219, avg. samples / sec: 65678.33
Iteration:   2960, Loss function: 3.392, Average Loss: 4.206, avg. samples / sec: 65853.42
Iteration:   2980, Loss function: 4.083, Average Loss: 4.233, avg. samples / sec: 65788.49
Iteration:   2980, Loss function: 4.611, Average Loss: 4.208, avg. samples / sec: 65885.90
Iteration:   2980, Loss function: 3.462, Average Loss: 4.212, avg. samples / sec: 65915.33
Iteration:   2980, Loss function: 4.443, Average Loss: 4.225, avg. samples / sec: 65682.37
Iteration:   2980, Loss function: 2.640, Average Loss: 4.220, avg. samples / sec: 65766.26
Iteration:   2980, Loss function: 4.872, Average Loss: 4.213, avg. samples / sec: 65697.92
Iteration:   2980, Loss function: 4.729, Average Loss: 4.220, avg. samples / sec: 65773.72
Iteration:   2980, Loss function: 3.866, Average Loss: 4.193, avg. samples / sec: 65670.03
Iteration:   2980, Loss function: 4.901, Average Loss: 4.233, avg. samples / sec: 65696.85
Iteration:   2980, Loss function: 4.038, Average Loss: 4.214, avg. samples / sec: 65748.90
Iteration:   2980, Loss function: 3.960, Average Loss: 4.193, avg. samples / sec: 65665.38
Iteration:   2980, Loss function: 4.085, Average Loss: 4.231, avg. samples / sec: 65564.69
Iteration:   2980, Loss function: 4.309, Average Loss: 4.210, avg. samples / sec: 65753.62
Iteration:   2980, Loss function: 3.875, Average Loss: 4.192, avg. samples / sec: 65667.98
Iteration:   2980, Loss function: 3.176, Average Loss: 4.215, avg. samples / sec: 65686.44
Iteration:   2980, Loss function: 4.021, Average Loss: 4.176, avg. samples / sec: 65736.66
Iteration:   2980, Loss function: 3.422, Average Loss: 4.217, avg. samples / sec: 65732.89
Iteration:   2980, Loss function: 4.526, Average Loss: 4.225, avg. samples / sec: 65658.01
Iteration:   2980, Loss function: 3.524, Average Loss: 4.199, avg. samples / sec: 65705.64
Iteration:   2980, Loss function: 4.298, Average Loss: 4.204, avg. samples / sec: 65661.07
Iteration:   2980, Loss function: 3.350, Average Loss: 4.222, avg. samples / sec: 65714.65
Iteration:   2980, Loss function: 3.391, Average Loss: 4.200, avg. samples / sec: 65658.22
Iteration:   2980, Loss function: 4.202, Average Loss: 4.196, avg. samples / sec: 65574.33
Iteration:   2980, Loss function: 3.507, Average Loss: 4.244, avg. samples / sec: 65587.48
Iteration:   2980, Loss function: 4.898, Average Loss: 4.213, avg. samples / sec: 65571.16
Iteration:   2980, Loss function: 3.385, Average Loss: 4.201, avg. samples / sec: 65731.08
Iteration:   2980, Loss function: 3.714, Average Loss: 4.193, avg. samples / sec: 65652.84
Iteration:   2980, Loss function: 3.544, Average Loss: 4.210, avg. samples / sec: 65682.80
Iteration:   2980, Loss function: 4.865, Average Loss: 4.245, avg. samples / sec: 65553.62
Iteration:   2980, Loss function: 4.493, Average Loss: 4.205, avg. samples / sec: 65573.32
Iteration:   3000, Loss function: 3.987, Average Loss: 4.190, avg. samples / sec: 65938.27
Iteration:   3000, Loss function: 4.831, Average Loss: 4.204, avg. samples / sec: 65993.70
Iteration:   3000, Loss function: 3.140, Average Loss: 4.223, avg. samples / sec: 65904.81
Iteration:   3000, Loss function: 3.679, Average Loss: 4.207, avg. samples / sec: 65781.40
Iteration:   3000, Loss function: 3.680, Average Loss: 4.238, avg. samples / sec: 65962.93
Iteration:   3000, Loss function: 3.820, Average Loss: 4.208, avg. samples / sec: 65951.17
Iteration:   3000, Loss function: 3.813, Average Loss: 4.212, avg. samples / sec: 65894.46
Iteration:   3000, Loss function: 3.515, Average Loss: 4.213, avg. samples / sec: 65859.94
Iteration:   3000, Loss function: 4.816, Average Loss: 4.218, avg. samples / sec: 65789.20
Iteration:   3000, Loss function: 3.902, Average Loss: 4.175, avg. samples / sec: 65856.77
Iteration:   3000, Loss function: 3.144, Average Loss: 4.212, avg. samples / sec: 65886.57
Iteration:   3000, Loss function: 3.780, Average Loss: 4.189, avg. samples / sec: 65827.24
Iteration:   3000, Loss function: 3.517, Average Loss: 4.231, avg. samples / sec: 65650.15
Iteration:   3000, Loss function: 5.739, Average Loss: 4.203, avg. samples / sec: 65848.58
Iteration:   3000, Loss function: 4.254, Average Loss: 4.216, avg. samples / sec: 65761.14
Iteration:   3000, Loss function: 4.562, Average Loss: 4.190, avg. samples / sec: 65815.56
Iteration:   3000, Loss function: 3.508, Average Loss: 4.218, avg. samples / sec: 65844.06
Iteration:   3000, Loss function: 2.817, Average Loss: 4.197, avg. samples / sec: 65807.90
Iteration:   3000, Loss function: 3.838, Average Loss: 4.205, avg. samples / sec: 65609.47
Iteration:   3000, Loss function: 3.517, Average Loss: 4.243, avg. samples / sec: 65891.35
Iteration:   3000, Loss function: 3.293, Average Loss: 4.194, avg. samples / sec: 65849.23
Iteration:   3000, Loss function: 3.450, Average Loss: 4.194, avg. samples / sec: 65792.79
Iteration:   3000, Loss function: 2.933, Average Loss: 4.203, avg. samples / sec: 65841.32
Iteration:   3000, Loss function: 3.309, Average Loss: 4.213, avg. samples / sec: 65737.00
Iteration:   3000, Loss function: 2.978, Average Loss: 4.207, avg. samples / sec: 65668.47
Iteration:   3000, Loss function: 3.836, Average Loss: 4.203, avg. samples / sec: 65799.15
Iteration:   3000, Loss function: 3.329, Average Loss: 4.211, avg. samples / sec: 65599.02
Iteration:   3000, Loss function: 3.618, Average Loss: 4.195, avg. samples / sec: 65679.40
Iteration:   3000, Loss function: 4.787, Average Loss: 4.226, avg. samples / sec: 65557.34
Iteration:   3000, Loss function: 4.356, Average Loss: 4.210, avg. samples / sec: 65525.40
:::MLL 1558651438.101 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558651438.102 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 3.976, Average Loss: 4.198, avg. samples / sec: 65595.39
Iteration:   3020, Loss function: 3.233, Average Loss: 4.188, avg. samples / sec: 65499.66
Iteration:   3020, Loss function: 2.561, Average Loss: 4.233, avg. samples / sec: 65383.31
Iteration:   3020, Loss function: 3.133, Average Loss: 4.186, avg. samples / sec: 65461.48
Iteration:   3020, Loss function: 4.604, Average Loss: 4.204, avg. samples / sec: 65498.32
Iteration:   3020, Loss function: 4.412, Average Loss: 4.203, avg. samples / sec: 65401.30
Iteration:   3020, Loss function: 3.223, Average Loss: 4.206, avg. samples / sec: 65480.55
Iteration:   3020, Loss function: 3.697, Average Loss: 4.204, avg. samples / sec: 65661.22
Iteration:   3020, Loss function: 4.640, Average Loss: 4.201, avg. samples / sec: 65312.76
Iteration:   3020, Loss function: 5.109, Average Loss: 4.205, avg. samples / sec: 65330.90
Iteration:   3020, Loss function: 3.404, Average Loss: 4.220, avg. samples / sec: 65282.02
Iteration:   3020, Loss function: 4.434, Average Loss: 4.186, avg. samples / sec: 65430.75
Iteration:   3020, Loss function: 3.451, Average Loss: 4.175, avg. samples / sec: 65322.03
Iteration:   3020, Loss function: 3.600, Average Loss: 4.193, avg. samples / sec: 65373.33
Iteration:   3020, Loss function: 3.421, Average Loss: 4.217, avg. samples / sec: 65574.91
Iteration:   3020, Loss function: 3.627, Average Loss: 4.202, avg. samples / sec: 65500.70
Iteration:   3020, Loss function: 4.095, Average Loss: 4.203, avg. samples / sec: 65429.11
Iteration:   3020, Loss function: 5.380, Average Loss: 4.210, avg. samples / sec: 65322.69
Iteration:   3020, Loss function: 3.334, Average Loss: 4.207, avg. samples / sec: 65256.06
Iteration:   3020, Loss function: 4.569, Average Loss: 4.186, avg. samples / sec: 65170.51
Iteration:   3020, Loss function: 3.424, Average Loss: 4.185, avg. samples / sec: 65379.94
Iteration:   3020, Loss function: 4.041, Average Loss: 4.203, avg. samples / sec: 65215.26
Iteration:   3020, Loss function: 4.972, Average Loss: 4.229, avg. samples / sec: 65282.87
Iteration:   3020, Loss function: 4.067, Average Loss: 4.211, avg. samples / sec: 65248.69
Iteration:   3020, Loss function: 4.875, Average Loss: 4.212, avg. samples / sec: 65218.01
Iteration:   3020, Loss function: 4.003, Average Loss: 4.205, avg. samples / sec: 65196.62
Iteration:   3020, Loss function: 3.461, Average Loss: 4.200, avg. samples / sec: 65299.14
Iteration:   3020, Loss function: 4.674, Average Loss: 4.213, avg. samples / sec: 65269.33
Iteration:   3020, Loss function: 4.174, Average Loss: 4.192, avg. samples / sec: 65368.08
Iteration:   3020, Loss function: 4.037, Average Loss: 4.240, avg. samples / sec: 65210.92
Iteration:   3040, Loss function: 4.545, Average Loss: 4.213, avg. samples / sec: 66003.80
Iteration:   3040, Loss function: 5.187, Average Loss: 4.194, avg. samples / sec: 65803.14
Iteration:   3040, Loss function: 4.195, Average Loss: 4.213, avg. samples / sec: 66090.29
Iteration:   3040, Loss function: 4.329, Average Loss: 4.197, avg. samples / sec: 66025.51
Iteration:   3040, Loss function: 3.818, Average Loss: 4.194, avg. samples / sec: 65891.26
Iteration:   3040, Loss function: 4.004, Average Loss: 4.215, avg. samples / sec: 65920.78
Iteration:   3040, Loss function: 4.099, Average Loss: 4.225, avg. samples / sec: 65778.48
Iteration:   3040, Loss function: 3.872, Average Loss: 4.222, avg. samples / sec: 65919.43
Iteration:   3040, Loss function: 3.758, Average Loss: 4.170, avg. samples / sec: 65873.82
Iteration:   3040, Loss function: 4.592, Average Loss: 4.203, avg. samples / sec: 65836.65
Iteration:   3040, Loss function: 4.324, Average Loss: 4.182, avg. samples / sec: 65840.59
Iteration:   3040, Loss function: 3.557, Average Loss: 4.206, avg. samples / sec: 65967.59
Iteration:   3040, Loss function: 4.137, Average Loss: 4.200, avg. samples / sec: 65793.68
Iteration:   3040, Loss function: 2.968, Average Loss: 4.202, avg. samples / sec: 65868.07
Iteration:   3040, Loss function: 2.683, Average Loss: 4.201, avg. samples / sec: 65859.02
Iteration:   3040, Loss function: 4.625, Average Loss: 4.192, avg. samples / sec: 65838.80
Iteration:   3040, Loss function: 3.657, Average Loss: 4.193, avg. samples / sec: 65953.02
Iteration:   3040, Loss function: 3.039, Average Loss: 4.198, avg. samples / sec: 65791.74
Iteration:   3040, Loss function: 4.098, Average Loss: 4.199, avg. samples / sec: 65858.19
Iteration:   3040, Loss function: 4.784, Average Loss: 4.200, avg. samples / sec: 65748.99
Iteration:   3040, Loss function: 5.279, Average Loss: 4.211, avg. samples / sec: 65856.95
Iteration:   3040, Loss function: 3.886, Average Loss: 4.179, avg. samples / sec: 65837.69
Iteration:   3040, Loss function: 4.536, Average Loss: 4.184, avg. samples / sec: 65619.18
Iteration:   3040, Loss function: 3.535, Average Loss: 4.182, avg. samples / sec: 65670.52
Iteration:   3040, Loss function: 3.021, Average Loss: 4.237, avg. samples / sec: 65956.69
Iteration:   3040, Loss function: 3.223, Average Loss: 4.205, avg. samples / sec: 65869.88
Iteration:   3040, Loss function: 3.174, Average Loss: 4.202, avg. samples / sec: 65735.52
Iteration:   3040, Loss function: 2.770, Average Loss: 4.185, avg. samples / sec: 65892.95
Iteration:   3040, Loss function: 4.385, Average Loss: 4.198, avg. samples / sec: 65728.41
Iteration:   3040, Loss function: 3.593, Average Loss: 4.185, avg. samples / sec: 65692.38
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558651439.084 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.35s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.34s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.34s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.35s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.38s)
DONE (t=2.10s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.16992
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31489
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17016
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04262
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.17535
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.27769
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18155
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26271
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07452
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.28957
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.43646
Current AP: 0.16992 AP goal: 0.23000
:::MLL 1558651442.165 eval_accuracy: {"value": 0.16991969911487773, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558651442.302 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558651442.309 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558651442.309 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 3.301, Average Loss: 4.228, avg. samples / sec: 8981.14
Iteration:   3060, Loss function: 4.587, Average Loss: 4.210, avg. samples / sec: 8975.74
Iteration:   3060, Loss function: 4.176, Average Loss: 4.200, avg. samples / sec: 8978.08
Iteration:   3060, Loss function: 3.877, Average Loss: 4.178, avg. samples / sec: 8979.59
Iteration:   3060, Loss function: 3.955, Average Loss: 4.215, avg. samples / sec: 8977.50
Iteration:   3060, Loss function: 4.026, Average Loss: 4.192, avg. samples / sec: 8977.83
Iteration:   3060, Loss function: 4.335, Average Loss: 4.193, avg. samples / sec: 8977.50
Iteration:   3060, Loss function: 3.982, Average Loss: 4.172, avg. samples / sec: 8979.34
Iteration:   3060, Loss function: 3.602, Average Loss: 4.195, avg. samples / sec: 8976.53
Iteration:   3060, Loss function: 3.722, Average Loss: 4.176, avg. samples / sec: 8980.07
Iteration:   3060, Loss function: 4.417, Average Loss: 4.200, avg. samples / sec: 8978.34
Iteration:   3060, Loss function: 4.291, Average Loss: 4.174, avg. samples / sec: 8977.95
Iteration:   3060, Loss function: 4.294, Average Loss: 4.209, avg. samples / sec: 8974.15
Iteration:   3060, Loss function: 3.802, Average Loss: 4.189, avg. samples / sec: 8976.95
Iteration:   3060, Loss function: 3.469, Average Loss: 4.183, avg. samples / sec: 8976.62
Iteration:   3060, Loss function: 4.010, Average Loss: 4.198, avg. samples / sec: 8976.65
Iteration:   3060, Loss function: 5.164, Average Loss: 4.211, avg. samples / sec: 8975.07
Iteration:   3060, Loss function: 3.153, Average Loss: 4.190, avg. samples / sec: 8978.83
Iteration:   3060, Loss function: 3.324, Average Loss: 4.222, avg. samples / sec: 8975.48
Iteration:   3060, Loss function: 5.352, Average Loss: 4.200, avg. samples / sec: 8977.41
Iteration:   3060, Loss function: 4.209, Average Loss: 4.205, avg. samples / sec: 8977.14
Iteration:   3060, Loss function: 4.590, Average Loss: 4.168, avg. samples / sec: 8975.19
Iteration:   3060, Loss function: 2.681, Average Loss: 4.173, avg. samples / sec: 8976.96
Iteration:   3060, Loss function: 3.072, Average Loss: 4.192, avg. samples / sec: 8973.21
Iteration:   3060, Loss function: 2.734, Average Loss: 4.191, avg. samples / sec: 8975.83
Iteration:   3060, Loss function: 3.679, Average Loss: 4.196, avg. samples / sec: 8975.71
Iteration:   3060, Loss function: 3.087, Average Loss: 4.191, avg. samples / sec: 8971.49
Iteration:   3060, Loss function: 3.076, Average Loss: 4.195, avg. samples / sec: 8974.60
Iteration:   3060, Loss function: 2.842, Average Loss: 4.172, avg. samples / sec: 8973.86
Iteration:   3060, Loss function: 3.304, Average Loss: 4.192, avg. samples / sec: 8972.38
:::MLL 1558651443.124 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558651443.124 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 5.307, Average Loss: 4.203, avg. samples / sec: 65707.20
Iteration:   3080, Loss function: 3.789, Average Loss: 4.179, avg. samples / sec: 65772.40
Iteration:   3080, Loss function: 2.822, Average Loss: 4.215, avg. samples / sec: 65530.76
Iteration:   3080, Loss function: 3.192, Average Loss: 4.163, avg. samples / sec: 65663.30
Iteration:   3080, Loss function: 4.113, Average Loss: 4.161, avg. samples / sec: 65657.64
Iteration:   3080, Loss function: 4.597, Average Loss: 4.186, avg. samples / sec: 65661.59
Iteration:   3080, Loss function: 3.827, Average Loss: 4.209, avg. samples / sec: 65699.73
Iteration:   3080, Loss function: 4.256, Average Loss: 4.169, avg. samples / sec: 65697.68
Iteration:   3080, Loss function: 2.666, Average Loss: 4.196, avg. samples / sec: 65654.28
Iteration:   3080, Loss function: 3.540, Average Loss: 4.189, avg. samples / sec: 65661.44
Iteration:   3080, Loss function: 3.344, Average Loss: 4.183, avg. samples / sec: 65624.01
Iteration:   3080, Loss function: 3.401, Average Loss: 4.171, avg. samples / sec: 65548.16
Iteration:   3080, Loss function: 4.553, Average Loss: 4.161, avg. samples / sec: 65671.41
Iteration:   3080, Loss function: 3.041, Average Loss: 4.179, avg. samples / sec: 65563.56
Iteration:   3080, Loss function: 3.466, Average Loss: 4.182, avg. samples / sec: 65727.49
Iteration:   3080, Loss function: 4.485, Average Loss: 4.183, avg. samples / sec: 65657.49
Iteration:   3080, Loss function: 3.526, Average Loss: 4.176, avg. samples / sec: 65600.46
Iteration:   3080, Loss function: 4.206, Average Loss: 4.180, avg. samples / sec: 65569.94
Iteration:   3080, Loss function: 4.732, Average Loss: 4.186, avg. samples / sec: 65639.84
Iteration:   3080, Loss function: 3.112, Average Loss: 4.193, avg. samples / sec: 65433.85
Iteration:   3080, Loss function: 3.756, Average Loss: 4.186, avg. samples / sec: 65685.89
Iteration:   3080, Loss function: 4.876, Average Loss: 4.175, avg. samples / sec: 65548.28
Iteration:   3080, Loss function: 4.727, Average Loss: 4.196, avg. samples / sec: 65565.76
Iteration:   3080, Loss function: 3.823, Average Loss: 4.197, avg. samples / sec: 65406.82
Iteration:   3080, Loss function: 3.364, Average Loss: 4.159, avg. samples / sec: 65469.42
Iteration:   3080, Loss function: 3.653, Average Loss: 4.181, avg. samples / sec: 65572.13
Iteration:   3080, Loss function: 3.123, Average Loss: 4.183, avg. samples / sec: 65436.74
Iteration:   3080, Loss function: 2.872, Average Loss: 4.203, avg. samples / sec: 65468.32
Iteration:   3080, Loss function: 2.587, Average Loss: 4.191, avg. samples / sec: 65397.54
Iteration:   3080, Loss function: 2.992, Average Loss: 4.164, avg. samples / sec: 65443.03
Iteration:   3100, Loss function: 4.424, Average Loss: 4.187, avg. samples / sec: 66047.60
Iteration:   3100, Loss function: 3.026, Average Loss: 4.171, avg. samples / sec: 65867.14
Iteration:   3100, Loss function: 3.085, Average Loss: 4.169, avg. samples / sec: 65995.83
Iteration:   3100, Loss function: 3.549, Average Loss: 4.160, avg. samples / sec: 65816.60
Iteration:   3100, Loss function: 3.915, Average Loss: 4.206, avg. samples / sec: 65750.89
Iteration:   3100, Loss function: 2.666, Average Loss: 4.166, avg. samples / sec: 65832.53
Iteration:   3100, Loss function: 4.857, Average Loss: 4.151, avg. samples / sec: 65787.81
Iteration:   3100, Loss function: 3.232, Average Loss: 4.193, avg. samples / sec: 65660.61
Iteration:   3100, Loss function: 5.074, Average Loss: 4.150, avg. samples / sec: 65760.55
Iteration:   3100, Loss function: 3.089, Average Loss: 4.187, avg. samples / sec: 65906.48
Iteration:   3100, Loss function: 3.276, Average Loss: 4.175, avg. samples / sec: 65870.90
Iteration:   3100, Loss function: 3.506, Average Loss: 4.183, avg. samples / sec: 65764.94
Iteration:   3100, Loss function: 3.192, Average Loss: 4.175, avg. samples / sec: 65736.08
Iteration:   3100, Loss function: 3.707, Average Loss: 4.152, avg. samples / sec: 65808.37
Iteration:   3100, Loss function: 5.649, Average Loss: 4.181, avg. samples / sec: 65841.51
Iteration:   3100, Loss function: 3.497, Average Loss: 4.164, avg. samples / sec: 65822.10
Iteration:   3100, Loss function: 3.057, Average Loss: 4.185, avg. samples / sec: 65932.16
Iteration:   3100, Loss function: 4.819, Average Loss: 4.171, avg. samples / sec: 65774.98
Iteration:   3100, Loss function: 3.859, Average Loss: 4.159, avg. samples / sec: 65718.66
Iteration:   3100, Loss function: 2.914, Average Loss: 4.163, avg. samples / sec: 65843.60
Iteration:   3100, Loss function: 2.855, Average Loss: 4.169, avg. samples / sec: 65648.44
Iteration:   3100, Loss function: 2.959, Average Loss: 4.197, avg. samples / sec: 65705.06
Iteration:   3100, Loss function: 4.209, Average Loss: 4.168, avg. samples / sec: 65787.41
Iteration:   3100, Loss function: 4.929, Average Loss: 4.153, avg. samples / sec: 66040.55
Iteration:   3100, Loss function: 3.628, Average Loss: 4.150, avg. samples / sec: 65829.55
Iteration:   3100, Loss function: 3.298, Average Loss: 4.170, avg. samples / sec: 65860.56
Iteration:   3100, Loss function: 4.688, Average Loss: 4.175, avg. samples / sec: 65740.86
Iteration:   3100, Loss function: 4.287, Average Loss: 4.182, avg. samples / sec: 65679.89
Iteration:   3100, Loss function: 3.415, Average Loss: 4.186, avg. samples / sec: 65751.20
Iteration:   3100, Loss function: 3.155, Average Loss: 4.172, avg. samples / sec: 65896.93
Iteration:   3120, Loss function: 2.757, Average Loss: 4.136, avg. samples / sec: 66230.96
Iteration:   3120, Loss function: 3.919, Average Loss: 4.162, avg. samples / sec: 66168.39
Iteration:   3120, Loss function: 3.820, Average Loss: 4.178, avg. samples / sec: 66222.27
Iteration:   3120, Loss function: 2.450, Average Loss: 4.147, avg. samples / sec: 66223.05
Iteration:   3120, Loss function: 2.892, Average Loss: 4.175, avg. samples / sec: 66310.86
Iteration:   3120, Loss function: 2.840, Average Loss: 4.148, avg. samples / sec: 66217.79
Iteration:   3120, Loss function: 5.428, Average Loss: 4.161, avg. samples / sec: 66118.66
Iteration:   3120, Loss function: 3.610, Average Loss: 4.172, avg. samples / sec: 66162.74
Iteration:   3120, Loss function: 4.303, Average Loss: 4.161, avg. samples / sec: 66180.42
Iteration:   3120, Loss function: 4.352, Average Loss: 4.161, avg. samples / sec: 66067.73
Iteration:   3120, Loss function: 2.956, Average Loss: 4.144, avg. samples / sec: 66119.15
Iteration:   3120, Loss function: 3.538, Average Loss: 4.180, avg. samples / sec: 65990.39
Iteration:   3120, Loss function: 2.263, Average Loss: 4.141, avg. samples / sec: 66137.15
Iteration:   3120, Loss function: 2.572, Average Loss: 4.155, avg. samples / sec: 66180.94
Iteration:   3120, Loss function: 4.470, Average Loss: 4.143, avg. samples / sec: 66108.73
Iteration:   3120, Loss function: 3.114, Average Loss: 4.147, avg. samples / sec: 66178.80
Iteration:   3120, Loss function: 3.754, Average Loss: 4.155, avg. samples / sec: 66183.90
Iteration:   3120, Loss function: 4.086, Average Loss: 4.177, avg. samples / sec: 66098.72
Iteration:   3120, Loss function: 3.309, Average Loss: 4.137, avg. samples / sec: 66192.82
Iteration:   3120, Loss function: 3.938, Average Loss: 4.152, avg. samples / sec: 66071.45
Iteration:   3120, Loss function: 4.280, Average Loss: 4.167, avg. samples / sec: 66184.27
Iteration:   3120, Loss function: 3.585, Average Loss: 4.193, avg. samples / sec: 66057.54
Iteration:   3120, Loss function: 3.767, Average Loss: 4.157, avg. samples / sec: 66152.71
Iteration:   3120, Loss function: 3.501, Average Loss: 4.163, avg. samples / sec: 66152.95
Iteration:   3120, Loss function: 4.865, Average Loss: 4.154, avg. samples / sec: 66088.80
Iteration:   3120, Loss function: 3.162, Average Loss: 4.168, avg. samples / sec: 66050.86
Iteration:   3120, Loss function: 3.632, Average Loss: 4.161, avg. samples / sec: 66172.99
Iteration:   3120, Loss function: 2.254, Average Loss: 4.186, avg. samples / sec: 66044.05
Iteration:   3120, Loss function: 3.369, Average Loss: 4.143, avg. samples / sec: 66055.31
Iteration:   3120, Loss function: 3.921, Average Loss: 4.174, avg. samples / sec: 65969.57
Iteration:   3140, Loss function: 3.468, Average Loss: 4.170, avg. samples / sec: 66105.14
Iteration:   3140, Loss function: 2.543, Average Loss: 4.141, avg. samples / sec: 66107.87
Iteration:   3140, Loss function: 3.864, Average Loss: 4.165, avg. samples / sec: 66042.99
Iteration:   3140, Loss function: 3.510, Average Loss: 4.127, avg. samples / sec: 66073.21
Iteration:   3140, Loss function: 3.488, Average Loss: 4.133, avg. samples / sec: 66110.66
Iteration:   3140, Loss function: 3.938, Average Loss: 4.127, avg. samples / sec: 66046.27
Iteration:   3140, Loss function: 3.813, Average Loss: 4.169, avg. samples / sec: 66080.06
Iteration:   3140, Loss function: 3.540, Average Loss: 4.141, avg. samples / sec: 66120.43
Iteration:   3140, Loss function: 3.611, Average Loss: 4.142, avg. samples / sec: 66019.45
Iteration:   3140, Loss function: 2.261, Average Loss: 4.140, avg. samples / sec: 66072.62
Iteration:   3140, Loss function: 3.700, Average Loss: 4.133, avg. samples / sec: 65990.24
Iteration:   3140, Loss function: 3.826, Average Loss: 4.146, avg. samples / sec: 66006.00
Iteration:   3140, Loss function: 1.653, Average Loss: 4.151, avg. samples / sec: 65982.23
Iteration:   3140, Loss function: 3.588, Average Loss: 4.120, avg. samples / sec: 65876.13
Iteration:   3140, Loss function: 3.175, Average Loss: 4.143, avg. samples / sec: 66062.71
Iteration:   3140, Loss function: 3.313, Average Loss: 4.178, avg. samples / sec: 66065.04
Iteration:   3140, Loss function: 2.829, Average Loss: 4.163, avg. samples / sec: 65943.64
Iteration:   3140, Loss function: 3.926, Average Loss: 4.134, avg. samples / sec: 66002.60
Iteration:   3140, Loss function: 4.383, Average Loss: 4.149, avg. samples / sec: 66117.79
Iteration:   3140, Loss function: 3.207, Average Loss: 4.157, avg. samples / sec: 66032.47
Iteration:   3140, Loss function: 2.987, Average Loss: 4.152, avg. samples / sec: 66084.58
Iteration:   3140, Loss function: 3.525, Average Loss: 4.161, avg. samples / sec: 66103.12
Iteration:   3140, Loss function: 4.133, Average Loss: 4.144, avg. samples / sec: 65915.08
Iteration:   3140, Loss function: 3.394, Average Loss: 4.132, avg. samples / sec: 65936.85
Iteration:   3140, Loss function: 4.100, Average Loss: 4.160, avg. samples / sec: 65888.92
Iteration:   3140, Loss function: 4.960, Average Loss: 4.129, avg. samples / sec: 65959.13
Iteration:   3140, Loss function: 2.887, Average Loss: 4.139, avg. samples / sec: 66014.19
Iteration:   3140, Loss function: 3.930, Average Loss: 4.135, avg. samples / sec: 66047.14
Iteration:   3140, Loss function: 3.728, Average Loss: 4.130, avg. samples / sec: 65845.66
Iteration:   3140, Loss function: 4.535, Average Loss: 4.174, avg. samples / sec: 66015.49
:::MLL 1558651444.909 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558651444.910 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 3.611, Average Loss: 4.155, avg. samples / sec: 65565.36
Iteration:   3160, Loss function: 2.692, Average Loss: 4.127, avg. samples / sec: 65645.93
Iteration:   3160, Loss function: 2.796, Average Loss: 4.124, avg. samples / sec: 65532.50
Iteration:   3160, Loss function: 3.433, Average Loss: 4.150, avg. samples / sec: 65436.28
Iteration:   3160, Loss function: 3.690, Average Loss: 4.120, avg. samples / sec: 65535.33
Iteration:   3160, Loss function: 2.815, Average Loss: 4.145, avg. samples / sec: 65593.86
Iteration:   3160, Loss function: 3.414, Average Loss: 4.123, avg. samples / sec: 65471.73
Iteration:   3160, Loss function: 3.806, Average Loss: 4.131, avg. samples / sec: 65394.89
Iteration:   3160, Loss function: 3.638, Average Loss: 4.117, avg. samples / sec: 65609.74
Iteration:   3160, Loss function: 3.121, Average Loss: 4.162, avg. samples / sec: 65631.59
Iteration:   3160, Loss function: 3.043, Average Loss: 4.130, avg. samples / sec: 65446.89
Iteration:   3160, Loss function: 2.947, Average Loss: 4.147, avg. samples / sec: 65511.54
Iteration:   3160, Loss function: 5.146, Average Loss: 4.135, avg. samples / sec: 65447.80
Iteration:   3160, Loss function: 3.022, Average Loss: 4.118, avg. samples / sec: 65382.00
Iteration:   3160, Loss function: 2.268, Average Loss: 4.133, avg. samples / sec: 65442.51
Iteration:   3160, Loss function: 4.340, Average Loss: 4.143, avg. samples / sec: 65498.51
Iteration:   3160, Loss function: 3.291, Average Loss: 4.115, avg. samples / sec: 65535.91
Iteration:   3160, Loss function: 3.213, Average Loss: 4.146, avg. samples / sec: 65515.19
Iteration:   3160, Loss function: 3.753, Average Loss: 4.129, avg. samples / sec: 65518.33
Iteration:   3160, Loss function: 3.081, Average Loss: 4.166, avg. samples / sec: 65463.94
Iteration:   3160, Loss function: 3.508, Average Loss: 4.120, avg. samples / sec: 65361.20
Iteration:   3160, Loss function: 3.793, Average Loss: 4.138, avg. samples / sec: 65418.57
Iteration:   3160, Loss function: 4.700, Average Loss: 4.113, avg. samples / sec: 65444.27
Iteration:   3160, Loss function: 3.297, Average Loss: 4.128, avg. samples / sec: 65445.94
Iteration:   3160, Loss function: 3.331, Average Loss: 4.119, avg. samples / sec: 65503.59
Iteration:   3160, Loss function: 3.254, Average Loss: 4.134, avg. samples / sec: 65429.45
Iteration:   3160, Loss function: 3.968, Average Loss: 4.125, avg. samples / sec: 65492.23
Iteration:   3160, Loss function: 3.200, Average Loss: 4.135, avg. samples / sec: 65422.22
Iteration:   3160, Loss function: 4.626, Average Loss: 4.115, avg. samples / sec: 65334.38
Iteration:   3160, Loss function: 3.124, Average Loss: 4.160, avg. samples / sec: 65217.92
Iteration:   3180, Loss function: 3.217, Average Loss: 4.147, avg. samples / sec: 66258.17
Iteration:   3180, Loss function: 3.644, Average Loss: 4.137, avg. samples / sec: 66238.99
Iteration:   3180, Loss function: 3.297, Average Loss: 4.113, avg. samples / sec: 66296.73
Iteration:   3180, Loss function: 5.485, Average Loss: 4.114, avg. samples / sec: 66327.87
Iteration:   3180, Loss function: 5.604, Average Loss: 4.118, avg. samples / sec: 66233.85
Iteration:   3180, Loss function: 3.699, Average Loss: 4.113, avg. samples / sec: 66192.97
Iteration:   3180, Loss function: 2.989, Average Loss: 4.124, avg. samples / sec: 66239.61
Iteration:   3180, Loss function: 2.995, Average Loss: 4.142, avg. samples / sec: 66151.09
Iteration:   3180, Loss function: 3.929, Average Loss: 4.116, avg. samples / sec: 66094.60
Iteration:   3180, Loss function: 3.314, Average Loss: 4.146, avg. samples / sec: 66326.34
Iteration:   3180, Loss function: 3.893, Average Loss: 4.121, avg. samples / sec: 66262.38
Iteration:   3180, Loss function: 4.929, Average Loss: 4.107, avg. samples / sec: 66216.92
Iteration:   3180, Loss function: 3.657, Average Loss: 4.140, avg. samples / sec: 66157.67
Iteration:   3180, Loss function: 3.258, Average Loss: 4.112, avg. samples / sec: 66038.63
Iteration:   3180, Loss function: 3.880, Average Loss: 4.115, avg. samples / sec: 66193.84
Iteration:   3180, Loss function: 1.748, Average Loss: 4.101, avg. samples / sec: 66141.40
Iteration:   3180, Loss function: 3.190, Average Loss: 4.143, avg. samples / sec: 65999.26
Iteration:   3180, Loss function: 2.962, Average Loss: 4.102, avg. samples / sec: 66241.07
Iteration:   3180, Loss function: 3.267, Average Loss: 4.122, avg. samples / sec: 66229.71
Iteration:   3180, Loss function: 3.724, Average Loss: 4.155, avg. samples / sec: 66173.30
Iteration:   3180, Loss function: 3.286, Average Loss: 4.108, avg. samples / sec: 66182.47
Iteration:   3180, Loss function: 4.028, Average Loss: 4.113, avg. samples / sec: 66106.81
Iteration:   3180, Loss function: 4.033, Average Loss: 4.132, avg. samples / sec: 66113.45
Iteration:   3180, Loss function: 4.640, Average Loss: 4.099, avg. samples / sec: 66076.78
Iteration:   3180, Loss function: 4.411, Average Loss: 4.106, avg. samples / sec: 66102.62
Iteration:   3180, Loss function: 5.107, Average Loss: 4.110, avg. samples / sec: 66030.46
Iteration:   3180, Loss function: 2.969, Average Loss: 4.120, avg. samples / sec: 66032.72
Iteration:   3180, Loss function: 3.624, Average Loss: 4.124, avg. samples / sec: 66048.04
Iteration:   3180, Loss function: 3.656, Average Loss: 4.129, avg. samples / sec: 65998.21
Iteration:   3180, Loss function: 4.757, Average Loss: 4.106, avg. samples / sec: 66013.36
Iteration:   3200, Loss function: 3.999, Average Loss: 4.113, avg. samples / sec: 66139.26
Iteration:   3200, Loss function: 3.371, Average Loss: 4.128, avg. samples / sec: 66150.44
Iteration:   3200, Loss function: 3.436, Average Loss: 4.101, avg. samples / sec: 66186.66
Iteration:   3200, Loss function: 3.679, Average Loss: 4.131, avg. samples / sec: 66132.99
Iteration:   3200, Loss function: 3.741, Average Loss: 4.103, avg. samples / sec: 66163.92
Iteration:   3200, Loss function: 4.102, Average Loss: 4.118, avg. samples / sec: 66303.34
Iteration:   3200, Loss function: 2.819, Average Loss: 4.122, avg. samples / sec: 66010.36
Iteration:   3200, Loss function: 2.623, Average Loss: 4.108, avg. samples / sec: 66093.20
Iteration:   3200, Loss function: 4.641, Average Loss: 4.117, avg. samples / sec: 66181.16
Iteration:   3200, Loss function: 3.807, Average Loss: 4.138, avg. samples / sec: 65985.29
Iteration:   3200, Loss function: 2.681, Average Loss: 4.090, avg. samples / sec: 66165.59
Iteration:   3200, Loss function: 2.684, Average Loss: 4.096, avg. samples / sec: 66083.96
Iteration:   3200, Loss function: 3.891, Average Loss: 4.092, avg. samples / sec: 66112.55
Iteration:   3200, Loss function: 3.566, Average Loss: 4.096, avg. samples / sec: 66028.23
Iteration:   3200, Loss function: 4.009, Average Loss: 4.090, avg. samples / sec: 66267.55
Iteration:   3200, Loss function: 3.269, Average Loss: 4.106, avg. samples / sec: 66045.00
Iteration:   3200, Loss function: 2.943, Average Loss: 4.100, avg. samples / sec: 65974.63
Iteration:   3200, Loss function: 3.948, Average Loss: 4.131, avg. samples / sec: 66084.58
Iteration:   3200, Loss function: 2.834, Average Loss: 4.110, avg. samples / sec: 66043.89
Iteration:   3200, Loss function: 3.956, Average Loss: 4.101, avg. samples / sec: 65967.75
Iteration:   3200, Loss function: 4.002, Average Loss: 4.144, avg. samples / sec: 66072.16
Iteration:   3200, Loss function: 2.867, Average Loss: 4.095, avg. samples / sec: 66066.43
Iteration:   3200, Loss function: 3.166, Average Loss: 4.105, avg. samples / sec: 66109.91
Iteration:   3200, Loss function: 2.818, Average Loss: 4.097, avg. samples / sec: 66099.37
Iteration:   3200, Loss function: 3.783, Average Loss: 4.099, avg. samples / sec: 66092.49
Iteration:   3200, Loss function: 4.552, Average Loss: 4.134, avg. samples / sec: 65984.21
Iteration:   3200, Loss function: 2.494, Average Loss: 4.112, avg. samples / sec: 66068.01
Iteration:   3200, Loss function: 4.029, Average Loss: 4.111, avg. samples / sec: 65949.53
Iteration:   3200, Loss function: 2.709, Average Loss: 4.100, avg. samples / sec: 66005.38
Iteration:   3200, Loss function: 3.689, Average Loss: 4.089, avg. samples / sec: 65952.03
:::MLL 1558651446.703 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558651446.704 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 3.448, Average Loss: 4.120, avg. samples / sec: 64510.33
Iteration:   3220, Loss function: 2.856, Average Loss: 4.094, avg. samples / sec: 64447.70
Iteration:   3220, Loss function: 3.306, Average Loss: 4.077, avg. samples / sec: 64422.45
Iteration:   3220, Loss function: 2.790, Average Loss: 4.118, avg. samples / sec: 64301.17
Iteration:   3220, Loss function: 2.941, Average Loss: 4.109, avg. samples / sec: 64353.96
Iteration:   3220, Loss function: 3.195, Average Loss: 4.121, avg. samples / sec: 64319.69
Iteration:   3220, Loss function: 3.392, Average Loss: 4.100, avg. samples / sec: 64438.74
Iteration:   3220, Loss function: 3.439, Average Loss: 4.077, avg. samples / sec: 64364.72
Iteration:   3220, Loss function: 3.162, Average Loss: 4.082, avg. samples / sec: 64424.92
Iteration:   3220, Loss function: 3.229, Average Loss: 4.094, avg. samples / sec: 64428.37
Iteration:   3220, Loss function: 3.087, Average Loss: 4.132, avg. samples / sec: 64331.46
Iteration:   3220, Loss function: 3.222, Average Loss: 4.137, avg. samples / sec: 64384.13
Iteration:   3220, Loss function: 2.349, Average Loss: 4.107, avg. samples / sec: 64224.57
Iteration:   3220, Loss function: 4.302, Average Loss: 4.097, avg. samples / sec: 64447.43
Iteration:   3220, Loss function: 3.696, Average Loss: 4.081, avg. samples / sec: 64471.64
Iteration:   3220, Loss function: 2.586, Average Loss: 4.082, avg. samples / sec: 64337.42
Iteration:   3220, Loss function: 4.427, Average Loss: 4.087, avg. samples / sec: 64338.27
Iteration:   3220, Loss function: 3.312, Average Loss: 4.090, avg. samples / sec: 64404.28
Iteration:   3220, Loss function: 3.633, Average Loss: 4.089, avg. samples / sec: 64370.25
Iteration:   3220, Loss function: 3.084, Average Loss: 4.086, avg. samples / sec: 64203.47
Iteration:   3220, Loss function: 4.034, Average Loss: 4.095, avg. samples / sec: 64253.47
Iteration:   3220, Loss function: 3.580, Average Loss: 4.082, avg. samples / sec: 64337.42
Iteration:   3220, Loss function: 3.958, Average Loss: 4.093, avg. samples / sec: 64201.72
Iteration:   3220, Loss function: 3.958, Average Loss: 4.092, avg. samples / sec: 64283.01
Iteration:   3220, Loss function: 5.353, Average Loss: 4.122, avg. samples / sec: 64288.70
Iteration:   3220, Loss function: 2.944, Average Loss: 4.083, avg. samples / sec: 64204.06
Iteration:   3220, Loss function: 3.953, Average Loss: 4.106, avg. samples / sec: 64134.14
Iteration:   3220, Loss function: 3.487, Average Loss: 4.106, avg. samples / sec: 64146.93
Iteration:   3220, Loss function: 4.402, Average Loss: 4.083, avg. samples / sec: 64165.47
Iteration:   3220, Loss function: 2.632, Average Loss: 4.098, avg. samples / sec: 64138.08
Iteration:   3240, Loss function: 2.874, Average Loss: 4.124, avg. samples / sec: 66020.28
Iteration:   3240, Loss function: 3.564, Average Loss: 4.094, avg. samples / sec: 65938.36
Iteration:   3240, Loss function: 4.683, Average Loss: 4.070, avg. samples / sec: 65927.60
Iteration:   3240, Loss function: 2.262, Average Loss: 4.081, avg. samples / sec: 65965.15
Iteration:   3240, Loss function: 3.424, Average Loss: 4.075, avg. samples / sec: 65991.63
Iteration:   3240, Loss function: 2.305, Average Loss: 4.105, avg. samples / sec: 65737.21
Iteration:   3240, Loss function: 3.712, Average Loss: 4.098, avg. samples / sec: 65845.42
Iteration:   3240, Loss function: 3.787, Average Loss: 4.069, avg. samples / sec: 65865.02
Iteration:   3240, Loss function: 3.307, Average Loss: 4.118, avg. samples / sec: 65867.08
Iteration:   3240, Loss function: 2.664, Average Loss: 4.065, avg. samples / sec: 65860.68
Iteration:   3240, Loss function: 2.486, Average Loss: 4.085, avg. samples / sec: 66180.14
Iteration:   3240, Loss function: 4.186, Average Loss: 4.081, avg. samples / sec: 65877.12
Iteration:   3240, Loss function: 3.183, Average Loss: 4.075, avg. samples / sec: 65903.15
Iteration:   3240, Loss function: 2.964, Average Loss: 4.108, avg. samples / sec: 65982.76
Iteration:   3240, Loss function: 3.611, Average Loss: 4.065, avg. samples / sec: 65756.17
Iteration:   3240, Loss function: 2.761, Average Loss: 4.081, avg. samples / sec: 65780.41
Iteration:   3240, Loss function: 4.201, Average Loss: 4.106, avg. samples / sec: 65775.19
Iteration:   3240, Loss function: 3.762, Average Loss: 4.097, avg. samples / sec: 65994.22
Iteration:   3240, Loss function: 2.804, Average Loss: 4.108, avg. samples / sec: 65777.77
Iteration:   3240, Loss function: 1.932, Average Loss: 4.074, avg. samples / sec: 66003.83
Iteration:   3240, Loss function: 3.252, Average Loss: 4.095, avg. samples / sec: 65986.68
Iteration:   3240, Loss function: 2.655, Average Loss: 4.072, avg. samples / sec: 65851.63
Iteration:   3240, Loss function: 3.491, Average Loss: 4.078, avg. samples / sec: 65876.66
Iteration:   3240, Loss function: 3.748, Average Loss: 4.069, avg. samples / sec: 65798.23
Iteration:   3240, Loss function: 3.146, Average Loss: 4.080, avg. samples / sec: 65686.32
Iteration:   3240, Loss function: 2.747, Average Loss: 4.074, avg. samples / sec: 65827.82
Iteration:   3240, Loss function: 3.269, Average Loss: 4.077, avg. samples / sec: 65772.22
Iteration:   3240, Loss function: 4.668, Average Loss: 4.088, avg. samples / sec: 65744.85
Iteration:   3240, Loss function: 4.073, Average Loss: 4.073, avg. samples / sec: 65823.15
Iteration:   3240, Loss function: 3.694, Average Loss: 4.088, avg. samples / sec: 65659.08
Iteration:   3260, Loss function: 5.013, Average Loss: 4.086, avg. samples / sec: 66024.12
Iteration:   3260, Loss function: 4.270, Average Loss: 4.087, avg. samples / sec: 65929.29
Iteration:   3260, Loss function: 3.362, Average Loss: 4.110, avg. samples / sec: 65783.82
Iteration:   3260, Loss function: 3.425, Average Loss: 4.097, avg. samples / sec: 65907.56
Iteration:   3260, Loss function: 3.711, Average Loss: 4.078, avg. samples / sec: 66106.41
Iteration:   3260, Loss function: 3.135, Average Loss: 4.069, avg. samples / sec: 65935.90
Iteration:   3260, Loss function: 3.989, Average Loss: 4.059, avg. samples / sec: 65989.06
Iteration:   3260, Loss function: 3.282, Average Loss: 4.060, avg. samples / sec: 65975.96
Iteration:   3260, Loss function: 4.035, Average Loss: 4.076, avg. samples / sec: 66037.79
Iteration:   3260, Loss function: 3.234, Average Loss: 4.109, avg. samples / sec: 65877.33
Iteration:   3260, Loss function: 2.686, Average Loss: 4.068, avg. samples / sec: 65836.71
Iteration:   3260, Loss function: 3.554, Average Loss: 4.054, avg. samples / sec: 65861.48
Iteration:   3260, Loss function: 3.606, Average Loss: 4.099, avg. samples / sec: 65916.59
Iteration:   3260, Loss function: 3.003, Average Loss: 4.081, avg. samples / sec: 65804.06
Iteration:   3260, Loss function: 3.992, Average Loss: 4.055, avg. samples / sec: 65889.10
Iteration:   3260, Loss function: 3.149, Average Loss: 4.064, avg. samples / sec: 65948.27
Iteration:   3260, Loss function: 3.793, Average Loss: 4.100, avg. samples / sec: 65902.78
Iteration:   3260, Loss function: 3.289, Average Loss: 4.072, avg. samples / sec: 65889.41
Iteration:   3260, Loss function: 3.711, Average Loss: 4.056, avg. samples / sec: 65789.93
Iteration:   3260, Loss function: 2.960, Average Loss: 4.063, avg. samples / sec: 65976.24
Iteration:   3260, Loss function: 3.521, Average Loss: 4.055, avg. samples / sec: 65800.50
Iteration:   3260, Loss function: 3.184, Average Loss: 4.060, avg. samples / sec: 65841.29
Iteration:   3260, Loss function: 3.981, Average Loss: 4.066, avg. samples / sec: 66002.35
Iteration:   3260, Loss function: 3.669, Average Loss: 4.067, avg. samples / sec: 65888.30
Iteration:   3260, Loss function: 3.144, Average Loss: 4.066, avg. samples / sec: 65777.04
Iteration:   3260, Loss function: 3.309, Average Loss: 4.075, avg. samples / sec: 65826.56
Iteration:   3260, Loss function: 5.299, Average Loss: 4.064, avg. samples / sec: 65882.32
Iteration:   3260, Loss function: 4.256, Average Loss: 4.068, avg. samples / sec: 65853.88
Iteration:   3260, Loss function: 2.307, Average Loss: 4.098, avg. samples / sec: 65772.22
Iteration:   3260, Loss function: 4.425, Average Loss: 4.086, avg. samples / sec: 65777.31
Iteration:   3280, Loss function: 4.306, Average Loss: 4.088, avg. samples / sec: 65631.07
Iteration:   3280, Loss function: 3.854, Average Loss: 4.049, avg. samples / sec: 65739.20
Iteration:   3280, Loss function: 3.748, Average Loss: 4.059, avg. samples / sec: 65644.89
Iteration:   3280, Loss function: 3.273, Average Loss: 4.053, avg. samples / sec: 65779.22
Iteration:   3280, Loss function: 2.556, Average Loss: 4.067, avg. samples / sec: 65704.48
Iteration:   3280, Loss function: 3.473, Average Loss: 4.046, avg. samples / sec: 65638.96
Iteration:   3280, Loss function: 4.280, Average Loss: 4.066, avg. samples / sec: 65618.36
Iteration:   3280, Loss function: 4.597, Average Loss: 4.077, avg. samples / sec: 65578.54
Iteration:   3280, Loss function: 2.835, Average Loss: 4.049, avg. samples / sec: 65729.12
Iteration:   3280, Loss function: 3.203, Average Loss: 4.106, avg. samples / sec: 65630.03
Iteration:   3280, Loss function: 3.153, Average Loss: 4.072, avg. samples / sec: 65568.38
Iteration:   3280, Loss function: 3.642, Average Loss: 4.087, avg. samples / sec: 65671.10
Iteration:   3280, Loss function: 3.302, Average Loss: 4.072, avg. samples / sec: 65798.10
Iteration:   3280, Loss function: 3.420, Average Loss: 4.053, avg. samples / sec: 65635.69
Iteration:   3280, Loss function: 3.812, Average Loss: 4.058, avg. samples / sec: 65687.54
Iteration:   3280, Loss function: 2.771, Average Loss: 4.101, avg. samples / sec: 65568.50
Iteration:   3280, Loss function: 2.107, Average Loss: 4.086, avg. samples / sec: 65766.78
Iteration:   3280, Loss function: 3.714, Average Loss: 4.054, avg. samples / sec: 65638.29
Iteration:   3280, Loss function: 3.521, Average Loss: 4.052, avg. samples / sec: 65654.68
Iteration:   3280, Loss function: 3.971, Average Loss: 4.082, avg. samples / sec: 65603.85
Iteration:   3280, Loss function: 3.861, Average Loss: 4.043, avg. samples / sec: 65649.54
Iteration:   3280, Loss function: 3.794, Average Loss: 4.058, avg. samples / sec: 65662.14
Iteration:   3280, Loss function: 3.181, Average Loss: 4.041, avg. samples / sec: 65603.33
Iteration:   3280, Loss function: 2.473, Average Loss: 4.047, avg. samples / sec: 65542.83
Iteration:   3280, Loss function: 3.010, Average Loss: 4.054, avg. samples / sec: 65628.05
Iteration:   3280, Loss function: 4.115, Average Loss: 4.067, avg. samples / sec: 65615.43
Iteration:   3280, Loss function: 2.787, Average Loss: 4.055, avg. samples / sec: 65598.69
Iteration:   3280, Loss function: 4.665, Average Loss: 4.060, avg. samples / sec: 65524.30
Iteration:   3280, Loss function: 3.437, Average Loss: 4.065, avg. samples / sec: 65545.02
Iteration:   3280, Loss function: 3.681, Average Loss: 4.042, avg. samples / sec: 65456.89
:::MLL 1558651448.492 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558651448.493 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 4.352, Average Loss: 4.094, avg. samples / sec: 65720.13
Iteration:   3300, Loss function: 3.118, Average Loss: 4.069, avg. samples / sec: 65732.89
Iteration:   3300, Loss function: 2.412, Average Loss: 4.030, avg. samples / sec: 65711.31
Iteration:   3300, Loss function: 2.627, Average Loss: 4.043, avg. samples / sec: 65695.32
Iteration:   3300, Loss function: 3.512, Average Loss: 4.095, avg. samples / sec: 65634.89
Iteration:   3300, Loss function: 5.029, Average Loss: 4.058, avg. samples / sec: 65612.58
Iteration:   3300, Loss function: 3.668, Average Loss: 4.071, avg. samples / sec: 65620.86
Iteration:   3300, Loss function: 3.688, Average Loss: 4.043, avg. samples / sec: 65703.53
Iteration:   3300, Loss function: 4.037, Average Loss: 4.076, avg. samples / sec: 65603.76
Iteration:   3300, Loss function: 4.112, Average Loss: 4.039, avg. samples / sec: 65580.46
Iteration:   3300, Loss function: 3.270, Average Loss: 4.046, avg. samples / sec: 65558.90
Iteration:   3300, Loss function: 3.157, Average Loss: 4.076, avg. samples / sec: 65543.22
Iteration:   3300, Loss function: 2.307, Average Loss: 4.049, avg. samples / sec: 65692.17
Iteration:   3300, Loss function: 3.634, Average Loss: 4.063, avg. samples / sec: 65590.72
Iteration:   3300, Loss function: 4.542, Average Loss: 4.037, avg. samples / sec: 65634.89
Iteration:   3300, Loss function: 3.040, Average Loss: 4.031, avg. samples / sec: 65545.48
Iteration:   3300, Loss function: 3.232, Average Loss: 4.032, avg. samples / sec: 65550.42
Iteration:   3300, Loss function: 3.326, Average Loss: 4.034, avg. samples / sec: 65736.50
Iteration:   3300, Loss function: 3.042, Average Loss: 4.043, avg. samples / sec: 65615.12
Iteration:   3300, Loss function: 3.495, Average Loss: 4.062, avg. samples / sec: 65531.67
Iteration:   3300, Loss function: 2.044, Average Loss: 4.039, avg. samples / sec: 65468.53
Iteration:   3300, Loss function: 2.678, Average Loss: 4.058, avg. samples / sec: 65615.70
Iteration:   3300, Loss function: 2.484, Average Loss: 4.029, avg. samples / sec: 65543.74
Iteration:   3300, Loss function: 3.789, Average Loss: 4.076, avg. samples / sec: 65502.28
Iteration:   3300, Loss function: 2.550, Average Loss: 4.054, avg. samples / sec: 65432.70
Iteration:   3300, Loss function: 2.922, Average Loss: 4.040, avg. samples / sec: 65472.67
Iteration:   3300, Loss function: 4.263, Average Loss: 4.040, avg. samples / sec: 65484.38
Iteration:   3300, Loss function: 3.641, Average Loss: 4.037, avg. samples / sec: 65513.82
Iteration:   3300, Loss function: 2.480, Average Loss: 4.045, avg. samples / sec: 65442.72
Iteration:   3300, Loss function: 4.431, Average Loss: 4.054, avg. samples / sec: 65467.96
Iteration:   3320, Loss function: 3.831, Average Loss: 4.069, avg. samples / sec: 66191.48
Iteration:   3320, Loss function: 3.691, Average Loss: 4.044, avg. samples / sec: 66260.13
Iteration:   3320, Loss function: 3.294, Average Loss: 4.084, avg. samples / sec: 66073.71
Iteration:   3320, Loss function: 4.168, Average Loss: 4.053, avg. samples / sec: 66074.76
Iteration:   3320, Loss function: 3.172, Average Loss: 4.038, avg. samples / sec: 66064.66
Iteration:   3320, Loss function: 4.480, Average Loss: 4.035, avg. samples / sec: 66228.53
Iteration:   3320, Loss function: 4.642, Average Loss: 4.035, avg. samples / sec: 66038.26
Iteration:   3320, Loss function: 3.697, Average Loss: 4.018, avg. samples / sec: 65972.75
Iteration:   3320, Loss function: 3.392, Average Loss: 4.020, avg. samples / sec: 66080.25
Iteration:   3320, Loss function: 3.420, Average Loss: 4.019, avg. samples / sec: 66077.77
Iteration:   3320, Loss function: 3.062, Average Loss: 4.024, avg. samples / sec: 66022.29
Iteration:   3320, Loss function: 3.365, Average Loss: 4.082, avg. samples / sec: 65911.29
Iteration:   3320, Loss function: 3.266, Average Loss: 4.043, avg. samples / sec: 66134.17
Iteration:   3320, Loss function: 3.586, Average Loss: 4.067, avg. samples / sec: 66016.85
Iteration:   3320, Loss function: 3.408, Average Loss: 4.027, avg. samples / sec: 66127.97
Iteration:   3320, Loss function: 4.444, Average Loss: 4.030, avg. samples / sec: 66068.97
Iteration:   3320, Loss function: 2.181, Average Loss: 4.058, avg. samples / sec: 65906.88
Iteration:   3320, Loss function: 2.743, Average Loss: 4.017, avg. samples / sec: 66005.50
Iteration:   3320, Loss function: 3.036, Average Loss: 4.025, avg. samples / sec: 66116.42
Iteration:   3320, Loss function: 2.180, Average Loss: 4.033, avg. samples / sec: 65986.43
Iteration:   3320, Loss function: 3.253, Average Loss: 4.028, avg. samples / sec: 65922.69
Iteration:   3320, Loss function: 2.872, Average Loss: 4.055, avg. samples / sec: 65947.93
Iteration:   3320, Loss function: 3.290, Average Loss: 4.027, avg. samples / sec: 65993.05
Iteration:   3320, Loss function: 3.841, Average Loss: 4.063, avg. samples / sec: 66069.96
Iteration:   3320, Loss function: 2.618, Average Loss: 4.050, avg. samples / sec: 65927.85
Iteration:   3320, Loss function: 2.443, Average Loss: 4.030, avg. samples / sec: 66054.66
Iteration:   3320, Loss function: 4.362, Average Loss: 4.028, avg. samples / sec: 66054.01
Iteration:   3320, Loss function: 4.482, Average Loss: 4.049, avg. samples / sec: 66165.75
Iteration:   3320, Loss function: 2.903, Average Loss: 4.053, avg. samples / sec: 65969.23
Iteration:   3320, Loss function: 4.111, Average Loss: 4.031, avg. samples / sec: 65929.23
Iteration:   3340, Loss function: 3.695, Average Loss: 4.042, avg. samples / sec: 65997.99
Iteration:   3340, Loss function: 4.165, Average Loss: 4.020, avg. samples / sec: 65902.13
Iteration:   3340, Loss function: 2.133, Average Loss: 4.045, avg. samples / sec: 65893.75
Iteration:   3340, Loss function: 3.782, Average Loss: 4.025, avg. samples / sec: 65826.41
Iteration:   3340, Loss function: 2.640, Average Loss: 4.061, avg. samples / sec: 65657.34
Iteration:   3340, Loss function: 4.239, Average Loss: 4.075, avg. samples / sec: 65739.60
Iteration:   3340, Loss function: 3.718, Average Loss: 4.032, avg. samples / sec: 65771.33
Iteration:   3340, Loss function: 3.278, Average Loss: 4.045, avg. samples / sec: 65772.62
Iteration:   3340, Loss function: 3.253, Average Loss: 4.019, avg. samples / sec: 65902.53
Iteration:   3340, Loss function: 3.722, Average Loss: 4.055, avg. samples / sec: 65816.05
Iteration:   3340, Loss function: 3.075, Average Loss: 4.025, avg. samples / sec: 65880.41
Iteration:   3340, Loss function: 3.398, Average Loss: 4.037, avg. samples / sec: 65921.40
Iteration:   3340, Loss function: 3.534, Average Loss: 4.016, avg. samples / sec: 65826.16
Iteration:   3340, Loss function: 2.798, Average Loss: 4.006, avg. samples / sec: 65779.61
Iteration:   3340, Loss function: 3.922, Average Loss: 4.012, avg. samples / sec: 65775.72
Iteration:   3340, Loss function: 3.567, Average Loss: 4.023, avg. samples / sec: 65815.83
Iteration:   3340, Loss function: 2.727, Average Loss: 4.071, avg. samples / sec: 65774.30
Iteration:   3340, Loss function: 3.184, Average Loss: 4.045, avg. samples / sec: 65820.51
Iteration:   3340, Loss function: 3.456, Average Loss: 4.053, avg. samples / sec: 65828.81
Iteration:   3340, Loss function: 3.412, Average Loss: 4.038, avg. samples / sec: 65816.66
Iteration:   3340, Loss function: 3.953, Average Loss: 4.013, avg. samples / sec: 65793.62
Iteration:   3340, Loss function: 3.716, Average Loss: 4.004, avg. samples / sec: 65726.48
Iteration:   3340, Loss function: 3.133, Average Loss: 4.010, avg. samples / sec: 65759.30
Iteration:   3340, Loss function: 3.436, Average Loss: 4.032, avg. samples / sec: 65518.08
Iteration:   3340, Loss function: 2.764, Average Loss: 4.036, avg. samples / sec: 65680.53
Iteration:   3340, Loss function: 2.419, Average Loss: 4.021, avg. samples / sec: 65633.76
Iteration:   3340, Loss function: 3.361, Average Loss: 4.010, avg. samples / sec: 65655.78
Iteration:   3340, Loss function: 4.114, Average Loss: 4.022, avg. samples / sec: 65791.28
Iteration:   3340, Loss function: 3.027, Average Loss: 4.015, avg. samples / sec: 65704.23
Iteration:   3340, Loss function: 3.544, Average Loss: 4.009, avg. samples / sec: 65668.44
:::MLL 1558651450.281 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558651450.281 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 3.299, Average Loss: 4.033, avg. samples / sec: 65510.35
Iteration:   3360, Loss function: 3.329, Average Loss: 4.039, avg. samples / sec: 65515.04
Iteration:   3360, Loss function: 2.246, Average Loss: 4.000, avg. samples / sec: 65641.71
Iteration:   3360, Loss function: 4.701, Average Loss: 4.033, avg. samples / sec: 65433.76
Iteration:   3360, Loss function: 3.841, Average Loss: 4.061, avg. samples / sec: 65513.67
Iteration:   3360, Loss function: 3.484, Average Loss: 4.004, avg. samples / sec: 65639.02
Iteration:   3360, Loss function: 3.337, Average Loss: 4.007, avg. samples / sec: 65390.71
Iteration:   3360, Loss function: 3.421, Average Loss: 3.987, avg. samples / sec: 65522.47
Iteration:   3360, Loss function: 5.345, Average Loss: 4.051, avg. samples / sec: 65422.49
Iteration:   3360, Loss function: 2.945, Average Loss: 4.061, avg. samples / sec: 65422.25
Iteration:   3360, Loss function: 3.025, Average Loss: 4.031, avg. samples / sec: 65475.17
Iteration:   3360, Loss function: 4.900, Average Loss: 4.000, avg. samples / sec: 65514.67
Iteration:   3360, Loss function: 3.295, Average Loss: 4.026, avg. samples / sec: 65581.38
Iteration:   3360, Loss function: 3.511, Average Loss: 4.005, avg. samples / sec: 65448.10
Iteration:   3360, Loss function: 3.389, Average Loss: 4.031, avg. samples / sec: 65364.78
Iteration:   3360, Loss function: 2.825, Average Loss: 4.013, avg. samples / sec: 65589.83
Iteration:   3360, Loss function: 3.660, Average Loss: 3.994, avg. samples / sec: 65440.90
Iteration:   3360, Loss function: 3.058, Average Loss: 4.016, avg. samples / sec: 65435.10
Iteration:   3360, Loss function: 3.349, Average Loss: 4.001, avg. samples / sec: 65448.25
Iteration:   3360, Loss function: 3.138, Average Loss: 4.005, avg. samples / sec: 65554.69
Iteration:   3360, Loss function: 3.382, Average Loss: 3.995, avg. samples / sec: 65588.37
Iteration:   3360, Loss function: 3.182, Average Loss: 4.010, avg. samples / sec: 65437.68
Iteration:   3360, Loss function: 5.605, Average Loss: 4.028, avg. samples / sec: 65534.11
Iteration:   3360, Loss function: 4.200, Average Loss: 4.010, avg. samples / sec: 65360.62
Iteration:   3360, Loss function: 4.113, Average Loss: 4.006, avg. samples / sec: 65379.21
Iteration:   3360, Loss function: 3.603, Average Loss: 4.041, avg. samples / sec: 65407.52
Iteration:   3360, Loss function: 3.258, Average Loss: 3.999, avg. samples / sec: 65452.91
Iteration:   3360, Loss function: 1.912, Average Loss: 4.025, avg. samples / sec: 65381.55
Iteration:   3360, Loss function: 4.058, Average Loss: 4.021, avg. samples / sec: 65294.97
Iteration:   3360, Loss function: 2.671, Average Loss: 4.027, avg. samples / sec: 65329.17
Iteration:   3380, Loss function: 3.924, Average Loss: 4.023, avg. samples / sec: 66095.00
Iteration:   3380, Loss function: 3.439, Average Loss: 3.998, avg. samples / sec: 66036.18
Iteration:   3380, Loss function: 3.873, Average Loss: 4.004, avg. samples / sec: 66056.71
Iteration:   3380, Loss function: 2.284, Average Loss: 4.024, avg. samples / sec: 65950.61
Iteration:   3380, Loss function: 3.356, Average Loss: 4.012, avg. samples / sec: 66127.97
Iteration:   3380, Loss function: 2.277, Average Loss: 3.976, avg. samples / sec: 66016.14
Iteration:   3380, Loss function: 5.053, Average Loss: 4.020, avg. samples / sec: 65949.23
Iteration:   3380, Loss function: 2.870, Average Loss: 3.991, avg. samples / sec: 65934.04
Iteration:   3380, Loss function: 3.360, Average Loss: 3.997, avg. samples / sec: 66028.76
Iteration:   3380, Loss function: 3.035, Average Loss: 3.981, avg. samples / sec: 66005.47
Iteration:   3380, Loss function: 2.851, Average Loss: 3.991, avg. samples / sec: 66039.43
Iteration:   3380, Loss function: 3.259, Average Loss: 4.048, avg. samples / sec: 65966.05
Iteration:   3380, Loss function: 2.801, Average Loss: 4.026, avg. samples / sec: 66042.68
Iteration:   3380, Loss function: 3.246, Average Loss: 4.002, avg. samples / sec: 66013.79
Iteration:   3380, Loss function: 2.819, Average Loss: 3.992, avg. samples / sec: 65983.16
Iteration:   3380, Loss function: 4.101, Average Loss: 3.989, avg. samples / sec: 65947.44
Iteration:   3380, Loss function: 3.251, Average Loss: 4.043, avg. samples / sec: 65894.03
Iteration:   3380, Loss function: 3.848, Average Loss: 4.022, avg. samples / sec: 65864.46
Iteration:   3380, Loss function: 3.149, Average Loss: 4.039, avg. samples / sec: 65920.84
Iteration:   3380, Loss function: 1.446, Average Loss: 3.984, avg. samples / sec: 65946.20
Iteration:   3380, Loss function: 2.980, Average Loss: 4.017, avg. samples / sec: 66063.92
Iteration:   3380, Loss function: 3.997, Average Loss: 4.016, avg. samples / sec: 65902.69
Iteration:   3380, Loss function: 2.915, Average Loss: 3.991, avg. samples / sec: 65991.53
Iteration:   3380, Loss function: 3.412, Average Loss: 4.029, avg. samples / sec: 65909.96
Iteration:   3380, Loss function: 3.955, Average Loss: 3.991, avg. samples / sec: 65857.32
Iteration:   3380, Loss function: 3.878, Average Loss: 3.990, avg. samples / sec: 65885.34
Iteration:   3380, Loss function: 3.038, Average Loss: 3.998, avg. samples / sec: 65863.60
Iteration:   3380, Loss function: 3.238, Average Loss: 4.017, avg. samples / sec: 65853.63
Iteration:   3380, Loss function: 2.832, Average Loss: 4.000, avg. samples / sec: 65835.02
Iteration:   3380, Loss function: 2.511, Average Loss: 4.010, avg. samples / sec: 65952.10
Iteration:   3400, Loss function: 3.979, Average Loss: 4.009, avg. samples / sec: 66041.76
Iteration:   3400, Loss function: 2.245, Average Loss: 3.984, avg. samples / sec: 66011.75
Iteration:   3400, Loss function: 3.973, Average Loss: 4.029, avg. samples / sec: 66083.22
Iteration:   3400, Loss function: 2.607, Average Loss: 3.997, avg. samples / sec: 66179.64
Iteration:   3400, Loss function: 2.955, Average Loss: 3.984, avg. samples / sec: 66034.85
Iteration:   3400, Loss function: 4.431, Average Loss: 4.015, avg. samples / sec: 65863.23
Iteration:   3400, Loss function: 4.277, Average Loss: 4.029, avg. samples / sec: 66014.32
Iteration:   3400, Loss function: 3.335, Average Loss: 4.003, avg. samples / sec: 65931.82
Iteration:   3400, Loss function: 4.011, Average Loss: 4.018, avg. samples / sec: 65918.72
Iteration:   3400, Loss function: 4.242, Average Loss: 3.974, avg. samples / sec: 66016.73
Iteration:   3400, Loss function: 3.901, Average Loss: 4.009, avg. samples / sec: 66108.39
Iteration:   3400, Loss function: 4.244, Average Loss: 3.979, avg. samples / sec: 65922.51
Iteration:   3400, Loss function: 4.398, Average Loss: 3.969, avg. samples / sec: 65925.66
Iteration:   3400, Loss function: 2.934, Average Loss: 3.992, avg. samples / sec: 65862.89
Iteration:   3400, Loss function: 3.263, Average Loss: 4.006, avg. samples / sec: 65990.79
Iteration:   3400, Loss function: 5.154, Average Loss: 3.982, avg. samples / sec: 66037.11
Iteration:   3400, Loss function: 3.951, Average Loss: 3.978, avg. samples / sec: 65977.14
Iteration:   3400, Loss function: 2.349, Average Loss: 3.982, avg. samples / sec: 65941.51
Iteration:   3400, Loss function: 3.742, Average Loss: 3.993, avg. samples / sec: 65823.21
Iteration:   3400, Loss function: 4.410, Average Loss: 4.016, avg. samples / sec: 65975.19
Iteration:   3400, Loss function: 3.587, Average Loss: 4.008, avg. samples / sec: 65949.44
Iteration:   3400, Loss function: 3.436, Average Loss: 3.990, avg. samples / sec: 65999.91
Iteration:   3400, Loss function: 3.271, Average Loss: 4.016, avg. samples / sec: 65884.69
Iteration:   3400, Loss function: 3.735, Average Loss: 3.986, avg. samples / sec: 66022.67
Iteration:   3400, Loss function: 3.596, Average Loss: 3.981, avg. samples / sec: 65866.03
Iteration:   3400, Loss function: 3.365, Average Loss: 4.009, avg. samples / sec: 65889.25
Iteration:   3400, Loss function: 3.999, Average Loss: 3.980, avg. samples / sec: 65939.91
Iteration:   3400, Loss function: 4.246, Average Loss: 4.040, avg. samples / sec: 65851.17
Iteration:   3400, Loss function: 3.266, Average Loss: 3.991, avg. samples / sec: 65847.57
Iteration:   3400, Loss function: 2.539, Average Loss: 3.966, avg. samples / sec: 65761.78
Iteration:   3420, Loss function: 2.960, Average Loss: 3.996, avg. samples / sec: 66131.97
Iteration:   3420, Loss function: 3.872, Average Loss: 3.973, avg. samples / sec: 66010.54
Iteration:   3420, Loss function: 3.310, Average Loss: 3.992, avg. samples / sec: 66062.56
Iteration:   3420, Loss function: 2.691, Average Loss: 3.980, avg. samples / sec: 66127.53
Iteration:   3420, Loss function: 4.361, Average Loss: 4.017, avg. samples / sec: 65958.55
Iteration:   3420, Loss function: 3.582, Average Loss: 3.966, avg. samples / sec: 66055.34
Iteration:   3420, Loss function: 2.113, Average Loss: 3.957, avg. samples / sec: 66162.08
Iteration:   3420, Loss function: 3.180, Average Loss: 4.008, avg. samples / sec: 66020.22
Iteration:   3420, Loss function: 3.203, Average Loss: 4.000, avg. samples / sec: 66113.26
Iteration:   3420, Loss function: 2.755, Average Loss: 3.993, avg. samples / sec: 66009.09
Iteration:   3420, Loss function: 3.769, Average Loss: 3.995, avg. samples / sec: 65866.71
Iteration:   3420, Loss function: 2.636, Average Loss: 4.002, avg. samples / sec: 66023.62
Iteration:   3420, Loss function: 3.802, Average Loss: 4.006, avg. samples / sec: 66036.22
Iteration:   3420, Loss function: 4.307, Average Loss: 3.975, avg. samples / sec: 66034.64
Iteration:   3420, Loss function: 3.346, Average Loss: 3.971, avg. samples / sec: 65956.23
Iteration:   3420, Loss function: 2.628, Average Loss: 3.970, avg. samples / sec: 65866.34
Iteration:   3420, Loss function: 3.653, Average Loss: 3.970, avg. samples / sec: 65997.25
Iteration:   3420, Loss function: 2.724, Average Loss: 4.016, avg. samples / sec: 65907.56
Iteration:   3420, Loss function: 2.618, Average Loss: 3.981, avg. samples / sec: 65967.99
Iteration:   3420, Loss function: 3.113, Average Loss: 3.966, avg. samples / sec: 65866.56
Iteration:   3420, Loss function: 3.433, Average Loss: 3.982, avg. samples / sec: 65970.34
Iteration:   3420, Loss function: 3.237, Average Loss: 4.004, avg. samples / sec: 65823.86
Iteration:   3420, Loss function: 1.854, Average Loss: 3.972, avg. samples / sec: 65888.36
Iteration:   3420, Loss function: 3.199, Average Loss: 4.026, avg. samples / sec: 65941.94
Iteration:   3420, Loss function: 3.406, Average Loss: 3.979, avg. samples / sec: 65845.45
Iteration:   3420, Loss function: 3.192, Average Loss: 3.986, avg. samples / sec: 65745.18
Iteration:   3420, Loss function: 3.843, Average Loss: 3.974, avg. samples / sec: 65880.48
Iteration:   3420, Loss function: 2.605, Average Loss: 3.995, avg. samples / sec: 65844.52
Iteration:   3420, Loss function: 3.853, Average Loss: 3.965, avg. samples / sec: 65761.90
Iteration:   3420, Loss function: 4.072, Average Loss: 3.969, avg. samples / sec: 65761.17
:::MLL 1558651452.048 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=2.49s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22265
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38324
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22682
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05915
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23558
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21822
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31745
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33391
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09852
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36269
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.51958
Current AP: 0.22265 AP goal: 0.23000
:::MLL 1558651455.663 eval_accuracy: {"value": 0.22265342116578551, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558651455.733 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558651455.740 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558651455.740 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558651455.766 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558651455.767 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 2.333, Average Loss: 4.000, avg. samples / sec: 7977.53
Iteration:   3440, Loss function: 3.051, Average Loss: 3.964, avg. samples / sec: 7978.01
Iteration:   3440, Loss function: 3.051, Average Loss: 3.961, avg. samples / sec: 7978.34
Iteration:   3440, Loss function: 3.963, Average Loss: 3.956, avg. samples / sec: 7979.21
Iteration:   3440, Loss function: 4.409, Average Loss: 3.958, avg. samples / sec: 7977.84
Iteration:   3440, Loss function: 3.267, Average Loss: 4.012, avg. samples / sec: 7978.95
Iteration:   3440, Loss function: 4.271, Average Loss: 4.005, avg. samples / sec: 7977.70
Iteration:   3440, Loss function: 4.005, Average Loss: 3.960, avg. samples / sec: 7980.76
Iteration:   3440, Loss function: 3.569, Average Loss: 3.959, avg. samples / sec: 7975.49
Iteration:   3440, Loss function: 2.126, Average Loss: 3.967, avg. samples / sec: 7975.36
Iteration:   3440, Loss function: 2.996, Average Loss: 3.946, avg. samples / sec: 7975.92
Iteration:   3440, Loss function: 4.476, Average Loss: 3.966, avg. samples / sec: 7978.61
Iteration:   3440, Loss function: 3.550, Average Loss: 3.988, avg. samples / sec: 7974.67
Iteration:   3440, Loss function: 3.862, Average Loss: 3.983, avg. samples / sec: 7979.30
Iteration:   3440, Loss function: 3.380, Average Loss: 3.976, avg. samples / sec: 7978.81
Iteration:   3440, Loss function: 3.534, Average Loss: 3.956, avg. samples / sec: 7975.68
Iteration:   3440, Loss function: 3.616, Average Loss: 3.953, avg. samples / sec: 7979.50
Iteration:   3440, Loss function: 3.362, Average Loss: 3.986, avg. samples / sec: 7976.18
Iteration:   3440, Loss function: 3.551, Average Loss: 4.003, avg. samples / sec: 7975.50
Iteration:   3440, Loss function: 3.095, Average Loss: 3.979, avg. samples / sec: 7974.40
Iteration:   3440, Loss function: 3.600, Average Loss: 3.969, avg. samples / sec: 7977.78
Iteration:   3440, Loss function: 3.559, Average Loss: 3.962, avg. samples / sec: 7976.29
Iteration:   3440, Loss function: 2.851, Average Loss: 3.986, avg. samples / sec: 7975.10
Iteration:   3440, Loss function: 4.071, Average Loss: 3.996, avg. samples / sec: 7977.77
Iteration:   3440, Loss function: 3.991, Average Loss: 3.986, avg. samples / sec: 7975.07
Iteration:   3440, Loss function: 2.278, Average Loss: 3.994, avg. samples / sec: 7975.82
Iteration:   3440, Loss function: 3.405, Average Loss: 3.990, avg. samples / sec: 7975.51
Iteration:   3440, Loss function: 2.994, Average Loss: 3.961, avg. samples / sec: 7976.03
Iteration:   3440, Loss function: 3.252, Average Loss: 3.971, avg. samples / sec: 7977.38
Iteration:   3440, Loss function: 3.514, Average Loss: 3.960, avg. samples / sec: 7976.85
Iteration:   3460, Loss function: 3.799, Average Loss: 3.990, avg. samples / sec: 66394.74
Iteration:   3460, Loss function: 3.191, Average Loss: 3.948, avg. samples / sec: 66475.92
Iteration:   3460, Loss function: 3.150, Average Loss: 3.973, avg. samples / sec: 66319.29
Iteration:   3460, Loss function: 2.711, Average Loss: 3.973, avg. samples / sec: 66359.54
Iteration:   3460, Loss function: 2.978, Average Loss: 3.980, avg. samples / sec: 66337.80
Iteration:   3460, Loss function: 4.076, Average Loss: 3.967, avg. samples / sec: 66334.02
Iteration:   3460, Loss function: 3.955, Average Loss: 3.948, avg. samples / sec: 66172.37
Iteration:   3460, Loss function: 3.285, Average Loss: 3.988, avg. samples / sec: 66090.75
Iteration:   3460, Loss function: 4.501, Average Loss: 3.982, avg. samples / sec: 66212.07
Iteration:   3460, Loss function: 3.111, Average Loss: 3.983, avg. samples / sec: 66267.11
Iteration:   3460, Loss function: 4.077, Average Loss: 3.957, avg. samples / sec: 66280.27
Iteration:   3460, Loss function: 3.755, Average Loss: 3.932, avg. samples / sec: 66195.96
Iteration:   3460, Loss function: 3.508, Average Loss: 3.972, avg. samples / sec: 66238.74
Iteration:   3460, Loss function: 2.857, Average Loss: 3.954, avg. samples / sec: 66233.63
Iteration:   3460, Loss function: 6.190, Average Loss: 3.948, avg. samples / sec: 66130.23
Iteration:   3460, Loss function: 3.691, Average Loss: 3.988, avg. samples / sec: 66240.08
Iteration:   3460, Loss function: 2.375, Average Loss: 4.005, avg. samples / sec: 66154.60
Iteration:   3460, Loss function: 3.684, Average Loss: 3.948, avg. samples / sec: 66163.64
Iteration:   3460, Loss function: 4.038, Average Loss: 3.954, avg. samples / sec: 66105.23
Iteration:   3460, Loss function: 3.175, Average Loss: 3.965, avg. samples / sec: 66190.74
Iteration:   3460, Loss function: 3.770, Average Loss: 3.955, avg. samples / sec: 66117.70
Iteration:   3460, Loss function: 4.688, Average Loss: 3.952, avg. samples / sec: 66114.16
Iteration:   3460, Loss function: 3.560, Average Loss: 3.955, avg. samples / sec: 66137.24
Iteration:   3460, Loss function: 3.712, Average Loss: 3.951, avg. samples / sec: 66237.81
Iteration:   3460, Loss function: 4.021, Average Loss: 3.996, avg. samples / sec: 66084.71
Iteration:   3460, Loss function: 3.577, Average Loss: 3.950, avg. samples / sec: 66094.16
Iteration:   3460, Loss function: 3.895, Average Loss: 3.979, avg. samples / sec: 66184.15
Iteration:   3460, Loss function: 3.073, Average Loss: 3.944, avg. samples / sec: 66109.35
Iteration:   3460, Loss function: 2.308, Average Loss: 3.968, avg. samples / sec: 66106.04
Iteration:   3460, Loss function: 3.327, Average Loss: 3.952, avg. samples / sec: 66057.48
Iteration:   3480, Loss function: 4.370, Average Loss: 3.937, avg. samples / sec: 66403.41
Iteration:   3480, Loss function: 3.327, Average Loss: 3.957, avg. samples / sec: 66344.17
Iteration:   3480, Loss function: 3.920, Average Loss: 3.979, avg. samples / sec: 66282.20
Iteration:   3480, Loss function: 3.801, Average Loss: 3.940, avg. samples / sec: 66266.71
Iteration:   3480, Loss function: 2.983, Average Loss: 3.940, avg. samples / sec: 66332.58
Iteration:   3480, Loss function: 3.389, Average Loss: 3.981, avg. samples / sec: 66284.01
Iteration:   3480, Loss function: 2.634, Average Loss: 3.955, avg. samples / sec: 66360.32
Iteration:   3480, Loss function: 3.735, Average Loss: 3.975, avg. samples / sec: 66061.69
Iteration:   3480, Loss function: 3.674, Average Loss: 3.969, avg. samples / sec: 66226.48
Iteration:   3480, Loss function: 2.226, Average Loss: 3.922, avg. samples / sec: 66211.04
Iteration:   3480, Loss function: 2.869, Average Loss: 3.974, avg. samples / sec: 66137.93
Iteration:   3480, Loss function: 5.083, Average Loss: 3.946, avg. samples / sec: 66178.49
Iteration:   3480, Loss function: 2.578, Average Loss: 3.994, avg. samples / sec: 66201.59
Iteration:   3480, Loss function: 3.839, Average Loss: 3.981, avg. samples / sec: 66252.29
Iteration:   3480, Loss function: 3.113, Average Loss: 3.938, avg. samples / sec: 66160.03
Iteration:   3480, Loss function: 4.129, Average Loss: 3.962, avg. samples / sec: 66056.86
Iteration:   3480, Loss function: 3.433, Average Loss: 3.942, avg. samples / sec: 66195.52
Iteration:   3480, Loss function: 2.886, Average Loss: 3.965, avg. samples / sec: 66235.16
Iteration:   3480, Loss function: 3.407, Average Loss: 3.959, avg. samples / sec: 66122.13
Iteration:   3480, Loss function: 3.587, Average Loss: 3.960, avg. samples / sec: 66137.06
Iteration:   3480, Loss function: 2.395, Average Loss: 3.944, avg. samples / sec: 66239.89
Iteration:   3480, Loss function: 5.071, Average Loss: 3.935, avg. samples / sec: 66150.62
Iteration:   3480, Loss function: 2.955, Average Loss: 3.977, avg. samples / sec: 66098.69
Iteration:   3480, Loss function: 4.622, Average Loss: 3.941, avg. samples / sec: 66090.75
Iteration:   3480, Loss function: 3.577, Average Loss: 3.936, avg. samples / sec: 66059.46
Iteration:   3480, Loss function: 4.059, Average Loss: 3.940, avg. samples / sec: 65973.49
Iteration:   3480, Loss function: 3.241, Average Loss: 3.944, avg. samples / sec: 66126.94
Iteration:   3480, Loss function: 2.808, Average Loss: 3.942, avg. samples / sec: 66124.46
Iteration:   3480, Loss function: 3.774, Average Loss: 3.930, avg. samples / sec: 66147.21
Iteration:   3480, Loss function: 4.448, Average Loss: 3.962, avg. samples / sec: 65875.06
:::MLL 1558651457.548 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558651457.548 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 4.170, Average Loss: 3.970, avg. samples / sec: 65873.79
Iteration:   3500, Loss function: 3.340, Average Loss: 3.923, avg. samples / sec: 65815.83
Iteration:   3500, Loss function: 2.671, Average Loss: 3.927, avg. samples / sec: 65983.90
Iteration:   3500, Loss function: 2.980, Average Loss: 3.930, avg. samples / sec: 65853.94
Iteration:   3500, Loss function: 2.563, Average Loss: 3.949, avg. samples / sec: 65942.13
Iteration:   3500, Loss function: 3.097, Average Loss: 3.962, avg. samples / sec: 65828.04
Iteration:   3500, Loss function: 2.605, Average Loss: 3.953, avg. samples / sec: 65882.26
Iteration:   3500, Loss function: 3.281, Average Loss: 3.950, avg. samples / sec: 65871.51
Iteration:   3500, Loss function: 2.830, Average Loss: 3.920, avg. samples / sec: 65974.88
Iteration:   3500, Loss function: 3.732, Average Loss: 3.944, avg. samples / sec: 65719.80
Iteration:   3500, Loss function: 4.290, Average Loss: 3.934, avg. samples / sec: 65873.55
Iteration:   3500, Loss function: 3.625, Average Loss: 3.924, avg. samples / sec: 65839.54
Iteration:   3500, Loss function: 4.221, Average Loss: 3.945, avg. samples / sec: 65764.79
Iteration:   3500, Loss function: 3.566, Average Loss: 3.983, avg. samples / sec: 65826.96
Iteration:   3500, Loss function: 4.003, Average Loss: 3.931, avg. samples / sec: 65922.79
Iteration:   3500, Loss function: 2.818, Average Loss: 3.967, avg. samples / sec: 65889.25
Iteration:   3500, Loss function: 2.829, Average Loss: 3.935, avg. samples / sec: 65769.02
Iteration:   3500, Loss function: 4.497, Average Loss: 3.934, avg. samples / sec: 65894.58
Iteration:   3500, Loss function: 3.501, Average Loss: 3.912, avg. samples / sec: 65735.95
Iteration:   3500, Loss function: 2.806, Average Loss: 3.973, avg. samples / sec: 65688.98
Iteration:   3500, Loss function: 4.307, Average Loss: 3.927, avg. samples / sec: 65687.39
Iteration:   3500, Loss function: 4.371, Average Loss: 3.960, avg. samples / sec: 65786.22
Iteration:   3500, Loss function: 2.945, Average Loss: 3.934, avg. samples / sec: 65784.80
Iteration:   3500, Loss function: 3.567, Average Loss: 3.930, avg. samples / sec: 65842.74
Iteration:   3500, Loss function: 2.478, Average Loss: 3.947, avg. samples / sec: 65931.98
Iteration:   3500, Loss function: 3.839, Average Loss: 3.957, avg. samples / sec: 65675.39
Iteration:   3500, Loss function: 4.681, Average Loss: 3.974, avg. samples / sec: 65718.97
Iteration:   3500, Loss function: 2.375, Average Loss: 3.968, avg. samples / sec: 65697.49
Iteration:   3500, Loss function: 3.226, Average Loss: 3.928, avg. samples / sec: 65768.53
Iteration:   3500, Loss function: 4.330, Average Loss: 3.929, avg. samples / sec: 65725.16
Iteration:   3520, Loss function: 2.925, Average Loss: 3.953, avg. samples / sec: 66254.96
Iteration:   3520, Loss function: 3.823, Average Loss: 3.947, avg. samples / sec: 66236.09
Iteration:   3520, Loss function: 2.726, Average Loss: 3.921, avg. samples / sec: 66333.21
Iteration:   3520, Loss function: 2.979, Average Loss: 3.972, avg. samples / sec: 66127.50
Iteration:   3520, Loss function: 2.981, Average Loss: 3.946, avg. samples / sec: 66189.59
Iteration:   3520, Loss function: 3.532, Average Loss: 3.917, avg. samples / sec: 66023.41
Iteration:   3520, Loss function: 3.204, Average Loss: 3.938, avg. samples / sec: 66203.61
Iteration:   3520, Loss function: 3.540, Average Loss: 3.946, avg. samples / sec: 66070.36
Iteration:   3520, Loss function: 3.284, Average Loss: 3.962, avg. samples / sec: 66204.01
Iteration:   3520, Loss function: 2.167, Average Loss: 3.958, avg. samples / sec: 65915.08
Iteration:   3520, Loss function: 3.435, Average Loss: 3.948, avg. samples / sec: 66020.41
Iteration:   3520, Loss function: 4.027, Average Loss: 3.939, avg. samples / sec: 66051.75
Iteration:   3520, Loss function: 3.835, Average Loss: 3.919, avg. samples / sec: 65961.57
Iteration:   3520, Loss function: 3.077, Average Loss: 3.912, avg. samples / sec: 65940.40
Iteration:   3520, Loss function: 4.146, Average Loss: 3.960, avg. samples / sec: 66119.90
Iteration:   3520, Loss function: 3.852, Average Loss: 3.941, avg. samples / sec: 65967.90
Iteration:   3520, Loss function: 4.002, Average Loss: 3.901, avg. samples / sec: 66123.40
Iteration:   3520, Loss function: 3.459, Average Loss: 3.925, avg. samples / sec: 66102.38
Iteration:   3520, Loss function: 2.940, Average Loss: 3.931, avg. samples / sec: 66140.97
Iteration:   3520, Loss function: 3.173, Average Loss: 3.935, avg. samples / sec: 66043.33
Iteration:   3520, Loss function: 2.600, Average Loss: 3.939, avg. samples / sec: 66008.35
Iteration:   3520, Loss function: 2.776, Average Loss: 3.910, avg. samples / sec: 66015.06
Iteration:   3520, Loss function: 2.850, Average Loss: 3.920, avg. samples / sec: 66171.47
Iteration:   3520, Loss function: 2.354, Average Loss: 3.926, avg. samples / sec: 66037.30
Iteration:   3520, Loss function: 3.622, Average Loss: 3.923, avg. samples / sec: 66047.33
Iteration:   3520, Loss function: 3.426, Average Loss: 3.923, avg. samples / sec: 66009.99
Iteration:   3520, Loss function: 3.014, Average Loss: 3.924, avg. samples / sec: 65974.67
Iteration:   3520, Loss function: 2.327, Average Loss: 3.910, avg. samples / sec: 65921.15
Iteration:   3520, Loss function: 4.098, Average Loss: 3.923, avg. samples / sec: 65997.53
Iteration:   3520, Loss function: 3.643, Average Loss: 3.956, avg. samples / sec: 65974.14
Iteration:   3540, Loss function: 3.474, Average Loss: 3.918, avg. samples / sec: 66090.53
Iteration:   3540, Loss function: 3.736, Average Loss: 3.910, avg. samples / sec: 66129.08
Iteration:   3540, Loss function: 2.567, Average Loss: 3.928, avg. samples / sec: 66055.75
Iteration:   3540, Loss function: 3.700, Average Loss: 3.938, avg. samples / sec: 66066.71
Iteration:   3540, Loss function: 4.082, Average Loss: 3.955, avg. samples / sec: 66049.09
Iteration:   3540, Loss function: 4.204, Average Loss: 3.932, avg. samples / sec: 66003.56
Iteration:   3540, Loss function: 2.714, Average Loss: 3.908, avg. samples / sec: 65987.21
Iteration:   3540, Loss function: 2.500, Average Loss: 3.925, avg. samples / sec: 66069.65
Iteration:   3540, Loss function: 2.411, Average Loss: 3.944, avg. samples / sec: 65866.56
Iteration:   3540, Loss function: 2.630, Average Loss: 3.911, avg. samples / sec: 66096.36
Iteration:   3540, Loss function: 3.126, Average Loss: 3.931, avg. samples / sec: 66080.25
Iteration:   3540, Loss function: 3.311, Average Loss: 3.913, avg. samples / sec: 66096.15
Iteration:   3540, Loss function: 2.530, Average Loss: 3.942, avg. samples / sec: 66200.16
Iteration:   3540, Loss function: 3.117, Average Loss: 3.887, avg. samples / sec: 65986.19
Iteration:   3540, Loss function: 2.786, Average Loss: 3.913, avg. samples / sec: 65982.17
Iteration:   3540, Loss function: 3.125, Average Loss: 3.909, avg. samples / sec: 65960.18
Iteration:   3540, Loss function: 2.846, Average Loss: 3.903, avg. samples / sec: 66001.08
Iteration:   3540, Loss function: 3.590, Average Loss: 3.908, avg. samples / sec: 66051.23
Iteration:   3540, Loss function: 3.024, Average Loss: 3.908, avg. samples / sec: 65963.98
Iteration:   3540, Loss function: 3.216, Average Loss: 3.908, avg. samples / sec: 65882.08
Iteration:   3540, Loss function: 2.959, Average Loss: 3.944, avg. samples / sec: 65910.24
Iteration:   3540, Loss function: 3.821, Average Loss: 3.928, avg. samples / sec: 65858.83
Iteration:   3540, Loss function: 3.481, Average Loss: 3.965, avg. samples / sec: 65851.78
Iteration:   3540, Loss function: 3.766, Average Loss: 3.903, avg. samples / sec: 66022.63
Iteration:   3540, Loss function: 2.493, Average Loss: 3.937, avg. samples / sec: 65850.65
Iteration:   3540, Loss function: 3.404, Average Loss: 3.939, avg. samples / sec: 65817.31
Iteration:   3540, Loss function: 3.686, Average Loss: 3.928, avg. samples / sec: 65874.75
Iteration:   3540, Loss function: 3.186, Average Loss: 3.915, avg. samples / sec: 65988.10
Iteration:   3540, Loss function: 3.351, Average Loss: 3.918, avg. samples / sec: 65895.26
Iteration:   3540, Loss function: 3.503, Average Loss: 3.951, avg. samples / sec: 65815.34
:::MLL 1558651459.076 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558651459.077 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 2.993, Average Loss: 3.930, avg. samples / sec: 65995.95
Iteration:   3560, Loss function: 2.439, Average Loss: 3.930, avg. samples / sec: 65788.95
Iteration:   3560, Loss function: 3.649, Average Loss: 3.929, avg. samples / sec: 65941.94
Iteration:   3560, Loss function: 2.722, Average Loss: 3.894, avg. samples / sec: 65782.90
Iteration:   3560, Loss function: 3.397, Average Loss: 3.901, avg. samples / sec: 65840.25
Iteration:   3560, Loss function: 4.017, Average Loss: 3.924, avg. samples / sec: 65896.56
Iteration:   3560, Loss function: 4.540, Average Loss: 3.907, avg. samples / sec: 65829.42
Iteration:   3560, Loss function: 2.901, Average Loss: 3.877, avg. samples / sec: 65801.30
Iteration:   3560, Loss function: 3.785, Average Loss: 3.918, avg. samples / sec: 65904.81
Iteration:   3560, Loss function: 3.086, Average Loss: 3.943, avg. samples / sec: 65969.14
Iteration:   3560, Loss function: 3.136, Average Loss: 3.922, avg. samples / sec: 65709.93
Iteration:   3560, Loss function: 4.119, Average Loss: 3.913, avg. samples / sec: 65713.98
Iteration:   3560, Loss function: 4.803, Average Loss: 3.949, avg. samples / sec: 65859.57
Iteration:   3560, Loss function: 3.826, Average Loss: 3.926, avg. samples / sec: 65727.25
Iteration:   3560, Loss function: 3.576, Average Loss: 3.900, avg. samples / sec: 65784.07
Iteration:   3560, Loss function: 3.536, Average Loss: 3.900, avg. samples / sec: 65774.89
Iteration:   3560, Loss function: 3.136, Average Loss: 3.889, avg. samples / sec: 65785.30
Iteration:   3560, Loss function: 2.345, Average Loss: 3.905, avg. samples / sec: 65700.56
Iteration:   3560, Loss function: 2.973, Average Loss: 3.935, avg. samples / sec: 65711.92
Iteration:   3560, Loss function: 3.594, Average Loss: 3.893, avg. samples / sec: 65798.16
Iteration:   3560, Loss function: 2.983, Average Loss: 3.903, avg. samples / sec: 65588.92
Iteration:   3560, Loss function: 3.052, Average Loss: 3.904, avg. samples / sec: 65824.44
Iteration:   3560, Loss function: 3.007, Average Loss: 3.908, avg. samples / sec: 65591.15
Iteration:   3560, Loss function: 3.023, Average Loss: 3.916, avg. samples / sec: 65750.21
Iteration:   3560, Loss function: 2.661, Average Loss: 3.922, avg. samples / sec: 65621.41
Iteration:   3560, Loss function: 2.098, Average Loss: 3.906, avg. samples / sec: 65521.01
Iteration:   3560, Loss function: 2.703, Average Loss: 3.943, avg. samples / sec: 65535.33
Iteration:   3560, Loss function: 4.619, Average Loss: 3.899, avg. samples / sec: 65644.16
Iteration:   3560, Loss function: 3.346, Average Loss: 3.902, avg. samples / sec: 65573.84
Iteration:   3560, Loss function: 4.685, Average Loss: 3.910, avg. samples / sec: 65781.40
Iteration:   3580, Loss function: 3.147, Average Loss: 3.892, avg. samples / sec: 66228.56
Iteration:   3580, Loss function: 3.972, Average Loss: 3.922, avg. samples / sec: 65893.57
Iteration:   3580, Loss function: 3.300, Average Loss: 3.904, avg. samples / sec: 66142.55
Iteration:   3580, Loss function: 2.930, Average Loss: 3.903, avg. samples / sec: 66028.36
Iteration:   3580, Loss function: 3.011, Average Loss: 3.917, avg. samples / sec: 66022.88
Iteration:   3580, Loss function: 4.140, Average Loss: 3.932, avg. samples / sec: 65991.78
Iteration:   3580, Loss function: 3.683, Average Loss: 3.891, avg. samples / sec: 66107.43
Iteration:   3580, Loss function: 3.140, Average Loss: 3.917, avg. samples / sec: 66007.27
Iteration:   3580, Loss function: 3.955, Average Loss: 3.940, avg. samples / sec: 65992.80
Iteration:   3580, Loss function: 4.309, Average Loss: 3.924, avg. samples / sec: 65902.90
Iteration:   3580, Loss function: 3.509, Average Loss: 3.913, avg. samples / sec: 66101.57
Iteration:   3580, Loss function: 3.370, Average Loss: 3.934, avg. samples / sec: 66158.95
Iteration:   3580, Loss function: 3.573, Average Loss: 3.879, avg. samples / sec: 66006.62
Iteration:   3580, Loss function: 3.981, Average Loss: 3.903, avg. samples / sec: 66001.02
Iteration:   3580, Loss function: 4.657, Average Loss: 3.898, avg. samples / sec: 66020.78
Iteration:   3580, Loss function: 2.960, Average Loss: 3.893, avg. samples / sec: 65962.62
Iteration:   3580, Loss function: 4.708, Average Loss: 3.889, avg. samples / sec: 66045.13
Iteration:   3580, Loss function: 2.738, Average Loss: 3.883, avg. samples / sec: 66119.53
Iteration:   3580, Loss function: 4.168, Average Loss: 3.906, avg. samples / sec: 66065.50
Iteration:   3580, Loss function: 3.598, Average Loss: 3.867, avg. samples / sec: 65960.55
Iteration:   3580, Loss function: 3.955, Average Loss: 3.891, avg. samples / sec: 65973.92
Iteration:   3580, Loss function: 2.969, Average Loss: 3.913, avg. samples / sec: 65923.44
Iteration:   3580, Loss function: 2.935, Average Loss: 3.924, avg. samples / sec: 66011.32
Iteration:   3580, Loss function: 3.649, Average Loss: 3.892, avg. samples / sec: 65950.95
Iteration:   3580, Loss function: 2.440, Average Loss: 3.892, avg. samples / sec: 66094.35
Iteration:   3580, Loss function: 3.450, Average Loss: 3.897, avg. samples / sec: 65883.77
Iteration:   3580, Loss function: 4.591, Average Loss: 3.886, avg. samples / sec: 65843.39
Iteration:   3580, Loss function: 3.057, Average Loss: 3.898, avg. samples / sec: 65961.29
Iteration:   3580, Loss function: 3.698, Average Loss: 3.902, avg. samples / sec: 66021.12
Iteration:   3580, Loss function: 4.090, Average Loss: 3.920, avg. samples / sec: 65796.41
Iteration:   3600, Loss function: 2.214, Average Loss: 3.924, avg. samples / sec: 66198.79
Iteration:   3600, Loss function: 3.238, Average Loss: 3.903, avg. samples / sec: 66149.63
Iteration:   3600, Loss function: 3.419, Average Loss: 3.858, avg. samples / sec: 66135.10
Iteration:   3600, Loss function: 3.640, Average Loss: 3.912, avg. samples / sec: 66040.83
Iteration:   3600, Loss function: 3.225, Average Loss: 3.895, avg. samples / sec: 66140.44
Iteration:   3600, Loss function: 3.591, Average Loss: 3.882, avg. samples / sec: 66106.04
Iteration:   3600, Loss function: 3.307, Average Loss: 3.891, avg. samples / sec: 66056.99
Iteration:   3600, Loss function: 3.229, Average Loss: 3.914, avg. samples / sec: 66084.49
Iteration:   3600, Loss function: 2.635, Average Loss: 3.882, avg. samples / sec: 66071.32
Iteration:   3600, Loss function: 3.265, Average Loss: 3.891, avg. samples / sec: 66078.91
Iteration:   3600, Loss function: 3.652, Average Loss: 3.865, avg. samples / sec: 66105.63
Iteration:   3600, Loss function: 3.025, Average Loss: 3.914, avg. samples / sec: 66136.41
Iteration:   3600, Loss function: 3.925, Average Loss: 3.881, avg. samples / sec: 66161.84
Iteration:   3600, Loss function: 3.209, Average Loss: 3.922, avg. samples / sec: 66065.75
Iteration:   3600, Loss function: 3.707, Average Loss: 3.904, avg. samples / sec: 66059.18
Iteration:   3600, Loss function: 3.106, Average Loss: 3.886, avg. samples / sec: 66114.81
Iteration:   3600, Loss function: 2.797, Average Loss: 3.888, avg. samples / sec: 65997.96
Iteration:   3600, Loss function: 3.210, Average Loss: 3.913, avg. samples / sec: 66181.97
Iteration:   3600, Loss function: 2.622, Average Loss: 3.933, avg. samples / sec: 66037.58
Iteration:   3600, Loss function: 3.298, Average Loss: 3.887, avg. samples / sec: 66184.49
Iteration:   3600, Loss function: 3.199, Average Loss: 3.874, avg. samples / sec: 66099.28
Iteration:   3600, Loss function: 3.519, Average Loss: 3.905, avg. samples / sec: 66020.22
Iteration:   3600, Loss function: 2.546, Average Loss: 3.905, avg. samples / sec: 66057.02
Iteration:   3600, Loss function: 3.945, Average Loss: 3.886, avg. samples / sec: 65985.11
Iteration:   3600, Loss function: 3.330, Average Loss: 3.895, avg. samples / sec: 66108.02
Iteration:   3600, Loss function: 3.266, Average Loss: 3.884, avg. samples / sec: 65998.55
Iteration:   3600, Loss function: 2.719, Average Loss: 3.880, avg. samples / sec: 65955.43
Iteration:   3600, Loss function: 3.081, Average Loss: 3.886, avg. samples / sec: 65844.71
Iteration:   3600, Loss function: 3.432, Average Loss: 3.890, avg. samples / sec: 65960.95
Iteration:   3600, Loss function: 4.861, Average Loss: 3.872, avg. samples / sec: 65917.92
Iteration:   3620, Loss function: 2.585, Average Loss: 3.903, avg. samples / sec: 66096.08
Iteration:   3620, Loss function: 3.761, Average Loss: 3.879, avg. samples / sec: 66229.49
Iteration:   3620, Loss function: 4.308, Average Loss: 3.920, avg. samples / sec: 65922.73
Iteration:   3620, Loss function: 4.015, Average Loss: 3.880, avg. samples / sec: 66006.62
Iteration:   3620, Loss function: 3.026, Average Loss: 3.879, avg. samples / sec: 65985.26
Iteration:   3620, Loss function: 3.781, Average Loss: 3.864, avg. samples / sec: 66197.51
Iteration:   3620, Loss function: 3.779, Average Loss: 3.908, avg. samples / sec: 66049.77
Iteration:   3620, Loss function: 2.976, Average Loss: 3.850, avg. samples / sec: 65962.31
Iteration:   3620, Loss function: 3.094, Average Loss: 3.874, avg. samples / sec: 65961.17
Iteration:   3620, Loss function: 2.816, Average Loss: 3.897, avg. samples / sec: 65880.29
Iteration:   3620, Loss function: 3.223, Average Loss: 3.892, avg. samples / sec: 66033.18
Iteration:   3620, Loss function: 2.968, Average Loss: 3.872, avg. samples / sec: 65965.65
Iteration:   3620, Loss function: 2.477, Average Loss: 3.880, avg. samples / sec: 65999.44
Iteration:   3620, Loss function: 3.176, Average Loss: 3.876, avg. samples / sec: 66075.51
Iteration:   3620, Loss function: 2.679, Average Loss: 3.901, avg. samples / sec: 65941.79
Iteration:   3620, Loss function: 3.607, Average Loss: 3.871, avg. samples / sec: 65954.13
Iteration:   3620, Loss function: 3.519, Average Loss: 3.857, avg. samples / sec: 65926.67
Iteration:   3620, Loss function: 3.611, Average Loss: 3.912, avg. samples / sec: 65933.77
Iteration:   3620, Loss function: 3.019, Average Loss: 3.870, avg. samples / sec: 66070.33
Iteration:   3620, Loss function: 2.521, Average Loss: 3.885, avg. samples / sec: 65900.44
Iteration:   3620, Loss function: 3.403, Average Loss: 3.878, avg. samples / sec: 66112.95
Iteration:   3620, Loss function: 3.739, Average Loss: 3.887, avg. samples / sec: 66029.10
Iteration:   3620, Loss function: 2.657, Average Loss: 3.871, avg. samples / sec: 66056.55
Iteration:   3620, Loss function: 3.878, Average Loss: 3.871, avg. samples / sec: 65910.27
Iteration:   3620, Loss function: 3.570, Average Loss: 3.895, avg. samples / sec: 65888.51
Iteration:   3620, Loss function: 2.683, Average Loss: 3.866, avg. samples / sec: 65937.72
Iteration:   3620, Loss function: 2.364, Average Loss: 3.917, avg. samples / sec: 65886.48
Iteration:   3620, Loss function: 5.019, Average Loss: 3.876, avg. samples / sec: 65870.25
Iteration:   3620, Loss function: 4.433, Average Loss: 3.906, avg. samples / sec: 65828.38
Iteration:   3620, Loss function: 4.846, Average Loss: 3.896, avg. samples / sec: 65867.27
:::MLL 1558651460.861 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558651460.862 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 4.775, Average Loss: 3.898, avg. samples / sec: 65456.25
Iteration:   3640, Loss function: 2.129, Average Loss: 3.851, avg. samples / sec: 65597.89
Iteration:   3640, Loss function: 2.698, Average Loss: 3.848, avg. samples / sec: 65511.96
Iteration:   3640, Loss function: 3.154, Average Loss: 3.865, avg. samples / sec: 65541.21
Iteration:   3640, Loss function: 4.040, Average Loss: 3.911, avg. samples / sec: 65459.50
Iteration:   3640, Loss function: 2.916, Average Loss: 3.899, avg. samples / sec: 65488.46
Iteration:   3640, Loss function: 3.209, Average Loss: 3.896, avg. samples / sec: 65664.19
Iteration:   3640, Loss function: 2.912, Average Loss: 3.872, avg. samples / sec: 65592.52
Iteration:   3640, Loss function: 3.226, Average Loss: 3.860, avg. samples / sec: 65535.42
Iteration:   3640, Loss function: 2.214, Average Loss: 3.888, avg. samples / sec: 65523.93
Iteration:   3640, Loss function: 2.815, Average Loss: 3.887, avg. samples / sec: 65478.57
Iteration:   3640, Loss function: 3.173, Average Loss: 3.904, avg. samples / sec: 65618.76
Iteration:   3640, Loss function: 4.164, Average Loss: 3.904, avg. samples / sec: 65531.34
Iteration:   3640, Loss function: 2.907, Average Loss: 3.875, avg. samples / sec: 65557.98
Iteration:   3640, Loss function: 4.020, Average Loss: 3.868, avg. samples / sec: 65463.06
Iteration:   3640, Loss function: 3.270, Average Loss: 3.883, avg. samples / sec: 65579.76
Iteration:   3640, Loss function: 3.442, Average Loss: 3.864, avg. samples / sec: 65544.11
Iteration:   3640, Loss function: 3.151, Average Loss: 3.851, avg. samples / sec: 65440.78
Iteration:   3640, Loss function: 2.698, Average Loss: 3.868, avg. samples / sec: 65424.31
Iteration:   3640, Loss function: 4.054, Average Loss: 3.858, avg. samples / sec: 65553.50
Iteration:   3640, Loss function: 3.830, Average Loss: 3.869, avg. samples / sec: 65346.71
Iteration:   3640, Loss function: 3.755, Average Loss: 3.864, avg. samples / sec: 65507.27
Iteration:   3640, Loss function: 2.873, Average Loss: 3.882, avg. samples / sec: 65609.22
Iteration:   3640, Loss function: 2.366, Average Loss: 3.869, avg. samples / sec: 65573.02
Iteration:   3640, Loss function: 3.685, Average Loss: 3.868, avg. samples / sec: 65431.66
Iteration:   3640, Loss function: 4.695, Average Loss: 3.872, avg. samples / sec: 65435.13
Iteration:   3640, Loss function: 3.050, Average Loss: 3.857, avg. samples / sec: 65452.05
Iteration:   3640, Loss function: 4.254, Average Loss: 3.867, avg. samples / sec: 65392.56
Iteration:   3640, Loss function: 2.962, Average Loss: 3.869, avg. samples / sec: 65286.56
Iteration:   3640, Loss function: 3.932, Average Loss: 3.881, avg. samples / sec: 65310.83
Iteration:   3660, Loss function: 2.844, Average Loss: 3.847, avg. samples / sec: 66099.37
Iteration:   3660, Loss function: 3.778, Average Loss: 3.891, avg. samples / sec: 66014.28
Iteration:   3660, Loss function: 3.915, Average Loss: 3.860, avg. samples / sec: 66175.51
Iteration:   3660, Loss function: 3.224, Average Loss: 3.881, avg. samples / sec: 66050.36
Iteration:   3660, Loss function: 2.796, Average Loss: 3.835, avg. samples / sec: 66026.16
Iteration:   3660, Loss function: 2.225, Average Loss: 3.894, avg. samples / sec: 66063.74
Iteration:   3660, Loss function: 3.438, Average Loss: 3.858, avg. samples / sec: 66080.96
Iteration:   3660, Loss function: 3.127, Average Loss: 3.874, avg. samples / sec: 66062.53
Iteration:   3660, Loss function: 3.054, Average Loss: 3.879, avg. samples / sec: 66044.48
Iteration:   3660, Loss function: 3.118, Average Loss: 3.857, avg. samples / sec: 66137.52
Iteration:   3660, Loss function: 3.410, Average Loss: 3.863, avg. samples / sec: 66075.82
Iteration:   3660, Loss function: 2.611, Average Loss: 3.852, avg. samples / sec: 66072.97
Iteration:   3660, Loss function: 4.526, Average Loss: 3.848, avg. samples / sec: 65950.18
Iteration:   3660, Loss function: 3.148, Average Loss: 3.859, avg. samples / sec: 65988.84
Iteration:   3660, Loss function: 2.994, Average Loss: 3.861, avg. samples / sec: 66178.46
Iteration:   3660, Loss function: 3.051, Average Loss: 3.874, avg. samples / sec: 66033.86
Iteration:   3660, Loss function: 3.686, Average Loss: 3.851, avg. samples / sec: 66052.31
Iteration:   3660, Loss function: 4.151, Average Loss: 3.861, avg. samples / sec: 66063.02
Iteration:   3660, Loss function: 3.143, Average Loss: 3.893, avg. samples / sec: 65999.54
Iteration:   3660, Loss function: 3.574, Average Loss: 3.899, avg. samples / sec: 65951.79
Iteration:   3660, Loss function: 3.915, Average Loss: 3.858, avg. samples / sec: 66053.92
Iteration:   3660, Loss function: 3.332, Average Loss: 3.866, avg. samples / sec: 65977.11
Iteration:   3660, Loss function: 2.673, Average Loss: 3.857, avg. samples / sec: 65994.53
Iteration:   3660, Loss function: 3.251, Average Loss: 3.876, avg. samples / sec: 66145.25
Iteration:   3660, Loss function: 4.120, Average Loss: 3.864, avg. samples / sec: 66028.79
Iteration:   3660, Loss function: 3.709, Average Loss: 3.871, avg. samples / sec: 66014.66
Iteration:   3660, Loss function: 4.349, Average Loss: 3.866, avg. samples / sec: 65910.09
Iteration:   3660, Loss function: 3.777, Average Loss: 3.862, avg. samples / sec: 66075.17
Iteration:   3660, Loss function: 3.060, Average Loss: 3.845, avg. samples / sec: 65900.87
Iteration:   3660, Loss function: 3.040, Average Loss: 3.886, avg. samples / sec: 65820.17
Iteration:   3680, Loss function: 3.359, Average Loss: 3.869, avg. samples / sec: 65995.21
Iteration:   3680, Loss function: 3.455, Average Loss: 3.851, avg. samples / sec: 66033.25
Iteration:   3680, Loss function: 3.556, Average Loss: 3.841, avg. samples / sec: 65976.52
Iteration:   3680, Loss function: 2.830, Average Loss: 3.856, avg. samples / sec: 65998.08
Iteration:   3680, Loss function: 2.716, Average Loss: 3.869, avg. samples / sec: 65990.27
Iteration:   3680, Loss function: 2.674, Average Loss: 3.824, avg. samples / sec: 65924.67
Iteration:   3680, Loss function: 4.756, Average Loss: 3.846, avg. samples / sec: 66015.49
Iteration:   3680, Loss function: 4.936, Average Loss: 3.849, avg. samples / sec: 66006.46
Iteration:   3680, Loss function: 2.892, Average Loss: 3.838, avg. samples / sec: 66104.33
Iteration:   3680, Loss function: 4.051, Average Loss: 3.850, avg. samples / sec: 65967.41
Iteration:   3680, Loss function: 3.462, Average Loss: 3.864, avg. samples / sec: 66020.56
Iteration:   3680, Loss function: 2.976, Average Loss: 3.854, avg. samples / sec: 66003.74
Iteration:   3680, Loss function: 2.519, Average Loss: 3.844, avg. samples / sec: 65901.24
Iteration:   3680, Loss function: 4.068, Average Loss: 3.843, avg. samples / sec: 65941.97
Iteration:   3680, Loss function: 2.918, Average Loss: 3.883, avg. samples / sec: 65836.90
Iteration:   3680, Loss function: 3.181, Average Loss: 3.834, avg. samples / sec: 65828.07
Iteration:   3680, Loss function: 3.561, Average Loss: 3.880, avg. samples / sec: 65879.61
Iteration:   3680, Loss function: 3.420, Average Loss: 3.876, avg. samples / sec: 66064.14
Iteration:   3680, Loss function: 3.310, Average Loss: 3.842, avg. samples / sec: 65854.00
Iteration:   3680, Loss function: 3.034, Average Loss: 3.839, avg. samples / sec: 65886.60
Iteration:   3680, Loss function: 2.461, Average Loss: 3.854, avg. samples / sec: 65962.34
Iteration:   3680, Loss function: 3.717, Average Loss: 3.855, avg. samples / sec: 65872.10
Iteration:   3680, Loss function: 3.767, Average Loss: 3.885, avg. samples / sec: 65910.42
Iteration:   3680, Loss function: 4.039, Average Loss: 3.857, avg. samples / sec: 65936.17
Iteration:   3680, Loss function: 4.530, Average Loss: 3.854, avg. samples / sec: 65782.07
Iteration:   3680, Loss function: 4.014, Average Loss: 3.855, avg. samples / sec: 65894.68
Iteration:   3680, Loss function: 5.208, Average Loss: 3.873, avg. samples / sec: 65793.00
Iteration:   3680, Loss function: 3.118, Average Loss: 3.863, avg. samples / sec: 65800.41
Iteration:   3680, Loss function: 3.675, Average Loss: 3.857, avg. samples / sec: 65832.90
Iteration:   3680, Loss function: 2.524, Average Loss: 3.889, avg. samples / sec: 65793.28
:::MLL 1558651462.647 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558651462.647 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 4.214, Average Loss: 3.876, avg. samples / sec: 65816.05
Iteration:   3700, Loss function: 2.863, Average Loss: 3.846, avg. samples / sec: 65954.53
Iteration:   3700, Loss function: 3.740, Average Loss: 3.868, avg. samples / sec: 65839.79
Iteration:   3700, Loss function: 2.918, Average Loss: 3.854, avg. samples / sec: 65732.30
Iteration:   3700, Loss function: 3.305, Average Loss: 3.843, avg. samples / sec: 65807.60
Iteration:   3700, Loss function: 2.867, Average Loss: 3.827, avg. samples / sec: 65724.70
Iteration:   3700, Loss function: 3.172, Average Loss: 3.858, avg. samples / sec: 65593.83
Iteration:   3700, Loss function: 2.773, Average Loss: 3.844, avg. samples / sec: 65774.83
Iteration:   3700, Loss function: 4.044, Average Loss: 3.839, avg. samples / sec: 65668.66
Iteration:   3700, Loss function: 3.890, Average Loss: 3.840, avg. samples / sec: 65671.59
Iteration:   3700, Loss function: 3.134, Average Loss: 3.841, avg. samples / sec: 65563.44
Iteration:   3700, Loss function: 3.129, Average Loss: 3.847, avg. samples / sec: 65731.29
Iteration:   3700, Loss function: 2.657, Average Loss: 3.870, avg. samples / sec: 65670.58
Iteration:   3700, Loss function: 2.685, Average Loss: 3.866, avg. samples / sec: 65690.79
Iteration:   3700, Loss function: 3.249, Average Loss: 3.847, avg. samples / sec: 65561.12
Iteration:   3700, Loss function: 2.666, Average Loss: 3.852, avg. samples / sec: 65741.35
Iteration:   3700, Loss function: 1.849, Average Loss: 3.856, avg. samples / sec: 65569.11
Iteration:   3700, Loss function: 3.273, Average Loss: 3.818, avg. samples / sec: 65585.38
Iteration:   3700, Loss function: 3.433, Average Loss: 3.831, avg. samples / sec: 65599.94
Iteration:   3700, Loss function: 3.025, Average Loss: 3.839, avg. samples / sec: 65591.61
Iteration:   3700, Loss function: 4.525, Average Loss: 3.831, avg. samples / sec: 65663.73
Iteration:   3700, Loss function: 3.193, Average Loss: 3.840, avg. samples / sec: 65576.16
Iteration:   3700, Loss function: 4.131, Average Loss: 3.881, avg. samples / sec: 65768.78
Iteration:   3700, Loss function: 3.534, Average Loss: 3.876, avg. samples / sec: 65647.46
Iteration:   3700, Loss function: 2.947, Average Loss: 3.837, avg. samples / sec: 65459.35
Iteration:   3700, Loss function: 3.521, Average Loss: 3.833, avg. samples / sec: 65591.61
Iteration:   3700, Loss function: 4.025, Average Loss: 3.849, avg. samples / sec: 65605.93
Iteration:   3700, Loss function: 2.505, Average Loss: 3.846, avg. samples / sec: 65614.88
Iteration:   3700, Loss function: 3.656, Average Loss: 3.831, avg. samples / sec: 65497.71
Iteration:   3700, Loss function: 3.339, Average Loss: 3.833, avg. samples / sec: 65434.03
Iteration:   3720, Loss function: 3.815, Average Loss: 3.819, avg. samples / sec: 65744.48
Iteration:   3720, Loss function: 3.997, Average Loss: 3.808, avg. samples / sec: 65819.80
Iteration:   3720, Loss function: 3.252, Average Loss: 3.831, avg. samples / sec: 65755.98
Iteration:   3720, Loss function: 2.571, Average Loss: 3.855, avg. samples / sec: 65721.30
Iteration:   3720, Loss function: 3.450, Average Loss: 3.856, avg. samples / sec: 65585.38
Iteration:   3720, Loss function: 2.423, Average Loss: 3.867, avg. samples / sec: 65736.69
Iteration:   3720, Loss function: 5.258, Average Loss: 3.875, avg. samples / sec: 65754.36
Iteration:   3720, Loss function: 3.423, Average Loss: 3.842, avg. samples / sec: 65705.43
Iteration:   3720, Loss function: 4.130, Average Loss: 3.824, avg. samples / sec: 65879.55
Iteration:   3720, Loss function: 2.683, Average Loss: 3.830, avg. samples / sec: 65664.01
Iteration:   3720, Loss function: 4.175, Average Loss: 3.838, avg. samples / sec: 65556.09
Iteration:   3720, Loss function: 3.189, Average Loss: 3.832, avg. samples / sec: 65759.54
Iteration:   3720, Loss function: 4.091, Average Loss: 3.841, avg. samples / sec: 65553.77
Iteration:   3720, Loss function: 2.904, Average Loss: 3.838, avg. samples / sec: 65661.44
Iteration:   3720, Loss function: 3.388, Average Loss: 3.856, avg. samples / sec: 65656.82
Iteration:   3720, Loss function: 3.825, Average Loss: 3.838, avg. samples / sec: 65631.22
Iteration:   3720, Loss function: 3.213, Average Loss: 3.846, avg. samples / sec: 65775.41
Iteration:   3720, Loss function: 4.128, Average Loss: 3.852, avg. samples / sec: 65600.86
Iteration:   3720, Loss function: 3.906, Average Loss: 3.837, avg. samples / sec: 65487.00
Iteration:   3720, Loss function: 3.152, Average Loss: 3.862, avg. samples / sec: 65470.97
Iteration:   3720, Loss function: 3.929, Average Loss: 3.834, avg. samples / sec: 65582.91
Iteration:   3720, Loss function: 3.199, Average Loss: 3.824, avg. samples / sec: 65733.81
Iteration:   3720, Loss function: 3.449, Average Loss: 3.822, avg. samples / sec: 65623.58
Iteration:   3720, Loss function: 3.186, Average Loss: 3.830, avg. samples / sec: 65628.17
Iteration:   3720, Loss function: 2.881, Average Loss: 3.840, avg. samples / sec: 65697.43
Iteration:   3720, Loss function: 3.307, Average Loss: 3.837, avg. samples / sec: 65502.95
Iteration:   3720, Loss function: 2.489, Average Loss: 3.831, avg. samples / sec: 65581.26
Iteration:   3720, Loss function: 3.409, Average Loss: 3.824, avg. samples / sec: 65703.41
Iteration:   3720, Loss function: 3.231, Average Loss: 3.843, avg. samples / sec: 65551.15
Iteration:   3720, Loss function: 4.515, Average Loss: 3.822, avg. samples / sec: 65527.68
Iteration:   3740, Loss function: 4.283, Average Loss: 3.848, avg. samples / sec: 65965.52
Iteration:   3740, Loss function: 4.096, Average Loss: 3.818, avg. samples / sec: 66001.73
Iteration:   3740, Loss function: 3.832, Average Loss: 3.812, avg. samples / sec: 65795.22
Iteration:   3740, Loss function: 3.735, Average Loss: 3.830, avg. samples / sec: 66001.30
Iteration:   3740, Loss function: 4.837, Average Loss: 3.851, avg. samples / sec: 65924.92
Iteration:   3740, Loss function: 3.188, Average Loss: 3.855, avg. samples / sec: 65914.09
Iteration:   3740, Loss function: 3.334, Average Loss: 3.835, avg. samples / sec: 65960.52
Iteration:   3740, Loss function: 3.210, Average Loss: 3.828, avg. samples / sec: 66041.72
Iteration:   3740, Loss function: 3.995, Average Loss: 3.834, avg. samples / sec: 65906.94
Iteration:   3740, Loss function: 4.058, Average Loss: 3.802, avg. samples / sec: 65791.28
Iteration:   3740, Loss function: 3.453, Average Loss: 3.853, avg. samples / sec: 65949.44
Iteration:   3740, Loss function: 3.795, Average Loss: 3.844, avg. samples / sec: 65966.88
Iteration:   3740, Loss function: 2.234, Average Loss: 3.818, avg. samples / sec: 65806.40
Iteration:   3740, Loss function: 3.525, Average Loss: 3.831, avg. samples / sec: 65921.55
Iteration:   3740, Loss function: 2.478, Average Loss: 3.820, avg. samples / sec: 66003.90
Iteration:   3740, Loss function: 4.273, Average Loss: 3.839, avg. samples / sec: 65935.43
Iteration:   3740, Loss function: 4.166, Average Loss: 3.834, avg. samples / sec: 66017.56
Iteration:   3740, Loss function: 4.883, Average Loss: 3.830, avg. samples / sec: 65919.24
Iteration:   3740, Loss function: 2.468, Average Loss: 3.831, avg. samples / sec: 65874.29
Iteration:   3740, Loss function: 3.749, Average Loss: 3.816, avg. samples / sec: 65914.65
Iteration:   3740, Loss function: 3.014, Average Loss: 3.819, avg. samples / sec: 65969.69
Iteration:   3740, Loss function: 2.361, Average Loss: 3.814, avg. samples / sec: 65981.83
Iteration:   3740, Loss function: 3.833, Average Loss: 3.832, avg. samples / sec: 65981.52
Iteration:   3740, Loss function: 2.926, Average Loss: 3.822, avg. samples / sec: 65849.38
Iteration:   3740, Loss function: 3.913, Average Loss: 3.808, avg. samples / sec: 66027.12
Iteration:   3740, Loss function: 2.491, Average Loss: 3.817, avg. samples / sec: 65811.41
Iteration:   3740, Loss function: 2.583, Average Loss: 3.819, avg. samples / sec: 65810.52
Iteration:   3740, Loss function: 2.214, Average Loss: 3.829, avg. samples / sec: 65862.89
Iteration:   3740, Loss function: 3.424, Average Loss: 3.849, avg. samples / sec: 65773.78
Iteration:   3740, Loss function: 2.827, Average Loss: 3.866, avg. samples / sec: 65705.67
Iteration:   3760, Loss function: 2.551, Average Loss: 3.824, avg. samples / sec: 66018.18
Iteration:   3760, Loss function: 3.377, Average Loss: 3.814, avg. samples / sec: 66087.68
Iteration:   3760, Loss function: 4.598, Average Loss: 3.799, avg. samples / sec: 65993.29
Iteration:   3760, Loss function: 3.748, Average Loss: 3.809, avg. samples / sec: 66096.18
Iteration:   3760, Loss function: 3.101, Average Loss: 3.826, avg. samples / sec: 65959.78
Iteration:   3760, Loss function: 2.605, Average Loss: 3.820, avg. samples / sec: 66028.54
Iteration:   3760, Loss function: 2.758, Average Loss: 3.844, avg. samples / sec: 65983.04
Iteration:   3760, Loss function: 4.449, Average Loss: 3.809, avg. samples / sec: 65980.78
Iteration:   3760, Loss function: 3.329, Average Loss: 3.851, avg. samples / sec: 65963.46
Iteration:   3760, Loss function: 4.016, Average Loss: 3.814, avg. samples / sec: 65970.19
Iteration:   3760, Loss function: 3.984, Average Loss: 3.792, avg. samples / sec: 65959.10
Iteration:   3760, Loss function: 3.976, Average Loss: 3.808, avg. samples / sec: 66013.98
Iteration:   3760, Loss function: 2.636, Average Loss: 3.824, avg. samples / sec: 65905.65
Iteration:   3760, Loss function: 3.562, Average Loss: 3.853, avg. samples / sec: 66141.31
Iteration:   3760, Loss function: 3.133, Average Loss: 3.837, avg. samples / sec: 65906.11
Iteration:   3760, Loss function: 3.059, Average Loss: 3.836, avg. samples / sec: 66084.68
Iteration:   3760, Loss function: 3.388, Average Loss: 3.838, avg. samples / sec: 65810.61
Iteration:   3760, Loss function: 3.219, Average Loss: 3.809, avg. samples / sec: 66003.68
Iteration:   3760, Loss function: 3.640, Average Loss: 3.813, avg. samples / sec: 65880.81
Iteration:   3760, Loss function: 3.838, Average Loss: 3.823, avg. samples / sec: 65972.07
Iteration:   3760, Loss function: 3.524, Average Loss: 3.829, avg. samples / sec: 65903.55
Iteration:   3760, Loss function: 2.488, Average Loss: 3.830, avg. samples / sec: 65854.74
Iteration:   3760, Loss function: 2.909, Average Loss: 3.820, avg. samples / sec: 65812.21
Iteration:   3760, Loss function: 3.386, Average Loss: 3.799, avg. samples / sec: 65917.95
Iteration:   3760, Loss function: 2.985, Average Loss: 3.810, avg. samples / sec: 65915.23
Iteration:   3760, Loss function: 2.890, Average Loss: 3.829, avg. samples / sec: 65913.69
Iteration:   3760, Loss function: 3.770, Average Loss: 3.820, avg. samples / sec: 65854.49
Iteration:   3760, Loss function: 3.915, Average Loss: 3.802, avg. samples / sec: 65874.35
Iteration:   3760, Loss function: 4.315, Average Loss: 3.826, avg. samples / sec: 65869.11
Iteration:   3760, Loss function: 2.864, Average Loss: 3.824, avg. samples / sec: 65776.61
:::MLL 1558651464.436 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558651464.437 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 3.096, Average Loss: 3.831, avg. samples / sec: 65513.88
Iteration:   3780, Loss function: 3.652, Average Loss: 3.814, avg. samples / sec: 65449.80
Iteration:   3780, Loss function: 2.859, Average Loss: 3.799, avg. samples / sec: 65475.96
Iteration:   3780, Loss function: 3.768, Average Loss: 3.836, avg. samples / sec: 65546.64
Iteration:   3780, Loss function: 4.575, Average Loss: 3.793, avg. samples / sec: 65412.17
Iteration:   3780, Loss function: 3.120, Average Loss: 3.812, avg. samples / sec: 65604.00
Iteration:   3780, Loss function: 2.829, Average Loss: 3.812, avg. samples / sec: 65633.73
Iteration:   3780, Loss function: 3.713, Average Loss: 3.825, avg. samples / sec: 65475.65
Iteration:   3780, Loss function: 4.459, Average Loss: 3.825, avg. samples / sec: 65471.06
Iteration:   3780, Loss function: 3.447, Average Loss: 3.843, avg. samples / sec: 65430.39
Iteration:   3780, Loss function: 3.151, Average Loss: 3.782, avg. samples / sec: 65411.41
Iteration:   3780, Loss function: 3.976, Average Loss: 3.787, avg. samples / sec: 65517.96
Iteration:   3780, Loss function: 2.109, Average Loss: 3.805, avg. samples / sec: 65445.22
Iteration:   3780, Loss function: 3.190, Average Loss: 3.803, avg. samples / sec: 65331.08
Iteration:   3780, Loss function: 2.281, Average Loss: 3.800, avg. samples / sec: 65346.44
Iteration:   3780, Loss function: 4.253, Average Loss: 3.801, avg. samples / sec: 65486.64
Iteration:   3780, Loss function: 3.728, Average Loss: 3.801, avg. samples / sec: 65437.86
Iteration:   3780, Loss function: 3.122, Average Loss: 3.820, avg. samples / sec: 65371.72
Iteration:   3780, Loss function: 3.804, Average Loss: 3.814, avg. samples / sec: 65383.46
Iteration:   3780, Loss function: 3.943, Average Loss: 3.818, avg. samples / sec: 65490.56
Iteration:   3780, Loss function: 4.488, Average Loss: 3.805, avg. samples / sec: 65366.53
Iteration:   3780, Loss function: 3.796, Average Loss: 3.808, avg. samples / sec: 65340.80
Iteration:   3780, Loss function: 2.201, Average Loss: 3.790, avg. samples / sec: 65507.79
Iteration:   3780, Loss function: 3.218, Average Loss: 3.813, avg. samples / sec: 65388.25
Iteration:   3780, Loss function: 3.221, Average Loss: 3.824, avg. samples / sec: 65408.01
Iteration:   3780, Loss function: 2.802, Average Loss: 3.810, avg. samples / sec: 65284.11
Iteration:   3780, Loss function: 3.339, Average Loss: 3.831, avg. samples / sec: 65338.83
Iteration:   3780, Loss function: 2.810, Average Loss: 3.808, avg. samples / sec: 65427.38
Iteration:   3780, Loss function: 2.959, Average Loss: 3.815, avg. samples / sec: 65490.77
Iteration:   3780, Loss function: 4.132, Average Loss: 3.842, avg. samples / sec: 65231.26
Iteration:   3800, Loss function: 4.479, Average Loss: 3.784, avg. samples / sec: 66030.52
Iteration:   3800, Loss function: 2.644, Average Loss: 3.813, avg. samples / sec: 65987.92
Iteration:   3800, Loss function: 4.558, Average Loss: 3.797, avg. samples / sec: 66013.11
Iteration:   3800, Loss function: 2.791, Average Loss: 3.788, avg. samples / sec: 65893.94
Iteration:   3800, Loss function: 3.307, Average Loss: 3.792, avg. samples / sec: 65948.89
Iteration:   3800, Loss function: 3.089, Average Loss: 3.791, avg. samples / sec: 65840.00
Iteration:   3800, Loss function: 3.978, Average Loss: 3.836, avg. samples / sec: 66096.52
Iteration:   3800, Loss function: 3.170, Average Loss: 3.820, avg. samples / sec: 65793.46
Iteration:   3800, Loss function: 3.136, Average Loss: 3.793, avg. samples / sec: 65953.64
Iteration:   3800, Loss function: 1.854, Average Loss: 3.806, avg. samples / sec: 65988.75
Iteration:   3800, Loss function: 2.898, Average Loss: 3.815, avg. samples / sec: 65901.79
Iteration:   3800, Loss function: 3.791, Average Loss: 3.793, avg. samples / sec: 65909.50
Iteration:   3800, Loss function: 3.238, Average Loss: 3.799, avg. samples / sec: 65989.99
Iteration:   3800, Loss function: 3.598, Average Loss: 3.794, avg. samples / sec: 65911.01
Iteration:   3800, Loss function: 2.391, Average Loss: 3.800, avg. samples / sec: 65823.21
Iteration:   3800, Loss function: 2.952, Average Loss: 3.816, avg. samples / sec: 65826.78
Iteration:   3800, Loss function: 3.169, Average Loss: 3.808, avg. samples / sec: 65983.72
Iteration:   3800, Loss function: 3.630, Average Loss: 3.836, avg. samples / sec: 65855.91
Iteration:   3800, Loss function: 2.925, Average Loss: 3.807, avg. samples / sec: 65806.86
Iteration:   3800, Loss function: 2.683, Average Loss: 3.805, avg. samples / sec: 65931.85
Iteration:   3800, Loss function: 3.369, Average Loss: 3.807, avg. samples / sec: 65880.04
Iteration:   3800, Loss function: 3.736, Average Loss: 3.774, avg. samples / sec: 65785.42
Iteration:   3800, Loss function: 5.470, Average Loss: 3.801, avg. samples / sec: 65860.34
Iteration:   3800, Loss function: 3.723, Average Loss: 3.804, avg. samples / sec: 65690.14
Iteration:   3800, Loss function: 3.393, Average Loss: 3.783, avg. samples / sec: 65759.42
Iteration:   3800, Loss function: 2.704, Average Loss: 3.823, avg. samples / sec: 65882.05
Iteration:   3800, Loss function: 5.607, Average Loss: 3.813, avg. samples / sec: 65793.89
Iteration:   3800, Loss function: 2.257, Average Loss: 3.800, avg. samples / sec: 65753.62
Iteration:   3800, Loss function: 4.384, Average Loss: 3.815, avg. samples / sec: 65816.33
Iteration:   3800, Loss function: 2.320, Average Loss: 3.828, avg. samples / sec: 65608.74
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558651465.465 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=2.55s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22643
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38873
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05682
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24027
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36751
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22050
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32071
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33752
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09778
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36767
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52382
Current AP: 0.22643 AP goal: 0.23000
:::MLL 1558651469.200 eval_accuracy: {"value": 0.22642809244985795, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558651469.262 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558651469.268 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558651469.269 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 3.761, Average Loss: 3.799, avg. samples / sec: 7770.92
Iteration:   3820, Loss function: 4.374, Average Loss: 3.787, avg. samples / sec: 7771.08
Iteration:   3820, Loss function: 2.895, Average Loss: 3.792, avg. samples / sec: 7771.72
Iteration:   3820, Loss function: 3.106, Average Loss: 3.801, avg. samples / sec: 7771.45
Iteration:   3820, Loss function: 2.680, Average Loss: 3.782, avg. samples / sec: 7770.23
Iteration:   3820, Loss function: 2.832, Average Loss: 3.796, avg. samples / sec: 7770.54
Iteration:   3820, Loss function: 3.265, Average Loss: 3.790, avg. samples / sec: 7772.69
Iteration:   3820, Loss function: 2.761, Average Loss: 3.810, avg. samples / sec: 7772.61
Iteration:   3820, Loss function: 2.154, Average Loss: 3.803, avg. samples / sec: 7770.22
Iteration:   3820, Loss function: 4.014, Average Loss: 3.775, avg. samples / sec: 7768.90
Iteration:   3820, Loss function: 3.795, Average Loss: 3.805, avg. samples / sec: 7772.15
Iteration:   3820, Loss function: 3.694, Average Loss: 3.828, avg. samples / sec: 7769.34
Iteration:   3820, Loss function: 3.113, Average Loss: 3.814, avg. samples / sec: 7770.43
Iteration:   3820, Loss function: 3.005, Average Loss: 3.798, avg. samples / sec: 7770.53
Iteration:   3820, Loss function: 2.777, Average Loss: 3.767, avg. samples / sec: 7771.29
Iteration:   3820, Loss function: 2.740, Average Loss: 3.826, avg. samples / sec: 7770.12
Iteration:   3820, Loss function: 4.508, Average Loss: 3.781, avg. samples / sec: 7768.65
Iteration:   3820, Loss function: 3.944, Average Loss: 3.786, avg. samples / sec: 7769.39
Iteration:   3820, Loss function: 2.419, Average Loss: 3.823, avg. samples / sec: 7771.91
Iteration:   3820, Loss function: 3.543, Average Loss: 3.780, avg. samples / sec: 7768.82
Iteration:   3820, Loss function: 2.821, Average Loss: 3.794, avg. samples / sec: 7768.05
Iteration:   3820, Loss function: 4.280, Average Loss: 3.797, avg. samples / sec: 7770.44
Iteration:   3820, Loss function: 3.721, Average Loss: 3.791, avg. samples / sec: 7769.03
Iteration:   3820, Loss function: 3.001, Average Loss: 3.788, avg. samples / sec: 7769.02
Iteration:   3820, Loss function: 5.209, Average Loss: 3.795, avg. samples / sec: 7770.09
Iteration:   3820, Loss function: 3.811, Average Loss: 3.812, avg. samples / sec: 7768.19
Iteration:   3820, Loss function: 3.771, Average Loss: 3.811, avg. samples / sec: 7770.29
Iteration:   3820, Loss function: 4.177, Average Loss: 3.797, avg. samples / sec: 7768.44
Iteration:   3820, Loss function: 5.301, Average Loss: 3.779, avg. samples / sec: 7769.92
Iteration:   3820, Loss function: 4.628, Average Loss: 3.804, avg. samples / sec: 7767.71
:::MLL 1558651470.039 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558651470.040 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 4.482, Average Loss: 3.765, avg. samples / sec: 65669.48
Iteration:   3840, Loss function: 3.898, Average Loss: 3.786, avg. samples / sec: 65571.89
Iteration:   3840, Loss function: 3.312, Average Loss: 3.793, avg. samples / sec: 65458.56
Iteration:   3840, Loss function: 3.750, Average Loss: 3.802, avg. samples / sec: 65562.37
Iteration:   3840, Loss function: 4.627, Average Loss: 3.806, avg. samples / sec: 65680.26
Iteration:   3840, Loss function: 2.712, Average Loss: 3.787, avg. samples / sec: 65587.06
Iteration:   3840, Loss function: 3.196, Average Loss: 3.772, avg. samples / sec: 65631.01
Iteration:   3840, Loss function: 4.865, Average Loss: 3.774, avg. samples / sec: 65632.51
Iteration:   3840, Loss function: 3.389, Average Loss: 3.784, avg. samples / sec: 65507.30
Iteration:   3840, Loss function: 4.211, Average Loss: 3.773, avg. samples / sec: 65668.63
Iteration:   3840, Loss function: 2.798, Average Loss: 3.787, avg. samples / sec: 65458.77
Iteration:   3840, Loss function: 2.889, Average Loss: 3.779, avg. samples / sec: 65417.42
Iteration:   3840, Loss function: 3.226, Average Loss: 3.775, avg. samples / sec: 65554.05
Iteration:   3840, Loss function: 3.400, Average Loss: 3.816, avg. samples / sec: 65512.54
Iteration:   3840, Loss function: 2.369, Average Loss: 3.795, avg. samples / sec: 65458.41
Iteration:   3840, Loss function: 3.455, Average Loss: 3.799, avg. samples / sec: 65575.95
Iteration:   3840, Loss function: 4.228, Average Loss: 3.778, avg. samples / sec: 65545.42
Iteration:   3840, Loss function: 4.390, Average Loss: 3.787, avg. samples / sec: 65377.15
Iteration:   3840, Loss function: 2.928, Average Loss: 3.792, avg. samples / sec: 65544.53
Iteration:   3840, Loss function: 3.445, Average Loss: 3.784, avg. samples / sec: 65580.92
Iteration:   3840, Loss function: 4.114, Average Loss: 3.822, avg. samples / sec: 65483.41
Iteration:   3840, Loss function: 3.312, Average Loss: 3.798, avg. samples / sec: 65462.12
Iteration:   3840, Loss function: 3.577, Average Loss: 3.789, avg. samples / sec: 65528.66
Iteration:   3840, Loss function: 3.841, Average Loss: 3.770, avg. samples / sec: 65457.74
Iteration:   3840, Loss function: 4.104, Average Loss: 3.774, avg. samples / sec: 65389.58
Iteration:   3840, Loss function: 3.447, Average Loss: 3.813, avg. samples / sec: 65496.37
Iteration:   3840, Loss function: 4.230, Average Loss: 3.784, avg. samples / sec: 65511.75
Iteration:   3840, Loss function: 3.679, Average Loss: 3.798, avg. samples / sec: 65610.97
Iteration:   3840, Loss function: 3.091, Average Loss: 3.782, avg. samples / sec: 65486.27
Iteration:   3840, Loss function: 3.490, Average Loss: 3.809, avg. samples / sec: 65365.17
Iteration:   3860, Loss function: 2.680, Average Loss: 3.786, avg. samples / sec: 65943.86
Iteration:   3860, Loss function: 2.962, Average Loss: 3.817, avg. samples / sec: 65829.98
Iteration:   3860, Loss function: 3.362, Average Loss: 3.784, avg. samples / sec: 65828.19
Iteration:   3860, Loss function: 2.982, Average Loss: 3.776, avg. samples / sec: 65877.21
Iteration:   3860, Loss function: 3.895, Average Loss: 3.777, avg. samples / sec: 65845.20
Iteration:   3860, Loss function: 3.497, Average Loss: 3.795, avg. samples / sec: 65717.74
Iteration:   3860, Loss function: 3.174, Average Loss: 3.764, avg. samples / sec: 65634.10
Iteration:   3860, Loss function: 3.369, Average Loss: 3.789, avg. samples / sec: 65682.95
Iteration:   3860, Loss function: 3.564, Average Loss: 3.793, avg. samples / sec: 65853.51
Iteration:   3860, Loss function: 2.830, Average Loss: 3.762, avg. samples / sec: 65680.19
Iteration:   3860, Loss function: 2.695, Average Loss: 3.767, avg. samples / sec: 65755.25
Iteration:   3860, Loss function: 1.938, Average Loss: 3.769, avg. samples / sec: 65788.06
Iteration:   3860, Loss function: 2.986, Average Loss: 3.765, avg. samples / sec: 65826.81
Iteration:   3860, Loss function: 3.593, Average Loss: 3.774, avg. samples / sec: 65733.01
Iteration:   3860, Loss function: 3.467, Average Loss: 3.781, avg. samples / sec: 65682.52
Iteration:   3860, Loss function: 3.936, Average Loss: 3.803, avg. samples / sec: 65809.26
Iteration:   3860, Loss function: 2.526, Average Loss: 3.813, avg. samples / sec: 65731.05
Iteration:   3860, Loss function: 4.323, Average Loss: 3.804, avg. samples / sec: 65868.59
Iteration:   3860, Loss function: 2.688, Average Loss: 3.780, avg. samples / sec: 65678.54
Iteration:   3860, Loss function: 3.146, Average Loss: 3.777, avg. samples / sec: 65579.95
Iteration:   3860, Loss function: 3.605, Average Loss: 3.783, avg. samples / sec: 65748.34
Iteration:   3860, Loss function: 3.006, Average Loss: 3.769, avg. samples / sec: 65769.39
Iteration:   3860, Loss function: 3.985, Average Loss: 3.769, avg. samples / sec: 65621.29
Iteration:   3860, Loss function: 4.271, Average Loss: 3.792, avg. samples / sec: 65700.50
Iteration:   3860, Loss function: 3.688, Average Loss: 3.762, avg. samples / sec: 65713.33
Iteration:   3860, Loss function: 4.069, Average Loss: 3.774, avg. samples / sec: 65632.23
Iteration:   3860, Loss function: 2.886, Average Loss: 3.796, avg. samples / sec: 65560.12
Iteration:   3860, Loss function: 3.097, Average Loss: 3.787, avg. samples / sec: 65657.06
Iteration:   3860, Loss function: 3.218, Average Loss: 3.787, avg. samples / sec: 65659.85
Iteration:   3860, Loss function: 4.675, Average Loss: 3.768, avg. samples / sec: 65549.53
Iteration:   3880, Loss function: 3.343, Average Loss: 3.758, avg. samples / sec: 65908.39
Iteration:   3880, Loss function: 3.187, Average Loss: 3.766, avg. samples / sec: 65836.83
Iteration:   3880, Loss function: 4.080, Average Loss: 3.759, avg. samples / sec: 65960.74
Iteration:   3880, Loss function: 2.948, Average Loss: 3.771, avg. samples / sec: 65910.18
Iteration:   3880, Loss function: 3.246, Average Loss: 3.794, avg. samples / sec: 65869.82
Iteration:   3880, Loss function: 2.955, Average Loss: 3.807, avg. samples / sec: 65890.15
Iteration:   3880, Loss function: 2.632, Average Loss: 3.778, avg. samples / sec: 65805.02
Iteration:   3880, Loss function: 4.539, Average Loss: 3.773, avg. samples / sec: 65777.40
Iteration:   3880, Loss function: 3.937, Average Loss: 3.772, avg. samples / sec: 65757.15
Iteration:   3880, Loss function: 3.850, Average Loss: 3.806, avg. samples / sec: 65756.78
Iteration:   3880, Loss function: 2.977, Average Loss: 3.777, avg. samples / sec: 65645.93
Iteration:   3880, Loss function: 2.986, Average Loss: 3.758, avg. samples / sec: 65970.37
Iteration:   3880, Loss function: 2.600, Average Loss: 3.775, avg. samples / sec: 65926.30
Iteration:   3880, Loss function: 3.396, Average Loss: 3.795, avg. samples / sec: 65828.25
Iteration:   3880, Loss function: 2.829, Average Loss: 3.779, avg. samples / sec: 65835.51
Iteration:   3880, Loss function: 3.135, Average Loss: 3.783, avg. samples / sec: 65850.49
Iteration:   3880, Loss function: 4.515, Average Loss: 3.761, avg. samples / sec: 65833.42
Iteration:   3880, Loss function: 2.293, Average Loss: 3.756, avg. samples / sec: 65752.79
Iteration:   3880, Loss function: 3.874, Average Loss: 3.770, avg. samples / sec: 65810.39
Iteration:   3880, Loss function: 3.830, Average Loss: 3.779, avg. samples / sec: 65723.26
Iteration:   3880, Loss function: 2.883, Average Loss: 3.765, avg. samples / sec: 65739.60
Iteration:   3880, Loss function: 3.855, Average Loss: 3.756, avg. samples / sec: 65699.73
Iteration:   3880, Loss function: 3.941, Average Loss: 3.772, avg. samples / sec: 65735.49
Iteration:   3880, Loss function: 3.576, Average Loss: 3.755, avg. samples / sec: 65812.98
Iteration:   3880, Loss function: 3.128, Average Loss: 3.788, avg. samples / sec: 65665.81
Iteration:   3880, Loss function: 2.894, Average Loss: 3.759, avg. samples / sec: 65694.58
Iteration:   3880, Loss function: 3.587, Average Loss: 3.782, avg. samples / sec: 65817.00
Iteration:   3880, Loss function: 3.215, Average Loss: 3.766, avg. samples / sec: 65765.86
Iteration:   3880, Loss function: 3.213, Average Loss: 3.783, avg. samples / sec: 65779.71
Iteration:   3880, Loss function: 3.831, Average Loss: 3.751, avg. samples / sec: 65639.84
Iteration:   3900, Loss function: 3.246, Average Loss: 3.769, avg. samples / sec: 65114.53
Iteration:   3900, Loss function: 3.703, Average Loss: 3.790, avg. samples / sec: 65149.06
Iteration:   3900, Loss function: 3.562, Average Loss: 3.750, avg. samples / sec: 65038.05
Iteration:   3900, Loss function: 3.402, Average Loss: 3.766, avg. samples / sec: 65190.67
Iteration:   3900, Loss function: 3.521, Average Loss: 3.751, avg. samples / sec: 65195.11
Iteration:   3900, Loss function: 2.581, Average Loss: 3.754, avg. samples / sec: 65215.71
Iteration:   3900, Loss function: 2.895, Average Loss: 3.754, avg. samples / sec: 64992.16
Iteration:   3900, Loss function: 3.445, Average Loss: 3.770, avg. samples / sec: 65152.04
Iteration:   3900, Loss function: 3.762, Average Loss: 3.779, avg. samples / sec: 65215.65
Iteration:   3900, Loss function: 5.271, Average Loss: 3.773, avg. samples / sec: 65230.14
Iteration:   3900, Loss function: 3.158, Average Loss: 3.754, avg. samples / sec: 65123.77
Iteration:   3900, Loss function: 3.719, Average Loss: 3.764, avg. samples / sec: 65087.16
Iteration:   3900, Loss function: 2.303, Average Loss: 3.768, avg. samples / sec: 65049.67
Iteration:   3900, Loss function: 4.257, Average Loss: 3.797, avg. samples / sec: 65063.27
Iteration:   3900, Loss function: 3.427, Average Loss: 3.771, avg. samples / sec: 65099.61
Iteration:   3900, Loss function: 3.987, Average Loss: 3.803, avg. samples / sec: 65010.00
Iteration:   3900, Loss function: 2.758, Average Loss: 3.750, avg. samples / sec: 65077.58
Iteration:   3900, Loss function: 2.913, Average Loss: 3.750, avg. samples / sec: 65114.14
Iteration:   3900, Loss function: 4.085, Average Loss: 3.743, avg. samples / sec: 65198.24
Iteration:   3900, Loss function: 3.767, Average Loss: 3.753, avg. samples / sec: 65059.67
Iteration:   3900, Loss function: 3.628, Average Loss: 3.769, avg. samples / sec: 65030.58
Iteration:   3900, Loss function: 4.142, Average Loss: 3.765, avg. samples / sec: 64976.94
Iteration:   3900, Loss function: 2.470, Average Loss: 3.771, avg. samples / sec: 65006.22
Iteration:   3900, Loss function: 3.259, Average Loss: 3.754, avg. samples / sec: 65067.72
Iteration:   3900, Loss function: 3.787, Average Loss: 3.772, avg. samples / sec: 65017.89
Iteration:   3900, Loss function: 2.822, Average Loss: 3.788, avg. samples / sec: 64930.99
Iteration:   3900, Loss function: 2.305, Average Loss: 3.780, avg. samples / sec: 65066.97
Iteration:   3900, Loss function: 2.626, Average Loss: 3.756, avg. samples / sec: 64899.38
Iteration:   3900, Loss function: 3.187, Average Loss: 3.761, avg. samples / sec: 64998.91
Iteration:   3900, Loss function: 1.796, Average Loss: 3.756, avg. samples / sec: 65020.26
:::MLL 1558651471.835 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558651471.835 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 4.342, Average Loss: 3.763, avg. samples / sec: 65703.41
Iteration:   3920, Loss function: 3.144, Average Loss: 3.745, avg. samples / sec: 65643.36
Iteration:   3920, Loss function: 2.678, Average Loss: 3.759, avg. samples / sec: 65693.24
Iteration:   3920, Loss function: 2.376, Average Loss: 3.745, avg. samples / sec: 65574.70
Iteration:   3920, Loss function: 3.874, Average Loss: 3.745, avg. samples / sec: 65542.86
Iteration:   3920, Loss function: 2.086, Average Loss: 3.754, avg. samples / sec: 65578.51
Iteration:   3920, Loss function: 3.136, Average Loss: 3.787, avg. samples / sec: 65581.62
Iteration:   3920, Loss function: 3.786, Average Loss: 3.755, avg. samples / sec: 65542.86
Iteration:   3920, Loss function: 3.412, Average Loss: 3.742, avg. samples / sec: 65576.34
Iteration:   3920, Loss function: 3.060, Average Loss: 3.744, avg. samples / sec: 65479.88
Iteration:   3920, Loss function: 3.239, Average Loss: 3.777, avg. samples / sec: 65611.27
Iteration:   3920, Loss function: 3.310, Average Loss: 3.782, avg. samples / sec: 65422.52
Iteration:   3920, Loss function: 3.230, Average Loss: 3.752, avg. samples / sec: 65581.72
Iteration:   3920, Loss function: 3.841, Average Loss: 3.762, avg. samples / sec: 65372.54
Iteration:   3920, Loss function: 2.577, Average Loss: 3.744, avg. samples / sec: 65442.45
Iteration:   3920, Loss function: 3.566, Average Loss: 3.759, avg. samples / sec: 65550.42
Iteration:   3920, Loss function: 3.000, Average Loss: 3.761, avg. samples / sec: 65443.54
Iteration:   3920, Loss function: 3.955, Average Loss: 3.746, avg. samples / sec: 65497.26
Iteration:   3920, Loss function: 4.100, Average Loss: 3.762, avg. samples / sec: 65490.17
Iteration:   3920, Loss function: 5.070, Average Loss: 3.754, avg. samples / sec: 65568.63
Iteration:   3920, Loss function: 3.225, Average Loss: 3.750, avg. samples / sec: 65417.72
Iteration:   3920, Loss function: 2.324, Average Loss: 3.734, avg. samples / sec: 65476.08
Iteration:   3920, Loss function: 3.125, Average Loss: 3.751, avg. samples / sec: 65609.84
Iteration:   3920, Loss function: 4.192, Average Loss: 3.798, avg. samples / sec: 65448.53
Iteration:   3920, Loss function: 4.299, Average Loss: 3.774, avg. samples / sec: 65403.97
Iteration:   3920, Loss function: 3.106, Average Loss: 3.767, avg. samples / sec: 65396.38
Iteration:   3920, Loss function: 2.648, Average Loss: 3.759, avg. samples / sec: 65383.58
Iteration:   3920, Loss function: 3.602, Average Loss: 3.749, avg. samples / sec: 65488.67
Iteration:   3920, Loss function: 2.991, Average Loss: 3.772, avg. samples / sec: 65515.10
Iteration:   3920, Loss function: 2.711, Average Loss: 3.761, avg. samples / sec: 65469.48
Iteration:   3940, Loss function: 2.918, Average Loss: 3.755, avg. samples / sec: 65677.59
Iteration:   3940, Loss function: 3.736, Average Loss: 3.751, avg. samples / sec: 65443.27
Iteration:   3940, Loss function: 2.155, Average Loss: 3.742, avg. samples / sec: 65411.07
Iteration:   3940, Loss function: 2.368, Average Loss: 3.772, avg. samples / sec: 65531.98
Iteration:   3940, Loss function: 2.741, Average Loss: 3.732, avg. samples / sec: 65538.90
Iteration:   3940, Loss function: 2.783, Average Loss: 3.742, avg. samples / sec: 65547.03
Iteration:   3940, Loss function: 2.652, Average Loss: 3.766, avg. samples / sec: 65585.90
Iteration:   3940, Loss function: 3.095, Average Loss: 3.750, avg. samples / sec: 65430.51
Iteration:   3940, Loss function: 2.969, Average Loss: 3.735, avg. samples / sec: 65399.57
Iteration:   3940, Loss function: 2.733, Average Loss: 3.745, avg. samples / sec: 65554.05
Iteration:   3940, Loss function: 3.954, Average Loss: 3.726, avg. samples / sec: 65543.28
Iteration:   3940, Loss function: 2.506, Average Loss: 3.756, avg. samples / sec: 65312.91
Iteration:   3940, Loss function: 2.613, Average Loss: 3.765, avg. samples / sec: 65534.11
Iteration:   3940, Loss function: 3.079, Average Loss: 3.742, avg. samples / sec: 65545.42
Iteration:   3940, Loss function: 3.661, Average Loss: 3.737, avg. samples / sec: 65437.71
Iteration:   3940, Loss function: 3.210, Average Loss: 3.768, avg. samples / sec: 65436.74
Iteration:   3940, Loss function: 3.007, Average Loss: 3.746, avg. samples / sec: 65394.26
Iteration:   3940, Loss function: 4.144, Average Loss: 3.757, avg. samples / sec: 65511.14
Iteration:   3940, Loss function: 3.689, Average Loss: 3.745, avg. samples / sec: 65446.95
Iteration:   3940, Loss function: 2.911, Average Loss: 3.791, avg. samples / sec: 65492.08
Iteration:   3940, Loss function: 2.598, Average Loss: 3.738, avg. samples / sec: 65434.12
Iteration:   3940, Loss function: 2.709, Average Loss: 3.736, avg. samples / sec: 65300.90
Iteration:   3940, Loss function: 2.452, Average Loss: 3.779, avg. samples / sec: 65322.18
Iteration:   3940, Loss function: 3.088, Average Loss: 3.735, avg. samples / sec: 65309.25
Iteration:   3940, Loss function: 3.707, Average Loss: 3.743, avg. samples / sec: 65446.92
Iteration:   3940, Loss function: 3.950, Average Loss: 3.756, avg. samples / sec: 65484.32
Iteration:   3940, Loss function: 3.643, Average Loss: 3.752, avg. samples / sec: 65382.64
Iteration:   3940, Loss function: 3.206, Average Loss: 3.749, avg. samples / sec: 65381.06
Iteration:   3940, Loss function: 3.206, Average Loss: 3.756, avg. samples / sec: 65318.91
Iteration:   3940, Loss function: 3.257, Average Loss: 3.751, avg. samples / sec: 65364.20
Iteration:   3960, Loss function: 3.112, Average Loss: 3.733, avg. samples / sec: 65345.83
Iteration:   3960, Loss function: 3.939, Average Loss: 3.779, avg. samples / sec: 65413.84
Iteration:   3960, Loss function: 4.132, Average Loss: 3.750, avg. samples / sec: 65180.12
Iteration:   3960, Loss function: 3.093, Average Loss: 3.723, avg. samples / sec: 65310.34
Iteration:   3960, Loss function: 3.413, Average Loss: 3.718, avg. samples / sec: 65426.41
Iteration:   3960, Loss function: 3.455, Average Loss: 3.761, avg. samples / sec: 65344.44
Iteration:   3960, Loss function: 2.899, Average Loss: 3.742, avg. samples / sec: 65444.91
Iteration:   3960, Loss function: 3.277, Average Loss: 3.755, avg. samples / sec: 65277.58
Iteration:   3960, Loss function: 2.677, Average Loss: 3.745, avg. samples / sec: 65279.79
Iteration:   3960, Loss function: 3.082, Average Loss: 3.743, avg. samples / sec: 65435.25
Iteration:   3960, Loss function: 2.907, Average Loss: 3.737, avg. samples / sec: 65265.31
Iteration:   3960, Loss function: 3.681, Average Loss: 3.769, avg. samples / sec: 65358.14
Iteration:   3960, Loss function: 3.257, Average Loss: 3.738, avg. samples / sec: 65456.37
Iteration:   3960, Loss function: 3.108, Average Loss: 3.727, avg. samples / sec: 65260.71
Iteration:   3960, Loss function: 2.865, Average Loss: 3.734, avg. samples / sec: 65293.82
Iteration:   3960, Loss function: 2.741, Average Loss: 3.743, avg. samples / sec: 65181.33
Iteration:   3960, Loss function: 4.464, Average Loss: 3.735, avg. samples / sec: 65316.70
Iteration:   3960, Loss function: 4.105, Average Loss: 3.727, avg. samples / sec: 65248.81
Iteration:   3960, Loss function: 4.389, Average Loss: 3.720, avg. samples / sec: 65235.70
Iteration:   3960, Loss function: 3.951, Average Loss: 3.735, avg. samples / sec: 65182.14
Iteration:   3960, Loss function: 3.697, Average Loss: 3.763, avg. samples / sec: 65195.11
Iteration:   3960, Loss function: 3.626, Average Loss: 3.747, avg. samples / sec: 65184.64
Iteration:   3960, Loss function: 2.502, Average Loss: 3.735, avg. samples / sec: 65241.16
Iteration:   3960, Loss function: 2.896, Average Loss: 3.749, avg. samples / sec: 65251.56
Iteration:   3960, Loss function: 4.524, Average Loss: 3.745, avg. samples / sec: 65181.78
Iteration:   3960, Loss function: 3.359, Average Loss: 3.766, avg. samples / sec: 65089.90
Iteration:   3960, Loss function: 4.832, Average Loss: 3.748, avg. samples / sec: 65303.11
Iteration:   3960, Loss function: 3.078, Average Loss: 3.751, avg. samples / sec: 65156.68
Iteration:   3960, Loss function: 2.716, Average Loss: 3.741, avg. samples / sec: 65144.66
Iteration:   3960, Loss function: 3.253, Average Loss: 3.729, avg. samples / sec: 65163.85
:::MLL 1558651473.637 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558651473.637 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.668, Average Loss: 3.711, avg. samples / sec: 64949.12
Iteration:   3980, Loss function: 4.152, Average Loss: 3.731, avg. samples / sec: 64927.04
Iteration:   3980, Loss function: 4.008, Average Loss: 3.765, avg. samples / sec: 64886.53
Iteration:   3980, Loss function: 3.610, Average Loss: 3.738, avg. samples / sec: 64872.49
Iteration:   3980, Loss function: 4.024, Average Loss: 3.731, avg. samples / sec: 65052.46
Iteration:   3980, Loss function: 3.148, Average Loss: 3.718, avg. samples / sec: 64891.04
Iteration:   3980, Loss function: 4.097, Average Loss: 3.747, avg. samples / sec: 64839.06
Iteration:   3980, Loss function: 4.175, Average Loss: 3.730, avg. samples / sec: 64872.97
Iteration:   3980, Loss function: 3.627, Average Loss: 3.760, avg. samples / sec: 64994.50
Iteration:   3980, Loss function: 3.404, Average Loss: 3.740, avg. samples / sec: 64948.25
Iteration:   3980, Loss function: 3.627, Average Loss: 3.751, avg. samples / sec: 64807.73
Iteration:   3980, Loss function: 3.232, Average Loss: 3.726, avg. samples / sec: 65022.06
Iteration:   3980, Loss function: 4.178, Average Loss: 3.720, avg. samples / sec: 64771.98
Iteration:   3980, Loss function: 2.829, Average Loss: 3.739, avg. samples / sec: 64767.43
Iteration:   3980, Loss function: 4.002, Average Loss: 3.733, avg. samples / sec: 64911.85
Iteration:   3980, Loss function: 2.730, Average Loss: 3.718, avg. samples / sec: 64848.10
Iteration:   3980, Loss function: 3.734, Average Loss: 3.733, avg. samples / sec: 64809.22
Iteration:   3980, Loss function: 3.513, Average Loss: 3.721, avg. samples / sec: 64686.36
Iteration:   3980, Loss function: 3.502, Average Loss: 3.769, avg. samples / sec: 64708.55
Iteration:   3980, Loss function: 2.564, Average Loss: 3.716, avg. samples / sec: 64809.60
Iteration:   3980, Loss function: 3.386, Average Loss: 3.740, avg. samples / sec: 64931.49
Iteration:   3980, Loss function: 2.432, Average Loss: 3.740, avg. samples / sec: 64910.50
Iteration:   3980, Loss function: 3.888, Average Loss: 3.742, avg. samples / sec: 64901.62
Iteration:   3980, Loss function: 2.872, Average Loss: 3.756, avg. samples / sec: 64836.83
Iteration:   3980, Loss function: 4.399, Average Loss: 3.736, avg. samples / sec: 64720.82
Iteration:   3980, Loss function: 3.999, Average Loss: 3.736, avg. samples / sec: 64736.22
Iteration:   3980, Loss function: 3.209, Average Loss: 3.727, avg. samples / sec: 64756.30
Iteration:   3980, Loss function: 3.208, Average Loss: 3.727, avg. samples / sec: 64833.73
Iteration:   3980, Loss function: 3.978, Average Loss: 3.748, avg. samples / sec: 64867.27
Iteration:   3980, Loss function: 2.831, Average Loss: 3.731, avg. samples / sec: 64621.08
Iteration:   4000, Loss function: 3.601, Average Loss: 3.732, avg. samples / sec: 66146.81
Iteration:   4000, Loss function: 4.492, Average Loss: 3.742, avg. samples / sec: 66270.04
Iteration:   4000, Loss function: 3.401, Average Loss: 3.711, avg. samples / sec: 66187.32
Iteration:   4000, Loss function: 3.541, Average Loss: 3.756, avg. samples / sec: 66066.96
Iteration:   4000, Loss function: 2.565, Average Loss: 3.735, avg. samples / sec: 66059.43
Iteration:   4000, Loss function: 2.301, Average Loss: 3.752, avg. samples / sec: 66160.07
Iteration:   4000, Loss function: 3.593, Average Loss: 3.710, avg. samples / sec: 65906.26
Iteration:   4000, Loss function: 2.261, Average Loss: 3.709, avg. samples / sec: 66003.80
Iteration:   4000, Loss function: 3.665, Average Loss: 3.714, avg. samples / sec: 66030.77
Iteration:   4000, Loss function: 3.826, Average Loss: 3.727, avg. samples / sec: 66073.80
Iteration:   4000, Loss function: 3.442, Average Loss: 3.730, avg. samples / sec: 66045.25
Iteration:   4000, Loss function: 3.593, Average Loss: 3.744, avg. samples / sec: 66021.71
Iteration:   4000, Loss function: 2.929, Average Loss: 3.710, avg. samples / sec: 66046.43
Iteration:   4000, Loss function: 3.886, Average Loss: 3.762, avg. samples / sec: 66060.52
Iteration:   4000, Loss function: 3.245, Average Loss: 3.718, avg. samples / sec: 66112.92
Iteration:   4000, Loss function: 4.319, Average Loss: 3.723, avg. samples / sec: 65918.50
Iteration:   4000, Loss function: 2.753, Average Loss: 3.737, avg. samples / sec: 65943.61
Iteration:   4000, Loss function: 3.808, Average Loss: 3.719, avg. samples / sec: 65934.32
Iteration:   4000, Loss function: 3.074, Average Loss: 3.712, avg. samples / sec: 65957.84
Iteration:   4000, Loss function: 3.293, Average Loss: 3.715, avg. samples / sec: 65999.72
Iteration:   4000, Loss function: 3.633, Average Loss: 3.754, avg. samples / sec: 65948.95
Iteration:   4000, Loss function: 3.981, Average Loss: 3.732, avg. samples / sec: 66043.02
Iteration:   4000, Loss function: 2.578, Average Loss: 3.719, avg. samples / sec: 66123.22
Iteration:   4000, Loss function: 2.710, Average Loss: 3.734, avg. samples / sec: 66033.55
Iteration:   4000, Loss function: 3.049, Average Loss: 3.726, avg. samples / sec: 66063.21
Iteration:   4000, Loss function: 3.632, Average Loss: 3.719, avg. samples / sec: 66057.88
Iteration:   4000, Loss function: 2.728, Average Loss: 3.728, avg. samples / sec: 65941.94
Iteration:   4000, Loss function: 3.319, Average Loss: 3.730, avg. samples / sec: 65831.94
Iteration:   4000, Loss function: 4.252, Average Loss: 3.738, avg. samples / sec: 65965.43
Iteration:   4000, Loss function: 3.692, Average Loss: 3.732, avg. samples / sec: 65960.95
Iteration:   4020, Loss function: 3.267, Average Loss: 3.747, avg. samples / sec: 65836.83
Iteration:   4020, Loss function: 4.260, Average Loss: 3.697, avg. samples / sec: 65740.61
Iteration:   4020, Loss function: 3.940, Average Loss: 3.727, avg. samples / sec: 65727.92
Iteration:   4020, Loss function: 3.322, Average Loss: 3.734, avg. samples / sec: 65685.03
Iteration:   4020, Loss function: 3.977, Average Loss: 3.726, avg. samples / sec: 65753.40
Iteration:   4020, Loss function: 3.023, Average Loss: 3.706, avg. samples / sec: 65736.44
Iteration:   4020, Loss function: 3.110, Average Loss: 3.737, avg. samples / sec: 65747.36
Iteration:   4020, Loss function: 3.174, Average Loss: 3.719, avg. samples / sec: 65719.89
Iteration:   4020, Loss function: 3.239, Average Loss: 3.732, avg. samples / sec: 65868.68
Iteration:   4020, Loss function: 3.381, Average Loss: 3.704, avg. samples / sec: 65728.32
Iteration:   4020, Loss function: 3.283, Average Loss: 3.721, avg. samples / sec: 65809.93
Iteration:   4020, Loss function: 2.603, Average Loss: 3.755, avg. samples / sec: 65733.71
Iteration:   4020, Loss function: 3.367, Average Loss: 3.724, avg. samples / sec: 65789.56
Iteration:   4020, Loss function: 3.360, Average Loss: 3.712, avg. samples / sec: 65747.91
Iteration:   4020, Loss function: 3.247, Average Loss: 3.708, avg. samples / sec: 65768.96
Iteration:   4020, Loss function: 2.851, Average Loss: 3.720, avg. samples / sec: 65536.37
Iteration:   4020, Loss function: 2.962, Average Loss: 3.713, avg. samples / sec: 65790.45
Iteration:   4020, Loss function: 2.849, Average Loss: 3.709, avg. samples / sec: 65693.94
Iteration:   4020, Loss function: 3.991, Average Loss: 3.725, avg. samples / sec: 65811.44
Iteration:   4020, Loss function: 3.023, Average Loss: 3.711, avg. samples / sec: 65731.69
Iteration:   4020, Loss function: 4.156, Average Loss: 3.710, avg. samples / sec: 65747.27
Iteration:   4020, Loss function: 2.316, Average Loss: 3.744, avg. samples / sec: 65585.59
Iteration:   4020, Loss function: 3.253, Average Loss: 3.737, avg. samples / sec: 65703.80
Iteration:   4020, Loss function: 4.089, Average Loss: 3.719, avg. samples / sec: 65693.36
Iteration:   4020, Loss function: 3.941, Average Loss: 3.703, avg. samples / sec: 65539.75
Iteration:   4020, Loss function: 3.573, Average Loss: 3.725, avg. samples / sec: 65750.95
Iteration:   4020, Loss function: 3.389, Average Loss: 3.720, avg. samples / sec: 65726.11
Iteration:   4020, Loss function: 4.220, Average Loss: 3.745, avg. samples / sec: 65692.29
Iteration:   4020, Loss function: 3.646, Average Loss: 3.725, avg. samples / sec: 65695.32
Iteration:   4020, Loss function: 2.588, Average Loss: 3.714, avg. samples / sec: 65696.33
Iteration:   4040, Loss function: 2.559, Average Loss: 3.696, avg. samples / sec: 66065.81
Iteration:   4040, Loss function: 2.584, Average Loss: 3.715, avg. samples / sec: 66039.53
Iteration:   4040, Loss function: 2.762, Average Loss: 3.708, avg. samples / sec: 66010.42
Iteration:   4040, Loss function: 3.449, Average Loss: 3.690, avg. samples / sec: 65953.89
Iteration:   4040, Loss function: 2.802, Average Loss: 3.738, avg. samples / sec: 65856.46
Iteration:   4040, Loss function: 2.636, Average Loss: 3.697, avg. samples / sec: 65959.44
Iteration:   4040, Loss function: 3.399, Average Loss: 3.716, avg. samples / sec: 66065.53
Iteration:   4040, Loss function: 3.484, Average Loss: 3.704, avg. samples / sec: 65980.72
Iteration:   4040, Loss function: 3.374, Average Loss: 3.696, avg. samples / sec: 66048.60
Iteration:   4040, Loss function: 3.120, Average Loss: 3.722, avg. samples / sec: 65900.07
Iteration:   4040, Loss function: 4.123, Average Loss: 3.732, avg. samples / sec: 65995.03
Iteration:   4040, Loss function: 3.151, Average Loss: 3.704, avg. samples / sec: 65974.51
Iteration:   4040, Loss function: 3.557, Average Loss: 3.723, avg. samples / sec: 65871.21
Iteration:   4040, Loss function: 3.338, Average Loss: 3.714, avg. samples / sec: 65916.22
Iteration:   4040, Loss function: 3.799, Average Loss: 3.701, avg. samples / sec: 65908.27
Iteration:   4040, Loss function: 4.652, Average Loss: 3.704, avg. samples / sec: 65934.23
Iteration:   4040, Loss function: 2.229, Average Loss: 3.709, avg. samples / sec: 65978.68
Iteration:   4040, Loss function: 3.868, Average Loss: 3.744, avg. samples / sec: 65906.11
Iteration:   4040, Loss function: 3.105, Average Loss: 3.700, avg. samples / sec: 65907.68
Iteration:   4040, Loss function: 3.475, Average Loss: 3.726, avg. samples / sec: 65804.37
Iteration:   4040, Loss function: 3.496, Average Loss: 3.729, avg. samples / sec: 65833.17
Iteration:   4040, Loss function: 2.959, Average Loss: 3.738, avg. samples / sec: 65884.26
Iteration:   4040, Loss function: 4.305, Average Loss: 3.739, avg. samples / sec: 65959.20
Iteration:   4040, Loss function: 3.124, Average Loss: 3.711, avg. samples / sec: 65911.84
Iteration:   4040, Loss function: 3.447, Average Loss: 3.710, avg. samples / sec: 65816.29
Iteration:   4040, Loss function: 3.705, Average Loss: 3.718, avg. samples / sec: 65870.56
Iteration:   4040, Loss function: 3.312, Average Loss: 3.715, avg. samples / sec: 65911.56
Iteration:   4040, Loss function: 3.069, Average Loss: 3.723, avg. samples / sec: 65771.08
Iteration:   4040, Loss function: 3.529, Average Loss: 3.706, avg. samples / sec: 65783.27
Iteration:   4040, Loss function: 4.484, Average Loss: 3.709, avg. samples / sec: 65847.23
:::MLL 1558651475.424 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558651475.425 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 2.036, Average Loss: 3.717, avg. samples / sec: 65707.42
Iteration:   4060, Loss function: 2.678, Average Loss: 3.681, avg. samples / sec: 65509.28
Iteration:   4060, Loss function: 3.144, Average Loss: 3.697, avg. samples / sec: 65553.10
Iteration:   4060, Loss function: 3.423, Average Loss: 3.729, avg. samples / sec: 65505.42
Iteration:   4060, Loss function: 3.163, Average Loss: 3.715, avg. samples / sec: 65526.68
Iteration:   4060, Loss function: 3.701, Average Loss: 3.719, avg. samples / sec: 65683.84
Iteration:   4060, Loss function: 2.489, Average Loss: 3.734, avg. samples / sec: 65616.98
Iteration:   4060, Loss function: 3.116, Average Loss: 3.696, avg. samples / sec: 65526.71
Iteration:   4060, Loss function: 3.389, Average Loss: 3.718, avg. samples / sec: 65588.55
Iteration:   4060, Loss function: 3.729, Average Loss: 3.693, avg. samples / sec: 65565.09
Iteration:   4060, Loss function: 3.796, Average Loss: 3.707, avg. samples / sec: 65626.00
Iteration:   4060, Loss function: 3.635, Average Loss: 3.702, avg. samples / sec: 65435.49
Iteration:   4060, Loss function: 2.820, Average Loss: 3.711, avg. samples / sec: 65597.47
Iteration:   4060, Loss function: 3.802, Average Loss: 3.714, avg. samples / sec: 65424.62
Iteration:   4060, Loss function: 3.916, Average Loss: 3.726, avg. samples / sec: 65475.62
Iteration:   4060, Loss function: 3.219, Average Loss: 3.721, avg. samples / sec: 65538.19
Iteration:   4060, Loss function: 2.466, Average Loss: 3.686, avg. samples / sec: 65401.81
Iteration:   4060, Loss function: 3.681, Average Loss: 3.696, avg. samples / sec: 65480.25
Iteration:   4060, Loss function: 2.803, Average Loss: 3.699, avg. samples / sec: 65561.82
Iteration:   4060, Loss function: 2.134, Average Loss: 3.738, avg. samples / sec: 65502.46
Iteration:   4060, Loss function: 3.007, Average Loss: 3.692, avg. samples / sec: 65322.12
Iteration:   4060, Loss function: 2.462, Average Loss: 3.688, avg. samples / sec: 65413.47
Iteration:   4060, Loss function: 2.972, Average Loss: 3.705, avg. samples / sec: 65453.48
Iteration:   4060, Loss function: 3.079, Average Loss: 3.706, avg. samples / sec: 65627.83
Iteration:   4060, Loss function: 3.447, Average Loss: 3.703, avg. samples / sec: 65453.42
Iteration:   4060, Loss function: 4.328, Average Loss: 3.710, avg. samples / sec: 65303.65
Iteration:   4060, Loss function: 3.720, Average Loss: 3.703, avg. samples / sec: 65543.16
Iteration:   4060, Loss function: 3.073, Average Loss: 3.704, avg. samples / sec: 65464.40
Iteration:   4060, Loss function: 4.029, Average Loss: 3.733, avg. samples / sec: 65446.74
Iteration:   4060, Loss function: 2.880, Average Loss: 3.692, avg. samples / sec: 65377.72
Iteration:   4080, Loss function: 4.330, Average Loss: 3.677, avg. samples / sec: 66002.91
Iteration:   4080, Loss function: 3.501, Average Loss: 3.728, avg. samples / sec: 66210.08
Iteration:   4080, Loss function: 2.911, Average Loss: 3.687, avg. samples / sec: 66041.14
Iteration:   4080, Loss function: 3.759, Average Loss: 3.722, avg. samples / sec: 65969.35
Iteration:   4080, Loss function: 3.294, Average Loss: 3.691, avg. samples / sec: 66010.33
Iteration:   4080, Loss function: 3.430, Average Loss: 3.720, avg. samples / sec: 65989.68
Iteration:   4080, Loss function: 2.395, Average Loss: 3.735, avg. samples / sec: 66052.00
Iteration:   4080, Loss function: 2.345, Average Loss: 3.689, avg. samples / sec: 66035.91
Iteration:   4080, Loss function: 2.322, Average Loss: 3.692, avg. samples / sec: 66004.33
Iteration:   4080, Loss function: 3.035, Average Loss: 3.706, avg. samples / sec: 65791.93
Iteration:   4080, Loss function: 4.092, Average Loss: 3.701, avg. samples / sec: 65973.80
Iteration:   4080, Loss function: 4.429, Average Loss: 3.680, avg. samples / sec: 66011.59
Iteration:   4080, Loss function: 1.652, Average Loss: 3.686, avg. samples / sec: 66128.87
Iteration:   4080, Loss function: 3.051, Average Loss: 3.710, avg. samples / sec: 65957.78
Iteration:   4080, Loss function: 2.908, Average Loss: 3.705, avg. samples / sec: 65923.62
Iteration:   4080, Loss function: 4.085, Average Loss: 3.692, avg. samples / sec: 65870.53
Iteration:   4080, Loss function: 3.439, Average Loss: 3.687, avg. samples / sec: 65998.08
Iteration:   4080, Loss function: 3.209, Average Loss: 3.675, avg. samples / sec: 66015.09
Iteration:   4080, Loss function: 3.308, Average Loss: 3.719, avg. samples / sec: 65973.83
Iteration:   4080, Loss function: 2.337, Average Loss: 3.700, avg. samples / sec: 66062.87
Iteration:   4080, Loss function: 2.623, Average Loss: 3.707, avg. samples / sec: 65952.25
Iteration:   4080, Loss function: 4.391, Average Loss: 3.693, avg. samples / sec: 65945.34
Iteration:   4080, Loss function: 4.026, Average Loss: 3.694, avg. samples / sec: 66010.88
Iteration:   4080, Loss function: 3.168, Average Loss: 3.696, avg. samples / sec: 65962.00
Iteration:   4080, Loss function: 4.386, Average Loss: 3.704, avg. samples / sec: 65895.23
Iteration:   4080, Loss function: 3.825, Average Loss: 3.711, avg. samples / sec: 65826.29
Iteration:   4080, Loss function: 2.894, Average Loss: 3.711, avg. samples / sec: 65876.32
Iteration:   4080, Loss function: 3.382, Average Loss: 3.698, avg. samples / sec: 65920.38
Iteration:   4080, Loss function: 3.722, Average Loss: 3.694, avg. samples / sec: 65861.33
Iteration:   4080, Loss function: 3.666, Average Loss: 3.698, avg. samples / sec: 65873.33
Iteration:   4100, Loss function: 3.223, Average Loss: 3.678, avg. samples / sec: 65818.17
Iteration:   4100, Loss function: 2.978, Average Loss: 3.695, avg. samples / sec: 65901.05
Iteration:   4100, Loss function: 3.957, Average Loss: 3.685, avg. samples / sec: 65866.80
Iteration:   4100, Loss function: 3.171, Average Loss: 3.691, avg. samples / sec: 65942.59
Iteration:   4100, Loss function: 3.965, Average Loss: 3.688, avg. samples / sec: 65866.77
Iteration:   4100, Loss function: 3.740, Average Loss: 3.711, avg. samples / sec: 65783.51
Iteration:   4100, Loss function: 3.562, Average Loss: 3.681, avg. samples / sec: 65787.72
Iteration:   4100, Loss function: 4.083, Average Loss: 3.691, avg. samples / sec: 66020.81
Iteration:   4100, Loss function: 2.732, Average Loss: 3.720, avg. samples / sec: 65750.28
Iteration:   4100, Loss function: 3.137, Average Loss: 3.698, avg. samples / sec: 65846.09
Iteration:   4100, Loss function: 3.025, Average Loss: 3.704, avg. samples / sec: 65929.26
Iteration:   4100, Loss function: 3.668, Average Loss: 3.683, avg. samples / sec: 65868.00
Iteration:   4100, Loss function: 3.851, Average Loss: 3.704, avg. samples / sec: 65784.25
Iteration:   4100, Loss function: 2.396, Average Loss: 3.678, avg. samples / sec: 65776.73
Iteration:   4100, Loss function: 3.181, Average Loss: 3.666, avg. samples / sec: 65789.41
Iteration:   4100, Loss function: 3.307, Average Loss: 3.675, avg. samples / sec: 65773.57
Iteration:   4100, Loss function: 3.814, Average Loss: 3.699, avg. samples / sec: 65852.06
Iteration:   4100, Loss function: 2.594, Average Loss: 3.681, avg. samples / sec: 65734.02
Iteration:   4100, Loss function: 2.953, Average Loss: 3.676, avg. samples / sec: 65684.82
Iteration:   4100, Loss function: 3.418, Average Loss: 3.705, avg. samples / sec: 65877.33
Iteration:   4100, Loss function: 2.925, Average Loss: 3.711, avg. samples / sec: 65775.35
Iteration:   4100, Loss function: 3.700, Average Loss: 3.714, avg. samples / sec: 65669.05
Iteration:   4100, Loss function: 2.698, Average Loss: 3.681, avg. samples / sec: 65733.68
Iteration:   4100, Loss function: 3.439, Average Loss: 3.695, avg. samples / sec: 65711.92
Iteration:   4100, Loss function: 3.265, Average Loss: 3.694, avg. samples / sec: 65853.35
Iteration:   4100, Loss function: 3.186, Average Loss: 3.732, avg. samples / sec: 65628.38
Iteration:   4100, Loss function: 3.806, Average Loss: 3.693, avg. samples / sec: 65699.73
Iteration:   4100, Loss function: 3.028, Average Loss: 3.685, avg. samples / sec: 65740.68
Iteration:   4100, Loss function: 4.249, Average Loss: 3.696, avg. samples / sec: 65637.58
Iteration:   4100, Loss function: 3.053, Average Loss: 3.694, avg. samples / sec: 65786.71
:::MLL 1558651477.212 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558651477.213 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 2.319, Average Loss: 3.694, avg. samples / sec: 65769.27
Iteration:   4120, Loss function: 2.772, Average Loss: 3.682, avg. samples / sec: 65639.75
Iteration:   4120, Loss function: 3.792, Average Loss: 3.673, avg. samples / sec: 65670.89
Iteration:   4120, Loss function: 3.369, Average Loss: 3.689, avg. samples / sec: 65732.40
Iteration:   4120, Loss function: 4.406, Average Loss: 3.691, avg. samples / sec: 65514.16
Iteration:   4120, Loss function: 3.966, Average Loss: 3.673, avg. samples / sec: 65491.08
Iteration:   4120, Loss function: 3.174, Average Loss: 3.679, avg. samples / sec: 65508.77
Iteration:   4120, Loss function: 3.742, Average Loss: 3.706, avg. samples / sec: 65526.92
Iteration:   4120, Loss function: 2.436, Average Loss: 3.662, avg. samples / sec: 65615.98
Iteration:   4120, Loss function: 2.460, Average Loss: 3.697, avg. samples / sec: 65618.05
Iteration:   4120, Loss function: 3.263, Average Loss: 3.684, avg. samples / sec: 65525.12
Iteration:   4120, Loss function: 3.282, Average Loss: 3.670, avg. samples / sec: 65613.26
Iteration:   4120, Loss function: 2.998, Average Loss: 3.672, avg. samples / sec: 65429.02
Iteration:   4120, Loss function: 3.207, Average Loss: 3.690, avg. samples / sec: 65553.04
Iteration:   4120, Loss function: 3.500, Average Loss: 3.693, avg. samples / sec: 65734.97
Iteration:   4120, Loss function: 5.609, Average Loss: 3.678, avg. samples / sec: 65704.60
Iteration:   4120, Loss function: 3.363, Average Loss: 3.692, avg. samples / sec: 65608.09
Iteration:   4120, Loss function: 2.762, Average Loss: 3.729, avg. samples / sec: 65705.21
Iteration:   4120, Loss function: 3.864, Average Loss: 3.705, avg. samples / sec: 65610.11
Iteration:   4120, Loss function: 2.538, Average Loss: 3.672, avg. samples / sec: 65572.44
Iteration:   4120, Loss function: 3.530, Average Loss: 3.676, avg. samples / sec: 65651.83
Iteration:   4120, Loss function: 3.794, Average Loss: 3.676, avg. samples / sec: 65607.45
Iteration:   4120, Loss function: 3.472, Average Loss: 3.679, avg. samples / sec: 65559.29
Iteration:   4120, Loss function: 3.631, Average Loss: 3.699, avg. samples / sec: 65554.50
Iteration:   4120, Loss function: 3.312, Average Loss: 3.693, avg. samples / sec: 65678.27
Iteration:   4120, Loss function: 3.989, Average Loss: 3.715, avg. samples / sec: 65483.26
Iteration:   4120, Loss function: 3.568, Average Loss: 3.688, avg. samples / sec: 65619.46
Iteration:   4120, Loss function: 4.770, Average Loss: 3.695, avg. samples / sec: 65604.46
Iteration:   4120, Loss function: 3.406, Average Loss: 3.709, avg. samples / sec: 65563.41
Iteration:   4120, Loss function: 3.313, Average Loss: 3.670, avg. samples / sec: 65412.44
Iteration:   4140, Loss function: 2.456, Average Loss: 3.669, avg. samples / sec: 66205.16
Iteration:   4140, Loss function: 2.924, Average Loss: 3.675, avg. samples / sec: 66165.10
Iteration:   4140, Loss function: 3.779, Average Loss: 3.670, avg. samples / sec: 66149.82
Iteration:   4140, Loss function: 4.118, Average Loss: 3.680, avg. samples / sec: 66140.41
Iteration:   4140, Loss function: 3.192, Average Loss: 3.675, avg. samples / sec: 65998.76
Iteration:   4140, Loss function: 2.585, Average Loss: 3.672, avg. samples / sec: 66104.27
Iteration:   4140, Loss function: 3.940, Average Loss: 3.685, avg. samples / sec: 66217.61
Iteration:   4140, Loss function: 4.121, Average Loss: 3.669, avg. samples / sec: 66226.35
Iteration:   4140, Loss function: 3.365, Average Loss: 3.700, avg. samples / sec: 66095.31
Iteration:   4140, Loss function: 3.166, Average Loss: 3.662, avg. samples / sec: 66103.03
Iteration:   4140, Loss function: 3.540, Average Loss: 3.690, avg. samples / sec: 66140.01
Iteration:   4140, Loss function: 4.256, Average Loss: 3.668, avg. samples / sec: 66099.77
Iteration:   4140, Loss function: 2.524, Average Loss: 3.717, avg. samples / sec: 66093.63
Iteration:   4140, Loss function: 2.653, Average Loss: 3.684, avg. samples / sec: 66076.81
Iteration:   4140, Loss function: 5.393, Average Loss: 3.691, avg. samples / sec: 65867.70
Iteration:   4140, Loss function: 3.320, Average Loss: 3.702, avg. samples / sec: 66171.28
Iteration:   4140, Loss function: 3.609, Average Loss: 3.677, avg. samples / sec: 65995.49
Iteration:   4140, Loss function: 2.820, Average Loss: 3.664, avg. samples / sec: 65991.93
Iteration:   4140, Loss function: 1.998, Average Loss: 3.669, avg. samples / sec: 66076.99
Iteration:   4140, Loss function: 3.389, Average Loss: 3.707, avg. samples / sec: 66115.15
Iteration:   4140, Loss function: 4.173, Average Loss: 3.697, avg. samples / sec: 66067.70
Iteration:   4140, Loss function: 3.851, Average Loss: 3.693, avg. samples / sec: 66026.93
Iteration:   4140, Loss function: 2.786, Average Loss: 3.688, avg. samples / sec: 66131.66
Iteration:   4140, Loss function: 3.957, Average Loss: 3.665, avg. samples / sec: 66030.52
Iteration:   4140, Loss function: 3.947, Average Loss: 3.666, avg. samples / sec: 66034.42
Iteration:   4140, Loss function: 4.224, Average Loss: 3.686, avg. samples / sec: 66061.82
Iteration:   4140, Loss function: 3.523, Average Loss: 3.687, avg. samples / sec: 65938.98
Iteration:   4140, Loss function: 3.004, Average Loss: 3.650, avg. samples / sec: 65935.74
Iteration:   4140, Loss function: 2.621, Average Loss: 3.682, avg. samples / sec: 65890.09
Iteration:   4140, Loss function: 2.756, Average Loss: 3.667, avg. samples / sec: 65884.66
Iteration:   4160, Loss function: 3.849, Average Loss: 3.680, avg. samples / sec: 66174.64
Iteration:   4160, Loss function: 3.941, Average Loss: 3.680, avg. samples / sec: 66080.15
Iteration:   4160, Loss function: 3.189, Average Loss: 3.658, avg. samples / sec: 66046.68
Iteration:   4160, Loss function: 3.277, Average Loss: 3.664, avg. samples / sec: 65997.03
Iteration:   4160, Loss function: 2.779, Average Loss: 3.660, avg. samples / sec: 65958.24
Iteration:   4160, Loss function: 3.921, Average Loss: 3.693, avg. samples / sec: 66025.79
Iteration:   4160, Loss function: 3.388, Average Loss: 3.686, avg. samples / sec: 66025.42
Iteration:   4160, Loss function: 2.818, Average Loss: 3.673, avg. samples / sec: 65955.09
Iteration:   4160, Loss function: 3.279, Average Loss: 3.673, avg. samples / sec: 66215.93
Iteration:   4160, Loss function: 3.529, Average Loss: 3.699, avg. samples / sec: 66033.59
Iteration:   4160, Loss function: 3.092, Average Loss: 3.656, avg. samples / sec: 65979.58
Iteration:   4160, Loss function: 3.892, Average Loss: 3.660, avg. samples / sec: 66072.25
Iteration:   4160, Loss function: 4.645, Average Loss: 3.665, avg. samples / sec: 65940.49
Iteration:   4160, Loss function: 2.215, Average Loss: 3.682, avg. samples / sec: 65957.13
Iteration:   4160, Loss function: 3.506, Average Loss: 3.709, avg. samples / sec: 65965.43
Iteration:   4160, Loss function: 3.463, Average Loss: 3.647, avg. samples / sec: 66089.20
Iteration:   4160, Loss function: 2.829, Average Loss: 3.661, avg. samples / sec: 65977.82
Iteration:   4160, Loss function: 4.397, Average Loss: 3.674, avg. samples / sec: 65916.22
Iteration:   4160, Loss function: 4.244, Average Loss: 3.671, avg. samples / sec: 65948.15
Iteration:   4160, Loss function: 2.916, Average Loss: 3.685, avg. samples / sec: 65954.66
Iteration:   4160, Loss function: 3.774, Average Loss: 3.665, avg. samples / sec: 66002.97
Iteration:   4160, Loss function: 2.027, Average Loss: 3.685, avg. samples / sec: 66001.73
Iteration:   4160, Loss function: 3.408, Average Loss: 3.662, avg. samples / sec: 65939.07
Iteration:   4160, Loss function: 3.195, Average Loss: 3.689, avg. samples / sec: 65949.60
Iteration:   4160, Loss function: 4.146, Average Loss: 3.665, avg. samples / sec: 65821.43
Iteration:   4160, Loss function: 3.589, Average Loss: 3.665, avg. samples / sec: 65882.38
Iteration:   4160, Loss function: 3.022, Average Loss: 3.663, avg. samples / sec: 66109.63
Iteration:   4160, Loss function: 3.660, Average Loss: 3.682, avg. samples / sec: 65905.95
Iteration:   4160, Loss function: 3.116, Average Loss: 3.691, avg. samples / sec: 65831.79
Iteration:   4160, Loss function: 3.379, Average Loss: 3.664, avg. samples / sec: 65713.70
Iteration:   4180, Loss function: 3.348, Average Loss: 3.707, avg. samples / sec: 66264.43
Iteration:   4180, Loss function: 2.415, Average Loss: 3.657, avg. samples / sec: 66317.69
Iteration:   4180, Loss function: 2.665, Average Loss: 3.689, avg. samples / sec: 66224.33
Iteration:   4180, Loss function: 3.784, Average Loss: 3.655, avg. samples / sec: 66357.54
Iteration:   4180, Loss function: 2.755, Average Loss: 3.670, avg. samples / sec: 66180.04
Iteration:   4180, Loss function: 2.570, Average Loss: 3.668, avg. samples / sec: 66177.49
Iteration:   4180, Loss function: 3.756, Average Loss: 3.658, avg. samples / sec: 66133.37
Iteration:   4180, Loss function: 2.923, Average Loss: 3.648, avg. samples / sec: 66184.30
Iteration:   4180, Loss function: 3.557, Average Loss: 3.654, avg. samples / sec: 66138.73
Iteration:   4180, Loss function: 2.551, Average Loss: 3.671, avg. samples / sec: 66307.96
Iteration:   4180, Loss function: 4.100, Average Loss: 3.675, avg. samples / sec: 66135.20
Iteration:   4180, Loss function: 4.138, Average Loss: 3.683, avg. samples / sec: 66290.99
Iteration:   4180, Loss function: 3.770, Average Loss: 3.665, avg. samples / sec: 66213.53
Iteration:   4180, Loss function: 3.728, Average Loss: 3.679, avg. samples / sec: 66166.22
Iteration:   4180, Loss function: 3.497, Average Loss: 3.678, avg. samples / sec: 66048.75
Iteration:   4180, Loss function: 3.684, Average Loss: 3.662, avg. samples / sec: 66205.57
Iteration:   4180, Loss function: 3.439, Average Loss: 3.675, avg. samples / sec: 66042.28
Iteration:   4180, Loss function: 2.696, Average Loss: 3.658, avg. samples / sec: 66120.55
Iteration:   4180, Loss function: 3.016, Average Loss: 3.689, avg. samples / sec: 66197.33
Iteration:   4180, Loss function: 3.642, Average Loss: 3.660, avg. samples / sec: 66205.04
Iteration:   4180, Loss function: 3.584, Average Loss: 3.685, avg. samples / sec: 66076.25
Iteration:   4180, Loss function: 4.611, Average Loss: 3.682, avg. samples / sec: 66162.24
Iteration:   4180, Loss function: 3.836, Average Loss: 3.678, avg. samples / sec: 66157.39
Iteration:   4180, Loss function: 3.700, Average Loss: 3.656, avg. samples / sec: 66113.57
Iteration:   4180, Loss function: 4.368, Average Loss: 3.667, avg. samples / sec: 66121.11
Iteration:   4180, Loss function: 3.332, Average Loss: 3.653, avg. samples / sec: 66058.41
Iteration:   4180, Loss function: 4.024, Average Loss: 3.653, avg. samples / sec: 65988.41
Iteration:   4180, Loss function: 4.254, Average Loss: 3.635, avg. samples / sec: 66067.48
Iteration:   4180, Loss function: 3.281, Average Loss: 3.659, avg. samples / sec: 66070.49
Iteration:   4180, Loss function: 3.045, Average Loss: 3.657, avg. samples / sec: 66107.43
:::MLL 1558651478.995 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558651478.996 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558651479.045 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=2.55s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23171
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39498
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23854
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06132
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24454
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34236
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10141
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37234
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52888
Current AP: 0.23171 AP goal: 0.23000
:::MLL 1558651482.817 eval_accuracy: {"value": 0.23171315465348594, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558651482.856 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558651482.862 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558651483.503 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
ENDING TIMING RUN AT 2019-05-23 10:44:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:42:06 PM
