Beginning trial 5 of 5
Gathering sys log on circe-n001
:::MLL 1558651825.108 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558651825.109 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558651825.109 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558651825.109 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558651825.110 submission_platform: {"value": "30xNVIDIA DGX-2H", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558651825.110 submission_entry: {"value": "{'hardware': 'NVIDIA DGX-2H', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.1 LTS / NVIDIA DGX Server 4.0.4 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) Platinum 8174 CPU @ 3.10GHz', 'num_cores': '48', 'num_vcpus': '96', 'accelerator': 'Tesla V100-SXM3-32GB-H', 'num_accelerators': '8', 'sys_mem_size': '1510 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '2x 894.3G + 8x 3.5T', 'cpu_accel_interconnect': 'UPI', 'network_card': 'Mellanox Technologies MT27800 Family [ConnectX-5]', 'num_network_cards': '10', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558651825.111 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558651825.111 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558651827.734 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.701 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.738 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.718 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.729 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.725 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.726 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.745 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.737 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.748 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.768 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.768 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.742 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.777 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.774 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.754 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.782 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.788 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.790 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.786 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.772 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.787 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.799 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.817 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.768 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.781 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.775 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.774 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.819 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651827.804 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node circe-n001
+ pids+=($!)
+ set +x
Launching on node circe-n002
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
Launching on node circe-n003
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n001
+ srun --mem=0 -N 1 -n 1 -w circe-n001 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n002
+ set +x
Launching on node circe-n004
+ srun --mem=0 -N 1 -n 1 -w circe-n002 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n003
+ pids+=($!)
+ set +x
Launching on node circe-n005
+ srun --mem=0 -N 1 -n 1 -w circe-n003 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n004
+ pids+=($!)
+ set +x
Launching on node circe-n006
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n005
+ pids+=($!)
+ set +x
Launching on node circe-n007
+ srun --mem=0 -N 1 -n 1 -w circe-n004 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n005 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n006
+ pids+=($!)
+ set +x
Launching on node circe-n008
+ srun --mem=0 -N 1 -n 1 -w circe-n006 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n007
+ pids+=($!)
+ set +x
Launching on node circe-n009
+ srun --mem=0 -N 1 -n 1 -w circe-n007 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n008
+ pids+=($!)
+ set +x
Launching on node circe-n010
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n009
+ srun --mem=0 -N 1 -n 1 -w circe-n008 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n011
+ srun --mem=0 -N 1 -n 1 -w circe-n009 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n010
+ pids+=($!)
+ set +x
Launching on node circe-n012
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n011
+ srun --mem=0 -N 1 -n 1 -w circe-n010 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n013
+ srun --mem=0 -N 1 -n 1 -w circe-n011 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n012
+ pids+=($!)
+ set +x
Launching on node circe-n014
+ srun --mem=0 -N 1 -n 1 -w circe-n012 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n015
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n013
+ pids+=($!)
+ set +x
Launching on node circe-n016
+ srun --mem=0 -N 1 -n 1 -w circe-n013 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n014
+ pids+=($!)
+ set +x
Launching on node circe-n017
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n015
+ srun --mem=0 -N 1 -n 1 -w circe-n014 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n018
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n016
+ srun --mem=0 -N 1 -n 1 -w circe-n015 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n019
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n017
+ srun --mem=0 -N 1 -n 1 -w circe-n016 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n020
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n018
+ srun --mem=0 -N 1 -n 1 -w circe-n017 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n021
+ srun --mem=0 -N 1 -n 1 -w circe-n018 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n019
+ pids+=($!)
+ set +x
Launching on node circe-n022
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n020
+ srun --mem=0 -N 1 -n 1 -w circe-n019 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n021
+ srun --mem=0 -N 1 -n 1 -w circe-n020 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ set +x
Launching on node circe-n023
+ srun --mem=0 -N 1 -n 1 -w circe-n021 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n022
+ pids+=($!)
+ set +x
Launching on node circe-n024
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n023
+ srun --mem=0 -N 1 -n 1 -w circe-n022 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n025
+ srun --mem=0 -N 1 -n 1 -w circe-n023 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n024
Launching on node circe-n026
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ srun --mem=0 -N 1 -n 1 -w circe-n024 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n025
+ pids+=($!)
+ set +x
Launching on node circe-n027
+ srun --mem=0 -N 1 -n 1 -w circe-n025 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ pids+=($!)
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n026
+ set +x
Launching on node circe-n028
+ srun --mem=0 -N 1 -n 1 -w circe-n026 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n027
Launching on node circe-n029
+ srun --mem=0 -N 1 -n 1 -w circe-n027 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n030
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n028
+ srun --mem=0 -N 1 -n 1 -w circe-n028 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n029
+ srun --mem=0 -N 1 -n 1 -w circe-n029 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n030
+ srun --mem=0 -N 1 -n 1 -w circe-n030 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:50:27 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:50:27 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:27 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
running benchmark
+ NUMEPOCHS=80
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:27 PM
running benchmark
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
STARTING TIMING RUN AT 2019-05-23 10:50:27 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
STARTING TIMING RUN AT 2019-05-23 10:50:27 PM
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:27 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:50:28 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558651831.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.323 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.324 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.324 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.324 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.325 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.418 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.419 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.419 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.419 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.419 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.419 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.407 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.407 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.408 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.408 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.408 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.408 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.408 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.408 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.420 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.420 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.420 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.421 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.421 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.421 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.421 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.421 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.417 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.401 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.402 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.402 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.402 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.402 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.447 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.447 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.447 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.447 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.447 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.447 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.447 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.448 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.424 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.414 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.414 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.441 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.441 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.441 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.442 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.412 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.412 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.412 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.412 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.412 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.412 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.412 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.412 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651831.444 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.425 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.425 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.425 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.425 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.425 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.425 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.425 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.426 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.415 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.443 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.416 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.445 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.446 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.446 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.446 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.446 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.446 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.447 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.439 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.439 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.439 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.440 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.440 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.440 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.440 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651831.441 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558651831.452 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.452 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.452 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.453 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.453 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.453 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.453 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651831.453 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.481 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.482 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.482 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.475 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.467 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.459 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.472 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.473 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.454 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.464 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.464 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.464 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.464 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.464 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.464 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.465 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.455 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.455 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.455 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.456 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.470 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.482 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.482 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.482 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.483 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.479 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.479 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.479 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.480 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.480 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.480 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.480 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.480 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651831.465 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651831.466 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.466 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.466 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.466 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.466 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.466 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651831.466 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
0 Using seed = 1144859555
2 Using seed = 1144859557
1 Using seed = 1144859556
:::MLL 1558651845.112 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
4 Using seed = 1144859559
3 Using seed = 1144859558
13 Using seed = 1144859568
14 Using seed = 1144859569
11 Using seed = 1144859566
9 Using seed = 1144859564
15 Using seed = 1144859570
10 Using seed = 1144859565
8 Using seed = 1144859563
12 Using seed = 1144859567
21 Using seed = 1144859576
22 Using seed = 1144859577
23 Using seed = 1144859578
16 Using seed = 1144859571
17 Using seed = 1144859572
18 Using seed = 1144859573
20 Using seed = 1144859575
19 Using seed = 1144859574
31 Using seed = 1144859586
30 Using seed = 1144859585
29 Using seed = 1144859584
26 Using seed = 1144859581
25 Using seed = 1144859580
24 Using seed = 1144859579
28 Using seed = 1144859583
27 Using seed = 1144859582
39 Using seed = 1144859594
37 Using seed = 1144859592
38 Using seed = 1144859593
36 Using seed = 1144859591
33 Using seed = 1144859588
32 Using seed = 1144859587
34 Using seed = 1144859589
35 Using seed = 1144859590
47 Using seed = 1144859602
46 Using seed = 1144859601
40 Using seed = 1144859595
44 Using seed = 1144859599
41 Using seed = 1144859596
43 Using seed = 1144859598
45 Using seed = 1144859600
42 Using seed = 1144859597
55 Using seed = 1144859610
49 Using seed = 1144859604
54 Using seed = 1144859609
53 Using seed = 1144859608
48 Using seed = 1144859603
50 Using seed = 1144859605
52 Using seed = 1144859607
51 Using seed = 1144859606
57 Using seed = 1144859612
61 Using seed = 1144859616
58 Using seed = 1144859613
62 Using seed = 1144859617
63 Using seed = 1144859618
56 Using seed = 1144859611
60 Using seed = 1144859615
59 Using seed = 1144859614
66 Using seed = 1144859621
65 Using seed = 1144859620
69 Using seed = 1144859624
70 Using seed = 1144859625
64 Using seed = 1144859619
67 Using seed = 1144859622
71 Using seed = 1144859626
68 Using seed = 1144859623
76 Using seed = 1144859631
77 Using seed = 1144859632
75 Using seed = 1144859630
78 Using seed = 1144859633
79 Using seed = 1144859634
73 Using seed = 1144859628
72 Using seed = 1144859627
74 Using seed = 1144859629
85 Using seed = 1144859640
86 Using seed = 1144859641
82 Using seed = 1144859637
80 Using seed = 1144859635
83 Using seed = 1144859638
81 Using seed = 1144859636
87 Using seed = 1144859642
84 Using seed = 1144859639
95 Using seed = 1144859650
93 Using seed = 1144859648
92 Using seed = 1144859647
94 Using seed = 1144859649
91 Using seed = 1144859646
88 Using seed = 1144859643
89 Using seed = 1144859644
90 Using seed = 1144859645
101 Using seed = 1144859656
99 Using seed = 1144859654
96 Using seed = 1144859651
97 Using seed = 1144859652
98 Using seed = 1144859653
102 Using seed = 1144859657
103 Using seed = 1144859658
100 Using seed = 1144859655
111 Using seed = 1144859666
110 Using seed = 1144859665
109 Using seed = 1144859664
104 Using seed = 1144859659
105 Using seed = 1144859660
106 Using seed = 1144859661
108 Using seed = 1144859663
107 Using seed = 1144859662
114 Using seed = 1144859669
112 Using seed = 1144859667
113 Using seed = 1144859668
117 Using seed = 1144859672
118 Using seed = 1144859673
119 Using seed = 1144859674
116 Using seed = 1144859671
115 Using seed = 1144859670
126 Using seed = 1144859681
127 Using seed = 1144859682
125 Using seed = 1144859680
121 Using seed = 1144859676
120 Using seed = 1144859675
122 Using seed = 1144859677
124 Using seed = 1144859679
123 Using seed = 1144859678
135 Using seed = 1144859690
134 Using seed = 1144859689
133 Using seed = 1144859688
132 Using seed = 1144859687
131 Using seed = 1144859686
130 Using seed = 1144859685
129 Using seed = 1144859684
128 Using seed = 1144859683
137 Using seed = 1144859692
138 Using seed = 1144859693
136 Using seed = 1144859691
139 Using seed = 1144859694
143 Using seed = 1144859698
141 Using seed = 1144859696
142 Using seed = 1144859697
140 Using seed = 1144859695
147 Using seed = 1144859702
149 Using seed = 1144859704
146 Using seed = 1144859701
151 Using seed = 1144859706
144 Using seed = 1144859699
150 Using seed = 1144859705
145 Using seed = 1144859700
148 Using seed = 1144859703
159 Using seed = 1144859714
158 Using seed = 1144859713
156 Using seed = 1144859711
155 Using seed = 1144859710
152 Using seed = 1144859707
157 Using seed = 1144859712
153 Using seed = 1144859708
154 Using seed = 1144859709
160 Using seed = 1144859715
161 Using seed = 1144859716
163 Using seed = 1144859718
162 Using seed = 1144859717
165 Using seed = 1144859720
167 Using seed = 1144859722
166 Using seed = 1144859721
164 Using seed = 1144859719
173 Using seed = 1144859728
171 Using seed = 1144859726
175 Using seed = 1144859730
174 Using seed = 1144859729
169 Using seed = 1144859724
170 Using seed = 1144859725
168 Using seed = 1144859723
172 Using seed = 1144859727
183 Using seed = 1144859738
182 Using seed = 1144859737
181 Using seed = 1144859736
179 Using seed = 1144859734
177 Using seed = 1144859732
176 Using seed = 1144859731
178 Using seed = 1144859733
180 Using seed = 1144859735
190 Using seed = 1144859745
191 Using seed = 1144859746
189 Using seed = 1144859744
187 Using seed = 1144859742
186 Using seed = 1144859741
188 Using seed = 1144859743
184 Using seed = 1144859739
185 Using seed = 1144859740
193 Using seed = 1144859748
197 Using seed = 1144859752
195 Using seed = 1144859750
192 Using seed = 1144859747
198 Using seed = 1144859753
194 Using seed = 1144859749
199 Using seed = 1144859754
196 Using seed = 1144859751
206 Using seed = 1144859761
202 Using seed = 1144859757
205 Using seed = 1144859760
207 Using seed = 1144859762
200 Using seed = 1144859755
201 Using seed = 1144859756
203 Using seed = 1144859758
204 Using seed = 1144859759
214 Using seed = 1144859769
211 Using seed = 1144859766
213 Using seed = 1144859768
215 Using seed = 1144859770
210 Using seed = 1144859765
209 Using seed = 1144859764
212 Using seed = 1144859767
208 Using seed = 1144859763
221 Using seed = 1144859776
222 Using seed = 1144859777
217 Using seed = 1144859772
219 Using seed = 1144859774
218 Using seed = 1144859773
223 Using seed = 1144859778
216 Using seed = 1144859771
220 Using seed = 1144859775
229 Using seed = 1144859784
231 Using seed = 1144859786
225 Using seed = 1144859780
230 Using seed = 1144859785
228 Using seed = 1144859783
226 Using seed = 1144859781
227 Using seed = 1144859782
224 Using seed = 1144859779
238 Using seed = 1144859793
239 Using seed = 1144859794
233 Using seed = 1144859788
237 Using seed = 1144859792
234 Using seed = 1144859789
235 Using seed = 1144859790
232 Using seed = 1144859787
236 Using seed = 1144859791
5 Using seed = 1144859560
6 Using seed = 1144859561
7 Using seed = 1144859562
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
:::MLL 1558651847.192 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558651847.192 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651847.207 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1558651847.208 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1558651847.208 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1558651847.208 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558651851.004 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558651851.004 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.47s)
creating index...
time_check a: 1558651852.637654781
time_check a: 1558651852.672023058
time_check a: 1558651852.680339813
time_check a: 1558651852.649080276
time_check a: 1558651852.637227535
time_check a: 1558651852.643960714
time_check a: 1558651852.665727139
time_check a: 1558651852.693193436
time_check a: 1558651852.653198481
time_check a: 1558651852.693198442
time_check a: 1558651852.674926519
time_check a: 1558651852.645087481
time_check a: 1558651852.650563240
time_check a: 1558651852.643558741
time_check a: 1558651852.675773859
time_check a: 1558651852.664642096
time_check a: 1558651852.670867205
time_check a: 1558651852.656796217
time_check a: 1558651852.675869226
time_check a: 1558651852.678512335
time_check a: 1558651852.663024187
time_check a: 1558651852.653115988
time_check a: 1558651852.672283888
time_check a: 1558651852.669811964
time_check a: 1558651852.653827667
time_check a: 1558651852.675210953
time_check a: 1558651852.680201054
time_check a: 1558651852.668695450
time_check a: 1558651852.680622339
time_check a: 1558651852.686489105
time_check b: 1558651856.354875565
time_check b: 1558651856.437801361
time_check b: 1558651856.469416380
time_check b: 1558651856.488560200
time_check b: 1558651856.478567839
time_check b: 1558651856.479255915
time_check b: 1558651856.509901762
time_check b: 1558651856.499897003
time_check b: 1558651856.535923243
time_check b: 1558651856.514832735
time_check b: 1558651856.539809465
time_check b: 1558651856.528759241
time_check b: 1558651856.527279854
time_check b: 1558651856.549221516
time_check b: 1558651856.545184374
time_check b: 1558651856.547787666
time_check b: 1558651856.578467369
time_check b: 1558651856.558191538
time_check b: 1558651856.577107668
time_check b: 1558651856.599532127
time_check b: 1558651856.581518173
time_check b: 1558651856.550998449
time_check b: 1558651856.574273825
time_check b: 1558651856.559691191
time_check b: 1558651856.607169867
time_check b: 1558651856.608490229
time_check b: 1558651856.651274920
time_check b: 1558651856.648455143
time_check b: 1558651856.646342516
time_check b: 1558651856.662237167
:::MLL 1558651857.300 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558651857.301 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 23.672, Average Loss: 0.024, avg. samples / sec: 177.31
Iteration:      0, Loss function: 23.702, Average Loss: 0.024, avg. samples / sec: 177.74
Iteration:      0, Loss function: 22.309, Average Loss: 0.022, avg. samples / sec: 174.32
Iteration:      0, Loss function: 22.260, Average Loss: 0.022, avg. samples / sec: 177.21
Iteration:      0, Loss function: 22.415, Average Loss: 0.022, avg. samples / sec: 179.81
Iteration:      0, Loss function: 24.052, Average Loss: 0.024, avg. samples / sec: 178.63
Iteration:      0, Loss function: 22.432, Average Loss: 0.022, avg. samples / sec: 178.84
Iteration:      0, Loss function: 22.764, Average Loss: 0.023, avg. samples / sec: 176.44
Iteration:      0, Loss function: 22.414, Average Loss: 0.022, avg. samples / sec: 179.06
Iteration:      0, Loss function: 22.304, Average Loss: 0.022, avg. samples / sec: 178.57
Iteration:      0, Loss function: 22.476, Average Loss: 0.022, avg. samples / sec: 174.48
Iteration:      0, Loss function: 22.427, Average Loss: 0.022, avg. samples / sec: 177.77
Iteration:      0, Loss function: 22.181, Average Loss: 0.022, avg. samples / sec: 178.54
Iteration:      0, Loss function: 24.016, Average Loss: 0.024, avg. samples / sec: 178.92
Iteration:      0, Loss function: 22.804, Average Loss: 0.023, avg. samples / sec: 177.71
Iteration:      0, Loss function: 22.381, Average Loss: 0.022, avg. samples / sec: 176.69
Iteration:      0, Loss function: 22.895, Average Loss: 0.023, avg. samples / sec: 176.75
Iteration:      0, Loss function: 22.346, Average Loss: 0.022, avg. samples / sec: 177.56
Iteration:      0, Loss function: 22.533, Average Loss: 0.023, avg. samples / sec: 176.56
Iteration:      0, Loss function: 22.441, Average Loss: 0.022, avg. samples / sec: 177.79
Iteration:      0, Loss function: 22.599, Average Loss: 0.023, avg. samples / sec: 178.17
Iteration:      0, Loss function: 22.289, Average Loss: 0.022, avg. samples / sec: 179.01
Iteration:      0, Loss function: 22.933, Average Loss: 0.023, avg. samples / sec: 171.73
Iteration:      0, Loss function: 22.416, Average Loss: 0.022, avg. samples / sec: 174.79
Iteration:      0, Loss function: 22.268, Average Loss: 0.022, avg. samples / sec: 178.17
Iteration:      0, Loss function: 21.842, Average Loss: 0.022, avg. samples / sec: 174.70
Iteration:      0, Loss function: 22.867, Average Loss: 0.023, avg. samples / sec: 178.31
Iteration:      0, Loss function: 22.692, Average Loss: 0.023, avg. samples / sec: 176.71
Iteration:      0, Loss function: 22.738, Average Loss: 0.023, avg. samples / sec: 176.48
Iteration:      0, Loss function: 22.552, Average Loss: 0.023, avg. samples / sec: 178.05
Iteration:     20, Loss function: 21.218, Average Loss: 0.444, avg. samples / sec: 44138.76
Iteration:     20, Loss function: 20.241, Average Loss: 0.441, avg. samples / sec: 44427.68
Iteration:     20, Loss function: 20.573, Average Loss: 0.442, avg. samples / sec: 44432.90
Iteration:     20, Loss function: 20.326, Average Loss: 0.443, avg. samples / sec: 44325.18
Iteration:     20, Loss function: 22.023, Average Loss: 0.445, avg. samples / sec: 44126.49
Iteration:     20, Loss function: 21.083, Average Loss: 0.443, avg. samples / sec: 44112.88
Iteration:     20, Loss function: 20.440, Average Loss: 0.445, avg. samples / sec: 43965.55
Iteration:     20, Loss function: 21.911, Average Loss: 0.448, avg. samples / sec: 44050.34
Iteration:     20, Loss function: 21.248, Average Loss: 0.447, avg. samples / sec: 44698.91
Iteration:     20, Loss function: 20.052, Average Loss: 0.443, avg. samples / sec: 43700.91
Iteration:     20, Loss function: 20.854, Average Loss: 0.442, avg. samples / sec: 43936.97
Iteration:     20, Loss function: 20.802, Average Loss: 0.442, avg. samples / sec: 43918.33
Iteration:     20, Loss function: 20.428, Average Loss: 0.444, avg. samples / sec: 44127.08
Iteration:     20, Loss function: 22.617, Average Loss: 0.446, avg. samples / sec: 44567.07
Iteration:     20, Loss function: 20.919, Average Loss: 0.443, avg. samples / sec: 43797.20
Iteration:     20, Loss function: 20.331, Average Loss: 0.442, avg. samples / sec: 44038.24
Iteration:     20, Loss function: 20.413, Average Loss: 0.444, avg. samples / sec: 44206.44
Iteration:     20, Loss function: 20.291, Average Loss: 0.443, avg. samples / sec: 43402.61
Iteration:     20, Loss function: 21.109, Average Loss: 0.442, avg. samples / sec: 43930.20
Iteration:     20, Loss function: 20.179, Average Loss: 0.443, avg. samples / sec: 44024.44
Iteration:     20, Loss function: 20.176, Average Loss: 0.446, avg. samples / sec: 43752.72
Iteration:     20, Loss function: 20.650, Average Loss: 0.445, avg. samples / sec: 44305.78
Iteration:     20, Loss function: 19.867, Average Loss: 0.443, avg. samples / sec: 43980.75
Iteration:     20, Loss function: 20.720, Average Loss: 0.443, avg. samples / sec: 43946.12
Iteration:     20, Loss function: 20.705, Average Loss: 0.444, avg. samples / sec: 43877.91
Iteration:     20, Loss function: 20.697, Average Loss: 0.442, avg. samples / sec: 44293.15
Iteration:     20, Loss function: 20.105, Average Loss: 0.441, avg. samples / sec: 43824.67
Iteration:     20, Loss function: 20.620, Average Loss: 0.444, avg. samples / sec: 43804.93
Iteration:     20, Loss function: 20.747, Average Loss: 0.448, avg. samples / sec: 42880.03
Iteration:     20, Loss function: 20.786, Average Loss: 0.440, avg. samples / sec: 43515.99
Iteration:     40, Loss function: 19.716, Average Loss: 0.838, avg. samples / sec: 63258.02
Iteration:     40, Loss function: 19.293, Average Loss: 0.835, avg. samples / sec: 63537.65
Iteration:     40, Loss function: 19.899, Average Loss: 0.834, avg. samples / sec: 63576.95
Iteration:     40, Loss function: 18.662, Average Loss: 0.828, avg. samples / sec: 63066.51
Iteration:     40, Loss function: 18.239, Average Loss: 0.835, avg. samples / sec: 63404.67
Iteration:     40, Loss function: 18.767, Average Loss: 0.838, avg. samples / sec: 63981.39
Iteration:     40, Loss function: 19.093, Average Loss: 0.839, avg. samples / sec: 63363.85
Iteration:     40, Loss function: 19.753, Average Loss: 0.837, avg. samples / sec: 63212.05
Iteration:     40, Loss function: 18.937, Average Loss: 0.835, avg. samples / sec: 63384.17
Iteration:     40, Loss function: 19.233, Average Loss: 0.833, avg. samples / sec: 63009.24
Iteration:     40, Loss function: 19.243, Average Loss: 0.833, avg. samples / sec: 63529.32
Iteration:     40, Loss function: 18.326, Average Loss: 0.835, avg. samples / sec: 63373.62
Iteration:     40, Loss function: 19.032, Average Loss: 0.830, avg. samples / sec: 63350.75
Iteration:     40, Loss function: 19.344, Average Loss: 0.830, avg. samples / sec: 63208.45
Iteration:     40, Loss function: 18.897, Average Loss: 0.833, avg. samples / sec: 63697.90
Iteration:     40, Loss function: 19.154, Average Loss: 0.831, avg. samples / sec: 63396.14
Iteration:     40, Loss function: 18.940, Average Loss: 0.834, avg. samples / sec: 63416.77
Iteration:     40, Loss function: 18.935, Average Loss: 0.838, avg. samples / sec: 63113.00
Iteration:     40, Loss function: 20.347, Average Loss: 0.838, avg. samples / sec: 62809.02
Iteration:     40, Loss function: 18.487, Average Loss: 0.832, avg. samples / sec: 63116.76
Iteration:     40, Loss function: 18.642, Average Loss: 0.836, avg. samples / sec: 62978.92
Iteration:     40, Loss function: 18.601, Average Loss: 0.834, avg. samples / sec: 63272.08
Iteration:     40, Loss function: 19.524, Average Loss: 0.841, avg. samples / sec: 63283.81
Iteration:     40, Loss function: 18.649, Average Loss: 0.830, avg. samples / sec: 62911.36
Iteration:     40, Loss function: 18.899, Average Loss: 0.832, avg. samples / sec: 63212.22
Iteration:     40, Loss function: 18.935, Average Loss: 0.836, avg. samples / sec: 62949.66
Iteration:     40, Loss function: 18.145, Average Loss: 0.828, avg. samples / sec: 63735.87
Iteration:     40, Loss function: 18.503, Average Loss: 0.839, avg. samples / sec: 63041.49
Iteration:     40, Loss function: 18.218, Average Loss: 0.832, avg. samples / sec: 62716.67
Iteration:     40, Loss function: 19.121, Average Loss: 0.832, avg. samples / sec: 62942.41
Iteration:     60, Loss function: 14.554, Average Loss: 1.107, avg. samples / sec: 64199.06
Iteration:     60, Loss function: 12.162, Average Loss: 1.108, avg. samples / sec: 64086.31
Iteration:     60, Loss function: 12.075, Average Loss: 1.106, avg. samples / sec: 64078.27
Iteration:     60, Loss function: 14.583, Average Loss: 1.113, avg. samples / sec: 64517.15
Iteration:     60, Loss function: 10.975, Average Loss: 1.103, avg. samples / sec: 64042.45
Iteration:     60, Loss function: 12.990, Average Loss: 1.093, avg. samples / sec: 64459.16
Iteration:     60, Loss function: 11.810, Average Loss: 1.099, avg. samples / sec: 64010.40
Iteration:     60, Loss function: 13.634, Average Loss: 1.109, avg. samples / sec: 64095.11
Iteration:     60, Loss function: 14.734, Average Loss: 1.106, avg. samples / sec: 64125.94
Iteration:     60, Loss function: 11.060, Average Loss: 1.104, avg. samples / sec: 63997.23
Iteration:     60, Loss function: 13.980, Average Loss: 1.106, avg. samples / sec: 63988.05
Iteration:     60, Loss function: 14.548, Average Loss: 1.109, avg. samples / sec: 64114.33
Iteration:     60, Loss function: 11.592, Average Loss: 1.109, avg. samples / sec: 63823.13
Iteration:     60, Loss function: 14.010, Average Loss: 1.102, avg. samples / sec: 63761.30
Iteration:     60, Loss function: 11.339, Average Loss: 1.107, avg. samples / sec: 63629.68
Iteration:     60, Loss function: 12.461, Average Loss: 1.092, avg. samples / sec: 64184.15
Iteration:     60, Loss function: 12.932, Average Loss: 1.098, avg. samples / sec: 63879.34
Iteration:     60, Loss function: 11.377, Average Loss: 1.098, avg. samples / sec: 63743.94
Iteration:     60, Loss function: 11.581, Average Loss: 1.104, avg. samples / sec: 64056.63
Iteration:     60, Loss function: 13.149, Average Loss: 1.101, avg. samples / sec: 63694.10
Iteration:     60, Loss function: 10.372, Average Loss: 1.098, avg. samples / sec: 64463.47
Iteration:     60, Loss function: 12.086, Average Loss: 1.110, avg. samples / sec: 63742.88
Iteration:     60, Loss function: 12.647, Average Loss: 1.105, avg. samples / sec: 64283.42
Iteration:     60, Loss function: 13.035, Average Loss: 1.102, avg. samples / sec: 63905.96
Iteration:     60, Loss function: 12.139, Average Loss: 1.103, avg. samples / sec: 63950.62
Iteration:     60, Loss function: 14.264, Average Loss: 1.101, avg. samples / sec: 63696.69
Iteration:     60, Loss function: 13.570, Average Loss: 1.100, avg. samples / sec: 63977.82
Iteration:     60, Loss function: 14.906, Average Loss: 1.098, avg. samples / sec: 63571.27
Iteration:     60, Loss function: 14.050, Average Loss: 1.105, avg. samples / sec: 63789.59
Iteration:     60, Loss function: 12.846, Average Loss: 1.103, avg. samples / sec: 63395.17
:::MLL 1558651860.047 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558651860.048 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 11.309, Average Loss: 1.303, avg. samples / sec: 64153.41
Iteration:     80, Loss function: 12.542, Average Loss: 1.311, avg. samples / sec: 64005.95
Iteration:     80, Loss function: 10.281, Average Loss: 1.300, avg. samples / sec: 64063.00
Iteration:     80, Loss function: 10.106, Average Loss: 1.306, avg. samples / sec: 63819.75
Iteration:     80, Loss function: 10.794, Average Loss: 1.309, avg. samples / sec: 64000.28
Iteration:     80, Loss function: 10.643, Average Loss: 1.308, avg. samples / sec: 63754.24
Iteration:     80, Loss function: 10.505, Average Loss: 1.296, avg. samples / sec: 63853.66
Iteration:     80, Loss function: 11.074, Average Loss: 1.308, avg. samples / sec: 63935.65
Iteration:     80, Loss function: 10.090, Average Loss: 1.300, avg. samples / sec: 64340.07
Iteration:     80, Loss function: 10.359, Average Loss: 1.300, avg. samples / sec: 64039.19
Iteration:     80, Loss function: 11.781, Average Loss: 1.303, avg. samples / sec: 64264.90
Iteration:     80, Loss function: 11.039, Average Loss: 1.304, avg. samples / sec: 64441.15
Iteration:     80, Loss function: 10.800, Average Loss: 1.305, avg. samples / sec: 63723.94
Iteration:     80, Loss function: 11.358, Average Loss: 1.305, avg. samples / sec: 63899.44
Iteration:     80, Loss function: 11.871, Average Loss: 1.307, avg. samples / sec: 64040.76
Iteration:     80, Loss function: 10.392, Average Loss: 1.310, avg. samples / sec: 63755.28
Iteration:     80, Loss function: 11.058, Average Loss: 1.287, avg. samples / sec: 63784.22
Iteration:     80, Loss function: 10.458, Average Loss: 1.307, avg. samples / sec: 64075.65
Iteration:     80, Loss function: 10.416, Average Loss: 1.303, avg. samples / sec: 64284.27
Iteration:     80, Loss function: 10.858, Average Loss: 1.309, avg. samples / sec: 63891.21
Iteration:     80, Loss function: 10.088, Average Loss: 1.316, avg. samples / sec: 63909.96
Iteration:     80, Loss function: 11.167, Average Loss: 1.302, avg. samples / sec: 63735.61
Iteration:     80, Loss function: 11.393, Average Loss: 1.289, avg. samples / sec: 63805.01
Iteration:     80, Loss function: 10.897, Average Loss: 1.307, avg. samples / sec: 63699.11
Iteration:     80, Loss function: 11.395, Average Loss: 1.306, avg. samples / sec: 63715.38
Iteration:     80, Loss function: 11.973, Average Loss: 1.311, avg. samples / sec: 63620.64
Iteration:     80, Loss function: 11.323, Average Loss: 1.297, avg. samples / sec: 63765.60
Iteration:     80, Loss function: 11.568, Average Loss: 1.298, avg. samples / sec: 63905.78
Iteration:     80, Loss function: 11.121, Average Loss: 1.302, avg. samples / sec: 63409.64
Iteration:     80, Loss function: 12.061, Average Loss: 1.306, avg. samples / sec: 63636.81
Iteration:    100, Loss function: 8.961, Average Loss: 1.471, avg. samples / sec: 65823.00
Iteration:    100, Loss function: 9.627, Average Loss: 1.488, avg. samples / sec: 65733.41
Iteration:    100, Loss function: 9.102, Average Loss: 1.481, avg. samples / sec: 65976.24
Iteration:    100, Loss function: 9.914, Average Loss: 1.487, avg. samples / sec: 65738.38
Iteration:    100, Loss function: 9.657, Average Loss: 1.482, avg. samples / sec: 66170.01
Iteration:    100, Loss function: 9.752, Average Loss: 1.479, avg. samples / sec: 65721.09
Iteration:    100, Loss function: 9.968, Average Loss: 1.478, avg. samples / sec: 65744.97
Iteration:    100, Loss function: 9.695, Average Loss: 1.480, avg. samples / sec: 65713.49
Iteration:    100, Loss function: 9.968, Average Loss: 1.486, avg. samples / sec: 65633.64
Iteration:    100, Loss function: 10.117, Average Loss: 1.491, avg. samples / sec: 65607.97
Iteration:    100, Loss function: 9.613, Average Loss: 1.490, avg. samples / sec: 65825.86
Iteration:    100, Loss function: 9.313, Average Loss: 1.463, avg. samples / sec: 65823.15
Iteration:    100, Loss function: 9.557, Average Loss: 1.487, avg. samples / sec: 65602.32
Iteration:    100, Loss function: 9.481, Average Loss: 1.478, avg. samples / sec: 65482.65
Iteration:    100, Loss function: 8.298, Average Loss: 1.463, avg. samples / sec: 65655.10
Iteration:    100, Loss function: 8.951, Average Loss: 1.487, avg. samples / sec: 65848.22
Iteration:    100, Loss function: 9.489, Average Loss: 1.488, avg. samples / sec: 65605.38
Iteration:    100, Loss function: 9.556, Average Loss: 1.485, avg. samples / sec: 65575.58
Iteration:    100, Loss function: 10.112, Average Loss: 1.475, avg. samples / sec: 65569.63
Iteration:    100, Loss function: 10.703, Average Loss: 1.474, avg. samples / sec: 65777.10
Iteration:    100, Loss function: 9.743, Average Loss: 1.483, avg. samples / sec: 65697.62
Iteration:    100, Loss function: 8.614, Average Loss: 1.486, avg. samples / sec: 65528.17
Iteration:    100, Loss function: 9.381, Average Loss: 1.474, avg. samples / sec: 65436.74
Iteration:    100, Loss function: 9.554, Average Loss: 1.487, avg. samples / sec: 65652.35
Iteration:    100, Loss function: 10.154, Average Loss: 1.484, avg. samples / sec: 65512.63
Iteration:    100, Loss function: 9.009, Average Loss: 1.479, avg. samples / sec: 65523.32
Iteration:    100, Loss function: 9.492, Average Loss: 1.475, avg. samples / sec: 65765.77
Iteration:    100, Loss function: 10.848, Average Loss: 1.494, avg. samples / sec: 65580.19
Iteration:    100, Loss function: 9.713, Average Loss: 1.486, avg. samples / sec: 65070.51
Iteration:    100, Loss function: 9.492, Average Loss: 1.481, avg. samples / sec: 65072.65
Iteration:    120, Loss function: 10.062, Average Loss: 1.637, avg. samples / sec: 65520.77
Iteration:    120, Loss function: 10.714, Average Loss: 1.639, avg. samples / sec: 65619.00
Iteration:    120, Loss function: 10.663, Average Loss: 1.628, avg. samples / sec: 65609.62
Iteration:    120, Loss function: 8.282, Average Loss: 1.628, avg. samples / sec: 65368.08
Iteration:    120, Loss function: 9.029, Average Loss: 1.645, avg. samples / sec: 65278.21
Iteration:    120, Loss function: 8.729, Average Loss: 1.643, avg. samples / sec: 65413.78
Iteration:    120, Loss function: 10.210, Average Loss: 1.638, avg. samples / sec: 65571.77
Iteration:    120, Loss function: 9.414, Average Loss: 1.635, avg. samples / sec: 65470.54
Iteration:    120, Loss function: 9.916, Average Loss: 1.637, avg. samples / sec: 65326.51
Iteration:    120, Loss function: 9.953, Average Loss: 1.645, avg. samples / sec: 65288.13
Iteration:    120, Loss function: 9.218, Average Loss: 1.633, avg. samples / sec: 65287.23
Iteration:    120, Loss function: 8.567, Average Loss: 1.626, avg. samples / sec: 65137.85
Iteration:    120, Loss function: 9.319, Average Loss: 1.634, avg. samples / sec: 65206.66
Iteration:    120, Loss function: 9.222, Average Loss: 1.642, avg. samples / sec: 65203.04
Iteration:    120, Loss function: 9.189, Average Loss: 1.640, avg. samples / sec: 65333.11
Iteration:    120, Loss function: 7.877, Average Loss: 1.640, avg. samples / sec: 65409.77
Iteration:    120, Loss function: 10.196, Average Loss: 1.628, avg. samples / sec: 65370.81
Iteration:    120, Loss function: 10.404, Average Loss: 1.628, avg. samples / sec: 65466.38
Iteration:    120, Loss function: 8.819, Average Loss: 1.643, avg. samples / sec: 65185.40
Iteration:    120, Loss function: 9.043, Average Loss: 1.633, avg. samples / sec: 66265.71
Iteration:    120, Loss function: 8.902, Average Loss: 1.631, avg. samples / sec: 65370.54
Iteration:    120, Loss function: 9.132, Average Loss: 1.641, avg. samples / sec: 65237.27
Iteration:    120, Loss function: 8.694, Average Loss: 1.647, avg. samples / sec: 65391.62
Iteration:    120, Loss function: 7.683, Average Loss: 1.613, avg. samples / sec: 65128.31
Iteration:    120, Loss function: 9.381, Average Loss: 1.646, avg. samples / sec: 65075.35
Iteration:    120, Loss function: 9.434, Average Loss: 1.625, avg. samples / sec: 65166.44
Iteration:    120, Loss function: 9.730, Average Loss: 1.636, avg. samples / sec: 65120.58
Iteration:    120, Loss function: 9.000, Average Loss: 1.636, avg. samples / sec: 64860.82
Iteration:    120, Loss function: 8.874, Average Loss: 1.640, avg. samples / sec: 65513.24
Iteration:    120, Loss function: 9.166, Average Loss: 1.618, avg. samples / sec: 64780.20
:::MLL 1558651861.856 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558651861.856 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 8.274, Average Loss: 1.789, avg. samples / sec: 65299.11
Iteration:    140, Loss function: 8.461, Average Loss: 1.782, avg. samples / sec: 65537.37
Iteration:    140, Loss function: 8.729, Average Loss: 1.779, avg. samples / sec: 65155.50
Iteration:    140, Loss function: 8.642, Average Loss: 1.770, avg. samples / sec: 65326.51
Iteration:    140, Loss function: 8.443, Average Loss: 1.787, avg. samples / sec: 65512.27
Iteration:    140, Loss function: 8.437, Average Loss: 1.784, avg. samples / sec: 65298.24
Iteration:    140, Loss function: 9.080, Average Loss: 1.771, avg. samples / sec: 65549.41
Iteration:    140, Loss function: 10.362, Average Loss: 1.759, avg. samples / sec: 65502.68
Iteration:    140, Loss function: 8.871, Average Loss: 1.769, avg. samples / sec: 65201.41
Iteration:    140, Loss function: 8.606, Average Loss: 1.786, avg. samples / sec: 65319.30
Iteration:    140, Loss function: 8.755, Average Loss: 1.777, avg. samples / sec: 65258.84
Iteration:    140, Loss function: 8.550, Average Loss: 1.781, avg. samples / sec: 65298.33
Iteration:    140, Loss function: 8.180, Average Loss: 1.776, avg. samples / sec: 65350.86
Iteration:    140, Loss function: 8.844, Average Loss: 1.775, avg. samples / sec: 65395.20
Iteration:    140, Loss function: 7.688, Average Loss: 1.777, avg. samples / sec: 65240.98
Iteration:    140, Loss function: 9.075, Average Loss: 1.787, avg. samples / sec: 65144.51
Iteration:    140, Loss function: 8.870, Average Loss: 1.781, avg. samples / sec: 65146.77
Iteration:    140, Loss function: 8.986, Average Loss: 1.781, avg. samples / sec: 65119.64
Iteration:    140, Loss function: 8.744, Average Loss: 1.784, avg. samples / sec: 65244.52
Iteration:    140, Loss function: 8.981, Average Loss: 1.771, avg. samples / sec: 65241.59
Iteration:    140, Loss function: 8.855, Average Loss: 1.782, avg. samples / sec: 65498.93
Iteration:    140, Loss function: 8.187, Average Loss: 1.793, avg. samples / sec: 65310.70
Iteration:    140, Loss function: 9.529, Average Loss: 1.784, avg. samples / sec: 65552.25
Iteration:    140, Loss function: 8.839, Average Loss: 1.782, avg. samples / sec: 65460.60
Iteration:    140, Loss function: 8.542, Average Loss: 1.758, avg. samples / sec: 65630.89
Iteration:    140, Loss function: 9.745, Average Loss: 1.770, avg. samples / sec: 64893.10
Iteration:    140, Loss function: 8.539, Average Loss: 1.775, avg. samples / sec: 65168.22
Iteration:    140, Loss function: 9.256, Average Loss: 1.781, avg. samples / sec: 65122.95
Iteration:    140, Loss function: 8.325, Average Loss: 1.778, avg. samples / sec: 64918.99
Iteration:    140, Loss function: 8.818, Average Loss: 1.782, avg. samples / sec: 64790.27
Iteration:    160, Loss function: 8.602, Average Loss: 1.931, avg. samples / sec: 65962.62
Iteration:    160, Loss function: 8.816, Average Loss: 1.906, avg. samples / sec: 66197.67
Iteration:    160, Loss function: 8.030, Average Loss: 1.906, avg. samples / sec: 65989.37
Iteration:    160, Loss function: 8.575, Average Loss: 1.922, avg. samples / sec: 66115.49
Iteration:    160, Loss function: 8.393, Average Loss: 1.910, avg. samples / sec: 66047.91
Iteration:    160, Loss function: 7.985, Average Loss: 1.918, avg. samples / sec: 65908.39
Iteration:    160, Loss function: 8.380, Average Loss: 1.917, avg. samples / sec: 66051.26
Iteration:    160, Loss function: 8.636, Average Loss: 1.905, avg. samples / sec: 66224.48
Iteration:    160, Loss function: 8.538, Average Loss: 1.913, avg. samples / sec: 65958.76
Iteration:    160, Loss function: 7.956, Average Loss: 1.931, avg. samples / sec: 66090.47
Iteration:    160, Loss function: 7.923, Average Loss: 1.913, avg. samples / sec: 65905.65
Iteration:    160, Loss function: 8.598, Average Loss: 1.926, avg. samples / sec: 65981.74
Iteration:    160, Loss function: 8.920, Average Loss: 1.909, avg. samples / sec: 66187.32
Iteration:    160, Loss function: 9.233, Average Loss: 1.897, avg. samples / sec: 65897.17
Iteration:    160, Loss function: 8.833, Average Loss: 1.921, avg. samples / sec: 66284.47
Iteration:    160, Loss function: 8.824, Average Loss: 1.919, avg. samples / sec: 66004.92
Iteration:    160, Loss function: 8.602, Average Loss: 1.916, avg. samples / sec: 65883.28
Iteration:    160, Loss function: 8.093, Average Loss: 1.906, avg. samples / sec: 65842.89
Iteration:    160, Loss function: 8.441, Average Loss: 1.911, avg. samples / sec: 66140.29
Iteration:    160, Loss function: 8.440, Average Loss: 1.913, avg. samples / sec: 65908.17
Iteration:    160, Loss function: 8.644, Average Loss: 1.920, avg. samples / sec: 65957.37
Iteration:    160, Loss function: 8.193, Average Loss: 1.919, avg. samples / sec: 65991.10
Iteration:    160, Loss function: 7.760, Average Loss: 1.920, avg. samples / sec: 65790.42
Iteration:    160, Loss function: 9.308, Average Loss: 1.922, avg. samples / sec: 66005.23
Iteration:    160, Loss function: 8.136, Average Loss: 1.921, avg. samples / sec: 65732.52
Iteration:    160, Loss function: 7.304, Average Loss: 1.915, avg. samples / sec: 66037.27
Iteration:    160, Loss function: 7.972, Average Loss: 1.918, avg. samples / sec: 65722.16
Iteration:    160, Loss function: 7.538, Average Loss: 1.903, avg. samples / sec: 65673.34
Iteration:    160, Loss function: 8.819, Average Loss: 1.909, avg. samples / sec: 65671.59
Iteration:    160, Loss function: 7.980, Average Loss: 1.894, avg. samples / sec: 65855.79
Iteration:    180, Loss function: 8.033, Average Loss: 2.045, avg. samples / sec: 64904.28
Iteration:    180, Loss function: 8.487, Average Loss: 2.042, avg. samples / sec: 64937.93
Iteration:    180, Loss function: 7.984, Average Loss: 2.046, avg. samples / sec: 65000.50
Iteration:    180, Loss function: 8.704, Average Loss: 2.039, avg. samples / sec: 65196.07
Iteration:    180, Loss function: 9.338, Average Loss: 2.024, avg. samples / sec: 64941.10
Iteration:    180, Loss function: 8.152, Average Loss: 2.036, avg. samples / sec: 64789.97
Iteration:    180, Loss function: 9.154, Average Loss: 2.058, avg. samples / sec: 64885.69
Iteration:    180, Loss function: 8.824, Average Loss: 2.060, avg. samples / sec: 64721.44
Iteration:    180, Loss function: 7.817, Average Loss: 2.037, avg. samples / sec: 64792.47
Iteration:    180, Loss function: 7.813, Average Loss: 2.035, avg. samples / sec: 64789.34
Iteration:    180, Loss function: 8.662, Average Loss: 2.034, avg. samples / sec: 64817.83
Iteration:    180, Loss function: 8.609, Average Loss: 2.040, avg. samples / sec: 65020.89
Iteration:    180, Loss function: 8.192, Average Loss: 2.050, avg. samples / sec: 64838.05
Iteration:    180, Loss function: 8.690, Average Loss: 2.036, avg. samples / sec: 64874.25
Iteration:    180, Loss function: 8.610, Average Loss: 2.038, avg. samples / sec: 64830.12
Iteration:    180, Loss function: 8.118, Average Loss: 2.050, avg. samples / sec: 64820.57
Iteration:    180, Loss function: 8.317, Average Loss: 2.052, avg. samples / sec: 64910.38
Iteration:    180, Loss function: 9.840, Average Loss: 2.050, avg. samples / sec: 64986.05
Iteration:    180, Loss function: 7.781, Average Loss: 2.045, avg. samples / sec: 64723.85
Iteration:    180, Loss function: 8.180, Average Loss: 2.050, avg. samples / sec: 64833.84
Iteration:    180, Loss function: 7.043, Average Loss: 2.022, avg. samples / sec: 65066.61
Iteration:    180, Loss function: 8.334, Average Loss: 2.046, avg. samples / sec: 64870.52
Iteration:    180, Loss function: 7.826, Average Loss: 2.039, avg. samples / sec: 64809.87
Iteration:    180, Loss function: 8.543, Average Loss: 2.031, avg. samples / sec: 64961.60
Iteration:    180, Loss function: 7.851, Average Loss: 2.040, avg. samples / sec: 64688.91
Iteration:    180, Loss function: 7.652, Average Loss: 2.039, avg. samples / sec: 64741.69
Iteration:    180, Loss function: 8.377, Average Loss: 2.055, avg. samples / sec: 64798.73
Iteration:    180, Loss function: 7.951, Average Loss: 2.049, avg. samples / sec: 64729.80
Iteration:    180, Loss function: 7.798, Average Loss: 2.051, avg. samples / sec: 64767.58
Iteration:    180, Loss function: 9.111, Average Loss: 2.051, avg. samples / sec: 64513.52
Iteration:    200, Loss function: 8.331, Average Loss: 2.188, avg. samples / sec: 65618.97
Iteration:    200, Loss function: 8.291, Average Loss: 2.164, avg. samples / sec: 65781.89
Iteration:    200, Loss function: 8.653, Average Loss: 2.168, avg. samples / sec: 65549.02
Iteration:    200, Loss function: 8.796, Average Loss: 2.166, avg. samples / sec: 65623.46
Iteration:    200, Loss function: 8.262, Average Loss: 2.160, avg. samples / sec: 65528.87
Iteration:    200, Loss function: 8.710, Average Loss: 2.175, avg. samples / sec: 65602.63
Iteration:    200, Loss function: 8.956, Average Loss: 2.177, avg. samples / sec: 65656.57
Iteration:    200, Loss function: 8.521, Average Loss: 2.174, avg. samples / sec: 65626.24
Iteration:    200, Loss function: 9.779, Average Loss: 2.162, avg. samples / sec: 65566.76
Iteration:    200, Loss function: 7.905, Average Loss: 2.179, avg. samples / sec: 65829.48
Iteration:    200, Loss function: 8.834, Average Loss: 2.173, avg. samples / sec: 65463.55
Iteration:    200, Loss function: 9.330, Average Loss: 2.163, avg. samples / sec: 65543.71
Iteration:    200, Loss function: 8.832, Average Loss: 2.173, avg. samples / sec: 65557.52
Iteration:    200, Loss function: 9.089, Average Loss: 2.181, avg. samples / sec: 65719.49
Iteration:    200, Loss function: 10.279, Average Loss: 2.181, avg. samples / sec: 65786.34
Iteration:    200, Loss function: 9.452, Average Loss: 2.174, avg. samples / sec: 65599.94
Iteration:    200, Loss function: 8.309, Average Loss: 2.167, avg. samples / sec: 65528.11
Iteration:    200, Loss function: 9.184, Average Loss: 2.189, avg. samples / sec: 65500.42
Iteration:    200, Loss function: 8.957, Average Loss: 2.176, avg. samples / sec: 65587.97
Iteration:    200, Loss function: 7.982, Average Loss: 2.168, avg. samples / sec: 65399.08
Iteration:    200, Loss function: 9.138, Average Loss: 2.163, avg. samples / sec: 65507.73
Iteration:    200, Loss function: 8.610, Average Loss: 2.165, avg. samples / sec: 65653.51
Iteration:    200, Loss function: 8.590, Average Loss: 2.166, avg. samples / sec: 65366.69
Iteration:    200, Loss function: 9.991, Average Loss: 2.177, avg. samples / sec: 65502.01
Iteration:    200, Loss function: 9.031, Average Loss: 2.152, avg. samples / sec: 65478.75
Iteration:    200, Loss function: 8.133, Average Loss: 2.160, avg. samples / sec: 65479.06
Iteration:    200, Loss function: 9.300, Average Loss: 2.179, avg. samples / sec: 65594.72
Iteration:    200, Loss function: 9.175, Average Loss: 2.168, avg. samples / sec: 65433.21
Iteration:    200, Loss function: 8.693, Average Loss: 2.156, avg. samples / sec: 65162.52
Iteration:    200, Loss function: 8.267, Average Loss: 2.181, avg. samples / sec: 65209.08
:::MLL 1558651863.654 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558651863.654 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 8.694, Average Loss: 2.317, avg. samples / sec: 65631.13
Iteration:    220, Loss function: 7.857, Average Loss: 2.287, avg. samples / sec: 65388.92
Iteration:    220, Loss function: 8.822, Average Loss: 2.298, avg. samples / sec: 65386.22
Iteration:    220, Loss function: 8.766, Average Loss: 2.282, avg. samples / sec: 65351.98
Iteration:    220, Loss function: 7.977, Average Loss: 2.292, avg. samples / sec: 65445.19
Iteration:    220, Loss function: 8.516, Average Loss: 2.305, avg. samples / sec: 65428.72
Iteration:    220, Loss function: 8.689, Average Loss: 2.298, avg. samples / sec: 65425.92
Iteration:    220, Loss function: 8.009, Average Loss: 2.297, avg. samples / sec: 65368.29
Iteration:    220, Loss function: 8.658, Average Loss: 2.275, avg. samples / sec: 65511.51
Iteration:    220, Loss function: 8.635, Average Loss: 2.286, avg. samples / sec: 65322.75
Iteration:    220, Loss function: 7.997, Average Loss: 2.285, avg. samples / sec: 65313.37
Iteration:    220, Loss function: 9.521, Average Loss: 2.312, avg. samples / sec: 65182.05
Iteration:    220, Loss function: 8.348, Average Loss: 2.298, avg. samples / sec: 65315.03
Iteration:    220, Loss function: 7.658, Average Loss: 2.304, avg. samples / sec: 65477.45
Iteration:    220, Loss function: 7.999, Average Loss: 2.287, avg. samples / sec: 65359.62
Iteration:    220, Loss function: 9.324, Average Loss: 2.301, avg. samples / sec: 65692.13
Iteration:    220, Loss function: 8.301, Average Loss: 2.303, avg. samples / sec: 65275.64
Iteration:    220, Loss function: 8.703, Average Loss: 2.297, avg. samples / sec: 65239.93
Iteration:    220, Loss function: 8.322, Average Loss: 2.279, avg. samples / sec: 65547.86
Iteration:    220, Loss function: 8.241, Average Loss: 2.291, avg. samples / sec: 65257.93
Iteration:    220, Loss function: 7.106, Average Loss: 2.303, avg. samples / sec: 65233.25
Iteration:    220, Loss function: 7.898, Average Loss: 2.288, avg. samples / sec: 65307.53
Iteration:    220, Loss function: 8.886, Average Loss: 2.283, avg. samples / sec: 65354.68
Iteration:    220, Loss function: 8.388, Average Loss: 2.290, avg. samples / sec: 65051.68
Iteration:    220, Loss function: 8.288, Average Loss: 2.287, avg. samples / sec: 65189.65
Iteration:    220, Loss function: 8.767, Average Loss: 2.300, avg. samples / sec: 65161.98
Iteration:    220, Loss function: 7.853, Average Loss: 2.295, avg. samples / sec: 65195.98
Iteration:    220, Loss function: 8.664, Average Loss: 2.292, avg. samples / sec: 65327.90
Iteration:    220, Loss function: 7.609, Average Loss: 2.292, avg. samples / sec: 64924.41
Iteration:    220, Loss function: 8.499, Average Loss: 2.297, avg. samples / sec: 64957.32
Iteration:    240, Loss function: 8.245, Average Loss: 2.409, avg. samples / sec: 65825.79
Iteration:    240, Loss function: 7.314, Average Loss: 2.398, avg. samples / sec: 65565.64
Iteration:    240, Loss function: 6.746, Average Loss: 2.401, avg. samples / sec: 65619.34
Iteration:    240, Loss function: 7.518, Average Loss: 2.395, avg. samples / sec: 65672.18
Iteration:    240, Loss function: 8.339, Average Loss: 2.408, avg. samples / sec: 65621.72
Iteration:    240, Loss function: 7.805, Average Loss: 2.411, avg. samples / sec: 65716.30
Iteration:    240, Loss function: 8.475, Average Loss: 2.393, avg. samples / sec: 65735.31
Iteration:    240, Loss function: 8.595, Average Loss: 2.406, avg. samples / sec: 65884.60
Iteration:    240, Loss function: 7.937, Average Loss: 2.410, avg. samples / sec: 65959.87
Iteration:    240, Loss function: 8.079, Average Loss: 2.426, avg. samples / sec: 65351.59
Iteration:    240, Loss function: 7.254, Average Loss: 2.416, avg. samples / sec: 65597.47
Iteration:    240, Loss function: 8.120, Average Loss: 2.400, avg. samples / sec: 65794.05
Iteration:    240, Loss function: 8.012, Average Loss: 2.385, avg. samples / sec: 65544.87
Iteration:    240, Loss function: 8.779, Average Loss: 2.402, avg. samples / sec: 65562.37
Iteration:    240, Loss function: 7.768, Average Loss: 2.422, avg. samples / sec: 65579.37
Iteration:    240, Loss function: 8.122, Average Loss: 2.408, avg. samples / sec: 65760.00
Iteration:    240, Loss function: 8.284, Average Loss: 2.412, avg. samples / sec: 65489.10
Iteration:    240, Loss function: 8.124, Average Loss: 2.419, avg. samples / sec: 65493.82
Iteration:    240, Loss function: 7.258, Average Loss: 2.394, avg. samples / sec: 65676.61
Iteration:    240, Loss function: 7.386, Average Loss: 2.413, avg. samples / sec: 65666.70
Iteration:    240, Loss function: 7.292, Average Loss: 2.410, avg. samples / sec: 65447.22
Iteration:    240, Loss function: 7.930, Average Loss: 2.406, avg. samples / sec: 65634.19
Iteration:    240, Loss function: 7.479, Average Loss: 2.400, avg. samples / sec: 65571.43
Iteration:    240, Loss function: 7.843, Average Loss: 2.408, avg. samples / sec: 65536.61
Iteration:    240, Loss function: 7.208, Average Loss: 2.408, avg. samples / sec: 65733.29
Iteration:    240, Loss function: 7.881, Average Loss: 2.399, avg. samples / sec: 65645.78
Iteration:    240, Loss function: 8.321, Average Loss: 2.398, avg. samples / sec: 65638.41
Iteration:    240, Loss function: 7.602, Average Loss: 2.388, avg. samples / sec: 65386.22
Iteration:    240, Loss function: 6.887, Average Loss: 2.403, avg. samples / sec: 65735.77
Iteration:    240, Loss function: 7.976, Average Loss: 2.408, avg. samples / sec: 65460.54
Iteration:    260, Loss function: 9.055, Average Loss: 2.504, avg. samples / sec: 65773.41
Iteration:    260, Loss function: 7.991, Average Loss: 2.504, avg. samples / sec: 66007.23
Iteration:    260, Loss function: 6.858, Average Loss: 2.508, avg. samples / sec: 66010.11
Iteration:    260, Loss function: 7.848, Average Loss: 2.520, avg. samples / sec: 65892.06
Iteration:    260, Loss function: 7.607, Average Loss: 2.503, avg. samples / sec: 65707.51
Iteration:    260, Loss function: 8.064, Average Loss: 2.523, avg. samples / sec: 65838.68
Iteration:    260, Loss function: 8.768, Average Loss: 2.516, avg. samples / sec: 65635.63
Iteration:    260, Loss function: 7.883, Average Loss: 2.532, avg. samples / sec: 65786.95
Iteration:    260, Loss function: 7.356, Average Loss: 2.505, avg. samples / sec: 65866.22
Iteration:    260, Loss function: 7.860, Average Loss: 2.498, avg. samples / sec: 65945.71
Iteration:    260, Loss function: 8.891, Average Loss: 2.519, avg. samples / sec: 65867.48
Iteration:    260, Loss function: 8.810, Average Loss: 2.512, avg. samples / sec: 65847.94
Iteration:    260, Loss function: 7.439, Average Loss: 2.514, avg. samples / sec: 65796.14
Iteration:    260, Loss function: 7.258, Average Loss: 2.514, avg. samples / sec: 65724.00
Iteration:    260, Loss function: 8.521, Average Loss: 2.506, avg. samples / sec: 65843.60
Iteration:    260, Loss function: 7.429, Average Loss: 2.512, avg. samples / sec: 65808.37
Iteration:    260, Loss function: 7.829, Average Loss: 2.494, avg. samples / sec: 65688.25
Iteration:    260, Loss function: 8.381, Average Loss: 2.506, avg. samples / sec: 65733.87
Iteration:    260, Loss function: 8.069, Average Loss: 2.516, avg. samples / sec: 65772.80
Iteration:    260, Loss function: 7.513, Average Loss: 2.517, avg. samples / sec: 65807.38
Iteration:    260, Loss function: 7.723, Average Loss: 2.513, avg. samples / sec: 65870.50
Iteration:    260, Loss function: 7.553, Average Loss: 2.504, avg. samples / sec: 65726.45
Iteration:    260, Loss function: 7.124, Average Loss: 2.520, avg. samples / sec: 65684.24
Iteration:    260, Loss function: 7.146, Average Loss: 2.506, avg. samples / sec: 65677.35
Iteration:    260, Loss function: 7.288, Average Loss: 2.521, avg. samples / sec: 65679.83
Iteration:    260, Loss function: 7.880, Average Loss: 2.504, avg. samples / sec: 65547.55
Iteration:    260, Loss function: 8.361, Average Loss: 2.512, avg. samples / sec: 65576.07
Iteration:    260, Loss function: 8.218, Average Loss: 2.517, avg. samples / sec: 65540.54
Iteration:    260, Loss function: 7.014, Average Loss: 2.489, avg. samples / sec: 65497.41
Iteration:    260, Loss function: 8.071, Average Loss: 2.507, avg. samples / sec: 65345.23
:::MLL 1558651865.445 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558651865.445 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 9.338, Average Loss: 2.609, avg. samples / sec: 65960.24
Iteration:    280, Loss function: 8.122, Average Loss: 2.622, avg. samples / sec: 66105.69
Iteration:    280, Loss function: 7.105, Average Loss: 2.595, avg. samples / sec: 65984.27
Iteration:    280, Loss function: 7.344, Average Loss: 2.631, avg. samples / sec: 65850.25
Iteration:    280, Loss function: 8.544, Average Loss: 2.640, avg. samples / sec: 65825.95
Iteration:    280, Loss function: 7.913, Average Loss: 2.622, avg. samples / sec: 65888.08
Iteration:    280, Loss function: 7.287, Average Loss: 2.613, avg. samples / sec: 65741.20
Iteration:    280, Loss function: 9.098, Average Loss: 2.611, avg. samples / sec: 65741.38
Iteration:    280, Loss function: 8.178, Average Loss: 2.612, avg. samples / sec: 65938.33
Iteration:    280, Loss function: 7.087, Average Loss: 2.624, avg. samples / sec: 65933.64
Iteration:    280, Loss function: 7.277, Average Loss: 2.617, avg. samples / sec: 65815.31
Iteration:    280, Loss function: 8.085, Average Loss: 2.620, avg. samples / sec: 65848.98
Iteration:    280, Loss function: 8.191, Average Loss: 2.620, avg. samples / sec: 65932.69
Iteration:    280, Loss function: 7.303, Average Loss: 2.616, avg. samples / sec: 65818.02
Iteration:    280, Loss function: 7.640, Average Loss: 2.619, avg. samples / sec: 65721.42
Iteration:    280, Loss function: 7.077, Average Loss: 2.605, avg. samples / sec: 65732.79
Iteration:    280, Loss function: 8.216, Average Loss: 2.622, avg. samples / sec: 65819.86
Iteration:    280, Loss function: 7.600, Average Loss: 2.623, avg. samples / sec: 65709.84
Iteration:    280, Loss function: 7.939, Average Loss: 2.612, avg. samples / sec: 65854.06
Iteration:    280, Loss function: 7.937, Average Loss: 2.617, avg. samples / sec: 65713.94
Iteration:    280, Loss function: 8.484, Average Loss: 2.611, avg. samples / sec: 65718.36
Iteration:    280, Loss function: 7.443, Average Loss: 2.614, avg. samples / sec: 65738.19
Iteration:    280, Loss function: 8.646, Average Loss: 2.609, avg. samples / sec: 65560.39
Iteration:    280, Loss function: 7.748, Average Loss: 2.626, avg. samples / sec: 65591.42
Iteration:    280, Loss function: 7.967, Average Loss: 2.610, avg. samples / sec: 65973.95
Iteration:    280, Loss function: 7.847, Average Loss: 2.621, avg. samples / sec: 65709.13
Iteration:    280, Loss function: 7.901, Average Loss: 2.618, avg. samples / sec: 65655.29
Iteration:    280, Loss function: 7.648, Average Loss: 2.598, avg. samples / sec: 65881.12
Iteration:    280, Loss function: 7.475, Average Loss: 2.614, avg. samples / sec: 65584.49
Iteration:    280, Loss function: 9.018, Average Loss: 2.614, avg. samples / sec: 65403.94
Iteration:    300, Loss function: 7.279, Average Loss: 2.708, avg. samples / sec: 66131.44
Iteration:    300, Loss function: 7.247, Average Loss: 2.712, avg. samples / sec: 66281.98
Iteration:    300, Loss function: 6.317, Average Loss: 2.689, avg. samples / sec: 66052.12
Iteration:    300, Loss function: 6.854, Average Loss: 2.703, avg. samples / sec: 66375.07
Iteration:    300, Loss function: 6.565, Average Loss: 2.709, avg. samples / sec: 66141.03
Iteration:    300, Loss function: 7.652, Average Loss: 2.724, avg. samples / sec: 66067.55
Iteration:    300, Loss function: 7.664, Average Loss: 2.702, avg. samples / sec: 66345.04
Iteration:    300, Loss function: 8.064, Average Loss: 2.703, avg. samples / sec: 66092.58
Iteration:    300, Loss function: 8.236, Average Loss: 2.711, avg. samples / sec: 66514.38
Iteration:    300, Loss function: 6.305, Average Loss: 2.699, avg. samples / sec: 66159.44
Iteration:    300, Loss function: 6.819, Average Loss: 2.711, avg. samples / sec: 66193.81
Iteration:    300, Loss function: 8.001, Average Loss: 2.714, avg. samples / sec: 66112.61
Iteration:    300, Loss function: 6.984, Average Loss: 2.704, avg. samples / sec: 66242.69
Iteration:    300, Loss function: 7.664, Average Loss: 2.714, avg. samples / sec: 66228.81
Iteration:    300, Loss function: 7.867, Average Loss: 2.707, avg. samples / sec: 66430.39
Iteration:    300, Loss function: 7.543, Average Loss: 2.713, avg. samples / sec: 66090.78
Iteration:    300, Loss function: 7.445, Average Loss: 2.711, avg. samples / sec: 66300.47
Iteration:    300, Loss function: 7.289, Average Loss: 2.707, avg. samples / sec: 66182.93
Iteration:    300, Loss function: 6.853, Average Loss: 2.714, avg. samples / sec: 66103.00
Iteration:    300, Loss function: 6.057, Average Loss: 2.690, avg. samples / sec: 66303.31
Iteration:    300, Loss function: 6.646, Average Loss: 2.709, avg. samples / sec: 66084.86
Iteration:    300, Loss function: 7.446, Average Loss: 2.705, avg. samples / sec: 66168.70
Iteration:    300, Loss function: 7.085, Average Loss: 2.714, avg. samples / sec: 66045.00
Iteration:    300, Loss function: 7.071, Average Loss: 2.715, avg. samples / sec: 66097.57
Iteration:    300, Loss function: 5.816, Average Loss: 2.713, avg. samples / sec: 65991.47
Iteration:    300, Loss function: 7.604, Average Loss: 2.720, avg. samples / sec: 65892.00
Iteration:    300, Loss function: 7.614, Average Loss: 2.708, avg. samples / sec: 65957.65
Iteration:    300, Loss function: 6.857, Average Loss: 2.732, avg. samples / sec: 65869.67
Iteration:    300, Loss function: 7.188, Average Loss: 2.721, avg. samples / sec: 66111.90
Iteration:    300, Loss function: 8.201, Average Loss: 2.717, avg. samples / sec: 66122.57
Iteration:    320, Loss function: 6.489, Average Loss: 2.798, avg. samples / sec: 66086.07
Iteration:    320, Loss function: 7.086, Average Loss: 2.802, avg. samples / sec: 65913.26
Iteration:    320, Loss function: 7.016, Average Loss: 2.794, avg. samples / sec: 66124.99
Iteration:    320, Loss function: 7.233, Average Loss: 2.796, avg. samples / sec: 66110.16
Iteration:    320, Loss function: 6.849, Average Loss: 2.804, avg. samples / sec: 66109.88
Iteration:    320, Loss function: 8.163, Average Loss: 2.806, avg. samples / sec: 66189.03
Iteration:    320, Loss function: 6.885, Average Loss: 2.791, avg. samples / sec: 66000.84
Iteration:    320, Loss function: 5.752, Average Loss: 2.793, avg. samples / sec: 66013.63
Iteration:    320, Loss function: 7.265, Average Loss: 2.804, avg. samples / sec: 66089.73
Iteration:    320, Loss function: 7.686, Average Loss: 2.781, avg. samples / sec: 65975.04
Iteration:    320, Loss function: 6.947, Average Loss: 2.807, avg. samples / sec: 65963.80
Iteration:    320, Loss function: 7.126, Average Loss: 2.801, avg. samples / sec: 66088.74
Iteration:    320, Loss function: 6.775, Average Loss: 2.802, avg. samples / sec: 66062.06
Iteration:    320, Loss function: 7.389, Average Loss: 2.795, avg. samples / sec: 66091.31
Iteration:    320, Loss function: 6.680, Average Loss: 2.821, avg. samples / sec: 66196.30
Iteration:    320, Loss function: 7.776, Average Loss: 2.792, avg. samples / sec: 66000.06
Iteration:    320, Loss function: 6.714, Average Loss: 2.805, avg. samples / sec: 66214.06
Iteration:    320, Loss function: 6.109, Average Loss: 2.800, avg. samples / sec: 65992.61
Iteration:    320, Loss function: 7.427, Average Loss: 2.799, avg. samples / sec: 66101.66
Iteration:    320, Loss function: 7.567, Average Loss: 2.805, avg. samples / sec: 66021.52
Iteration:    320, Loss function: 7.014, Average Loss: 2.802, avg. samples / sec: 65898.25
Iteration:    320, Loss function: 7.483, Average Loss: 2.800, avg. samples / sec: 66004.14
Iteration:    320, Loss function: 8.455, Average Loss: 2.804, avg. samples / sec: 66007.85
Iteration:    320, Loss function: 6.979, Average Loss: 2.778, avg. samples / sec: 65937.56
Iteration:    320, Loss function: 8.345, Average Loss: 2.799, avg. samples / sec: 65868.93
Iteration:    320, Loss function: 7.322, Average Loss: 2.807, avg. samples / sec: 66028.51
Iteration:    320, Loss function: 6.708, Average Loss: 2.798, avg. samples / sec: 65922.60
Iteration:    320, Loss function: 9.264, Average Loss: 2.805, avg. samples / sec: 65898.90
Iteration:    320, Loss function: 7.241, Average Loss: 2.793, avg. samples / sec: 65836.93
Iteration:    320, Loss function: 7.528, Average Loss: 2.795, avg. samples / sec: 65904.01
Iteration:    340, Loss function: 7.379, Average Loss: 2.894, avg. samples / sec: 66420.96
Iteration:    340, Loss function: 7.241, Average Loss: 2.892, avg. samples / sec: 66618.65
Iteration:    340, Loss function: 7.565, Average Loss: 2.889, avg. samples / sec: 66782.74
Iteration:    340, Loss function: 6.368, Average Loss: 2.898, avg. samples / sec: 66584.65
Iteration:    340, Loss function: 7.338, Average Loss: 2.890, avg. samples / sec: 66404.47
Iteration:    340, Loss function: 7.379, Average Loss: 2.889, avg. samples / sec: 66456.39
Iteration:    340, Loss function: 7.860, Average Loss: 2.916, avg. samples / sec: 66503.05
Iteration:    340, Loss function: 8.082, Average Loss: 2.896, avg. samples / sec: 66265.81
Iteration:    340, Loss function: 8.392, Average Loss: 2.888, avg. samples / sec: 66458.02
Iteration:    340, Loss function: 7.753, Average Loss: 2.901, avg. samples / sec: 66454.76
Iteration:    340, Loss function: 7.484, Average Loss: 2.896, avg. samples / sec: 66329.43
Iteration:    340, Loss function: 6.760, Average Loss: 2.898, avg. samples / sec: 66416.55
Iteration:    340, Loss function: 7.127, Average Loss: 2.888, avg. samples / sec: 66524.05
Iteration:    340, Loss function: 7.836, Average Loss: 2.890, avg. samples / sec: 66396.52
Iteration:    340, Loss function: 7.680, Average Loss: 2.896, avg. samples / sec: 66369.95
Iteration:    340, Loss function: 6.932, Average Loss: 2.890, avg. samples / sec: 66263.66
Iteration:    340, Loss function: 8.388, Average Loss: 2.876, avg. samples / sec: 66359.41
Iteration:    340, Loss function: 8.255, Average Loss: 2.895, avg. samples / sec: 66539.07
Iteration:    340, Loss function: 7.757, Average Loss: 2.894, avg. samples / sec: 66367.91
Iteration:    340, Loss function: 7.000, Average Loss: 2.902, avg. samples / sec: 66516.14
Iteration:    340, Loss function: 6.808, Average Loss: 2.887, avg. samples / sec: 66268.67
Iteration:    340, Loss function: 7.538, Average Loss: 2.899, avg. samples / sec: 66249.61
Iteration:    340, Loss function: 7.804, Average Loss: 2.890, avg. samples / sec: 66516.14
Iteration:    340, Loss function: 8.515, Average Loss: 2.889, avg. samples / sec: 66298.69
Iteration:    340, Loss function: 6.880, Average Loss: 2.897, avg. samples / sec: 66347.17
Iteration:    340, Loss function: 7.892, Average Loss: 2.899, avg. samples / sec: 66241.29
Iteration:    340, Loss function: 6.815, Average Loss: 2.896, avg. samples / sec: 66183.80
Iteration:    340, Loss function: 8.748, Average Loss: 2.876, avg. samples / sec: 66354.32
Iteration:    340, Loss function: 6.785, Average Loss: 2.899, avg. samples / sec: 66370.29
Iteration:    340, Loss function: 7.644, Average Loss: 2.901, avg. samples / sec: 66227.10
:::MLL 1558651867.224 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558651867.225 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 7.703, Average Loss: 2.978, avg. samples / sec: 64961.42
Iteration:    360, Loss function: 6.418, Average Loss: 3.004, avg. samples / sec: 64988.45
Iteration:    360, Loss function: 6.995, Average Loss: 2.978, avg. samples / sec: 65142.79
Iteration:    360, Loss function: 6.879, Average Loss: 2.971, avg. samples / sec: 64929.10
Iteration:    360, Loss function: 6.777, Average Loss: 2.983, avg. samples / sec: 64967.17
Iteration:    360, Loss function: 7.063, Average Loss: 2.976, avg. samples / sec: 64840.53
Iteration:    360, Loss function: 7.712, Average Loss: 2.976, avg. samples / sec: 64987.01
Iteration:    360, Loss function: 7.553, Average Loss: 2.974, avg. samples / sec: 65042.52
Iteration:    360, Loss function: 6.767, Average Loss: 2.962, avg. samples / sec: 65143.79
Iteration:    360, Loss function: 7.089, Average Loss: 2.988, avg. samples / sec: 65028.12
Iteration:    360, Loss function: 7.025, Average Loss: 2.976, avg. samples / sec: 64969.18
Iteration:    360, Loss function: 7.034, Average Loss: 2.978, avg. samples / sec: 64849.12
Iteration:    360, Loss function: 5.765, Average Loss: 2.981, avg. samples / sec: 64986.92
Iteration:    360, Loss function: 7.396, Average Loss: 2.984, avg. samples / sec: 64907.15
Iteration:    360, Loss function: 6.947, Average Loss: 2.959, avg. samples / sec: 64968.40
Iteration:    360, Loss function: 7.836, Average Loss: 2.984, avg. samples / sec: 65088.40
Iteration:    360, Loss function: 5.426, Average Loss: 2.977, avg. samples / sec: 64871.87
Iteration:    360, Loss function: 7.260, Average Loss: 2.976, avg. samples / sec: 64884.95
Iteration:    360, Loss function: 7.693, Average Loss: 2.986, avg. samples / sec: 65059.25
Iteration:    360, Loss function: 6.653, Average Loss: 2.977, avg. samples / sec: 64778.56
Iteration:    360, Loss function: 7.404, Average Loss: 2.974, avg. samples / sec: 64816.34
Iteration:    360, Loss function: 8.365, Average Loss: 2.977, avg. samples / sec: 64909.45
Iteration:    360, Loss function: 6.528, Average Loss: 2.978, avg. samples / sec: 64891.79
Iteration:    360, Loss function: 7.781, Average Loss: 2.979, avg. samples / sec: 64967.92
Iteration:    360, Loss function: 7.295, Average Loss: 2.980, avg. samples / sec: 64839.60
Iteration:    360, Loss function: 6.397, Average Loss: 2.986, avg. samples / sec: 65033.25
Iteration:    360, Loss function: 7.735, Average Loss: 2.986, avg. samples / sec: 64973.11
Iteration:    360, Loss function: 5.612, Average Loss: 2.980, avg. samples / sec: 65002.53
Iteration:    360, Loss function: 6.818, Average Loss: 2.983, avg. samples / sec: 64884.44
Iteration:    360, Loss function: 6.479, Average Loss: 2.987, avg. samples / sec: 64657.48
Iteration:    380, Loss function: 6.723, Average Loss: 3.054, avg. samples / sec: 66295.26
Iteration:    380, Loss function: 5.579, Average Loss: 3.053, avg. samples / sec: 66284.23
Iteration:    380, Loss function: 6.824, Average Loss: 3.056, avg. samples / sec: 66375.35
Iteration:    380, Loss function: 6.351, Average Loss: 3.056, avg. samples / sec: 66119.31
Iteration:    380, Loss function: 6.556, Average Loss: 3.050, avg. samples / sec: 66229.34
Iteration:    380, Loss function: 7.020, Average Loss: 3.057, avg. samples / sec: 66156.99
Iteration:    380, Loss function: 7.069, Average Loss: 3.030, avg. samples / sec: 66248.80
Iteration:    380, Loss function: 6.310, Average Loss: 3.054, avg. samples / sec: 66100.67
Iteration:    380, Loss function: 7.125, Average Loss: 3.067, avg. samples / sec: 66328.90
Iteration:    380, Loss function: 6.535, Average Loss: 3.058, avg. samples / sec: 66160.41
Iteration:    380, Loss function: 7.367, Average Loss: 3.058, avg. samples / sec: 66289.62
Iteration:    380, Loss function: 6.161, Average Loss: 3.055, avg. samples / sec: 66326.50
Iteration:    380, Loss function: 6.921, Average Loss: 3.053, avg. samples / sec: 66260.13
Iteration:    380, Loss function: 6.754, Average Loss: 3.083, avg. samples / sec: 66046.12
Iteration:    380, Loss function: 8.745, Average Loss: 3.055, avg. samples / sec: 66203.86
Iteration:    380, Loss function: 8.118, Average Loss: 3.053, avg. samples / sec: 66245.12
Iteration:    380, Loss function: 6.714, Average Loss: 3.060, avg. samples / sec: 66158.79
Iteration:    380, Loss function: 6.518, Average Loss: 3.050, avg. samples / sec: 66198.69
Iteration:    380, Loss function: 6.682, Average Loss: 3.041, avg. samples / sec: 66116.49
Iteration:    380, Loss function: 6.018, Average Loss: 3.058, avg. samples / sec: 66272.97
Iteration:    380, Loss function: 6.500, Average Loss: 3.066, avg. samples / sec: 66086.16
Iteration:    380, Loss function: 6.506, Average Loss: 3.067, avg. samples / sec: 66226.23
Iteration:    380, Loss function: 6.334, Average Loss: 3.068, avg. samples / sec: 66270.70
Iteration:    380, Loss function: 5.979, Average Loss: 3.059, avg. samples / sec: 66092.95
Iteration:    380, Loss function: 6.535, Average Loss: 3.066, avg. samples / sec: 66004.58
Iteration:    380, Loss function: 6.613, Average Loss: 3.053, avg. samples / sec: 66044.14
Iteration:    380, Loss function: 6.670, Average Loss: 3.057, avg. samples / sec: 66019.97
Iteration:    380, Loss function: 6.704, Average Loss: 3.060, avg. samples / sec: 66076.03
Iteration:    380, Loss function: 6.549, Average Loss: 3.052, avg. samples / sec: 65957.50
Iteration:    380, Loss function: 6.488, Average Loss: 3.065, avg. samples / sec: 65948.58
Iteration:    400, Loss function: 6.733, Average Loss: 3.162, avg. samples / sec: 65284.05
Iteration:    400, Loss function: 7.483, Average Loss: 3.128, avg. samples / sec: 65198.46
Iteration:    400, Loss function: 7.201, Average Loss: 3.130, avg. samples / sec: 65134.21
Iteration:    400, Loss function: 7.112, Average Loss: 3.129, avg. samples / sec: 65259.81
Iteration:    400, Loss function: 7.820, Average Loss: 3.130, avg. samples / sec: 65331.54
Iteration:    400, Loss function: 8.102, Average Loss: 3.137, avg. samples / sec: 65298.06
Iteration:    400, Loss function: 6.846, Average Loss: 3.131, avg. samples / sec: 65072.05
Iteration:    400, Loss function: 6.983, Average Loss: 3.130, avg. samples / sec: 65200.08
Iteration:    400, Loss function: 7.352, Average Loss: 3.128, avg. samples / sec: 65200.54
Iteration:    400, Loss function: 5.809, Average Loss: 3.132, avg. samples / sec: 65377.57
Iteration:    400, Loss function: 5.577, Average Loss: 3.124, avg. samples / sec: 65110.32
Iteration:    400, Loss function: 7.097, Average Loss: 3.128, avg. samples / sec: 65166.14
Iteration:    400, Loss function: 6.997, Average Loss: 3.116, avg. samples / sec: 65198.28
Iteration:    400, Loss function: 7.237, Average Loss: 3.134, avg. samples / sec: 65169.93
Iteration:    400, Loss function: 7.611, Average Loss: 3.142, avg. samples / sec: 65270.47
Iteration:    400, Loss function: 6.322, Average Loss: 3.136, avg. samples / sec: 65135.87
Iteration:    400, Loss function: 6.240, Average Loss: 3.124, avg. samples / sec: 65128.34
Iteration:    400, Loss function: 7.333, Average Loss: 3.137, avg. samples / sec: 65112.45
Iteration:    400, Loss function: 6.646, Average Loss: 3.147, avg. samples / sec: 65361.38
Iteration:    400, Loss function: 6.476, Average Loss: 3.100, avg. samples / sec: 65050.93
Iteration:    400, Loss function: 7.624, Average Loss: 3.133, avg. samples / sec: 65202.14
Iteration:    400, Loss function: 5.947, Average Loss: 3.130, avg. samples / sec: 65009.70
Iteration:    400, Loss function: 7.419, Average Loss: 3.133, avg. samples / sec: 65021.28
Iteration:    400, Loss function: 7.296, Average Loss: 3.125, avg. samples / sec: 65331.50
Iteration:    400, Loss function: 7.072, Average Loss: 3.124, avg. samples / sec: 65121.12
Iteration:    400, Loss function: 6.562, Average Loss: 3.129, avg. samples / sec: 65081.06
Iteration:    400, Loss function: 7.401, Average Loss: 3.143, avg. samples / sec: 65148.33
Iteration:    400, Loss function: 7.143, Average Loss: 3.145, avg. samples / sec: 65089.30
Iteration:    400, Loss function: 5.979, Average Loss: 3.130, avg. samples / sec: 65186.45
Iteration:    400, Loss function: 6.347, Average Loss: 3.141, avg. samples / sec: 64973.94
:::MLL 1558651869.015 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558651869.016 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 7.566, Average Loss: 3.201, avg. samples / sec: 66479.49
Iteration:    420, Loss function: 7.224, Average Loss: 3.216, avg. samples / sec: 66437.18
Iteration:    420, Loss function: 6.570, Average Loss: 3.203, avg. samples / sec: 66356.57
Iteration:    420, Loss function: 6.418, Average Loss: 3.208, avg. samples / sec: 66399.46
Iteration:    420, Loss function: 6.109, Average Loss: 3.209, avg. samples / sec: 66327.62
Iteration:    420, Loss function: 6.095, Average Loss: 3.238, avg. samples / sec: 66248.39
Iteration:    420, Loss function: 7.500, Average Loss: 3.214, avg. samples / sec: 66523.24
Iteration:    420, Loss function: 8.121, Average Loss: 3.200, avg. samples / sec: 66387.61
Iteration:    420, Loss function: 5.523, Average Loss: 3.204, avg. samples / sec: 66284.44
Iteration:    420, Loss function: 5.104, Average Loss: 3.186, avg. samples / sec: 66322.84
Iteration:    420, Loss function: 6.295, Average Loss: 3.199, avg. samples / sec: 66266.55
Iteration:    420, Loss function: 6.026, Average Loss: 3.204, avg. samples / sec: 66325.68
Iteration:    420, Loss function: 7.857, Average Loss: 3.202, avg. samples / sec: 66377.67
Iteration:    420, Loss function: 6.799, Average Loss: 3.173, avg. samples / sec: 66335.61
Iteration:    420, Loss function: 6.001, Average Loss: 3.201, avg. samples / sec: 66422.91
Iteration:    420, Loss function: 6.964, Average Loss: 3.217, avg. samples / sec: 66357.57
Iteration:    420, Loss function: 7.059, Average Loss: 3.202, avg. samples / sec: 66201.90
Iteration:    420, Loss function: 7.238, Average Loss: 3.199, avg. samples / sec: 66247.55
Iteration:    420, Loss function: 6.360, Average Loss: 3.217, avg. samples / sec: 66398.09
Iteration:    420, Loss function: 7.194, Average Loss: 3.202, avg. samples / sec: 66126.69
Iteration:    420, Loss function: 6.901, Average Loss: 3.208, avg. samples / sec: 66331.43
Iteration:    420, Loss function: 6.640, Average Loss: 3.197, avg. samples / sec: 66144.57
Iteration:    420, Loss function: 6.810, Average Loss: 3.197, avg. samples / sec: 66304.78
Iteration:    420, Loss function: 6.710, Average Loss: 3.205, avg. samples / sec: 66204.26
Iteration:    420, Loss function: 6.203, Average Loss: 3.209, avg. samples / sec: 66261.16
Iteration:    420, Loss function: 6.846, Average Loss: 3.199, avg. samples / sec: 66181.38
Iteration:    420, Loss function: 6.658, Average Loss: 3.212, avg. samples / sec: 66224.76
Iteration:    420, Loss function: 7.260, Average Loss: 3.197, avg. samples / sec: 66243.35
Iteration:    420, Loss function: 7.310, Average Loss: 3.218, avg. samples / sec: 66090.53
Iteration:    420, Loss function: 6.205, Average Loss: 3.199, avg. samples / sec: 65948.82
Iteration:    440, Loss function: 6.998, Average Loss: 3.271, avg. samples / sec: 65203.37
Iteration:    440, Loss function: 5.887, Average Loss: 3.270, avg. samples / sec: 65371.23
Iteration:    440, Loss function: 6.504, Average Loss: 3.277, avg. samples / sec: 65227.00
Iteration:    440, Loss function: 6.753, Average Loss: 3.275, avg. samples / sec: 65362.02
Iteration:    440, Loss function: 7.953, Average Loss: 3.285, avg. samples / sec: 65232.04
Iteration:    440, Loss function: 6.203, Average Loss: 3.281, avg. samples / sec: 65309.16
Iteration:    440, Loss function: 6.774, Average Loss: 3.279, avg. samples / sec: 65196.19
Iteration:    440, Loss function: 6.136, Average Loss: 3.271, avg. samples / sec: 65313.13
Iteration:    440, Loss function: 5.720, Average Loss: 3.270, avg. samples / sec: 65275.80
Iteration:    440, Loss function: 7.426, Average Loss: 3.314, avg. samples / sec: 65176.26
Iteration:    440, Loss function: 7.072, Average Loss: 3.271, avg. samples / sec: 65352.17
Iteration:    440, Loss function: 6.054, Average Loss: 3.276, avg. samples / sec: 65116.70
Iteration:    440, Loss function: 6.032, Average Loss: 3.271, avg. samples / sec: 65276.01
Iteration:    440, Loss function: 6.473, Average Loss: 3.289, avg. samples / sec: 65101.75
Iteration:    440, Loss function: 5.442, Average Loss: 3.273, avg. samples / sec: 65196.34
Iteration:    440, Loss function: 6.871, Average Loss: 3.278, avg. samples / sec: 65285.71
Iteration:    440, Loss function: 6.428, Average Loss: 3.283, avg. samples / sec: 65246.18
Iteration:    440, Loss function: 7.981, Average Loss: 3.248, avg. samples / sec: 65187.99
Iteration:    440, Loss function: 6.948, Average Loss: 3.291, avg. samples / sec: 65175.00
Iteration:    440, Loss function: 7.590, Average Loss: 3.280, avg. samples / sec: 65123.50
Iteration:    440, Loss function: 6.237, Average Loss: 3.290, avg. samples / sec: 65399.11
Iteration:    440, Loss function: 7.500, Average Loss: 3.275, avg. samples / sec: 65409.22
Iteration:    440, Loss function: 8.638, Average Loss: 3.275, avg. samples / sec: 65089.36
Iteration:    440, Loss function: 6.565, Average Loss: 3.256, avg. samples / sec: 65068.92
Iteration:    440, Loss function: 6.384, Average Loss: 3.284, avg. samples / sec: 65156.80
Iteration:    440, Loss function: 6.122, Average Loss: 3.285, avg. samples / sec: 65107.85
Iteration:    440, Loss function: 6.287, Average Loss: 3.269, avg. samples / sec: 65089.87
Iteration:    440, Loss function: 7.160, Average Loss: 3.275, avg. samples / sec: 65099.52
Iteration:    440, Loss function: 7.585, Average Loss: 3.286, avg. samples / sec: 65118.44
Iteration:    440, Loss function: 6.656, Average Loss: 3.285, avg. samples / sec: 65012.94
Iteration:    460, Loss function: 6.283, Average Loss: 3.341, avg. samples / sec: 66040.98
Iteration:    460, Loss function: 7.762, Average Loss: 3.346, avg. samples / sec: 66085.45
Iteration:    460, Loss function: 6.328, Average Loss: 3.345, avg. samples / sec: 65952.25
Iteration:    460, Loss function: 6.361, Average Loss: 3.318, avg. samples / sec: 66171.75
Iteration:    460, Loss function: 5.705, Average Loss: 3.338, avg. samples / sec: 66120.98
Iteration:    460, Loss function: 6.591, Average Loss: 3.334, avg. samples / sec: 65966.79
Iteration:    460, Loss function: 6.811, Average Loss: 3.357, avg. samples / sec: 66087.16
Iteration:    460, Loss function: 6.317, Average Loss: 3.338, avg. samples / sec: 65970.34
Iteration:    460, Loss function: 6.008, Average Loss: 3.350, avg. samples / sec: 65938.02
Iteration:    460, Loss function: 6.175, Average Loss: 3.381, avg. samples / sec: 65949.60
Iteration:    460, Loss function: 5.441, Average Loss: 3.345, avg. samples / sec: 66102.62
Iteration:    460, Loss function: 6.684, Average Loss: 3.357, avg. samples / sec: 66141.87
Iteration:    460, Loss function: 6.463, Average Loss: 3.345, avg. samples / sec: 65998.39
Iteration:    460, Loss function: 6.430, Average Loss: 3.352, avg. samples / sec: 65974.79
Iteration:    460, Loss function: 5.957, Average Loss: 3.349, avg. samples / sec: 65914.99
Iteration:    460, Loss function: 6.673, Average Loss: 3.343, avg. samples / sec: 65872.19
Iteration:    460, Loss function: 7.088, Average Loss: 3.343, avg. samples / sec: 65971.36
Iteration:    460, Loss function: 6.796, Average Loss: 3.344, avg. samples / sec: 66113.17
Iteration:    460, Loss function: 6.129, Average Loss: 3.352, avg. samples / sec: 66137.24
Iteration:    460, Loss function: 5.980, Average Loss: 3.348, avg. samples / sec: 65974.51
Iteration:    460, Loss function: 5.899, Average Loss: 3.352, avg. samples / sec: 66170.94
Iteration:    460, Loss function: 5.141, Average Loss: 3.334, avg. samples / sec: 65949.19
Iteration:    460, Loss function: 5.069, Average Loss: 3.362, avg. samples / sec: 65996.94
Iteration:    460, Loss function: 6.670, Average Loss: 3.311, avg. samples / sec: 65976.70
Iteration:    460, Loss function: 5.469, Average Loss: 3.341, avg. samples / sec: 65903.83
Iteration:    460, Loss function: 6.280, Average Loss: 3.337, avg. samples / sec: 65796.14
Iteration:    460, Loss function: 6.140, Average Loss: 3.340, avg. samples / sec: 66020.22
Iteration:    460, Loss function: 5.381, Average Loss: 3.353, avg. samples / sec: 66028.30
Iteration:    460, Loss function: 6.478, Average Loss: 3.356, avg. samples / sec: 65801.57
Iteration:    460, Loss function: 6.778, Average Loss: 3.346, avg. samples / sec: 65906.91
Iteration:    480, Loss function: 7.091, Average Loss: 3.407, avg. samples / sec: 65856.77
Iteration:    480, Loss function: 8.459, Average Loss: 3.402, avg. samples / sec: 65832.34
Iteration:    480, Loss function: 6.203, Average Loss: 3.419, avg. samples / sec: 65995.30
Iteration:    480, Loss function: 6.598, Average Loss: 3.422, avg. samples / sec: 65815.10
Iteration:    480, Loss function: 6.978, Average Loss: 3.405, avg. samples / sec: 65875.43
Iteration:    480, Loss function: 6.381, Average Loss: 3.395, avg. samples / sec: 65886.91
Iteration:    480, Loss function: 5.510, Average Loss: 3.398, avg. samples / sec: 65644.80
Iteration:    480, Loss function: 5.834, Average Loss: 3.396, avg. samples / sec: 65779.58
Iteration:    480, Loss function: 6.991, Average Loss: 3.404, avg. samples / sec: 65720.32
Iteration:    480, Loss function: 5.512, Average Loss: 3.402, avg. samples / sec: 65862.28
Iteration:    480, Loss function: 5.844, Average Loss: 3.409, avg. samples / sec: 65795.83
Iteration:    480, Loss function: 5.910, Average Loss: 3.400, avg. samples / sec: 65739.66
Iteration:    480, Loss function: 6.291, Average Loss: 3.407, avg. samples / sec: 65795.80
Iteration:    480, Loss function: 7.102, Average Loss: 3.408, avg. samples / sec: 65766.23
Iteration:    480, Loss function: 6.990, Average Loss: 3.408, avg. samples / sec: 65905.83
Iteration:    480, Loss function: 6.525, Average Loss: 3.414, avg. samples / sec: 65718.27
Iteration:    480, Loss function: 6.545, Average Loss: 3.417, avg. samples / sec: 65794.45
Iteration:    480, Loss function: 5.800, Average Loss: 3.371, avg. samples / sec: 65693.67
Iteration:    480, Loss function: 6.355, Average Loss: 3.414, avg. samples / sec: 65831.70
Iteration:    480, Loss function: 6.661, Average Loss: 3.405, avg. samples / sec: 65745.80
Iteration:    480, Loss function: 6.889, Average Loss: 3.393, avg. samples / sec: 65801.27
Iteration:    480, Loss function: 6.423, Average Loss: 3.439, avg. samples / sec: 65704.66
Iteration:    480, Loss function: 6.962, Average Loss: 3.372, avg. samples / sec: 65786.37
Iteration:    480, Loss function: 6.708, Average Loss: 3.407, avg. samples / sec: 65762.55
Iteration:    480, Loss function: 5.887, Average Loss: 3.414, avg. samples / sec: 65696.27
Iteration:    480, Loss function: 7.122, Average Loss: 3.403, avg. samples / sec: 65797.12
Iteration:    480, Loss function: 7.291, Average Loss: 3.411, avg. samples / sec: 65716.67
Iteration:    480, Loss function: 6.459, Average Loss: 3.407, avg. samples / sec: 65662.41
Iteration:    480, Loss function: 8.360, Average Loss: 3.409, avg. samples / sec: 65600.64
Iteration:    480, Loss function: 6.278, Average Loss: 3.420, avg. samples / sec: 65697.86
:::MLL 1558651870.806 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558651870.806 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 6.302, Average Loss: 3.449, avg. samples / sec: 66097.01
Iteration:    500, Loss function: 6.769, Average Loss: 3.457, avg. samples / sec: 65925.90
Iteration:    500, Loss function: 5.228, Average Loss: 3.466, avg. samples / sec: 65848.15
Iteration:    500, Loss function: 6.247, Average Loss: 3.481, avg. samples / sec: 65855.85
Iteration:    500, Loss function: 5.418, Average Loss: 3.504, avg. samples / sec: 66004.17
Iteration:    500, Loss function: 6.317, Average Loss: 3.472, avg. samples / sec: 66028.73
Iteration:    500, Loss function: 6.505, Average Loss: 3.463, avg. samples / sec: 65896.68
Iteration:    500, Loss function: 6.128, Average Loss: 3.464, avg. samples / sec: 65833.42
Iteration:    500, Loss function: 5.981, Average Loss: 3.472, avg. samples / sec: 66031.82
Iteration:    500, Loss function: 6.767, Average Loss: 3.465, avg. samples / sec: 65889.84
Iteration:    500, Loss function: 6.981, Average Loss: 3.466, avg. samples / sec: 66015.99
Iteration:    500, Loss function: 6.153, Average Loss: 3.463, avg. samples / sec: 65800.35
Iteration:    500, Loss function: 6.583, Average Loss: 3.433, avg. samples / sec: 65946.08
Iteration:    500, Loss function: 6.918, Average Loss: 3.474, avg. samples / sec: 65916.87
Iteration:    500, Loss function: 7.677, Average Loss: 3.472, avg. samples / sec: 65877.40
Iteration:    500, Loss function: 6.029, Average Loss: 3.457, avg. samples / sec: 65845.57
Iteration:    500, Loss function: 6.410, Average Loss: 3.474, avg. samples / sec: 65974.91
Iteration:    500, Loss function: 6.535, Average Loss: 3.469, avg. samples / sec: 65889.50
Iteration:    500, Loss function: 7.132, Average Loss: 3.476, avg. samples / sec: 65895.38
Iteration:    500, Loss function: 5.811, Average Loss: 3.460, avg. samples / sec: 65771.33
Iteration:    500, Loss function: 6.005, Average Loss: 3.482, avg. samples / sec: 65742.79
Iteration:    500, Loss function: 7.426, Average Loss: 3.437, avg. samples / sec: 65850.98
Iteration:    500, Loss function: 5.581, Average Loss: 3.466, avg. samples / sec: 65861.57
Iteration:    500, Loss function: 6.377, Average Loss: 3.469, avg. samples / sec: 65806.03
Iteration:    500, Loss function: 6.110, Average Loss: 3.480, avg. samples / sec: 65914.56
Iteration:    500, Loss function: 7.246, Average Loss: 3.459, avg. samples / sec: 65763.74
Iteration:    500, Loss function: 6.273, Average Loss: 3.468, avg. samples / sec: 65857.94
Iteration:    500, Loss function: 6.305, Average Loss: 3.469, avg. samples / sec: 65772.09
Iteration:    500, Loss function: 6.227, Average Loss: 3.479, avg. samples / sec: 65728.59
Iteration:    500, Loss function: 5.989, Average Loss: 3.470, avg. samples / sec: 65667.89
Iteration:    520, Loss function: 6.044, Average Loss: 3.524, avg. samples / sec: 66319.82
Iteration:    520, Loss function: 6.414, Average Loss: 3.543, avg. samples / sec: 66249.20
Iteration:    520, Loss function: 6.677, Average Loss: 3.520, avg. samples / sec: 66265.34
Iteration:    520, Loss function: 5.613, Average Loss: 3.517, avg. samples / sec: 66237.00
Iteration:    520, Loss function: 4.642, Average Loss: 3.529, avg. samples / sec: 66257.99
Iteration:    520, Loss function: 6.436, Average Loss: 3.522, avg. samples / sec: 66221.59
Iteration:    520, Loss function: 6.384, Average Loss: 3.523, avg. samples / sec: 66300.60
Iteration:    520, Loss function: 5.699, Average Loss: 3.526, avg. samples / sec: 66220.94
Iteration:    520, Loss function: 6.419, Average Loss: 3.536, avg. samples / sec: 66276.09
Iteration:    520, Loss function: 6.545, Average Loss: 3.513, avg. samples / sec: 66146.56
Iteration:    520, Loss function: 6.792, Average Loss: 3.523, avg. samples / sec: 66198.01
Iteration:    520, Loss function: 6.458, Average Loss: 3.526, avg. samples / sec: 66354.76
Iteration:    520, Loss function: 6.480, Average Loss: 3.529, avg. samples / sec: 66174.79
Iteration:    520, Loss function: 5.826, Average Loss: 3.515, avg. samples / sec: 66190.74
Iteration:    520, Loss function: 5.854, Average Loss: 3.487, avg. samples / sec: 66175.94
Iteration:    520, Loss function: 6.452, Average Loss: 3.534, avg. samples / sec: 66358.76
Iteration:    520, Loss function: 5.395, Average Loss: 3.533, avg. samples / sec: 66192.10
Iteration:    520, Loss function: 6.937, Average Loss: 3.526, avg. samples / sec: 66118.69
Iteration:    520, Loss function: 6.380, Average Loss: 3.532, avg. samples / sec: 66235.81
Iteration:    520, Loss function: 5.855, Average Loss: 3.520, avg. samples / sec: 66190.42
Iteration:    520, Loss function: 5.540, Average Loss: 3.531, avg. samples / sec: 66159.51
Iteration:    520, Loss function: 6.397, Average Loss: 3.525, avg. samples / sec: 66236.44
Iteration:    520, Loss function: 5.498, Average Loss: 3.523, avg. samples / sec: 66048.81
Iteration:    520, Loss function: 6.313, Average Loss: 3.536, avg. samples / sec: 66296.64
Iteration:    520, Loss function: 5.499, Average Loss: 3.553, avg. samples / sec: 66014.13
Iteration:    520, Loss function: 6.103, Average Loss: 3.525, avg. samples / sec: 66151.09
Iteration:    520, Loss function: 5.972, Average Loss: 3.523, avg. samples / sec: 66040.36
Iteration:    520, Loss function: 6.163, Average Loss: 3.516, avg. samples / sec: 66146.96
Iteration:    520, Loss function: 6.150, Average Loss: 3.495, avg. samples / sec: 66098.28
Iteration:    520, Loss function: 6.097, Average Loss: 3.506, avg. samples / sec: 65828.13
Iteration:    540, Loss function: 7.315, Average Loss: 3.563, avg. samples / sec: 66613.32
Iteration:    540, Loss function: 6.637, Average Loss: 3.580, avg. samples / sec: 66239.95
Iteration:    540, Loss function: 6.488, Average Loss: 3.565, avg. samples / sec: 66362.63
Iteration:    540, Loss function: 6.665, Average Loss: 3.573, avg. samples / sec: 66449.87
Iteration:    540, Loss function: 8.714, Average Loss: 3.536, avg. samples / sec: 66357.66
Iteration:    540, Loss function: 5.269, Average Loss: 3.574, avg. samples / sec: 66263.16
Iteration:    540, Loss function: 6.416, Average Loss: 3.571, avg. samples / sec: 66296.32
Iteration:    540, Loss function: 6.290, Average Loss: 3.560, avg. samples / sec: 66266.62
Iteration:    540, Loss function: 5.831, Average Loss: 3.571, avg. samples / sec: 66440.88
Iteration:    540, Loss function: 5.519, Average Loss: 3.573, avg. samples / sec: 66227.78
Iteration:    540, Loss function: 5.616, Average Loss: 3.583, avg. samples / sec: 66315.73
Iteration:    540, Loss function: 5.290, Average Loss: 3.584, avg. samples / sec: 66227.78
Iteration:    540, Loss function: 5.835, Average Loss: 3.572, avg. samples / sec: 66212.35
Iteration:    540, Loss function: 5.481, Average Loss: 3.593, avg. samples / sec: 66217.89
Iteration:    540, Loss function: 6.293, Average Loss: 3.567, avg. samples / sec: 66406.63
Iteration:    540, Loss function: 5.445, Average Loss: 3.571, avg. samples / sec: 66162.12
Iteration:    540, Loss function: 6.259, Average Loss: 3.602, avg. samples / sec: 66360.69
Iteration:    540, Loss function: 5.921, Average Loss: 3.573, avg. samples / sec: 66227.04
Iteration:    540, Loss function: 5.357, Average Loss: 3.577, avg. samples / sec: 66290.93
Iteration:    540, Loss function: 5.875, Average Loss: 3.590, avg. samples / sec: 66329.84
Iteration:    540, Loss function: 5.393, Average Loss: 3.581, avg. samples / sec: 66266.86
Iteration:    540, Loss function: 6.570, Average Loss: 3.550, avg. samples / sec: 66382.58
Iteration:    540, Loss function: 6.442, Average Loss: 3.578, avg. samples / sec: 66281.42
Iteration:    540, Loss function: 6.393, Average Loss: 3.574, avg. samples / sec: 66259.70
Iteration:    540, Loss function: 5.000, Average Loss: 3.582, avg. samples / sec: 66237.65
Iteration:    540, Loss function: 5.638, Average Loss: 3.575, avg. samples / sec: 66164.72
Iteration:    540, Loss function: 5.988, Average Loss: 3.577, avg. samples / sec: 66306.96
Iteration:    540, Loss function: 7.771, Average Loss: 3.593, avg. samples / sec: 65998.15
Iteration:    540, Loss function: 6.958, Average Loss: 3.580, avg. samples / sec: 66049.12
Iteration:    540, Loss function: 6.231, Average Loss: 3.573, avg. samples / sec: 66069.68
:::MLL 1558651872.586 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558651872.586 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 7.131, Average Loss: 3.639, avg. samples / sec: 66012.43
Iteration:    560, Loss function: 6.203, Average Loss: 3.626, avg. samples / sec: 65977.60
Iteration:    560, Loss function: 5.919, Average Loss: 3.634, avg. samples / sec: 66071.35
Iteration:    560, Loss function: 6.806, Average Loss: 3.626, avg. samples / sec: 66040.46
Iteration:    560, Loss function: 6.137, Average Loss: 3.620, avg. samples / sec: 65803.23
Iteration:    560, Loss function: 6.438, Average Loss: 3.632, avg. samples / sec: 66033.49
Iteration:    560, Loss function: 4.808, Average Loss: 3.632, avg. samples / sec: 66129.86
Iteration:    560, Loss function: 6.052, Average Loss: 3.619, avg. samples / sec: 65936.30
Iteration:    560, Loss function: 6.146, Average Loss: 3.627, avg. samples / sec: 65902.93
Iteration:    560, Loss function: 5.064, Average Loss: 3.636, avg. samples / sec: 65773.14
Iteration:    560, Loss function: 6.229, Average Loss: 3.642, avg. samples / sec: 65920.38
Iteration:    560, Loss function: 5.389, Average Loss: 3.627, avg. samples / sec: 66102.62
Iteration:    560, Loss function: 5.996, Average Loss: 3.625, avg. samples / sec: 65935.19
Iteration:    560, Loss function: 5.424, Average Loss: 3.645, avg. samples / sec: 66027.71
Iteration:    560, Loss function: 6.005, Average Loss: 3.642, avg. samples / sec: 65880.20
Iteration:    560, Loss function: 6.067, Average Loss: 3.624, avg. samples / sec: 65808.58
Iteration:    560, Loss function: 5.456, Average Loss: 3.619, avg. samples / sec: 65761.38
Iteration:    560, Loss function: 5.426, Average Loss: 3.652, avg. samples / sec: 65880.11
Iteration:    560, Loss function: 5.531, Average Loss: 3.625, avg. samples / sec: 65854.95
Iteration:    560, Loss function: 5.083, Average Loss: 3.629, avg. samples / sec: 65785.17
Iteration:    560, Loss function: 5.520, Average Loss: 3.629, avg. samples / sec: 65710.11
Iteration:    560, Loss function: 6.611, Average Loss: 3.614, avg. samples / sec: 65723.51
Iteration:    560, Loss function: 5.859, Average Loss: 3.590, avg. samples / sec: 65669.76
Iteration:    560, Loss function: 6.060, Average Loss: 3.623, avg. samples / sec: 65726.02
Iteration:    560, Loss function: 5.181, Average Loss: 3.636, avg. samples / sec: 65695.41
Iteration:    560, Loss function: 7.087, Average Loss: 3.631, avg. samples / sec: 65733.10
Iteration:    560, Loss function: 5.285, Average Loss: 3.623, avg. samples / sec: 65654.86
Iteration:    560, Loss function: 5.275, Average Loss: 3.629, avg. samples / sec: 65590.48
Iteration:    560, Loss function: 6.167, Average Loss: 3.634, avg. samples / sec: 65681.08
Iteration:    560, Loss function: 6.195, Average Loss: 3.608, avg. samples / sec: 65632.35
Iteration:    580, Loss function: 5.950, Average Loss: 3.671, avg. samples / sec: 66360.23
Iteration:    580, Loss function: 5.255, Average Loss: 3.681, avg. samples / sec: 66314.92
Iteration:    580, Loss function: 6.493, Average Loss: 3.665, avg. samples / sec: 66314.42
Iteration:    580, Loss function: 6.078, Average Loss: 3.674, avg. samples / sec: 66332.05
Iteration:    580, Loss function: 5.700, Average Loss: 3.664, avg. samples / sec: 66336.70
Iteration:    580, Loss function: 5.503, Average Loss: 3.688, avg. samples / sec: 66503.30
Iteration:    580, Loss function: 6.666, Average Loss: 3.699, avg. samples / sec: 66331.30
Iteration:    580, Loss function: 5.608, Average Loss: 3.668, avg. samples / sec: 66239.33
Iteration:    580, Loss function: 5.898, Average Loss: 3.672, avg. samples / sec: 66360.07
Iteration:    580, Loss function: 5.778, Average Loss: 3.674, avg. samples / sec: 66524.24
Iteration:    580, Loss function: 6.089, Average Loss: 3.682, avg. samples / sec: 66165.91
Iteration:    580, Loss function: 5.887, Average Loss: 3.676, avg. samples / sec: 66325.84
Iteration:    580, Loss function: 6.539, Average Loss: 3.684, avg. samples / sec: 66232.17
Iteration:    580, Loss function: 5.997, Average Loss: 3.664, avg. samples / sec: 66372.04
Iteration:    580, Loss function: 6.137, Average Loss: 3.671, avg. samples / sec: 66253.13
Iteration:    580, Loss function: 5.197, Average Loss: 3.684, avg. samples / sec: 66203.33
Iteration:    580, Loss function: 5.363, Average Loss: 3.692, avg. samples / sec: 66227.66
Iteration:    580, Loss function: 6.610, Average Loss: 3.672, avg. samples / sec: 66391.30
Iteration:    580, Loss function: 5.797, Average Loss: 3.674, avg. samples / sec: 66147.95
Iteration:    580, Loss function: 5.955, Average Loss: 3.672, avg. samples / sec: 66455.54
Iteration:    580, Loss function: 5.058, Average Loss: 3.683, avg. samples / sec: 66270.26
Iteration:    580, Loss function: 6.211, Average Loss: 3.677, avg. samples / sec: 66052.84
Iteration:    580, Loss function: 5.650, Average Loss: 3.659, avg. samples / sec: 66470.49
Iteration:    580, Loss function: 6.508, Average Loss: 3.677, avg. samples / sec: 66169.66
Iteration:    580, Loss function: 5.113, Average Loss: 3.675, avg. samples / sec: 66382.79
Iteration:    580, Loss function: 5.049, Average Loss: 3.692, avg. samples / sec: 66151.15
Iteration:    580, Loss function: 5.499, Average Loss: 3.687, avg. samples / sec: 66376.54
Iteration:    580, Loss function: 5.315, Average Loss: 3.671, avg. samples / sec: 66017.56
Iteration:    580, Loss function: 7.348, Average Loss: 3.636, avg. samples / sec: 66218.66
Iteration:    580, Loss function: 5.859, Average Loss: 3.686, avg. samples / sec: 65922.20
Iteration:    600, Loss function: 5.794, Average Loss: 3.713, avg. samples / sec: 66415.27
Iteration:    600, Loss function: 5.420, Average Loss: 3.730, avg. samples / sec: 66461.15
Iteration:    600, Loss function: 5.387, Average Loss: 3.726, avg. samples / sec: 66646.87
Iteration:    600, Loss function: 5.847, Average Loss: 3.719, avg. samples / sec: 66280.61
Iteration:    600, Loss function: 6.320, Average Loss: 3.710, avg. samples / sec: 66284.44
Iteration:    600, Loss function: 5.545, Average Loss: 3.713, avg. samples / sec: 66328.87
Iteration:    600, Loss function: 6.346, Average Loss: 3.716, avg. samples / sec: 66335.24
Iteration:    600, Loss function: 5.990, Average Loss: 3.715, avg. samples / sec: 66424.41
Iteration:    600, Loss function: 6.271, Average Loss: 3.720, avg. samples / sec: 66393.77
Iteration:    600, Loss function: 6.232, Average Loss: 3.745, avg. samples / sec: 66303.19
Iteration:    600, Loss function: 4.902, Average Loss: 3.701, avg. samples / sec: 66462.00
Iteration:    600, Loss function: 7.181, Average Loss: 3.726, avg. samples / sec: 66394.02
Iteration:    600, Loss function: 6.184, Average Loss: 3.734, avg. samples / sec: 66293.05
Iteration:    600, Loss function: 6.933, Average Loss: 3.727, avg. samples / sec: 66219.69
Iteration:    600, Loss function: 5.458, Average Loss: 3.722, avg. samples / sec: 66484.35
Iteration:    600, Loss function: 5.073, Average Loss: 3.731, avg. samples / sec: 66368.73
Iteration:    600, Loss function: 5.782, Average Loss: 3.720, avg. samples / sec: 66401.37
Iteration:    600, Loss function: 6.417, Average Loss: 3.733, avg. samples / sec: 66351.01
Iteration:    600, Loss function: 4.761, Average Loss: 3.718, avg. samples / sec: 66272.01
Iteration:    600, Loss function: 5.988, Average Loss: 3.687, avg. samples / sec: 66481.44
Iteration:    600, Loss function: 6.760, Average Loss: 3.728, avg. samples / sec: 66372.07
Iteration:    600, Loss function: 5.697, Average Loss: 3.714, avg. samples / sec: 66319.07
Iteration:    600, Loss function: 6.826, Average Loss: 3.716, avg. samples / sec: 66199.13
Iteration:    600, Loss function: 5.216, Average Loss: 3.726, avg. samples / sec: 66254.93
Iteration:    600, Loss function: 6.039, Average Loss: 3.723, avg. samples / sec: 66271.23
Iteration:    600, Loss function: 5.433, Average Loss: 3.731, avg. samples / sec: 66395.74
Iteration:    600, Loss function: 5.761, Average Loss: 3.723, avg. samples / sec: 66336.49
Iteration:    600, Loss function: 4.650, Average Loss: 3.709, avg. samples / sec: 66260.88
Iteration:    600, Loss function: 5.980, Average Loss: 3.733, avg. samples / sec: 66354.79
Iteration:    600, Loss function: 5.978, Average Loss: 3.728, avg. samples / sec: 66265.40
Iteration:    620, Loss function: 5.458, Average Loss: 3.758, avg. samples / sec: 66679.23
Iteration:    620, Loss function: 5.238, Average Loss: 3.772, avg. samples / sec: 66531.94
Iteration:    620, Loss function: 6.118, Average Loss: 3.752, avg. samples / sec: 66703.47
Iteration:    620, Loss function: 7.037, Average Loss: 3.771, avg. samples / sec: 66618.77
Iteration:    620, Loss function: 6.456, Average Loss: 3.767, avg. samples / sec: 66534.36
Iteration:    620, Loss function: 5.939, Average Loss: 3.760, avg. samples / sec: 66478.08
Iteration:    620, Loss function: 5.342, Average Loss: 3.774, avg. samples / sec: 66583.93
Iteration:    620, Loss function: 6.640, Average Loss: 3.756, avg. samples / sec: 66514.42
Iteration:    620, Loss function: 5.761, Average Loss: 3.763, avg. samples / sec: 66636.79
Iteration:    620, Loss function: 6.066, Average Loss: 3.771, avg. samples / sec: 66586.57
Iteration:    620, Loss function: 4.775, Average Loss: 3.757, avg. samples / sec: 66381.95
Iteration:    620, Loss function: 6.834, Average Loss: 3.759, avg. samples / sec: 66593.02
Iteration:    620, Loss function: 6.541, Average Loss: 3.774, avg. samples / sec: 66548.75
Iteration:    620, Loss function: 6.518, Average Loss: 3.731, avg. samples / sec: 66548.27
Iteration:    620, Loss function: 5.414, Average Loss: 3.767, avg. samples / sec: 66577.01
Iteration:    620, Loss function: 7.351, Average Loss: 3.789, avg. samples / sec: 66490.16
Iteration:    620, Loss function: 5.613, Average Loss: 3.769, avg. samples / sec: 66387.64
Iteration:    620, Loss function: 5.632, Average Loss: 3.750, avg. samples / sec: 66431.08
Iteration:    620, Loss function: 5.407, Average Loss: 3.764, avg. samples / sec: 66470.84
Iteration:    620, Loss function: 5.864, Average Loss: 3.769, avg. samples / sec: 66553.33
Iteration:    620, Loss function: 5.893, Average Loss: 3.761, avg. samples / sec: 66480.59
Iteration:    620, Loss function: 5.825, Average Loss: 3.746, avg. samples / sec: 66427.35
Iteration:    620, Loss function: 5.216, Average Loss: 3.772, avg. samples / sec: 66570.00
Iteration:    620, Loss function: 4.984, Average Loss: 3.773, avg. samples / sec: 66416.49
Iteration:    620, Loss function: 6.380, Average Loss: 3.767, avg. samples / sec: 66507.20
Iteration:    620, Loss function: 4.987, Average Loss: 3.759, avg. samples / sec: 66448.74
Iteration:    620, Loss function: 5.324, Average Loss: 3.761, avg. samples / sec: 66486.74
Iteration:    620, Loss function: 5.312, Average Loss: 3.776, avg. samples / sec: 66501.42
Iteration:    620, Loss function: 6.056, Average Loss: 3.761, avg. samples / sec: 66351.92
Iteration:    620, Loss function: 4.938, Average Loss: 3.758, avg. samples / sec: 66415.61
:::MLL 1558651874.360 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558651874.360 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 5.611, Average Loss: 3.815, avg. samples / sec: 65996.66
Iteration:    640, Loss function: 5.899, Average Loss: 3.827, avg. samples / sec: 65999.48
Iteration:    640, Loss function: 5.179, Average Loss: 3.820, avg. samples / sec: 65831.73
Iteration:    640, Loss function: 5.208, Average Loss: 3.815, avg. samples / sec: 65881.15
Iteration:    640, Loss function: 5.966, Average Loss: 3.809, avg. samples / sec: 66020.69
Iteration:    640, Loss function: 7.012, Average Loss: 3.805, avg. samples / sec: 66049.12
Iteration:    640, Loss function: 5.221, Average Loss: 3.804, avg. samples / sec: 65964.69
Iteration:    640, Loss function: 5.703, Average Loss: 3.796, avg. samples / sec: 65885.87
Iteration:    640, Loss function: 5.795, Average Loss: 3.778, avg. samples / sec: 65927.75
Iteration:    640, Loss function: 6.634, Average Loss: 3.801, avg. samples / sec: 65887.99
Iteration:    640, Loss function: 5.531, Average Loss: 3.788, avg. samples / sec: 65974.05
Iteration:    640, Loss function: 5.174, Average Loss: 3.791, avg. samples / sec: 65929.48
Iteration:    640, Loss function: 5.852, Average Loss: 3.809, avg. samples / sec: 66045.59
Iteration:    640, Loss function: 5.443, Average Loss: 3.801, avg. samples / sec: 66011.35
Iteration:    640, Loss function: 6.139, Average Loss: 3.794, avg. samples / sec: 65900.62
Iteration:    640, Loss function: 6.013, Average Loss: 3.800, avg. samples / sec: 65679.46
Iteration:    640, Loss function: 5.574, Average Loss: 3.793, avg. samples / sec: 65786.80
Iteration:    640, Loss function: 4.958, Average Loss: 3.810, avg. samples / sec: 65867.48
Iteration:    640, Loss function: 6.103, Average Loss: 3.805, avg. samples / sec: 65899.14
Iteration:    640, Loss function: 6.233, Average Loss: 3.812, avg. samples / sec: 65939.66
Iteration:    640, Loss function: 5.012, Average Loss: 3.816, avg. samples / sec: 65849.51
Iteration:    640, Loss function: 5.799, Average Loss: 3.797, avg. samples / sec: 65854.18
Iteration:    640, Loss function: 5.325, Average Loss: 3.817, avg. samples / sec: 65936.61
Iteration:    640, Loss function: 5.104, Average Loss: 3.804, avg. samples / sec: 65784.59
Iteration:    640, Loss function: 5.953, Average Loss: 3.805, avg. samples / sec: 65798.99
Iteration:    640, Loss function: 6.085, Average Loss: 3.816, avg. samples / sec: 65797.52
Iteration:    640, Loss function: 6.176, Average Loss: 3.807, avg. samples / sec: 65892.83
Iteration:    640, Loss function: 6.515, Average Loss: 3.816, avg. samples / sec: 65787.26
Iteration:    640, Loss function: 7.097, Average Loss: 3.822, avg. samples / sec: 65789.53
Iteration:    640, Loss function: 5.464, Average Loss: 3.811, avg. samples / sec: 65660.06
Iteration:    660, Loss function: 5.971, Average Loss: 3.836, avg. samples / sec: 66544.72
Iteration:    660, Loss function: 5.857, Average Loss: 3.855, avg. samples / sec: 66517.77
Iteration:    660, Loss function: 5.880, Average Loss: 3.844, avg. samples / sec: 66405.22
Iteration:    660, Loss function: 5.332, Average Loss: 3.844, avg. samples / sec: 66522.70
Iteration:    660, Loss function: 6.436, Average Loss: 3.846, avg. samples / sec: 66363.07
Iteration:    660, Loss function: 5.769, Average Loss: 3.846, avg. samples / sec: 66648.17
Iteration:    660, Loss function: 7.000, Average Loss: 3.856, avg. samples / sec: 66503.71
Iteration:    660, Loss function: 4.572, Average Loss: 3.856, avg. samples / sec: 66325.25
Iteration:    660, Loss function: 5.356, Average Loss: 3.838, avg. samples / sec: 66419.90
Iteration:    660, Loss function: 5.558, Average Loss: 3.842, avg. samples / sec: 66466.73
Iteration:    660, Loss function: 6.827, Average Loss: 3.840, avg. samples / sec: 66406.50
Iteration:    660, Loss function: 5.530, Average Loss: 3.851, avg. samples / sec: 66330.74
Iteration:    660, Loss function: 5.626, Average Loss: 3.836, avg. samples / sec: 66367.63
Iteration:    660, Loss function: 5.204, Average Loss: 3.850, avg. samples / sec: 66309.24
Iteration:    660, Loss function: 6.699, Average Loss: 3.866, avg. samples / sec: 66594.25
Iteration:    660, Loss function: 5.120, Average Loss: 3.847, avg. samples / sec: 66447.46
Iteration:    660, Loss function: 5.356, Average Loss: 3.832, avg. samples / sec: 66365.60
Iteration:    660, Loss function: 6.437, Average Loss: 3.829, avg. samples / sec: 66353.23
Iteration:    660, Loss function: 5.571, Average Loss: 3.854, avg. samples / sec: 66276.68
Iteration:    660, Loss function: 5.337, Average Loss: 3.838, avg. samples / sec: 66396.31
Iteration:    660, Loss function: 5.243, Average Loss: 3.849, avg. samples / sec: 66385.48
Iteration:    660, Loss function: 6.362, Average Loss: 3.856, avg. samples / sec: 66386.14
Iteration:    660, Loss function: 4.998, Average Loss: 3.854, avg. samples / sec: 66475.82
Iteration:    660, Loss function: 6.970, Average Loss: 3.845, avg. samples / sec: 66358.19
Iteration:    660, Loss function: 5.738, Average Loss: 3.847, avg. samples / sec: 66291.52
Iteration:    660, Loss function: 6.411, Average Loss: 3.836, avg. samples / sec: 66335.05
Iteration:    660, Loss function: 6.493, Average Loss: 3.808, avg. samples / sec: 66261.07
Iteration:    660, Loss function: 5.452, Average Loss: 3.830, avg. samples / sec: 66278.71
Iteration:    660, Loss function: 7.031, Average Loss: 3.848, avg. samples / sec: 66268.89
Iteration:    660, Loss function: 6.620, Average Loss: 3.843, avg. samples / sec: 66137.59
Iteration:    680, Loss function: 5.043, Average Loss: 3.868, avg. samples / sec: 66707.57
Iteration:    680, Loss function: 5.265, Average Loss: 3.869, avg. samples / sec: 66359.41
Iteration:    680, Loss function: 4.678, Average Loss: 3.875, avg. samples / sec: 66509.17
Iteration:    680, Loss function: 5.183, Average Loss: 3.895, avg. samples / sec: 66495.02
Iteration:    680, Loss function: 4.850, Average Loss: 3.885, avg. samples / sec: 66452.66
Iteration:    680, Loss function: 6.794, Average Loss: 3.884, avg. samples / sec: 66393.90
Iteration:    680, Loss function: 4.850, Average Loss: 3.876, avg. samples / sec: 66408.13
Iteration:    680, Loss function: 4.320, Average Loss: 3.896, avg. samples / sec: 66396.56
Iteration:    680, Loss function: 5.861, Average Loss: 3.866, avg. samples / sec: 66436.71
Iteration:    680, Loss function: 5.990, Average Loss: 3.882, avg. samples / sec: 66410.60
Iteration:    680, Loss function: 7.228, Average Loss: 3.894, avg. samples / sec: 66382.36
Iteration:    680, Loss function: 6.077, Average Loss: 3.883, avg. samples / sec: 66375.20
Iteration:    680, Loss function: 4.929, Average Loss: 3.900, avg. samples / sec: 66400.12
Iteration:    680, Loss function: 6.733, Average Loss: 3.891, avg. samples / sec: 66360.66
Iteration:    680, Loss function: 4.242, Average Loss: 3.851, avg. samples / sec: 66498.13
Iteration:    680, Loss function: 4.645, Average Loss: 3.877, avg. samples / sec: 66332.74
Iteration:    680, Loss function: 5.542, Average Loss: 3.889, avg. samples / sec: 66418.55
Iteration:    680, Loss function: 5.859, Average Loss: 3.897, avg. samples / sec: 66271.41
Iteration:    680, Loss function: 6.242, Average Loss: 3.881, avg. samples / sec: 66320.07
Iteration:    680, Loss function: 4.570, Average Loss: 3.886, avg. samples / sec: 66341.39
Iteration:    680, Loss function: 6.332, Average Loss: 3.879, avg. samples / sec: 66371.35
Iteration:    680, Loss function: 5.252, Average Loss: 3.860, avg. samples / sec: 66360.54
Iteration:    680, Loss function: 6.405, Average Loss: 3.890, avg. samples / sec: 66392.02
Iteration:    680, Loss function: 7.095, Average Loss: 3.885, avg. samples / sec: 66457.42
Iteration:    680, Loss function: 5.576, Average Loss: 3.881, avg. samples / sec: 66271.54
Iteration:    680, Loss function: 5.627, Average Loss: 3.879, avg. samples / sec: 66342.83
Iteration:    680, Loss function: 6.033, Average Loss: 3.892, avg. samples / sec: 66341.48
Iteration:    680, Loss function: 5.345, Average Loss: 3.895, avg. samples / sec: 66331.24
Iteration:    680, Loss function: 7.116, Average Loss: 3.878, avg. samples / sec: 66408.66
Iteration:    680, Loss function: 6.798, Average Loss: 3.884, avg. samples / sec: 66270.54
:::MLL 1558651876.138 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558651876.138 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 5.514, Average Loss: 3.905, avg. samples / sec: 65825.73
Iteration:    700, Loss function: 6.514, Average Loss: 3.914, avg. samples / sec: 66130.14
Iteration:    700, Loss function: 5.619, Average Loss: 3.902, avg. samples / sec: 65718.33
Iteration:    700, Loss function: 6.255, Average Loss: 3.915, avg. samples / sec: 65852.58
Iteration:    700, Loss function: 6.751, Average Loss: 3.916, avg. samples / sec: 65867.30
Iteration:    700, Loss function: 5.577, Average Loss: 3.928, avg. samples / sec: 65910.15
Iteration:    700, Loss function: 5.792, Average Loss: 3.918, avg. samples / sec: 65991.53
Iteration:    700, Loss function: 5.031, Average Loss: 3.923, avg. samples / sec: 65921.92
Iteration:    700, Loss function: 5.026, Average Loss: 3.911, avg. samples / sec: 65916.50
Iteration:    700, Loss function: 6.226, Average Loss: 3.922, avg. samples / sec: 65957.28
Iteration:    700, Loss function: 5.866, Average Loss: 3.932, avg. samples / sec: 65978.71
Iteration:    700, Loss function: 5.656, Average Loss: 3.903, avg. samples / sec: 65759.97
Iteration:    700, Loss function: 6.290, Average Loss: 3.880, avg. samples / sec: 65843.75
Iteration:    700, Loss function: 5.307, Average Loss: 3.918, avg. samples / sec: 65816.94
Iteration:    700, Loss function: 4.951, Average Loss: 3.935, avg. samples / sec: 65802.40
Iteration:    700, Loss function: 6.328, Average Loss: 3.925, avg. samples / sec: 65837.73
Iteration:    700, Loss function: 6.119, Average Loss: 3.916, avg. samples / sec: 65743.56
Iteration:    700, Loss function: 5.445, Average Loss: 3.910, avg. samples / sec: 65896.99
Iteration:    700, Loss function: 6.343, Average Loss: 3.892, avg. samples / sec: 65752.58
Iteration:    700, Loss function: 5.136, Average Loss: 3.930, avg. samples / sec: 65740.09
Iteration:    700, Loss function: 5.031, Average Loss: 3.894, avg. samples / sec: 65808.15
Iteration:    700, Loss function: 6.802, Average Loss: 3.914, avg. samples / sec: 65702.15
Iteration:    700, Loss function: 5.981, Average Loss: 3.928, avg. samples / sec: 65680.38
Iteration:    700, Loss function: 5.178, Average Loss: 3.923, avg. samples / sec: 65758.10
Iteration:    700, Loss function: 5.125, Average Loss: 3.911, avg. samples / sec: 65747.58
Iteration:    700, Loss function: 6.250, Average Loss: 3.925, avg. samples / sec: 65802.10
Iteration:    700, Loss function: 6.439, Average Loss: 3.912, avg. samples / sec: 65885.71
Iteration:    700, Loss function: 5.507, Average Loss: 3.925, avg. samples / sec: 65668.78
Iteration:    700, Loss function: 6.394, Average Loss: 3.926, avg. samples / sec: 65739.26
Iteration:    700, Loss function: 5.814, Average Loss: 3.915, avg. samples / sec: 65695.63
Iteration:    720, Loss function: 4.889, Average Loss: 3.936, avg. samples / sec: 66253.34
Iteration:    720, Loss function: 5.260, Average Loss: 3.936, avg. samples / sec: 66270.88
Iteration:    720, Loss function: 5.371, Average Loss: 3.938, avg. samples / sec: 66182.25
Iteration:    720, Loss function: 6.784, Average Loss: 3.959, avg. samples / sec: 66303.93
Iteration:    720, Loss function: 5.752, Average Loss: 3.957, avg. samples / sec: 66255.84
Iteration:    720, Loss function: 6.435, Average Loss: 3.959, avg. samples / sec: 66325.09
Iteration:    720, Loss function: 5.787, Average Loss: 3.949, avg. samples / sec: 66381.73
Iteration:    720, Loss function: 5.415, Average Loss: 3.944, avg. samples / sec: 66247.21
Iteration:    720, Loss function: 4.296, Average Loss: 3.911, avg. samples / sec: 66276.59
Iteration:    720, Loss function: 5.214, Average Loss: 3.959, avg. samples / sec: 66360.01
Iteration:    720, Loss function: 5.062, Average Loss: 3.962, avg. samples / sec: 66376.70
Iteration:    720, Loss function: 5.582, Average Loss: 3.959, avg. samples / sec: 66445.61
Iteration:    720, Loss function: 4.378, Average Loss: 3.950, avg. samples / sec: 66226.82
Iteration:    720, Loss function: 5.361, Average Loss: 3.954, avg. samples / sec: 66209.46
Iteration:    720, Loss function: 5.847, Average Loss: 3.951, avg. samples / sec: 66340.08
Iteration:    720, Loss function: 5.730, Average Loss: 3.971, avg. samples / sec: 66211.73
Iteration:    720, Loss function: 5.347, Average Loss: 3.947, avg. samples / sec: 66409.41
Iteration:    720, Loss function: 5.972, Average Loss: 3.949, avg. samples / sec: 66154.32
Iteration:    720, Loss function: 4.764, Average Loss: 3.955, avg. samples / sec: 66175.32
Iteration:    720, Loss function: 5.296, Average Loss: 3.960, avg. samples / sec: 66347.48
Iteration:    720, Loss function: 5.585, Average Loss: 3.960, avg. samples / sec: 66284.07
Iteration:    720, Loss function: 5.441, Average Loss: 3.925, avg. samples / sec: 66255.24
Iteration:    720, Loss function: 5.274, Average Loss: 3.923, avg. samples / sec: 66268.33
Iteration:    720, Loss function: 6.271, Average Loss: 3.941, avg. samples / sec: 66217.58
Iteration:    720, Loss function: 5.865, Average Loss: 3.950, avg. samples / sec: 66063.52
Iteration:    720, Loss function: 5.266, Average Loss: 3.947, avg. samples / sec: 66254.68
Iteration:    720, Loss function: 3.974, Average Loss: 3.965, avg. samples / sec: 66108.14
Iteration:    720, Loss function: 5.969, Average Loss: 3.953, avg. samples / sec: 66078.51
Iteration:    720, Loss function: 4.573, Average Loss: 3.955, avg. samples / sec: 66239.70
Iteration:    720, Loss function: 4.520, Average Loss: 3.943, avg. samples / sec: 65986.28
Iteration:    740, Loss function: 6.818, Average Loss: 4.012, avg. samples / sec: 66436.43
Iteration:    740, Loss function: 6.645, Average Loss: 4.000, avg. samples / sec: 66432.96
Iteration:    740, Loss function: 6.501, Average Loss: 3.991, avg. samples / sec: 66385.11
Iteration:    740, Loss function: 6.879, Average Loss: 3.994, avg. samples / sec: 66373.32
Iteration:    740, Loss function: 7.684, Average Loss: 4.013, avg. samples / sec: 66396.99
Iteration:    740, Loss function: 7.175, Average Loss: 4.026, avg. samples / sec: 66483.98
Iteration:    740, Loss function: 6.585, Average Loss: 4.014, avg. samples / sec: 66481.19
Iteration:    740, Loss function: 6.795, Average Loss: 4.011, avg. samples / sec: 66497.88
Iteration:    740, Loss function: 7.033, Average Loss: 3.996, avg. samples / sec: 66391.39
Iteration:    740, Loss function: 8.338, Average Loss: 3.962, avg. samples / sec: 66381.79
Iteration:    740, Loss function: 6.227, Average Loss: 4.005, avg. samples / sec: 66404.22
Iteration:    740, Loss function: 7.143, Average Loss: 4.005, avg. samples / sec: 66540.73
Iteration:    740, Loss function: 7.276, Average Loss: 4.015, avg. samples / sec: 66341.73
Iteration:    740, Loss function: 6.820, Average Loss: 4.006, avg. samples / sec: 66432.80
Iteration:    740, Loss function: 5.710, Average Loss: 4.013, avg. samples / sec: 66365.26
Iteration:    740, Loss function: 5.231, Average Loss: 4.010, avg. samples / sec: 66360.44
Iteration:    740, Loss function: 6.769, Average Loss: 3.999, avg. samples / sec: 66569.34
Iteration:    740, Loss function: 6.563, Average Loss: 4.002, avg. samples / sec: 66453.35
Iteration:    740, Loss function: 6.195, Average Loss: 3.994, avg. samples / sec: 66432.02
Iteration:    740, Loss function: 6.552, Average Loss: 3.979, avg. samples / sec: 66410.85
Iteration:    740, Loss function: 6.819, Average Loss: 4.009, avg. samples / sec: 66376.57
Iteration:    740, Loss function: 5.721, Average Loss: 3.989, avg. samples / sec: 66292.39
Iteration:    740, Loss function: 7.732, Average Loss: 4.003, avg. samples / sec: 66347.14
Iteration:    740, Loss function: 7.315, Average Loss: 4.019, avg. samples / sec: 66442.41
Iteration:    740, Loss function: 6.365, Average Loss: 4.011, avg. samples / sec: 66451.22
Iteration:    740, Loss function: 6.782, Average Loss: 4.003, avg. samples / sec: 66338.77
Iteration:    740, Loss function: 6.789, Average Loss: 3.976, avg. samples / sec: 66362.26
Iteration:    740, Loss function: 7.047, Average Loss: 4.009, avg. samples / sec: 66272.29
Iteration:    740, Loss function: 6.865, Average Loss: 3.994, avg. samples / sec: 66341.48
Iteration:    740, Loss function: 5.943, Average Loss: 4.022, avg. samples / sec: 66095.18
Iteration:    760, Loss function: 6.310, Average Loss: 4.031, avg. samples / sec: 66536.74
Iteration:    760, Loss function: 6.646, Average Loss: 4.044, avg. samples / sec: 66557.67
Iteration:    760, Loss function: 5.771, Average Loss: 4.034, avg. samples / sec: 66556.23
Iteration:    760, Loss function: 4.713, Average Loss: 4.028, avg. samples / sec: 66447.46
Iteration:    760, Loss function: 5.543, Average Loss: 4.050, avg. samples / sec: 66437.12
Iteration:    760, Loss function: 5.745, Average Loss: 4.033, avg. samples / sec: 66525.66
Iteration:    760, Loss function: 5.210, Average Loss: 4.049, avg. samples / sec: 66584.56
Iteration:    760, Loss function: 5.445, Average Loss: 4.038, avg. samples / sec: 66553.24
Iteration:    760, Loss function: 6.507, Average Loss: 4.049, avg. samples / sec: 66604.13
Iteration:    760, Loss function: 5.659, Average Loss: 4.046, avg. samples / sec: 66371.32
Iteration:    760, Loss function: 4.838, Average Loss: 4.041, avg. samples / sec: 66544.16
Iteration:    760, Loss function: 5.629, Average Loss: 4.019, avg. samples / sec: 66479.46
Iteration:    760, Loss function: 6.102, Average Loss: 4.056, avg. samples / sec: 66455.61
Iteration:    760, Loss function: 6.572, Average Loss: 4.051, avg. samples / sec: 66375.54
Iteration:    760, Loss function: 5.275, Average Loss: 4.036, avg. samples / sec: 66403.34
Iteration:    760, Loss function: 5.450, Average Loss: 4.061, avg. samples / sec: 66691.22
Iteration:    760, Loss function: 6.121, Average Loss: 4.046, avg. samples / sec: 66362.60
Iteration:    760, Loss function: 5.437, Average Loss: 4.067, avg. samples / sec: 66355.70
Iteration:    760, Loss function: 5.014, Average Loss: 4.043, avg. samples / sec: 66331.08
Iteration:    760, Loss function: 6.718, Average Loss: 4.045, avg. samples / sec: 66399.56
Iteration:    760, Loss function: 3.860, Average Loss: 4.040, avg. samples / sec: 66427.88
Iteration:    760, Loss function: 5.829, Average Loss: 4.040, avg. samples / sec: 66418.80
Iteration:    760, Loss function: 5.051, Average Loss: 4.050, avg. samples / sec: 66406.79
Iteration:    760, Loss function: 5.206, Average Loss: 4.048, avg. samples / sec: 66425.03
Iteration:    760, Loss function: 5.610, Average Loss: 4.005, avg. samples / sec: 66346.54
Iteration:    760, Loss function: 5.635, Average Loss: 4.059, avg. samples / sec: 66355.45
Iteration:    760, Loss function: 5.230, Average Loss: 4.059, avg. samples / sec: 66389.86
Iteration:    760, Loss function: 6.349, Average Loss: 4.049, avg. samples / sec: 66288.06
Iteration:    760, Loss function: 5.363, Average Loss: 4.033, avg. samples / sec: 66462.66
Iteration:    760, Loss function: 5.155, Average Loss: 4.015, avg. samples / sec: 66358.76
:::MLL 1558651877.913 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558651877.913 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 4.172, Average Loss: 4.057, avg. samples / sec: 65666.33
Iteration:    780, Loss function: 4.854, Average Loss: 4.082, avg. samples / sec: 65936.42
Iteration:    780, Loss function: 5.924, Average Loss: 4.076, avg. samples / sec: 65817.92
Iteration:    780, Loss function: 6.317, Average Loss: 4.078, avg. samples / sec: 65814.42
Iteration:    780, Loss function: 4.691, Average Loss: 4.059, avg. samples / sec: 65759.11
Iteration:    780, Loss function: 5.426, Average Loss: 4.061, avg. samples / sec: 65700.89
Iteration:    780, Loss function: 5.252, Average Loss: 4.074, avg. samples / sec: 65698.66
Iteration:    780, Loss function: 5.303, Average Loss: 4.072, avg. samples / sec: 65789.99
Iteration:    780, Loss function: 5.281, Average Loss: 4.057, avg. samples / sec: 65664.07
Iteration:    780, Loss function: 5.784, Average Loss: 4.075, avg. samples / sec: 65755.80
Iteration:    780, Loss function: 4.890, Average Loss: 4.085, avg. samples / sec: 65833.88
Iteration:    780, Loss function: 5.213, Average Loss: 4.079, avg. samples / sec: 65652.63
Iteration:    780, Loss function: 5.143, Average Loss: 4.073, avg. samples / sec: 65677.47
Iteration:    780, Loss function: 5.846, Average Loss: 4.047, avg. samples / sec: 65677.84
Iteration:    780, Loss function: 4.895, Average Loss: 4.068, avg. samples / sec: 65729.05
Iteration:    780, Loss function: 5.821, Average Loss: 4.097, avg. samples / sec: 65715.38
Iteration:    780, Loss function: 4.871, Average Loss: 4.077, avg. samples / sec: 65640.98
Iteration:    780, Loss function: 6.779, Average Loss: 4.079, avg. samples / sec: 65540.69
Iteration:    780, Loss function: 4.471, Average Loss: 4.086, avg. samples / sec: 65745.18
Iteration:    780, Loss function: 5.627, Average Loss: 4.090, avg. samples / sec: 65665.29
Iteration:    780, Loss function: 4.278, Average Loss: 4.071, avg. samples / sec: 65630.34
Iteration:    780, Loss function: 5.017, Average Loss: 4.062, avg. samples / sec: 65546.67
Iteration:    780, Loss function: 6.009, Average Loss: 4.065, avg. samples / sec: 65665.17
Iteration:    780, Loss function: 4.853, Average Loss: 4.082, avg. samples / sec: 65644.16
Iteration:    780, Loss function: 6.115, Average Loss: 4.089, avg. samples / sec: 65550.63
Iteration:    780, Loss function: 4.885, Average Loss: 4.061, avg. samples / sec: 65720.93
Iteration:    780, Loss function: 5.997, Average Loss: 4.032, avg. samples / sec: 65657.43
Iteration:    780, Loss function: 4.942, Average Loss: 4.076, avg. samples / sec: 65624.32
Iteration:    780, Loss function: 4.717, Average Loss: 4.081, avg. samples / sec: 65510.62
Iteration:    780, Loss function: 5.748, Average Loss: 4.041, avg. samples / sec: 65607.85
Iteration:    800, Loss function: 5.262, Average Loss: 4.104, avg. samples / sec: 66519.16
Iteration:    800, Loss function: 5.455, Average Loss: 4.106, avg. samples / sec: 66596.29
Iteration:    800, Loss function: 6.278, Average Loss: 4.124, avg. samples / sec: 66578.58
Iteration:    800, Loss function: 6.191, Average Loss: 4.091, avg. samples / sec: 66506.76
Iteration:    800, Loss function: 4.532, Average Loss: 4.116, avg. samples / sec: 66621.64
Iteration:    800, Loss function: 5.059, Average Loss: 4.105, avg. samples / sec: 66566.03
Iteration:    800, Loss function: 4.704, Average Loss: 4.096, avg. samples / sec: 66532.69
Iteration:    800, Loss function: 5.119, Average Loss: 4.103, avg. samples / sec: 66514.95
Iteration:    800, Loss function: 5.394, Average Loss: 4.083, avg. samples / sec: 66369.95
Iteration:    800, Loss function: 4.297, Average Loss: 4.096, avg. samples / sec: 66415.89
Iteration:    800, Loss function: 5.884, Average Loss: 4.100, avg. samples / sec: 66466.42
Iteration:    800, Loss function: 5.531, Average Loss: 4.102, avg. samples / sec: 66509.49
Iteration:    800, Loss function: 5.238, Average Loss: 4.059, avg. samples / sec: 66590.47
Iteration:    800, Loss function: 6.185, Average Loss: 4.113, avg. samples / sec: 66357.91
Iteration:    800, Loss function: 6.765, Average Loss: 4.085, avg. samples / sec: 66434.96
Iteration:    800, Loss function: 4.747, Average Loss: 4.108, avg. samples / sec: 66648.58
Iteration:    800, Loss function: 5.925, Average Loss: 4.079, avg. samples / sec: 66467.45
Iteration:    800, Loss function: 5.589, Average Loss: 4.109, avg. samples / sec: 66531.75
Iteration:    800, Loss function: 5.514, Average Loss: 4.114, avg. samples / sec: 66426.41
Iteration:    800, Loss function: 5.566, Average Loss: 4.114, avg. samples / sec: 66476.17
Iteration:    800, Loss function: 5.884, Average Loss: 4.103, avg. samples / sec: 66394.71
Iteration:    800, Loss function: 5.517, Average Loss: 4.095, avg. samples / sec: 66383.92
Iteration:    800, Loss function: 4.607, Average Loss: 4.067, avg. samples / sec: 66697.40
Iteration:    800, Loss function: 6.522, Average Loss: 4.097, avg. samples / sec: 66362.35
Iteration:    800, Loss function: 5.665, Average Loss: 4.099, avg. samples / sec: 66445.11
Iteration:    800, Loss function: 4.736, Average Loss: 4.084, avg. samples / sec: 66530.74
Iteration:    800, Loss function: 5.403, Average Loss: 4.111, avg. samples / sec: 66446.36
Iteration:    800, Loss function: 5.235, Average Loss: 4.085, avg. samples / sec: 66456.83
Iteration:    800, Loss function: 5.456, Average Loss: 4.090, avg. samples / sec: 66445.02
Iteration:    800, Loss function: 5.752, Average Loss: 4.106, avg. samples / sec: 66447.93
Iteration:    820, Loss function: 5.152, Average Loss: 4.109, avg. samples / sec: 66514.63
Iteration:    820, Loss function: 5.967, Average Loss: 4.127, avg. samples / sec: 66482.63
Iteration:    820, Loss function: 5.401, Average Loss: 4.106, avg. samples / sec: 66566.95
Iteration:    820, Loss function: 5.870, Average Loss: 4.129, avg. samples / sec: 66405.28
Iteration:    820, Loss function: 4.770, Average Loss: 4.120, avg. samples / sec: 66405.03
Iteration:    820, Loss function: 5.338, Average Loss: 4.119, avg. samples / sec: 66580.88
Iteration:    820, Loss function: 4.937, Average Loss: 4.114, avg. samples / sec: 66513.88
Iteration:    820, Loss function: 4.966, Average Loss: 4.139, avg. samples / sec: 66536.77
Iteration:    820, Loss function: 5.420, Average Loss: 4.137, avg. samples / sec: 66526.32
Iteration:    820, Loss function: 6.026, Average Loss: 4.083, avg. samples / sec: 66504.97
Iteration:    820, Loss function: 5.469, Average Loss: 4.149, avg. samples / sec: 66379.98
Iteration:    820, Loss function: 5.876, Average Loss: 4.135, avg. samples / sec: 66492.73
Iteration:    820, Loss function: 5.743, Average Loss: 4.137, avg. samples / sec: 66452.72
Iteration:    820, Loss function: 6.555, Average Loss: 4.144, avg. samples / sec: 66325.43
Iteration:    820, Loss function: 5.287, Average Loss: 4.126, avg. samples / sec: 66369.95
Iteration:    820, Loss function: 5.165, Average Loss: 4.120, avg. samples / sec: 66447.55
Iteration:    820, Loss function: 4.690, Average Loss: 4.121, avg. samples / sec: 66498.28
Iteration:    820, Loss function: 5.091, Average Loss: 4.124, avg. samples / sec: 66477.05
Iteration:    820, Loss function: 4.824, Average Loss: 4.123, avg. samples / sec: 66337.49
Iteration:    820, Loss function: 3.994, Average Loss: 4.140, avg. samples / sec: 66387.17
Iteration:    820, Loss function: 4.717, Average Loss: 4.127, avg. samples / sec: 66546.14
Iteration:    820, Loss function: 6.078, Average Loss: 4.111, avg. samples / sec: 66455.70
Iteration:    820, Loss function: 5.638, Average Loss: 4.124, avg. samples / sec: 66336.61
Iteration:    820, Loss function: 5.918, Average Loss: 4.131, avg. samples / sec: 66292.43
Iteration:    820, Loss function: 4.559, Average Loss: 4.132, avg. samples / sec: 66340.45
Iteration:    820, Loss function: 5.173, Average Loss: 4.141, avg. samples / sec: 66444.73
Iteration:    820, Loss function: 4.896, Average Loss: 4.097, avg. samples / sec: 66365.44
Iteration:    820, Loss function: 6.014, Average Loss: 4.136, avg. samples / sec: 66298.66
Iteration:    820, Loss function: 4.969, Average Loss: 4.112, avg. samples / sec: 66332.11
Iteration:    820, Loss function: 5.657, Average Loss: 4.115, avg. samples / sec: 66061.44
:::MLL 1558651879.688 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558651879.688 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 4.882, Average Loss: 4.139, avg. samples / sec: 66154.04
Iteration:    840, Loss function: 5.379, Average Loss: 4.130, avg. samples / sec: 66122.66
Iteration:    840, Loss function: 5.161, Average Loss: 4.157, avg. samples / sec: 66299.41
Iteration:    840, Loss function: 5.121, Average Loss: 4.161, avg. samples / sec: 66321.53
Iteration:    840, Loss function: 6.208, Average Loss: 4.142, avg. samples / sec: 66123.78
Iteration:    840, Loss function: 5.259, Average Loss: 4.138, avg. samples / sec: 66407.69
Iteration:    840, Loss function: 5.897, Average Loss: 4.149, avg. samples / sec: 66224.30
Iteration:    840, Loss function: 5.892, Average Loss: 4.175, avg. samples / sec: 66104.92
Iteration:    840, Loss function: 5.122, Average Loss: 4.162, avg. samples / sec: 66260.29
Iteration:    840, Loss function: 3.981, Average Loss: 4.155, avg. samples / sec: 66142.99
Iteration:    840, Loss function: 4.513, Average Loss: 4.143, avg. samples / sec: 66076.22
Iteration:    840, Loss function: 5.192, Average Loss: 4.107, avg. samples / sec: 66082.73
Iteration:    840, Loss function: 5.578, Average Loss: 4.159, avg. samples / sec: 66153.33
Iteration:    840, Loss function: 4.844, Average Loss: 4.152, avg. samples / sec: 66032.26
Iteration:    840, Loss function: 5.162, Average Loss: 4.146, avg. samples / sec: 66179.30
Iteration:    840, Loss function: 4.546, Average Loss: 4.136, avg. samples / sec: 66177.81
Iteration:    840, Loss function: 5.538, Average Loss: 4.162, avg. samples / sec: 66052.12
Iteration:    840, Loss function: 5.561, Average Loss: 4.140, avg. samples / sec: 66144.76
Iteration:    840, Loss function: 5.359, Average Loss: 4.144, avg. samples / sec: 66133.06
Iteration:    840, Loss function: 4.898, Average Loss: 4.153, avg. samples / sec: 66206.56
Iteration:    840, Loss function: 3.980, Average Loss: 4.162, avg. samples / sec: 66017.13
Iteration:    840, Loss function: 4.612, Average Loss: 4.167, avg. samples / sec: 66138.83
Iteration:    840, Loss function: 5.657, Average Loss: 4.123, avg. samples / sec: 66189.21
Iteration:    840, Loss function: 5.455, Average Loss: 4.148, avg. samples / sec: 66133.92
Iteration:    840, Loss function: 6.996, Average Loss: 4.145, avg. samples / sec: 66097.08
Iteration:    840, Loss function: 5.209, Average Loss: 4.136, avg. samples / sec: 66338.89
Iteration:    840, Loss function: 4.905, Average Loss: 4.151, avg. samples / sec: 65899.54
Iteration:    840, Loss function: 5.484, Average Loss: 4.126, avg. samples / sec: 65868.74
Iteration:    840, Loss function: 4.182, Average Loss: 4.148, avg. samples / sec: 65973.18
Iteration:    840, Loss function: 5.195, Average Loss: 4.171, avg. samples / sec: 65947.99
Iteration:    860, Loss function: 3.897, Average Loss: 4.144, avg. samples / sec: 66348.54
Iteration:    860, Loss function: 4.530, Average Loss: 4.195, avg. samples / sec: 66151.34
Iteration:    860, Loss function: 4.000, Average Loss: 4.172, avg. samples / sec: 66136.10
Iteration:    860, Loss function: 4.426, Average Loss: 4.167, avg. samples / sec: 66171.16
Iteration:    860, Loss function: 5.909, Average Loss: 4.165, avg. samples / sec: 66141.62
Iteration:    860, Loss function: 3.820, Average Loss: 4.177, avg. samples / sec: 66003.68
Iteration:    860, Loss function: 5.120, Average Loss: 4.164, avg. samples / sec: 66009.65
Iteration:    860, Loss function: 5.206, Average Loss: 4.181, avg. samples / sec: 66010.30
Iteration:    860, Loss function: 5.123, Average Loss: 4.177, avg. samples / sec: 66074.17
Iteration:    860, Loss function: 5.845, Average Loss: 4.157, avg. samples / sec: 65960.18
Iteration:    860, Loss function: 6.090, Average Loss: 4.130, avg. samples / sec: 66039.19
Iteration:    860, Loss function: 5.633, Average Loss: 4.153, avg. samples / sec: 66120.64
Iteration:    860, Loss function: 5.948, Average Loss: 4.159, avg. samples / sec: 66046.68
Iteration:    860, Loss function: 3.589, Average Loss: 4.192, avg. samples / sec: 66230.02
Iteration:    860, Loss function: 6.218, Average Loss: 4.179, avg. samples / sec: 66071.39
Iteration:    860, Loss function: 5.336, Average Loss: 4.169, avg. samples / sec: 65989.80
Iteration:    860, Loss function: 5.102, Average Loss: 4.183, avg. samples / sec: 66011.01
Iteration:    860, Loss function: 4.172, Average Loss: 4.166, avg. samples / sec: 66102.10
Iteration:    860, Loss function: 5.435, Average Loss: 4.188, avg. samples / sec: 65998.39
Iteration:    860, Loss function: 5.686, Average Loss: 4.177, avg. samples / sec: 66142.12
Iteration:    860, Loss function: 5.675, Average Loss: 4.169, avg. samples / sec: 66048.25
Iteration:    860, Loss function: 4.987, Average Loss: 4.183, avg. samples / sec: 66001.27
Iteration:    860, Loss function: 6.090, Average Loss: 4.162, avg. samples / sec: 65881.55
Iteration:    860, Loss function: 4.844, Average Loss: 4.153, avg. samples / sec: 65886.39
Iteration:    860, Loss function: 4.594, Average Loss: 4.185, avg. samples / sec: 66003.22
Iteration:    860, Loss function: 4.891, Average Loss: 4.174, avg. samples / sec: 65921.12
Iteration:    860, Loss function: 4.734, Average Loss: 4.171, avg. samples / sec: 65936.98
Iteration:    860, Loss function: 4.394, Average Loss: 4.168, avg. samples / sec: 66088.61
Iteration:    860, Loss function: 6.349, Average Loss: 4.178, avg. samples / sec: 65866.96
Iteration:    860, Loss function: 5.722, Average Loss: 4.146, avg. samples / sec: 65903.40
Iteration:    880, Loss function: 6.408, Average Loss: 4.217, avg. samples / sec: 66496.02
Iteration:    880, Loss function: 3.967, Average Loss: 4.166, avg. samples / sec: 66404.78
Iteration:    880, Loss function: 6.804, Average Loss: 4.215, avg. samples / sec: 66567.32
Iteration:    880, Loss function: 5.427, Average Loss: 4.200, avg. samples / sec: 66500.67
Iteration:    880, Loss function: 5.312, Average Loss: 4.178, avg. samples / sec: 66497.34
Iteration:    880, Loss function: 6.425, Average Loss: 4.204, avg. samples / sec: 66508.17
Iteration:    880, Loss function: 4.881, Average Loss: 4.192, avg. samples / sec: 66373.95
Iteration:    880, Loss function: 4.525, Average Loss: 4.196, avg. samples / sec: 66433.71
Iteration:    880, Loss function: 4.635, Average Loss: 4.198, avg. samples / sec: 66637.86
Iteration:    880, Loss function: 6.734, Average Loss: 4.210, avg. samples / sec: 66535.20
Iteration:    880, Loss function: 6.042, Average Loss: 4.203, avg. samples / sec: 66412.01
Iteration:    880, Loss function: 5.040, Average Loss: 4.189, avg. samples / sec: 66580.78
Iteration:    880, Loss function: 4.814, Average Loss: 4.208, avg. samples / sec: 66463.19
Iteration:    880, Loss function: 5.791, Average Loss: 4.200, avg. samples / sec: 66584.18
Iteration:    880, Loss function: 5.125, Average Loss: 4.194, avg. samples / sec: 66322.87
Iteration:    880, Loss function: 4.729, Average Loss: 4.195, avg. samples / sec: 66469.68
Iteration:    880, Loss function: 5.917, Average Loss: 4.153, avg. samples / sec: 66403.63
Iteration:    880, Loss function: 4.843, Average Loss: 4.202, avg. samples / sec: 66394.71
Iteration:    880, Loss function: 4.526, Average Loss: 4.180, avg. samples / sec: 66415.80
Iteration:    880, Loss function: 6.073, Average Loss: 4.191, avg. samples / sec: 66467.74
Iteration:    880, Loss function: 5.799, Average Loss: 4.183, avg. samples / sec: 66486.24
Iteration:    880, Loss function: 5.785, Average Loss: 4.191, avg. samples / sec: 66529.46
Iteration:    880, Loss function: 6.001, Average Loss: 4.181, avg. samples / sec: 66385.70
Iteration:    880, Loss function: 6.056, Average Loss: 4.191, avg. samples / sec: 66388.52
Iteration:    880, Loss function: 6.684, Average Loss: 4.187, avg. samples / sec: 66293.27
Iteration:    880, Loss function: 5.664, Average Loss: 4.209, avg. samples / sec: 66469.33
Iteration:    880, Loss function: 5.191, Average Loss: 4.171, avg. samples / sec: 66548.40
Iteration:    880, Loss function: 5.278, Average Loss: 4.195, avg. samples / sec: 66334.49
Iteration:    880, Loss function: 5.560, Average Loss: 4.204, avg. samples / sec: 66335.96
Iteration:    880, Loss function: 5.345, Average Loss: 4.188, avg. samples / sec: 66296.76
Iteration:    900, Loss function: 5.562, Average Loss: 4.186, avg. samples / sec: 66628.41
Iteration:    900, Loss function: 5.757, Average Loss: 4.214, avg. samples / sec: 66748.45
Iteration:    900, Loss function: 6.034, Average Loss: 4.238, avg. samples / sec: 66510.40
Iteration:    900, Loss function: 5.590, Average Loss: 4.219, avg. samples / sec: 66646.62
Iteration:    900, Loss function: 4.053, Average Loss: 4.219, avg. samples / sec: 66597.62
Iteration:    900, Loss function: 5.512, Average Loss: 4.217, avg. samples / sec: 66582.39
Iteration:    900, Loss function: 3.856, Average Loss: 4.222, avg. samples / sec: 66578.77
Iteration:    900, Loss function: 5.097, Average Loss: 4.199, avg. samples / sec: 66702.27
Iteration:    900, Loss function: 5.936, Average Loss: 4.220, avg. samples / sec: 66683.46
Iteration:    900, Loss function: 4.436, Average Loss: 4.215, avg. samples / sec: 66680.84
Iteration:    900, Loss function: 5.806, Average Loss: 4.233, avg. samples / sec: 66513.13
Iteration:    900, Loss function: 3.782, Average Loss: 4.211, avg. samples / sec: 66534.73
Iteration:    900, Loss function: 4.842, Average Loss: 4.230, avg. samples / sec: 66653.46
Iteration:    900, Loss function: 4.481, Average Loss: 4.236, avg. samples / sec: 66423.81
Iteration:    900, Loss function: 4.862, Average Loss: 4.235, avg. samples / sec: 66488.81
Iteration:    900, Loss function: 5.252, Average Loss: 4.204, avg. samples / sec: 66588.08
Iteration:    900, Loss function: 5.366, Average Loss: 4.217, avg. samples / sec: 66578.61
Iteration:    900, Loss function: 4.636, Average Loss: 4.230, avg. samples / sec: 66584.34
Iteration:    900, Loss function: 4.565, Average Loss: 4.215, avg. samples / sec: 66588.62
Iteration:    900, Loss function: 5.629, Average Loss: 4.229, avg. samples / sec: 66491.79
Iteration:    900, Loss function: 5.131, Average Loss: 4.232, avg. samples / sec: 66519.19
Iteration:    900, Loss function: 5.595, Average Loss: 4.220, avg. samples / sec: 66529.74
Iteration:    900, Loss function: 4.848, Average Loss: 4.202, avg. samples / sec: 66544.75
Iteration:    900, Loss function: 6.387, Average Loss: 4.204, avg. samples / sec: 66521.26
Iteration:    900, Loss function: 4.065, Average Loss: 4.202, avg. samples / sec: 66396.71
Iteration:    900, Loss function: 4.830, Average Loss: 4.214, avg. samples / sec: 66543.09
Iteration:    900, Loss function: 4.710, Average Loss: 4.225, avg. samples / sec: 66363.13
Iteration:    900, Loss function: 4.255, Average Loss: 4.224, avg. samples / sec: 66455.26
Iteration:    900, Loss function: 5.628, Average Loss: 4.230, avg. samples / sec: 66483.57
Iteration:    900, Loss function: 4.524, Average Loss: 4.177, avg. samples / sec: 66382.64
:::MLL 1558651881.462 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558651881.462 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 5.163, Average Loss: 4.254, avg. samples / sec: 66145.13
Iteration:    920, Loss function: 4.744, Average Loss: 4.238, avg. samples / sec: 66127.41
Iteration:    920, Loss function: 4.792, Average Loss: 4.251, avg. samples / sec: 66199.16
Iteration:    920, Loss function: 5.644, Average Loss: 4.245, avg. samples / sec: 66225.57
Iteration:    920, Loss function: 4.970, Average Loss: 4.239, avg. samples / sec: 66223.99
Iteration:    920, Loss function: 5.077, Average Loss: 4.218, avg. samples / sec: 66242.97
Iteration:    920, Loss function: 6.154, Average Loss: 4.219, avg. samples / sec: 66186.41
Iteration:    920, Loss function: 5.008, Average Loss: 4.238, avg. samples / sec: 66073.55
Iteration:    920, Loss function: 5.736, Average Loss: 4.235, avg. samples / sec: 65973.43
Iteration:    920, Loss function: 5.586, Average Loss: 4.204, avg. samples / sec: 65925.84
Iteration:    920, Loss function: 4.471, Average Loss: 4.251, avg. samples / sec: 66178.96
Iteration:    920, Loss function: 4.967, Average Loss: 4.237, avg. samples / sec: 66067.11
Iteration:    920, Loss function: 4.853, Average Loss: 4.245, avg. samples / sec: 66216.77
Iteration:    920, Loss function: 4.811, Average Loss: 4.232, avg. samples / sec: 66151.84
Iteration:    920, Loss function: 5.272, Average Loss: 4.236, avg. samples / sec: 66100.24
Iteration:    920, Loss function: 5.838, Average Loss: 4.243, avg. samples / sec: 66184.30
Iteration:    920, Loss function: 4.741, Average Loss: 4.226, avg. samples / sec: 66121.98
Iteration:    920, Loss function: 4.233, Average Loss: 4.239, avg. samples / sec: 66100.21
Iteration:    920, Loss function: 4.253, Average Loss: 4.246, avg. samples / sec: 66206.38
Iteration:    920, Loss function: 3.623, Average Loss: 4.234, avg. samples / sec: 66099.87
Iteration:    920, Loss function: 3.772, Average Loss: 4.252, avg. samples / sec: 66102.53
Iteration:    920, Loss function: 5.300, Average Loss: 4.201, avg. samples / sec: 66259.95
Iteration:    920, Loss function: 5.218, Average Loss: 4.235, avg. samples / sec: 66039.28
Iteration:    920, Loss function: 5.419, Average Loss: 4.236, avg. samples / sec: 65989.15
Iteration:    920, Loss function: 4.994, Average Loss: 4.254, avg. samples / sec: 66069.12
Iteration:    920, Loss function: 4.329, Average Loss: 4.236, avg. samples / sec: 66123.37
Iteration:    920, Loss function: 4.688, Average Loss: 4.220, avg. samples / sec: 65980.38
Iteration:    920, Loss function: 4.492, Average Loss: 4.252, avg. samples / sec: 66034.30
Iteration:    920, Loss function: 4.981, Average Loss: 4.226, avg. samples / sec: 66038.32
Iteration:    920, Loss function: 5.386, Average Loss: 4.221, avg. samples / sec: 65961.36
Iteration:    940, Loss function: 6.789, Average Loss: 4.279, avg. samples / sec: 66398.93
Iteration:    940, Loss function: 6.027, Average Loss: 4.248, avg. samples / sec: 66521.98
Iteration:    940, Loss function: 4.936, Average Loss: 4.255, avg. samples / sec: 66512.15
Iteration:    940, Loss function: 5.522, Average Loss: 4.265, avg. samples / sec: 66424.91
Iteration:    940, Loss function: 6.279, Average Loss: 4.255, avg. samples / sec: 66386.42
Iteration:    940, Loss function: 6.002, Average Loss: 4.218, avg. samples / sec: 66481.63
Iteration:    940, Loss function: 4.949, Average Loss: 4.257, avg. samples / sec: 66478.43
Iteration:    940, Loss function: 6.003, Average Loss: 4.263, avg. samples / sec: 66386.39
Iteration:    940, Loss function: 4.910, Average Loss: 4.270, avg. samples / sec: 66501.42
Iteration:    940, Loss function: 5.273, Average Loss: 4.252, avg. samples / sec: 66447.08
Iteration:    940, Loss function: 6.389, Average Loss: 4.234, avg. samples / sec: 66489.34
Iteration:    940, Loss function: 5.637, Average Loss: 4.255, avg. samples / sec: 66469.18
Iteration:    940, Loss function: 5.942, Average Loss: 4.257, avg. samples / sec: 66373.13
Iteration:    940, Loss function: 5.183, Average Loss: 4.221, avg. samples / sec: 66455.29
Iteration:    940, Loss function: 5.718, Average Loss: 4.277, avg. samples / sec: 66460.06
Iteration:    940, Loss function: 6.423, Average Loss: 4.245, avg. samples / sec: 66374.04
Iteration:    940, Loss function: 4.236, Average Loss: 4.241, avg. samples / sec: 66498.72
Iteration:    940, Loss function: 6.223, Average Loss: 4.254, avg. samples / sec: 66348.70
Iteration:    940, Loss function: 5.472, Average Loss: 4.235, avg. samples / sec: 66302.34
Iteration:    940, Loss function: 5.240, Average Loss: 4.252, avg. samples / sec: 66384.11
Iteration:    940, Loss function: 6.724, Average Loss: 4.272, avg. samples / sec: 66298.91
Iteration:    940, Loss function: 5.678, Average Loss: 4.257, avg. samples / sec: 66256.05
Iteration:    940, Loss function: 4.830, Average Loss: 4.249, avg. samples / sec: 66373.35
Iteration:    940, Loss function: 5.816, Average Loss: 4.266, avg. samples / sec: 66325.15
Iteration:    940, Loss function: 5.822, Average Loss: 4.262, avg. samples / sec: 66309.08
Iteration:    940, Loss function: 5.997, Average Loss: 4.269, avg. samples / sec: 66387.30
Iteration:    940, Loss function: 5.859, Average Loss: 4.253, avg. samples / sec: 66346.01
Iteration:    940, Loss function: 4.270, Average Loss: 4.240, avg. samples / sec: 66461.69
Iteration:    940, Loss function: 5.498, Average Loss: 4.238, avg. samples / sec: 66188.59
Iteration:    940, Loss function: 5.459, Average Loss: 4.257, avg. samples / sec: 66054.85
Iteration:    960, Loss function: 6.492, Average Loss: 4.274, avg. samples / sec: 66903.31
Iteration:    960, Loss function: 4.616, Average Loss: 4.274, avg. samples / sec: 66669.76
Iteration:    960, Loss function: 5.176, Average Loss: 4.274, avg. samples / sec: 66717.61
Iteration:    960, Loss function: 6.507, Average Loss: 4.277, avg. samples / sec: 66645.90
Iteration:    960, Loss function: 3.367, Average Loss: 4.285, avg. samples / sec: 66848.41
Iteration:    960, Loss function: 4.443, Average Loss: 4.269, avg. samples / sec: 66612.47
Iteration:    960, Loss function: 6.199, Average Loss: 4.238, avg. samples / sec: 66616.00
Iteration:    960, Loss function: 6.157, Average Loss: 4.272, avg. samples / sec: 66749.34
Iteration:    960, Loss function: 5.831, Average Loss: 4.256, avg. samples / sec: 66747.89
Iteration:    960, Loss function: 4.746, Average Loss: 4.281, avg. samples / sec: 66542.93
Iteration:    960, Loss function: 4.566, Average Loss: 4.258, avg. samples / sec: 66791.10
Iteration:    960, Loss function: 5.187, Average Loss: 4.237, avg. samples / sec: 66658.51
Iteration:    960, Loss function: 4.440, Average Loss: 4.270, avg. samples / sec: 66696.21
Iteration:    960, Loss function: 5.981, Average Loss: 4.290, avg. samples / sec: 66739.54
Iteration:    960, Loss function: 4.929, Average Loss: 4.285, avg. samples / sec: 66587.64
Iteration:    960, Loss function: 4.760, Average Loss: 4.299, avg. samples / sec: 66477.02
Iteration:    960, Loss function: 4.711, Average Loss: 4.270, avg. samples / sec: 66636.29
Iteration:    960, Loss function: 4.852, Average Loss: 4.278, avg. samples / sec: 66742.57
Iteration:    960, Loss function: 4.614, Average Loss: 4.283, avg. samples / sec: 66715.81
Iteration:    960, Loss function: 6.488, Average Loss: 4.294, avg. samples / sec: 66605.80
Iteration:    960, Loss function: 4.983, Average Loss: 4.261, avg. samples / sec: 66780.27
Iteration:    960, Loss function: 5.175, Average Loss: 4.286, avg. samples / sec: 66683.20
Iteration:    960, Loss function: 5.864, Average Loss: 4.290, avg. samples / sec: 66561.19
Iteration:    960, Loss function: 5.553, Average Loss: 4.280, avg. samples / sec: 66924.22
Iteration:    960, Loss function: 3.796, Average Loss: 4.273, avg. samples / sec: 66635.88
Iteration:    960, Loss function: 5.769, Average Loss: 4.268, avg. samples / sec: 66627.72
Iteration:    960, Loss function: 6.260, Average Loss: 4.276, avg. samples / sec: 66495.33
Iteration:    960, Loss function: 4.074, Average Loss: 4.262, avg. samples / sec: 66549.59
Iteration:    960, Loss function: 5.691, Average Loss: 4.256, avg. samples / sec: 66502.30
Iteration:    960, Loss function: 5.776, Average Loss: 4.286, avg. samples / sec: 66358.82
:::MLL 1558651883.233 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558651883.234 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 5.774, Average Loss: 4.289, avg. samples / sec: 66345.92
Iteration:    980, Loss function: 4.741, Average Loss: 4.297, avg. samples / sec: 66304.03
Iteration:    980, Loss function: 4.708, Average Loss: 4.298, avg. samples / sec: 66538.16
Iteration:    980, Loss function: 5.041, Average Loss: 4.310, avg. samples / sec: 66360.32
Iteration:    980, Loss function: 5.307, Average Loss: 4.298, avg. samples / sec: 66323.16
Iteration:    980, Loss function: 5.173, Average Loss: 4.253, avg. samples / sec: 66290.77
Iteration:    980, Loss function: 5.506, Average Loss: 4.276, avg. samples / sec: 66357.23
Iteration:    980, Loss function: 5.172, Average Loss: 4.289, avg. samples / sec: 66151.53
Iteration:    980, Loss function: 4.797, Average Loss: 4.285, avg. samples / sec: 66209.18
Iteration:    980, Loss function: 3.514, Average Loss: 4.295, avg. samples / sec: 66450.09
Iteration:    980, Loss function: 4.330, Average Loss: 4.293, avg. samples / sec: 66305.46
Iteration:    980, Loss function: 5.196, Average Loss: 4.273, avg. samples / sec: 66253.97
Iteration:    980, Loss function: 5.443, Average Loss: 4.306, avg. samples / sec: 66330.90
Iteration:    980, Loss function: 4.145, Average Loss: 4.273, avg. samples / sec: 66250.85
Iteration:    980, Loss function: 5.388, Average Loss: 4.286, avg. samples / sec: 66199.44
Iteration:    980, Loss function: 5.391, Average Loss: 4.253, avg. samples / sec: 66239.39
Iteration:    980, Loss function: 3.882, Average Loss: 4.282, avg. samples / sec: 66351.67
Iteration:    980, Loss function: 3.986, Average Loss: 4.305, avg. samples / sec: 66298.69
Iteration:    980, Loss function: 4.692, Average Loss: 4.286, avg. samples / sec: 66197.36
Iteration:    980, Loss function: 5.548, Average Loss: 4.300, avg. samples / sec: 66225.63
Iteration:    980, Loss function: 6.072, Average Loss: 4.278, avg. samples / sec: 66284.82
Iteration:    980, Loss function: 5.693, Average Loss: 4.297, avg. samples / sec: 66160.53
Iteration:    980, Loss function: 4.551, Average Loss: 4.286, avg. samples / sec: 66042.00
Iteration:    980, Loss function: 4.398, Average Loss: 4.293, avg. samples / sec: 66190.18
Iteration:    980, Loss function: 4.472, Average Loss: 4.300, avg. samples / sec: 66116.74
Iteration:    980, Loss function: 4.022, Average Loss: 4.300, avg. samples / sec: 66122.66
Iteration:    980, Loss function: 6.229, Average Loss: 4.304, avg. samples / sec: 66020.56
Iteration:    980, Loss function: 4.244, Average Loss: 4.299, avg. samples / sec: 66123.09
Iteration:    980, Loss function: 4.426, Average Loss: 4.270, avg. samples / sec: 66235.88
Iteration:    980, Loss function: 3.881, Average Loss: 4.291, avg. samples / sec: 66201.31
Iteration:   1000, Loss function: 4.696, Average Loss: 4.266, avg. samples / sec: 66578.71
Iteration:   1000, Loss function: 5.500, Average Loss: 4.304, avg. samples / sec: 66382.76
Iteration:   1000, Loss function: 5.565, Average Loss: 4.316, avg. samples / sec: 66418.80
Iteration:   1000, Loss function: 4.753, Average Loss: 4.314, avg. samples / sec: 66429.39
Iteration:   1000, Loss function: 4.806, Average Loss: 4.302, avg. samples / sec: 66480.72
Iteration:   1000, Loss function: 6.201, Average Loss: 4.327, avg. samples / sec: 66414.02
Iteration:   1000, Loss function: 5.656, Average Loss: 4.314, avg. samples / sec: 66684.43
Iteration:   1000, Loss function: 5.568, Average Loss: 4.315, avg. samples / sec: 66423.19
Iteration:   1000, Loss function: 4.909, Average Loss: 4.315, avg. samples / sec: 66647.95
Iteration:   1000, Loss function: 4.964, Average Loss: 4.315, avg. samples / sec: 66439.85
Iteration:   1000, Loss function: 6.330, Average Loss: 4.267, avg. samples / sec: 66372.54
Iteration:   1000, Loss function: 3.892, Average Loss: 4.299, avg. samples / sec: 66396.96
Iteration:   1000, Loss function: 5.266, Average Loss: 4.302, avg. samples / sec: 66588.84
Iteration:   1000, Loss function: 4.897, Average Loss: 4.308, avg. samples / sec: 66621.35
Iteration:   1000, Loss function: 5.887, Average Loss: 4.310, avg. samples / sec: 66574.02
Iteration:   1000, Loss function: 3.960, Average Loss: 4.319, avg. samples / sec: 66412.95
Iteration:   1000, Loss function: 3.770, Average Loss: 4.285, avg. samples / sec: 66446.64
Iteration:   1000, Loss function: 4.122, Average Loss: 4.303, avg. samples / sec: 66416.05
Iteration:   1000, Loss function: 4.984, Average Loss: 4.304, avg. samples / sec: 66355.29
Iteration:   1000, Loss function: 4.057, Average Loss: 4.308, avg. samples / sec: 66536.05
Iteration:   1000, Loss function: 5.196, Average Loss: 4.287, avg. samples / sec: 66330.65
Iteration:   1000, Loss function: 5.396, Average Loss: 4.306, avg. samples / sec: 66464.54
Iteration:   1000, Loss function: 5.645, Average Loss: 4.319, avg. samples / sec: 66522.55
Iteration:   1000, Loss function: 4.528, Average Loss: 4.280, avg. samples / sec: 66315.48
Iteration:   1000, Loss function: 4.616, Average Loss: 4.314, avg. samples / sec: 66401.44
Iteration:   1000, Loss function: 5.670, Average Loss: 4.316, avg. samples / sec: 66333.02
Iteration:   1000, Loss function: 6.046, Average Loss: 4.308, avg. samples / sec: 66488.68
Iteration:   1000, Loss function: 5.953, Average Loss: 4.298, avg. samples / sec: 66326.28
Iteration:   1000, Loss function: 4.552, Average Loss: 4.291, avg. samples / sec: 66378.45
Iteration:   1000, Loss function: 5.198, Average Loss: 4.285, avg. samples / sec: 66398.68
Iteration:   1020, Loss function: 4.770, Average Loss: 4.334, avg. samples / sec: 66284.88
Iteration:   1020, Loss function: 5.700, Average Loss: 4.332, avg. samples / sec: 66297.23
Iteration:   1020, Loss function: 4.659, Average Loss: 4.319, avg. samples / sec: 66276.90
Iteration:   1020, Loss function: 4.375, Average Loss: 4.344, avg. samples / sec: 66275.62
Iteration:   1020, Loss function: 5.192, Average Loss: 4.334, avg. samples / sec: 66276.74
Iteration:   1020, Loss function: 4.313, Average Loss: 4.318, avg. samples / sec: 66367.04
Iteration:   1020, Loss function: 4.990, Average Loss: 4.335, avg. samples / sec: 66256.05
Iteration:   1020, Loss function: 4.688, Average Loss: 4.302, avg. samples / sec: 66354.48
Iteration:   1020, Loss function: 4.894, Average Loss: 4.282, avg. samples / sec: 66261.79
Iteration:   1020, Loss function: 5.622, Average Loss: 4.300, avg. samples / sec: 66386.48
Iteration:   1020, Loss function: 3.403, Average Loss: 4.329, avg. samples / sec: 66437.12
Iteration:   1020, Loss function: 5.772, Average Loss: 4.325, avg. samples / sec: 66173.30
Iteration:   1020, Loss function: 4.538, Average Loss: 4.325, avg. samples / sec: 66262.91
Iteration:   1020, Loss function: 4.700, Average Loss: 4.319, avg. samples / sec: 66246.37
Iteration:   1020, Loss function: 5.800, Average Loss: 4.284, avg. samples / sec: 66129.83
Iteration:   1020, Loss function: 5.457, Average Loss: 4.330, avg. samples / sec: 66166.37
Iteration:   1020, Loss function: 6.087, Average Loss: 4.334, avg. samples / sec: 66245.03
Iteration:   1020, Loss function: 4.661, Average Loss: 4.325, avg. samples / sec: 66386.36
Iteration:   1020, Loss function: 6.763, Average Loss: 4.316, avg. samples / sec: 66213.41
Iteration:   1020, Loss function: 6.375, Average Loss: 4.326, avg. samples / sec: 66201.96
Iteration:   1020, Loss function: 4.129, Average Loss: 4.329, avg. samples / sec: 66171.31
Iteration:   1020, Loss function: 6.025, Average Loss: 4.336, avg. samples / sec: 66278.89
Iteration:   1020, Loss function: 4.949, Average Loss: 4.317, avg. samples / sec: 66230.77
Iteration:   1020, Loss function: 4.919, Average Loss: 4.323, avg. samples / sec: 66224.27
Iteration:   1020, Loss function: 5.339, Average Loss: 4.302, avg. samples / sec: 66181.47
Iteration:   1020, Loss function: 4.558, Average Loss: 4.310, avg. samples / sec: 66332.61
Iteration:   1020, Loss function: 5.078, Average Loss: 4.325, avg. samples / sec: 66225.07
Iteration:   1020, Loss function: 5.675, Average Loss: 4.310, avg. samples / sec: 66349.63
Iteration:   1020, Loss function: 5.691, Average Loss: 4.300, avg. samples / sec: 66299.88
Iteration:   1020, Loss function: 4.570, Average Loss: 4.332, avg. samples / sec: 66208.90
Iteration:   1040, Loss function: 5.880, Average Loss: 4.299, avg. samples / sec: 66437.15
Iteration:   1040, Loss function: 5.819, Average Loss: 4.350, avg. samples / sec: 66402.50
Iteration:   1040, Loss function: 5.457, Average Loss: 4.362, avg. samples / sec: 66339.33
Iteration:   1040, Loss function: 6.169, Average Loss: 4.340, avg. samples / sec: 66348.79
Iteration:   1040, Loss function: 4.653, Average Loss: 4.344, avg. samples / sec: 66262.35
Iteration:   1040, Loss function: 5.392, Average Loss: 4.336, avg. samples / sec: 66285.35
Iteration:   1040, Loss function: 6.210, Average Loss: 4.347, avg. samples / sec: 66454.82
Iteration:   1040, Loss function: 4.500, Average Loss: 4.337, avg. samples / sec: 66368.48
Iteration:   1040, Loss function: 5.526, Average Loss: 4.320, avg. samples / sec: 66339.20
Iteration:   1040, Loss function: 5.150, Average Loss: 4.342, avg. samples / sec: 66241.67
Iteration:   1040, Loss function: 4.918, Average Loss: 4.341, avg. samples / sec: 66332.15
Iteration:   1040, Loss function: 5.931, Average Loss: 4.345, avg. samples / sec: 66337.55
Iteration:   1040, Loss function: 6.100, Average Loss: 4.332, avg. samples / sec: 66353.76
Iteration:   1040, Loss function: 4.679, Average Loss: 4.331, avg. samples / sec: 66389.64
Iteration:   1040, Loss function: 5.086, Average Loss: 4.346, avg. samples / sec: 66301.25
Iteration:   1040, Loss function: 5.406, Average Loss: 4.324, avg. samples / sec: 66366.60
Iteration:   1040, Loss function: 5.612, Average Loss: 4.342, avg. samples / sec: 66310.98
Iteration:   1040, Loss function: 4.273, Average Loss: 4.314, avg. samples / sec: 66220.41
Iteration:   1040, Loss function: 5.671, Average Loss: 4.346, avg. samples / sec: 66320.38
Iteration:   1040, Loss function: 4.524, Average Loss: 4.346, avg. samples / sec: 66174.14
Iteration:   1040, Loss function: 4.088, Average Loss: 4.341, avg. samples / sec: 66222.74
Iteration:   1040, Loss function: 4.404, Average Loss: 4.315, avg. samples / sec: 66420.84
Iteration:   1040, Loss function: 4.848, Average Loss: 4.351, avg. samples / sec: 66422.22
Iteration:   1040, Loss function: 5.874, Average Loss: 4.355, avg. samples / sec: 66268.39
Iteration:   1040, Loss function: 4.358, Average Loss: 4.307, avg. samples / sec: 66228.87
Iteration:   1040, Loss function: 4.980, Average Loss: 4.346, avg. samples / sec: 66297.32
Iteration:   1040, Loss function: 5.064, Average Loss: 4.333, avg. samples / sec: 66257.11
Iteration:   1040, Loss function: 4.137, Average Loss: 4.323, avg. samples / sec: 66258.45
Iteration:   1040, Loss function: 4.220, Average Loss: 4.326, avg. samples / sec: 66247.18
Iteration:   1040, Loss function: 4.998, Average Loss: 4.353, avg. samples / sec: 66195.31
:::MLL 1558651885.008 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558651885.009 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 4.419, Average Loss: 4.309, avg. samples / sec: 65945.92
Iteration:   1060, Loss function: 6.231, Average Loss: 4.359, avg. samples / sec: 66020.41
Iteration:   1060, Loss function: 6.102, Average Loss: 4.352, avg. samples / sec: 65960.49
Iteration:   1060, Loss function: 3.521, Average Loss: 4.381, avg. samples / sec: 65932.35
Iteration:   1060, Loss function: 4.839, Average Loss: 4.329, avg. samples / sec: 66058.25
Iteration:   1060, Loss function: 5.596, Average Loss: 4.373, avg. samples / sec: 66084.68
Iteration:   1060, Loss function: 4.718, Average Loss: 4.351, avg. samples / sec: 65880.26
Iteration:   1060, Loss function: 5.142, Average Loss: 4.357, avg. samples / sec: 65935.28
Iteration:   1060, Loss function: 5.285, Average Loss: 4.356, avg. samples / sec: 65865.23
Iteration:   1060, Loss function: 4.847, Average Loss: 4.357, avg. samples / sec: 65858.25
Iteration:   1060, Loss function: 4.650, Average Loss: 4.359, avg. samples / sec: 65980.75
Iteration:   1060, Loss function: 5.634, Average Loss: 4.357, avg. samples / sec: 65885.99
Iteration:   1060, Loss function: 4.536, Average Loss: 4.365, avg. samples / sec: 65972.10
Iteration:   1060, Loss function: 5.985, Average Loss: 4.365, avg. samples / sec: 66061.17
Iteration:   1060, Loss function: 4.890, Average Loss: 4.345, avg. samples / sec: 65909.47
Iteration:   1060, Loss function: 5.583, Average Loss: 4.347, avg. samples / sec: 65851.14
Iteration:   1060, Loss function: 5.375, Average Loss: 4.347, avg. samples / sec: 65891.78
Iteration:   1060, Loss function: 5.089, Average Loss: 4.328, avg. samples / sec: 66000.34
Iteration:   1060, Loss function: 5.696, Average Loss: 4.357, avg. samples / sec: 65931.55
Iteration:   1060, Loss function: 5.337, Average Loss: 4.363, avg. samples / sec: 65735.22
Iteration:   1060, Loss function: 5.333, Average Loss: 4.348, avg. samples / sec: 66001.73
Iteration:   1060, Loss function: 4.929, Average Loss: 4.337, avg. samples / sec: 66034.61
Iteration:   1060, Loss function: 5.024, Average Loss: 4.358, avg. samples / sec: 65941.67
Iteration:   1060, Loss function: 4.482, Average Loss: 4.367, avg. samples / sec: 65875.86
Iteration:   1060, Loss function: 4.832, Average Loss: 4.350, avg. samples / sec: 65865.91
Iteration:   1060, Loss function: 5.445, Average Loss: 4.332, avg. samples / sec: 65737.61
Iteration:   1060, Loss function: 4.353, Average Loss: 4.335, avg. samples / sec: 65921.37
Iteration:   1060, Loss function: 4.066, Average Loss: 4.336, avg. samples / sec: 65821.95
Iteration:   1060, Loss function: 4.212, Average Loss: 4.363, avg. samples / sec: 65895.11
Iteration:   1060, Loss function: 5.956, Average Loss: 4.327, avg. samples / sec: 65821.15
Iteration:   1080, Loss function: 5.895, Average Loss: 4.381, avg. samples / sec: 66637.45
Iteration:   1080, Loss function: 5.391, Average Loss: 4.368, avg. samples / sec: 66527.45
Iteration:   1080, Loss function: 5.164, Average Loss: 4.369, avg. samples / sec: 66387.95
Iteration:   1080, Loss function: 4.961, Average Loss: 4.373, avg. samples / sec: 66574.49
Iteration:   1080, Loss function: 5.594, Average Loss: 4.373, avg. samples / sec: 66535.49
Iteration:   1080, Loss function: 4.320, Average Loss: 4.363, avg. samples / sec: 66521.32
Iteration:   1080, Loss function: 5.017, Average Loss: 4.367, avg. samples / sec: 66611.12
Iteration:   1080, Loss function: 4.806, Average Loss: 4.347, avg. samples / sec: 66477.02
Iteration:   1080, Loss function: 5.433, Average Loss: 4.379, avg. samples / sec: 66458.21
Iteration:   1080, Loss function: 4.073, Average Loss: 4.363, avg. samples / sec: 66307.77
Iteration:   1080, Loss function: 3.556, Average Loss: 4.373, avg. samples / sec: 66431.58
Iteration:   1080, Loss function: 4.860, Average Loss: 4.375, avg. samples / sec: 66486.20
Iteration:   1080, Loss function: 4.354, Average Loss: 4.395, avg. samples / sec: 66310.61
Iteration:   1080, Loss function: 4.824, Average Loss: 4.381, avg. samples / sec: 66337.02
Iteration:   1080, Loss function: 4.638, Average Loss: 4.381, avg. samples / sec: 66422.75
Iteration:   1080, Loss function: 4.877, Average Loss: 4.342, avg. samples / sec: 66522.01
Iteration:   1080, Loss function: 6.006, Average Loss: 4.354, avg. samples / sec: 66518.78
Iteration:   1080, Loss function: 4.748, Average Loss: 4.319, avg. samples / sec: 66230.74
Iteration:   1080, Loss function: 5.849, Average Loss: 4.363, avg. samples / sec: 66477.64
Iteration:   1080, Loss function: 3.573, Average Loss: 4.358, avg. samples / sec: 66385.08
Iteration:   1080, Loss function: 5.771, Average Loss: 4.355, avg. samples / sec: 66380.61
Iteration:   1080, Loss function: 4.800, Average Loss: 4.342, avg. samples / sec: 66279.08
Iteration:   1080, Loss function: 5.198, Average Loss: 4.369, avg. samples / sec: 66297.38
Iteration:   1080, Loss function: 4.383, Average Loss: 4.349, avg. samples / sec: 66413.01
Iteration:   1080, Loss function: 5.060, Average Loss: 4.366, avg. samples / sec: 66398.28
Iteration:   1080, Loss function: 4.373, Average Loss: 4.367, avg. samples / sec: 66283.79
Iteration:   1080, Loss function: 4.024, Average Loss: 4.348, avg. samples / sec: 66432.86
Iteration:   1080, Loss function: 3.932, Average Loss: 4.366, avg. samples / sec: 66274.22
Iteration:   1080, Loss function: 4.877, Average Loss: 4.374, avg. samples / sec: 66347.51
Iteration:   1080, Loss function: 4.391, Average Loss: 4.341, avg. samples / sec: 66429.26
Iteration:   1100, Loss function: 4.893, Average Loss: 4.386, avg. samples / sec: 66486.93
Iteration:   1100, Loss function: 4.817, Average Loss: 4.378, avg. samples / sec: 66485.51
Iteration:   1100, Loss function: 4.404, Average Loss: 4.405, avg. samples / sec: 66571.63
Iteration:   1100, Loss function: 6.065, Average Loss: 4.383, avg. samples / sec: 66428.23
Iteration:   1100, Loss function: 4.700, Average Loss: 4.333, avg. samples / sec: 66552.71
Iteration:   1100, Loss function: 5.250, Average Loss: 4.383, avg. samples / sec: 66579.59
Iteration:   1100, Loss function: 4.162, Average Loss: 4.383, avg. samples / sec: 66360.54
Iteration:   1100, Loss function: 4.237, Average Loss: 4.367, avg. samples / sec: 66542.71
Iteration:   1100, Loss function: 4.898, Average Loss: 4.382, avg. samples / sec: 66547.27
Iteration:   1100, Loss function: 4.581, Average Loss: 4.375, avg. samples / sec: 66453.85
Iteration:   1100, Loss function: 5.706, Average Loss: 4.384, avg. samples / sec: 66412.48
Iteration:   1100, Loss function: 5.442, Average Loss: 4.368, avg. samples / sec: 66499.82
Iteration:   1100, Loss function: 5.952, Average Loss: 4.388, avg. samples / sec: 66446.14
Iteration:   1100, Loss function: 5.580, Average Loss: 4.373, avg. samples / sec: 66492.38
Iteration:   1100, Loss function: 5.869, Average Loss: 4.386, avg. samples / sec: 66315.35
Iteration:   1100, Loss function: 5.169, Average Loss: 4.383, avg. samples / sec: 66497.25
Iteration:   1100, Loss function: 4.623, Average Loss: 4.388, avg. samples / sec: 66289.59
Iteration:   1100, Loss function: 5.052, Average Loss: 4.355, avg. samples / sec: 66377.10
Iteration:   1100, Loss function: 4.005, Average Loss: 4.372, avg. samples / sec: 66441.44
Iteration:   1100, Loss function: 5.533, Average Loss: 4.393, avg. samples / sec: 66369.29
Iteration:   1100, Loss function: 5.737, Average Loss: 4.355, avg. samples / sec: 66565.94
Iteration:   1100, Loss function: 4.981, Average Loss: 4.391, avg. samples / sec: 66400.87
Iteration:   1100, Loss function: 4.777, Average Loss: 4.392, avg. samples / sec: 66389.74
Iteration:   1100, Loss function: 5.063, Average Loss: 4.354, avg. samples / sec: 66374.45
Iteration:   1100, Loss function: 5.413, Average Loss: 4.372, avg. samples / sec: 66449.40
Iteration:   1100, Loss function: 4.979, Average Loss: 4.393, avg. samples / sec: 66279.74
Iteration:   1100, Loss function: 5.549, Average Loss: 4.367, avg. samples / sec: 66418.08
Iteration:   1100, Loss function: 4.542, Average Loss: 4.356, avg. samples / sec: 66321.88
Iteration:   1100, Loss function: 6.191, Average Loss: 4.388, avg. samples / sec: 66382.73
Iteration:   1100, Loss function: 4.099, Average Loss: 4.362, avg. samples / sec: 66264.15
:::MLL 1558651886.782 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558651886.782 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 5.591, Average Loss: 4.365, avg. samples / sec: 66523.99
Iteration:   1120, Loss function: 4.282, Average Loss: 4.395, avg. samples / sec: 66251.66
Iteration:   1120, Loss function: 4.536, Average Loss: 4.405, avg. samples / sec: 66354.23
Iteration:   1120, Loss function: 3.665, Average Loss: 4.376, avg. samples / sec: 66213.90
Iteration:   1120, Loss function: 4.945, Average Loss: 4.387, avg. samples / sec: 66131.07
Iteration:   1120, Loss function: 4.383, Average Loss: 4.342, avg. samples / sec: 66164.60
Iteration:   1120, Loss function: 6.118, Average Loss: 4.394, avg. samples / sec: 66092.43
Iteration:   1120, Loss function: 4.054, Average Loss: 4.401, avg. samples / sec: 66369.73
Iteration:   1120, Loss function: 5.406, Average Loss: 4.392, avg. samples / sec: 66182.40
Iteration:   1120, Loss function: 4.044, Average Loss: 4.382, avg. samples / sec: 66201.52
Iteration:   1120, Loss function: 4.868, Average Loss: 4.416, avg. samples / sec: 66082.48
Iteration:   1120, Loss function: 4.604, Average Loss: 4.373, avg. samples / sec: 66441.19
Iteration:   1120, Loss function: 4.812, Average Loss: 4.393, avg. samples / sec: 66234.29
Iteration:   1120, Loss function: 4.961, Average Loss: 4.391, avg. samples / sec: 66133.40
Iteration:   1120, Loss function: 3.654, Average Loss: 4.397, avg. samples / sec: 66250.10
Iteration:   1120, Loss function: 3.599, Average Loss: 4.397, avg. samples / sec: 66234.26
Iteration:   1120, Loss function: 4.663, Average Loss: 4.395, avg. samples / sec: 66120.46
Iteration:   1120, Loss function: 5.337, Average Loss: 4.401, avg. samples / sec: 66358.57
Iteration:   1120, Loss function: 6.375, Average Loss: 4.400, avg. samples / sec: 66140.26
Iteration:   1120, Loss function: 5.830, Average Loss: 4.379, avg. samples / sec: 66131.38
Iteration:   1120, Loss function: 4.108, Average Loss: 4.378, avg. samples / sec: 66308.27
Iteration:   1120, Loss function: 5.290, Average Loss: 4.394, avg. samples / sec: 66144.60
Iteration:   1120, Loss function: 4.511, Average Loss: 4.381, avg. samples / sec: 66127.28
Iteration:   1120, Loss function: 3.465, Average Loss: 4.378, avg. samples / sec: 66155.00
Iteration:   1120, Loss function: 3.106, Average Loss: 4.380, avg. samples / sec: 66207.03
Iteration:   1120, Loss function: 4.493, Average Loss: 4.366, avg. samples / sec: 66127.93
Iteration:   1120, Loss function: 6.271, Average Loss: 4.392, avg. samples / sec: 66059.65
Iteration:   1120, Loss function: 3.819, Average Loss: 4.392, avg. samples / sec: 66066.96
Iteration:   1120, Loss function: 4.182, Average Loss: 4.365, avg. samples / sec: 66149.38
Iteration:   1120, Loss function: 5.053, Average Loss: 4.362, avg. samples / sec: 66088.49
Iteration:   1140, Loss function: 4.846, Average Loss: 4.349, avg. samples / sec: 66212.29
Iteration:   1140, Loss function: 5.837, Average Loss: 4.405, avg. samples / sec: 66194.40
Iteration:   1140, Loss function: 4.742, Average Loss: 4.399, avg. samples / sec: 66158.54
Iteration:   1140, Loss function: 4.690, Average Loss: 4.404, avg. samples / sec: 66206.19
Iteration:   1140, Loss function: 5.614, Average Loss: 4.422, avg. samples / sec: 66148.61
Iteration:   1140, Loss function: 4.242, Average Loss: 4.401, avg. samples / sec: 66003.87
Iteration:   1140, Loss function: 5.441, Average Loss: 4.402, avg. samples / sec: 66217.17
Iteration:   1140, Loss function: 5.931, Average Loss: 4.378, avg. samples / sec: 66256.61
Iteration:   1140, Loss function: 6.162, Average Loss: 4.390, avg. samples / sec: 66240.20
Iteration:   1140, Loss function: 5.489, Average Loss: 4.377, avg. samples / sec: 66294.67
Iteration:   1140, Loss function: 6.451, Average Loss: 4.394, avg. samples / sec: 66109.48
Iteration:   1140, Loss function: 5.878, Average Loss: 4.405, avg. samples / sec: 66111.18
Iteration:   1140, Loss function: 5.031, Average Loss: 4.391, avg. samples / sec: 66151.03
Iteration:   1140, Loss function: 4.687, Average Loss: 4.413, avg. samples / sec: 66006.21
Iteration:   1140, Loss function: 4.487, Average Loss: 4.374, avg. samples / sec: 66270.70
Iteration:   1140, Loss function: 4.046, Average Loss: 4.403, avg. samples / sec: 66044.60
Iteration:   1140, Loss function: 6.502, Average Loss: 4.406, avg. samples / sec: 66201.80
Iteration:   1140, Loss function: 4.092, Average Loss: 4.408, avg. samples / sec: 66118.57
Iteration:   1140, Loss function: 6.804, Average Loss: 4.401, avg. samples / sec: 66091.19
Iteration:   1140, Loss function: 4.773, Average Loss: 4.401, avg. samples / sec: 66236.44
Iteration:   1140, Loss function: 4.927, Average Loss: 4.383, avg. samples / sec: 66012.09
Iteration:   1140, Loss function: 4.161, Average Loss: 4.415, avg. samples / sec: 66023.75
Iteration:   1140, Loss function: 4.158, Average Loss: 4.392, avg. samples / sec: 66125.89
Iteration:   1140, Loss function: 5.505, Average Loss: 4.374, avg. samples / sec: 65897.88
Iteration:   1140, Loss function: 4.279, Average Loss: 4.403, avg. samples / sec: 66036.87
Iteration:   1140, Loss function: 3.887, Average Loss: 4.402, avg. samples / sec: 66028.88
Iteration:   1140, Loss function: 5.287, Average Loss: 4.407, avg. samples / sec: 66022.82
Iteration:   1140, Loss function: 4.182, Average Loss: 4.388, avg. samples / sec: 66060.24
Iteration:   1140, Loss function: 5.283, Average Loss: 4.386, avg. samples / sec: 66018.55
Iteration:   1140, Loss function: 6.111, Average Loss: 4.387, avg. samples / sec: 65947.59
Iteration:   1160, Loss function: 3.683, Average Loss: 4.363, avg. samples / sec: 66275.84
Iteration:   1160, Loss function: 5.631, Average Loss: 4.391, avg. samples / sec: 66376.29
Iteration:   1160, Loss function: 5.650, Average Loss: 4.410, avg. samples / sec: 66351.17
Iteration:   1160, Loss function: 4.018, Average Loss: 4.405, avg. samples / sec: 66350.42
Iteration:   1160, Loss function: 4.869, Average Loss: 4.422, avg. samples / sec: 66345.32
Iteration:   1160, Loss function: 5.264, Average Loss: 4.414, avg. samples / sec: 66281.73
Iteration:   1160, Loss function: 4.993, Average Loss: 4.409, avg. samples / sec: 66308.46
Iteration:   1160, Loss function: 5.307, Average Loss: 4.398, avg. samples / sec: 66311.23
Iteration:   1160, Loss function: 5.987, Average Loss: 4.422, avg. samples / sec: 66364.76
Iteration:   1160, Loss function: 4.874, Average Loss: 4.415, avg. samples / sec: 66433.68
Iteration:   1160, Loss function: 4.088, Average Loss: 4.418, avg. samples / sec: 66191.05
Iteration:   1160, Loss function: 4.893, Average Loss: 4.431, avg. samples / sec: 66239.05
Iteration:   1160, Loss function: 5.190, Average Loss: 4.414, avg. samples / sec: 66306.74
Iteration:   1160, Loss function: 5.032, Average Loss: 4.398, avg. samples / sec: 66401.91
Iteration:   1160, Loss function: 5.332, Average Loss: 4.405, avg. samples / sec: 66275.53
Iteration:   1160, Loss function: 4.266, Average Loss: 4.381, avg. samples / sec: 66267.36
Iteration:   1160, Loss function: 5.161, Average Loss: 4.421, avg. samples / sec: 66326.75
Iteration:   1160, Loss function: 4.288, Average Loss: 4.388, avg. samples / sec: 66177.43
Iteration:   1160, Loss function: 4.409, Average Loss: 4.396, avg. samples / sec: 66225.45
Iteration:   1160, Loss function: 5.375, Average Loss: 4.411, avg. samples / sec: 66287.44
Iteration:   1160, Loss function: 4.602, Average Loss: 4.409, avg. samples / sec: 66200.72
Iteration:   1160, Loss function: 5.590, Average Loss: 4.423, avg. samples / sec: 66234.60
Iteration:   1160, Loss function: 5.078, Average Loss: 4.409, avg. samples / sec: 66076.62
Iteration:   1160, Loss function: 5.742, Average Loss: 4.403, avg. samples / sec: 66159.32
Iteration:   1160, Loss function: 3.970, Average Loss: 4.401, avg. samples / sec: 66291.02
Iteration:   1160, Loss function: 4.541, Average Loss: 4.413, avg. samples / sec: 66135.04
Iteration:   1160, Loss function: 4.902, Average Loss: 4.410, avg. samples / sec: 66170.13
Iteration:   1160, Loss function: 3.669, Average Loss: 4.394, avg. samples / sec: 66282.04
Iteration:   1160, Loss function: 5.122, Average Loss: 4.416, avg. samples / sec: 66102.25
Iteration:   1160, Loss function: 5.161, Average Loss: 4.387, avg. samples / sec: 66065.35
Iteration:   1180, Loss function: 5.085, Average Loss: 4.396, avg. samples / sec: 66369.60
Iteration:   1180, Loss function: 4.640, Average Loss: 4.443, avg. samples / sec: 66432.99
Iteration:   1180, Loss function: 4.689, Average Loss: 4.415, avg. samples / sec: 66341.33
Iteration:   1180, Loss function: 4.802, Average Loss: 4.414, avg. samples / sec: 66358.44
Iteration:   1180, Loss function: 3.968, Average Loss: 4.415, avg. samples / sec: 66549.03
Iteration:   1180, Loss function: 5.425, Average Loss: 4.428, avg. samples / sec: 66386.77
Iteration:   1180, Loss function: 4.892, Average Loss: 4.418, avg. samples / sec: 66460.34
Iteration:   1180, Loss function: 6.792, Average Loss: 4.398, avg. samples / sec: 66471.59
Iteration:   1180, Loss function: 5.344, Average Loss: 4.376, avg. samples / sec: 66235.75
Iteration:   1180, Loss function: 3.815, Average Loss: 4.430, avg. samples / sec: 66305.87
Iteration:   1180, Loss function: 5.076, Average Loss: 4.423, avg. samples / sec: 66316.54
Iteration:   1180, Loss function: 5.586, Average Loss: 4.430, avg. samples / sec: 66450.56
Iteration:   1180, Loss function: 5.271, Average Loss: 4.430, avg. samples / sec: 66423.37
Iteration:   1180, Loss function: 4.919, Average Loss: 4.431, avg. samples / sec: 66289.53
Iteration:   1180, Loss function: 4.614, Average Loss: 4.422, avg. samples / sec: 66290.40
Iteration:   1180, Loss function: 5.626, Average Loss: 4.426, avg. samples / sec: 66476.51
Iteration:   1180, Loss function: 5.192, Average Loss: 4.392, avg. samples / sec: 66397.74
Iteration:   1180, Loss function: 4.881, Average Loss: 4.410, avg. samples / sec: 66281.05
Iteration:   1180, Loss function: 4.556, Average Loss: 4.419, avg. samples / sec: 66449.97
Iteration:   1180, Loss function: 4.924, Average Loss: 4.425, avg. samples / sec: 66295.92
Iteration:   1180, Loss function: 4.025, Average Loss: 4.420, avg. samples / sec: 66232.05
Iteration:   1180, Loss function: 4.588, Average Loss: 4.414, avg. samples / sec: 66419.21
Iteration:   1180, Loss function: 3.533, Average Loss: 4.401, avg. samples / sec: 66346.92
Iteration:   1180, Loss function: 6.285, Average Loss: 4.420, avg. samples / sec: 66395.80
Iteration:   1180, Loss function: 3.967, Average Loss: 4.406, avg. samples / sec: 66423.72
Iteration:   1180, Loss function: 5.240, Average Loss: 4.423, avg. samples / sec: 66455.86
Iteration:   1180, Loss function: 4.495, Average Loss: 4.405, avg. samples / sec: 66338.23
Iteration:   1180, Loss function: 4.626, Average Loss: 4.411, avg. samples / sec: 66354.88
Iteration:   1180, Loss function: 6.208, Average Loss: 4.399, avg. samples / sec: 66456.36
Iteration:   1180, Loss function: 4.548, Average Loss: 4.421, avg. samples / sec: 66312.14
:::MLL 1558651888.558 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558651888.559 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 4.833, Average Loss: 4.421, avg. samples / sec: 66059.00
Iteration:   1200, Loss function: 4.204, Average Loss: 4.421, avg. samples / sec: 66047.64
Iteration:   1200, Loss function: 5.237, Average Loss: 4.426, avg. samples / sec: 66024.61
Iteration:   1200, Loss function: 5.366, Average Loss: 4.429, avg. samples / sec: 66158.64
Iteration:   1200, Loss function: 5.188, Average Loss: 4.388, avg. samples / sec: 66077.46
Iteration:   1200, Loss function: 4.366, Average Loss: 4.449, avg. samples / sec: 65981.86
Iteration:   1200, Loss function: 4.458, Average Loss: 4.401, avg. samples / sec: 66112.73
Iteration:   1200, Loss function: 3.807, Average Loss: 4.437, avg. samples / sec: 66046.55
Iteration:   1200, Loss function: 5.838, Average Loss: 4.436, avg. samples / sec: 66052.96
Iteration:   1200, Loss function: 5.529, Average Loss: 4.419, avg. samples / sec: 66097.08
Iteration:   1200, Loss function: 3.657, Average Loss: 4.424, avg. samples / sec: 65995.21
Iteration:   1200, Loss function: 4.142, Average Loss: 4.425, avg. samples / sec: 66063.52
Iteration:   1200, Loss function: 4.131, Average Loss: 4.425, avg. samples / sec: 66017.31
Iteration:   1200, Loss function: 4.708, Average Loss: 4.415, avg. samples / sec: 66028.08
Iteration:   1200, Loss function: 5.210, Average Loss: 4.426, avg. samples / sec: 66124.80
Iteration:   1200, Loss function: 4.456, Average Loss: 4.427, avg. samples / sec: 66055.84
Iteration:   1200, Loss function: 4.672, Average Loss: 4.441, avg. samples / sec: 65983.19
Iteration:   1200, Loss function: 5.171, Average Loss: 4.436, avg. samples / sec: 65920.41
Iteration:   1200, Loss function: 4.930, Average Loss: 4.436, avg. samples / sec: 66008.22
Iteration:   1200, Loss function: 4.833, Average Loss: 4.427, avg. samples / sec: 66040.73
Iteration:   1200, Loss function: 5.111, Average Loss: 4.409, avg. samples / sec: 65944.78
Iteration:   1200, Loss function: 4.565, Average Loss: 4.414, avg. samples / sec: 66038.97
Iteration:   1200, Loss function: 4.156, Average Loss: 4.409, avg. samples / sec: 66064.29
Iteration:   1200, Loss function: 4.851, Average Loss: 4.441, avg. samples / sec: 65943.52
Iteration:   1200, Loss function: 3.852, Average Loss: 4.405, avg. samples / sec: 66007.76
Iteration:   1200, Loss function: 5.141, Average Loss: 4.409, avg. samples / sec: 66050.02
Iteration:   1200, Loss function: 4.181, Average Loss: 4.431, avg. samples / sec: 66057.20
Iteration:   1200, Loss function: 5.059, Average Loss: 4.425, avg. samples / sec: 65858.03
Iteration:   1200, Loss function: 4.675, Average Loss: 4.409, avg. samples / sec: 65739.42
Iteration:   1200, Loss function: 5.708, Average Loss: 4.433, avg. samples / sec: 65978.93
Iteration:   1220, Loss function: 5.637, Average Loss: 4.451, avg. samples / sec: 65386.76
Iteration:   1220, Loss function: 5.813, Average Loss: 4.442, avg. samples / sec: 65202.71
Iteration:   1220, Loss function: 5.155, Average Loss: 4.460, avg. samples / sec: 65325.36
Iteration:   1220, Loss function: 4.213, Average Loss: 4.439, avg. samples / sec: 65180.66
Iteration:   1220, Loss function: 3.889, Average Loss: 4.466, avg. samples / sec: 65212.12
Iteration:   1220, Loss function: 4.214, Average Loss: 4.440, avg. samples / sec: 65297.00
Iteration:   1220, Loss function: 5.787, Average Loss: 4.438, avg. samples / sec: 65146.14
Iteration:   1220, Loss function: 4.982, Average Loss: 4.443, avg. samples / sec: 65366.75
Iteration:   1220, Loss function: 3.958, Average Loss: 4.435, avg. samples / sec: 65139.12
Iteration:   1220, Loss function: 6.026, Average Loss: 4.422, avg. samples / sec: 65311.98
Iteration:   1220, Loss function: 5.951, Average Loss: 4.438, avg. samples / sec: 65266.03
Iteration:   1220, Loss function: 5.836, Average Loss: 4.422, avg. samples / sec: 65377.97
Iteration:   1220, Loss function: 4.672, Average Loss: 4.454, avg. samples / sec: 65315.21
Iteration:   1220, Loss function: 5.801, Average Loss: 4.418, avg. samples / sec: 65254.97
Iteration:   1220, Loss function: 6.102, Average Loss: 4.436, avg. samples / sec: 65221.39
Iteration:   1220, Loss function: 5.825, Average Loss: 4.438, avg. samples / sec: 65223.47
Iteration:   1220, Loss function: 4.052, Average Loss: 4.401, avg. samples / sec: 65111.04
Iteration:   1220, Loss function: 6.366, Average Loss: 4.452, avg. samples / sec: 65362.65
Iteration:   1220, Loss function: 4.359, Average Loss: 4.429, avg. samples / sec: 65252.70
Iteration:   1220, Loss function: 5.422, Average Loss: 4.436, avg. samples / sec: 65286.41
Iteration:   1220, Loss function: 5.171, Average Loss: 4.442, avg. samples / sec: 65197.25
Iteration:   1220, Loss function: 5.434, Average Loss: 4.433, avg. samples / sec: 65141.26
Iteration:   1220, Loss function: 5.376, Average Loss: 4.412, avg. samples / sec: 65098.95
Iteration:   1220, Loss function: 6.934, Average Loss: 4.449, avg. samples / sec: 65133.76
Iteration:   1220, Loss function: 6.039, Average Loss: 4.438, avg. samples / sec: 65147.64
Iteration:   1220, Loss function: 5.419, Average Loss: 4.431, avg. samples / sec: 65162.91
Iteration:   1220, Loss function: 4.330, Average Loss: 4.447, avg. samples / sec: 65124.58
Iteration:   1220, Loss function: 5.019, Average Loss: 4.446, avg. samples / sec: 65171.11
Iteration:   1220, Loss function: 4.658, Average Loss: 4.418, avg. samples / sec: 65184.86
Iteration:   1220, Loss function: 5.936, Average Loss: 4.426, avg. samples / sec: 65177.68
Iteration:   1240, Loss function: 4.885, Average Loss: 4.404, avg. samples / sec: 66550.76
Iteration:   1240, Loss function: 6.320, Average Loss: 4.452, avg. samples / sec: 66286.72
Iteration:   1240, Loss function: 4.864, Average Loss: 4.468, avg. samples / sec: 66315.07
Iteration:   1240, Loss function: 5.037, Average Loss: 4.461, avg. samples / sec: 66242.94
Iteration:   1240, Loss function: 5.057, Average Loss: 4.455, avg. samples / sec: 66292.49
Iteration:   1240, Loss function: 5.661, Average Loss: 4.448, avg. samples / sec: 66411.70
Iteration:   1240, Loss function: 2.788, Average Loss: 4.429, avg. samples / sec: 66329.12
Iteration:   1240, Loss function: 5.050, Average Loss: 4.456, avg. samples / sec: 66259.29
Iteration:   1240, Loss function: 6.505, Average Loss: 4.446, avg. samples / sec: 66291.12
Iteration:   1240, Loss function: 5.564, Average Loss: 4.457, avg. samples / sec: 66402.28
Iteration:   1240, Loss function: 5.407, Average Loss: 4.446, avg. samples / sec: 66295.42
Iteration:   1240, Loss function: 5.110, Average Loss: 4.437, avg. samples / sec: 66258.70
Iteration:   1240, Loss function: 4.612, Average Loss: 4.456, avg. samples / sec: 66351.38
Iteration:   1240, Loss function: 4.334, Average Loss: 4.475, avg. samples / sec: 66232.17
Iteration:   1240, Loss function: 6.307, Average Loss: 4.446, avg. samples / sec: 66271.54
Iteration:   1240, Loss function: 4.465, Average Loss: 4.422, avg. samples / sec: 66341.89
Iteration:   1240, Loss function: 5.330, Average Loss: 4.453, avg. samples / sec: 66223.15
Iteration:   1240, Loss function: 4.095, Average Loss: 4.447, avg. samples / sec: 66274.75
Iteration:   1240, Loss function: 4.848, Average Loss: 4.435, avg. samples / sec: 66226.23
Iteration:   1240, Loss function: 4.762, Average Loss: 4.445, avg. samples / sec: 66318.88
Iteration:   1240, Loss function: 4.670, Average Loss: 4.442, avg. samples / sec: 66287.06
Iteration:   1240, Loss function: 5.689, Average Loss: 4.431, avg. samples / sec: 66359.63
Iteration:   1240, Loss function: 4.304, Average Loss: 4.441, avg. samples / sec: 66292.80
Iteration:   1240, Loss function: 4.993, Average Loss: 4.457, avg. samples / sec: 66294.27
Iteration:   1240, Loss function: 4.637, Average Loss: 4.438, avg. samples / sec: 66358.01
Iteration:   1240, Loss function: 4.288, Average Loss: 4.451, avg. samples / sec: 66167.65
Iteration:   1240, Loss function: 4.799, Average Loss: 4.461, avg. samples / sec: 66211.48
Iteration:   1240, Loss function: 5.614, Average Loss: 4.470, avg. samples / sec: 66174.45
Iteration:   1240, Loss function: 3.564, Average Loss: 4.448, avg. samples / sec: 66225.95
Iteration:   1240, Loss function: 5.010, Average Loss: 4.439, avg. samples / sec: 66120.36
:::MLL 1558651890.344 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558651890.345 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 4.763, Average Loss: 4.453, avg. samples / sec: 66080.77
Iteration:   1260, Loss function: 4.324, Average Loss: 4.472, avg. samples / sec: 66020.75
Iteration:   1260, Loss function: 3.441, Average Loss: 4.459, avg. samples / sec: 66083.72
Iteration:   1260, Loss function: 4.116, Average Loss: 4.457, avg. samples / sec: 65931.21
Iteration:   1260, Loss function: 5.203, Average Loss: 4.402, avg. samples / sec: 65805.78
Iteration:   1260, Loss function: 3.934, Average Loss: 4.453, avg. samples / sec: 66050.42
Iteration:   1260, Loss function: 3.876, Average Loss: 4.447, avg. samples / sec: 65947.44
Iteration:   1260, Loss function: 4.043, Average Loss: 4.448, avg. samples / sec: 66022.60
Iteration:   1260, Loss function: 5.322, Average Loss: 4.470, avg. samples / sec: 66076.75
Iteration:   1260, Loss function: 5.356, Average Loss: 4.460, avg. samples / sec: 65990.70
Iteration:   1260, Loss function: 4.364, Average Loss: 4.445, avg. samples / sec: 65946.26
Iteration:   1260, Loss function: 5.443, Average Loss: 4.465, avg. samples / sec: 65953.52
Iteration:   1260, Loss function: 4.826, Average Loss: 4.458, avg. samples / sec: 65970.13
Iteration:   1260, Loss function: 4.468, Average Loss: 4.465, avg. samples / sec: 66012.89
Iteration:   1260, Loss function: 4.182, Average Loss: 4.479, avg. samples / sec: 65924.70
Iteration:   1260, Loss function: 5.966, Average Loss: 4.465, avg. samples / sec: 65892.74
Iteration:   1260, Loss function: 4.288, Average Loss: 4.458, avg. samples / sec: 65862.65
Iteration:   1260, Loss function: 3.827, Average Loss: 4.434, avg. samples / sec: 65873.45
Iteration:   1260, Loss function: 3.961, Average Loss: 4.472, avg. samples / sec: 65806.37
Iteration:   1260, Loss function: 5.114, Average Loss: 4.443, avg. samples / sec: 65933.03
Iteration:   1260, Loss function: 4.161, Average Loss: 4.447, avg. samples / sec: 66077.18
Iteration:   1260, Loss function: 5.778, Average Loss: 4.469, avg. samples / sec: 65962.22
Iteration:   1260, Loss function: 3.980, Average Loss: 4.434, avg. samples / sec: 65901.18
Iteration:   1260, Loss function: 5.386, Average Loss: 4.452, avg. samples / sec: 65883.74
Iteration:   1260, Loss function: 5.055, Average Loss: 4.448, avg. samples / sec: 65890.33
Iteration:   1260, Loss function: 3.801, Average Loss: 4.426, avg. samples / sec: 65831.30
Iteration:   1260, Loss function: 5.143, Average Loss: 4.456, avg. samples / sec: 65924.82
Iteration:   1260, Loss function: 4.087, Average Loss: 4.464, avg. samples / sec: 65758.87
Iteration:   1260, Loss function: 5.030, Average Loss: 4.454, avg. samples / sec: 65818.45
Iteration:   1260, Loss function: 4.773, Average Loss: 4.447, avg. samples / sec: 65738.56
Iteration:   1280, Loss function: 5.068, Average Loss: 4.463, avg. samples / sec: 66702.23
Iteration:   1280, Loss function: 3.790, Average Loss: 4.468, avg. samples / sec: 66468.27
Iteration:   1280, Loss function: 4.412, Average Loss: 4.402, avg. samples / sec: 66350.60
Iteration:   1280, Loss function: 4.572, Average Loss: 4.474, avg. samples / sec: 66460.96
Iteration:   1280, Loss function: 5.302, Average Loss: 4.471, avg. samples / sec: 66448.74
Iteration:   1280, Loss function: 4.916, Average Loss: 4.455, avg. samples / sec: 66237.03
Iteration:   1280, Loss function: 5.045, Average Loss: 4.436, avg. samples / sec: 66434.18
Iteration:   1280, Loss function: 5.624, Average Loss: 4.437, avg. samples / sec: 66523.36
Iteration:   1280, Loss function: 4.796, Average Loss: 4.452, avg. samples / sec: 66360.26
Iteration:   1280, Loss function: 4.124, Average Loss: 4.486, avg. samples / sec: 66414.42
Iteration:   1280, Loss function: 4.588, Average Loss: 4.474, avg. samples / sec: 66219.01
Iteration:   1280, Loss function: 5.220, Average Loss: 4.457, avg. samples / sec: 66358.88
Iteration:   1280, Loss function: 4.290, Average Loss: 4.463, avg. samples / sec: 66384.55
Iteration:   1280, Loss function: 5.919, Average Loss: 4.462, avg. samples / sec: 66210.98
Iteration:   1280, Loss function: 4.271, Average Loss: 4.458, avg. samples / sec: 66274.72
Iteration:   1280, Loss function: 4.600, Average Loss: 4.477, avg. samples / sec: 66330.21
Iteration:   1280, Loss function: 4.068, Average Loss: 4.454, avg. samples / sec: 66503.77
Iteration:   1280, Loss function: 5.240, Average Loss: 4.472, avg. samples / sec: 66481.63
Iteration:   1280, Loss function: 6.390, Average Loss: 4.442, avg. samples / sec: 66418.08
Iteration:   1280, Loss function: 5.005, Average Loss: 4.454, avg. samples / sec: 66359.35
Iteration:   1280, Loss function: 4.761, Average Loss: 4.453, avg. samples / sec: 66308.02
Iteration:   1280, Loss function: 4.450, Average Loss: 4.472, avg. samples / sec: 66379.17
Iteration:   1280, Loss function: 4.758, Average Loss: 4.451, avg. samples / sec: 66346.17
Iteration:   1280, Loss function: 4.551, Average Loss: 4.467, avg. samples / sec: 66287.09
Iteration:   1280, Loss function: 4.488, Average Loss: 4.452, avg. samples / sec: 66548.90
Iteration:   1280, Loss function: 3.778, Average Loss: 4.466, avg. samples / sec: 66282.70
Iteration:   1280, Loss function: 3.941, Average Loss: 4.449, avg. samples / sec: 66369.29
Iteration:   1280, Loss function: 4.668, Average Loss: 4.459, avg. samples / sec: 66306.90
Iteration:   1280, Loss function: 3.958, Average Loss: 4.453, avg. samples / sec: 66130.82
Iteration:   1280, Loss function: 4.889, Average Loss: 4.468, avg. samples / sec: 66133.71
Iteration:   1300, Loss function: 5.345, Average Loss: 4.462, avg. samples / sec: 66672.32
Iteration:   1300, Loss function: 5.336, Average Loss: 4.478, avg. samples / sec: 66651.98
Iteration:   1300, Loss function: 4.460, Average Loss: 4.406, avg. samples / sec: 66604.10
Iteration:   1300, Loss function: 4.648, Average Loss: 4.469, avg. samples / sec: 66648.04
Iteration:   1300, Loss function: 4.699, Average Loss: 4.446, avg. samples / sec: 66607.72
Iteration:   1300, Loss function: 5.800, Average Loss: 4.472, avg. samples / sec: 66493.92
Iteration:   1300, Loss function: 5.231, Average Loss: 4.480, avg. samples / sec: 66716.25
Iteration:   1300, Loss function: 4.841, Average Loss: 4.491, avg. samples / sec: 66600.54
Iteration:   1300, Loss function: 4.269, Average Loss: 4.452, avg. samples / sec: 66556.38
Iteration:   1300, Loss function: 5.882, Average Loss: 4.460, avg. samples / sec: 66608.60
Iteration:   1300, Loss function: 3.667, Average Loss: 4.456, avg. samples / sec: 66553.49
Iteration:   1300, Loss function: 4.241, Average Loss: 4.471, avg. samples / sec: 66362.57
Iteration:   1300, Loss function: 4.975, Average Loss: 4.458, avg. samples / sec: 66746.15
Iteration:   1300, Loss function: 4.841, Average Loss: 4.462, avg. samples / sec: 66533.73
Iteration:   1300, Loss function: 4.635, Average Loss: 4.459, avg. samples / sec: 66618.17
Iteration:   1300, Loss function: 4.887, Average Loss: 4.452, avg. samples / sec: 66628.69
Iteration:   1300, Loss function: 5.419, Average Loss: 4.471, avg. samples / sec: 66621.83
Iteration:   1300, Loss function: 4.165, Average Loss: 4.459, avg. samples / sec: 66661.44
Iteration:   1300, Loss function: 5.482, Average Loss: 4.480, avg. samples / sec: 66549.15
Iteration:   1300, Loss function: 3.856, Average Loss: 4.445, avg. samples / sec: 66462.94
Iteration:   1300, Loss function: 6.595, Average Loss: 4.485, avg. samples / sec: 66488.21
Iteration:   1300, Loss function: 5.527, Average Loss: 4.452, avg. samples / sec: 66507.45
Iteration:   1300, Loss function: 4.741, Average Loss: 4.469, avg. samples / sec: 66465.92
Iteration:   1300, Loss function: 5.361, Average Loss: 4.475, avg. samples / sec: 66497.97
Iteration:   1300, Loss function: 5.697, Average Loss: 4.459, avg. samples / sec: 66418.77
Iteration:   1300, Loss function: 3.540, Average Loss: 4.475, avg. samples / sec: 66677.05
Iteration:   1300, Loss function: 3.626, Average Loss: 4.475, avg. samples / sec: 66385.01
Iteration:   1300, Loss function: 5.145, Average Loss: 4.456, avg. samples / sec: 66484.95
Iteration:   1300, Loss function: 4.426, Average Loss: 4.478, avg. samples / sec: 66347.98
Iteration:   1300, Loss function: 3.884, Average Loss: 4.455, avg. samples / sec: 66475.29
Iteration:   1320, Loss function: 4.413, Average Loss: 4.480, avg. samples / sec: 66756.11
Iteration:   1320, Loss function: 5.558, Average Loss: 4.420, avg. samples / sec: 66488.12
Iteration:   1320, Loss function: 4.752, Average Loss: 4.474, avg. samples / sec: 66482.22
Iteration:   1320, Loss function: 4.621, Average Loss: 4.473, avg. samples / sec: 66432.24
Iteration:   1320, Loss function: 4.595, Average Loss: 4.486, avg. samples / sec: 66435.99
Iteration:   1320, Loss function: 4.638, Average Loss: 4.477, avg. samples / sec: 66481.63
Iteration:   1320, Loss function: 4.563, Average Loss: 4.456, avg. samples / sec: 66511.28
Iteration:   1320, Loss function: 4.460, Average Loss: 4.461, avg. samples / sec: 66708.17
Iteration:   1320, Loss function: 5.791, Average Loss: 4.482, avg. samples / sec: 66518.50
Iteration:   1320, Loss function: 4.169, Average Loss: 4.457, avg. samples / sec: 66575.78
Iteration:   1320, Loss function: 4.799, Average Loss: 4.470, avg. samples / sec: 66512.78
Iteration:   1320, Loss function: 4.925, Average Loss: 4.487, avg. samples / sec: 66608.44
Iteration:   1320, Loss function: 5.442, Average Loss: 4.471, avg. samples / sec: 66568.99
Iteration:   1320, Loss function: 5.017, Average Loss: 4.478, avg. samples / sec: 66565.72
Iteration:   1320, Loss function: 5.403, Average Loss: 4.494, avg. samples / sec: 66427.70
Iteration:   1320, Loss function: 3.751, Average Loss: 4.488, avg. samples / sec: 66523.49
Iteration:   1320, Loss function: 5.598, Average Loss: 4.456, avg. samples / sec: 66362.69
Iteration:   1320, Loss function: 4.892, Average Loss: 4.484, avg. samples / sec: 66597.84
Iteration:   1320, Loss function: 4.211, Average Loss: 4.469, avg. samples / sec: 66527.16
Iteration:   1320, Loss function: 4.676, Average Loss: 4.488, avg. samples / sec: 66496.49
Iteration:   1320, Loss function: 4.361, Average Loss: 4.460, avg. samples / sec: 66548.62
Iteration:   1320, Loss function: 4.935, Average Loss: 4.456, avg. samples / sec: 66468.49
Iteration:   1320, Loss function: 4.228, Average Loss: 4.480, avg. samples / sec: 66481.94
Iteration:   1320, Loss function: 6.036, Average Loss: 4.488, avg. samples / sec: 66327.78
Iteration:   1320, Loss function: 5.030, Average Loss: 4.472, avg. samples / sec: 66411.79
Iteration:   1320, Loss function: 3.433, Average Loss: 4.464, avg. samples / sec: 66367.94
Iteration:   1320, Loss function: 4.997, Average Loss: 4.466, avg. samples / sec: 66366.91
Iteration:   1320, Loss function: 5.184, Average Loss: 4.454, avg. samples / sec: 66411.01
Iteration:   1320, Loss function: 4.277, Average Loss: 4.475, avg. samples / sec: 66415.52
Iteration:   1320, Loss function: 6.984, Average Loss: 4.470, avg. samples / sec: 66345.86
:::MLL 1558651892.116 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558651892.116 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 5.125, Average Loss: 4.478, avg. samples / sec: 66111.43
Iteration:   1340, Loss function: 4.427, Average Loss: 4.423, avg. samples / sec: 66065.25
Iteration:   1340, Loss function: 5.450, Average Loss: 4.486, avg. samples / sec: 66129.86
Iteration:   1340, Loss function: 4.290, Average Loss: 4.482, avg. samples / sec: 66077.64
Iteration:   1340, Loss function: 5.043, Average Loss: 4.479, avg. samples / sec: 66079.44
Iteration:   1340, Loss function: 4.478, Average Loss: 4.462, avg. samples / sec: 66170.38
Iteration:   1340, Loss function: 4.274, Average Loss: 4.481, avg. samples / sec: 66056.52
Iteration:   1340, Loss function: 4.254, Average Loss: 4.486, avg. samples / sec: 66039.16
Iteration:   1340, Loss function: 4.603, Average Loss: 4.489, avg. samples / sec: 65903.34
Iteration:   1340, Loss function: 4.088, Average Loss: 4.489, avg. samples / sec: 65974.76
Iteration:   1340, Loss function: 4.831, Average Loss: 4.475, avg. samples / sec: 66135.44
Iteration:   1340, Loss function: 4.119, Average Loss: 4.497, avg. samples / sec: 66029.72
Iteration:   1340, Loss function: 4.639, Average Loss: 4.472, avg. samples / sec: 66150.38
Iteration:   1340, Loss function: 4.096, Average Loss: 4.478, avg. samples / sec: 66005.41
Iteration:   1340, Loss function: 4.766, Average Loss: 4.470, avg. samples / sec: 66130.32
Iteration:   1340, Loss function: 3.828, Average Loss: 4.478, avg. samples / sec: 66147.05
Iteration:   1340, Loss function: 3.606, Average Loss: 4.494, avg. samples / sec: 66038.75
Iteration:   1340, Loss function: 4.614, Average Loss: 4.464, avg. samples / sec: 66069.62
Iteration:   1340, Loss function: 3.892, Average Loss: 4.485, avg. samples / sec: 66076.78
Iteration:   1340, Loss function: 4.267, Average Loss: 4.477, avg. samples / sec: 65904.07
Iteration:   1340, Loss function: 4.473, Average Loss: 4.487, avg. samples / sec: 66030.00
Iteration:   1340, Loss function: 5.404, Average Loss: 4.466, avg. samples / sec: 65948.39
Iteration:   1340, Loss function: 4.713, Average Loss: 4.459, avg. samples / sec: 66106.44
Iteration:   1340, Loss function: 5.241, Average Loss: 4.475, avg. samples / sec: 66111.00
Iteration:   1340, Loss function: 3.131, Average Loss: 4.492, avg. samples / sec: 66035.47
Iteration:   1340, Loss function: 5.135, Average Loss: 4.499, avg. samples / sec: 65983.19
Iteration:   1340, Loss function: 5.152, Average Loss: 4.463, avg. samples / sec: 65961.94
Iteration:   1340, Loss function: 3.719, Average Loss: 4.474, avg. samples / sec: 65993.02
Iteration:   1340, Loss function: 4.642, Average Loss: 4.466, avg. samples / sec: 65809.04
Iteration:   1340, Loss function: 6.400, Average Loss: 4.465, avg. samples / sec: 65790.55
Iteration:   1360, Loss function: 4.771, Average Loss: 4.475, avg. samples / sec: 66787.20
Iteration:   1360, Loss function: 4.664, Average Loss: 4.476, avg. samples / sec: 66584.72
Iteration:   1360, Loss function: 4.593, Average Loss: 4.495, avg. samples / sec: 66729.46
Iteration:   1360, Loss function: 4.618, Average Loss: 4.426, avg. samples / sec: 66530.02
Iteration:   1360, Loss function: 4.811, Average Loss: 4.482, avg. samples / sec: 66585.50
Iteration:   1360, Loss function: 5.439, Average Loss: 4.471, avg. samples / sec: 66882.17
Iteration:   1360, Loss function: 6.512, Average Loss: 4.477, avg. samples / sec: 66693.62
Iteration:   1360, Loss function: 4.357, Average Loss: 4.469, avg. samples / sec: 66622.11
Iteration:   1360, Loss function: 4.257, Average Loss: 4.461, avg. samples / sec: 66719.16
Iteration:   1360, Loss function: 3.739, Average Loss: 4.492, avg. samples / sec: 66647.03
Iteration:   1360, Loss function: 6.462, Average Loss: 4.479, avg. samples / sec: 66575.50
Iteration:   1360, Loss function: 4.136, Average Loss: 4.482, avg. samples / sec: 66664.34
Iteration:   1360, Loss function: 5.169, Average Loss: 4.495, avg. samples / sec: 66734.42
Iteration:   1360, Loss function: 5.186, Average Loss: 4.482, avg. samples / sec: 66701.29
Iteration:   1360, Loss function: 4.580, Average Loss: 4.474, avg. samples / sec: 66624.66
Iteration:   1360, Loss function: 4.283, Average Loss: 4.467, avg. samples / sec: 66643.97
Iteration:   1360, Loss function: 4.009, Average Loss: 4.481, avg. samples / sec: 66606.24
Iteration:   1360, Loss function: 4.880, Average Loss: 4.471, avg. samples / sec: 66710.98
Iteration:   1360, Loss function: 3.965, Average Loss: 4.482, avg. samples / sec: 66597.36
Iteration:   1360, Loss function: 3.675, Average Loss: 4.465, avg. samples / sec: 66647.38
Iteration:   1360, Loss function: 4.785, Average Loss: 4.467, avg. samples / sec: 66696.80
Iteration:   1360, Loss function: 5.478, Average Loss: 4.489, avg. samples / sec: 66632.00
Iteration:   1360, Loss function: 4.565, Average Loss: 4.488, avg. samples / sec: 66609.77
Iteration:   1360, Loss function: 5.351, Average Loss: 4.501, avg. samples / sec: 66688.47
Iteration:   1360, Loss function: 4.160, Average Loss: 4.500, avg. samples / sec: 66556.85
Iteration:   1360, Loss function: 4.610, Average Loss: 4.474, avg. samples / sec: 66718.37
Iteration:   1360, Loss function: 4.526, Average Loss: 4.487, avg. samples / sec: 66377.89
Iteration:   1360, Loss function: 4.482, Average Loss: 4.500, avg. samples / sec: 66538.72
Iteration:   1360, Loss function: 5.258, Average Loss: 4.488, avg. samples / sec: 66457.92
Iteration:   1360, Loss function: 3.957, Average Loss: 4.492, avg. samples / sec: 66360.76
Iteration:   1380, Loss function: 4.447, Average Loss: 4.431, avg. samples / sec: 66493.70
Iteration:   1380, Loss function: 5.829, Average Loss: 4.481, avg. samples / sec: 66552.77
Iteration:   1380, Loss function: 4.033, Average Loss: 4.484, avg. samples / sec: 66512.72
Iteration:   1380, Loss function: 4.317, Average Loss: 4.480, avg. samples / sec: 66401.75
Iteration:   1380, Loss function: 5.123, Average Loss: 4.481, avg. samples / sec: 66457.67
Iteration:   1380, Loss function: 4.239, Average Loss: 4.503, avg. samples / sec: 66625.92
Iteration:   1380, Loss function: 4.819, Average Loss: 4.484, avg. samples / sec: 66549.88
Iteration:   1380, Loss function: 4.903, Average Loss: 4.493, avg. samples / sec: 66628.19
Iteration:   1380, Loss function: 4.666, Average Loss: 4.489, avg. samples / sec: 66438.81
Iteration:   1380, Loss function: 4.673, Average Loss: 4.480, avg. samples / sec: 66521.54
Iteration:   1380, Loss function: 4.449, Average Loss: 4.505, avg. samples / sec: 66565.41
Iteration:   1380, Loss function: 4.416, Average Loss: 4.479, avg. samples / sec: 66355.20
Iteration:   1380, Loss function: 3.959, Average Loss: 4.493, avg. samples / sec: 66462.09
Iteration:   1380, Loss function: 4.096, Average Loss: 4.488, avg. samples / sec: 66509.27
Iteration:   1380, Loss function: 5.060, Average Loss: 4.491, avg. samples / sec: 66633.45
Iteration:   1380, Loss function: 3.858, Average Loss: 4.468, avg. samples / sec: 66505.63
Iteration:   1380, Loss function: 4.311, Average Loss: 4.479, avg. samples / sec: 66389.30
Iteration:   1380, Loss function: 3.252, Average Loss: 4.487, avg. samples / sec: 66514.20
Iteration:   1380, Loss function: 4.383, Average Loss: 4.506, avg. samples / sec: 66473.79
Iteration:   1380, Loss function: 4.618, Average Loss: 4.497, avg. samples / sec: 66302.22
Iteration:   1380, Loss function: 4.849, Average Loss: 4.498, avg. samples / sec: 66618.80
Iteration:   1380, Loss function: 5.187, Average Loss: 4.468, avg. samples / sec: 66412.70
Iteration:   1380, Loss function: 5.054, Average Loss: 4.482, avg. samples / sec: 66384.64
Iteration:   1380, Loss function: 4.173, Average Loss: 4.492, avg. samples / sec: 66332.52
Iteration:   1380, Loss function: 4.470, Average Loss: 4.468, avg. samples / sec: 66311.08
Iteration:   1380, Loss function: 5.838, Average Loss: 4.480, avg. samples / sec: 66442.51
Iteration:   1380, Loss function: 5.221, Average Loss: 4.472, avg. samples / sec: 66346.82
Iteration:   1380, Loss function: 4.552, Average Loss: 4.497, avg. samples / sec: 66360.98
Iteration:   1380, Loss function: 5.017, Average Loss: 4.477, avg. samples / sec: 66284.57
Iteration:   1380, Loss function: 3.697, Average Loss: 4.495, avg. samples / sec: 66290.34
:::MLL 1558651893.887 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558651893.888 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 4.602, Average Loss: 4.480, avg. samples / sec: 66393.36
Iteration:   1400, Loss function: 2.983, Average Loss: 4.428, avg. samples / sec: 66325.22
Iteration:   1400, Loss function: 5.574, Average Loss: 4.482, avg. samples / sec: 66386.17
Iteration:   1400, Loss function: 5.033, Average Loss: 4.498, avg. samples / sec: 66353.10
Iteration:   1400, Loss function: 5.007, Average Loss: 4.489, avg. samples / sec: 66317.91
Iteration:   1400, Loss function: 5.477, Average Loss: 4.499, avg. samples / sec: 66331.62
Iteration:   1400, Loss function: 4.753, Average Loss: 4.502, avg. samples / sec: 66406.41
Iteration:   1400, Loss function: 4.549, Average Loss: 4.469, avg. samples / sec: 66413.51
Iteration:   1400, Loss function: 3.976, Average Loss: 4.482, avg. samples / sec: 66333.36
Iteration:   1400, Loss function: 3.938, Average Loss: 4.496, avg. samples / sec: 66402.84
Iteration:   1400, Loss function: 4.714, Average Loss: 4.472, avg. samples / sec: 66289.12
Iteration:   1400, Loss function: 4.042, Average Loss: 4.469, avg. samples / sec: 66396.84
Iteration:   1400, Loss function: 4.627, Average Loss: 4.504, avg. samples / sec: 66243.04
Iteration:   1400, Loss function: 4.257, Average Loss: 4.487, avg. samples / sec: 66210.89
Iteration:   1400, Loss function: 4.742, Average Loss: 4.479, avg. samples / sec: 66390.02
Iteration:   1400, Loss function: 5.405, Average Loss: 4.497, avg. samples / sec: 66247.80
Iteration:   1400, Loss function: 5.175, Average Loss: 4.497, avg. samples / sec: 66411.73
Iteration:   1400, Loss function: 3.949, Average Loss: 4.499, avg. samples / sec: 66336.11
Iteration:   1400, Loss function: 4.444, Average Loss: 4.485, avg. samples / sec: 66231.77
Iteration:   1400, Loss function: 5.333, Average Loss: 4.478, avg. samples / sec: 66382.92
Iteration:   1400, Loss function: 4.107, Average Loss: 4.506, avg. samples / sec: 66290.77
Iteration:   1400, Loss function: 4.703, Average Loss: 4.498, avg. samples / sec: 66375.48
Iteration:   1400, Loss function: 4.533, Average Loss: 4.507, avg. samples / sec: 66191.92
Iteration:   1400, Loss function: 5.020, Average Loss: 4.495, avg. samples / sec: 66159.82
Iteration:   1400, Loss function: 4.241, Average Loss: 4.480, avg. samples / sec: 66140.41
Iteration:   1400, Loss function: 4.123, Average Loss: 4.486, avg. samples / sec: 66107.46
Iteration:   1400, Loss function: 3.820, Average Loss: 4.488, avg. samples / sec: 66194.37
Iteration:   1400, Loss function: 4.330, Average Loss: 4.484, avg. samples / sec: 66202.89
Iteration:   1400, Loss function: 5.539, Average Loss: 4.484, avg. samples / sec: 66035.60
Iteration:   1400, Loss function: 4.204, Average Loss: 4.481, avg. samples / sec: 66178.96
Iteration:   1420, Loss function: 4.043, Average Loss: 4.482, avg. samples / sec: 66486.80
Iteration:   1420, Loss function: 4.261, Average Loss: 4.482, avg. samples / sec: 66491.91
Iteration:   1420, Loss function: 4.909, Average Loss: 4.480, avg. samples / sec: 66691.50
Iteration:   1420, Loss function: 4.170, Average Loss: 4.482, avg. samples / sec: 66550.03
Iteration:   1420, Loss function: 4.548, Average Loss: 4.502, avg. samples / sec: 66518.87
Iteration:   1420, Loss function: 3.808, Average Loss: 4.493, avg. samples / sec: 66460.59
Iteration:   1420, Loss function: 4.589, Average Loss: 4.435, avg. samples / sec: 66427.29
Iteration:   1420, Loss function: 4.137, Average Loss: 4.497, avg. samples / sec: 66535.17
Iteration:   1420, Loss function: 4.794, Average Loss: 4.500, avg. samples / sec: 66448.71
Iteration:   1420, Loss function: 4.579, Average Loss: 4.500, avg. samples / sec: 66523.14
Iteration:   1420, Loss function: 5.142, Average Loss: 4.497, avg. samples / sec: 66408.48
Iteration:   1420, Loss function: 4.088, Average Loss: 4.485, avg. samples / sec: 66541.93
Iteration:   1420, Loss function: 3.918, Average Loss: 4.479, avg. samples / sec: 66493.51
Iteration:   1420, Loss function: 4.257, Average Loss: 4.483, avg. samples / sec: 66509.86
Iteration:   1420, Loss function: 3.947, Average Loss: 4.496, avg. samples / sec: 66551.23
Iteration:   1420, Loss function: 4.989, Average Loss: 4.484, avg. samples / sec: 66699.52
Iteration:   1420, Loss function: 4.573, Average Loss: 4.493, avg. samples / sec: 66478.18
Iteration:   1420, Loss function: 4.329, Average Loss: 4.501, avg. samples / sec: 66480.03
Iteration:   1420, Loss function: 3.707, Average Loss: 4.492, avg. samples / sec: 66425.25
Iteration:   1420, Loss function: 4.804, Average Loss: 4.486, avg. samples / sec: 66509.52
Iteration:   1420, Loss function: 3.680, Average Loss: 4.479, avg. samples / sec: 66430.23
Iteration:   1420, Loss function: 4.309, Average Loss: 4.501, avg. samples / sec: 66424.44
Iteration:   1420, Loss function: 4.359, Average Loss: 4.504, avg. samples / sec: 66432.17
Iteration:   1420, Loss function: 3.637, Average Loss: 4.489, avg. samples / sec: 66481.78
Iteration:   1420, Loss function: 3.218, Average Loss: 4.471, avg. samples / sec: 66325.40
Iteration:   1420, Loss function: 4.655, Average Loss: 4.483, avg. samples / sec: 66531.65
Iteration:   1420, Loss function: 4.173, Average Loss: 4.491, avg. samples / sec: 66552.71
Iteration:   1420, Loss function: 4.769, Average Loss: 4.510, avg. samples / sec: 66365.73
Iteration:   1420, Loss function: 4.828, Average Loss: 4.468, avg. samples / sec: 66311.27
Iteration:   1420, Loss function: 5.413, Average Loss: 4.482, avg. samples / sec: 66286.35
Iteration:   1440, Loss function: 4.007, Average Loss: 4.484, avg. samples / sec: 66623.65
Iteration:   1440, Loss function: 4.941, Average Loss: 4.487, avg. samples / sec: 66483.38
Iteration:   1440, Loss function: 4.333, Average Loss: 4.496, avg. samples / sec: 66634.27
Iteration:   1440, Loss function: 4.142, Average Loss: 4.496, avg. samples / sec: 66567.10
Iteration:   1440, Loss function: 3.741, Average Loss: 4.484, avg. samples / sec: 66423.31
Iteration:   1440, Loss function: 4.806, Average Loss: 4.507, avg. samples / sec: 66477.05
Iteration:   1440, Loss function: 4.190, Average Loss: 4.487, avg. samples / sec: 66465.01
Iteration:   1440, Loss function: 2.976, Average Loss: 4.438, avg. samples / sec: 66492.60
Iteration:   1440, Loss function: 3.922, Average Loss: 4.487, avg. samples / sec: 66620.69
Iteration:   1440, Loss function: 4.426, Average Loss: 4.478, avg. samples / sec: 66640.98
Iteration:   1440, Loss function: 5.353, Average Loss: 4.497, avg. samples / sec: 66442.13
Iteration:   1440, Loss function: 4.731, Average Loss: 4.484, avg. samples / sec: 66382.04
Iteration:   1440, Loss function: 4.233, Average Loss: 4.479, avg. samples / sec: 66564.52
Iteration:   1440, Loss function: 5.946, Average Loss: 4.506, avg. samples / sec: 66564.81
Iteration:   1440, Loss function: 4.849, Average Loss: 4.504, avg. samples / sec: 66424.63
Iteration:   1440, Loss function: 5.381, Average Loss: 4.492, avg. samples / sec: 66509.89
Iteration:   1440, Loss function: 3.781, Average Loss: 4.507, avg. samples / sec: 66570.75
Iteration:   1440, Loss function: 4.192, Average Loss: 4.489, avg. samples / sec: 66422.31
Iteration:   1440, Loss function: 5.212, Average Loss: 4.502, avg. samples / sec: 66474.66
Iteration:   1440, Loss function: 3.815, Average Loss: 4.500, avg. samples / sec: 66373.16
Iteration:   1440, Loss function: 3.531, Average Loss: 4.491, avg. samples / sec: 66520.38
Iteration:   1440, Loss function: 4.411, Average Loss: 4.482, avg. samples / sec: 66448.34
Iteration:   1440, Loss function: 4.275, Average Loss: 4.501, avg. samples / sec: 66357.85
Iteration:   1440, Loss function: 4.996, Average Loss: 4.509, avg. samples / sec: 66569.37
Iteration:   1440, Loss function: 3.346, Average Loss: 4.488, avg. samples / sec: 66479.34
Iteration:   1440, Loss function: 4.396, Average Loss: 4.485, avg. samples / sec: 66607.97
Iteration:   1440, Loss function: 4.185, Average Loss: 4.494, avg. samples / sec: 66506.44
Iteration:   1440, Loss function: 3.501, Average Loss: 4.483, avg. samples / sec: 66336.70
Iteration:   1440, Loss function: 5.306, Average Loss: 4.475, avg. samples / sec: 66514.32
Iteration:   1440, Loss function: 3.784, Average Loss: 4.481, avg. samples / sec: 66464.54
Iteration:   1460, Loss function: 4.702, Average Loss: 4.486, avg. samples / sec: 66603.85
Iteration:   1460, Loss function: 4.610, Average Loss: 4.483, avg. samples / sec: 66522.26
Iteration:   1460, Loss function: 4.439, Average Loss: 4.441, avg. samples / sec: 66541.08
Iteration:   1460, Loss function: 4.953, Average Loss: 4.487, avg. samples / sec: 66475.10
Iteration:   1460, Loss function: 5.948, Average Loss: 4.503, avg. samples / sec: 66469.27
Iteration:   1460, Loss function: 3.615, Average Loss: 4.487, avg. samples / sec: 66569.84
Iteration:   1460, Loss function: 4.822, Average Loss: 4.486, avg. samples / sec: 66457.77
Iteration:   1460, Loss function: 3.473, Average Loss: 4.497, avg. samples / sec: 66615.97
Iteration:   1460, Loss function: 4.647, Average Loss: 4.496, avg. samples / sec: 66389.14
Iteration:   1460, Loss function: 4.803, Average Loss: 4.504, avg. samples / sec: 66591.32
Iteration:   1460, Loss function: 3.571, Average Loss: 4.507, avg. samples / sec: 66561.00
Iteration:   1460, Loss function: 4.686, Average Loss: 4.500, avg. samples / sec: 66477.02
Iteration:   1460, Loss function: 4.855, Average Loss: 4.496, avg. samples / sec: 66595.41
Iteration:   1460, Loss function: 4.021, Average Loss: 4.477, avg. samples / sec: 66525.88
Iteration:   1460, Loss function: 4.115, Average Loss: 4.489, avg. samples / sec: 66588.11
Iteration:   1460, Loss function: 5.273, Average Loss: 4.506, avg. samples / sec: 66411.39
Iteration:   1460, Loss function: 4.577, Average Loss: 4.509, avg. samples / sec: 66578.80
Iteration:   1460, Loss function: 5.096, Average Loss: 4.474, avg. samples / sec: 66649.33
Iteration:   1460, Loss function: 3.653, Average Loss: 4.487, avg. samples / sec: 66424.69
Iteration:   1460, Loss function: 3.967, Average Loss: 4.510, avg. samples / sec: 66513.54
Iteration:   1460, Loss function: 4.657, Average Loss: 4.475, avg. samples / sec: 66437.78
Iteration:   1460, Loss function: 3.470, Average Loss: 4.485, avg. samples / sec: 66504.72
Iteration:   1460, Loss function: 3.664, Average Loss: 4.506, avg. samples / sec: 66473.85
Iteration:   1460, Loss function: 4.167, Average Loss: 4.497, avg. samples / sec: 66478.65
Iteration:   1460, Loss function: 4.306, Average Loss: 4.482, avg. samples / sec: 66577.35
Iteration:   1460, Loss function: 4.832, Average Loss: 4.480, avg. samples / sec: 66578.46
Iteration:   1460, Loss function: 5.096, Average Loss: 4.489, avg. samples / sec: 66490.53
Iteration:   1460, Loss function: 3.990, Average Loss: 4.489, avg. samples / sec: 66488.68
Iteration:   1460, Loss function: 4.392, Average Loss: 4.488, avg. samples / sec: 66499.04
Iteration:   1460, Loss function: 4.192, Average Loss: 4.491, avg. samples / sec: 66504.25
:::MLL 1558651895.658 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558651895.658 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 5.233, Average Loss: 4.497, avg. samples / sec: 66029.29
Iteration:   1480, Loss function: 3.516, Average Loss: 4.488, avg. samples / sec: 65937.96
Iteration:   1480, Loss function: 4.674, Average Loss: 4.502, avg. samples / sec: 66034.76
Iteration:   1480, Loss function: 3.864, Average Loss: 4.483, avg. samples / sec: 66083.53
Iteration:   1480, Loss function: 3.856, Average Loss: 4.503, avg. samples / sec: 66079.13
Iteration:   1480, Loss function: 3.395, Average Loss: 4.502, avg. samples / sec: 66032.07
Iteration:   1480, Loss function: 5.248, Average Loss: 4.494, avg. samples / sec: 66035.04
Iteration:   1480, Loss function: 5.172, Average Loss: 4.477, avg. samples / sec: 66060.33
Iteration:   1480, Loss function: 4.445, Average Loss: 4.437, avg. samples / sec: 65923.56
Iteration:   1480, Loss function: 4.690, Average Loss: 4.473, avg. samples / sec: 66059.68
Iteration:   1480, Loss function: 4.042, Average Loss: 4.496, avg. samples / sec: 66013.14
Iteration:   1480, Loss function: 3.979, Average Loss: 4.505, avg. samples / sec: 65980.44
Iteration:   1480, Loss function: 5.153, Average Loss: 4.486, avg. samples / sec: 65938.30
Iteration:   1480, Loss function: 3.675, Average Loss: 4.482, avg. samples / sec: 66089.33
Iteration:   1480, Loss function: 3.926, Average Loss: 4.487, avg. samples / sec: 65928.37
Iteration:   1480, Loss function: 4.220, Average Loss: 4.498, avg. samples / sec: 65921.68
Iteration:   1480, Loss function: 3.613, Average Loss: 4.477, avg. samples / sec: 65970.13
Iteration:   1480, Loss function: 3.694, Average Loss: 4.476, avg. samples / sec: 65821.03
Iteration:   1480, Loss function: 4.634, Average Loss: 4.491, avg. samples / sec: 65989.65
Iteration:   1480, Loss function: 4.944, Average Loss: 4.489, avg. samples / sec: 65991.97
Iteration:   1480, Loss function: 4.265, Average Loss: 4.503, avg. samples / sec: 65934.23
Iteration:   1480, Loss function: 6.142, Average Loss: 4.492, avg. samples / sec: 66022.94
Iteration:   1480, Loss function: 4.178, Average Loss: 4.499, avg. samples / sec: 66026.69
Iteration:   1480, Loss function: 3.980, Average Loss: 4.507, avg. samples / sec: 65959.94
Iteration:   1480, Loss function: 5.217, Average Loss: 4.513, avg. samples / sec: 65935.90
Iteration:   1480, Loss function: 3.806, Average Loss: 4.490, avg. samples / sec: 66016.45
Iteration:   1480, Loss function: 4.618, Average Loss: 4.491, avg. samples / sec: 66028.33
Iteration:   1480, Loss function: 4.617, Average Loss: 4.491, avg. samples / sec: 65984.49
Iteration:   1480, Loss function: 4.997, Average Loss: 4.511, avg. samples / sec: 65946.60
Iteration:   1480, Loss function: 5.193, Average Loss: 4.492, avg. samples / sec: 65972.26
Iteration:   1500, Loss function: 5.191, Average Loss: 4.504, avg. samples / sec: 66813.86
Iteration:   1500, Loss function: 5.805, Average Loss: 4.494, avg. samples / sec: 66726.99
Iteration:   1500, Loss function: 5.211, Average Loss: 4.501, avg. samples / sec: 66695.79
Iteration:   1500, Loss function: 3.216, Average Loss: 4.482, avg. samples / sec: 66716.73
Iteration:   1500, Loss function: 4.042, Average Loss: 4.441, avg. samples / sec: 66739.73
Iteration:   1500, Loss function: 4.752, Average Loss: 4.488, avg. samples / sec: 66793.00
Iteration:   1500, Loss function: 4.345, Average Loss: 4.501, avg. samples / sec: 66790.37
Iteration:   1500, Loss function: 5.181, Average Loss: 4.482, avg. samples / sec: 66780.37
Iteration:   1500, Loss function: 4.194, Average Loss: 4.502, avg. samples / sec: 66798.85
Iteration:   1500, Loss function: 5.300, Average Loss: 4.491, avg. samples / sec: 66760.88
Iteration:   1500, Loss function: 5.563, Average Loss: 4.491, avg. samples / sec: 66815.77
Iteration:   1500, Loss function: 4.350, Average Loss: 4.492, avg. samples / sec: 66892.26
Iteration:   1500, Loss function: 4.342, Average Loss: 4.499, avg. samples / sec: 66760.15
Iteration:   1500, Loss function: 4.649, Average Loss: 4.479, avg. samples / sec: 66698.48
Iteration:   1500, Loss function: 3.934, Average Loss: 4.490, avg. samples / sec: 66762.02
Iteration:   1500, Loss function: 5.130, Average Loss: 4.489, avg. samples / sec: 66601.20
Iteration:   1500, Loss function: 3.313, Average Loss: 4.489, avg. samples / sec: 66792.90
Iteration:   1500, Loss function: 4.831, Average Loss: 4.516, avg. samples / sec: 66780.72
Iteration:   1500, Loss function: 4.768, Average Loss: 4.492, avg. samples / sec: 66603.94
Iteration:   1500, Loss function: 4.565, Average Loss: 4.509, avg. samples / sec: 66688.85
Iteration:   1500, Loss function: 4.777, Average Loss: 4.496, avg. samples / sec: 66678.98
Iteration:   1500, Loss function: 4.503, Average Loss: 4.482, avg. samples / sec: 66644.76
Iteration:   1500, Loss function: 5.533, Average Loss: 4.502, avg. samples / sec: 66576.32
Iteration:   1500, Loss function: 4.834, Average Loss: 4.482, avg. samples / sec: 66571.32
Iteration:   1500, Loss function: 4.513, Average Loss: 4.496, avg. samples / sec: 66693.08
Iteration:   1500, Loss function: 4.511, Average Loss: 4.485, avg. samples / sec: 66627.72
Iteration:   1500, Loss function: 5.104, Average Loss: 4.498, avg. samples / sec: 66571.10
Iteration:   1500, Loss function: 3.859, Average Loss: 4.517, avg. samples / sec: 66714.68
Iteration:   1500, Loss function: 3.997, Average Loss: 4.493, avg. samples / sec: 66573.17
Iteration:   1500, Loss function: 3.624, Average Loss: 4.509, avg. samples / sec: 66455.70
Iteration:   1520, Loss function: 3.223, Average Loss: 4.444, avg. samples / sec: 66303.84
Iteration:   1520, Loss function: 3.973, Average Loss: 4.487, avg. samples / sec: 66460.93
Iteration:   1520, Loss function: 3.353, Average Loss: 4.500, avg. samples / sec: 66170.53
Iteration:   1520, Loss function: 5.518, Average Loss: 4.502, avg. samples / sec: 66290.21
Iteration:   1520, Loss function: 3.857, Average Loss: 4.501, avg. samples / sec: 66317.38
Iteration:   1520, Loss function: 4.524, Average Loss: 4.520, avg. samples / sec: 66414.89
Iteration:   1520, Loss function: 5.298, Average Loss: 4.495, avg. samples / sec: 66366.51
Iteration:   1520, Loss function: 4.435, Average Loss: 4.488, avg. samples / sec: 66284.32
Iteration:   1520, Loss function: 4.044, Average Loss: 4.483, avg. samples / sec: 66218.07
Iteration:   1520, Loss function: 4.112, Average Loss: 4.499, avg. samples / sec: 66149.97
Iteration:   1520, Loss function: 5.334, Average Loss: 4.481, avg. samples / sec: 66287.31
Iteration:   1520, Loss function: 3.377, Average Loss: 4.516, avg. samples / sec: 66290.49
Iteration:   1520, Loss function: 4.755, Average Loss: 4.494, avg. samples / sec: 66284.57
Iteration:   1520, Loss function: 4.854, Average Loss: 4.487, avg. samples / sec: 66247.83
Iteration:   1520, Loss function: 5.138, Average Loss: 4.483, avg. samples / sec: 66194.40
Iteration:   1520, Loss function: 5.297, Average Loss: 4.508, avg. samples / sec: 66319.54
Iteration:   1520, Loss function: 4.591, Average Loss: 4.495, avg. samples / sec: 66210.54
Iteration:   1520, Loss function: 3.989, Average Loss: 4.511, avg. samples / sec: 66489.15
Iteration:   1520, Loss function: 5.333, Average Loss: 4.503, avg. samples / sec: 66140.88
Iteration:   1520, Loss function: 4.797, Average Loss: 4.503, avg. samples / sec: 66175.26
Iteration:   1520, Loss function: 4.226, Average Loss: 4.513, avg. samples / sec: 66308.68
Iteration:   1520, Loss function: 5.414, Average Loss: 4.497, avg. samples / sec: 66189.99
Iteration:   1520, Loss function: 4.265, Average Loss: 4.490, avg. samples / sec: 66127.90
Iteration:   1520, Loss function: 5.054, Average Loss: 4.497, avg. samples / sec: 66269.08
Iteration:   1520, Loss function: 3.323, Average Loss: 4.484, avg. samples / sec: 66279.24
Iteration:   1520, Loss function: 4.343, Average Loss: 4.493, avg. samples / sec: 66306.31
Iteration:   1520, Loss function: 3.417, Average Loss: 4.502, avg. samples / sec: 66277.87
Iteration:   1520, Loss function: 4.307, Average Loss: 4.491, avg. samples / sec: 66140.26
Iteration:   1520, Loss function: 3.738, Average Loss: 4.486, avg. samples / sec: 66201.62
Iteration:   1520, Loss function: 5.064, Average Loss: 4.498, avg. samples / sec: 66208.77
:::MLL 1558651897.430 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558651897.430 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.605, Average Loss: 4.505, avg. samples / sec: 66499.76
Iteration:   1540, Loss function: 5.178, Average Loss: 4.509, avg. samples / sec: 66467.01
Iteration:   1540, Loss function: 4.779, Average Loss: 4.501, avg. samples / sec: 66343.70
Iteration:   1540, Loss function: 4.493, Average Loss: 4.483, avg. samples / sec: 66430.67
Iteration:   1540, Loss function: 3.446, Average Loss: 4.501, avg. samples / sec: 66482.41
Iteration:   1540, Loss function: 4.465, Average Loss: 4.488, avg. samples / sec: 66366.10
Iteration:   1540, Loss function: 5.042, Average Loss: 4.507, avg. samples / sec: 66488.93
Iteration:   1540, Loss function: 5.211, Average Loss: 4.446, avg. samples / sec: 66273.63
Iteration:   1540, Loss function: 4.344, Average Loss: 4.481, avg. samples / sec: 66429.10
Iteration:   1540, Loss function: 4.117, Average Loss: 4.480, avg. samples / sec: 66337.30
Iteration:   1540, Loss function: 4.435, Average Loss: 4.497, avg. samples / sec: 66320.81
Iteration:   1540, Loss function: 4.612, Average Loss: 4.511, avg. samples / sec: 66378.60
Iteration:   1540, Loss function: 4.473, Average Loss: 4.510, avg. samples / sec: 66357.23
Iteration:   1540, Loss function: 3.274, Average Loss: 4.506, avg. samples / sec: 66359.16
Iteration:   1540, Loss function: 5.614, Average Loss: 4.495, avg. samples / sec: 66409.92
Iteration:   1540, Loss function: 4.108, Average Loss: 4.501, avg. samples / sec: 66246.77
Iteration:   1540, Loss function: 3.688, Average Loss: 4.514, avg. samples / sec: 66276.53
Iteration:   1540, Loss function: 5.199, Average Loss: 4.493, avg. samples / sec: 66381.79
Iteration:   1540, Loss function: 4.868, Average Loss: 4.502, avg. samples / sec: 66217.20
Iteration:   1540, Loss function: 5.049, Average Loss: 4.482, avg. samples / sec: 66247.12
Iteration:   1540, Loss function: 4.187, Average Loss: 4.521, avg. samples / sec: 66201.90
Iteration:   1540, Loss function: 4.120, Average Loss: 4.486, avg. samples / sec: 66286.56
Iteration:   1540, Loss function: 5.130, Average Loss: 4.500, avg. samples / sec: 66137.68
Iteration:   1540, Loss function: 4.535, Average Loss: 4.483, avg. samples / sec: 66342.26
Iteration:   1540, Loss function: 4.120, Average Loss: 4.484, avg. samples / sec: 66185.89
Iteration:   1540, Loss function: 4.858, Average Loss: 4.490, avg. samples / sec: 66054.14
Iteration:   1540, Loss function: 4.394, Average Loss: 4.489, avg. samples / sec: 66145.22
Iteration:   1540, Loss function: 4.457, Average Loss: 4.497, avg. samples / sec: 66240.02
Iteration:   1540, Loss function: 3.357, Average Loss: 4.495, avg. samples / sec: 66076.28
Iteration:   1540, Loss function: 5.223, Average Loss: 4.494, avg. samples / sec: 65950.74
Iteration:   1560, Loss function: 3.573, Average Loss: 4.492, avg. samples / sec: 66310.39
Iteration:   1560, Loss function: 4.501, Average Loss: 4.494, avg. samples / sec: 66219.88
Iteration:   1560, Loss function: 4.658, Average Loss: 4.499, avg. samples / sec: 66121.70
Iteration:   1560, Loss function: 4.151, Average Loss: 4.491, avg. samples / sec: 66415.52
Iteration:   1560, Loss function: 4.203, Average Loss: 4.447, avg. samples / sec: 66145.35
Iteration:   1560, Loss function: 4.771, Average Loss: 4.502, avg. samples / sec: 66335.99
Iteration:   1560, Loss function: 4.575, Average Loss: 4.512, avg. samples / sec: 66037.82
Iteration:   1560, Loss function: 4.858, Average Loss: 4.478, avg. samples / sec: 66129.42
Iteration:   1560, Loss function: 3.817, Average Loss: 4.491, avg. samples / sec: 66213.00
Iteration:   1560, Loss function: 3.998, Average Loss: 4.480, avg. samples / sec: 66209.39
Iteration:   1560, Loss function: 4.360, Average Loss: 4.491, avg. samples / sec: 66400.87
Iteration:   1560, Loss function: 3.889, Average Loss: 4.501, avg. samples / sec: 66186.63
Iteration:   1560, Loss function: 3.594, Average Loss: 4.498, avg. samples / sec: 66141.59
Iteration:   1560, Loss function: 2.899, Average Loss: 4.496, avg. samples / sec: 66344.73
Iteration:   1560, Loss function: 4.329, Average Loss: 4.511, avg. samples / sec: 66128.21
Iteration:   1560, Loss function: 5.586, Average Loss: 4.490, avg. samples / sec: 66325.06
Iteration:   1560, Loss function: 4.893, Average Loss: 4.514, avg. samples / sec: 66108.30
Iteration:   1560, Loss function: 4.585, Average Loss: 4.507, avg. samples / sec: 66078.23
Iteration:   1560, Loss function: 4.417, Average Loss: 4.510, avg. samples / sec: 65982.97
Iteration:   1560, Loss function: 3.995, Average Loss: 4.514, avg. samples / sec: 66117.26
Iteration:   1560, Loss function: 5.614, Average Loss: 4.501, avg. samples / sec: 66003.18
Iteration:   1560, Loss function: 4.403, Average Loss: 4.486, avg. samples / sec: 66178.68
Iteration:   1560, Loss function: 4.163, Average Loss: 4.483, avg. samples / sec: 65980.38
Iteration:   1560, Loss function: 3.935, Average Loss: 4.516, avg. samples / sec: 66150.19
Iteration:   1560, Loss function: 3.602, Average Loss: 4.482, avg. samples / sec: 66197.76
Iteration:   1560, Loss function: 4.974, Average Loss: 4.509, avg. samples / sec: 65962.90
Iteration:   1560, Loss function: 4.478, Average Loss: 4.479, avg. samples / sec: 66116.11
Iteration:   1560, Loss function: 3.591, Average Loss: 4.496, avg. samples / sec: 66026.16
Iteration:   1560, Loss function: 5.360, Average Loss: 4.482, avg. samples / sec: 65925.04
Iteration:   1560, Loss function: 4.902, Average Loss: 4.495, avg. samples / sec: 66366.88
Iteration:   1580, Loss function: 5.127, Average Loss: 4.443, avg. samples / sec: 66451.53
Iteration:   1580, Loss function: 4.778, Average Loss: 4.492, avg. samples / sec: 66698.89
Iteration:   1580, Loss function: 4.965, Average Loss: 4.494, avg. samples / sec: 66309.77
Iteration:   1580, Loss function: 4.218, Average Loss: 4.512, avg. samples / sec: 66453.19
Iteration:   1580, Loss function: 4.997, Average Loss: 4.494, avg. samples / sec: 66361.85
Iteration:   1580, Loss function: 4.256, Average Loss: 4.508, avg. samples / sec: 66544.41
Iteration:   1580, Loss function: 5.465, Average Loss: 4.493, avg. samples / sec: 66327.96
Iteration:   1580, Loss function: 3.098, Average Loss: 4.500, avg. samples / sec: 66425.28
Iteration:   1580, Loss function: 5.472, Average Loss: 4.511, avg. samples / sec: 66366.79
Iteration:   1580, Loss function: 5.176, Average Loss: 4.492, avg. samples / sec: 66373.32
Iteration:   1580, Loss function: 3.447, Average Loss: 4.478, avg. samples / sec: 66370.41
Iteration:   1580, Loss function: 4.776, Average Loss: 4.488, avg. samples / sec: 66198.76
Iteration:   1580, Loss function: 4.360, Average Loss: 4.513, avg. samples / sec: 66434.74
Iteration:   1580, Loss function: 5.239, Average Loss: 4.494, avg. samples / sec: 66388.74
Iteration:   1580, Loss function: 3.997, Average Loss: 4.490, avg. samples / sec: 66418.71
Iteration:   1580, Loss function: 3.682, Average Loss: 4.504, avg. samples / sec: 66388.30
Iteration:   1580, Loss function: 4.371, Average Loss: 4.504, avg. samples / sec: 66279.99
Iteration:   1580, Loss function: 3.821, Average Loss: 4.512, avg. samples / sec: 66401.28
Iteration:   1580, Loss function: 4.719, Average Loss: 4.481, avg. samples / sec: 66415.24
Iteration:   1580, Loss function: 5.142, Average Loss: 4.482, avg. samples / sec: 66301.28
Iteration:   1580, Loss function: 3.328, Average Loss: 4.477, avg. samples / sec: 66492.67
Iteration:   1580, Loss function: 4.979, Average Loss: 4.496, avg. samples / sec: 66338.05
Iteration:   1580, Loss function: 4.722, Average Loss: 4.500, avg. samples / sec: 66346.01
Iteration:   1580, Loss function: 3.511, Average Loss: 4.493, avg. samples / sec: 66289.31
Iteration:   1580, Loss function: 3.616, Average Loss: 4.491, avg. samples / sec: 66274.09
Iteration:   1580, Loss function: 3.965, Average Loss: 4.512, avg. samples / sec: 66262.19
Iteration:   1580, Loss function: 3.719, Average Loss: 4.512, avg. samples / sec: 66296.70
Iteration:   1580, Loss function: 4.084, Average Loss: 4.503, avg. samples / sec: 66380.92
Iteration:   1580, Loss function: 4.943, Average Loss: 4.481, avg. samples / sec: 66291.99
Iteration:   1580, Loss function: 4.867, Average Loss: 4.477, avg. samples / sec: 66370.38
Iteration:   1600, Loss function: 4.912, Average Loss: 4.493, avg. samples / sec: 66688.54
Iteration:   1600, Loss function: 4.964, Average Loss: 4.495, avg. samples / sec: 66629.42
Iteration:   1600, Loss function: 3.836, Average Loss: 4.505, avg. samples / sec: 66693.49
Iteration:   1600, Loss function: 4.117, Average Loss: 4.510, avg. samples / sec: 66581.22
Iteration:   1600, Loss function: 4.472, Average Loss: 4.491, avg. samples / sec: 66533.51
Iteration:   1600, Loss function: 5.078, Average Loss: 4.448, avg. samples / sec: 66426.22
Iteration:   1600, Loss function: 4.111, Average Loss: 4.493, avg. samples / sec: 66579.34
Iteration:   1600, Loss function: 5.141, Average Loss: 4.495, avg. samples / sec: 66514.07
Iteration:   1600, Loss function: 4.136, Average Loss: 4.511, avg. samples / sec: 66507.85
Iteration:   1600, Loss function: 4.421, Average Loss: 4.498, avg. samples / sec: 66508.51
Iteration:   1600, Loss function: 5.242, Average Loss: 4.512, avg. samples / sec: 66573.27
Iteration:   1600, Loss function: 4.247, Average Loss: 4.508, avg. samples / sec: 66469.90
Iteration:   1600, Loss function: 3.977, Average Loss: 4.507, avg. samples / sec: 66563.71
Iteration:   1600, Loss function: 3.911, Average Loss: 4.492, avg. samples / sec: 66621.48
Iteration:   1600, Loss function: 3.358, Average Loss: 4.490, avg. samples / sec: 66621.76
Iteration:   1600, Loss function: 3.858, Average Loss: 4.480, avg. samples / sec: 66669.32
Iteration:   1600, Loss function: 4.709, Average Loss: 4.512, avg. samples / sec: 66514.60
Iteration:   1600, Loss function: 4.194, Average Loss: 4.492, avg. samples / sec: 66513.07
Iteration:   1600, Loss function: 3.648, Average Loss: 4.484, avg. samples / sec: 66649.77
Iteration:   1600, Loss function: 3.994, Average Loss: 4.508, avg. samples / sec: 66567.45
Iteration:   1600, Loss function: 4.437, Average Loss: 4.478, avg. samples / sec: 66529.71
Iteration:   1600, Loss function: 4.963, Average Loss: 4.472, avg. samples / sec: 66550.22
Iteration:   1600, Loss function: 4.416, Average Loss: 4.496, avg. samples / sec: 66525.34
Iteration:   1600, Loss function: 4.121, Average Loss: 4.478, avg. samples / sec: 66453.47
Iteration:   1600, Loss function: 5.344, Average Loss: 4.488, avg. samples / sec: 66469.02
Iteration:   1600, Loss function: 5.396, Average Loss: 4.502, avg. samples / sec: 66560.22
Iteration:   1600, Loss function: 4.506, Average Loss: 4.484, avg. samples / sec: 66499.54
Iteration:   1600, Loss function: 4.297, Average Loss: 4.505, avg. samples / sec: 66572.83
Iteration:   1600, Loss function: 4.308, Average Loss: 4.509, avg. samples / sec: 66555.22
Iteration:   1600, Loss function: 4.473, Average Loss: 4.496, avg. samples / sec: 66263.47
:::MLL 1558651899.203 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558651899.204 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 4.217, Average Loss: 4.513, avg. samples / sec: 66280.48
Iteration:   1620, Loss function: 5.182, Average Loss: 4.511, avg. samples / sec: 66239.61
Iteration:   1620, Loss function: 4.431, Average Loss: 4.497, avg. samples / sec: 66260.07
Iteration:   1620, Loss function: 5.790, Average Loss: 4.512, avg. samples / sec: 66173.30
Iteration:   1620, Loss function: 4.003, Average Loss: 4.494, avg. samples / sec: 66085.14
Iteration:   1620, Loss function: 3.478, Average Loss: 4.504, avg. samples / sec: 66349.01
Iteration:   1620, Loss function: 4.460, Average Loss: 4.505, avg. samples / sec: 66232.45
Iteration:   1620, Loss function: 4.352, Average Loss: 4.504, avg. samples / sec: 66285.60
Iteration:   1620, Loss function: 3.529, Average Loss: 4.507, avg. samples / sec: 66307.99
Iteration:   1620, Loss function: 4.116, Average Loss: 4.511, avg. samples / sec: 66299.50
Iteration:   1620, Loss function: 4.042, Average Loss: 4.491, avg. samples / sec: 66170.60
Iteration:   1620, Loss function: 3.950, Average Loss: 4.449, avg. samples / sec: 66139.70
Iteration:   1620, Loss function: 6.248, Average Loss: 4.491, avg. samples / sec: 66133.71
Iteration:   1620, Loss function: 5.000, Average Loss: 4.493, avg. samples / sec: 66186.01
Iteration:   1620, Loss function: 5.303, Average Loss: 4.504, avg. samples / sec: 66035.38
Iteration:   1620, Loss function: 3.978, Average Loss: 4.491, avg. samples / sec: 66081.14
Iteration:   1620, Loss function: 4.993, Average Loss: 4.492, avg. samples / sec: 66215.68
Iteration:   1620, Loss function: 3.880, Average Loss: 4.485, avg. samples / sec: 66171.25
Iteration:   1620, Loss function: 4.878, Average Loss: 4.474, avg. samples / sec: 66196.27
Iteration:   1620, Loss function: 4.520, Average Loss: 4.508, avg. samples / sec: 66155.84
Iteration:   1620, Loss function: 4.674, Average Loss: 4.480, avg. samples / sec: 66209.30
Iteration:   1620, Loss function: 5.399, Average Loss: 4.483, avg. samples / sec: 66203.48
Iteration:   1620, Loss function: 6.029, Average Loss: 4.476, avg. samples / sec: 66169.35
Iteration:   1620, Loss function: 4.919, Average Loss: 4.502, avg. samples / sec: 66123.72
Iteration:   1620, Loss function: 5.755, Average Loss: 4.493, avg. samples / sec: 65942.59
Iteration:   1620, Loss function: 4.275, Average Loss: 4.487, avg. samples / sec: 66180.42
Iteration:   1620, Loss function: 4.929, Average Loss: 4.492, avg. samples / sec: 66098.38
Iteration:   1620, Loss function: 5.318, Average Loss: 4.484, avg. samples / sec: 66084.55
Iteration:   1620, Loss function: 4.057, Average Loss: 4.485, avg. samples / sec: 66053.58
Iteration:   1620, Loss function: 5.147, Average Loss: 4.498, avg. samples / sec: 66167.65
Iteration:   1640, Loss function: 4.268, Average Loss: 4.490, avg. samples / sec: 66851.83
Iteration:   1640, Loss function: 4.202, Average Loss: 4.514, avg. samples / sec: 66626.17
Iteration:   1640, Loss function: 4.982, Average Loss: 4.496, avg. samples / sec: 66571.13
Iteration:   1640, Loss function: 6.315, Average Loss: 4.451, avg. samples / sec: 66661.41
Iteration:   1640, Loss function: 4.996, Average Loss: 4.481, avg. samples / sec: 66662.79
Iteration:   1640, Loss function: 4.169, Average Loss: 4.495, avg. samples / sec: 66545.07
Iteration:   1640, Loss function: 4.809, Average Loss: 4.503, avg. samples / sec: 66627.84
Iteration:   1640, Loss function: 3.415, Average Loss: 4.485, avg. samples / sec: 66685.10
Iteration:   1640, Loss function: 4.527, Average Loss: 4.510, avg. samples / sec: 66496.97
Iteration:   1640, Loss function: 4.055, Average Loss: 4.509, avg. samples / sec: 66501.33
Iteration:   1640, Loss function: 3.565, Average Loss: 4.484, avg. samples / sec: 66715.18
Iteration:   1640, Loss function: 4.612, Average Loss: 4.480, avg. samples / sec: 66652.23
Iteration:   1640, Loss function: 5.589, Average Loss: 4.506, avg. samples / sec: 66516.58
Iteration:   1640, Loss function: 3.809, Average Loss: 4.485, avg. samples / sec: 66587.39
Iteration:   1640, Loss function: 5.758, Average Loss: 4.487, avg. samples / sec: 66738.72
Iteration:   1640, Loss function: 4.233, Average Loss: 4.490, avg. samples / sec: 66593.21
Iteration:   1640, Loss function: 4.236, Average Loss: 4.493, avg. samples / sec: 66645.74
Iteration:   1640, Loss function: 3.675, Average Loss: 4.475, avg. samples / sec: 66602.75
Iteration:   1640, Loss function: 6.531, Average Loss: 4.503, avg. samples / sec: 66479.46
Iteration:   1640, Loss function: 4.682, Average Loss: 4.501, avg. samples / sec: 66493.29
Iteration:   1640, Loss function: 3.359, Average Loss: 4.495, avg. samples / sec: 66697.66
Iteration:   1640, Loss function: 5.193, Average Loss: 4.486, avg. samples / sec: 66500.82
Iteration:   1640, Loss function: 3.193, Average Loss: 4.512, avg. samples / sec: 66509.05
Iteration:   1640, Loss function: 4.962, Average Loss: 4.474, avg. samples / sec: 66550.57
Iteration:   1640, Loss function: 3.512, Average Loss: 4.508, avg. samples / sec: 66529.61
Iteration:   1640, Loss function: 4.161, Average Loss: 4.487, avg. samples / sec: 66469.43
Iteration:   1640, Loss function: 3.479, Average Loss: 4.490, avg. samples / sec: 66502.43
Iteration:   1640, Loss function: 3.676, Average Loss: 4.502, avg. samples / sec: 66426.76
Iteration:   1640, Loss function: 3.763, Average Loss: 4.493, avg. samples / sec: 66442.98
Iteration:   1640, Loss function: 3.262, Average Loss: 4.501, avg. samples / sec: 66494.20
Iteration:   1660, Loss function: 4.623, Average Loss: 4.495, avg. samples / sec: 66693.49
Iteration:   1660, Loss function: 4.758, Average Loss: 4.486, avg. samples / sec: 66609.36
Iteration:   1660, Loss function: 4.229, Average Loss: 4.447, avg. samples / sec: 66581.92
Iteration:   1660, Loss function: 3.543, Average Loss: 4.504, avg. samples / sec: 66648.83
Iteration:   1660, Loss function: 5.059, Average Loss: 4.478, avg. samples / sec: 66653.34
Iteration:   1660, Loss function: 2.971, Average Loss: 4.482, avg. samples / sec: 66439.31
Iteration:   1660, Loss function: 3.653, Average Loss: 4.502, avg. samples / sec: 66612.85
Iteration:   1660, Loss function: 5.800, Average Loss: 4.487, avg. samples / sec: 66699.55
Iteration:   1660, Loss function: 5.042, Average Loss: 4.495, avg. samples / sec: 66656.58
Iteration:   1660, Loss function: 4.707, Average Loss: 4.494, avg. samples / sec: 66622.99
Iteration:   1660, Loss function: 4.966, Average Loss: 4.489, avg. samples / sec: 66679.61
Iteration:   1660, Loss function: 4.572, Average Loss: 4.515, avg. samples / sec: 66460.53
Iteration:   1660, Loss function: 3.936, Average Loss: 4.507, avg. samples / sec: 66539.70
Iteration:   1660, Loss function: 2.859, Average Loss: 4.481, avg. samples / sec: 66565.28
Iteration:   1660, Loss function: 5.863, Average Loss: 4.500, avg. samples / sec: 66611.31
Iteration:   1660, Loss function: 5.010, Average Loss: 4.500, avg. samples / sec: 66704.35
Iteration:   1660, Loss function: 4.124, Average Loss: 4.492, avg. samples / sec: 66691.79
Iteration:   1660, Loss function: 4.254, Average Loss: 4.485, avg. samples / sec: 66629.83
Iteration:   1660, Loss function: 4.337, Average Loss: 4.502, avg. samples / sec: 66614.65
Iteration:   1660, Loss function: 4.178, Average Loss: 4.482, avg. samples / sec: 66476.86
Iteration:   1660, Loss function: 3.405, Average Loss: 4.508, avg. samples / sec: 66589.72
Iteration:   1660, Loss function: 4.917, Average Loss: 4.481, avg. samples / sec: 66445.27
Iteration:   1660, Loss function: 5.022, Average Loss: 4.512, avg. samples / sec: 66540.04
Iteration:   1660, Loss function: 4.347, Average Loss: 4.478, avg. samples / sec: 66526.06
Iteration:   1660, Loss function: 4.385, Average Loss: 4.504, avg. samples / sec: 66496.68
Iteration:   1660, Loss function: 5.024, Average Loss: 4.492, avg. samples / sec: 66517.96
Iteration:   1660, Loss function: 4.090, Average Loss: 4.478, avg. samples / sec: 66444.73
Iteration:   1660, Loss function: 4.320, Average Loss: 4.485, avg. samples / sec: 66405.16
Iteration:   1660, Loss function: 3.594, Average Loss: 4.476, avg. samples / sec: 66504.65
Iteration:   1660, Loss function: 5.653, Average Loss: 4.501, avg. samples / sec: 66422.65
:::MLL 1558651900.975 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558651900.976 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 4.281, Average Loss: 4.477, avg. samples / sec: 66118.04
Iteration:   1680, Loss function: 4.241, Average Loss: 4.498, avg. samples / sec: 66018.49
Iteration:   1680, Loss function: 4.425, Average Loss: 4.509, avg. samples / sec: 66161.59
Iteration:   1680, Loss function: 2.716, Average Loss: 4.481, avg. samples / sec: 66041.48
Iteration:   1680, Loss function: 4.566, Average Loss: 4.518, avg. samples / sec: 66126.26
Iteration:   1680, Loss function: 4.193, Average Loss: 4.499, avg. samples / sec: 66124.15
Iteration:   1680, Loss function: 3.968, Average Loss: 4.497, avg. samples / sec: 66164.76
Iteration:   1680, Loss function: 5.114, Average Loss: 4.499, avg. samples / sec: 66083.41
Iteration:   1680, Loss function: 3.815, Average Loss: 4.507, avg. samples / sec: 65959.57
Iteration:   1680, Loss function: 4.936, Average Loss: 4.503, avg. samples / sec: 66250.95
Iteration:   1680, Loss function: 4.362, Average Loss: 4.505, avg. samples / sec: 66130.26
Iteration:   1680, Loss function: 3.811, Average Loss: 4.514, avg. samples / sec: 66121.76
Iteration:   1680, Loss function: 3.828, Average Loss: 4.483, avg. samples / sec: 65969.08
Iteration:   1680, Loss function: 5.125, Average Loss: 4.485, avg. samples / sec: 66182.68
Iteration:   1680, Loss function: 4.903, Average Loss: 4.475, avg. samples / sec: 66164.94
Iteration:   1680, Loss function: 3.237, Average Loss: 4.502, avg. samples / sec: 66103.77
Iteration:   1680, Loss function: 4.472, Average Loss: 4.481, avg. samples / sec: 66040.86
Iteration:   1680, Loss function: 4.709, Average Loss: 4.486, avg. samples / sec: 66090.29
Iteration:   1680, Loss function: 3.563, Average Loss: 4.491, avg. samples / sec: 65950.03
Iteration:   1680, Loss function: 5.085, Average Loss: 4.509, avg. samples / sec: 65936.98
Iteration:   1680, Loss function: 4.688, Average Loss: 4.480, avg. samples / sec: 66072.81
Iteration:   1680, Loss function: 5.139, Average Loss: 4.495, avg. samples / sec: 65952.53
Iteration:   1680, Loss function: 6.158, Average Loss: 4.447, avg. samples / sec: 65870.74
Iteration:   1680, Loss function: 5.865, Average Loss: 4.485, avg. samples / sec: 66040.39
Iteration:   1680, Loss function: 3.750, Average Loss: 4.489, avg. samples / sec: 65900.99
Iteration:   1680, Loss function: 4.852, Average Loss: 4.490, avg. samples / sec: 65918.07
Iteration:   1680, Loss function: 3.889, Average Loss: 4.492, avg. samples / sec: 65981.03
Iteration:   1680, Loss function: 4.287, Average Loss: 4.485, avg. samples / sec: 65962.07
Iteration:   1680, Loss function: 4.329, Average Loss: 4.476, avg. samples / sec: 66045.90
Iteration:   1680, Loss function: 4.427, Average Loss: 4.495, avg. samples / sec: 65932.41
Iteration:   1700, Loss function: 3.509, Average Loss: 4.502, avg. samples / sec: 66462.44
Iteration:   1700, Loss function: 4.538, Average Loss: 4.479, avg. samples / sec: 66545.35
Iteration:   1700, Loss function: 5.297, Average Loss: 4.478, avg. samples / sec: 66394.05
Iteration:   1700, Loss function: 4.984, Average Loss: 4.490, avg. samples / sec: 66559.68
Iteration:   1700, Loss function: 3.190, Average Loss: 4.446, avg. samples / sec: 66602.12
Iteration:   1700, Loss function: 3.969, Average Loss: 4.490, avg. samples / sec: 66589.56
Iteration:   1700, Loss function: 4.922, Average Loss: 4.479, avg. samples / sec: 66362.19
Iteration:   1700, Loss function: 4.175, Average Loss: 4.481, avg. samples / sec: 66460.62
Iteration:   1700, Loss function: 4.537, Average Loss: 4.483, avg. samples / sec: 66461.90
Iteration:   1700, Loss function: 4.309, Average Loss: 4.486, avg. samples / sec: 66538.69
Iteration:   1700, Loss function: 4.771, Average Loss: 4.505, avg. samples / sec: 66292.92
Iteration:   1700, Loss function: 4.720, Average Loss: 4.522, avg. samples / sec: 66313.86
Iteration:   1700, Loss function: 3.523, Average Loss: 4.496, avg. samples / sec: 66411.76
Iteration:   1700, Loss function: 4.291, Average Loss: 4.510, avg. samples / sec: 66409.04
Iteration:   1700, Loss function: 3.446, Average Loss: 4.472, avg. samples / sec: 66529.55
Iteration:   1700, Loss function: 4.719, Average Loss: 4.513, avg. samples / sec: 66434.08
Iteration:   1700, Loss function: 3.340, Average Loss: 4.479, avg. samples / sec: 66401.31
Iteration:   1700, Loss function: 4.472, Average Loss: 4.507, avg. samples / sec: 66363.26
Iteration:   1700, Loss function: 4.335, Average Loss: 4.476, avg. samples / sec: 66412.79
Iteration:   1700, Loss function: 3.813, Average Loss: 4.473, avg. samples / sec: 66357.57
Iteration:   1700, Loss function: 4.207, Average Loss: 4.498, avg. samples / sec: 66298.38
Iteration:   1700, Loss function: 4.011, Average Loss: 4.492, avg. samples / sec: 66472.25
Iteration:   1700, Loss function: 5.019, Average Loss: 4.497, avg. samples / sec: 66407.54
Iteration:   1700, Loss function: 4.195, Average Loss: 4.494, avg. samples / sec: 66260.20
Iteration:   1700, Loss function: 4.288, Average Loss: 4.502, avg. samples / sec: 66300.10
Iteration:   1700, Loss function: 5.962, Average Loss: 4.496, avg. samples / sec: 66497.44
Iteration:   1700, Loss function: 4.408, Average Loss: 4.505, avg. samples / sec: 66287.84
Iteration:   1700, Loss function: 4.562, Average Loss: 4.485, avg. samples / sec: 66387.74
Iteration:   1700, Loss function: 4.144, Average Loss: 4.481, avg. samples / sec: 66384.42
Iteration:   1700, Loss function: 5.242, Average Loss: 4.497, avg. samples / sec: 66240.61
Iteration:   1720, Loss function: 5.195, Average Loss: 4.450, avg. samples / sec: 66707.00
Iteration:   1720, Loss function: 3.551, Average Loss: 4.477, avg. samples / sec: 66683.58
Iteration:   1720, Loss function: 4.014, Average Loss: 4.502, avg. samples / sec: 66586.76
Iteration:   1720, Loss function: 4.766, Average Loss: 4.510, avg. samples / sec: 66786.89
Iteration:   1720, Loss function: 4.296, Average Loss: 4.501, avg. samples / sec: 66773.98
Iteration:   1720, Loss function: 3.689, Average Loss: 4.482, avg. samples / sec: 66656.27
Iteration:   1720, Loss function: 5.495, Average Loss: 4.518, avg. samples / sec: 66718.37
Iteration:   1720, Loss function: 3.852, Average Loss: 4.482, avg. samples / sec: 66707.92
Iteration:   1720, Loss function: 3.409, Average Loss: 4.485, avg. samples / sec: 66647.79
Iteration:   1720, Loss function: 5.087, Average Loss: 4.478, avg. samples / sec: 66762.53
Iteration:   1720, Loss function: 3.339, Average Loss: 4.505, avg. samples / sec: 66714.71
Iteration:   1720, Loss function: 4.047, Average Loss: 4.479, avg. samples / sec: 66556.29
Iteration:   1720, Loss function: 4.400, Average Loss: 4.477, avg. samples / sec: 66734.36
Iteration:   1720, Loss function: 4.868, Average Loss: 4.494, avg. samples / sec: 66784.99
Iteration:   1720, Loss function: 5.669, Average Loss: 4.498, avg. samples / sec: 66829.39
Iteration:   1720, Loss function: 4.251, Average Loss: 4.501, avg. samples / sec: 66780.15
Iteration:   1720, Loss function: 4.513, Average Loss: 4.495, avg. samples / sec: 66729.65
Iteration:   1720, Loss function: 3.469, Average Loss: 4.490, avg. samples / sec: 66717.68
Iteration:   1720, Loss function: 4.652, Average Loss: 4.481, avg. samples / sec: 66632.47
Iteration:   1720, Loss function: 3.710, Average Loss: 4.490, avg. samples / sec: 66641.23
Iteration:   1720, Loss function: 4.461, Average Loss: 4.506, avg. samples / sec: 66642.87
Iteration:   1720, Loss function: 3.490, Average Loss: 4.492, avg. samples / sec: 66517.49
Iteration:   1720, Loss function: 3.350, Average Loss: 4.478, avg. samples / sec: 66762.24
Iteration:   1720, Loss function: 3.293, Average Loss: 4.477, avg. samples / sec: 66634.90
Iteration:   1720, Loss function: 4.555, Average Loss: 4.482, avg. samples / sec: 66559.71
Iteration:   1720, Loss function: 5.866, Average Loss: 4.486, avg. samples / sec: 66615.43
Iteration:   1720, Loss function: 3.512, Average Loss: 4.483, avg. samples / sec: 66655.61
Iteration:   1720, Loss function: 3.400, Average Loss: 4.471, avg. samples / sec: 66559.49
Iteration:   1720, Loss function: 4.339, Average Loss: 4.505, avg. samples / sec: 66664.72
Iteration:   1720, Loss function: 4.220, Average Loss: 4.497, avg. samples / sec: 66594.22
Iteration:   1740, Loss function: 2.682, Average Loss: 4.481, avg. samples / sec: 66520.69
Iteration:   1740, Loss function: 3.895, Average Loss: 4.448, avg. samples / sec: 66376.04
Iteration:   1740, Loss function: 3.279, Average Loss: 4.473, avg. samples / sec: 66379.54
Iteration:   1740, Loss function: 3.273, Average Loss: 4.512, avg. samples / sec: 66400.56
Iteration:   1740, Loss function: 5.850, Average Loss: 4.489, avg. samples / sec: 66532.06
Iteration:   1740, Loss function: 3.934, Average Loss: 4.511, avg. samples / sec: 66452.91
Iteration:   1740, Loss function: 5.328, Average Loss: 4.495, avg. samples / sec: 66397.31
Iteration:   1740, Loss function: 5.122, Average Loss: 4.479, avg. samples / sec: 66388.61
Iteration:   1740, Loss function: 3.241, Average Loss: 4.478, avg. samples / sec: 66510.37
Iteration:   1740, Loss function: 3.766, Average Loss: 4.487, avg. samples / sec: 66436.65
Iteration:   1740, Loss function: 4.916, Average Loss: 4.480, avg. samples / sec: 66381.23
Iteration:   1740, Loss function: 4.319, Average Loss: 4.502, avg. samples / sec: 66423.34
Iteration:   1740, Loss function: 5.006, Average Loss: 4.489, avg. samples / sec: 66404.16
Iteration:   1740, Loss function: 3.764, Average Loss: 4.492, avg. samples / sec: 66399.03
Iteration:   1740, Loss function: 6.468, Average Loss: 4.486, avg. samples / sec: 66465.48
Iteration:   1740, Loss function: 4.912, Average Loss: 4.478, avg. samples / sec: 66375.54
Iteration:   1740, Loss function: 5.666, Average Loss: 4.472, avg. samples / sec: 66504.34
Iteration:   1740, Loss function: 5.169, Average Loss: 4.505, avg. samples / sec: 66408.26
Iteration:   1740, Loss function: 5.190, Average Loss: 4.500, avg. samples / sec: 66349.38
Iteration:   1740, Loss function: 4.229, Average Loss: 4.498, avg. samples / sec: 66282.70
Iteration:   1740, Loss function: 3.694, Average Loss: 4.480, avg. samples / sec: 66358.98
Iteration:   1740, Loss function: 4.968, Average Loss: 4.478, avg. samples / sec: 66461.50
Iteration:   1740, Loss function: 5.936, Average Loss: 4.486, avg. samples / sec: 66379.76
Iteration:   1740, Loss function: 5.543, Average Loss: 4.472, avg. samples / sec: 66386.45
Iteration:   1740, Loss function: 4.383, Average Loss: 4.494, avg. samples / sec: 66334.02
Iteration:   1740, Loss function: 3.581, Average Loss: 4.489, avg. samples / sec: 66496.93
Iteration:   1740, Loss function: 3.897, Average Loss: 4.507, avg. samples / sec: 66391.80
Iteration:   1740, Loss function: 4.755, Average Loss: 4.480, avg. samples / sec: 66220.75
Iteration:   1740, Loss function: 4.494, Average Loss: 4.485, avg. samples / sec: 66208.80
Iteration:   1740, Loss function: 4.071, Average Loss: 4.482, avg. samples / sec: 66371.20
:::MLL 1558651902.746 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558651902.746 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 5.211, Average Loss: 4.473, avg. samples / sec: 66184.46
Iteration:   1760, Loss function: 3.155, Average Loss: 4.505, avg. samples / sec: 66246.09
Iteration:   1760, Loss function: 5.055, Average Loss: 4.469, avg. samples / sec: 66103.18
Iteration:   1760, Loss function: 4.365, Average Loss: 4.491, avg. samples / sec: 66199.53
Iteration:   1760, Loss function: 4.880, Average Loss: 4.498, avg. samples / sec: 66174.76
Iteration:   1760, Loss function: 4.773, Average Loss: 4.482, avg. samples / sec: 66090.75
Iteration:   1760, Loss function: 5.616, Average Loss: 4.492, avg. samples / sec: 66144.57
Iteration:   1760, Loss function: 4.368, Average Loss: 4.513, avg. samples / sec: 66048.78
Iteration:   1760, Loss function: 5.216, Average Loss: 4.509, avg. samples / sec: 66053.86
Iteration:   1760, Loss function: 4.529, Average Loss: 4.479, avg. samples / sec: 66109.66
Iteration:   1760, Loss function: 4.013, Average Loss: 4.451, avg. samples / sec: 66016.17
Iteration:   1760, Loss function: 3.233, Average Loss: 4.484, avg. samples / sec: 66203.14
Iteration:   1760, Loss function: 4.205, Average Loss: 4.466, avg. samples / sec: 66153.45
Iteration:   1760, Loss function: 5.034, Average Loss: 4.499, avg. samples / sec: 66130.88
Iteration:   1760, Loss function: 4.484, Average Loss: 4.473, avg. samples / sec: 66195.27
Iteration:   1760, Loss function: 5.101, Average Loss: 4.494, avg. samples / sec: 66196.24
Iteration:   1760, Loss function: 5.133, Average Loss: 4.496, avg. samples / sec: 66053.77
Iteration:   1760, Loss function: 4.230, Average Loss: 4.476, avg. samples / sec: 66133.27
Iteration:   1760, Loss function: 5.392, Average Loss: 4.482, avg. samples / sec: 66158.14
Iteration:   1760, Loss function: 3.926, Average Loss: 4.496, avg. samples / sec: 66140.50
Iteration:   1760, Loss function: 3.424, Average Loss: 4.484, avg. samples / sec: 66185.30
Iteration:   1760, Loss function: 4.521, Average Loss: 4.489, avg. samples / sec: 66084.09
Iteration:   1760, Loss function: 4.866, Average Loss: 4.478, avg. samples / sec: 66056.24
Iteration:   1760, Loss function: 5.007, Average Loss: 4.479, avg. samples / sec: 65949.69
Iteration:   1760, Loss function: 5.602, Average Loss: 4.476, avg. samples / sec: 66236.53
Iteration:   1760, Loss function: 3.838, Average Loss: 4.484, avg. samples / sec: 66228.12
Iteration:   1760, Loss function: 3.714, Average Loss: 4.479, avg. samples / sec: 66206.87
Iteration:   1760, Loss function: 4.323, Average Loss: 4.507, avg. samples / sec: 66179.55
Iteration:   1760, Loss function: 3.929, Average Loss: 4.482, avg. samples / sec: 66051.57
Iteration:   1760, Loss function: 3.956, Average Loss: 4.476, avg. samples / sec: 66073.52
Iteration:   1780, Loss function: 4.090, Average Loss: 4.452, avg. samples / sec: 66897.88
Iteration:   1780, Loss function: 4.613, Average Loss: 4.483, avg. samples / sec: 66915.73
Iteration:   1780, Loss function: 5.359, Average Loss: 4.468, avg. samples / sec: 66709.91
Iteration:   1780, Loss function: 3.460, Average Loss: 4.494, avg. samples / sec: 66806.68
Iteration:   1780, Loss function: 4.545, Average Loss: 4.490, avg. samples / sec: 66795.97
Iteration:   1780, Loss function: 3.690, Average Loss: 4.467, avg. samples / sec: 66677.78
Iteration:   1780, Loss function: 4.679, Average Loss: 4.480, avg. samples / sec: 66798.03
Iteration:   1780, Loss function: 3.948, Average Loss: 4.469, avg. samples / sec: 66762.56
Iteration:   1780, Loss function: 4.110, Average Loss: 4.480, avg. samples / sec: 66697.44
Iteration:   1780, Loss function: 4.040, Average Loss: 4.485, avg. samples / sec: 66766.57
Iteration:   1780, Loss function: 3.974, Average Loss: 4.508, avg. samples / sec: 66698.23
Iteration:   1780, Loss function: 4.353, Average Loss: 4.507, avg. samples / sec: 66791.22
Iteration:   1780, Loss function: 4.548, Average Loss: 4.498, avg. samples / sec: 66608.95
Iteration:   1780, Loss function: 4.850, Average Loss: 4.491, avg. samples / sec: 66690.02
Iteration:   1780, Loss function: 4.796, Average Loss: 4.512, avg. samples / sec: 66660.05
Iteration:   1780, Loss function: 5.066, Average Loss: 4.497, avg. samples / sec: 66562.51
Iteration:   1780, Loss function: 4.094, Average Loss: 4.488, avg. samples / sec: 66587.83
Iteration:   1780, Loss function: 4.363, Average Loss: 4.472, avg. samples / sec: 66687.43
Iteration:   1780, Loss function: 4.049, Average Loss: 4.482, avg. samples / sec: 66582.36
Iteration:   1780, Loss function: 3.513, Average Loss: 4.477, avg. samples / sec: 66719.00
Iteration:   1780, Loss function: 4.262, Average Loss: 4.479, avg. samples / sec: 66683.77
Iteration:   1780, Loss function: 3.850, Average Loss: 4.478, avg. samples / sec: 66665.70
Iteration:   1780, Loss function: 4.206, Average Loss: 4.485, avg. samples / sec: 66631.43
Iteration:   1780, Loss function: 3.071, Average Loss: 4.496, avg. samples / sec: 66624.06
Iteration:   1780, Loss function: 4.122, Average Loss: 4.481, avg. samples / sec: 66647.25
Iteration:   1780, Loss function: 3.989, Average Loss: 4.476, avg. samples / sec: 66667.24
Iteration:   1780, Loss function: 5.293, Average Loss: 4.479, avg. samples / sec: 66741.25
Iteration:   1780, Loss function: 3.527, Average Loss: 4.481, avg. samples / sec: 66597.84
Iteration:   1780, Loss function: 3.192, Average Loss: 4.473, avg. samples / sec: 66547.96
Iteration:   1780, Loss function: 3.960, Average Loss: 4.455, avg. samples / sec: 66543.91
Iteration:   1800, Loss function: 4.647, Average Loss: 4.484, avg. samples / sec: 66827.49
Iteration:   1800, Loss function: 4.206, Average Loss: 4.483, avg. samples / sec: 66889.09
Iteration:   1800, Loss function: 3.822, Average Loss: 4.447, avg. samples / sec: 66625.10
Iteration:   1800, Loss function: 4.014, Average Loss: 4.462, avg. samples / sec: 66738.21
Iteration:   1800, Loss function: 3.916, Average Loss: 4.485, avg. samples / sec: 66617.39
Iteration:   1800, Loss function: 4.681, Average Loss: 4.490, avg. samples / sec: 66691.75
Iteration:   1800, Loss function: 3.313, Average Loss: 4.475, avg. samples / sec: 66816.75
Iteration:   1800, Loss function: 4.615, Average Loss: 4.460, avg. samples / sec: 66623.84
Iteration:   1800, Loss function: 5.076, Average Loss: 4.495, avg. samples / sec: 66733.47
Iteration:   1800, Loss function: 4.135, Average Loss: 4.509, avg. samples / sec: 66732.33
Iteration:   1800, Loss function: 3.128, Average Loss: 4.495, avg. samples / sec: 66758.92
Iteration:   1800, Loss function: 4.623, Average Loss: 4.479, avg. samples / sec: 66641.11
Iteration:   1800, Loss function: 3.917, Average Loss: 4.501, avg. samples / sec: 66670.99
Iteration:   1800, Loss function: 5.244, Average Loss: 4.481, avg. samples / sec: 66716.19
Iteration:   1800, Loss function: 4.545, Average Loss: 4.474, avg. samples / sec: 66671.12
Iteration:   1800, Loss function: 3.570, Average Loss: 4.511, avg. samples / sec: 66614.90
Iteration:   1800, Loss function: 4.608, Average Loss: 4.474, avg. samples / sec: 66691.19
Iteration:   1800, Loss function: 4.920, Average Loss: 4.481, avg. samples / sec: 66596.17
Iteration:   1800, Loss function: 3.606, Average Loss: 4.477, avg. samples / sec: 66699.24
Iteration:   1800, Loss function: 5.588, Average Loss: 4.484, avg. samples / sec: 66658.35
Iteration:   1800, Loss function: 4.605, Average Loss: 4.465, avg. samples / sec: 66566.32
Iteration:   1800, Loss function: 3.757, Average Loss: 4.476, avg. samples / sec: 66560.72
Iteration:   1800, Loss function: 4.630, Average Loss: 4.481, avg. samples / sec: 66734.26
Iteration:   1800, Loss function: 3.685, Average Loss: 4.481, avg. samples / sec: 66686.20
Iteration:   1800, Loss function: 4.806, Average Loss: 4.454, avg. samples / sec: 66742.89
Iteration:   1800, Loss function: 3.626, Average Loss: 4.476, avg. samples / sec: 66636.95
Iteration:   1800, Loss function: 4.164, Average Loss: 4.497, avg. samples / sec: 66644.45
Iteration:   1800, Loss function: 4.049, Average Loss: 4.470, avg. samples / sec: 66654.98
Iteration:   1800, Loss function: 4.515, Average Loss: 4.469, avg. samples / sec: 66703.94
Iteration:   1800, Loss function: 3.823, Average Loss: 4.484, avg. samples / sec: 66497.31
:::MLL 1558651904.515 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558651904.515 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 3.426, Average Loss: 4.486, avg. samples / sec: 66554.84
Iteration:   1820, Loss function: 4.057, Average Loss: 4.458, avg. samples / sec: 66255.12
Iteration:   1820, Loss function: 4.504, Average Loss: 4.506, avg. samples / sec: 66332.74
Iteration:   1820, Loss function: 4.797, Average Loss: 4.485, avg. samples / sec: 66241.32
Iteration:   1820, Loss function: 4.809, Average Loss: 4.478, avg. samples / sec: 66115.49
Iteration:   1820, Loss function: 4.555, Average Loss: 4.489, avg. samples / sec: 66289.77
Iteration:   1820, Loss function: 4.192, Average Loss: 4.474, avg. samples / sec: 66310.36
Iteration:   1820, Loss function: 3.784, Average Loss: 4.494, avg. samples / sec: 66329.31
Iteration:   1820, Loss function: 4.607, Average Loss: 4.509, avg. samples / sec: 66364.98
Iteration:   1820, Loss function: 3.558, Average Loss: 4.492, avg. samples / sec: 66275.06
Iteration:   1820, Loss function: 4.481, Average Loss: 4.454, avg. samples / sec: 66236.93
Iteration:   1820, Loss function: 4.794, Average Loss: 4.474, avg. samples / sec: 66359.57
Iteration:   1820, Loss function: 4.214, Average Loss: 4.448, avg. samples / sec: 66364.73
Iteration:   1820, Loss function: 4.687, Average Loss: 4.447, avg. samples / sec: 66151.71
Iteration:   1820, Loss function: 4.287, Average Loss: 4.472, avg. samples / sec: 66206.22
Iteration:   1820, Loss function: 4.256, Average Loss: 4.482, avg. samples / sec: 66315.85
Iteration:   1820, Loss function: 3.608, Average Loss: 4.479, avg. samples / sec: 66115.80
Iteration:   1820, Loss function: 5.215, Average Loss: 4.489, avg. samples / sec: 66128.80
Iteration:   1820, Loss function: 4.522, Average Loss: 4.464, avg. samples / sec: 66327.93
Iteration:   1820, Loss function: 4.944, Average Loss: 4.473, avg. samples / sec: 66256.18
Iteration:   1820, Loss function: 3.941, Average Loss: 4.478, avg. samples / sec: 66277.49
Iteration:   1820, Loss function: 3.634, Average Loss: 4.477, avg. samples / sec: 66221.71
Iteration:   1820, Loss function: 4.679, Average Loss: 4.467, avg. samples / sec: 66263.16
Iteration:   1820, Loss function: 4.085, Average Loss: 4.481, avg. samples / sec: 66274.34
Iteration:   1820, Loss function: 3.053, Average Loss: 4.464, avg. samples / sec: 66322.59
Iteration:   1820, Loss function: 6.202, Average Loss: 4.486, avg. samples / sec: 66237.24
Iteration:   1820, Loss function: 3.483, Average Loss: 4.482, avg. samples / sec: 66364.73
Iteration:   1820, Loss function: 4.303, Average Loss: 4.473, avg. samples / sec: 66264.09
Iteration:   1820, Loss function: 3.900, Average Loss: 4.473, avg. samples / sec: 66224.67
Iteration:   1820, Loss function: 4.395, Average Loss: 4.476, avg. samples / sec: 66198.10
Iteration:   1840, Loss function: 3.715, Average Loss: 4.450, avg. samples / sec: 66301.59
Iteration:   1840, Loss function: 4.293, Average Loss: 4.470, avg. samples / sec: 66315.57
Iteration:   1840, Loss function: 3.862, Average Loss: 4.483, avg. samples / sec: 66220.34
Iteration:   1840, Loss function: 4.150, Average Loss: 4.443, avg. samples / sec: 66351.10
Iteration:   1840, Loss function: 3.318, Average Loss: 4.487, avg. samples / sec: 66295.42
Iteration:   1840, Loss function: 3.042, Average Loss: 4.471, avg. samples / sec: 66288.31
Iteration:   1840, Loss function: 4.161, Average Loss: 4.489, avg. samples / sec: 66303.75
Iteration:   1840, Loss function: 4.354, Average Loss: 4.502, avg. samples / sec: 66296.35
Iteration:   1840, Loss function: 4.972, Average Loss: 4.483, avg. samples / sec: 66247.61
Iteration:   1840, Loss function: 5.175, Average Loss: 4.453, avg. samples / sec: 66304.59
Iteration:   1840, Loss function: 4.320, Average Loss: 4.499, avg. samples / sec: 66207.15
Iteration:   1840, Loss function: 4.929, Average Loss: 4.470, avg. samples / sec: 66385.08
Iteration:   1840, Loss function: 3.597, Average Loss: 4.485, avg. samples / sec: 66404.38
Iteration:   1840, Loss function: 5.093, Average Loss: 4.469, avg. samples / sec: 66268.33
Iteration:   1840, Loss function: 4.317, Average Loss: 4.466, avg. samples / sec: 66331.40
Iteration:   1840, Loss function: 4.914, Average Loss: 4.477, avg. samples / sec: 66273.75
Iteration:   1840, Loss function: 3.371, Average Loss: 4.476, avg. samples / sec: 66354.70
Iteration:   1840, Loss function: 4.640, Average Loss: 4.468, avg. samples / sec: 66296.95
Iteration:   1840, Loss function: 4.437, Average Loss: 4.478, avg. samples / sec: 66252.97
Iteration:   1840, Loss function: 3.827, Average Loss: 4.466, avg. samples / sec: 66319.29
Iteration:   1840, Loss function: 5.325, Average Loss: 4.445, avg. samples / sec: 66224.98
Iteration:   1840, Loss function: 5.171, Average Loss: 4.488, avg. samples / sec: 66184.92
Iteration:   1840, Loss function: 4.578, Average Loss: 4.472, avg. samples / sec: 66343.70
Iteration:   1840, Loss function: 6.277, Average Loss: 4.472, avg. samples / sec: 66311.17
Iteration:   1840, Loss function: 4.459, Average Loss: 4.458, avg. samples / sec: 66248.89
Iteration:   1840, Loss function: 4.549, Average Loss: 4.470, avg. samples / sec: 66190.42
Iteration:   1840, Loss function: 5.872, Average Loss: 4.471, avg. samples / sec: 66257.95
Iteration:   1840, Loss function: 4.665, Average Loss: 4.475, avg. samples / sec: 66189.24
Iteration:   1840, Loss function: 4.044, Average Loss: 4.476, avg. samples / sec: 66193.22
Iteration:   1840, Loss function: 4.232, Average Loss: 4.483, avg. samples / sec: 66152.83
Iteration:   1860, Loss function: 3.864, Average Loss: 4.441, avg. samples / sec: 66618.83
Iteration:   1860, Loss function: 4.087, Average Loss: 4.455, avg. samples / sec: 66620.63
Iteration:   1860, Loss function: 4.047, Average Loss: 4.475, avg. samples / sec: 66818.74
Iteration:   1860, Loss function: 4.587, Average Loss: 4.467, avg. samples / sec: 66531.40
Iteration:   1860, Loss function: 4.488, Average Loss: 4.483, avg. samples / sec: 66526.06
Iteration:   1860, Loss function: 4.373, Average Loss: 4.497, avg. samples / sec: 66594.03
Iteration:   1860, Loss function: 3.750, Average Loss: 4.482, avg. samples / sec: 66598.12
Iteration:   1860, Loss function: 3.468, Average Loss: 4.482, avg. samples / sec: 66796.92
Iteration:   1860, Loss function: 3.397, Average Loss: 4.480, avg. samples / sec: 66535.55
Iteration:   1860, Loss function: 4.731, Average Loss: 4.477, avg. samples / sec: 66630.05
Iteration:   1860, Loss function: 4.193, Average Loss: 4.486, avg. samples / sec: 66671.85
Iteration:   1860, Loss function: 4.679, Average Loss: 4.445, avg. samples / sec: 66473.13
Iteration:   1860, Loss function: 4.543, Average Loss: 4.477, avg. samples / sec: 66555.31
Iteration:   1860, Loss function: 5.676, Average Loss: 4.465, avg. samples / sec: 66645.96
Iteration:   1860, Loss function: 4.235, Average Loss: 4.475, avg. samples / sec: 66619.40
Iteration:   1860, Loss function: 3.773, Average Loss: 4.495, avg. samples / sec: 66509.20
Iteration:   1860, Loss function: 3.811, Average Loss: 4.443, avg. samples / sec: 66605.08
Iteration:   1860, Loss function: 4.087, Average Loss: 4.464, avg. samples / sec: 66636.54
Iteration:   1860, Loss function: 5.525, Average Loss: 4.465, avg. samples / sec: 66585.63
Iteration:   1860, Loss function: 4.393, Average Loss: 4.471, avg. samples / sec: 66472.72
Iteration:   1860, Loss function: 3.198, Average Loss: 4.486, avg. samples / sec: 66471.97
Iteration:   1860, Loss function: 5.348, Average Loss: 4.464, avg. samples / sec: 66614.87
Iteration:   1860, Loss function: 3.509, Average Loss: 4.465, avg. samples / sec: 66574.74
Iteration:   1860, Loss function: 5.746, Average Loss: 4.464, avg. samples / sec: 66500.04
Iteration:   1860, Loss function: 4.616, Average Loss: 4.464, avg. samples / sec: 66524.78
Iteration:   1860, Loss function: 4.268, Average Loss: 4.471, avg. samples / sec: 66562.14
Iteration:   1860, Loss function: 2.665, Average Loss: 4.461, avg. samples / sec: 66536.96
Iteration:   1860, Loss function: 4.497, Average Loss: 4.451, avg. samples / sec: 66595.29
Iteration:   1860, Loss function: 5.228, Average Loss: 4.472, avg. samples / sec: 66661.15
Iteration:   1860, Loss function: 3.372, Average Loss: 4.465, avg. samples / sec: 66623.56
Iteration:   1880, Loss function: 3.442, Average Loss: 4.438, avg. samples / sec: 66714.27
Iteration:   1880, Loss function: 5.210, Average Loss: 4.466, avg. samples / sec: 66751.17
Iteration:   1880, Loss function: 4.326, Average Loss: 4.482, avg. samples / sec: 66770.81
Iteration:   1880, Loss function: 3.271, Average Loss: 4.484, avg. samples / sec: 66762.78
Iteration:   1880, Loss function: 4.427, Average Loss: 4.446, avg. samples / sec: 66772.36
Iteration:   1880, Loss function: 4.408, Average Loss: 4.476, avg. samples / sec: 66755.35
Iteration:   1880, Loss function: 3.754, Average Loss: 4.470, avg. samples / sec: 66693.24
Iteration:   1880, Loss function: 3.722, Average Loss: 4.491, avg. samples / sec: 66710.48
Iteration:   1880, Loss function: 5.480, Average Loss: 4.497, avg. samples / sec: 66774.77
Iteration:   1880, Loss function: 3.331, Average Loss: 4.475, avg. samples / sec: 66764.11
Iteration:   1880, Loss function: 3.539, Average Loss: 4.463, avg. samples / sec: 66760.75
Iteration:   1880, Loss function: 5.273, Average Loss: 4.468, avg. samples / sec: 66786.60
Iteration:   1880, Loss function: 4.796, Average Loss: 4.480, avg. samples / sec: 66651.92
Iteration:   1880, Loss function: 4.860, Average Loss: 4.468, avg. samples / sec: 66750.10
Iteration:   1880, Loss function: 3.995, Average Loss: 4.479, avg. samples / sec: 66656.61
Iteration:   1880, Loss function: 3.947, Average Loss: 4.483, avg. samples / sec: 66645.08
Iteration:   1880, Loss function: 4.447, Average Loss: 4.463, avg. samples / sec: 66733.38
Iteration:   1880, Loss function: 4.070, Average Loss: 4.463, avg. samples / sec: 66713.19
Iteration:   1880, Loss function: 4.474, Average Loss: 4.463, avg. samples / sec: 66694.78
Iteration:   1880, Loss function: 3.986, Average Loss: 4.458, avg. samples / sec: 66578.55
Iteration:   1880, Loss function: 4.466, Average Loss: 4.457, avg. samples / sec: 66705.33
Iteration:   1880, Loss function: 4.182, Average Loss: 4.441, avg. samples / sec: 66653.34
Iteration:   1880, Loss function: 5.350, Average Loss: 4.463, avg. samples / sec: 66672.76
Iteration:   1880, Loss function: 4.562, Average Loss: 4.445, avg. samples / sec: 66690.52
Iteration:   1880, Loss function: 4.430, Average Loss: 4.468, avg. samples / sec: 66666.01
Iteration:   1880, Loss function: 4.626, Average Loss: 4.481, avg. samples / sec: 66542.08
Iteration:   1880, Loss function: 5.122, Average Loss: 4.472, avg. samples / sec: 66588.40
Iteration:   1880, Loss function: 5.005, Average Loss: 4.465, avg. samples / sec: 66609.26
Iteration:   1880, Loss function: 4.391, Average Loss: 4.461, avg. samples / sec: 66661.12
Iteration:   1880, Loss function: 5.773, Average Loss: 4.461, avg. samples / sec: 66501.52
:::MLL 1558651906.284 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558651906.285 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 2.967, Average Loss: 4.474, avg. samples / sec: 66242.41
Iteration:   1900, Loss function: 4.641, Average Loss: 4.486, avg. samples / sec: 66123.81
Iteration:   1900, Loss function: 3.441, Average Loss: 4.487, avg. samples / sec: 66164.57
Iteration:   1900, Loss function: 4.321, Average Loss: 4.469, avg. samples / sec: 66140.66
Iteration:   1900, Loss function: 5.315, Average Loss: 4.440, avg. samples / sec: 66112.70
Iteration:   1900, Loss function: 3.415, Average Loss: 4.461, avg. samples / sec: 66061.29
Iteration:   1900, Loss function: 3.261, Average Loss: 4.462, avg. samples / sec: 66184.27
Iteration:   1900, Loss function: 3.910, Average Loss: 4.464, avg. samples / sec: 66058.72
Iteration:   1900, Loss function: 4.298, Average Loss: 4.464, avg. samples / sec: 66196.11
Iteration:   1900, Loss function: 4.655, Average Loss: 4.439, avg. samples / sec: 65964.91
Iteration:   1900, Loss function: 4.162, Average Loss: 4.479, avg. samples / sec: 66012.21
Iteration:   1900, Loss function: 3.171, Average Loss: 4.474, avg. samples / sec: 66114.10
Iteration:   1900, Loss function: 4.781, Average Loss: 4.475, avg. samples / sec: 66236.47
Iteration:   1900, Loss function: 3.387, Average Loss: 4.468, avg. samples / sec: 66099.90
Iteration:   1900, Loss function: 3.945, Average Loss: 4.478, avg. samples / sec: 66106.78
Iteration:   1900, Loss function: 4.531, Average Loss: 4.465, avg. samples / sec: 66045.35
Iteration:   1900, Loss function: 3.443, Average Loss: 4.470, avg. samples / sec: 66046.00
Iteration:   1900, Loss function: 3.341, Average Loss: 4.458, avg. samples / sec: 66268.61
Iteration:   1900, Loss function: 4.841, Average Loss: 4.466, avg. samples / sec: 66160.47
Iteration:   1900, Loss function: 4.352, Average Loss: 4.460, avg. samples / sec: 66174.20
Iteration:   1900, Loss function: 4.014, Average Loss: 4.437, avg. samples / sec: 66114.22
Iteration:   1900, Loss function: 4.410, Average Loss: 4.460, avg. samples / sec: 66076.44
Iteration:   1900, Loss function: 4.200, Average Loss: 4.463, avg. samples / sec: 66141.56
Iteration:   1900, Loss function: 4.003, Average Loss: 4.455, avg. samples / sec: 66052.99
Iteration:   1900, Loss function: 5.152, Average Loss: 4.490, avg. samples / sec: 65920.35
Iteration:   1900, Loss function: 3.913, Average Loss: 4.457, avg. samples / sec: 66024.58
Iteration:   1900, Loss function: 4.342, Average Loss: 4.436, avg. samples / sec: 66042.03
Iteration:   1900, Loss function: 4.825, Average Loss: 4.463, avg. samples / sec: 66068.69
Iteration:   1900, Loss function: 4.014, Average Loss: 4.462, avg. samples / sec: 65947.77
Iteration:   1900, Loss function: 6.648, Average Loss: 4.461, avg. samples / sec: 65903.30
Iteration:   1920, Loss function: 4.526, Average Loss: 4.471, avg. samples / sec: 66596.11
Iteration:   1920, Loss function: 4.279, Average Loss: 4.437, avg. samples / sec: 66419.43
Iteration:   1920, Loss function: 5.331, Average Loss: 4.460, avg. samples / sec: 66456.48
Iteration:   1920, Loss function: 3.338, Average Loss: 4.452, avg. samples / sec: 66435.68
Iteration:   1920, Loss function: 5.261, Average Loss: 4.475, avg. samples / sec: 66483.32
Iteration:   1920, Loss function: 5.479, Average Loss: 4.459, avg. samples / sec: 66518.90
Iteration:   1920, Loss function: 4.379, Average Loss: 4.438, avg. samples / sec: 66481.44
Iteration:   1920, Loss function: 4.706, Average Loss: 4.488, avg. samples / sec: 66579.21
Iteration:   1920, Loss function: 4.238, Average Loss: 4.484, avg. samples / sec: 66356.45
Iteration:   1920, Loss function: 4.143, Average Loss: 4.484, avg. samples / sec: 66320.38
Iteration:   1920, Loss function: 5.158, Average Loss: 4.450, avg. samples / sec: 66552.52
Iteration:   1920, Loss function: 4.377, Average Loss: 4.460, avg. samples / sec: 66677.24
Iteration:   1920, Loss function: 3.777, Average Loss: 4.452, avg. samples / sec: 66463.28
Iteration:   1920, Loss function: 5.269, Average Loss: 4.472, avg. samples / sec: 66298.76
Iteration:   1920, Loss function: 4.107, Average Loss: 4.463, avg. samples / sec: 66461.22
Iteration:   1920, Loss function: 4.543, Average Loss: 4.472, avg. samples / sec: 66256.55
Iteration:   1920, Loss function: 5.024, Average Loss: 4.469, avg. samples / sec: 66391.58
Iteration:   1920, Loss function: 4.068, Average Loss: 4.460, avg. samples / sec: 66536.77
Iteration:   1920, Loss function: 4.184, Average Loss: 4.460, avg. samples / sec: 66373.88
Iteration:   1920, Loss function: 4.446, Average Loss: 4.476, avg. samples / sec: 66386.83
Iteration:   1920, Loss function: 3.963, Average Loss: 4.437, avg. samples / sec: 66498.00
Iteration:   1920, Loss function: 6.083, Average Loss: 4.458, avg. samples / sec: 66467.92
Iteration:   1920, Loss function: 3.344, Average Loss: 4.452, avg. samples / sec: 66329.24
Iteration:   1920, Loss function: 5.242, Average Loss: 4.462, avg. samples / sec: 66430.98
Iteration:   1920, Loss function: 3.327, Average Loss: 4.467, avg. samples / sec: 66332.99
Iteration:   1920, Loss function: 4.826, Average Loss: 4.431, avg. samples / sec: 66409.98
Iteration:   1920, Loss function: 3.928, Average Loss: 4.456, avg. samples / sec: 66473.63
Iteration:   1920, Loss function: 3.098, Average Loss: 4.470, avg. samples / sec: 66291.27
Iteration:   1920, Loss function: 5.770, Average Loss: 4.459, avg. samples / sec: 66353.85
Iteration:   1920, Loss function: 3.005, Average Loss: 4.455, avg. samples / sec: 66273.88
Iteration:   1940, Loss function: 4.000, Average Loss: 4.468, avg. samples / sec: 66880.99
Iteration:   1940, Loss function: 3.765, Average Loss: 4.445, avg. samples / sec: 66758.92
Iteration:   1940, Loss function: 5.084, Average Loss: 4.471, avg. samples / sec: 66864.81
Iteration:   1940, Loss function: 4.273, Average Loss: 4.489, avg. samples / sec: 66716.00
Iteration:   1940, Loss function: 5.212, Average Loss: 4.437, avg. samples / sec: 66672.54
Iteration:   1940, Loss function: 4.367, Average Loss: 4.458, avg. samples / sec: 66691.34
Iteration:   1940, Loss function: 5.559, Average Loss: 4.458, avg. samples / sec: 66636.95
Iteration:   1940, Loss function: 4.715, Average Loss: 4.473, avg. samples / sec: 66742.95
Iteration:   1940, Loss function: 3.981, Average Loss: 4.437, avg. samples / sec: 66739.22
Iteration:   1940, Loss function: 4.908, Average Loss: 4.473, avg. samples / sec: 66693.17
Iteration:   1940, Loss function: 5.107, Average Loss: 4.447, avg. samples / sec: 66668.34
Iteration:   1940, Loss function: 4.118, Average Loss: 4.476, avg. samples / sec: 66593.65
Iteration:   1940, Loss function: 4.528, Average Loss: 4.459, avg. samples / sec: 66734.80
Iteration:   1940, Loss function: 5.863, Average Loss: 4.485, avg. samples / sec: 66602.02
Iteration:   1940, Loss function: 3.449, Average Loss: 4.459, avg. samples / sec: 66702.93
Iteration:   1940, Loss function: 4.577, Average Loss: 4.469, avg. samples / sec: 66660.78
Iteration:   1940, Loss function: 4.373, Average Loss: 4.453, avg. samples / sec: 66548.53
Iteration:   1940, Loss function: 3.565, Average Loss: 4.458, avg. samples / sec: 66554.65
Iteration:   1940, Loss function: 4.342, Average Loss: 4.465, avg. samples / sec: 66615.97
Iteration:   1940, Loss function: 4.691, Average Loss: 4.463, avg. samples / sec: 66748.30
Iteration:   1940, Loss function: 4.209, Average Loss: 4.468, avg. samples / sec: 66480.25
Iteration:   1940, Loss function: 3.539, Average Loss: 4.459, avg. samples / sec: 66631.53
Iteration:   1940, Loss function: 4.772, Average Loss: 4.467, avg. samples / sec: 66712.43
Iteration:   1940, Loss function: 4.527, Average Loss: 4.456, avg. samples / sec: 66810.73
Iteration:   1940, Loss function: 3.252, Average Loss: 4.477, avg. samples / sec: 66525.50
Iteration:   1940, Loss function: 5.209, Average Loss: 4.451, avg. samples / sec: 66599.69
Iteration:   1940, Loss function: 4.411, Average Loss: 4.438, avg. samples / sec: 66439.69
Iteration:   1940, Loss function: 3.779, Average Loss: 4.455, avg. samples / sec: 66536.65
Iteration:   1940, Loss function: 4.425, Average Loss: 4.430, avg. samples / sec: 66564.59
Iteration:   1940, Loss function: 3.281, Average Loss: 4.455, avg. samples / sec: 66543.78
:::MLL 1558651908.055 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558651908.055 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.789, Average Loss: 4.472, avg. samples / sec: 66641.74
Iteration:   1960, Loss function: 3.963, Average Loss: 4.432, avg. samples / sec: 66471.62
Iteration:   1960, Loss function: 3.400, Average Loss: 4.432, avg. samples / sec: 66416.08
Iteration:   1960, Loss function: 4.253, Average Loss: 4.464, avg. samples / sec: 66245.59
Iteration:   1960, Loss function: 4.659, Average Loss: 4.451, avg. samples / sec: 66602.65
Iteration:   1960, Loss function: 4.895, Average Loss: 4.487, avg. samples / sec: 66363.63
Iteration:   1960, Loss function: 4.636, Average Loss: 4.470, avg. samples / sec: 66439.25
Iteration:   1960, Loss function: 4.691, Average Loss: 4.457, avg. samples / sec: 66361.98
Iteration:   1960, Loss function: 4.873, Average Loss: 4.437, avg. samples / sec: 66539.29
Iteration:   1960, Loss function: 4.519, Average Loss: 4.449, avg. samples / sec: 66456.61
Iteration:   1960, Loss function: 3.552, Average Loss: 4.449, avg. samples / sec: 66367.29
Iteration:   1960, Loss function: 4.076, Average Loss: 4.455, avg. samples / sec: 66426.32
Iteration:   1960, Loss function: 3.952, Average Loss: 4.468, avg. samples / sec: 66384.98
Iteration:   1960, Loss function: 5.047, Average Loss: 4.471, avg. samples / sec: 66393.49
Iteration:   1960, Loss function: 3.733, Average Loss: 4.460, avg. samples / sec: 66446.89
Iteration:   1960, Loss function: 5.521, Average Loss: 4.482, avg. samples / sec: 66377.67
Iteration:   1960, Loss function: 4.516, Average Loss: 4.454, avg. samples / sec: 66416.58
Iteration:   1960, Loss function: 5.493, Average Loss: 4.446, avg. samples / sec: 66334.24
Iteration:   1960, Loss function: 4.697, Average Loss: 4.455, avg. samples / sec: 66446.24
Iteration:   1960, Loss function: 4.692, Average Loss: 4.470, avg. samples / sec: 66223.83
Iteration:   1960, Loss function: 3.704, Average Loss: 4.453, avg. samples / sec: 66361.63
Iteration:   1960, Loss function: 3.774, Average Loss: 4.448, avg. samples / sec: 66409.57
Iteration:   1960, Loss function: 4.467, Average Loss: 4.441, avg. samples / sec: 66163.45
Iteration:   1960, Loss function: 4.865, Average Loss: 4.451, avg. samples / sec: 66478.02
Iteration:   1960, Loss function: 4.084, Average Loss: 4.471, avg. samples / sec: 66280.39
Iteration:   1960, Loss function: 5.071, Average Loss: 4.458, avg. samples / sec: 66322.38
Iteration:   1960, Loss function: 4.244, Average Loss: 4.466, avg. samples / sec: 66214.53
Iteration:   1960, Loss function: 5.048, Average Loss: 4.428, avg. samples / sec: 66435.71
Iteration:   1960, Loss function: 4.544, Average Loss: 4.459, avg. samples / sec: 66223.92
Iteration:   1960, Loss function: 4.393, Average Loss: 4.452, avg. samples / sec: 65999.94
Iteration:   1980, Loss function: 4.642, Average Loss: 4.431, avg. samples / sec: 66353.63
Iteration:   1980, Loss function: 4.795, Average Loss: 4.465, avg. samples / sec: 66306.09
Iteration:   1980, Loss function: 4.712, Average Loss: 4.464, avg. samples / sec: 66224.20
Iteration:   1980, Loss function: 4.636, Average Loss: 4.465, avg. samples / sec: 66236.65
Iteration:   1980, Loss function: 3.633, Average Loss: 4.468, avg. samples / sec: 66294.67
Iteration:   1980, Loss function: 4.486, Average Loss: 4.429, avg. samples / sec: 66118.94
Iteration:   1980, Loss function: 5.087, Average Loss: 4.436, avg. samples / sec: 66322.25
Iteration:   1980, Loss function: 3.960, Average Loss: 4.477, avg. samples / sec: 66230.55
Iteration:   1980, Loss function: 3.462, Average Loss: 4.431, avg. samples / sec: 66335.46
Iteration:   1980, Loss function: 4.272, Average Loss: 4.446, avg. samples / sec: 66238.40
Iteration:   1980, Loss function: 3.768, Average Loss: 4.447, avg. samples / sec: 66269.48
Iteration:   1980, Loss function: 4.641, Average Loss: 4.457, avg. samples / sec: 66150.16
Iteration:   1980, Loss function: 4.489, Average Loss: 4.468, avg. samples / sec: 66331.27
Iteration:   1980, Loss function: 3.815, Average Loss: 4.444, avg. samples / sec: 66143.89
Iteration:   1980, Loss function: 5.615, Average Loss: 4.468, avg. samples / sec: 66201.49
Iteration:   1980, Loss function: 5.238, Average Loss: 4.447, avg. samples / sec: 66116.18
Iteration:   1980, Loss function: 4.265, Average Loss: 4.469, avg. samples / sec: 66019.26
Iteration:   1980, Loss function: 4.065, Average Loss: 4.454, avg. samples / sec: 66134.58
Iteration:   1980, Loss function: 3.950, Average Loss: 4.453, avg. samples / sec: 66289.81
Iteration:   1980, Loss function: 3.619, Average Loss: 4.464, avg. samples / sec: 66290.40
Iteration:   1980, Loss function: 4.242, Average Loss: 4.450, avg. samples / sec: 66167.12
Iteration:   1980, Loss function: 3.685, Average Loss: 4.442, avg. samples / sec: 66183.55
Iteration:   1980, Loss function: 3.302, Average Loss: 4.480, avg. samples / sec: 66068.23
Iteration:   1980, Loss function: 5.624, Average Loss: 4.450, avg. samples / sec: 66237.00
Iteration:   1980, Loss function: 3.718, Average Loss: 4.445, avg. samples / sec: 66515.92
Iteration:   1980, Loss function: 4.344, Average Loss: 4.444, avg. samples / sec: 66211.10
Iteration:   1980, Loss function: 4.044, Average Loss: 4.428, avg. samples / sec: 65989.40
Iteration:   1980, Loss function: 2.686, Average Loss: 4.458, avg. samples / sec: 66262.63
Iteration:   1980, Loss function: 3.472, Average Loss: 4.446, avg. samples / sec: 65983.53
Iteration:   1980, Loss function: 4.243, Average Loss: 4.456, avg. samples / sec: 66036.25
Iteration:   2000, Loss function: 4.593, Average Loss: 4.460, avg. samples / sec: 66490.69
Iteration:   2000, Loss function: 3.532, Average Loss: 4.429, avg. samples / sec: 66578.20
Iteration:   2000, Loss function: 3.088, Average Loss: 4.443, avg. samples / sec: 66613.51
Iteration:   2000, Loss function: 3.697, Average Loss: 4.420, avg. samples / sec: 66537.47
Iteration:   2000, Loss function: 4.565, Average Loss: 4.458, avg. samples / sec: 66463.32
Iteration:   2000, Loss function: 4.295, Average Loss: 4.475, avg. samples / sec: 66614.11
Iteration:   2000, Loss function: 3.983, Average Loss: 4.441, avg. samples / sec: 66581.22
Iteration:   2000, Loss function: 2.781, Average Loss: 4.457, avg. samples / sec: 66410.35
Iteration:   2000, Loss function: 4.368, Average Loss: 4.423, avg. samples / sec: 66344.79
Iteration:   2000, Loss function: 4.289, Average Loss: 4.474, avg. samples / sec: 66483.60
Iteration:   2000, Loss function: 5.589, Average Loss: 4.435, avg. samples / sec: 66476.83
Iteration:   2000, Loss function: 3.826, Average Loss: 4.425, avg. samples / sec: 66590.79
Iteration:   2000, Loss function: 4.487, Average Loss: 4.442, avg. samples / sec: 66538.16
Iteration:   2000, Loss function: 5.140, Average Loss: 4.447, avg. samples / sec: 66630.36
Iteration:   2000, Loss function: 3.485, Average Loss: 4.453, avg. samples / sec: 66486.52
Iteration:   2000, Loss function: 4.373, Average Loss: 4.452, avg. samples / sec: 66508.73
Iteration:   2000, Loss function: 6.253, Average Loss: 4.450, avg. samples / sec: 66482.50
Iteration:   2000, Loss function: 3.720, Average Loss: 4.464, avg. samples / sec: 66438.53
Iteration:   2000, Loss function: 3.890, Average Loss: 4.438, avg. samples / sec: 66589.62
Iteration:   2000, Loss function: 4.019, Average Loss: 4.463, avg. samples / sec: 66476.33
Iteration:   2000, Loss function: 3.875, Average Loss: 4.449, avg. samples / sec: 66525.50
Iteration:   2000, Loss function: 3.939, Average Loss: 4.445, avg. samples / sec: 66445.05
Iteration:   2000, Loss function: 3.753, Average Loss: 4.431, avg. samples / sec: 66485.70
Iteration:   2000, Loss function: 4.758, Average Loss: 4.457, avg. samples / sec: 66439.85
Iteration:   2000, Loss function: 5.203, Average Loss: 4.439, avg. samples / sec: 66516.55
Iteration:   2000, Loss function: 4.312, Average Loss: 4.457, avg. samples / sec: 66473.57
Iteration:   2000, Loss function: 4.555, Average Loss: 4.437, avg. samples / sec: 66430.54
Iteration:   2000, Loss function: 4.098, Average Loss: 4.460, avg. samples / sec: 66517.40
Iteration:   2000, Loss function: 4.846, Average Loss: 4.442, avg. samples / sec: 66430.20
Iteration:   2000, Loss function: 4.855, Average Loss: 4.462, avg. samples / sec: 66286.41
Iteration:   2020, Loss function: 5.662, Average Loss: 4.421, avg. samples / sec: 66620.47
Iteration:   2020, Loss function: 5.878, Average Loss: 4.456, avg. samples / sec: 66588.49
Iteration:   2020, Loss function: 6.131, Average Loss: 4.451, avg. samples / sec: 66651.70
Iteration:   2020, Loss function: 5.027, Average Loss: 4.421, avg. samples / sec: 66590.91
Iteration:   2020, Loss function: 4.383, Average Loss: 4.461, avg. samples / sec: 66659.55
Iteration:   2020, Loss function: 5.110, Average Loss: 4.421, avg. samples / sec: 66590.54
Iteration:   2020, Loss function: 4.085, Average Loss: 4.438, avg. samples / sec: 66633.64
Iteration:   2020, Loss function: 3.932, Average Loss: 4.433, avg. samples / sec: 66492.51
Iteration:   2020, Loss function: 4.607, Average Loss: 4.467, avg. samples / sec: 66526.41
Iteration:   2020, Loss function: 3.934, Average Loss: 4.455, avg. samples / sec: 66509.11
Iteration:   2020, Loss function: 4.270, Average Loss: 4.454, avg. samples / sec: 66427.85
Iteration:   2020, Loss function: 3.778, Average Loss: 4.457, avg. samples / sec: 66591.45
Iteration:   2020, Loss function: 3.811, Average Loss: 4.437, avg. samples / sec: 66579.30
Iteration:   2020, Loss function: 3.757, Average Loss: 4.447, avg. samples / sec: 66536.74
Iteration:   2020, Loss function: 4.428, Average Loss: 4.442, avg. samples / sec: 66652.14
Iteration:   2020, Loss function: 4.825, Average Loss: 4.428, avg. samples / sec: 66428.57
Iteration:   2020, Loss function: 4.722, Average Loss: 4.457, avg. samples / sec: 66603.72
Iteration:   2020, Loss function: 3.863, Average Loss: 4.439, avg. samples / sec: 66416.30
Iteration:   2020, Loss function: 4.793, Average Loss: 4.447, avg. samples / sec: 66495.27
Iteration:   2020, Loss function: 4.153, Average Loss: 4.431, avg. samples / sec: 66456.70
Iteration:   2020, Loss function: 3.474, Average Loss: 4.446, avg. samples / sec: 66495.80
Iteration:   2020, Loss function: 3.937, Average Loss: 4.476, avg. samples / sec: 66386.61
Iteration:   2020, Loss function: 5.213, Average Loss: 4.428, avg. samples / sec: 66509.46
Iteration:   2020, Loss function: 4.155, Average Loss: 4.441, avg. samples / sec: 66467.42
Iteration:   2020, Loss function: 5.176, Average Loss: 4.454, avg. samples / sec: 66487.68
Iteration:   2020, Loss function: 4.989, Average Loss: 4.462, avg. samples / sec: 66558.46
Iteration:   2020, Loss function: 3.201, Average Loss: 4.452, avg. samples / sec: 66466.32
Iteration:   2020, Loss function: 4.129, Average Loss: 4.435, avg. samples / sec: 66409.01
Iteration:   2020, Loss function: 3.485, Average Loss: 4.450, avg. samples / sec: 66456.61
Iteration:   2020, Loss function: 3.078, Average Loss: 4.435, avg. samples / sec: 66401.28
:::MLL 1558651909.828 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558651909.828 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 3.834, Average Loss: 4.420, avg. samples / sec: 66058.22
Iteration:   2040, Loss function: 4.644, Average Loss: 4.453, avg. samples / sec: 66153.98
Iteration:   2040, Loss function: 4.099, Average Loss: 4.453, avg. samples / sec: 66078.14
Iteration:   2040, Loss function: 4.509, Average Loss: 4.419, avg. samples / sec: 65972.19
Iteration:   2040, Loss function: 5.017, Average Loss: 4.471, avg. samples / sec: 66126.10
Iteration:   2040, Loss function: 4.017, Average Loss: 4.446, avg. samples / sec: 66184.39
Iteration:   2040, Loss function: 5.059, Average Loss: 4.439, avg. samples / sec: 66054.01
Iteration:   2040, Loss function: 4.764, Average Loss: 4.449, avg. samples / sec: 65908.70
Iteration:   2040, Loss function: 5.235, Average Loss: 4.451, avg. samples / sec: 66019.48
Iteration:   2040, Loss function: 4.058, Average Loss: 4.434, avg. samples / sec: 66014.16
Iteration:   2040, Loss function: 4.674, Average Loss: 4.440, avg. samples / sec: 66078.08
Iteration:   2040, Loss function: 5.085, Average Loss: 4.446, avg. samples / sec: 66137.52
Iteration:   2040, Loss function: 5.226, Average Loss: 4.438, avg. samples / sec: 66033.49
Iteration:   2040, Loss function: 4.212, Average Loss: 4.433, avg. samples / sec: 66056.64
Iteration:   2040, Loss function: 3.952, Average Loss: 4.452, avg. samples / sec: 65962.10
Iteration:   2040, Loss function: 3.459, Average Loss: 4.417, avg. samples / sec: 65909.31
Iteration:   2040, Loss function: 3.915, Average Loss: 4.442, avg. samples / sec: 65855.94
Iteration:   2040, Loss function: 4.063, Average Loss: 4.456, avg. samples / sec: 66083.16
Iteration:   2040, Loss function: 4.987, Average Loss: 4.426, avg. samples / sec: 66031.14
Iteration:   2040, Loss function: 4.862, Average Loss: 4.425, avg. samples / sec: 65941.63
Iteration:   2040, Loss function: 3.955, Average Loss: 4.433, avg. samples / sec: 65915.20
Iteration:   2040, Loss function: 3.298, Average Loss: 4.434, avg. samples / sec: 65944.72
Iteration:   2040, Loss function: 4.361, Average Loss: 4.424, avg. samples / sec: 66003.15
Iteration:   2040, Loss function: 5.342, Average Loss: 4.440, avg. samples / sec: 65996.69
Iteration:   2040, Loss function: 4.071, Average Loss: 4.432, avg. samples / sec: 66057.91
Iteration:   2040, Loss function: 5.052, Average Loss: 4.465, avg. samples / sec: 65908.30
Iteration:   2040, Loss function: 4.834, Average Loss: 4.436, avg. samples / sec: 65930.62
Iteration:   2040, Loss function: 4.545, Average Loss: 4.430, avg. samples / sec: 66073.43
Iteration:   2040, Loss function: 4.944, Average Loss: 4.447, avg. samples / sec: 65952.16
Iteration:   2040, Loss function: 3.762, Average Loss: 4.458, avg. samples / sec: 65767.30
Iteration:   2060, Loss function: 3.147, Average Loss: 4.446, avg. samples / sec: 66608.66
Iteration:   2060, Loss function: 3.917, Average Loss: 4.426, avg. samples / sec: 66611.50
Iteration:   2060, Loss function: 4.069, Average Loss: 4.468, avg. samples / sec: 66438.69
Iteration:   2060, Loss function: 4.117, Average Loss: 4.444, avg. samples / sec: 66647.63
Iteration:   2060, Loss function: 4.219, Average Loss: 4.414, avg. samples / sec: 66427.95
Iteration:   2060, Loss function: 3.394, Average Loss: 4.422, avg. samples / sec: 66541.80
Iteration:   2060, Loss function: 4.356, Average Loss: 4.431, avg. samples / sec: 66549.78
Iteration:   2060, Loss function: 4.340, Average Loss: 4.452, avg. samples / sec: 66640.48
Iteration:   2060, Loss function: 4.398, Average Loss: 4.418, avg. samples / sec: 66548.24
Iteration:   2060, Loss function: 3.581, Average Loss: 4.439, avg. samples / sec: 66489.34
Iteration:   2060, Loss function: 4.300, Average Loss: 4.446, avg. samples / sec: 66414.33
Iteration:   2060, Loss function: 3.220, Average Loss: 4.440, avg. samples / sec: 66507.73
Iteration:   2060, Loss function: 3.716, Average Loss: 4.447, avg. samples / sec: 66325.72
Iteration:   2060, Loss function: 4.046, Average Loss: 4.447, avg. samples / sec: 66450.97
Iteration:   2060, Loss function: 3.630, Average Loss: 4.451, avg. samples / sec: 66487.99
Iteration:   2060, Loss function: 4.729, Average Loss: 4.425, avg. samples / sec: 66481.50
Iteration:   2060, Loss function: 5.294, Average Loss: 4.435, avg. samples / sec: 66385.33
Iteration:   2060, Loss function: 5.346, Average Loss: 4.428, avg. samples / sec: 66379.73
Iteration:   2060, Loss function: 3.422, Average Loss: 4.420, avg. samples / sec: 66173.58
Iteration:   2060, Loss function: 4.614, Average Loss: 4.427, avg. samples / sec: 66475.29
Iteration:   2060, Loss function: 5.878, Average Loss: 4.448, avg. samples / sec: 66335.71
Iteration:   2060, Loss function: 3.678, Average Loss: 4.437, avg. samples / sec: 66451.16
Iteration:   2060, Loss function: 5.202, Average Loss: 4.419, avg. samples / sec: 66458.99
Iteration:   2060, Loss function: 4.616, Average Loss: 4.437, avg. samples / sec: 66313.64
Iteration:   2060, Loss function: 3.607, Average Loss: 4.414, avg. samples / sec: 66351.17
Iteration:   2060, Loss function: 3.678, Average Loss: 4.447, avg. samples / sec: 66316.88
Iteration:   2060, Loss function: 3.349, Average Loss: 4.438, avg. samples / sec: 66280.23
Iteration:   2060, Loss function: 3.493, Average Loss: 4.430, avg. samples / sec: 66363.48
Iteration:   2060, Loss function: 4.016, Average Loss: 4.461, avg. samples / sec: 66345.57
Iteration:   2060, Loss function: 3.848, Average Loss: 4.427, avg. samples / sec: 66298.01
Iteration:   2080, Loss function: 3.281, Average Loss: 4.413, avg. samples / sec: 66672.63
Iteration:   2080, Loss function: 4.154, Average Loss: 4.404, avg. samples / sec: 66584.56
Iteration:   2080, Loss function: 4.023, Average Loss: 4.409, avg. samples / sec: 66727.94
Iteration:   2080, Loss function: 3.599, Average Loss: 4.446, avg. samples / sec: 66549.34
Iteration:   2080, Loss function: 4.194, Average Loss: 4.438, avg. samples / sec: 66362.04
Iteration:   2080, Loss function: 4.474, Average Loss: 4.463, avg. samples / sec: 66506.98
Iteration:   2080, Loss function: 3.631, Average Loss: 4.427, avg. samples / sec: 66678.47
Iteration:   2080, Loss function: 3.882, Average Loss: 4.444, avg. samples / sec: 66607.15
Iteration:   2080, Loss function: 5.204, Average Loss: 4.422, avg. samples / sec: 66477.77
Iteration:   2080, Loss function: 4.570, Average Loss: 4.437, avg. samples / sec: 66608.35
Iteration:   2080, Loss function: 5.659, Average Loss: 4.448, avg. samples / sec: 66531.18
Iteration:   2080, Loss function: 3.297, Average Loss: 4.422, avg. samples / sec: 66541.30
Iteration:   2080, Loss function: 5.084, Average Loss: 4.428, avg. samples / sec: 66437.94
Iteration:   2080, Loss function: 3.625, Average Loss: 4.435, avg. samples / sec: 66482.38
Iteration:   2080, Loss function: 4.512, Average Loss: 4.422, avg. samples / sec: 66492.38
Iteration:   2080, Loss function: 3.219, Average Loss: 4.435, avg. samples / sec: 66442.29
Iteration:   2080, Loss function: 5.491, Average Loss: 4.426, avg. samples / sec: 66637.99
Iteration:   2080, Loss function: 4.048, Average Loss: 4.439, avg. samples / sec: 66377.92
Iteration:   2080, Loss function: 3.640, Average Loss: 4.445, avg. samples / sec: 66560.88
Iteration:   2080, Loss function: 3.847, Average Loss: 4.449, avg. samples / sec: 66447.27
Iteration:   2080, Loss function: 4.874, Average Loss: 4.427, avg. samples / sec: 66601.55
Iteration:   2080, Loss function: 4.545, Average Loss: 4.447, avg. samples / sec: 66397.53
Iteration:   2080, Loss function: 4.351, Average Loss: 4.410, avg. samples / sec: 66503.93
Iteration:   2080, Loss function: 3.659, Average Loss: 4.423, avg. samples / sec: 66460.12
Iteration:   2080, Loss function: 3.843, Average Loss: 4.432, avg. samples / sec: 66450.53
Iteration:   2080, Loss function: 4.365, Average Loss: 4.437, avg. samples / sec: 66369.41
Iteration:   2080, Loss function: 4.358, Average Loss: 4.431, avg. samples / sec: 66490.94
Iteration:   2080, Loss function: 3.821, Average Loss: 4.413, avg. samples / sec: 66359.60
Iteration:   2080, Loss function: 3.969, Average Loss: 4.458, avg. samples / sec: 66496.24
Iteration:   2080, Loss function: 4.061, Average Loss: 4.421, avg. samples / sec: 66241.51
:::MLL 1558651911.602 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558651911.602 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 3.855, Average Loss: 4.414, avg. samples / sec: 66226.57
Iteration:   2100, Loss function: 3.676, Average Loss: 4.438, avg. samples / sec: 66207.65
Iteration:   2100, Loss function: 3.967, Average Loss: 4.433, avg. samples / sec: 66120.67
Iteration:   2100, Loss function: 3.493, Average Loss: 4.432, avg. samples / sec: 66120.80
Iteration:   2100, Loss function: 4.179, Average Loss: 4.433, avg. samples / sec: 66231.70
Iteration:   2100, Loss function: 3.259, Average Loss: 4.403, avg. samples / sec: 66033.52
Iteration:   2100, Loss function: 4.156, Average Loss: 4.423, avg. samples / sec: 66254.62
Iteration:   2100, Loss function: 4.372, Average Loss: 4.407, avg. samples / sec: 66037.52
Iteration:   2100, Loss function: 4.007, Average Loss: 4.437, avg. samples / sec: 66214.81
Iteration:   2100, Loss function: 3.960, Average Loss: 4.429, avg. samples / sec: 66168.17
Iteration:   2100, Loss function: 4.781, Average Loss: 4.406, avg. samples / sec: 66030.74
Iteration:   2100, Loss function: 4.934, Average Loss: 4.414, avg. samples / sec: 66194.37
Iteration:   2100, Loss function: 4.133, Average Loss: 4.440, avg. samples / sec: 66078.48
Iteration:   2100, Loss function: 4.739, Average Loss: 4.436, avg. samples / sec: 66132.56
Iteration:   2100, Loss function: 3.701, Average Loss: 4.429, avg. samples / sec: 66145.69
Iteration:   2100, Loss function: 3.347, Average Loss: 4.404, avg. samples / sec: 66116.33
Iteration:   2100, Loss function: 4.208, Average Loss: 4.420, avg. samples / sec: 66079.41
Iteration:   2100, Loss function: 2.799, Average Loss: 4.418, avg. samples / sec: 66034.30
Iteration:   2100, Loss function: 3.824, Average Loss: 4.431, avg. samples / sec: 65979.17
Iteration:   2100, Loss function: 4.622, Average Loss: 4.415, avg. samples / sec: 66206.97
Iteration:   2100, Loss function: 4.648, Average Loss: 4.413, avg. samples / sec: 66100.52
Iteration:   2100, Loss function: 2.761, Average Loss: 4.438, avg. samples / sec: 66038.69
Iteration:   2100, Loss function: 4.594, Average Loss: 4.426, avg. samples / sec: 66066.24
Iteration:   2100, Loss function: 4.053, Average Loss: 4.425, avg. samples / sec: 65996.23
Iteration:   2100, Loss function: 3.865, Average Loss: 4.455, avg. samples / sec: 65908.88
Iteration:   2100, Loss function: 3.227, Average Loss: 4.421, avg. samples / sec: 66001.86
Iteration:   2100, Loss function: 4.030, Average Loss: 4.425, avg. samples / sec: 66040.02
Iteration:   2100, Loss function: 3.952, Average Loss: 4.455, avg. samples / sec: 66133.40
Iteration:   2100, Loss function: 3.639, Average Loss: 4.415, avg. samples / sec: 65939.29
Iteration:   2100, Loss function: 4.814, Average Loss: 4.429, avg. samples / sec: 65861.94
Iteration:   2120, Loss function: 3.631, Average Loss: 4.399, avg. samples / sec: 66159.51
Iteration:   2120, Loss function: 4.076, Average Loss: 4.431, avg. samples / sec: 66108.05
Iteration:   2120, Loss function: 3.993, Average Loss: 4.400, avg. samples / sec: 66078.29
Iteration:   2120, Loss function: 4.716, Average Loss: 4.429, avg. samples / sec: 66141.28
Iteration:   2120, Loss function: 4.508, Average Loss: 4.410, avg. samples / sec: 66207.78
Iteration:   2120, Loss function: 4.391, Average Loss: 4.421, avg. samples / sec: 66195.96
Iteration:   2120, Loss function: 5.719, Average Loss: 4.433, avg. samples / sec: 66170.94
Iteration:   2120, Loss function: 5.118, Average Loss: 4.412, avg. samples / sec: 66234.01
Iteration:   2120, Loss function: 4.251, Average Loss: 4.410, avg. samples / sec: 66063.86
Iteration:   2120, Loss function: 5.863, Average Loss: 4.416, avg. samples / sec: 66156.46
Iteration:   2120, Loss function: 3.163, Average Loss: 4.436, avg. samples / sec: 65946.42
Iteration:   2120, Loss function: 3.692, Average Loss: 4.422, avg. samples / sec: 66197.79
Iteration:   2120, Loss function: 3.388, Average Loss: 4.451, avg. samples / sec: 66204.57
Iteration:   2120, Loss function: 4.461, Average Loss: 4.399, avg. samples / sec: 66025.82
Iteration:   2120, Loss function: 4.217, Average Loss: 4.432, avg. samples / sec: 66172.86
Iteration:   2120, Loss function: 4.322, Average Loss: 4.432, avg. samples / sec: 66050.64
Iteration:   2120, Loss function: 5.036, Average Loss: 4.427, avg. samples / sec: 65931.95
Iteration:   2120, Loss function: 3.647, Average Loss: 4.427, avg. samples / sec: 65996.42
Iteration:   2120, Loss function: 5.411, Average Loss: 4.428, avg. samples / sec: 66226.79
Iteration:   2120, Loss function: 4.886, Average Loss: 4.417, avg. samples / sec: 66074.79
Iteration:   2120, Loss function: 4.209, Average Loss: 4.404, avg. samples / sec: 65859.85
Iteration:   2120, Loss function: 4.330, Average Loss: 4.409, avg. samples / sec: 66104.86
Iteration:   2120, Loss function: 4.112, Average Loss: 4.415, avg. samples / sec: 66143.39
Iteration:   2120, Loss function: 4.000, Average Loss: 4.426, avg. samples / sec: 66063.36
Iteration:   2120, Loss function: 2.729, Average Loss: 4.399, avg. samples / sec: 66029.90
Iteration:   2120, Loss function: 3.640, Average Loss: 4.427, avg. samples / sec: 65921.74
Iteration:   2120, Loss function: 3.834, Average Loss: 4.449, avg. samples / sec: 66131.94
Iteration:   2120, Loss function: 3.089, Average Loss: 4.421, avg. samples / sec: 66101.07
Iteration:   2120, Loss function: 4.549, Average Loss: 4.430, avg. samples / sec: 65917.88
Iteration:   2120, Loss function: 4.001, Average Loss: 4.419, avg. samples / sec: 65898.25
Iteration:   2140, Loss function: 5.314, Average Loss: 4.424, avg. samples / sec: 66611.06
Iteration:   2140, Loss function: 3.576, Average Loss: 4.430, avg. samples / sec: 66446.11
Iteration:   2140, Loss function: 3.877, Average Loss: 4.401, avg. samples / sec: 66494.74
Iteration:   2140, Loss function: 2.578, Average Loss: 4.441, avg. samples / sec: 66491.98
Iteration:   2140, Loss function: 4.879, Average Loss: 4.415, avg. samples / sec: 66485.55
Iteration:   2140, Loss function: 4.721, Average Loss: 4.419, avg. samples / sec: 66469.11
Iteration:   2140, Loss function: 3.929, Average Loss: 4.409, avg. samples / sec: 66434.77
Iteration:   2140, Loss function: 3.313, Average Loss: 4.408, avg. samples / sec: 66435.59
Iteration:   2140, Loss function: 3.381, Average Loss: 4.407, avg. samples / sec: 66546.45
Iteration:   2140, Loss function: 4.739, Average Loss: 4.424, avg. samples / sec: 66368.07
Iteration:   2140, Loss function: 3.685, Average Loss: 4.409, avg. samples / sec: 66385.95
Iteration:   2140, Loss function: 5.074, Average Loss: 4.424, avg. samples / sec: 66427.04
Iteration:   2140, Loss function: 4.468, Average Loss: 4.397, avg. samples / sec: 66419.96
Iteration:   2140, Loss function: 4.095, Average Loss: 4.399, avg. samples / sec: 66240.83
Iteration:   2140, Loss function: 5.572, Average Loss: 4.413, avg. samples / sec: 66451.56
Iteration:   2140, Loss function: 4.366, Average Loss: 4.429, avg. samples / sec: 66346.79
Iteration:   2140, Loss function: 3.957, Average Loss: 4.425, avg. samples / sec: 66393.46
Iteration:   2140, Loss function: 4.862, Average Loss: 4.428, avg. samples / sec: 66394.52
Iteration:   2140, Loss function: 4.528, Average Loss: 4.429, avg. samples / sec: 66336.14
Iteration:   2140, Loss function: 4.803, Average Loss: 4.429, avg. samples / sec: 66381.36
Iteration:   2140, Loss function: 4.075, Average Loss: 4.411, avg. samples / sec: 66400.53
Iteration:   2140, Loss function: 4.299, Average Loss: 4.426, avg. samples / sec: 66403.41
Iteration:   2140, Loss function: 4.419, Average Loss: 4.419, avg. samples / sec: 66427.98
Iteration:   2140, Loss function: 5.487, Average Loss: 4.422, avg. samples / sec: 66456.17
Iteration:   2140, Loss function: 5.317, Average Loss: 4.402, avg. samples / sec: 66358.98
Iteration:   2140, Loss function: 4.266, Average Loss: 4.418, avg. samples / sec: 66422.19
Iteration:   2140, Loss function: 4.950, Average Loss: 4.416, avg. samples / sec: 66291.05
Iteration:   2140, Loss function: 5.092, Average Loss: 4.397, avg. samples / sec: 66393.96
Iteration:   2140, Loss function: 4.349, Average Loss: 4.444, avg. samples / sec: 66381.32
Iteration:   2140, Loss function: 3.581, Average Loss: 4.403, avg. samples / sec: 66286.78
Iteration:   2160, Loss function: 4.717, Average Loss: 4.430, avg. samples / sec: 66599.06
Iteration:   2160, Loss function: 3.365, Average Loss: 4.420, avg. samples / sec: 66555.53
Iteration:   2160, Loss function: 4.066, Average Loss: 4.420, avg. samples / sec: 66797.02
Iteration:   2160, Loss function: 3.814, Average Loss: 4.398, avg. samples / sec: 66529.74
Iteration:   2160, Loss function: 4.050, Average Loss: 4.420, avg. samples / sec: 66729.36
Iteration:   2160, Loss function: 4.079, Average Loss: 4.427, avg. samples / sec: 66724.12
Iteration:   2160, Loss function: 5.348, Average Loss: 4.424, avg. samples / sec: 66731.51
Iteration:   2160, Loss function: 3.957, Average Loss: 4.399, avg. samples / sec: 66654.19
Iteration:   2160, Loss function: 4.251, Average Loss: 4.403, avg. samples / sec: 66590.03
Iteration:   2160, Loss function: 3.623, Average Loss: 4.396, avg. samples / sec: 66721.06
Iteration:   2160, Loss function: 4.481, Average Loss: 4.422, avg. samples / sec: 66564.90
Iteration:   2160, Loss function: 4.587, Average Loss: 4.423, avg. samples / sec: 66612.95
Iteration:   2160, Loss function: 3.581, Average Loss: 4.424, avg. samples / sec: 66629.64
Iteration:   2160, Loss function: 4.120, Average Loss: 4.434, avg. samples / sec: 66481.03
Iteration:   2160, Loss function: 3.048, Average Loss: 4.428, avg. samples / sec: 66589.34
Iteration:   2160, Loss function: 4.212, Average Loss: 4.413, avg. samples / sec: 66566.47
Iteration:   2160, Loss function: 3.574, Average Loss: 4.406, avg. samples / sec: 66488.71
Iteration:   2160, Loss function: 4.019, Average Loss: 4.429, avg. samples / sec: 66593.02
Iteration:   2160, Loss function: 4.417, Average Loss: 4.413, avg. samples / sec: 66452.16
Iteration:   2160, Loss function: 3.458, Average Loss: 4.421, avg. samples / sec: 66473.75
Iteration:   2160, Loss function: 3.876, Average Loss: 4.441, avg. samples / sec: 66654.60
Iteration:   2160, Loss function: 3.348, Average Loss: 4.397, avg. samples / sec: 66625.29
Iteration:   2160, Loss function: 4.888, Average Loss: 4.409, avg. samples / sec: 66577.80
Iteration:   2160, Loss function: 4.300, Average Loss: 4.403, avg. samples / sec: 66545.85
Iteration:   2160, Loss function: 3.914, Average Loss: 4.420, avg. samples / sec: 66514.76
Iteration:   2160, Loss function: 2.809, Average Loss: 4.392, avg. samples / sec: 66512.94
Iteration:   2160, Loss function: 3.665, Average Loss: 4.417, avg. samples / sec: 66522.30
Iteration:   2160, Loss function: 5.213, Average Loss: 4.413, avg. samples / sec: 66524.84
Iteration:   2160, Loss function: 4.308, Average Loss: 4.402, avg. samples / sec: 66615.25
Iteration:   2160, Loss function: 3.486, Average Loss: 4.404, avg. samples / sec: 66379.54
:::MLL 1558651913.376 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558651913.377 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 5.081, Average Loss: 4.428, avg. samples / sec: 65305.08
Iteration:   2180, Loss function: 4.334, Average Loss: 4.393, avg. samples / sec: 65388.74
Iteration:   2180, Loss function: 3.527, Average Loss: 4.412, avg. samples / sec: 65309.28
Iteration:   2180, Loss function: 3.002, Average Loss: 4.407, avg. samples / sec: 65425.38
Iteration:   2180, Loss function: 3.389, Average Loss: 4.394, avg. samples / sec: 65264.82
Iteration:   2180, Loss function: 4.355, Average Loss: 4.398, avg. samples / sec: 65404.76
Iteration:   2180, Loss function: 3.808, Average Loss: 4.421, avg. samples / sec: 65354.32
Iteration:   2180, Loss function: 3.862, Average Loss: 4.417, avg. samples / sec: 65331.11
Iteration:   2180, Loss function: 4.918, Average Loss: 4.425, avg. samples / sec: 65262.28
Iteration:   2180, Loss function: 3.770, Average Loss: 4.398, avg. samples / sec: 65370.48
Iteration:   2180, Loss function: 4.802, Average Loss: 4.390, avg. samples / sec: 65393.89
Iteration:   2180, Loss function: 4.837, Average Loss: 4.411, avg. samples / sec: 65451.39
Iteration:   2180, Loss function: 3.449, Average Loss: 4.420, avg. samples / sec: 65371.14
Iteration:   2180, Loss function: 2.789, Average Loss: 4.423, avg. samples / sec: 65237.99
Iteration:   2180, Loss function: 4.031, Average Loss: 4.392, avg. samples / sec: 65281.96
Iteration:   2180, Loss function: 3.207, Average Loss: 4.413, avg. samples / sec: 65199.96
Iteration:   2180, Loss function: 4.600, Average Loss: 4.414, avg. samples / sec: 65321.88
Iteration:   2180, Loss function: 4.554, Average Loss: 4.425, avg. samples / sec: 65358.17
Iteration:   2180, Loss function: 3.564, Average Loss: 4.413, avg. samples / sec: 65190.49
Iteration:   2180, Loss function: 5.219, Average Loss: 4.410, avg. samples / sec: 65316.79
Iteration:   2180, Loss function: 3.673, Average Loss: 4.420, avg. samples / sec: 65322.63
Iteration:   2180, Loss function: 4.207, Average Loss: 4.433, avg. samples / sec: 65334.72
Iteration:   2180, Loss function: 4.790, Average Loss: 4.402, avg. samples / sec: 65411.22
Iteration:   2180, Loss function: 4.853, Average Loss: 4.408, avg. samples / sec: 65414.90
Iteration:   2180, Loss function: 4.580, Average Loss: 4.401, avg. samples / sec: 65244.46
Iteration:   2180, Loss function: 5.310, Average Loss: 4.385, avg. samples / sec: 65322.54
Iteration:   2180, Loss function: 4.145, Average Loss: 4.399, avg. samples / sec: 65301.08
Iteration:   2180, Loss function: 4.894, Average Loss: 4.427, avg. samples / sec: 65242.52
Iteration:   2180, Loss function: 4.835, Average Loss: 4.403, avg. samples / sec: 65391.16
Iteration:   2180, Loss function: 5.364, Average Loss: 4.421, avg. samples / sec: 65243.64
Iteration:   2200, Loss function: 3.385, Average Loss: 4.391, avg. samples / sec: 66777.33
Iteration:   2200, Loss function: 3.582, Average Loss: 4.420, avg. samples / sec: 66615.50
Iteration:   2200, Loss function: 3.351, Average Loss: 4.386, avg. samples / sec: 66577.39
Iteration:   2200, Loss function: 4.481, Average Loss: 4.406, avg. samples / sec: 66557.33
Iteration:   2200, Loss function: 3.998, Average Loss: 4.414, avg. samples / sec: 66833.29
Iteration:   2200, Loss function: 4.053, Average Loss: 4.386, avg. samples / sec: 66752.85
Iteration:   2200, Loss function: 3.352, Average Loss: 4.417, avg. samples / sec: 66649.30
Iteration:   2200, Loss function: 3.995, Average Loss: 4.398, avg. samples / sec: 66768.28
Iteration:   2200, Loss function: 3.617, Average Loss: 4.415, avg. samples / sec: 66622.39
Iteration:   2200, Loss function: 3.659, Average Loss: 4.392, avg. samples / sec: 66722.10
Iteration:   2200, Loss function: 4.068, Average Loss: 4.402, avg. samples / sec: 66691.00
Iteration:   2200, Loss function: 4.303, Average Loss: 4.386, avg. samples / sec: 66563.80
Iteration:   2200, Loss function: 3.781, Average Loss: 4.401, avg. samples / sec: 66680.14
Iteration:   2200, Loss function: 3.876, Average Loss: 4.390, avg. samples / sec: 66591.04
Iteration:   2200, Loss function: 5.493, Average Loss: 4.409, avg. samples / sec: 66632.51
Iteration:   2200, Loss function: 4.782, Average Loss: 4.409, avg. samples / sec: 66599.69
Iteration:   2200, Loss function: 3.996, Average Loss: 4.396, avg. samples / sec: 66536.68
Iteration:   2200, Loss function: 4.198, Average Loss: 4.421, avg. samples / sec: 66581.85
Iteration:   2200, Loss function: 4.126, Average Loss: 4.403, avg. samples / sec: 66633.36
Iteration:   2200, Loss function: 4.364, Average Loss: 4.390, avg. samples / sec: 66613.01
Iteration:   2200, Loss function: 5.812, Average Loss: 4.424, avg. samples / sec: 66688.31
Iteration:   2200, Loss function: 3.748, Average Loss: 4.418, avg. samples / sec: 66620.25
Iteration:   2200, Loss function: 4.231, Average Loss: 4.414, avg. samples / sec: 66602.62
Iteration:   2200, Loss function: 4.413, Average Loss: 4.384, avg. samples / sec: 66537.21
Iteration:   2200, Loss function: 5.694, Average Loss: 4.417, avg. samples / sec: 66539.44
Iteration:   2200, Loss function: 4.376, Average Loss: 4.408, avg. samples / sec: 66554.56
Iteration:   2200, Loss function: 4.671, Average Loss: 4.403, avg. samples / sec: 66550.13
Iteration:   2200, Loss function: 3.147, Average Loss: 4.426, avg. samples / sec: 66476.76
Iteration:   2200, Loss function: 3.556, Average Loss: 4.400, avg. samples / sec: 66485.45
Iteration:   2200, Loss function: 3.514, Average Loss: 4.416, avg. samples / sec: 66403.25
Iteration:   2220, Loss function: 2.576, Average Loss: 4.383, avg. samples / sec: 66723.24
Iteration:   2220, Loss function: 3.726, Average Loss: 4.403, avg. samples / sec: 66583.27
Iteration:   2220, Loss function: 3.970, Average Loss: 4.383, avg. samples / sec: 66585.75
Iteration:   2220, Loss function: 4.566, Average Loss: 4.419, avg. samples / sec: 66665.66
Iteration:   2220, Loss function: 5.610, Average Loss: 4.414, avg. samples / sec: 66598.62
Iteration:   2220, Loss function: 4.395, Average Loss: 4.389, avg. samples / sec: 66442.38
Iteration:   2220, Loss function: 2.899, Average Loss: 4.382, avg. samples / sec: 66529.86
Iteration:   2220, Loss function: 5.239, Average Loss: 4.416, avg. samples / sec: 66456.80
Iteration:   2220, Loss function: 5.432, Average Loss: 4.392, avg. samples / sec: 66592.93
Iteration:   2220, Loss function: 5.426, Average Loss: 4.406, avg. samples / sec: 66595.79
Iteration:   2220, Loss function: 4.966, Average Loss: 4.417, avg. samples / sec: 66619.31
Iteration:   2220, Loss function: 4.198, Average Loss: 4.379, avg. samples / sec: 66640.22
Iteration:   2220, Loss function: 3.962, Average Loss: 4.396, avg. samples / sec: 66553.87
Iteration:   2220, Loss function: 5.418, Average Loss: 4.405, avg. samples / sec: 66634.77
Iteration:   2220, Loss function: 3.883, Average Loss: 4.398, avg. samples / sec: 66565.97
Iteration:   2220, Loss function: 2.319, Average Loss: 4.394, avg. samples / sec: 66551.95
Iteration:   2220, Loss function: 3.472, Average Loss: 4.394, avg. samples / sec: 66727.75
Iteration:   2220, Loss function: 4.415, Average Loss: 4.424, avg. samples / sec: 66746.53
Iteration:   2220, Loss function: 4.280, Average Loss: 4.386, avg. samples / sec: 66511.62
Iteration:   2220, Loss function: 4.083, Average Loss: 4.410, avg. samples / sec: 66544.72
Iteration:   2220, Loss function: 4.848, Average Loss: 4.398, avg. samples / sec: 66502.96
Iteration:   2220, Loss function: 3.464, Average Loss: 4.411, avg. samples / sec: 66533.26
Iteration:   2220, Loss function: 4.370, Average Loss: 4.425, avg. samples / sec: 66692.80
Iteration:   2220, Loss function: 5.628, Average Loss: 4.389, avg. samples / sec: 66523.77
Iteration:   2220, Loss function: 4.693, Average Loss: 4.417, avg. samples / sec: 66573.14
Iteration:   2220, Loss function: 4.016, Average Loss: 4.408, avg. samples / sec: 66455.07
Iteration:   2220, Loss function: 3.125, Average Loss: 4.398, avg. samples / sec: 66430.08
Iteration:   2220, Loss function: 3.523, Average Loss: 4.398, avg. samples / sec: 66570.44
Iteration:   2220, Loss function: 5.343, Average Loss: 4.409, avg. samples / sec: 66467.01
Iteration:   2220, Loss function: 4.540, Average Loss: 4.413, avg. samples / sec: 66267.21
:::MLL 1558651915.151 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558651915.152 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 4.031, Average Loss: 4.409, avg. samples / sec: 66398.24
Iteration:   2240, Loss function: 4.261, Average Loss: 4.393, avg. samples / sec: 66344.98
Iteration:   2240, Loss function: 3.892, Average Loss: 4.400, avg. samples / sec: 66475.01
Iteration:   2240, Loss function: 4.689, Average Loss: 4.377, avg. samples / sec: 66324.09
Iteration:   2240, Loss function: 3.691, Average Loss: 4.407, avg. samples / sec: 66622.68
Iteration:   2240, Loss function: 3.882, Average Loss: 4.376, avg. samples / sec: 66235.13
Iteration:   2240, Loss function: 5.458, Average Loss: 4.412, avg. samples / sec: 66357.41
Iteration:   2240, Loss function: 4.648, Average Loss: 4.410, avg. samples / sec: 66286.00
Iteration:   2240, Loss function: 2.516, Average Loss: 4.390, avg. samples / sec: 66359.73
Iteration:   2240, Loss function: 3.550, Average Loss: 4.407, avg. samples / sec: 66384.86
Iteration:   2240, Loss function: 3.433, Average Loss: 4.375, avg. samples / sec: 66274.34
Iteration:   2240, Loss function: 3.484, Average Loss: 4.381, avg. samples / sec: 66372.79
Iteration:   2240, Loss function: 4.533, Average Loss: 4.373, avg. samples / sec: 66319.07
Iteration:   2240, Loss function: 5.573, Average Loss: 4.414, avg. samples / sec: 66385.92
Iteration:   2240, Loss function: 4.145, Average Loss: 4.403, avg. samples / sec: 66331.08
Iteration:   2240, Loss function: 2.784, Average Loss: 4.389, avg. samples / sec: 66279.77
Iteration:   2240, Loss function: 3.954, Average Loss: 4.390, avg. samples / sec: 66410.26
Iteration:   2240, Loss function: 3.212, Average Loss: 4.384, avg. samples / sec: 66368.79
Iteration:   2240, Loss function: 3.897, Average Loss: 4.395, avg. samples / sec: 66402.59
Iteration:   2240, Loss function: 4.243, Average Loss: 4.414, avg. samples / sec: 66221.46
Iteration:   2240, Loss function: 5.051, Average Loss: 4.395, avg. samples / sec: 66309.49
Iteration:   2240, Loss function: 4.966, Average Loss: 4.407, avg. samples / sec: 66362.01
Iteration:   2240, Loss function: 3.533, Average Loss: 4.382, avg. samples / sec: 66307.55
Iteration:   2240, Loss function: 4.054, Average Loss: 4.406, avg. samples / sec: 66366.63
Iteration:   2240, Loss function: 3.268, Average Loss: 4.417, avg. samples / sec: 66308.30
Iteration:   2240, Loss function: 3.831, Average Loss: 4.377, avg. samples / sec: 66297.07
Iteration:   2240, Loss function: 3.452, Average Loss: 4.382, avg. samples / sec: 66202.27
Iteration:   2240, Loss function: 3.932, Average Loss: 4.400, avg. samples / sec: 66331.08
Iteration:   2240, Loss function: 4.825, Average Loss: 4.401, avg. samples / sec: 66202.92
Iteration:   2240, Loss function: 3.757, Average Loss: 4.419, avg. samples / sec: 66215.49
Iteration:   2260, Loss function: 4.704, Average Loss: 4.385, avg. samples / sec: 66472.81
Iteration:   2260, Loss function: 2.852, Average Loss: 4.372, avg. samples / sec: 66506.38
Iteration:   2260, Loss function: 3.761, Average Loss: 4.402, avg. samples / sec: 66493.80
Iteration:   2260, Loss function: 4.557, Average Loss: 4.399, avg. samples / sec: 66386.52
Iteration:   2260, Loss function: 4.558, Average Loss: 4.406, avg. samples / sec: 66504.40
Iteration:   2260, Loss function: 4.995, Average Loss: 4.372, avg. samples / sec: 66465.32
Iteration:   2260, Loss function: 6.290, Average Loss: 4.391, avg. samples / sec: 66502.74
Iteration:   2260, Loss function: 4.283, Average Loss: 4.380, avg. samples / sec: 66539.60
Iteration:   2260, Loss function: 5.090, Average Loss: 4.395, avg. samples / sec: 66542.84
Iteration:   2260, Loss function: 4.162, Average Loss: 4.368, avg. samples / sec: 66423.25
Iteration:   2260, Loss function: 4.253, Average Loss: 4.407, avg. samples / sec: 66431.95
Iteration:   2260, Loss function: 3.991, Average Loss: 4.383, avg. samples / sec: 66444.11
Iteration:   2260, Loss function: 3.990, Average Loss: 4.394, avg. samples / sec: 66384.98
Iteration:   2260, Loss function: 4.970, Average Loss: 4.400, avg. samples / sec: 66512.37
Iteration:   2260, Loss function: 4.134, Average Loss: 4.376, avg. samples / sec: 66318.75
Iteration:   2260, Loss function: 5.261, Average Loss: 4.391, avg. samples / sec: 66402.66
Iteration:   2260, Loss function: 4.833, Average Loss: 4.414, avg. samples / sec: 66414.70
Iteration:   2260, Loss function: 5.107, Average Loss: 4.407, avg. samples / sec: 66323.16
Iteration:   2260, Loss function: 4.443, Average Loss: 4.415, avg. samples / sec: 66461.53
Iteration:   2260, Loss function: 5.168, Average Loss: 4.385, avg. samples / sec: 66375.26
Iteration:   2260, Loss function: 3.632, Average Loss: 4.401, avg. samples / sec: 66349.07
Iteration:   2260, Loss function: 4.269, Average Loss: 4.393, avg. samples / sec: 66257.02
Iteration:   2260, Loss function: 4.485, Average Loss: 4.416, avg. samples / sec: 66507.70
Iteration:   2260, Loss function: 4.453, Average Loss: 4.374, avg. samples / sec: 66369.57
Iteration:   2260, Loss function: 4.899, Average Loss: 4.404, avg. samples / sec: 66382.67
Iteration:   2260, Loss function: 4.211, Average Loss: 4.380, avg. samples / sec: 66332.05
Iteration:   2260, Loss function: 3.860, Average Loss: 4.406, avg. samples / sec: 66301.50
Iteration:   2260, Loss function: 4.533, Average Loss: 4.408, avg. samples / sec: 66246.43
Iteration:   2260, Loss function: 5.249, Average Loss: 4.372, avg. samples / sec: 66342.79
Iteration:   2260, Loss function: 3.820, Average Loss: 4.380, avg. samples / sec: 66243.41
Iteration:   2280, Loss function: 4.821, Average Loss: 4.399, avg. samples / sec: 66565.94
Iteration:   2280, Loss function: 2.837, Average Loss: 4.380, avg. samples / sec: 66466.58
Iteration:   2280, Loss function: 4.091, Average Loss: 4.368, avg. samples / sec: 66565.28
Iteration:   2280, Loss function: 4.399, Average Loss: 4.376, avg. samples / sec: 66522.45
Iteration:   2280, Loss function: 3.935, Average Loss: 4.369, avg. samples / sec: 66497.69
Iteration:   2280, Loss function: 2.885, Average Loss: 4.387, avg. samples / sec: 66622.80
Iteration:   2280, Loss function: 4.297, Average Loss: 4.405, avg. samples / sec: 66578.77
Iteration:   2280, Loss function: 4.499, Average Loss: 4.399, avg. samples / sec: 66636.54
Iteration:   2280, Loss function: 4.041, Average Loss: 4.368, avg. samples / sec: 66400.25
Iteration:   2280, Loss function: 3.838, Average Loss: 4.404, avg. samples / sec: 66651.41
Iteration:   2280, Loss function: 4.597, Average Loss: 4.410, avg. samples / sec: 66554.34
Iteration:   2280, Loss function: 4.950, Average Loss: 4.409, avg. samples / sec: 66501.48
Iteration:   2280, Loss function: 4.476, Average Loss: 4.395, avg. samples / sec: 66498.60
Iteration:   2280, Loss function: 4.225, Average Loss: 4.396, avg. samples / sec: 66394.80
Iteration:   2280, Loss function: 4.277, Average Loss: 4.391, avg. samples / sec: 66466.48
Iteration:   2280, Loss function: 3.002, Average Loss: 4.402, avg. samples / sec: 66443.23
Iteration:   2280, Loss function: 4.164, Average Loss: 4.385, avg. samples / sec: 66448.37
Iteration:   2280, Loss function: 5.609, Average Loss: 4.412, avg. samples / sec: 66550.13
Iteration:   2280, Loss function: 4.246, Average Loss: 4.396, avg. samples / sec: 66549.19
Iteration:   2280, Loss function: 3.763, Average Loss: 4.373, avg. samples / sec: 66473.97
Iteration:   2280, Loss function: 3.449, Average Loss: 4.398, avg. samples / sec: 66552.33
Iteration:   2280, Loss function: 5.325, Average Loss: 4.383, avg. samples / sec: 66607.59
Iteration:   2280, Loss function: 3.665, Average Loss: 4.368, avg. samples / sec: 66599.98
Iteration:   2280, Loss function: 3.580, Average Loss: 4.389, avg. samples / sec: 66458.30
Iteration:   2280, Loss function: 4.513, Average Loss: 4.394, avg. samples / sec: 66429.17
Iteration:   2280, Loss function: 4.992, Average Loss: 4.409, avg. samples / sec: 66447.65
Iteration:   2280, Loss function: 4.552, Average Loss: 4.383, avg. samples / sec: 66443.51
Iteration:   2280, Loss function: 3.661, Average Loss: 4.386, avg. samples / sec: 66361.41
Iteration:   2280, Loss function: 5.183, Average Loss: 4.380, avg. samples / sec: 66464.44
Iteration:   2280, Loss function: 4.428, Average Loss: 4.370, avg. samples / sec: 66467.30
:::MLL 1558651916.327 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.76 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.36s)
DONE (t=0.36s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.37s)
DONE (t=0.38s)
DONE (t=0.39s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=2.51s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.15133
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.28582
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.14686
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03945
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.16310
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.23919
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.16944
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.25713
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.27273
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.39525
Current AP: 0.15133 AP goal: 0.23000
:::MLL 1558651920.023 eval_accuracy: {"value": 0.15132689566808996, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558651920.071 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558651920.077 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558651920.077 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 3.908, Average Loss: 4.387, avg. samples / sec: 7781.64
Iteration:   2300, Loss function: 4.435, Average Loss: 4.394, avg. samples / sec: 7778.97
Iteration:   2300, Loss function: 3.378, Average Loss: 4.380, avg. samples / sec: 7781.55
Iteration:   2300, Loss function: 3.400, Average Loss: 4.379, avg. samples / sec: 7781.45
Iteration:   2300, Loss function: 4.595, Average Loss: 4.403, avg. samples / sec: 7779.64
Iteration:   2300, Loss function: 3.174, Average Loss: 4.369, avg. samples / sec: 7779.82
Iteration:   2300, Loss function: 3.726, Average Loss: 4.381, avg. samples / sec: 7779.28
Iteration:   2300, Loss function: 4.661, Average Loss: 4.376, avg. samples / sec: 7779.71
Iteration:   2300, Loss function: 3.264, Average Loss: 4.370, avg. samples / sec: 7777.50
Iteration:   2300, Loss function: 5.348, Average Loss: 4.383, avg. samples / sec: 7780.21
Iteration:   2300, Loss function: 3.507, Average Loss: 4.397, avg. samples / sec: 7778.37
Iteration:   2300, Loss function: 3.404, Average Loss: 4.356, avg. samples / sec: 7779.10
Iteration:   2300, Loss function: 3.875, Average Loss: 4.406, avg. samples / sec: 7778.26
Iteration:   2300, Loss function: 4.865, Average Loss: 4.364, avg. samples / sec: 7777.38
Iteration:   2300, Loss function: 5.003, Average Loss: 4.366, avg. samples / sec: 7777.47
Iteration:   2300, Loss function: 3.397, Average Loss: 4.400, avg. samples / sec: 7777.62
Iteration:   2300, Loss function: 4.429, Average Loss: 4.370, avg. samples / sec: 7777.30
Iteration:   2300, Loss function: 4.063, Average Loss: 4.386, avg. samples / sec: 7777.41
Iteration:   2300, Loss function: 4.213, Average Loss: 4.384, avg. samples / sec: 7778.77
Iteration:   2300, Loss function: 4.411, Average Loss: 4.391, avg. samples / sec: 7778.14
Iteration:   2300, Loss function: 3.969, Average Loss: 4.386, avg. samples / sec: 7775.91
Iteration:   2300, Loss function: 4.479, Average Loss: 4.392, avg. samples / sec: 7777.60
Iteration:   2300, Loss function: 4.269, Average Loss: 4.403, avg. samples / sec: 7778.82
Iteration:   2300, Loss function: 4.510, Average Loss: 4.406, avg. samples / sec: 7777.73
Iteration:   2300, Loss function: 3.845, Average Loss: 4.385, avg. samples / sec: 7777.21
Iteration:   2300, Loss function: 3.162, Average Loss: 4.389, avg. samples / sec: 7777.25
Iteration:   2300, Loss function: 3.936, Average Loss: 4.387, avg. samples / sec: 7776.42
Iteration:   2300, Loss function: 4.966, Average Loss: 4.373, avg. samples / sec: 7775.85
Iteration:   2300, Loss function: 3.959, Average Loss: 4.402, avg. samples / sec: 7774.91
Iteration:   2300, Loss function: 3.310, Average Loss: 4.368, avg. samples / sec: 7777.01
:::MLL 1558651920.740 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558651920.740 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 4.163, Average Loss: 4.367, avg. samples / sec: 65607.24
Iteration:   2320, Loss function: 3.994, Average Loss: 4.392, avg. samples / sec: 65441.66
Iteration:   2320, Loss function: 4.631, Average Loss: 4.379, avg. samples / sec: 65506.42
Iteration:   2320, Loss function: 3.765, Average Loss: 4.392, avg. samples / sec: 65502.68
Iteration:   2320, Loss function: 2.632, Average Loss: 4.381, avg. samples / sec: 65363.44
Iteration:   2320, Loss function: 3.872, Average Loss: 4.385, avg. samples / sec: 65540.02
Iteration:   2320, Loss function: 4.504, Average Loss: 4.374, avg. samples / sec: 65422.55
Iteration:   2320, Loss function: 3.763, Average Loss: 4.387, avg. samples / sec: 65510.81
Iteration:   2320, Loss function: 4.123, Average Loss: 4.383, avg. samples / sec: 65571.62
Iteration:   2320, Loss function: 5.092, Average Loss: 4.368, avg. samples / sec: 65466.16
Iteration:   2320, Loss function: 4.708, Average Loss: 4.377, avg. samples / sec: 65450.23
Iteration:   2320, Loss function: 3.057, Average Loss: 4.374, avg. samples / sec: 65335.78
Iteration:   2320, Loss function: 3.773, Average Loss: 4.395, avg. samples / sec: 65443.64
Iteration:   2320, Loss function: 3.709, Average Loss: 4.363, avg. samples / sec: 65431.06
Iteration:   2320, Loss function: 5.017, Average Loss: 4.360, avg. samples / sec: 65641.80
Iteration:   2320, Loss function: 4.532, Average Loss: 4.363, avg. samples / sec: 65443.12
Iteration:   2320, Loss function: 4.942, Average Loss: 4.367, avg. samples / sec: 65533.32
Iteration:   2320, Loss function: 4.646, Average Loss: 4.382, avg. samples / sec: 65437.38
Iteration:   2320, Loss function: 4.100, Average Loss: 4.350, avg. samples / sec: 65389.68
Iteration:   2320, Loss function: 4.425, Average Loss: 4.386, avg. samples / sec: 65435.64
Iteration:   2320, Loss function: 4.193, Average Loss: 4.380, avg. samples / sec: 65477.17
Iteration:   2320, Loss function: 4.600, Average Loss: 4.377, avg. samples / sec: 65299.42
Iteration:   2320, Loss function: 4.476, Average Loss: 4.383, avg. samples / sec: 65515.28
Iteration:   2320, Loss function: 3.995, Average Loss: 4.402, avg. samples / sec: 65351.50
Iteration:   2320, Loss function: 3.665, Average Loss: 4.376, avg. samples / sec: 65290.76
Iteration:   2320, Loss function: 5.379, Average Loss: 4.367, avg. samples / sec: 65289.92
Iteration:   2320, Loss function: 4.325, Average Loss: 4.398, avg. samples / sec: 65553.10
Iteration:   2320, Loss function: 3.524, Average Loss: 4.393, avg. samples / sec: 65218.43
Iteration:   2320, Loss function: 3.300, Average Loss: 4.408, avg. samples / sec: 65290.46
Iteration:   2320, Loss function: 4.532, Average Loss: 4.405, avg. samples / sec: 65291.31
Iteration:   2340, Loss function: 5.115, Average Loss: 4.362, avg. samples / sec: 65725.53
Iteration:   2340, Loss function: 4.038, Average Loss: 4.370, avg. samples / sec: 65711.65
Iteration:   2340, Loss function: 4.700, Average Loss: 4.351, avg. samples / sec: 65730.59
Iteration:   2340, Loss function: 3.035, Average Loss: 4.379, avg. samples / sec: 65615.79
Iteration:   2340, Loss function: 3.343, Average Loss: 4.363, avg. samples / sec: 65695.47
Iteration:   2340, Loss function: 3.398, Average Loss: 4.359, avg. samples / sec: 65445.61
Iteration:   2340, Loss function: 4.301, Average Loss: 4.366, avg. samples / sec: 65681.79
Iteration:   2340, Loss function: 3.800, Average Loss: 4.383, avg. samples / sec: 65620.80
Iteration:   2340, Loss function: 4.086, Average Loss: 4.380, avg. samples / sec: 65642.41
Iteration:   2340, Loss function: 3.731, Average Loss: 4.400, avg. samples / sec: 65700.56
Iteration:   2340, Loss function: 4.171, Average Loss: 4.367, avg. samples / sec: 65578.60
Iteration:   2340, Loss function: 5.340, Average Loss: 4.378, avg. samples / sec: 65631.47
Iteration:   2340, Loss function: 4.278, Average Loss: 4.390, avg. samples / sec: 65713.27
Iteration:   2340, Loss function: 4.667, Average Loss: 4.384, avg. samples / sec: 65478.06
Iteration:   2340, Loss function: 6.096, Average Loss: 4.411, avg. samples / sec: 65778.23
Iteration:   2340, Loss function: 4.687, Average Loss: 4.376, avg. samples / sec: 65583.33
Iteration:   2340, Loss function: 4.533, Average Loss: 4.374, avg. samples / sec: 65620.71
Iteration:   2340, Loss function: 3.924, Average Loss: 4.381, avg. samples / sec: 65529.39
Iteration:   2340, Loss function: 4.492, Average Loss: 4.360, avg. samples / sec: 65590.51
Iteration:   2340, Loss function: 4.248, Average Loss: 4.358, avg. samples / sec: 65642.63
Iteration:   2340, Loss function: 3.716, Average Loss: 4.370, avg. samples / sec: 65644.28
Iteration:   2340, Loss function: 4.387, Average Loss: 4.400, avg. samples / sec: 65755.64
Iteration:   2340, Loss function: 4.428, Average Loss: 4.393, avg. samples / sec: 65461.72
Iteration:   2340, Loss function: 3.975, Average Loss: 4.376, avg. samples / sec: 65453.76
Iteration:   2340, Loss function: 4.311, Average Loss: 4.380, avg. samples / sec: 65591.82
Iteration:   2340, Loss function: 5.153, Average Loss: 4.374, avg. samples / sec: 65581.14
Iteration:   2340, Loss function: 3.365, Average Loss: 4.385, avg. samples / sec: 65534.75
Iteration:   2340, Loss function: 4.575, Average Loss: 4.382, avg. samples / sec: 65579.64
Iteration:   2340, Loss function: 5.156, Average Loss: 4.396, avg. samples / sec: 65531.19
Iteration:   2340, Loss function: 4.637, Average Loss: 4.356, avg. samples / sec: 65409.55
Iteration:   2360, Loss function: 5.400, Average Loss: 4.364, avg. samples / sec: 65911.23
Iteration:   2360, Loss function: 3.621, Average Loss: 4.352, avg. samples / sec: 66240.58
Iteration:   2360, Loss function: 3.847, Average Loss: 4.371, avg. samples / sec: 65925.93
Iteration:   2360, Loss function: 5.570, Average Loss: 4.381, avg. samples / sec: 66099.37
Iteration:   2360, Loss function: 4.812, Average Loss: 4.358, avg. samples / sec: 65945.09
Iteration:   2360, Loss function: 3.792, Average Loss: 4.379, avg. samples / sec: 66018.49
Iteration:   2360, Loss function: 5.246, Average Loss: 4.379, avg. samples / sec: 66004.67
Iteration:   2360, Loss function: 5.363, Average Loss: 4.367, avg. samples / sec: 65860.74
Iteration:   2360, Loss function: 3.825, Average Loss: 4.372, avg. samples / sec: 66024.52
Iteration:   2360, Loss function: 3.863, Average Loss: 4.372, avg. samples / sec: 65955.83
Iteration:   2360, Loss function: 5.406, Average Loss: 4.373, avg. samples / sec: 65862.09
Iteration:   2360, Loss function: 4.112, Average Loss: 4.363, avg. samples / sec: 65875.24
Iteration:   2360, Loss function: 4.236, Average Loss: 4.393, avg. samples / sec: 65928.96
Iteration:   2360, Loss function: 3.752, Average Loss: 4.393, avg. samples / sec: 66100.92
Iteration:   2360, Loss function: 3.937, Average Loss: 4.388, avg. samples / sec: 65949.41
Iteration:   2360, Loss function: 4.296, Average Loss: 4.352, avg. samples / sec: 65948.36
Iteration:   2360, Loss function: 3.768, Average Loss: 4.376, avg. samples / sec: 65866.68
Iteration:   2360, Loss function: 3.811, Average Loss: 4.368, avg. samples / sec: 65960.46
Iteration:   2360, Loss function: 4.696, Average Loss: 4.370, avg. samples / sec: 65946.48
Iteration:   2360, Loss function: 4.174, Average Loss: 4.354, avg. samples / sec: 65940.96
Iteration:   2360, Loss function: 6.034, Average Loss: 4.407, avg. samples / sec: 65942.00
Iteration:   2360, Loss function: 2.868, Average Loss: 4.370, avg. samples / sec: 65908.88
Iteration:   2360, Loss function: 3.961, Average Loss: 4.377, avg. samples / sec: 65959.53
Iteration:   2360, Loss function: 4.957, Average Loss: 4.389, avg. samples / sec: 65930.71
Iteration:   2360, Loss function: 4.744, Average Loss: 4.370, avg. samples / sec: 65932.60
Iteration:   2360, Loss function: 4.471, Average Loss: 4.368, avg. samples / sec: 65761.60
Iteration:   2360, Loss function: 3.723, Average Loss: 4.381, avg. samples / sec: 65930.19
Iteration:   2360, Loss function: 3.789, Average Loss: 4.395, avg. samples / sec: 65884.39
Iteration:   2360, Loss function: 3.621, Average Loss: 4.344, avg. samples / sec: 65734.11
Iteration:   2360, Loss function: 2.912, Average Loss: 4.359, avg. samples / sec: 65759.54
:::MLL 1558651922.527 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558651922.528 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 3.858, Average Loss: 4.366, avg. samples / sec: 66137.74
Iteration:   2380, Loss function: 4.311, Average Loss: 4.354, avg. samples / sec: 65967.81
Iteration:   2380, Loss function: 5.564, Average Loss: 4.371, avg. samples / sec: 66026.69
Iteration:   2380, Loss function: 4.122, Average Loss: 4.370, avg. samples / sec: 65975.62
Iteration:   2380, Loss function: 4.911, Average Loss: 4.354, avg. samples / sec: 66020.96
Iteration:   2380, Loss function: 4.252, Average Loss: 4.361, avg. samples / sec: 65985.94
Iteration:   2380, Loss function: 3.341, Average Loss: 4.382, avg. samples / sec: 66083.31
Iteration:   2380, Loss function: 4.029, Average Loss: 4.363, avg. samples / sec: 65930.28
Iteration:   2380, Loss function: 4.330, Average Loss: 4.368, avg. samples / sec: 66057.82
Iteration:   2380, Loss function: 4.761, Average Loss: 4.388, avg. samples / sec: 65987.24
Iteration:   2380, Loss function: 3.063, Average Loss: 4.352, avg. samples / sec: 65882.38
Iteration:   2380, Loss function: 4.165, Average Loss: 4.365, avg. samples / sec: 65965.86
Iteration:   2380, Loss function: 3.067, Average Loss: 4.359, avg. samples / sec: 65850.37
Iteration:   2380, Loss function: 3.174, Average Loss: 4.399, avg. samples / sec: 65990.70
Iteration:   2380, Loss function: 4.331, Average Loss: 4.372, avg. samples / sec: 65852.34
Iteration:   2380, Loss function: 3.925, Average Loss: 4.349, avg. samples / sec: 65954.19
Iteration:   2380, Loss function: 3.942, Average Loss: 4.381, avg. samples / sec: 65956.82
Iteration:   2380, Loss function: 3.813, Average Loss: 4.352, avg. samples / sec: 65959.32
Iteration:   2380, Loss function: 3.891, Average Loss: 4.385, avg. samples / sec: 65939.01
Iteration:   2380, Loss function: 2.645, Average Loss: 4.365, avg. samples / sec: 65914.59
Iteration:   2380, Loss function: 4.283, Average Loss: 4.361, avg. samples / sec: 65921.03
Iteration:   2380, Loss function: 3.159, Average Loss: 4.337, avg. samples / sec: 66011.59
Iteration:   2380, Loss function: 4.162, Average Loss: 4.368, avg. samples / sec: 65918.44
Iteration:   2380, Loss function: 4.280, Average Loss: 4.373, avg. samples / sec: 65832.22
Iteration:   2380, Loss function: 4.040, Average Loss: 4.361, avg. samples / sec: 65851.97
Iteration:   2380, Loss function: 4.680, Average Loss: 4.387, avg. samples / sec: 65947.87
Iteration:   2380, Loss function: 4.226, Average Loss: 4.372, avg. samples / sec: 65840.06
Iteration:   2380, Loss function: 3.979, Average Loss: 4.355, avg. samples / sec: 65958.82
Iteration:   2380, Loss function: 4.762, Average Loss: 4.368, avg. samples / sec: 65849.72
Iteration:   2380, Loss function: 4.426, Average Loss: 4.381, avg. samples / sec: 65855.72
Iteration:   2400, Loss function: 3.803, Average Loss: 4.354, avg. samples / sec: 65331.96
Iteration:   2400, Loss function: 3.418, Average Loss: 4.357, avg. samples / sec: 65402.27
Iteration:   2400, Loss function: 4.956, Average Loss: 4.345, avg. samples / sec: 65309.49
Iteration:   2400, Loss function: 4.953, Average Loss: 4.379, avg. samples / sec: 65419.97
Iteration:   2400, Loss function: 4.955, Average Loss: 4.379, avg. samples / sec: 65407.28
Iteration:   2400, Loss function: 3.112, Average Loss: 4.352, avg. samples / sec: 65318.15
Iteration:   2400, Loss function: 4.237, Average Loss: 4.348, avg. samples / sec: 65404.27
Iteration:   2400, Loss function: 3.155, Average Loss: 4.350, avg. samples / sec: 65406.34
Iteration:   2400, Loss function: 4.972, Average Loss: 4.372, avg. samples / sec: 65298.93
Iteration:   2400, Loss function: 4.202, Average Loss: 4.393, avg. samples / sec: 65354.44
Iteration:   2400, Loss function: 5.460, Average Loss: 4.354, avg. samples / sec: 65487.12
Iteration:   2400, Loss function: 3.003, Average Loss: 4.339, avg. samples / sec: 65414.08
Iteration:   2400, Loss function: 4.158, Average Loss: 4.358, avg. samples / sec: 65427.44
Iteration:   2400, Loss function: 3.647, Average Loss: 4.364, avg. samples / sec: 65481.61
Iteration:   2400, Loss function: 3.311, Average Loss: 4.357, avg. samples / sec: 65214.36
Iteration:   2400, Loss function: 3.028, Average Loss: 4.376, avg. samples / sec: 65249.80
Iteration:   2400, Loss function: 3.872, Average Loss: 4.362, avg. samples / sec: 65494.34
Iteration:   2400, Loss function: 2.497, Average Loss: 4.358, avg. samples / sec: 65249.23
Iteration:   2400, Loss function: 4.313, Average Loss: 4.372, avg. samples / sec: 65366.02
Iteration:   2400, Loss function: 4.546, Average Loss: 4.381, avg. samples / sec: 65249.86
Iteration:   2400, Loss function: 3.132, Average Loss: 4.380, avg. samples / sec: 65407.64
Iteration:   2400, Loss function: 4.028, Average Loss: 4.355, avg. samples / sec: 65289.01
Iteration:   2400, Loss function: 3.966, Average Loss: 4.359, avg. samples / sec: 65307.65
Iteration:   2400, Loss function: 4.106, Average Loss: 4.353, avg. samples / sec: 65310.31
Iteration:   2400, Loss function: 3.442, Average Loss: 4.373, avg. samples / sec: 65275.92
Iteration:   2400, Loss function: 4.103, Average Loss: 4.377, avg. samples / sec: 65427.20
Iteration:   2400, Loss function: 4.323, Average Loss: 4.368, avg. samples / sec: 65188.35
Iteration:   2400, Loss function: 3.775, Average Loss: 4.349, avg. samples / sec: 65215.90
Iteration:   2400, Loss function: 3.602, Average Loss: 4.362, avg. samples / sec: 65303.05
Iteration:   2400, Loss function: 5.194, Average Loss: 4.367, avg. samples / sec: 65138.82
Iteration:   2420, Loss function: 4.439, Average Loss: 4.350, avg. samples / sec: 66017.96
Iteration:   2420, Loss function: 4.244, Average Loss: 4.356, avg. samples / sec: 66121.30
Iteration:   2420, Loss function: 5.044, Average Loss: 4.370, avg. samples / sec: 66055.78
Iteration:   2420, Loss function: 4.725, Average Loss: 4.351, avg. samples / sec: 65975.00
Iteration:   2420, Loss function: 3.888, Average Loss: 4.346, avg. samples / sec: 66048.38
Iteration:   2420, Loss function: 3.468, Average Loss: 4.354, avg. samples / sec: 66081.36
Iteration:   2420, Loss function: 4.278, Average Loss: 4.368, avg. samples / sec: 66039.87
Iteration:   2420, Loss function: 4.444, Average Loss: 4.373, avg. samples / sec: 66014.10
Iteration:   2420, Loss function: 3.405, Average Loss: 4.373, avg. samples / sec: 65932.29
Iteration:   2420, Loss function: 4.113, Average Loss: 4.355, avg. samples / sec: 65987.73
Iteration:   2420, Loss function: 3.913, Average Loss: 4.350, avg. samples / sec: 65901.76
Iteration:   2420, Loss function: 3.978, Average Loss: 4.379, avg. samples / sec: 66005.19
Iteration:   2420, Loss function: 4.938, Average Loss: 4.376, avg. samples / sec: 66001.08
Iteration:   2420, Loss function: 5.609, Average Loss: 4.366, avg. samples / sec: 66065.38
Iteration:   2420, Loss function: 4.169, Average Loss: 4.348, avg. samples / sec: 65992.61
Iteration:   2420, Loss function: 4.679, Average Loss: 4.368, avg. samples / sec: 66025.70
Iteration:   2420, Loss function: 3.704, Average Loss: 4.351, avg. samples / sec: 65946.02
Iteration:   2420, Loss function: 4.576, Average Loss: 4.354, avg. samples / sec: 65994.69
Iteration:   2420, Loss function: 4.512, Average Loss: 4.371, avg. samples / sec: 65980.81
Iteration:   2420, Loss function: 6.257, Average Loss: 4.349, avg. samples / sec: 65905.77
Iteration:   2420, Loss function: 4.844, Average Loss: 4.344, avg. samples / sec: 65830.87
Iteration:   2420, Loss function: 3.445, Average Loss: 4.374, avg. samples / sec: 65817.55
Iteration:   2420, Loss function: 4.396, Average Loss: 4.390, avg. samples / sec: 65853.85
Iteration:   2420, Loss function: 3.832, Average Loss: 4.363, avg. samples / sec: 65864.10
Iteration:   2420, Loss function: 5.518, Average Loss: 4.346, avg. samples / sec: 65958.49
Iteration:   2420, Loss function: 4.528, Average Loss: 4.353, avg. samples / sec: 65855.11
Iteration:   2420, Loss function: 4.802, Average Loss: 4.360, avg. samples / sec: 65952.50
Iteration:   2420, Loss function: 4.154, Average Loss: 4.338, avg. samples / sec: 65815.43
Iteration:   2420, Loss function: 4.287, Average Loss: 4.343, avg. samples / sec: 65787.11
Iteration:   2420, Loss function: 5.012, Average Loss: 4.372, avg. samples / sec: 65888.61
Iteration:   2440, Loss function: 4.364, Average Loss: 4.348, avg. samples / sec: 66273.10
Iteration:   2440, Loss function: 3.989, Average Loss: 4.351, avg. samples / sec: 66188.25
Iteration:   2440, Loss function: 4.810, Average Loss: 4.367, avg. samples / sec: 66212.35
Iteration:   2440, Loss function: 5.034, Average Loss: 4.370, avg. samples / sec: 66217.33
Iteration:   2440, Loss function: 4.660, Average Loss: 4.361, avg. samples / sec: 66085.08
Iteration:   2440, Loss function: 4.410, Average Loss: 4.345, avg. samples / sec: 66255.59
Iteration:   2440, Loss function: 4.704, Average Loss: 4.366, avg. samples / sec: 66264.81
Iteration:   2440, Loss function: 3.731, Average Loss: 4.354, avg. samples / sec: 66304.12
Iteration:   2440, Loss function: 2.257, Average Loss: 4.370, avg. samples / sec: 66179.67
Iteration:   2440, Loss function: 3.808, Average Loss: 4.345, avg. samples / sec: 66118.72
Iteration:   2440, Loss function: 4.514, Average Loss: 4.350, avg. samples / sec: 66188.96
Iteration:   2440, Loss function: 3.651, Average Loss: 4.341, avg. samples / sec: 66339.55
Iteration:   2440, Loss function: 4.429, Average Loss: 4.386, avg. samples / sec: 66284.01
Iteration:   2440, Loss function: 4.018, Average Loss: 4.344, avg. samples / sec: 66287.03
Iteration:   2440, Loss function: 3.990, Average Loss: 4.349, avg. samples / sec: 66302.94
Iteration:   2440, Loss function: 4.355, Average Loss: 4.344, avg. samples / sec: 66193.28
Iteration:   2440, Loss function: 4.749, Average Loss: 4.371, avg. samples / sec: 66234.29
Iteration:   2440, Loss function: 4.310, Average Loss: 4.338, avg. samples / sec: 66200.28
Iteration:   2440, Loss function: 4.050, Average Loss: 4.349, avg. samples / sec: 66105.63
Iteration:   2440, Loss function: 3.341, Average Loss: 4.344, avg. samples / sec: 66036.96
Iteration:   2440, Loss function: 4.247, Average Loss: 4.364, avg. samples / sec: 66166.93
Iteration:   2440, Loss function: 4.962, Average Loss: 4.377, avg. samples / sec: 66125.17
Iteration:   2440, Loss function: 4.649, Average Loss: 4.340, avg. samples / sec: 66148.76
Iteration:   2440, Loss function: 3.855, Average Loss: 4.347, avg. samples / sec: 66143.24
Iteration:   2440, Loss function: 3.419, Average Loss: 4.367, avg. samples / sec: 66113.70
Iteration:   2440, Loss function: 3.933, Average Loss: 4.348, avg. samples / sec: 66009.00
Iteration:   2440, Loss function: 3.945, Average Loss: 4.360, avg. samples / sec: 66106.66
Iteration:   2440, Loss function: 5.050, Average Loss: 4.336, avg. samples / sec: 66196.15
Iteration:   2440, Loss function: 5.025, Average Loss: 4.371, avg. samples / sec: 66152.83
Iteration:   2440, Loss function: 4.280, Average Loss: 4.356, avg. samples / sec: 66080.74
:::MLL 1558651924.316 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558651924.316 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.948, Average Loss: 4.353, avg. samples / sec: 65589.53
Iteration:   2460, Loss function: 4.973, Average Loss: 4.340, avg. samples / sec: 65384.03
Iteration:   2460, Loss function: 3.975, Average Loss: 4.343, avg. samples / sec: 65522.38
Iteration:   2460, Loss function: 4.138, Average Loss: 4.338, avg. samples / sec: 65603.27
Iteration:   2460, Loss function: 3.669, Average Loss: 4.357, avg. samples / sec: 65487.76
Iteration:   2460, Loss function: 4.241, Average Loss: 4.342, avg. samples / sec: 65513.76
Iteration:   2460, Loss function: 4.151, Average Loss: 4.343, avg. samples / sec: 65635.26
Iteration:   2460, Loss function: 5.078, Average Loss: 4.330, avg. samples / sec: 65632.02
Iteration:   2460, Loss function: 3.914, Average Loss: 4.337, avg. samples / sec: 65378.30
Iteration:   2460, Loss function: 3.604, Average Loss: 4.351, avg. samples / sec: 65490.23
Iteration:   2460, Loss function: 4.185, Average Loss: 4.344, avg. samples / sec: 65497.62
Iteration:   2460, Loss function: 3.699, Average Loss: 4.343, avg. samples / sec: 65558.62
Iteration:   2460, Loss function: 3.840, Average Loss: 4.335, avg. samples / sec: 65513.85
Iteration:   2460, Loss function: 4.199, Average Loss: 4.382, avg. samples / sec: 65481.98
Iteration:   2460, Loss function: 4.409, Average Loss: 4.360, avg. samples / sec: 65570.09
Iteration:   2460, Loss function: 5.698, Average Loss: 4.361, avg. samples / sec: 65546.61
Iteration:   2460, Loss function: 4.039, Average Loss: 4.359, avg. samples / sec: 65436.71
Iteration:   2460, Loss function: 5.169, Average Loss: 4.342, avg. samples / sec: 65548.89
Iteration:   2460, Loss function: 4.364, Average Loss: 4.368, avg. samples / sec: 65541.09
Iteration:   2460, Loss function: 2.840, Average Loss: 4.361, avg. samples / sec: 65410.19
Iteration:   2460, Loss function: 4.148, Average Loss: 4.335, avg. samples / sec: 65501.52
Iteration:   2460, Loss function: 3.697, Average Loss: 4.337, avg. samples / sec: 65457.31
Iteration:   2460, Loss function: 3.537, Average Loss: 4.364, avg. samples / sec: 65477.84
Iteration:   2460, Loss function: 4.468, Average Loss: 4.337, avg. samples / sec: 65425.38
Iteration:   2460, Loss function: 5.105, Average Loss: 4.351, avg. samples / sec: 65392.50
Iteration:   2460, Loss function: 3.483, Average Loss: 4.366, avg. samples / sec: 65381.91
Iteration:   2460, Loss function: 2.906, Average Loss: 4.360, avg. samples / sec: 65424.40
Iteration:   2460, Loss function: 4.036, Average Loss: 4.335, avg. samples / sec: 65447.37
Iteration:   2460, Loss function: 3.136, Average Loss: 4.363, avg. samples / sec: 65527.41
Iteration:   2460, Loss function: 5.712, Average Loss: 4.351, avg. samples / sec: 65496.22
Iteration:   2480, Loss function: 4.276, Average Loss: 4.330, avg. samples / sec: 66192.51
Iteration:   2480, Loss function: 4.648, Average Loss: 4.347, avg. samples / sec: 66136.10
Iteration:   2480, Loss function: 3.244, Average Loss: 4.338, avg. samples / sec: 66137.31
Iteration:   2480, Loss function: 4.421, Average Loss: 4.374, avg. samples / sec: 66101.14
Iteration:   2480, Loss function: 4.404, Average Loss: 4.329, avg. samples / sec: 66089.05
Iteration:   2480, Loss function: 5.385, Average Loss: 4.359, avg. samples / sec: 66186.01
Iteration:   2480, Loss function: 4.532, Average Loss: 4.364, avg. samples / sec: 66130.17
Iteration:   2480, Loss function: 3.563, Average Loss: 4.343, avg. samples / sec: 66177.25
Iteration:   2480, Loss function: 3.805, Average Loss: 4.354, avg. samples / sec: 66027.03
Iteration:   2480, Loss function: 5.511, Average Loss: 4.341, avg. samples / sec: 66013.51
Iteration:   2480, Loss function: 2.659, Average Loss: 4.347, avg. samples / sec: 65943.15
Iteration:   2480, Loss function: 2.802, Average Loss: 4.335, avg. samples / sec: 66027.92
Iteration:   2480, Loss function: 4.500, Average Loss: 4.339, avg. samples / sec: 66031.64
Iteration:   2480, Loss function: 4.181, Average Loss: 4.341, avg. samples / sec: 66087.53
Iteration:   2480, Loss function: 4.530, Average Loss: 4.352, avg. samples / sec: 66081.05
Iteration:   2480, Loss function: 4.367, Average Loss: 4.331, avg. samples / sec: 65960.52
Iteration:   2480, Loss function: 4.312, Average Loss: 4.338, avg. samples / sec: 66035.32
Iteration:   2480, Loss function: 5.184, Average Loss: 4.357, avg. samples / sec: 66159.01
Iteration:   2480, Loss function: 4.055, Average Loss: 4.333, avg. samples / sec: 65920.97
Iteration:   2480, Loss function: 4.177, Average Loss: 4.332, avg. samples / sec: 66043.86
Iteration:   2480, Loss function: 4.761, Average Loss: 4.332, avg. samples / sec: 66130.20
Iteration:   2480, Loss function: 2.969, Average Loss: 4.355, avg. samples / sec: 66013.51
Iteration:   2480, Loss function: 3.656, Average Loss: 4.351, avg. samples / sec: 66201.18
Iteration:   2480, Loss function: 5.082, Average Loss: 4.357, avg. samples / sec: 66029.93
Iteration:   2480, Loss function: 3.571, Average Loss: 4.350, avg. samples / sec: 65978.37
Iteration:   2480, Loss function: 4.835, Average Loss: 4.358, avg. samples / sec: 65947.96
Iteration:   2480, Loss function: 3.237, Average Loss: 4.353, avg. samples / sec: 66097.57
Iteration:   2480, Loss function: 4.069, Average Loss: 4.328, avg. samples / sec: 65960.34
Iteration:   2480, Loss function: 3.893, Average Loss: 4.326, avg. samples / sec: 65961.60
Iteration:   2480, Loss function: 4.546, Average Loss: 4.335, avg. samples / sec: 65892.24
Iteration:   2500, Loss function: 2.981, Average Loss: 4.321, avg. samples / sec: 66281.64
Iteration:   2500, Loss function: 3.908, Average Loss: 4.342, avg. samples / sec: 66107.52
Iteration:   2500, Loss function: 2.976, Average Loss: 4.332, avg. samples / sec: 65998.80
Iteration:   2500, Loss function: 2.763, Average Loss: 4.339, avg. samples / sec: 66056.03
Iteration:   2500, Loss function: 3.718, Average Loss: 4.328, avg. samples / sec: 66216.89
Iteration:   2500, Loss function: 2.975, Average Loss: 4.351, avg. samples / sec: 66111.62
Iteration:   2500, Loss function: 4.590, Average Loss: 4.345, avg. samples / sec: 65944.29
Iteration:   2500, Loss function: 3.162, Average Loss: 4.325, avg. samples / sec: 65864.25
Iteration:   2500, Loss function: 3.536, Average Loss: 4.361, avg. samples / sec: 65957.90
Iteration:   2500, Loss function: 4.001, Average Loss: 4.348, avg. samples / sec: 66082.66
Iteration:   2500, Loss function: 3.088, Average Loss: 4.326, avg. samples / sec: 66020.41
Iteration:   2500, Loss function: 3.443, Average Loss: 4.358, avg. samples / sec: 66088.18
Iteration:   2500, Loss function: 4.399, Average Loss: 4.334, avg. samples / sec: 65957.71
Iteration:   2500, Loss function: 3.566, Average Loss: 4.354, avg. samples / sec: 65971.45
Iteration:   2500, Loss function: 3.530, Average Loss: 4.328, avg. samples / sec: 66028.88
Iteration:   2500, Loss function: 3.759, Average Loss: 4.335, avg. samples / sec: 65931.95
Iteration:   2500, Loss function: 3.813, Average Loss: 4.325, avg. samples / sec: 65985.63
Iteration:   2500, Loss function: 3.839, Average Loss: 4.350, avg. samples / sec: 65887.44
Iteration:   2500, Loss function: 4.913, Average Loss: 4.324, avg. samples / sec: 65960.49
Iteration:   2500, Loss function: 4.356, Average Loss: 4.349, avg. samples / sec: 65929.17
Iteration:   2500, Loss function: 3.873, Average Loss: 4.336, avg. samples / sec: 65917.30
Iteration:   2500, Loss function: 4.267, Average Loss: 4.331, avg. samples / sec: 65896.80
Iteration:   2500, Loss function: 3.401, Average Loss: 4.346, avg. samples / sec: 66001.05
Iteration:   2500, Loss function: 4.196, Average Loss: 4.368, avg. samples / sec: 65843.26
Iteration:   2500, Loss function: 4.577, Average Loss: 4.344, avg. samples / sec: 65989.09
Iteration:   2500, Loss function: 3.978, Average Loss: 4.357, avg. samples / sec: 65809.10
Iteration:   2500, Loss function: 4.530, Average Loss: 4.354, avg. samples / sec: 65939.78
Iteration:   2500, Loss function: 3.873, Average Loss: 4.332, avg. samples / sec: 65858.15
Iteration:   2500, Loss function: 3.965, Average Loss: 4.325, avg. samples / sec: 65783.33
Iteration:   2500, Loss function: 5.922, Average Loss: 4.329, avg. samples / sec: 65931.42
:::MLL 1558651926.101 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558651926.102 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 3.510, Average Loss: 4.331, avg. samples / sec: 65664.34
Iteration:   2520, Loss function: 3.806, Average Loss: 4.342, avg. samples / sec: 65848.62
Iteration:   2520, Loss function: 3.632, Average Loss: 4.320, avg. samples / sec: 65733.07
Iteration:   2520, Loss function: 3.938, Average Loss: 4.338, avg. samples / sec: 65850.15
Iteration:   2520, Loss function: 3.916, Average Loss: 4.333, avg. samples / sec: 65591.36
Iteration:   2520, Loss function: 5.036, Average Loss: 4.339, avg. samples / sec: 65677.50
Iteration:   2520, Loss function: 3.067, Average Loss: 4.366, avg. samples / sec: 65826.65
Iteration:   2520, Loss function: 3.450, Average Loss: 4.319, avg. samples / sec: 65749.60
Iteration:   2520, Loss function: 3.927, Average Loss: 4.346, avg. samples / sec: 65733.71
Iteration:   2520, Loss function: 4.287, Average Loss: 4.327, avg. samples / sec: 65776.15
Iteration:   2520, Loss function: 4.208, Average Loss: 4.335, avg. samples / sec: 65595.57
Iteration:   2520, Loss function: 4.814, Average Loss: 4.328, avg. samples / sec: 65758.74
Iteration:   2520, Loss function: 5.468, Average Loss: 4.355, avg. samples / sec: 65668.35
Iteration:   2520, Loss function: 3.731, Average Loss: 4.351, avg. samples / sec: 65672.11
Iteration:   2520, Loss function: 3.082, Average Loss: 4.318, avg. samples / sec: 65624.35
Iteration:   2520, Loss function: 2.697, Average Loss: 4.318, avg. samples / sec: 65585.71
Iteration:   2520, Loss function: 3.972, Average Loss: 4.346, avg. samples / sec: 65735.03
Iteration:   2520, Loss function: 4.878, Average Loss: 4.331, avg. samples / sec: 65671.01
Iteration:   2520, Loss function: 3.999, Average Loss: 4.328, avg. samples / sec: 65788.55
Iteration:   2520, Loss function: 4.402, Average Loss: 4.323, avg. samples / sec: 65725.44
Iteration:   2520, Loss function: 2.936, Average Loss: 4.318, avg. samples / sec: 65616.19
Iteration:   2520, Loss function: 3.687, Average Loss: 4.313, avg. samples / sec: 65659.42
Iteration:   2520, Loss function: 3.580, Average Loss: 4.351, avg. samples / sec: 65700.83
Iteration:   2520, Loss function: 4.269, Average Loss: 4.348, avg. samples / sec: 65701.78
Iteration:   2520, Loss function: 3.701, Average Loss: 4.339, avg. samples / sec: 65541.15
Iteration:   2520, Loss function: 3.278, Average Loss: 4.340, avg. samples / sec: 65644.55
Iteration:   2520, Loss function: 3.681, Average Loss: 4.324, avg. samples / sec: 65655.26
Iteration:   2520, Loss function: 3.503, Average Loss: 4.342, avg. samples / sec: 65447.65
Iteration:   2520, Loss function: 3.833, Average Loss: 4.318, avg. samples / sec: 65306.20
Iteration:   2520, Loss function: 3.999, Average Loss: 4.329, avg. samples / sec: 65490.87
Iteration:   2540, Loss function: 3.867, Average Loss: 4.316, avg. samples / sec: 65927.57
Iteration:   2540, Loss function: 4.347, Average Loss: 4.323, avg. samples / sec: 65964.26
Iteration:   2540, Loss function: 4.295, Average Loss: 4.340, avg. samples / sec: 65974.36
Iteration:   2540, Loss function: 4.832, Average Loss: 4.309, avg. samples / sec: 66039.74
Iteration:   2540, Loss function: 4.159, Average Loss: 4.347, avg. samples / sec: 66031.11
Iteration:   2540, Loss function: 5.481, Average Loss: 4.333, avg. samples / sec: 65842.95
Iteration:   2540, Loss function: 4.551, Average Loss: 4.343, avg. samples / sec: 65883.77
Iteration:   2540, Loss function: 4.544, Average Loss: 4.333, avg. samples / sec: 66020.13
Iteration:   2540, Loss function: 2.891, Average Loss: 4.314, avg. samples / sec: 65905.18
Iteration:   2540, Loss function: 4.654, Average Loss: 4.308, avg. samples / sec: 66113.51
Iteration:   2540, Loss function: 2.411, Average Loss: 4.326, avg. samples / sec: 65894.65
Iteration:   2540, Loss function: 2.838, Average Loss: 4.327, avg. samples / sec: 65821.61
Iteration:   2540, Loss function: 3.874, Average Loss: 4.345, avg. samples / sec: 65832.04
Iteration:   2540, Loss function: 3.262, Average Loss: 4.313, avg. samples / sec: 65827.79
Iteration:   2540, Loss function: 3.282, Average Loss: 4.326, avg. samples / sec: 65782.99
Iteration:   2540, Loss function: 3.012, Average Loss: 4.328, avg. samples / sec: 65734.05
Iteration:   2540, Loss function: 3.368, Average Loss: 4.322, avg. samples / sec: 66013.98
Iteration:   2540, Loss function: 3.504, Average Loss: 4.317, avg. samples / sec: 65913.85
Iteration:   2540, Loss function: 3.541, Average Loss: 4.314, avg. samples / sec: 65901.73
Iteration:   2540, Loss function: 3.832, Average Loss: 4.323, avg. samples / sec: 66003.56
Iteration:   2540, Loss function: 3.465, Average Loss: 4.330, avg. samples / sec: 65694.16
Iteration:   2540, Loss function: 3.170, Average Loss: 4.360, avg. samples / sec: 65740.12
Iteration:   2540, Loss function: 3.190, Average Loss: 4.318, avg. samples / sec: 65881.92
Iteration:   2540, Loss function: 3.552, Average Loss: 4.344, avg. samples / sec: 65885.71
Iteration:   2540, Loss function: 2.976, Average Loss: 4.315, avg. samples / sec: 65746.07
Iteration:   2540, Loss function: 5.997, Average Loss: 4.341, avg. samples / sec: 65930.96
Iteration:   2540, Loss function: 4.405, Average Loss: 4.344, avg. samples / sec: 65772.06
Iteration:   2540, Loss function: 3.435, Average Loss: 4.331, avg. samples / sec: 65883.31
Iteration:   2540, Loss function: 3.616, Average Loss: 4.318, avg. samples / sec: 65760.28
Iteration:   2540, Loss function: 4.695, Average Loss: 4.330, avg. samples / sec: 65682.67
Iteration:   2560, Loss function: 3.626, Average Loss: 4.321, avg. samples / sec: 66328.40
Iteration:   2560, Loss function: 4.227, Average Loss: 4.335, avg. samples / sec: 66116.83
Iteration:   2560, Loss function: 3.710, Average Loss: 4.317, avg. samples / sec: 66221.99
Iteration:   2560, Loss function: 4.452, Average Loss: 4.333, avg. samples / sec: 66128.65
Iteration:   2560, Loss function: 5.392, Average Loss: 4.309, avg. samples / sec: 66250.70
Iteration:   2560, Loss function: 3.035, Average Loss: 4.307, avg. samples / sec: 66125.08
Iteration:   2560, Loss function: 4.933, Average Loss: 4.310, avg. samples / sec: 65988.07
Iteration:   2560, Loss function: 3.391, Average Loss: 4.324, avg. samples / sec: 66265.46
Iteration:   2560, Loss function: 4.306, Average Loss: 4.322, avg. samples / sec: 66143.52
Iteration:   2560, Loss function: 3.498, Average Loss: 4.324, avg. samples / sec: 66209.24
Iteration:   2560, Loss function: 3.124, Average Loss: 4.321, avg. samples / sec: 66131.16
Iteration:   2560, Loss function: 3.167, Average Loss: 4.312, avg. samples / sec: 66242.23
Iteration:   2560, Loss function: 3.710, Average Loss: 4.339, avg. samples / sec: 66169.04
Iteration:   2560, Loss function: 5.261, Average Loss: 4.337, avg. samples / sec: 66207.28
Iteration:   2560, Loss function: 3.988, Average Loss: 4.355, avg. samples / sec: 66156.21
Iteration:   2560, Loss function: 4.027, Average Loss: 4.326, avg. samples / sec: 66044.88
Iteration:   2560, Loss function: 3.453, Average Loss: 4.303, avg. samples / sec: 66085.05
Iteration:   2560, Loss function: 4.278, Average Loss: 4.317, avg. samples / sec: 66102.78
Iteration:   2560, Loss function: 4.233, Average Loss: 4.309, avg. samples / sec: 66100.24
Iteration:   2560, Loss function: 4.540, Average Loss: 4.346, avg. samples / sec: 66073.34
Iteration:   2560, Loss function: 4.338, Average Loss: 4.303, avg. samples / sec: 66012.31
Iteration:   2560, Loss function: 4.581, Average Loss: 4.330, avg. samples / sec: 66126.69
Iteration:   2560, Loss function: 4.438, Average Loss: 4.337, avg. samples / sec: 65931.98
Iteration:   2560, Loss function: 3.944, Average Loss: 4.304, avg. samples / sec: 66032.90
Iteration:   2560, Loss function: 4.454, Average Loss: 4.338, avg. samples / sec: 65941.20
Iteration:   2560, Loss function: 4.419, Average Loss: 4.302, avg. samples / sec: 65894.77
Iteration:   2560, Loss function: 3.889, Average Loss: 4.320, avg. samples / sec: 65990.79
Iteration:   2560, Loss function: 3.661, Average Loss: 4.320, avg. samples / sec: 65796.11
Iteration:   2560, Loss function: 6.081, Average Loss: 4.314, avg. samples / sec: 65975.81
Iteration:   2560, Loss function: 2.721, Average Loss: 4.335, avg. samples / sec: 66008.19
Iteration:   2580, Loss function: 3.547, Average Loss: 4.334, avg. samples / sec: 66144.63
Iteration:   2580, Loss function: 4.783, Average Loss: 4.303, avg. samples / sec: 66186.26
Iteration:   2580, Loss function: 3.908, Average Loss: 4.329, avg. samples / sec: 66303.93
Iteration:   2580, Loss function: 4.417, Average Loss: 4.302, avg. samples / sec: 66168.67
Iteration:   2580, Loss function: 4.868, Average Loss: 4.316, avg. samples / sec: 65999.14
Iteration:   2580, Loss function: 3.594, Average Loss: 4.292, avg. samples / sec: 66295.01
Iteration:   2580, Loss function: 4.986, Average Loss: 4.322, avg. samples / sec: 66174.51
Iteration:   2580, Loss function: 3.884, Average Loss: 4.315, avg. samples / sec: 66316.79
Iteration:   2580, Loss function: 4.265, Average Loss: 4.313, avg. samples / sec: 66076.47
Iteration:   2580, Loss function: 3.543, Average Loss: 4.345, avg. samples / sec: 66190.80
Iteration:   2580, Loss function: 3.836, Average Loss: 4.305, avg. samples / sec: 66199.88
Iteration:   2580, Loss function: 4.460, Average Loss: 4.318, avg. samples / sec: 66177.06
Iteration:   2580, Loss function: 3.941, Average Loss: 4.323, avg. samples / sec: 66085.58
Iteration:   2580, Loss function: 4.370, Average Loss: 4.317, avg. samples / sec: 66084.55
Iteration:   2580, Loss function: 4.454, Average Loss: 4.315, avg. samples / sec: 66070.74
Iteration:   2580, Loss function: 2.860, Average Loss: 4.324, avg. samples / sec: 66084.65
Iteration:   2580, Loss function: 3.236, Average Loss: 4.345, avg. samples / sec: 66091.46
Iteration:   2580, Loss function: 4.319, Average Loss: 4.306, avg. samples / sec: 66065.19
Iteration:   2580, Loss function: 4.016, Average Loss: 4.322, avg. samples / sec: 66153.02
Iteration:   2580, Loss function: 2.752, Average Loss: 4.312, avg. samples / sec: 66216.61
Iteration:   2580, Loss function: 3.507, Average Loss: 4.314, avg. samples / sec: 66225.73
Iteration:   2580, Loss function: 3.424, Average Loss: 4.306, avg. samples / sec: 65936.05
Iteration:   2580, Loss function: 5.757, Average Loss: 4.302, avg. samples / sec: 66060.76
Iteration:   2580, Loss function: 4.363, Average Loss: 4.329, avg. samples / sec: 65913.45
Iteration:   2580, Loss function: 3.389, Average Loss: 4.335, avg. samples / sec: 66179.67
Iteration:   2580, Loss function: 3.223, Average Loss: 4.328, avg. samples / sec: 66065.97
Iteration:   2580, Loss function: 3.972, Average Loss: 4.298, avg. samples / sec: 65980.13
Iteration:   2580, Loss function: 3.178, Average Loss: 4.332, avg. samples / sec: 65962.96
Iteration:   2580, Loss function: 4.046, Average Loss: 4.329, avg. samples / sec: 65943.64
Iteration:   2580, Loss function: 4.217, Average Loss: 4.302, avg. samples / sec: 65991.44
:::MLL 1558651927.886 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558651927.886 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 3.678, Average Loss: 4.293, avg. samples / sec: 65503.19
Iteration:   2600, Loss function: 4.011, Average Loss: 4.315, avg. samples / sec: 65487.79
Iteration:   2600, Loss function: 4.304, Average Loss: 4.297, avg. samples / sec: 65413.50
Iteration:   2600, Loss function: 4.149, Average Loss: 4.317, avg. samples / sec: 65514.06
Iteration:   2600, Loss function: 3.615, Average Loss: 4.324, avg. samples / sec: 65409.37
Iteration:   2600, Loss function: 5.692, Average Loss: 4.313, avg. samples / sec: 65484.05
Iteration:   2600, Loss function: 4.464, Average Loss: 4.341, avg. samples / sec: 65542.89
Iteration:   2600, Loss function: 2.556, Average Loss: 4.336, avg. samples / sec: 65474.04
Iteration:   2600, Loss function: 3.838, Average Loss: 4.313, avg. samples / sec: 65481.80
Iteration:   2600, Loss function: 3.007, Average Loss: 4.302, avg. samples / sec: 65444.24
Iteration:   2600, Loss function: 4.160, Average Loss: 4.309, avg. samples / sec: 65509.89
Iteration:   2600, Loss function: 3.305, Average Loss: 4.307, avg. samples / sec: 65504.50
Iteration:   2600, Loss function: 4.590, Average Loss: 4.290, avg. samples / sec: 65588.00
Iteration:   2600, Loss function: 3.937, Average Loss: 4.324, avg. samples / sec: 65585.93
Iteration:   2600, Loss function: 3.649, Average Loss: 4.315, avg. samples / sec: 65364.23
Iteration:   2600, Loss function: 3.870, Average Loss: 4.330, avg. samples / sec: 65553.25
Iteration:   2600, Loss function: 3.984, Average Loss: 4.303, avg. samples / sec: 65517.78
Iteration:   2600, Loss function: 4.561, Average Loss: 4.323, avg. samples / sec: 65566.61
Iteration:   2600, Loss function: 3.779, Average Loss: 4.332, avg. samples / sec: 65237.69
Iteration:   2600, Loss function: 3.293, Average Loss: 4.291, avg. samples / sec: 65322.51
Iteration:   2600, Loss function: 3.400, Average Loss: 4.294, avg. samples / sec: 65490.07
Iteration:   2600, Loss function: 4.989, Average Loss: 4.304, avg. samples / sec: 65322.36
Iteration:   2600, Loss function: 3.378, Average Loss: 4.329, avg. samples / sec: 65509.37
Iteration:   2600, Loss function: 5.406, Average Loss: 4.328, avg. samples / sec: 65495.74
Iteration:   2600, Loss function: 4.923, Average Loss: 4.315, avg. samples / sec: 65289.16
Iteration:   2600, Loss function: 4.778, Average Loss: 4.313, avg. samples / sec: 65349.41
Iteration:   2600, Loss function: 4.404, Average Loss: 4.304, avg. samples / sec: 65300.75
Iteration:   2600, Loss function: 3.269, Average Loss: 4.295, avg. samples / sec: 65545.11
Iteration:   2600, Loss function: 3.031, Average Loss: 4.303, avg. samples / sec: 65346.11
Iteration:   2600, Loss function: 5.069, Average Loss: 4.319, avg. samples / sec: 65303.47
Iteration:   2620, Loss function: 4.606, Average Loss: 4.289, avg. samples / sec: 65909.99
Iteration:   2620, Loss function: 4.506, Average Loss: 4.291, avg. samples / sec: 66007.82
Iteration:   2620, Loss function: 3.583, Average Loss: 4.318, avg. samples / sec: 65943.95
Iteration:   2620, Loss function: 4.655, Average Loss: 4.290, avg. samples / sec: 66061.10
Iteration:   2620, Loss function: 4.638, Average Loss: 4.301, avg. samples / sec: 66057.29
Iteration:   2620, Loss function: 5.354, Average Loss: 4.304, avg. samples / sec: 65917.08
Iteration:   2620, Loss function: 3.737, Average Loss: 4.302, avg. samples / sec: 65867.91
Iteration:   2620, Loss function: 4.078, Average Loss: 4.292, avg. samples / sec: 65738.01
Iteration:   2620, Loss function: 3.723, Average Loss: 4.299, avg. samples / sec: 66006.62
Iteration:   2620, Loss function: 3.676, Average Loss: 4.315, avg. samples / sec: 65843.35
Iteration:   2620, Loss function: 3.906, Average Loss: 4.324, avg. samples / sec: 65920.81
Iteration:   2620, Loss function: 3.720, Average Loss: 4.314, avg. samples / sec: 65816.33
Iteration:   2620, Loss function: 3.724, Average Loss: 4.300, avg. samples / sec: 65938.89
Iteration:   2620, Loss function: 2.747, Average Loss: 4.332, avg. samples / sec: 65803.20
Iteration:   2620, Loss function: 2.800, Average Loss: 4.307, avg. samples / sec: 65950.27
Iteration:   2620, Loss function: 4.369, Average Loss: 4.329, avg. samples / sec: 65925.75
Iteration:   2620, Loss function: 5.768, Average Loss: 4.310, avg. samples / sec: 65799.39
Iteration:   2620, Loss function: 3.834, Average Loss: 4.303, avg. samples / sec: 65937.62
Iteration:   2620, Loss function: 4.041, Average Loss: 4.295, avg. samples / sec: 65849.23
Iteration:   2620, Loss function: 4.979, Average Loss: 4.313, avg. samples / sec: 65714.47
Iteration:   2620, Loss function: 3.825, Average Loss: 4.311, avg. samples / sec: 66023.90
Iteration:   2620, Loss function: 3.193, Average Loss: 4.326, avg. samples / sec: 65931.39
Iteration:   2620, Loss function: 3.869, Average Loss: 4.291, avg. samples / sec: 65878.23
Iteration:   2620, Loss function: 3.956, Average Loss: 4.292, avg. samples / sec: 65860.71
Iteration:   2620, Loss function: 2.820, Average Loss: 4.285, avg. samples / sec: 65828.68
Iteration:   2620, Loss function: 2.361, Average Loss: 4.331, avg. samples / sec: 65745.89
Iteration:   2620, Loss function: 4.354, Average Loss: 4.320, avg. samples / sec: 65855.51
Iteration:   2620, Loss function: 3.530, Average Loss: 4.307, avg. samples / sec: 65828.44
Iteration:   2620, Loss function: 3.182, Average Loss: 4.318, avg. samples / sec: 65822.41
Iteration:   2620, Loss function: 4.100, Average Loss: 4.306, avg. samples / sec: 65736.14
Iteration:   2640, Loss function: 3.057, Average Loss: 4.289, avg. samples / sec: 66150.72
Iteration:   2640, Loss function: 4.412, Average Loss: 4.291, avg. samples / sec: 66066.15
Iteration:   2640, Loss function: 4.388, Average Loss: 4.300, avg. samples / sec: 66164.72
Iteration:   2640, Loss function: 4.033, Average Loss: 4.315, avg. samples / sec: 66107.62
Iteration:   2640, Loss function: 4.269, Average Loss: 4.298, avg. samples / sec: 66078.82
Iteration:   2640, Loss function: 4.272, Average Loss: 4.308, avg. samples / sec: 66138.73
Iteration:   2640, Loss function: 4.142, Average Loss: 4.295, avg. samples / sec: 66072.81
Iteration:   2640, Loss function: 4.308, Average Loss: 4.309, avg. samples / sec: 66044.82
Iteration:   2640, Loss function: 4.257, Average Loss: 4.299, avg. samples / sec: 66119.28
Iteration:   2640, Loss function: 3.627, Average Loss: 4.302, avg. samples / sec: 66097.54
Iteration:   2640, Loss function: 4.594, Average Loss: 4.326, avg. samples / sec: 66129.77
Iteration:   2640, Loss function: 3.381, Average Loss: 4.319, avg. samples / sec: 66116.18
Iteration:   2640, Loss function: 4.855, Average Loss: 4.293, avg. samples / sec: 66013.79
Iteration:   2640, Loss function: 3.514, Average Loss: 4.289, avg. samples / sec: 66101.91
Iteration:   2640, Loss function: 4.401, Average Loss: 4.294, avg. samples / sec: 65995.03
Iteration:   2640, Loss function: 3.828, Average Loss: 4.290, avg. samples / sec: 66108.73
Iteration:   2640, Loss function: 4.549, Average Loss: 4.327, avg. samples / sec: 66055.53
Iteration:   2640, Loss function: 3.514, Average Loss: 4.314, avg. samples / sec: 66009.80
Iteration:   2640, Loss function: 4.703, Average Loss: 4.318, avg. samples / sec: 65969.57
Iteration:   2640, Loss function: 4.140, Average Loss: 4.285, avg. samples / sec: 65919.27
Iteration:   2640, Loss function: 5.247, Average Loss: 4.290, avg. samples / sec: 65947.62
Iteration:   2640, Loss function: 3.719, Average Loss: 4.290, avg. samples / sec: 66019.23
Iteration:   2640, Loss function: 4.610, Average Loss: 4.327, avg. samples / sec: 65992.34
Iteration:   2640, Loss function: 2.958, Average Loss: 4.300, avg. samples / sec: 66048.19
Iteration:   2640, Loss function: 4.042, Average Loss: 4.304, avg. samples / sec: 66103.55
Iteration:   2640, Loss function: 3.401, Average Loss: 4.283, avg. samples / sec: 66025.73
Iteration:   2640, Loss function: 3.280, Average Loss: 4.295, avg. samples / sec: 65966.88
Iteration:   2640, Loss function: 4.817, Average Loss: 4.306, avg. samples / sec: 65973.71
Iteration:   2640, Loss function: 4.036, Average Loss: 4.319, avg. samples / sec: 65956.36
Iteration:   2640, Loss function: 4.748, Average Loss: 4.313, avg. samples / sec: 65970.19
:::MLL 1558651929.676 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558651929.677 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 5.044, Average Loss: 4.296, avg. samples / sec: 65168.10
Iteration:   2660, Loss function: 4.002, Average Loss: 4.290, avg. samples / sec: 65105.99
Iteration:   2660, Loss function: 4.197, Average Loss: 4.294, avg. samples / sec: 65222.02
Iteration:   2660, Loss function: 3.856, Average Loss: 4.301, avg. samples / sec: 65136.35
Iteration:   2660, Loss function: 4.543, Average Loss: 4.281, avg. samples / sec: 65282.02
Iteration:   2660, Loss function: 4.300, Average Loss: 4.325, avg. samples / sec: 65202.05
Iteration:   2660, Loss function: 3.600, Average Loss: 4.285, avg. samples / sec: 65163.67
Iteration:   2660, Loss function: 4.473, Average Loss: 4.294, avg. samples / sec: 65145.29
Iteration:   2660, Loss function: 3.707, Average Loss: 4.307, avg. samples / sec: 65199.09
Iteration:   2660, Loss function: 4.112, Average Loss: 4.292, avg. samples / sec: 65089.48
Iteration:   2660, Loss function: 5.055, Average Loss: 4.289, avg. samples / sec: 65032.71
Iteration:   2660, Loss function: 4.403, Average Loss: 4.288, avg. samples / sec: 65201.29
Iteration:   2660, Loss function: 4.133, Average Loss: 4.313, avg. samples / sec: 65136.02
Iteration:   2660, Loss function: 4.125, Average Loss: 4.321, avg. samples / sec: 65209.98
Iteration:   2660, Loss function: 5.115, Average Loss: 4.292, avg. samples / sec: 65189.23
Iteration:   2660, Loss function: 4.446, Average Loss: 4.308, avg. samples / sec: 65028.69
Iteration:   2660, Loss function: 4.346, Average Loss: 4.298, avg. samples / sec: 65206.96
Iteration:   2660, Loss function: 2.881, Average Loss: 4.317, avg. samples / sec: 65075.89
Iteration:   2660, Loss function: 4.130, Average Loss: 4.298, avg. samples / sec: 65170.45
Iteration:   2660, Loss function: 4.206, Average Loss: 4.305, avg. samples / sec: 65027.25
Iteration:   2660, Loss function: 4.572, Average Loss: 4.293, avg. samples / sec: 65161.77
Iteration:   2660, Loss function: 4.346, Average Loss: 4.289, avg. samples / sec: 65085.66
Iteration:   2660, Loss function: 2.673, Average Loss: 4.290, avg. samples / sec: 64970.02
Iteration:   2660, Loss function: 5.107, Average Loss: 4.312, avg. samples / sec: 65225.25
Iteration:   2660, Loss function: 5.180, Average Loss: 4.286, avg. samples / sec: 65005.98
Iteration:   2660, Loss function: 4.156, Average Loss: 4.281, avg. samples / sec: 64999.45
Iteration:   2660, Loss function: 3.178, Average Loss: 4.319, avg. samples / sec: 65127.17
Iteration:   2660, Loss function: 4.807, Average Loss: 4.279, avg. samples / sec: 65010.30
Iteration:   2660, Loss function: 4.593, Average Loss: 4.314, avg. samples / sec: 65005.29
Iteration:   2660, Loss function: 4.299, Average Loss: 4.305, avg. samples / sec: 64882.41
Iteration:   2680, Loss function: 3.439, Average Loss: 4.286, avg. samples / sec: 65876.69
Iteration:   2680, Loss function: 4.146, Average Loss: 4.314, avg. samples / sec: 66096.73
Iteration:   2680, Loss function: 4.438, Average Loss: 4.298, avg. samples / sec: 65900.38
Iteration:   2680, Loss function: 3.708, Average Loss: 4.320, avg. samples / sec: 65908.33
Iteration:   2680, Loss function: 5.792, Average Loss: 4.295, avg. samples / sec: 65784.22
Iteration:   2680, Loss function: 4.353, Average Loss: 4.291, avg. samples / sec: 65853.23
Iteration:   2680, Loss function: 4.106, Average Loss: 4.288, avg. samples / sec: 65883.56
Iteration:   2680, Loss function: 3.254, Average Loss: 4.293, avg. samples / sec: 65873.73
Iteration:   2680, Loss function: 3.509, Average Loss: 4.311, avg. samples / sec: 65898.68
Iteration:   2680, Loss function: 4.494, Average Loss: 4.287, avg. samples / sec: 65859.82
Iteration:   2680, Loss function: 3.764, Average Loss: 4.279, avg. samples / sec: 66018.40
Iteration:   2680, Loss function: 4.596, Average Loss: 4.276, avg. samples / sec: 65829.85
Iteration:   2680, Loss function: 3.751, Average Loss: 4.303, avg. samples / sec: 65880.88
Iteration:   2680, Loss function: 4.713, Average Loss: 4.303, avg. samples / sec: 65978.34
Iteration:   2680, Loss function: 4.340, Average Loss: 4.298, avg. samples / sec: 65933.58
Iteration:   2680, Loss function: 4.780, Average Loss: 4.313, avg. samples / sec: 65910.33
Iteration:   2680, Loss function: 4.310, Average Loss: 4.295, avg. samples / sec: 66053.46
Iteration:   2680, Loss function: 4.525, Average Loss: 4.284, avg. samples / sec: 65917.18
Iteration:   2680, Loss function: 5.120, Average Loss: 4.286, avg. samples / sec: 65784.59
Iteration:   2680, Loss function: 4.772, Average Loss: 4.292, avg. samples / sec: 65869.67
Iteration:   2680, Loss function: 5.356, Average Loss: 4.306, avg. samples / sec: 65787.38
Iteration:   2680, Loss function: 4.336, Average Loss: 4.286, avg. samples / sec: 65889.93
Iteration:   2680, Loss function: 3.585, Average Loss: 4.278, avg. samples / sec: 65766.75
Iteration:   2680, Loss function: 3.098, Average Loss: 4.294, avg. samples / sec: 65837.05
Iteration:   2680, Loss function: 2.813, Average Loss: 4.287, avg. samples / sec: 65831.88
Iteration:   2680, Loss function: 4.300, Average Loss: 4.281, avg. samples / sec: 65748.56
Iteration:   2680, Loss function: 4.763, Average Loss: 4.303, avg. samples / sec: 65928.28
Iteration:   2680, Loss function: 3.883, Average Loss: 4.276, avg. samples / sec: 65667.22
Iteration:   2680, Loss function: 2.530, Average Loss: 4.275, avg. samples / sec: 65851.45
Iteration:   2680, Loss function: 3.446, Average Loss: 4.271, avg. samples / sec: 65869.88
Iteration:   2700, Loss function: 3.857, Average Loss: 4.288, avg. samples / sec: 66154.63
Iteration:   2700, Loss function: 4.192, Average Loss: 4.280, avg. samples / sec: 66048.69
Iteration:   2700, Loss function: 3.845, Average Loss: 4.286, avg. samples / sec: 66158.73
Iteration:   2700, Loss function: 4.142, Average Loss: 4.293, avg. samples / sec: 66103.71
Iteration:   2700, Loss function: 3.427, Average Loss: 4.295, avg. samples / sec: 66079.04
Iteration:   2700, Loss function: 4.419, Average Loss: 4.283, avg. samples / sec: 66214.25
Iteration:   2700, Loss function: 3.263, Average Loss: 4.282, avg. samples / sec: 66092.77
Iteration:   2700, Loss function: 3.267, Average Loss: 4.316, avg. samples / sec: 66045.81
Iteration:   2700, Loss function: 3.531, Average Loss: 4.280, avg. samples / sec: 66217.98
Iteration:   2700, Loss function: 3.137, Average Loss: 4.297, avg. samples / sec: 66148.20
Iteration:   2700, Loss function: 4.951, Average Loss: 4.290, avg. samples / sec: 66076.84
Iteration:   2700, Loss function: 4.426, Average Loss: 4.268, avg. samples / sec: 66285.88
Iteration:   2700, Loss function: 4.659, Average Loss: 4.309, avg. samples / sec: 66145.84
Iteration:   2700, Loss function: 4.795, Average Loss: 4.277, avg. samples / sec: 66182.16
Iteration:   2700, Loss function: 3.415, Average Loss: 4.300, avg. samples / sec: 66086.38
Iteration:   2700, Loss function: 3.496, Average Loss: 4.300, avg. samples / sec: 66147.30
Iteration:   2700, Loss function: 2.934, Average Loss: 4.291, avg. samples / sec: 66064.82
Iteration:   2700, Loss function: 4.758, Average Loss: 4.282, avg. samples / sec: 66194.12
Iteration:   2700, Loss function: 3.201, Average Loss: 4.274, avg. samples / sec: 66225.48
Iteration:   2700, Loss function: 4.354, Average Loss: 4.271, avg. samples / sec: 66061.69
Iteration:   2700, Loss function: 3.968, Average Loss: 4.280, avg. samples / sec: 66156.93
Iteration:   2700, Loss function: 4.125, Average Loss: 4.279, avg. samples / sec: 66118.94
Iteration:   2700, Loss function: 3.074, Average Loss: 4.282, avg. samples / sec: 66070.55
Iteration:   2700, Loss function: 3.632, Average Loss: 4.294, avg. samples / sec: 66145.38
Iteration:   2700, Loss function: 5.025, Average Loss: 4.275, avg. samples / sec: 66154.26
Iteration:   2700, Loss function: 4.130, Average Loss: 4.308, avg. samples / sec: 65939.75
Iteration:   2700, Loss function: 4.758, Average Loss: 4.291, avg. samples / sec: 66055.10
Iteration:   2700, Loss function: 4.334, Average Loss: 4.298, avg. samples / sec: 66013.45
Iteration:   2700, Loss function: 3.887, Average Loss: 4.282, avg. samples / sec: 65909.01
Iteration:   2700, Loss function: 4.806, Average Loss: 4.316, avg. samples / sec: 65811.13
Iteration:   2720, Loss function: 3.608, Average Loss: 4.275, avg. samples / sec: 66100.24
Iteration:   2720, Loss function: 3.773, Average Loss: 4.272, avg. samples / sec: 66201.21
Iteration:   2720, Loss function: 3.484, Average Loss: 4.288, avg. samples / sec: 66011.69
Iteration:   2720, Loss function: 4.191, Average Loss: 4.317, avg. samples / sec: 66038.41
Iteration:   2720, Loss function: 3.393, Average Loss: 4.306, avg. samples / sec: 66187.22
Iteration:   2720, Loss function: 4.313, Average Loss: 4.289, avg. samples / sec: 65948.89
Iteration:   2720, Loss function: 4.510, Average Loss: 4.281, avg. samples / sec: 66013.45
Iteration:   2720, Loss function: 4.555, Average Loss: 4.277, avg. samples / sec: 65998.49
Iteration:   2720, Loss function: 3.534, Average Loss: 4.289, avg. samples / sec: 65944.91
Iteration:   2720, Loss function: 4.420, Average Loss: 4.277, avg. samples / sec: 66061.72
Iteration:   2720, Loss function: 3.300, Average Loss: 4.277, avg. samples / sec: 66115.96
Iteration:   2720, Loss function: 2.918, Average Loss: 4.266, avg. samples / sec: 65980.26
Iteration:   2720, Loss function: 3.793, Average Loss: 4.282, avg. samples / sec: 65931.82
Iteration:   2720, Loss function: 3.615, Average Loss: 4.295, avg. samples / sec: 66033.96
Iteration:   2720, Loss function: 3.288, Average Loss: 4.276, avg. samples / sec: 65929.29
Iteration:   2720, Loss function: 5.226, Average Loss: 4.299, avg. samples / sec: 66113.32
Iteration:   2720, Loss function: 4.833, Average Loss: 4.282, avg. samples / sec: 66048.66
Iteration:   2720, Loss function: 3.253, Average Loss: 4.271, avg. samples / sec: 66014.90
Iteration:   2720, Loss function: 4.248, Average Loss: 4.276, avg. samples / sec: 66143.08
Iteration:   2720, Loss function: 2.587, Average Loss: 4.293, avg. samples / sec: 65962.04
Iteration:   2720, Loss function: 4.011, Average Loss: 4.276, avg. samples / sec: 66000.99
Iteration:   2720, Loss function: 4.332, Average Loss: 4.298, avg. samples / sec: 65885.22
Iteration:   2720, Loss function: 4.398, Average Loss: 4.310, avg. samples / sec: 66114.13
Iteration:   2720, Loss function: 5.269, Average Loss: 4.293, avg. samples / sec: 65990.51
Iteration:   2720, Loss function: 4.615, Average Loss: 4.286, avg. samples / sec: 65855.85
Iteration:   2720, Loss function: 4.166, Average Loss: 4.268, avg. samples / sec: 65953.15
Iteration:   2720, Loss function: 3.528, Average Loss: 4.306, avg. samples / sec: 65871.61
Iteration:   2720, Loss function: 3.378, Average Loss: 4.282, avg. samples / sec: 65949.78
Iteration:   2720, Loss function: 3.059, Average Loss: 4.286, avg. samples / sec: 65974.79
Iteration:   2720, Loss function: 4.409, Average Loss: 4.271, avg. samples / sec: 65832.50
:::MLL 1558651931.461 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558651931.461 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 4.460, Average Loss: 4.281, avg. samples / sec: 65622.48
Iteration:   2740, Loss function: 4.699, Average Loss: 4.314, avg. samples / sec: 65573.63
Iteration:   2740, Loss function: 3.696, Average Loss: 4.276, avg. samples / sec: 65628.44
Iteration:   2740, Loss function: 4.304, Average Loss: 4.269, avg. samples / sec: 65683.44
Iteration:   2740, Loss function: 3.410, Average Loss: 4.265, avg. samples / sec: 65532.50
Iteration:   2740, Loss function: 3.872, Average Loss: 4.287, avg. samples / sec: 65586.69
Iteration:   2740, Loss function: 3.672, Average Loss: 4.271, avg. samples / sec: 65598.57
Iteration:   2740, Loss function: 3.595, Average Loss: 4.268, avg. samples / sec: 65442.48
Iteration:   2740, Loss function: 4.008, Average Loss: 4.264, avg. samples / sec: 65699.12
Iteration:   2740, Loss function: 3.465, Average Loss: 4.281, avg. samples / sec: 65570.06
Iteration:   2740, Loss function: 4.550, Average Loss: 4.279, avg. samples / sec: 65704.63
Iteration:   2740, Loss function: 2.566, Average Loss: 4.283, avg. samples / sec: 65678.51
Iteration:   2740, Loss function: 3.850, Average Loss: 4.277, avg. samples / sec: 65533.35
Iteration:   2740, Loss function: 3.834, Average Loss: 4.279, avg. samples / sec: 65725.65
Iteration:   2740, Loss function: 3.700, Average Loss: 4.274, avg. samples / sec: 65736.96
Iteration:   2740, Loss function: 4.885, Average Loss: 4.287, avg. samples / sec: 65624.47
Iteration:   2740, Loss function: 3.803, Average Loss: 4.278, avg. samples / sec: 65569.30
Iteration:   2740, Loss function: 4.524, Average Loss: 4.265, avg. samples / sec: 65576.68
Iteration:   2740, Loss function: 4.409, Average Loss: 4.288, avg. samples / sec: 65622.88
Iteration:   2740, Loss function: 3.643, Average Loss: 4.293, avg. samples / sec: 65558.04
Iteration:   2740, Loss function: 4.512, Average Loss: 4.292, avg. samples / sec: 65527.71
Iteration:   2740, Loss function: 3.807, Average Loss: 4.272, avg. samples / sec: 65499.51
Iteration:   2740, Loss function: 3.972, Average Loss: 4.268, avg. samples / sec: 65566.12
Iteration:   2740, Loss function: 3.682, Average Loss: 4.274, avg. samples / sec: 65462.18
Iteration:   2740, Loss function: 4.346, Average Loss: 4.297, avg. samples / sec: 65596.83
Iteration:   2740, Loss function: 3.411, Average Loss: 4.292, avg. samples / sec: 65543.04
Iteration:   2740, Loss function: 4.133, Average Loss: 4.267, avg. samples / sec: 65519.76
Iteration:   2740, Loss function: 3.964, Average Loss: 4.308, avg. samples / sec: 65533.90
Iteration:   2740, Loss function: 4.166, Average Loss: 4.260, avg. samples / sec: 65423.86
Iteration:   2740, Loss function: 3.986, Average Loss: 4.297, avg. samples / sec: 65366.08
Iteration:   2760, Loss function: 4.148, Average Loss: 4.276, avg. samples / sec: 66103.52
Iteration:   2760, Loss function: 4.712, Average Loss: 4.264, avg. samples / sec: 66156.74
Iteration:   2760, Loss function: 3.556, Average Loss: 4.276, avg. samples / sec: 66088.02
Iteration:   2760, Loss function: 4.878, Average Loss: 4.275, avg. samples / sec: 66151.68
Iteration:   2760, Loss function: 4.468, Average Loss: 4.267, avg. samples / sec: 66105.07
Iteration:   2760, Loss function: 4.287, Average Loss: 4.274, avg. samples / sec: 66115.22
Iteration:   2760, Loss function: 3.270, Average Loss: 4.283, avg. samples / sec: 66071.32
Iteration:   2760, Loss function: 4.208, Average Loss: 4.275, avg. samples / sec: 66079.87
Iteration:   2760, Loss function: 4.444, Average Loss: 4.270, avg. samples / sec: 66164.72
Iteration:   2760, Loss function: 3.701, Average Loss: 4.266, avg. samples / sec: 66141.71
Iteration:   2760, Loss function: 5.694, Average Loss: 4.266, avg. samples / sec: 66144.51
Iteration:   2760, Loss function: 3.659, Average Loss: 4.269, avg. samples / sec: 66156.31
Iteration:   2760, Loss function: 3.517, Average Loss: 4.278, avg. samples / sec: 66154.82
Iteration:   2760, Loss function: 2.954, Average Loss: 4.275, avg. samples / sec: 66066.06
Iteration:   2760, Loss function: 4.589, Average Loss: 4.307, avg. samples / sec: 65996.14
Iteration:   2760, Loss function: 4.171, Average Loss: 4.259, avg. samples / sec: 66064.91
Iteration:   2760, Loss function: 3.828, Average Loss: 4.287, avg. samples / sec: 66116.61
Iteration:   2760, Loss function: 5.492, Average Loss: 4.264, avg. samples / sec: 66000.16
Iteration:   2760, Loss function: 2.919, Average Loss: 4.274, avg. samples / sec: 66048.60
Iteration:   2760, Loss function: 3.124, Average Loss: 4.304, avg. samples / sec: 66183.77
Iteration:   2760, Loss function: 3.605, Average Loss: 4.293, avg. samples / sec: 66180.29
Iteration:   2760, Loss function: 4.610, Average Loss: 4.283, avg. samples / sec: 66117.57
Iteration:   2760, Loss function: 4.092, Average Loss: 4.258, avg. samples / sec: 66145.72
Iteration:   2760, Loss function: 4.820, Average Loss: 4.275, avg. samples / sec: 66004.27
Iteration:   2760, Loss function: 3.650, Average Loss: 4.291, avg. samples / sec: 66039.06
Iteration:   2760, Loss function: 3.184, Average Loss: 4.274, avg. samples / sec: 65992.31
Iteration:   2760, Loss function: 3.556, Average Loss: 4.260, avg. samples / sec: 66088.12
Iteration:   2760, Loss function: 4.335, Average Loss: 4.269, avg. samples / sec: 65963.98
Iteration:   2760, Loss function: 4.141, Average Loss: 4.292, avg. samples / sec: 66044.39
Iteration:   2760, Loss function: 3.525, Average Loss: 4.256, avg. samples / sec: 65871.98
Iteration:   2780, Loss function: 3.356, Average Loss: 4.272, avg. samples / sec: 66092.49
Iteration:   2780, Loss function: 4.400, Average Loss: 4.263, avg. samples / sec: 65986.31
Iteration:   2780, Loss function: 4.761, Average Loss: 4.271, avg. samples / sec: 66081.92
Iteration:   2780, Loss function: 3.884, Average Loss: 4.255, avg. samples / sec: 66082.76
Iteration:   2780, Loss function: 3.872, Average Loss: 4.288, avg. samples / sec: 66135.01
Iteration:   2780, Loss function: 3.614, Average Loss: 4.305, avg. samples / sec: 66032.29
Iteration:   2780, Loss function: 4.573, Average Loss: 4.262, avg. samples / sec: 66043.46
Iteration:   2780, Loss function: 3.656, Average Loss: 4.301, avg. samples / sec: 66046.99
Iteration:   2780, Loss function: 4.691, Average Loss: 4.277, avg. samples / sec: 66038.23
Iteration:   2780, Loss function: 3.864, Average Loss: 4.264, avg. samples / sec: 65990.36
Iteration:   2780, Loss function: 4.419, Average Loss: 4.258, avg. samples / sec: 66156.59
Iteration:   2780, Loss function: 4.090, Average Loss: 4.282, avg. samples / sec: 65953.48
Iteration:   2780, Loss function: 4.351, Average Loss: 4.268, avg. samples / sec: 66118.81
Iteration:   2780, Loss function: 3.909, Average Loss: 4.259, avg. samples / sec: 65942.19
Iteration:   2780, Loss function: 3.600, Average Loss: 4.272, avg. samples / sec: 65965.74
Iteration:   2780, Loss function: 2.895, Average Loss: 4.272, avg. samples / sec: 65834.37
Iteration:   2780, Loss function: 4.809, Average Loss: 4.280, avg. samples / sec: 66049.96
Iteration:   2780, Loss function: 4.061, Average Loss: 4.275, avg. samples / sec: 65871.30
Iteration:   2780, Loss function: 4.115, Average Loss: 4.259, avg. samples / sec: 66077.67
Iteration:   2780, Loss function: 5.316, Average Loss: 4.268, avg. samples / sec: 66080.03
Iteration:   2780, Loss function: 3.972, Average Loss: 4.277, avg. samples / sec: 65909.75
Iteration:   2780, Loss function: 4.662, Average Loss: 4.272, avg. samples / sec: 66001.21
Iteration:   2780, Loss function: 3.682, Average Loss: 4.264, avg. samples / sec: 65881.37
Iteration:   2780, Loss function: 3.949, Average Loss: 4.287, avg. samples / sec: 65946.85
Iteration:   2780, Loss function: 3.344, Average Loss: 4.261, avg. samples / sec: 65860.25
Iteration:   2780, Loss function: 4.810, Average Loss: 4.260, avg. samples / sec: 65958.45
Iteration:   2780, Loss function: 4.685, Average Loss: 4.268, avg. samples / sec: 65817.86
Iteration:   2780, Loss function: 4.054, Average Loss: 4.281, avg. samples / sec: 65812.33
Iteration:   2780, Loss function: 5.741, Average Loss: 4.287, avg. samples / sec: 65907.53
Iteration:   2780, Loss function: 4.823, Average Loss: 4.268, avg. samples / sec: 65736.14
:::MLL 1558651933.247 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558651933.248 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 4.457, Average Loss: 4.272, avg. samples / sec: 65674.10
Iteration:   2800, Loss function: 3.911, Average Loss: 4.252, avg. samples / sec: 65653.88
Iteration:   2800, Loss function: 2.752, Average Loss: 4.266, avg. samples / sec: 65685.40
Iteration:   2800, Loss function: 4.312, Average Loss: 4.282, avg. samples / sec: 65718.11
Iteration:   2800, Loss function: 3.723, Average Loss: 4.258, avg. samples / sec: 65672.30
Iteration:   2800, Loss function: 4.258, Average Loss: 4.281, avg. samples / sec: 65793.03
Iteration:   2800, Loss function: 3.502, Average Loss: 4.279, avg. samples / sec: 65562.22
Iteration:   2800, Loss function: 3.927, Average Loss: 4.270, avg. samples / sec: 65586.39
Iteration:   2800, Loss function: 3.168, Average Loss: 4.266, avg. samples / sec: 65438.86
Iteration:   2800, Loss function: 4.849, Average Loss: 4.299, avg. samples / sec: 65526.98
Iteration:   2800, Loss function: 2.790, Average Loss: 4.243, avg. samples / sec: 65461.42
Iteration:   2800, Loss function: 3.696, Average Loss: 4.261, avg. samples / sec: 65501.82
Iteration:   2800, Loss function: 4.243, Average Loss: 4.283, avg. samples / sec: 65490.65
Iteration:   2800, Loss function: 3.774, Average Loss: 4.276, avg. samples / sec: 65540.27
Iteration:   2800, Loss function: 5.078, Average Loss: 4.269, avg. samples / sec: 65567.44
Iteration:   2800, Loss function: 4.399, Average Loss: 4.253, avg. samples / sec: 65414.66
Iteration:   2800, Loss function: 3.911, Average Loss: 4.270, avg. samples / sec: 65415.78
Iteration:   2800, Loss function: 3.489, Average Loss: 4.263, avg. samples / sec: 65506.03
Iteration:   2800, Loss function: 4.999, Average Loss: 4.265, avg. samples / sec: 65500.39
Iteration:   2800, Loss function: 4.420, Average Loss: 4.275, avg. samples / sec: 65678.54
Iteration:   2800, Loss function: 4.206, Average Loss: 4.248, avg. samples / sec: 65539.90
Iteration:   2800, Loss function: 4.482, Average Loss: 4.261, avg. samples / sec: 65535.06
Iteration:   2800, Loss function: 4.563, Average Loss: 4.270, avg. samples / sec: 65534.42
Iteration:   2800, Loss function: 3.237, Average Loss: 4.266, avg. samples / sec: 65636.76
Iteration:   2800, Loss function: 4.853, Average Loss: 4.262, avg. samples / sec: 65438.62
Iteration:   2800, Loss function: 3.269, Average Loss: 4.251, avg. samples / sec: 65567.07
Iteration:   2800, Loss function: 4.698, Average Loss: 4.260, avg. samples / sec: 65633.00
Iteration:   2800, Loss function: 3.872, Average Loss: 4.257, avg. samples / sec: 65402.60
Iteration:   2800, Loss function: 4.997, Average Loss: 4.293, avg. samples / sec: 65373.78
Iteration:   2800, Loss function: 3.194, Average Loss: 4.258, avg. samples / sec: 65408.80
Iteration:   2820, Loss function: 4.204, Average Loss: 4.283, avg. samples / sec: 66034.45
Iteration:   2820, Loss function: 4.840, Average Loss: 4.257, avg. samples / sec: 65871.76
Iteration:   2820, Loss function: 3.200, Average Loss: 4.272, avg. samples / sec: 65835.11
Iteration:   2820, Loss function: 5.058, Average Loss: 4.269, avg. samples / sec: 65819.31
Iteration:   2820, Loss function: 4.372, Average Loss: 4.265, avg. samples / sec: 65679.22
Iteration:   2820, Loss function: 3.990, Average Loss: 4.260, avg. samples / sec: 65944.84
Iteration:   2820, Loss function: 3.700, Average Loss: 4.297, avg. samples / sec: 65808.52
Iteration:   2820, Loss function: 5.045, Average Loss: 4.267, avg. samples / sec: 65786.92
Iteration:   2820, Loss function: 4.242, Average Loss: 4.251, avg. samples / sec: 66029.22
Iteration:   2820, Loss function: 4.191, Average Loss: 4.245, avg. samples / sec: 65825.12
Iteration:   2820, Loss function: 3.434, Average Loss: 4.265, avg. samples / sec: 65845.08
Iteration:   2820, Loss function: 3.553, Average Loss: 4.252, avg. samples / sec: 65850.37
Iteration:   2820, Loss function: 4.639, Average Loss: 4.247, avg. samples / sec: 65780.66
Iteration:   2820, Loss function: 3.770, Average Loss: 4.272, avg. samples / sec: 65772.03
Iteration:   2820, Loss function: 5.753, Average Loss: 4.263, avg. samples / sec: 65750.31
Iteration:   2820, Loss function: 5.062, Average Loss: 4.261, avg. samples / sec: 65781.43
Iteration:   2820, Loss function: 4.043, Average Loss: 4.279, avg. samples / sec: 65672.15
Iteration:   2820, Loss function: 3.787, Average Loss: 4.253, avg. samples / sec: 65704.02
Iteration:   2820, Loss function: 3.397, Average Loss: 4.248, avg. samples / sec: 65611.79
Iteration:   2820, Loss function: 3.973, Average Loss: 4.263, avg. samples / sec: 65651.95
Iteration:   2820, Loss function: 3.705, Average Loss: 4.245, avg. samples / sec: 65814.27
Iteration:   2820, Loss function: 4.478, Average Loss: 4.267, avg. samples / sec: 65755.86
Iteration:   2820, Loss function: 4.211, Average Loss: 4.258, avg. samples / sec: 65745.34
Iteration:   2820, Loss function: 4.641, Average Loss: 4.287, avg. samples / sec: 65675.79
Iteration:   2820, Loss function: 4.665, Average Loss: 4.269, avg. samples / sec: 65784.68
Iteration:   2820, Loss function: 4.385, Average Loss: 4.258, avg. samples / sec: 65762.00
Iteration:   2820, Loss function: 3.151, Average Loss: 4.268, avg. samples / sec: 65746.29
Iteration:   2820, Loss function: 3.955, Average Loss: 4.280, avg. samples / sec: 65690.48
Iteration:   2820, Loss function: 3.008, Average Loss: 4.239, avg. samples / sec: 65685.09
Iteration:   2820, Loss function: 4.574, Average Loss: 4.256, avg. samples / sec: 65742.12
Iteration:   2840, Loss function: 3.202, Average Loss: 4.261, avg. samples / sec: 66067.85
Iteration:   2840, Loss function: 4.051, Average Loss: 4.237, avg. samples / sec: 66189.49
Iteration:   2840, Loss function: 4.010, Average Loss: 4.258, avg. samples / sec: 66087.62
Iteration:   2840, Loss function: 4.552, Average Loss: 4.289, avg. samples / sec: 66053.58
Iteration:   2840, Loss function: 4.497, Average Loss: 4.265, avg. samples / sec: 66007.88
Iteration:   2840, Loss function: 4.034, Average Loss: 4.251, avg. samples / sec: 66261.88
Iteration:   2840, Loss function: 3.610, Average Loss: 4.238, avg. samples / sec: 66096.70
Iteration:   2840, Loss function: 3.962, Average Loss: 4.266, avg. samples / sec: 66131.16
Iteration:   2840, Loss function: 5.076, Average Loss: 4.265, avg. samples / sec: 66111.74
Iteration:   2840, Loss function: 3.224, Average Loss: 4.274, avg. samples / sec: 66089.88
Iteration:   2840, Loss function: 5.728, Average Loss: 4.237, avg. samples / sec: 66129.05
Iteration:   2840, Loss function: 4.548, Average Loss: 4.274, avg. samples / sec: 66025.57
Iteration:   2840, Loss function: 3.547, Average Loss: 4.256, avg. samples / sec: 65909.87
Iteration:   2840, Loss function: 3.597, Average Loss: 4.260, avg. samples / sec: 65935.12
Iteration:   2840, Loss function: 4.811, Average Loss: 4.253, avg. samples / sec: 66058.10
Iteration:   2840, Loss function: 4.458, Average Loss: 4.243, avg. samples / sec: 65987.08
Iteration:   2840, Loss function: 3.655, Average Loss: 4.255, avg. samples / sec: 66014.81
Iteration:   2840, Loss function: 4.019, Average Loss: 4.282, avg. samples / sec: 66047.76
Iteration:   2840, Loss function: 2.696, Average Loss: 4.260, avg. samples / sec: 66005.19
Iteration:   2840, Loss function: 3.258, Average Loss: 4.254, avg. samples / sec: 66042.25
Iteration:   2840, Loss function: 5.492, Average Loss: 4.267, avg. samples / sec: 66036.43
Iteration:   2840, Loss function: 4.163, Average Loss: 4.249, avg. samples / sec: 65988.01
Iteration:   2840, Loss function: 4.858, Average Loss: 4.253, avg. samples / sec: 65959.91
Iteration:   2840, Loss function: 3.702, Average Loss: 4.270, avg. samples / sec: 66041.04
Iteration:   2840, Loss function: 5.073, Average Loss: 4.282, avg. samples / sec: 65838.00
Iteration:   2840, Loss function: 3.670, Average Loss: 4.258, avg. samples / sec: 65991.87
Iteration:   2840, Loss function: 3.966, Average Loss: 4.259, avg. samples / sec: 65876.19
Iteration:   2840, Loss function: 3.394, Average Loss: 4.237, avg. samples / sec: 65897.54
Iteration:   2840, Loss function: 5.318, Average Loss: 4.261, avg. samples / sec: 65843.39
Iteration:   2840, Loss function: 4.341, Average Loss: 4.237, avg. samples / sec: 65875.52
Iteration:   2860, Loss function: 3.523, Average Loss: 4.254, avg. samples / sec: 66082.69
Iteration:   2860, Loss function: 3.938, Average Loss: 4.286, avg. samples / sec: 65926.73
Iteration:   2860, Loss function: 4.178, Average Loss: 4.253, avg. samples / sec: 65877.15
Iteration:   2860, Loss function: 4.365, Average Loss: 4.254, avg. samples / sec: 66018.40
Iteration:   2860, Loss function: 4.828, Average Loss: 4.228, avg. samples / sec: 65881.46
Iteration:   2860, Loss function: 5.629, Average Loss: 4.254, avg. samples / sec: 66042.47
Iteration:   2860, Loss function: 4.408, Average Loss: 4.255, avg. samples / sec: 65980.50
Iteration:   2860, Loss function: 4.728, Average Loss: 4.265, avg. samples / sec: 66027.37
Iteration:   2860, Loss function: 4.552, Average Loss: 4.246, avg. samples / sec: 65963.92
Iteration:   2860, Loss function: 3.783, Average Loss: 4.267, avg. samples / sec: 66007.02
Iteration:   2860, Loss function: 4.056, Average Loss: 4.232, avg. samples / sec: 65879.61
Iteration:   2860, Loss function: 3.419, Average Loss: 4.257, avg. samples / sec: 65819.83
Iteration:   2860, Loss function: 4.785, Average Loss: 4.252, avg. samples / sec: 66098.16
Iteration:   2860, Loss function: 4.846, Average Loss: 4.246, avg. samples / sec: 65965.65
Iteration:   2860, Loss function: 2.609, Average Loss: 4.261, avg. samples / sec: 65842.52
Iteration:   2860, Loss function: 3.429, Average Loss: 4.236, avg. samples / sec: 65920.01
Iteration:   2860, Loss function: 3.229, Average Loss: 4.256, avg. samples / sec: 66008.97
Iteration:   2860, Loss function: 4.666, Average Loss: 4.236, avg. samples / sec: 65944.26
Iteration:   2860, Loss function: 4.467, Average Loss: 4.271, avg. samples / sec: 65917.33
Iteration:   2860, Loss function: 4.576, Average Loss: 4.245, avg. samples / sec: 65937.62
Iteration:   2860, Loss function: 3.803, Average Loss: 4.244, avg. samples / sec: 65800.01
Iteration:   2860, Loss function: 3.468, Average Loss: 4.261, avg. samples / sec: 65799.95
Iteration:   2860, Loss function: 5.188, Average Loss: 4.234, avg. samples / sec: 66062.87
Iteration:   2860, Loss function: 3.247, Average Loss: 4.272, avg. samples / sec: 65852.34
Iteration:   2860, Loss function: 3.664, Average Loss: 4.276, avg. samples / sec: 65873.12
Iteration:   2860, Loss function: 3.250, Average Loss: 4.271, avg. samples / sec: 65775.44
Iteration:   2860, Loss function: 4.077, Average Loss: 4.248, avg. samples / sec: 65873.42
Iteration:   2860, Loss function: 3.404, Average Loss: 4.260, avg. samples / sec: 65763.56
Iteration:   2860, Loss function: 6.058, Average Loss: 4.231, avg. samples / sec: 65864.71
Iteration:   2860, Loss function: 3.201, Average Loss: 4.249, avg. samples / sec: 65810.98
:::MLL 1558651935.034 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558651935.034 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 3.190, Average Loss: 4.248, avg. samples / sec: 65525.67
Iteration:   2880, Loss function: 3.850, Average Loss: 4.247, avg. samples / sec: 65572.01
Iteration:   2880, Loss function: 3.469, Average Loss: 4.250, avg. samples / sec: 65557.80
Iteration:   2880, Loss function: 4.391, Average Loss: 4.233, avg. samples / sec: 65589.93
Iteration:   2880, Loss function: 4.388, Average Loss: 4.246, avg. samples / sec: 65423.40
Iteration:   2880, Loss function: 3.563, Average Loss: 4.257, avg. samples / sec: 65496.83
Iteration:   2880, Loss function: 5.128, Average Loss: 4.222, avg. samples / sec: 65486.79
Iteration:   2880, Loss function: 3.364, Average Loss: 4.250, avg. samples / sec: 65613.13
Iteration:   2880, Loss function: 4.051, Average Loss: 4.259, avg. samples / sec: 65569.75
Iteration:   2880, Loss function: 3.515, Average Loss: 4.280, avg. samples / sec: 65402.24
Iteration:   2880, Loss function: 5.521, Average Loss: 4.243, avg. samples / sec: 65592.49
Iteration:   2880, Loss function: 4.403, Average Loss: 4.246, avg. samples / sec: 65390.59
Iteration:   2880, Loss function: 3.178, Average Loss: 4.260, avg. samples / sec: 65420.24
Iteration:   2880, Loss function: 3.208, Average Loss: 4.224, avg. samples / sec: 65370.05
Iteration:   2880, Loss function: 4.582, Average Loss: 4.273, avg. samples / sec: 65563.56
Iteration:   2880, Loss function: 3.814, Average Loss: 4.241, avg. samples / sec: 65428.20
Iteration:   2880, Loss function: 4.321, Average Loss: 4.262, avg. samples / sec: 65456.19
Iteration:   2880, Loss function: 4.413, Average Loss: 4.246, avg. samples / sec: 65369.54
Iteration:   2880, Loss function: 3.960, Average Loss: 4.245, avg. samples / sec: 65432.09
Iteration:   2880, Loss function: 4.817, Average Loss: 4.236, avg. samples / sec: 65476.59
Iteration:   2880, Loss function: 4.594, Average Loss: 4.232, avg. samples / sec: 65414.99
Iteration:   2880, Loss function: 4.891, Average Loss: 4.233, avg. samples / sec: 65423.22
Iteration:   2880, Loss function: 4.387, Average Loss: 4.260, avg. samples / sec: 65518.69
Iteration:   2880, Loss function: 3.719, Average Loss: 4.265, avg. samples / sec: 65381.33
Iteration:   2880, Loss function: 4.476, Average Loss: 4.268, avg. samples / sec: 65483.14
Iteration:   2880, Loss function: 3.323, Average Loss: 4.238, avg. samples / sec: 65431.42
Iteration:   2880, Loss function: 3.305, Average Loss: 4.259, avg. samples / sec: 65371.93
Iteration:   2880, Loss function: 4.247, Average Loss: 4.225, avg. samples / sec: 65516.50
Iteration:   2880, Loss function: 3.219, Average Loss: 4.247, avg. samples / sec: 65214.51
Iteration:   2880, Loss function: 3.227, Average Loss: 4.245, avg. samples / sec: 65487.64
Iteration:   2900, Loss function: 3.655, Average Loss: 4.251, avg. samples / sec: 65972.07
Iteration:   2900, Loss function: 4.096, Average Loss: 4.222, avg. samples / sec: 65989.43
Iteration:   2900, Loss function: 4.680, Average Loss: 4.223, avg. samples / sec: 66094.04
Iteration:   2900, Loss function: 3.972, Average Loss: 4.238, avg. samples / sec: 65937.10
Iteration:   2900, Loss function: 4.936, Average Loss: 4.240, avg. samples / sec: 65962.99
Iteration:   2900, Loss function: 3.519, Average Loss: 4.258, avg. samples / sec: 66019.91
Iteration:   2900, Loss function: 4.071, Average Loss: 4.258, avg. samples / sec: 65963.95
Iteration:   2900, Loss function: 2.610, Average Loss: 4.243, avg. samples / sec: 65900.28
Iteration:   2900, Loss function: 2.761, Average Loss: 4.222, avg. samples / sec: 65850.52
Iteration:   2900, Loss function: 2.755, Average Loss: 4.246, avg. samples / sec: 65766.75
Iteration:   2900, Loss function: 4.707, Average Loss: 4.230, avg. samples / sec: 65917.67
Iteration:   2900, Loss function: 3.920, Average Loss: 4.259, avg. samples / sec: 65932.75
Iteration:   2900, Loss function: 3.451, Average Loss: 4.241, avg. samples / sec: 65743.22
Iteration:   2900, Loss function: 3.784, Average Loss: 4.277, avg. samples / sec: 65817.49
Iteration:   2900, Loss function: 3.672, Average Loss: 4.232, avg. samples / sec: 65927.23
Iteration:   2900, Loss function: 5.121, Average Loss: 4.246, avg. samples / sec: 65761.20
Iteration:   2900, Loss function: 5.638, Average Loss: 4.240, avg. samples / sec: 65814.11
Iteration:   2900, Loss function: 4.739, Average Loss: 4.259, avg. samples / sec: 65829.21
Iteration:   2900, Loss function: 3.396, Average Loss: 4.241, avg. samples / sec: 65783.61
Iteration:   2900, Loss function: 5.406, Average Loss: 4.256, avg. samples / sec: 65775.10
Iteration:   2900, Loss function: 3.744, Average Loss: 4.231, avg. samples / sec: 65751.53
Iteration:   2900, Loss function: 3.966, Average Loss: 4.269, avg. samples / sec: 65828.35
Iteration:   2900, Loss function: 4.715, Average Loss: 4.242, avg. samples / sec: 65814.85
Iteration:   2900, Loss function: 4.205, Average Loss: 4.248, avg. samples / sec: 65804.00
Iteration:   2900, Loss function: 2.975, Average Loss: 4.245, avg. samples / sec: 65941.70
Iteration:   2900, Loss function: 5.439, Average Loss: 4.257, avg. samples / sec: 65823.76
Iteration:   2900, Loss function: 2.541, Average Loss: 4.227, avg. samples / sec: 65788.83
Iteration:   2900, Loss function: 4.654, Average Loss: 4.270, avg. samples / sec: 65841.14
Iteration:   2900, Loss function: 5.419, Average Loss: 4.232, avg. samples / sec: 65769.98
Iteration:   2900, Loss function: 4.189, Average Loss: 4.245, avg. samples / sec: 65828.90
Iteration:   2920, Loss function: 3.153, Average Loss: 4.238, avg. samples / sec: 66241.14
Iteration:   2920, Loss function: 4.191, Average Loss: 4.238, avg. samples / sec: 66154.48
Iteration:   2920, Loss function: 4.047, Average Loss: 4.277, avg. samples / sec: 66157.08
Iteration:   2920, Loss function: 3.627, Average Loss: 4.234, avg. samples / sec: 66242.85
Iteration:   2920, Loss function: 4.163, Average Loss: 4.235, avg. samples / sec: 66016.36
Iteration:   2920, Loss function: 3.980, Average Loss: 4.243, avg. samples / sec: 65949.29
Iteration:   2920, Loss function: 3.894, Average Loss: 4.215, avg. samples / sec: 66063.12
Iteration:   2920, Loss function: 4.347, Average Loss: 4.254, avg. samples / sec: 66137.93
Iteration:   2920, Loss function: 3.939, Average Loss: 4.244, avg. samples / sec: 66054.35
Iteration:   2920, Loss function: 3.356, Average Loss: 4.228, avg. samples / sec: 66136.34
Iteration:   2920, Loss function: 4.000, Average Loss: 4.251, avg. samples / sec: 66176.62
Iteration:   2920, Loss function: 4.502, Average Loss: 4.239, avg. samples / sec: 66233.45
Iteration:   2920, Loss function: 3.485, Average Loss: 4.240, avg. samples / sec: 65960.18
Iteration:   2920, Loss function: 3.248, Average Loss: 4.258, avg. samples / sec: 65966.94
Iteration:   2920, Loss function: 4.975, Average Loss: 4.220, avg. samples / sec: 65928.28
Iteration:   2920, Loss function: 3.116, Average Loss: 4.266, avg. samples / sec: 66086.75
Iteration:   2920, Loss function: 3.812, Average Loss: 4.230, avg. samples / sec: 66020.28
Iteration:   2920, Loss function: 4.194, Average Loss: 4.251, avg. samples / sec: 65929.57
Iteration:   2920, Loss function: 4.074, Average Loss: 4.229, avg. samples / sec: 66019.76
Iteration:   2920, Loss function: 2.929, Average Loss: 4.239, avg. samples / sec: 66010.60
Iteration:   2920, Loss function: 4.375, Average Loss: 4.215, avg. samples / sec: 65874.44
Iteration:   2920, Loss function: 4.068, Average Loss: 4.264, avg. samples / sec: 66096.11
Iteration:   2920, Loss function: 4.258, Average Loss: 4.234, avg. samples / sec: 66033.62
Iteration:   2920, Loss function: 4.198, Average Loss: 4.241, avg. samples / sec: 65895.57
Iteration:   2920, Loss function: 3.566, Average Loss: 4.241, avg. samples / sec: 65961.85
Iteration:   2920, Loss function: 2.935, Average Loss: 4.257, avg. samples / sec: 65973.37
Iteration:   2920, Loss function: 4.380, Average Loss: 4.224, avg. samples / sec: 66046.89
Iteration:   2920, Loss function: 3.751, Average Loss: 4.248, avg. samples / sec: 66004.89
Iteration:   2920, Loss function: 4.638, Average Loss: 4.252, avg. samples / sec: 65883.68
Iteration:   2920, Loss function: 3.612, Average Loss: 4.231, avg. samples / sec: 66021.55
:::MLL 1558651936.820 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558651936.821 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.410, Average Loss: 4.239, avg. samples / sec: 65931.67
Iteration:   2940, Loss function: 4.821, Average Loss: 4.214, avg. samples / sec: 65964.04
Iteration:   2940, Loss function: 4.286, Average Loss: 4.213, avg. samples / sec: 65800.71
Iteration:   2940, Loss function: 4.504, Average Loss: 4.229, avg. samples / sec: 65941.45
Iteration:   2940, Loss function: 3.264, Average Loss: 4.220, avg. samples / sec: 65931.11
Iteration:   2940, Loss function: 4.624, Average Loss: 4.270, avg. samples / sec: 65718.94
Iteration:   2940, Loss function: 3.414, Average Loss: 4.230, avg. samples / sec: 65782.47
Iteration:   2940, Loss function: 3.886, Average Loss: 4.248, avg. samples / sec: 65741.23
Iteration:   2940, Loss function: 3.116, Average Loss: 4.226, avg. samples / sec: 65707.72
Iteration:   2940, Loss function: 4.675, Average Loss: 4.211, avg. samples / sec: 65801.85
Iteration:   2940, Loss function: 5.412, Average Loss: 4.240, avg. samples / sec: 65782.84
Iteration:   2940, Loss function: 3.672, Average Loss: 4.231, avg. samples / sec: 65786.31
Iteration:   2940, Loss function: 4.390, Average Loss: 4.236, avg. samples / sec: 65736.44
Iteration:   2940, Loss function: 3.800, Average Loss: 4.246, avg. samples / sec: 65816.91
Iteration:   2940, Loss function: 3.488, Average Loss: 4.248, avg. samples / sec: 65884.26
Iteration:   2940, Loss function: 4.407, Average Loss: 4.233, avg. samples / sec: 65611.58
Iteration:   2940, Loss function: 4.958, Average Loss: 4.257, avg. samples / sec: 65767.24
Iteration:   2940, Loss function: 4.364, Average Loss: 4.259, avg. samples / sec: 65764.11
Iteration:   2940, Loss function: 3.991, Average Loss: 4.229, avg. samples / sec: 65810.64
Iteration:   2940, Loss function: 5.044, Average Loss: 4.247, avg. samples / sec: 65872.41
Iteration:   2940, Loss function: 4.359, Average Loss: 4.233, avg. samples / sec: 65694.55
Iteration:   2940, Loss function: 3.704, Average Loss: 4.261, avg. samples / sec: 65745.98
Iteration:   2940, Loss function: 3.275, Average Loss: 4.224, avg. samples / sec: 65650.45
Iteration:   2940, Loss function: 3.698, Average Loss: 4.234, avg. samples / sec: 65792.11
Iteration:   2940, Loss function: 4.073, Average Loss: 4.228, avg. samples / sec: 65823.15
Iteration:   2940, Loss function: 3.935, Average Loss: 4.229, avg. samples / sec: 65586.17
Iteration:   2940, Loss function: 3.543, Average Loss: 4.230, avg. samples / sec: 65692.96
Iteration:   2940, Loss function: 3.809, Average Loss: 4.239, avg. samples / sec: 65686.35
Iteration:   2940, Loss function: 3.599, Average Loss: 4.243, avg. samples / sec: 65744.66
Iteration:   2940, Loss function: 3.953, Average Loss: 4.229, avg. samples / sec: 65441.72
Iteration:   2960, Loss function: 3.981, Average Loss: 4.229, avg. samples / sec: 65874.50
Iteration:   2960, Loss function: 2.849, Average Loss: 4.212, avg. samples / sec: 65805.75
Iteration:   2960, Loss function: 3.924, Average Loss: 4.225, avg. samples / sec: 65834.80
Iteration:   2960, Loss function: 3.747, Average Loss: 4.260, avg. samples / sec: 65793.50
Iteration:   2960, Loss function: 2.559, Average Loss: 4.226, avg. samples / sec: 65735.37
Iteration:   2960, Loss function: 4.175, Average Loss: 4.244, avg. samples / sec: 65798.96
Iteration:   2960, Loss function: 3.857, Average Loss: 4.221, avg. samples / sec: 65912.83
Iteration:   2960, Loss function: 3.570, Average Loss: 4.226, avg. samples / sec: 65847.78
Iteration:   2960, Loss function: 3.776, Average Loss: 4.226, avg. samples / sec: 65793.28
Iteration:   2960, Loss function: 4.574, Average Loss: 4.207, avg. samples / sec: 65708.55
Iteration:   2960, Loss function: 3.410, Average Loss: 4.252, avg. samples / sec: 65778.94
Iteration:   2960, Loss function: 4.213, Average Loss: 4.236, avg. samples / sec: 65762.49
Iteration:   2960, Loss function: 4.170, Average Loss: 4.227, avg. samples / sec: 65759.54
Iteration:   2960, Loss function: 5.182, Average Loss: 4.225, avg. samples / sec: 65771.88
Iteration:   2960, Loss function: 4.527, Average Loss: 4.203, avg. samples / sec: 65725.01
Iteration:   2960, Loss function: 4.731, Average Loss: 4.244, avg. samples / sec: 65788.92
Iteration:   2960, Loss function: 4.440, Average Loss: 4.225, avg. samples / sec: 65707.36
Iteration:   2960, Loss function: 4.204, Average Loss: 4.239, avg. samples / sec: 65703.50
Iteration:   2960, Loss function: 3.153, Average Loss: 4.225, avg. samples / sec: 65810.18
Iteration:   2960, Loss function: 4.046, Average Loss: 4.231, avg. samples / sec: 65875.18
Iteration:   2960, Loss function: 2.994, Average Loss: 4.229, avg. samples / sec: 65487.12
Iteration:   2960, Loss function: 3.627, Average Loss: 4.256, avg. samples / sec: 65789.50
Iteration:   2960, Loss function: 4.551, Average Loss: 4.207, avg. samples / sec: 65559.02
Iteration:   2960, Loss function: 2.903, Average Loss: 4.223, avg. samples / sec: 65821.06
Iteration:   2960, Loss function: 4.373, Average Loss: 4.254, avg. samples / sec: 65680.90
Iteration:   2960, Loss function: 3.212, Average Loss: 4.239, avg. samples / sec: 65809.26
Iteration:   2960, Loss function: 3.584, Average Loss: 4.225, avg. samples / sec: 65777.07
Iteration:   2960, Loss function: 4.263, Average Loss: 4.223, avg. samples / sec: 65744.17
Iteration:   2960, Loss function: 3.310, Average Loss: 4.223, avg. samples / sec: 65858.12
Iteration:   2960, Loss function: 3.679, Average Loss: 4.243, avg. samples / sec: 65571.77
Iteration:   2980, Loss function: 3.983, Average Loss: 4.204, avg. samples / sec: 66239.46
Iteration:   2980, Loss function: 4.315, Average Loss: 4.227, avg. samples / sec: 65997.96
Iteration:   2980, Loss function: 4.084, Average Loss: 4.221, avg. samples / sec: 66187.94
Iteration:   2980, Loss function: 3.940, Average Loss: 4.220, avg. samples / sec: 65961.73
Iteration:   2980, Loss function: 4.294, Average Loss: 4.229, avg. samples / sec: 66052.62
Iteration:   2980, Loss function: 3.789, Average Loss: 4.221, avg. samples / sec: 66001.18
Iteration:   2980, Loss function: 4.508, Average Loss: 4.219, avg. samples / sec: 66048.25
Iteration:   2980, Loss function: 4.064, Average Loss: 4.219, avg. samples / sec: 66024.61
Iteration:   2980, Loss function: 4.464, Average Loss: 4.224, avg. samples / sec: 66007.45
Iteration:   2980, Loss function: 3.359, Average Loss: 4.200, avg. samples / sec: 66025.17
Iteration:   2980, Loss function: 3.940, Average Loss: 4.235, avg. samples / sec: 66054.97
Iteration:   2980, Loss function: 3.999, Average Loss: 4.220, avg. samples / sec: 66112.70
Iteration:   2980, Loss function: 3.786, Average Loss: 4.245, avg. samples / sec: 65927.48
Iteration:   2980, Loss function: 4.099, Average Loss: 4.243, avg. samples / sec: 65943.73
Iteration:   2980, Loss function: 4.353, Average Loss: 4.224, avg. samples / sec: 66015.30
Iteration:   2980, Loss function: 3.269, Average Loss: 4.216, avg. samples / sec: 65892.40
Iteration:   2980, Loss function: 3.119, Average Loss: 4.257, avg. samples / sec: 65882.75
Iteration:   2980, Loss function: 3.897, Average Loss: 4.211, avg. samples / sec: 65818.72
Iteration:   2980, Loss function: 2.688, Average Loss: 4.217, avg. samples / sec: 65952.71
Iteration:   2980, Loss function: 3.410, Average Loss: 4.215, avg. samples / sec: 65931.58
Iteration:   2980, Loss function: 4.679, Average Loss: 4.235, avg. samples / sec: 66017.41
Iteration:   2980, Loss function: 4.582, Average Loss: 4.232, avg. samples / sec: 65974.45
Iteration:   2980, Loss function: 4.962, Average Loss: 4.215, avg. samples / sec: 65970.19
Iteration:   2980, Loss function: 4.389, Average Loss: 4.237, avg. samples / sec: 66086.60
Iteration:   2980, Loss function: 4.019, Average Loss: 4.203, avg. samples / sec: 65920.44
Iteration:   2980, Loss function: 3.245, Average Loss: 4.222, avg. samples / sec: 65913.20
Iteration:   2980, Loss function: 2.671, Average Loss: 4.221, avg. samples / sec: 66000.93
Iteration:   2980, Loss function: 5.317, Average Loss: 4.248, avg. samples / sec: 65964.38
Iteration:   2980, Loss function: 4.317, Average Loss: 4.238, avg. samples / sec: 65821.74
Iteration:   2980, Loss function: 5.056, Average Loss: 4.259, avg. samples / sec: 65866.47
Iteration:   3000, Loss function: 4.349, Average Loss: 4.214, avg. samples / sec: 66077.58
Iteration:   3000, Loss function: 3.271, Average Loss: 4.214, avg. samples / sec: 66049.49
Iteration:   3000, Loss function: 3.698, Average Loss: 4.248, avg. samples / sec: 66112.58
Iteration:   3000, Loss function: 2.951, Average Loss: 4.210, avg. samples / sec: 66171.71
Iteration:   3000, Loss function: 3.254, Average Loss: 4.220, avg. samples / sec: 65923.81
Iteration:   3000, Loss function: 4.331, Average Loss: 4.216, avg. samples / sec: 65928.62
Iteration:   3000, Loss function: 3.110, Average Loss: 4.227, avg. samples / sec: 66087.09
Iteration:   3000, Loss function: 3.850, Average Loss: 4.224, avg. samples / sec: 65931.61
Iteration:   3000, Loss function: 5.159, Average Loss: 4.221, avg. samples / sec: 65979.89
Iteration:   3000, Loss function: 4.612, Average Loss: 4.201, avg. samples / sec: 65925.62
Iteration:   3000, Loss function: 4.144, Average Loss: 4.213, avg. samples / sec: 66077.49
Iteration:   3000, Loss function: 4.901, Average Loss: 4.226, avg. samples / sec: 66052.90
Iteration:   3000, Loss function: 2.930, Average Loss: 4.226, avg. samples / sec: 65948.02
Iteration:   3000, Loss function: 4.724, Average Loss: 4.218, avg. samples / sec: 66096.92
Iteration:   3000, Loss function: 3.341, Average Loss: 4.223, avg. samples / sec: 65975.72
Iteration:   3000, Loss function: 4.559, Average Loss: 4.218, avg. samples / sec: 65853.42
Iteration:   3000, Loss function: 3.396, Average Loss: 4.210, avg. samples / sec: 65988.63
Iteration:   3000, Loss function: 3.462, Average Loss: 4.251, avg. samples / sec: 66121.70
Iteration:   3000, Loss function: 3.868, Average Loss: 4.213, avg. samples / sec: 65885.96
Iteration:   3000, Loss function: 3.630, Average Loss: 4.236, avg. samples / sec: 65998.33
Iteration:   3000, Loss function: 3.225, Average Loss: 4.246, avg. samples / sec: 66038.88
Iteration:   3000, Loss function: 3.924, Average Loss: 4.200, avg. samples / sec: 65731.29
Iteration:   3000, Loss function: 4.226, Average Loss: 4.210, avg. samples / sec: 65966.51
Iteration:   3000, Loss function: 3.283, Average Loss: 4.237, avg. samples / sec: 65921.28
Iteration:   3000, Loss function: 4.515, Average Loss: 4.238, avg. samples / sec: 65931.39
Iteration:   3000, Loss function: 3.562, Average Loss: 4.233, avg. samples / sec: 66086.35
Iteration:   3000, Loss function: 3.735, Average Loss: 4.200, avg. samples / sec: 65971.21
Iteration:   3000, Loss function: 3.658, Average Loss: 4.212, avg. samples / sec: 65827.09
Iteration:   3000, Loss function: 3.461, Average Loss: 4.212, avg. samples / sec: 65896.49
Iteration:   3000, Loss function: 3.336, Average Loss: 4.214, avg. samples / sec: 65754.91
:::MLL 1558651938.607 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558651938.608 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 3.756, Average Loss: 4.194, avg. samples / sec: 65767.40
Iteration:   3020, Loss function: 2.660, Average Loss: 4.239, avg. samples / sec: 65549.93
Iteration:   3020, Loss function: 3.473, Average Loss: 4.217, avg. samples / sec: 65495.83
Iteration:   3020, Loss function: 3.303, Average Loss: 4.223, avg. samples / sec: 65544.20
Iteration:   3020, Loss function: 4.261, Average Loss: 4.215, avg. samples / sec: 65554.72
Iteration:   3020, Loss function: 4.396, Average Loss: 4.222, avg. samples / sec: 65574.12
Iteration:   3020, Loss function: 4.815, Average Loss: 4.207, avg. samples / sec: 65396.38
Iteration:   3020, Loss function: 4.105, Average Loss: 4.201, avg. samples / sec: 65520.77
Iteration:   3020, Loss function: 3.986, Average Loss: 4.226, avg. samples / sec: 65547.13
Iteration:   3020, Loss function: 3.769, Average Loss: 4.210, avg. samples / sec: 65565.06
Iteration:   3020, Loss function: 3.701, Average Loss: 4.209, avg. samples / sec: 65496.77
Iteration:   3020, Loss function: 4.981, Average Loss: 4.234, avg. samples / sec: 65603.12
Iteration:   3020, Loss function: 2.858, Average Loss: 4.223, avg. samples / sec: 65515.62
Iteration:   3020, Loss function: 5.066, Average Loss: 4.212, avg. samples / sec: 65497.62
Iteration:   3020, Loss function: 3.955, Average Loss: 4.207, avg. samples / sec: 65546.91
Iteration:   3020, Loss function: 2.812, Average Loss: 4.207, avg. samples / sec: 65592.58
Iteration:   3020, Loss function: 3.862, Average Loss: 4.231, avg. samples / sec: 65530.94
Iteration:   3020, Loss function: 4.033, Average Loss: 4.207, avg. samples / sec: 65478.82
Iteration:   3020, Loss function: 3.917, Average Loss: 4.210, avg. samples / sec: 65497.53
Iteration:   3020, Loss function: 6.361, Average Loss: 4.248, avg. samples / sec: 65512.75
Iteration:   3020, Loss function: 3.138, Average Loss: 4.204, avg. samples / sec: 65373.08
Iteration:   3020, Loss function: 3.943, Average Loss: 4.205, avg. samples / sec: 65555.91
Iteration:   3020, Loss function: 4.590, Average Loss: 4.210, avg. samples / sec: 65264.46
Iteration:   3020, Loss function: 4.818, Average Loss: 4.204, avg. samples / sec: 65467.71
Iteration:   3020, Loss function: 3.599, Average Loss: 4.191, avg. samples / sec: 65490.35
Iteration:   3020, Loss function: 3.816, Average Loss: 4.231, avg. samples / sec: 65447.19
Iteration:   3020, Loss function: 3.331, Average Loss: 4.220, avg. samples / sec: 65352.92
Iteration:   3020, Loss function: 3.502, Average Loss: 4.246, avg. samples / sec: 65408.34
Iteration:   3020, Loss function: 3.656, Average Loss: 4.223, avg. samples / sec: 65444.33
Iteration:   3020, Loss function: 3.402, Average Loss: 4.207, avg. samples / sec: 65589.01
Iteration:   3040, Loss function: 3.769, Average Loss: 4.197, avg. samples / sec: 66164.51
Iteration:   3040, Loss function: 3.578, Average Loss: 4.227, avg. samples / sec: 66057.29
Iteration:   3040, Loss function: 3.352, Average Loss: 4.203, avg. samples / sec: 66102.44
Iteration:   3040, Loss function: 4.220, Average Loss: 4.235, avg. samples / sec: 66101.60
Iteration:   3040, Loss function: 3.828, Average Loss: 4.205, avg. samples / sec: 66087.00
Iteration:   3040, Loss function: 3.286, Average Loss: 4.197, avg. samples / sec: 65917.70
Iteration:   3040, Loss function: 4.677, Average Loss: 4.217, avg. samples / sec: 66033.83
Iteration:   3040, Loss function: 3.479, Average Loss: 4.203, avg. samples / sec: 66217.51
Iteration:   3040, Loss function: 3.848, Average Loss: 4.220, avg. samples / sec: 66224.14
Iteration:   3040, Loss function: 3.556, Average Loss: 4.205, avg. samples / sec: 66047.45
Iteration:   3040, Loss function: 3.783, Average Loss: 4.202, avg. samples / sec: 66155.00
Iteration:   3040, Loss function: 4.612, Average Loss: 4.220, avg. samples / sec: 65990.45
Iteration:   3040, Loss function: 3.909, Average Loss: 4.225, avg. samples / sec: 66184.52
Iteration:   3040, Loss function: 3.443, Average Loss: 4.212, avg. samples / sec: 66009.86
Iteration:   3040, Loss function: 2.872, Average Loss: 4.227, avg. samples / sec: 66085.27
Iteration:   3040, Loss function: 4.969, Average Loss: 4.211, avg. samples / sec: 66054.88
Iteration:   3040, Loss function: 4.373, Average Loss: 4.217, avg. samples / sec: 65993.20
Iteration:   3040, Loss function: 3.479, Average Loss: 4.241, avg. samples / sec: 66177.93
Iteration:   3040, Loss function: 3.452, Average Loss: 4.241, avg. samples / sec: 66087.65
Iteration:   3040, Loss function: 3.818, Average Loss: 4.198, avg. samples / sec: 66067.67
Iteration:   3040, Loss function: 4.089, Average Loss: 4.208, avg. samples / sec: 66105.88
Iteration:   3040, Loss function: 5.041, Average Loss: 4.221, avg. samples / sec: 65969.14
Iteration:   3040, Loss function: 3.801, Average Loss: 4.204, avg. samples / sec: 66066.83
Iteration:   3040, Loss function: 4.888, Average Loss: 4.220, avg. samples / sec: 65984.89
Iteration:   3040, Loss function: 3.887, Average Loss: 4.221, avg. samples / sec: 66144.01
Iteration:   3040, Loss function: 3.343, Average Loss: 4.206, avg. samples / sec: 65995.37
Iteration:   3040, Loss function: 4.823, Average Loss: 4.203, avg. samples / sec: 66031.17
Iteration:   3040, Loss function: 2.975, Average Loss: 4.198, avg. samples / sec: 66142.65
Iteration:   3040, Loss function: 3.117, Average Loss: 4.202, avg. samples / sec: 65893.44
Iteration:   3040, Loss function: 4.010, Average Loss: 4.185, avg. samples / sec: 65962.59
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558651939.586 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=0.57s)
DONE (t=0.57s)
DONE (t=0.58s)
DONE (t=0.59s)
DONE (t=0.60s)
DONE (t=2.81s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17486
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32247
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17136
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04245
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18801
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.28574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26899
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30399
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.44644
Current AP: 0.17486 AP goal: 0.23000
:::MLL 1558651943.607 eval_accuracy: {"value": 0.17485982738158704, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558651943.665 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558651943.671 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558651943.672 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 4.973, Average Loss: 4.194, avg. samples / sec: 7303.09
Iteration:   3060, Loss function: 4.194, Average Loss: 4.208, avg. samples / sec: 7302.01
Iteration:   3060, Loss function: 4.006, Average Loss: 4.219, avg. samples / sec: 7302.03
Iteration:   3060, Loss function: 3.454, Average Loss: 4.199, avg. samples / sec: 7300.83
Iteration:   3060, Loss function: 2.386, Average Loss: 4.200, avg. samples / sec: 7301.54
Iteration:   3060, Loss function: 4.626, Average Loss: 4.202, avg. samples / sec: 7302.46
Iteration:   3060, Loss function: 3.182, Average Loss: 4.195, avg. samples / sec: 7300.96
Iteration:   3060, Loss function: 4.294, Average Loss: 4.212, avg. samples / sec: 7301.78
Iteration:   3060, Loss function: 4.698, Average Loss: 4.197, avg. samples / sec: 7299.88
Iteration:   3060, Loss function: 3.640, Average Loss: 4.213, avg. samples / sec: 7302.03
Iteration:   3060, Loss function: 3.045, Average Loss: 4.205, avg. samples / sec: 7301.77
Iteration:   3060, Loss function: 3.380, Average Loss: 4.208, avg. samples / sec: 7301.41
Iteration:   3060, Loss function: 4.320, Average Loss: 4.201, avg. samples / sec: 7302.86
Iteration:   3060, Loss function: 3.235, Average Loss: 4.223, avg. samples / sec: 7299.29
Iteration:   3060, Loss function: 2.950, Average Loss: 4.216, avg. samples / sec: 7301.26
Iteration:   3060, Loss function: 3.301, Average Loss: 4.200, avg. samples / sec: 7301.63
Iteration:   3060, Loss function: 3.219, Average Loss: 4.173, avg. samples / sec: 7303.43
Iteration:   3060, Loss function: 4.340, Average Loss: 4.238, avg. samples / sec: 7301.18
Iteration:   3060, Loss function: 4.406, Average Loss: 4.202, avg. samples / sec: 7300.35
Iteration:   3060, Loss function: 4.271, Average Loss: 4.194, avg. samples / sec: 7301.09
Iteration:   3060, Loss function: 4.143, Average Loss: 4.211, avg. samples / sec: 7300.41
Iteration:   3060, Loss function: 2.834, Average Loss: 4.203, avg. samples / sec: 7300.40
Iteration:   3060, Loss function: 3.531, Average Loss: 4.202, avg. samples / sec: 7300.70
Iteration:   3060, Loss function: 3.854, Average Loss: 4.188, avg. samples / sec: 7301.95
Iteration:   3060, Loss function: 3.629, Average Loss: 4.235, avg. samples / sec: 7300.74
Iteration:   3060, Loss function: 3.602, Average Loss: 4.214, avg. samples / sec: 7300.99
Iteration:   3060, Loss function: 3.453, Average Loss: 4.194, avg. samples / sec: 7299.87
Iteration:   3060, Loss function: 4.865, Average Loss: 4.202, avg. samples / sec: 7300.32
Iteration:   3060, Loss function: 4.468, Average Loss: 4.215, avg. samples / sec: 7300.63
Iteration:   3060, Loss function: 4.120, Average Loss: 4.227, avg. samples / sec: 7298.73
:::MLL 1558651944.485 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558651944.486 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 4.232, Average Loss: 4.196, avg. samples / sec: 65704.85
Iteration:   3080, Loss function: 2.433, Average Loss: 4.209, avg. samples / sec: 65687.08
Iteration:   3080, Loss function: 3.566, Average Loss: 4.188, avg. samples / sec: 65574.33
Iteration:   3080, Loss function: 3.399, Average Loss: 4.191, avg. samples / sec: 65702.98
Iteration:   3080, Loss function: 3.230, Average Loss: 4.186, avg. samples / sec: 65782.16
Iteration:   3080, Loss function: 2.950, Average Loss: 4.211, avg. samples / sec: 65854.95
Iteration:   3080, Loss function: 5.134, Average Loss: 4.202, avg. samples / sec: 65725.84
Iteration:   3080, Loss function: 3.414, Average Loss: 4.190, avg. samples / sec: 65755.37
Iteration:   3080, Loss function: 3.844, Average Loss: 4.187, avg. samples / sec: 65662.29
Iteration:   3080, Loss function: 4.464, Average Loss: 4.189, avg. samples / sec: 65658.41
Iteration:   3080, Loss function: 2.894, Average Loss: 4.185, avg. samples / sec: 65722.34
Iteration:   3080, Loss function: 4.708, Average Loss: 4.224, avg. samples / sec: 65742.76
Iteration:   3080, Loss function: 3.333, Average Loss: 4.187, avg. samples / sec: 65732.37
Iteration:   3080, Loss function: 2.491, Average Loss: 4.204, avg. samples / sec: 65763.01
Iteration:   3080, Loss function: 3.936, Average Loss: 4.202, avg. samples / sec: 65728.41
Iteration:   3080, Loss function: 3.420, Average Loss: 4.200, avg. samples / sec: 65612.22
Iteration:   3080, Loss function: 4.599, Average Loss: 4.192, avg. samples / sec: 65615.91
Iteration:   3080, Loss function: 3.444, Average Loss: 4.195, avg. samples / sec: 65633.88
Iteration:   3080, Loss function: 2.377, Average Loss: 4.185, avg. samples / sec: 65716.00
Iteration:   3080, Loss function: 4.123, Average Loss: 4.193, avg. samples / sec: 65596.37
Iteration:   3080, Loss function: 3.498, Average Loss: 4.194, avg. samples / sec: 65617.59
Iteration:   3080, Loss function: 3.071, Average Loss: 4.204, avg. samples / sec: 65615.55
Iteration:   3080, Loss function: 3.263, Average Loss: 4.191, avg. samples / sec: 65560.21
Iteration:   3080, Loss function: 3.122, Average Loss: 4.175, avg. samples / sec: 65620.07
Iteration:   3080, Loss function: 3.807, Average Loss: 4.190, avg. samples / sec: 65693.02
Iteration:   3080, Loss function: 3.697, Average Loss: 4.195, avg. samples / sec: 65617.99
Iteration:   3080, Loss function: 3.296, Average Loss: 4.211, avg. samples / sec: 65576.89
Iteration:   3080, Loss function: 3.398, Average Loss: 4.224, avg. samples / sec: 65592.12
Iteration:   3080, Loss function: 3.982, Average Loss: 4.164, avg. samples / sec: 65580.59
Iteration:   3080, Loss function: 2.755, Average Loss: 4.197, avg. samples / sec: 65539.47
Iteration:   3100, Loss function: 4.018, Average Loss: 4.180, avg. samples / sec: 65913.20
Iteration:   3100, Loss function: 3.512, Average Loss: 4.180, avg. samples / sec: 66069.74
Iteration:   3100, Loss function: 3.491, Average Loss: 4.184, avg. samples / sec: 65999.29
Iteration:   3100, Loss function: 3.212, Average Loss: 4.193, avg. samples / sec: 65907.53
Iteration:   3100, Loss function: 3.807, Average Loss: 4.179, avg. samples / sec: 65899.14
Iteration:   3100, Loss function: 4.482, Average Loss: 4.201, avg. samples / sec: 65840.80
Iteration:   3100, Loss function: 2.699, Average Loss: 4.184, avg. samples / sec: 65786.16
Iteration:   3100, Loss function: 4.366, Average Loss: 4.166, avg. samples / sec: 65990.92
Iteration:   3100, Loss function: 3.109, Average Loss: 4.176, avg. samples / sec: 65803.82
Iteration:   3100, Loss function: 3.348, Average Loss: 4.174, avg. samples / sec: 65869.33
Iteration:   3100, Loss function: 3.350, Average Loss: 4.218, avg. samples / sec: 65867.02
Iteration:   3100, Loss function: 3.678, Average Loss: 4.146, avg. samples / sec: 65984.30
Iteration:   3100, Loss function: 3.319, Average Loss: 4.185, avg. samples / sec: 65931.42
Iteration:   3100, Loss function: 3.110, Average Loss: 4.172, avg. samples / sec: 65753.68
Iteration:   3100, Loss function: 3.126, Average Loss: 4.201, avg. samples / sec: 65951.35
Iteration:   3100, Loss function: 4.857, Average Loss: 4.190, avg. samples / sec: 65867.02
Iteration:   3100, Loss function: 2.412, Average Loss: 4.179, avg. samples / sec: 65885.25
Iteration:   3100, Loss function: 3.044, Average Loss: 4.172, avg. samples / sec: 65838.37
Iteration:   3100, Loss function: 3.354, Average Loss: 4.199, avg. samples / sec: 65753.77
Iteration:   3100, Loss function: 3.141, Average Loss: 4.178, avg. samples / sec: 65802.77
Iteration:   3100, Loss function: 4.525, Average Loss: 4.188, avg. samples / sec: 65912.61
Iteration:   3100, Loss function: 2.978, Average Loss: 4.211, avg. samples / sec: 65899.45
Iteration:   3100, Loss function: 4.320, Average Loss: 4.181, avg. samples / sec: 65734.45
Iteration:   3100, Loss function: 3.752, Average Loss: 4.181, avg. samples / sec: 65889.32
Iteration:   3100, Loss function: 3.243, Average Loss: 4.196, avg. samples / sec: 65864.74
Iteration:   3100, Loss function: 2.419, Average Loss: 4.182, avg. samples / sec: 65937.65
Iteration:   3100, Loss function: 2.541, Average Loss: 4.185, avg. samples / sec: 65845.82
Iteration:   3100, Loss function: 4.229, Average Loss: 4.191, avg. samples / sec: 65793.25
Iteration:   3100, Loss function: 5.113, Average Loss: 4.176, avg. samples / sec: 65823.58
Iteration:   3100, Loss function: 3.540, Average Loss: 4.187, avg. samples / sec: 65779.31
Iteration:   3120, Loss function: 4.721, Average Loss: 4.170, avg. samples / sec: 64932.00
Iteration:   3120, Loss function: 4.140, Average Loss: 4.175, avg. samples / sec: 64851.09
Iteration:   3120, Loss function: 5.224, Average Loss: 4.202, avg. samples / sec: 64754.39
Iteration:   3120, Loss function: 2.880, Average Loss: 4.166, avg. samples / sec: 64676.95
Iteration:   3120, Loss function: 3.480, Average Loss: 4.163, avg. samples / sec: 64896.33
Iteration:   3120, Loss function: 3.628, Average Loss: 4.163, avg. samples / sec: 64785.98
Iteration:   3120, Loss function: 3.456, Average Loss: 4.171, avg. samples / sec: 64719.30
Iteration:   3120, Loss function: 3.268, Average Loss: 4.170, avg. samples / sec: 64638.41
Iteration:   3120, Loss function: 2.824, Average Loss: 4.166, avg. samples / sec: 64819.14
Iteration:   3120, Loss function: 3.438, Average Loss: 4.202, avg. samples / sec: 64822.07
Iteration:   3120, Loss function: 4.515, Average Loss: 4.184, avg. samples / sec: 64782.49
Iteration:   3120, Loss function: 2.672, Average Loss: 4.126, avg. samples / sec: 64735.57
Iteration:   3120, Loss function: 4.825, Average Loss: 4.164, avg. samples / sec: 64782.43
Iteration:   3120, Loss function: 2.983, Average Loss: 4.169, avg. samples / sec: 64629.64
Iteration:   3120, Loss function: 4.011, Average Loss: 4.172, avg. samples / sec: 64646.30
Iteration:   3120, Loss function: 3.812, Average Loss: 4.188, avg. samples / sec: 64783.83
Iteration:   3120, Loss function: 5.780, Average Loss: 4.166, avg. samples / sec: 64689.74
Iteration:   3120, Loss function: 3.578, Average Loss: 4.168, avg. samples / sec: 64809.34
Iteration:   3120, Loss function: 3.236, Average Loss: 4.158, avg. samples / sec: 64718.23
Iteration:   3120, Loss function: 3.388, Average Loss: 4.172, avg. samples / sec: 64749.72
Iteration:   3120, Loss function: 2.764, Average Loss: 4.163, avg. samples / sec: 64703.56
Iteration:   3120, Loss function: 3.438, Average Loss: 4.175, avg. samples / sec: 64576.96
Iteration:   3120, Loss function: 3.585, Average Loss: 4.179, avg. samples / sec: 64739.02
Iteration:   3120, Loss function: 4.248, Average Loss: 4.168, avg. samples / sec: 64736.16
Iteration:   3120, Loss function: 3.809, Average Loss: 4.159, avg. samples / sec: 64639.19
Iteration:   3120, Loss function: 3.254, Average Loss: 4.180, avg. samples / sec: 64715.80
Iteration:   3120, Loss function: 3.804, Average Loss: 4.153, avg. samples / sec: 64581.51
Iteration:   3120, Loss function: 3.822, Average Loss: 4.177, avg. samples / sec: 64680.30
Iteration:   3120, Loss function: 2.777, Average Loss: 4.192, avg. samples / sec: 64610.00
Iteration:   3120, Loss function: 3.890, Average Loss: 4.206, avg. samples / sec: 64588.47
Iteration:   3140, Loss function: 4.503, Average Loss: 4.153, avg. samples / sec: 66072.01
Iteration:   3140, Loss function: 4.241, Average Loss: 4.152, avg. samples / sec: 66120.40
Iteration:   3140, Loss function: 3.856, Average Loss: 4.153, avg. samples / sec: 66106.47
Iteration:   3140, Loss function: 3.521, Average Loss: 4.159, avg. samples / sec: 66083.41
Iteration:   3140, Loss function: 2.815, Average Loss: 4.192, avg. samples / sec: 65974.76
Iteration:   3140, Loss function: 3.800, Average Loss: 4.154, avg. samples / sec: 66131.88
Iteration:   3140, Loss function: 4.064, Average Loss: 4.152, avg. samples / sec: 66030.80
Iteration:   3140, Loss function: 2.212, Average Loss: 4.163, avg. samples / sec: 65974.05
Iteration:   3140, Loss function: 3.327, Average Loss: 4.156, avg. samples / sec: 65915.76
Iteration:   3140, Loss function: 2.942, Average Loss: 4.152, avg. samples / sec: 66009.28
Iteration:   3140, Loss function: 3.971, Average Loss: 4.167, avg. samples / sec: 66123.87
Iteration:   3140, Loss function: 3.968, Average Loss: 4.156, avg. samples / sec: 65971.08
Iteration:   3140, Loss function: 3.026, Average Loss: 4.156, avg. samples / sec: 65891.29
Iteration:   3140, Loss function: 4.802, Average Loss: 4.150, avg. samples / sec: 66080.77
Iteration:   3140, Loss function: 2.683, Average Loss: 4.151, avg. samples / sec: 66000.62
Iteration:   3140, Loss function: 2.266, Average Loss: 4.169, avg. samples / sec: 66042.28
Iteration:   3140, Loss function: 3.526, Average Loss: 4.156, avg. samples / sec: 66122.23
Iteration:   3140, Loss function: 3.613, Average Loss: 4.153, avg. samples / sec: 65890.46
Iteration:   3140, Loss function: 3.600, Average Loss: 4.174, avg. samples / sec: 65953.48
Iteration:   3140, Loss function: 2.762, Average Loss: 4.190, avg. samples / sec: 65920.29
Iteration:   3140, Loss function: 3.934, Average Loss: 4.114, avg. samples / sec: 65913.82
Iteration:   3140, Loss function: 3.205, Average Loss: 4.175, avg. samples / sec: 65927.97
Iteration:   3140, Loss function: 4.680, Average Loss: 4.180, avg. samples / sec: 66066.93
Iteration:   3140, Loss function: 3.606, Average Loss: 4.152, avg. samples / sec: 65960.34
Iteration:   3140, Loss function: 3.959, Average Loss: 4.167, avg. samples / sec: 65947.59
Iteration:   3140, Loss function: 2.981, Average Loss: 4.142, avg. samples / sec: 65929.88
Iteration:   3140, Loss function: 3.303, Average Loss: 4.152, avg. samples / sec: 65785.91
Iteration:   3140, Loss function: 3.841, Average Loss: 4.197, avg. samples / sec: 66009.34
Iteration:   3140, Loss function: 3.337, Average Loss: 4.157, avg. samples / sec: 65843.17
Iteration:   3140, Loss function: 5.420, Average Loss: 4.147, avg. samples / sec: 65924.42
:::MLL 1558651946.282 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558651946.282 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 3.406, Average Loss: 4.140, avg. samples / sec: 65626.43
Iteration:   3160, Loss function: 2.818, Average Loss: 4.135, avg. samples / sec: 65485.39
Iteration:   3160, Loss function: 4.562, Average Loss: 4.151, avg. samples / sec: 65527.44
Iteration:   3160, Loss function: 4.426, Average Loss: 4.140, avg. samples / sec: 65450.93
Iteration:   3160, Loss function: 4.313, Average Loss: 4.142, avg. samples / sec: 65449.90
Iteration:   3160, Loss function: 2.667, Average Loss: 4.153, avg. samples / sec: 65639.60
Iteration:   3160, Loss function: 3.304, Average Loss: 4.140, avg. samples / sec: 65566.64
Iteration:   3160, Loss function: 3.594, Average Loss: 4.135, avg. samples / sec: 65608.25
Iteration:   3160, Loss function: 3.764, Average Loss: 4.132, avg. samples / sec: 65459.53
Iteration:   3160, Loss function: 4.958, Average Loss: 4.149, avg. samples / sec: 65454.24
Iteration:   3160, Loss function: 2.971, Average Loss: 4.148, avg. samples / sec: 65481.49
Iteration:   3160, Loss function: 3.114, Average Loss: 4.160, avg. samples / sec: 65520.37
Iteration:   3160, Loss function: 3.334, Average Loss: 4.136, avg. samples / sec: 65662.78
Iteration:   3160, Loss function: 3.455, Average Loss: 4.139, avg. samples / sec: 65482.71
Iteration:   3160, Loss function: 3.398, Average Loss: 4.168, avg. samples / sec: 65539.38
Iteration:   3160, Loss function: 2.761, Average Loss: 4.128, avg. samples / sec: 65552.40
Iteration:   3160, Loss function: 2.774, Average Loss: 4.183, avg. samples / sec: 65382.49
Iteration:   3160, Loss function: 4.444, Average Loss: 4.142, avg. samples / sec: 65431.18
Iteration:   3160, Loss function: 3.873, Average Loss: 4.158, avg. samples / sec: 65495.34
Iteration:   3160, Loss function: 3.174, Average Loss: 4.146, avg. samples / sec: 65360.87
Iteration:   3160, Loss function: 4.461, Average Loss: 4.137, avg. samples / sec: 65542.67
Iteration:   3160, Loss function: 3.345, Average Loss: 4.149, avg. samples / sec: 65399.63
Iteration:   3160, Loss function: 3.841, Average Loss: 4.142, avg. samples / sec: 65363.87
Iteration:   3160, Loss function: 2.326, Average Loss: 4.135, avg. samples / sec: 65401.81
Iteration:   3160, Loss function: 3.882, Average Loss: 4.183, avg. samples / sec: 65513.42
Iteration:   3160, Loss function: 4.404, Average Loss: 4.148, avg. samples / sec: 65572.65
Iteration:   3160, Loss function: 3.692, Average Loss: 4.150, avg. samples / sec: 65336.87
Iteration:   3160, Loss function: 3.869, Average Loss: 4.154, avg. samples / sec: 65364.47
Iteration:   3160, Loss function: 2.813, Average Loss: 4.103, avg. samples / sec: 65402.48
Iteration:   3160, Loss function: 3.236, Average Loss: 4.176, avg. samples / sec: 65276.64
Iteration:   3180, Loss function: 3.565, Average Loss: 4.124, avg. samples / sec: 65962.34
Iteration:   3180, Loss function: 3.573, Average Loss: 4.169, avg. samples / sec: 66056.30
Iteration:   3180, Loss function: 4.124, Average Loss: 4.134, avg. samples / sec: 66096.02
Iteration:   3180, Loss function: 4.681, Average Loss: 4.124, avg. samples / sec: 66030.86
Iteration:   3180, Loss function: 3.853, Average Loss: 4.137, avg. samples / sec: 65931.05
Iteration:   3180, Loss function: 3.068, Average Loss: 4.166, avg. samples / sec: 66268.24
Iteration:   3180, Loss function: 3.944, Average Loss: 4.125, avg. samples / sec: 65964.44
Iteration:   3180, Loss function: 3.971, Average Loss: 4.127, avg. samples / sec: 65827.42
Iteration:   3180, Loss function: 3.772, Average Loss: 4.150, avg. samples / sec: 65989.93
Iteration:   3180, Loss function: 4.647, Average Loss: 4.125, avg. samples / sec: 65977.88
Iteration:   3180, Loss function: 3.691, Average Loss: 4.117, avg. samples / sec: 65902.53
Iteration:   3180, Loss function: 2.680, Average Loss: 4.090, avg. samples / sec: 66077.58
Iteration:   3180, Loss function: 4.396, Average Loss: 4.149, avg. samples / sec: 65890.89
Iteration:   3180, Loss function: 3.678, Average Loss: 4.130, avg. samples / sec: 65834.74
Iteration:   3180, Loss function: 3.595, Average Loss: 4.141, avg. samples / sec: 65846.86
Iteration:   3180, Loss function: 2.251, Average Loss: 4.132, avg. samples / sec: 65880.54
Iteration:   3180, Loss function: 3.377, Average Loss: 4.129, avg. samples / sec: 65819.58
Iteration:   3180, Loss function: 3.228, Average Loss: 4.128, avg. samples / sec: 65878.01
Iteration:   3180, Loss function: 3.181, Average Loss: 4.154, avg. samples / sec: 65871.33
Iteration:   3180, Loss function: 4.141, Average Loss: 4.126, avg. samples / sec: 65782.13
Iteration:   3180, Loss function: 3.676, Average Loss: 4.129, avg. samples / sec: 65933.27
Iteration:   3180, Loss function: 3.508, Average Loss: 4.138, avg. samples / sec: 65939.17
Iteration:   3180, Loss function: 3.940, Average Loss: 4.137, avg. samples / sec: 65915.66
Iteration:   3180, Loss function: 5.301, Average Loss: 4.140, avg. samples / sec: 65790.58
Iteration:   3180, Loss function: 3.679, Average Loss: 4.117, avg. samples / sec: 65894.31
Iteration:   3180, Loss function: 4.618, Average Loss: 4.143, avg. samples / sec: 65929.63
Iteration:   3180, Loss function: 3.178, Average Loss: 4.138, avg. samples / sec: 65866.40
Iteration:   3180, Loss function: 3.444, Average Loss: 4.117, avg. samples / sec: 65825.30
Iteration:   3180, Loss function: 3.801, Average Loss: 4.174, avg. samples / sec: 65888.76
Iteration:   3180, Loss function: 3.799, Average Loss: 4.127, avg. samples / sec: 65720.10
Iteration:   3200, Loss function: 4.073, Average Loss: 4.118, avg. samples / sec: 66097.20
Iteration:   3200, Loss function: 3.097, Average Loss: 4.116, avg. samples / sec: 65936.33
Iteration:   3200, Loss function: 4.190, Average Loss: 4.134, avg. samples / sec: 66063.89
Iteration:   3200, Loss function: 4.632, Average Loss: 4.156, avg. samples / sec: 65924.24
Iteration:   3200, Loss function: 3.267, Average Loss: 4.121, avg. samples / sec: 66056.92
Iteration:   3200, Loss function: 3.625, Average Loss: 4.155, avg. samples / sec: 65946.39
Iteration:   3200, Loss function: 4.387, Average Loss: 4.128, avg. samples / sec: 66121.51
Iteration:   3200, Loss function: 4.811, Average Loss: 4.126, avg. samples / sec: 65876.87
Iteration:   3200, Loss function: 4.246, Average Loss: 4.123, avg. samples / sec: 65929.36
Iteration:   3200, Loss function: 3.519, Average Loss: 4.110, avg. samples / sec: 65988.66
Iteration:   3200, Loss function: 3.239, Average Loss: 4.145, avg. samples / sec: 66067.30
Iteration:   3200, Loss function: 3.614, Average Loss: 4.114, avg. samples / sec: 65965.28
Iteration:   3200, Loss function: 3.324, Average Loss: 4.115, avg. samples / sec: 66026.19
Iteration:   3200, Loss function: 2.538, Average Loss: 4.139, avg. samples / sec: 65927.57
Iteration:   3200, Loss function: 2.889, Average Loss: 4.117, avg. samples / sec: 65968.30
Iteration:   3200, Loss function: 4.049, Average Loss: 4.124, avg. samples / sec: 66064.54
Iteration:   3200, Loss function: 2.990, Average Loss: 4.116, avg. samples / sec: 65996.01
Iteration:   3200, Loss function: 4.284, Average Loss: 4.125, avg. samples / sec: 66068.88
Iteration:   3200, Loss function: 4.141, Average Loss: 4.110, avg. samples / sec: 65811.13
Iteration:   3200, Loss function: 2.349, Average Loss: 4.118, avg. samples / sec: 65959.16
Iteration:   3200, Loss function: 4.311, Average Loss: 4.074, avg. samples / sec: 65903.64
Iteration:   3200, Loss function: 2.968, Average Loss: 4.111, avg. samples / sec: 65835.63
Iteration:   3200, Loss function: 2.613, Average Loss: 4.159, avg. samples / sec: 66014.41
Iteration:   3200, Loss function: 3.313, Average Loss: 4.129, avg. samples / sec: 65995.24
Iteration:   3200, Loss function: 3.786, Average Loss: 4.109, avg. samples / sec: 65989.15
Iteration:   3200, Loss function: 4.034, Average Loss: 4.118, avg. samples / sec: 65916.96
Iteration:   3200, Loss function: 3.634, Average Loss: 4.109, avg. samples / sec: 66001.86
Iteration:   3200, Loss function: 4.518, Average Loss: 4.118, avg. samples / sec: 66137.96
Iteration:   3200, Loss function: 2.429, Average Loss: 4.134, avg. samples / sec: 65877.15
Iteration:   3200, Loss function: 2.759, Average Loss: 4.133, avg. samples / sec: 65869.54
:::MLL 1558651948.067 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558651948.068 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 3.388, Average Loss: 4.095, avg. samples / sec: 65854.89
Iteration:   3220, Loss function: 4.116, Average Loss: 4.111, avg. samples / sec: 65903.70
Iteration:   3220, Loss function: 2.875, Average Loss: 4.102, avg. samples / sec: 65837.20
Iteration:   3220, Loss function: 4.109, Average Loss: 4.144, avg. samples / sec: 65758.96
Iteration:   3220, Loss function: 2.848, Average Loss: 4.103, avg. samples / sec: 65677.65
Iteration:   3220, Loss function: 3.424, Average Loss: 4.101, avg. samples / sec: 65853.57
Iteration:   3220, Loss function: 3.347, Average Loss: 4.127, avg. samples / sec: 65776.82
Iteration:   3220, Loss function: 2.504, Average Loss: 4.105, avg. samples / sec: 65792.11
Iteration:   3220, Loss function: 4.140, Average Loss: 4.123, avg. samples / sec: 65831.11
Iteration:   3220, Loss function: 4.155, Average Loss: 4.144, avg. samples / sec: 65652.75
Iteration:   3220, Loss function: 4.821, Average Loss: 4.117, avg. samples / sec: 65663.55
Iteration:   3220, Loss function: 3.026, Average Loss: 4.119, avg. samples / sec: 65918.81
Iteration:   3220, Loss function: 3.630, Average Loss: 4.100, avg. samples / sec: 65760.34
Iteration:   3220, Loss function: 4.482, Average Loss: 4.106, avg. samples / sec: 65518.60
Iteration:   3220, Loss function: 3.504, Average Loss: 4.105, avg. samples / sec: 65771.82
Iteration:   3220, Loss function: 2.984, Average Loss: 4.127, avg. samples / sec: 65621.44
Iteration:   3220, Loss function: 3.207, Average Loss: 4.104, avg. samples / sec: 65760.77
Iteration:   3220, Loss function: 2.919, Average Loss: 4.105, avg. samples / sec: 65698.23
Iteration:   3220, Loss function: 3.751, Average Loss: 4.112, avg. samples / sec: 65624.74
Iteration:   3220, Loss function: 3.464, Average Loss: 4.116, avg. samples / sec: 65641.83
Iteration:   3220, Loss function: 3.222, Average Loss: 4.064, avg. samples / sec: 65709.99
Iteration:   3220, Loss function: 4.322, Average Loss: 4.108, avg. samples / sec: 65651.43
Iteration:   3220, Loss function: 3.700, Average Loss: 4.109, avg. samples / sec: 65589.53
Iteration:   3220, Loss function: 2.958, Average Loss: 4.103, avg. samples / sec: 65834.43
Iteration:   3220, Loss function: 3.517, Average Loss: 4.144, avg. samples / sec: 65724.49
Iteration:   3220, Loss function: 2.874, Average Loss: 4.135, avg. samples / sec: 65553.16
Iteration:   3220, Loss function: 3.121, Average Loss: 4.112, avg. samples / sec: 65613.59
Iteration:   3220, Loss function: 2.242, Average Loss: 4.099, avg. samples / sec: 65616.40
Iteration:   3220, Loss function: 3.592, Average Loss: 4.122, avg. samples / sec: 65577.08
Iteration:   3220, Loss function: 3.087, Average Loss: 4.100, avg. samples / sec: 65690.33
Iteration:   3240, Loss function: 3.246, Average Loss: 4.133, avg. samples / sec: 65777.80
Iteration:   3240, Loss function: 3.598, Average Loss: 4.092, avg. samples / sec: 65704.36
Iteration:   3240, Loss function: 2.275, Average Loss: 4.100, avg. samples / sec: 65668.53
Iteration:   3240, Loss function: 3.361, Average Loss: 4.129, avg. samples / sec: 65818.60
Iteration:   3240, Loss function: 3.873, Average Loss: 4.097, avg. samples / sec: 65880.94
Iteration:   3240, Loss function: 3.317, Average Loss: 4.095, avg. samples / sec: 65845.23
Iteration:   3240, Loss function: 3.184, Average Loss: 4.107, avg. samples / sec: 65866.50
Iteration:   3240, Loss function: 2.213, Average Loss: 4.132, avg. samples / sec: 65844.95
Iteration:   3240, Loss function: 4.648, Average Loss: 4.098, avg. samples / sec: 65801.82
Iteration:   3240, Loss function: 3.270, Average Loss: 4.089, avg. samples / sec: 65699.06
Iteration:   3240, Loss function: 4.316, Average Loss: 4.104, avg. samples / sec: 65887.62
Iteration:   3240, Loss function: 2.719, Average Loss: 4.088, avg. samples / sec: 65769.73
Iteration:   3240, Loss function: 2.490, Average Loss: 4.088, avg. samples / sec: 65723.57
Iteration:   3240, Loss function: 3.056, Average Loss: 4.084, avg. samples / sec: 65883.56
Iteration:   3240, Loss function: 3.478, Average Loss: 4.119, avg. samples / sec: 65870.90
Iteration:   3240, Loss function: 3.358, Average Loss: 4.105, avg. samples / sec: 65764.30
Iteration:   3240, Loss function: 2.816, Average Loss: 4.089, avg. samples / sec: 65646.42
Iteration:   3240, Loss function: 3.282, Average Loss: 4.096, avg. samples / sec: 65744.23
Iteration:   3240, Loss function: 3.342, Average Loss: 4.092, avg. samples / sec: 65685.55
Iteration:   3240, Loss function: 4.153, Average Loss: 4.053, avg. samples / sec: 65797.46
Iteration:   3240, Loss function: 3.911, Average Loss: 4.087, avg. samples / sec: 65561.09
Iteration:   3240, Loss function: 2.847, Average Loss: 4.093, avg. samples / sec: 65754.85
Iteration:   3240, Loss function: 2.914, Average Loss: 4.115, avg. samples / sec: 65713.82
Iteration:   3240, Loss function: 3.079, Average Loss: 4.113, avg. samples / sec: 65621.14
Iteration:   3240, Loss function: 3.118, Average Loss: 4.085, avg. samples / sec: 65872.75
Iteration:   3240, Loss function: 3.773, Average Loss: 4.099, avg. samples / sec: 65729.58
Iteration:   3240, Loss function: 3.334, Average Loss: 4.109, avg. samples / sec: 65597.56
Iteration:   3240, Loss function: 3.935, Average Loss: 4.105, avg. samples / sec: 65611.12
Iteration:   3240, Loss function: 3.698, Average Loss: 4.093, avg. samples / sec: 65638.47
Iteration:   3240, Loss function: 3.892, Average Loss: 4.107, avg. samples / sec: 65771.30
Iteration:   3260, Loss function: 4.222, Average Loss: 4.089, avg. samples / sec: 65410.47
Iteration:   3260, Loss function: 3.642, Average Loss: 4.079, avg. samples / sec: 65406.19
Iteration:   3260, Loss function: 4.863, Average Loss: 4.096, avg. samples / sec: 65320.00
Iteration:   3260, Loss function: 3.274, Average Loss: 4.118, avg. samples / sec: 65317.42
Iteration:   3260, Loss function: 4.100, Average Loss: 4.083, avg. samples / sec: 65217.46
Iteration:   3260, Loss function: 2.764, Average Loss: 4.086, avg. samples / sec: 65412.99
Iteration:   3260, Loss function: 2.808, Average Loss: 4.082, avg. samples / sec: 65250.95
Iteration:   3260, Loss function: 2.278, Average Loss: 4.120, avg. samples / sec: 65154.75
Iteration:   3260, Loss function: 3.256, Average Loss: 4.099, avg. samples / sec: 65377.30
Iteration:   3260, Loss function: 3.299, Average Loss: 4.081, avg. samples / sec: 65308.68
Iteration:   3260, Loss function: 3.662, Average Loss: 4.089, avg. samples / sec: 65216.77
Iteration:   3260, Loss function: 3.881, Average Loss: 4.076, avg. samples / sec: 65308.34
Iteration:   3260, Loss function: 3.921, Average Loss: 4.096, avg. samples / sec: 65368.60
Iteration:   3260, Loss function: 3.378, Average Loss: 4.090, avg. samples / sec: 65249.99
Iteration:   3260, Loss function: 3.657, Average Loss: 4.099, avg. samples / sec: 65314.82
Iteration:   3260, Loss function: 2.902, Average Loss: 4.112, avg. samples / sec: 65255.45
Iteration:   3260, Loss function: 4.133, Average Loss: 4.121, avg. samples / sec: 65169.60
Iteration:   3260, Loss function: 3.316, Average Loss: 4.097, avg. samples / sec: 65220.42
Iteration:   3260, Loss function: 3.818, Average Loss: 4.078, avg. samples / sec: 65215.65
Iteration:   3260, Loss function: 2.924, Average Loss: 4.072, avg. samples / sec: 65300.81
Iteration:   3260, Loss function: 3.383, Average Loss: 4.087, avg. samples / sec: 65231.17
Iteration:   3260, Loss function: 3.421, Average Loss: 4.073, avg. samples / sec: 65210.34
Iteration:   3260, Loss function: 3.259, Average Loss: 4.091, avg. samples / sec: 65407.10
Iteration:   3260, Loss function: 3.813, Average Loss: 4.079, avg. samples / sec: 65179.19
Iteration:   3260, Loss function: 3.431, Average Loss: 4.042, avg. samples / sec: 65185.82
Iteration:   3260, Loss function: 3.964, Average Loss: 4.094, avg. samples / sec: 65281.84
Iteration:   3260, Loss function: 3.211, Average Loss: 4.084, avg. samples / sec: 65284.81
Iteration:   3260, Loss function: 3.890, Average Loss: 4.082, avg. samples / sec: 65172.04
Iteration:   3260, Loss function: 2.923, Average Loss: 4.089, avg. samples / sec: 65033.10
Iteration:   3260, Loss function: 3.800, Average Loss: 4.072, avg. samples / sec: 65097.39
Iteration:   3280, Loss function: 3.292, Average Loss: 4.108, avg. samples / sec: 66361.38
Iteration:   3280, Loss function: 2.644, Average Loss: 4.087, avg. samples / sec: 66345.57
Iteration:   3280, Loss function: 2.667, Average Loss: 4.111, avg. samples / sec: 66314.70
Iteration:   3280, Loss function: 3.988, Average Loss: 4.072, avg. samples / sec: 66142.37
Iteration:   3280, Loss function: 3.592, Average Loss: 4.079, avg. samples / sec: 66269.08
Iteration:   3280, Loss function: 4.551, Average Loss: 4.085, avg. samples / sec: 66268.39
Iteration:   3280, Loss function: 4.339, Average Loss: 4.086, avg. samples / sec: 66119.90
Iteration:   3280, Loss function: 2.930, Average Loss: 4.075, avg. samples / sec: 66209.21
Iteration:   3280, Loss function: 3.550, Average Loss: 4.062, avg. samples / sec: 66269.17
Iteration:   3280, Loss function: 2.911, Average Loss: 4.085, avg. samples / sec: 66172.58
Iteration:   3280, Loss function: 3.156, Average Loss: 4.078, avg. samples / sec: 66363.54
Iteration:   3280, Loss function: 3.472, Average Loss: 4.072, avg. samples / sec: 66147.05
Iteration:   3280, Loss function: 4.786, Average Loss: 4.070, avg. samples / sec: 66231.95
Iteration:   3280, Loss function: 4.261, Average Loss: 4.070, avg. samples / sec: 66154.23
Iteration:   3280, Loss function: 2.941, Average Loss: 4.058, avg. samples / sec: 66179.70
Iteration:   3280, Loss function: 4.211, Average Loss: 4.107, avg. samples / sec: 66093.63
Iteration:   3280, Loss function: 2.226, Average Loss: 4.084, avg. samples / sec: 66278.83
Iteration:   3280, Loss function: 2.651, Average Loss: 4.072, avg. samples / sec: 66117.63
Iteration:   3280, Loss function: 4.206, Average Loss: 4.035, avg. samples / sec: 66241.79
Iteration:   3280, Loss function: 3.250, Average Loss: 4.108, avg. samples / sec: 66178.33
Iteration:   3280, Loss function: 2.680, Average Loss: 4.068, avg. samples / sec: 66101.35
Iteration:   3280, Loss function: 2.613, Average Loss: 4.071, avg. samples / sec: 66193.60
Iteration:   3280, Loss function: 3.903, Average Loss: 4.069, avg. samples / sec: 66260.32
Iteration:   3280, Loss function: 6.067, Average Loss: 4.075, avg. samples / sec: 65915.33
Iteration:   3280, Loss function: 3.181, Average Loss: 4.059, avg. samples / sec: 66122.85
Iteration:   3280, Loss function: 3.799, Average Loss: 4.079, avg. samples / sec: 66109.76
Iteration:   3280, Loss function: 2.904, Average Loss: 4.059, avg. samples / sec: 66220.03
Iteration:   3280, Loss function: 3.096, Average Loss: 4.081, avg. samples / sec: 66134.92
Iteration:   3280, Loss function: 3.467, Average Loss: 4.071, avg. samples / sec: 66128.00
Iteration:   3280, Loss function: 4.241, Average Loss: 4.072, avg. samples / sec: 66123.06
:::MLL 1558651949.858 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558651949.858 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 3.212, Average Loss: 4.098, avg. samples / sec: 65206.72
Iteration:   3300, Loss function: 2.284, Average Loss: 4.061, avg. samples / sec: 65448.65
Iteration:   3300, Loss function: 3.564, Average Loss: 4.072, avg. samples / sec: 65467.74
Iteration:   3300, Loss function: 3.074, Average Loss: 4.060, avg. samples / sec: 65360.29
Iteration:   3300, Loss function: 4.092, Average Loss: 4.095, avg. samples / sec: 65329.32
Iteration:   3300, Loss function: 3.068, Average Loss: 4.066, avg. samples / sec: 65396.75
Iteration:   3300, Loss function: 4.545, Average Loss: 4.083, avg. samples / sec: 65213.06
Iteration:   3300, Loss function: 2.423, Average Loss: 4.022, avg. samples / sec: 65329.42
Iteration:   3300, Loss function: 3.136, Average Loss: 4.041, avg. samples / sec: 65274.53
Iteration:   3300, Loss function: 3.136, Average Loss: 4.053, avg. samples / sec: 65241.47
Iteration:   3300, Loss function: 3.505, Average Loss: 4.059, avg. samples / sec: 65263.37
Iteration:   3300, Loss function: 4.533, Average Loss: 4.061, avg. samples / sec: 65170.18
Iteration:   3300, Loss function: 3.661, Average Loss: 4.063, avg. samples / sec: 65449.84
Iteration:   3300, Loss function: 3.975, Average Loss: 4.044, avg. samples / sec: 65380.21
Iteration:   3300, Loss function: 3.767, Average Loss: 4.076, avg. samples / sec: 65225.04
Iteration:   3300, Loss function: 4.055, Average Loss: 4.065, avg. samples / sec: 65174.06
Iteration:   3300, Loss function: 3.961, Average Loss: 4.063, avg. samples / sec: 65206.18
Iteration:   3300, Loss function: 2.914, Average Loss: 4.067, avg. samples / sec: 65249.65
Iteration:   3300, Loss function: 3.229, Average Loss: 4.067, avg. samples / sec: 65214.69
Iteration:   3300, Loss function: 3.191, Average Loss: 4.049, avg. samples / sec: 65326.72
Iteration:   3300, Loss function: 2.841, Average Loss: 4.058, avg. samples / sec: 65221.30
Iteration:   3300, Loss function: 3.294, Average Loss: 4.055, avg. samples / sec: 65268.39
Iteration:   3300, Loss function: 2.806, Average Loss: 4.075, avg. samples / sec: 65178.77
Iteration:   3300, Loss function: 3.971, Average Loss: 4.099, avg. samples / sec: 65065.98
Iteration:   3300, Loss function: 3.734, Average Loss: 4.098, avg. samples / sec: 65209.14
Iteration:   3300, Loss function: 3.264, Average Loss: 4.061, avg. samples / sec: 65272.80
Iteration:   3300, Loss function: 3.009, Average Loss: 4.057, avg. samples / sec: 65293.06
Iteration:   3300, Loss function: 3.881, Average Loss: 4.082, avg. samples / sec: 65039.91
Iteration:   3300, Loss function: 3.613, Average Loss: 4.059, avg. samples / sec: 65215.71
Iteration:   3300, Loss function: 2.849, Average Loss: 4.054, avg. samples / sec: 65043.25
Iteration:   3320, Loss function: 2.762, Average Loss: 4.047, avg. samples / sec: 66149.69
Iteration:   3320, Loss function: 3.575, Average Loss: 4.085, avg. samples / sec: 66130.98
Iteration:   3320, Loss function: 3.961, Average Loss: 4.073, avg. samples / sec: 66151.62
Iteration:   3320, Loss function: 3.200, Average Loss: 4.065, avg. samples / sec: 66140.04
Iteration:   3320, Loss function: 3.520, Average Loss: 4.087, avg. samples / sec: 66020.16
Iteration:   3320, Loss function: 3.259, Average Loss: 4.047, avg. samples / sec: 66135.85
Iteration:   3320, Loss function: 4.061, Average Loss: 4.041, avg. samples / sec: 66286.53
Iteration:   3320, Loss function: 3.375, Average Loss: 4.047, avg. samples / sec: 65960.77
Iteration:   3320, Loss function: 3.807, Average Loss: 4.088, avg. samples / sec: 66103.59
Iteration:   3320, Loss function: 3.182, Average Loss: 4.054, avg. samples / sec: 66064.36
Iteration:   3320, Loss function: 4.664, Average Loss: 4.055, avg. samples / sec: 66035.94
Iteration:   3320, Loss function: 3.279, Average Loss: 4.031, avg. samples / sec: 66047.67
Iteration:   3320, Loss function: 4.686, Average Loss: 4.063, avg. samples / sec: 66058.97
Iteration:   3320, Loss function: 3.475, Average Loss: 4.059, avg. samples / sec: 65947.37
Iteration:   3320, Loss function: 4.482, Average Loss: 4.056, avg. samples / sec: 65929.20
Iteration:   3320, Loss function: 3.679, Average Loss: 4.048, avg. samples / sec: 66081.30
Iteration:   3320, Loss function: 3.447, Average Loss: 4.044, avg. samples / sec: 66004.98
Iteration:   3320, Loss function: 3.758, Average Loss: 4.040, avg. samples / sec: 65964.78
Iteration:   3320, Loss function: 3.947, Average Loss: 4.088, avg. samples / sec: 66036.80
Iteration:   3320, Loss function: 4.192, Average Loss: 4.013, avg. samples / sec: 65924.82
Iteration:   3320, Loss function: 3.279, Average Loss: 4.069, avg. samples / sec: 66048.13
Iteration:   3320, Loss function: 3.315, Average Loss: 4.036, avg. samples / sec: 65998.15
Iteration:   3320, Loss function: 3.371, Average Loss: 4.052, avg. samples / sec: 65951.51
Iteration:   3320, Loss function: 2.960, Average Loss: 4.055, avg. samples / sec: 65902.93
Iteration:   3320, Loss function: 2.707, Average Loss: 4.041, avg. samples / sec: 66008.53
Iteration:   3320, Loss function: 4.394, Average Loss: 4.027, avg. samples / sec: 65911.72
Iteration:   3320, Loss function: 2.188, Average Loss: 4.057, avg. samples / sec: 65890.18
Iteration:   3320, Loss function: 2.402, Average Loss: 4.057, avg. samples / sec: 65876.29
Iteration:   3320, Loss function: 2.691, Average Loss: 4.055, avg. samples / sec: 65800.78
Iteration:   3320, Loss function: 3.123, Average Loss: 4.049, avg. samples / sec: 65804.52
Iteration:   3340, Loss function: 3.415, Average Loss: 4.036, avg. samples / sec: 66168.48
Iteration:   3340, Loss function: 3.308, Average Loss: 4.035, avg. samples / sec: 66091.59
Iteration:   3340, Loss function: 3.679, Average Loss: 4.039, avg. samples / sec: 66109.85
Iteration:   3340, Loss function: 2.462, Average Loss: 4.049, avg. samples / sec: 66144.82
Iteration:   3340, Loss function: 4.409, Average Loss: 4.076, avg. samples / sec: 66084.74
Iteration:   3340, Loss function: 3.952, Average Loss: 4.043, avg. samples / sec: 66101.48
Iteration:   3340, Loss function: 3.167, Average Loss: 4.073, avg. samples / sec: 66004.82
Iteration:   3340, Loss function: 3.515, Average Loss: 4.063, avg. samples / sec: 65955.86
Iteration:   3340, Loss function: 3.567, Average Loss: 4.074, avg. samples / sec: 66114.87
Iteration:   3340, Loss function: 3.467, Average Loss: 4.019, avg. samples / sec: 66175.82
Iteration:   3340, Loss function: 3.121, Average Loss: 4.057, avg. samples / sec: 66115.06
Iteration:   3340, Loss function: 3.756, Average Loss: 4.077, avg. samples / sec: 65912.24
Iteration:   3340, Loss function: 4.345, Average Loss: 4.025, avg. samples / sec: 66094.04
Iteration:   3340, Loss function: 3.503, Average Loss: 4.019, avg. samples / sec: 66020.13
Iteration:   3340, Loss function: 2.988, Average Loss: 4.037, avg. samples / sec: 66113.57
Iteration:   3340, Loss function: 3.625, Average Loss: 4.054, avg. samples / sec: 65918.38
Iteration:   3340, Loss function: 4.103, Average Loss: 4.041, avg. samples / sec: 65871.36
Iteration:   3340, Loss function: 1.829, Average Loss: 4.045, avg. samples / sec: 66111.09
Iteration:   3340, Loss function: 4.179, Average Loss: 4.033, avg. samples / sec: 66062.40
Iteration:   3340, Loss function: 4.021, Average Loss: 4.029, avg. samples / sec: 65955.65
Iteration:   3340, Loss function: 3.039, Average Loss: 4.049, avg. samples / sec: 65976.06
Iteration:   3340, Loss function: 4.203, Average Loss: 4.047, avg. samples / sec: 66159.79
Iteration:   3340, Loss function: 3.437, Average Loss: 4.043, avg. samples / sec: 66097.42
Iteration:   3340, Loss function: 3.726, Average Loss: 4.039, avg. samples / sec: 66232.17
Iteration:   3340, Loss function: 2.979, Average Loss: 4.042, avg. samples / sec: 66168.45
Iteration:   3340, Loss function: 3.256, Average Loss: 4.027, avg. samples / sec: 66015.61
Iteration:   3340, Loss function: 2.543, Average Loss: 4.047, avg. samples / sec: 65939.17
Iteration:   3340, Loss function: 4.242, Average Loss: 4.001, avg. samples / sec: 65940.34
Iteration:   3340, Loss function: 2.847, Average Loss: 4.032, avg. samples / sec: 65893.29
Iteration:   3340, Loss function: 4.096, Average Loss: 4.031, avg. samples / sec: 65958.67
:::MLL 1558651951.645 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558651951.646 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 2.860, Average Loss: 4.035, avg. samples / sec: 65837.42
Iteration:   3360, Loss function: 3.686, Average Loss: 4.067, avg. samples / sec: 65751.81
Iteration:   3360, Loss function: 3.862, Average Loss: 4.025, avg. samples / sec: 65720.78
Iteration:   3360, Loss function: 3.751, Average Loss: 4.009, avg. samples / sec: 65797.73
Iteration:   3360, Loss function: 3.120, Average Loss: 4.021, avg. samples / sec: 65829.55
Iteration:   3360, Loss function: 3.484, Average Loss: 4.047, avg. samples / sec: 65750.80
Iteration:   3360, Loss function: 4.360, Average Loss: 4.032, avg. samples / sec: 65654.43
Iteration:   3360, Loss function: 2.538, Average Loss: 4.023, avg. samples / sec: 65629.57
Iteration:   3360, Loss function: 3.693, Average Loss: 4.046, avg. samples / sec: 65749.91
Iteration:   3360, Loss function: 3.793, Average Loss: 4.028, avg. samples / sec: 65777.53
Iteration:   3360, Loss function: 2.718, Average Loss: 4.034, avg. samples / sec: 65657.37
Iteration:   3360, Loss function: 3.736, Average Loss: 4.025, avg. samples / sec: 65782.96
Iteration:   3360, Loss function: 3.966, Average Loss: 4.032, avg. samples / sec: 65792.97
Iteration:   3360, Loss function: 2.816, Average Loss: 4.008, avg. samples / sec: 65711.40
Iteration:   3360, Loss function: 4.404, Average Loss: 4.009, avg. samples / sec: 65702.92
Iteration:   3360, Loss function: 4.085, Average Loss: 4.058, avg. samples / sec: 65661.07
Iteration:   3360, Loss function: 3.201, Average Loss: 4.029, avg. samples / sec: 65763.90
Iteration:   3360, Loss function: 2.970, Average Loss: 3.987, avg. samples / sec: 65854.95
Iteration:   3360, Loss function: 3.621, Average Loss: 4.066, avg. samples / sec: 65594.32
Iteration:   3360, Loss function: 3.891, Average Loss: 4.020, avg. samples / sec: 65854.31
Iteration:   3360, Loss function: 3.493, Average Loss: 4.042, avg. samples / sec: 65690.70
Iteration:   3360, Loss function: 4.140, Average Loss: 4.016, avg. samples / sec: 65687.82
Iteration:   3360, Loss function: 3.175, Average Loss: 4.017, avg. samples / sec: 65831.02
Iteration:   3360, Loss function: 2.782, Average Loss: 4.042, avg. samples / sec: 65659.17
Iteration:   3360, Loss function: 2.801, Average Loss: 4.029, avg. samples / sec: 65688.98
Iteration:   3360, Loss function: 3.128, Average Loss: 4.032, avg. samples / sec: 65683.93
Iteration:   3360, Loss function: 2.825, Average Loss: 4.021, avg. samples / sec: 65667.86
Iteration:   3360, Loss function: 2.061, Average Loss: 4.032, avg. samples / sec: 65634.25
Iteration:   3360, Loss function: 3.485, Average Loss: 4.037, avg. samples / sec: 65569.33
Iteration:   3360, Loss function: 4.373, Average Loss: 4.066, avg. samples / sec: 65491.60
Iteration:   3380, Loss function: 3.120, Average Loss: 4.011, avg. samples / sec: 66197.51
Iteration:   3380, Loss function: 3.238, Average Loss: 4.049, avg. samples / sec: 66230.58
Iteration:   3380, Loss function: 2.901, Average Loss: 4.029, avg. samples / sec: 66250.91
Iteration:   3380, Loss function: 2.918, Average Loss: 4.020, avg. samples / sec: 66159.16
Iteration:   3380, Loss function: 2.992, Average Loss: 4.028, avg. samples / sec: 65953.95
Iteration:   3380, Loss function: 2.724, Average Loss: 4.013, avg. samples / sec: 66065.04
Iteration:   3380, Loss function: 3.231, Average Loss: 4.030, avg. samples / sec: 66087.31
Iteration:   3380, Loss function: 4.626, Average Loss: 4.036, avg. samples / sec: 66058.56
Iteration:   3380, Loss function: 3.318, Average Loss: 4.055, avg. samples / sec: 66162.52
Iteration:   3380, Loss function: 3.151, Average Loss: 4.056, avg. samples / sec: 66297.04
Iteration:   3380, Loss function: 2.830, Average Loss: 4.030, avg. samples / sec: 66184.89
Iteration:   3380, Loss function: 2.964, Average Loss: 4.019, avg. samples / sec: 66222.93
Iteration:   3380, Loss function: 2.371, Average Loss: 3.993, avg. samples / sec: 65983.75
Iteration:   3380, Loss function: 3.754, Average Loss: 3.979, avg. samples / sec: 66101.48
Iteration:   3380, Loss function: 2.316, Average Loss: 4.052, avg. samples / sec: 65963.49
Iteration:   3380, Loss function: 3.214, Average Loss: 4.022, avg. samples / sec: 66011.10
Iteration:   3380, Loss function: 3.244, Average Loss: 4.017, avg. samples / sec: 65967.38
Iteration:   3380, Loss function: 3.517, Average Loss: 4.007, avg. samples / sec: 66115.22
Iteration:   3380, Loss function: 3.915, Average Loss: 4.011, avg. samples / sec: 66097.73
Iteration:   3380, Loss function: 4.395, Average Loss: 4.012, avg. samples / sec: 66179.42
Iteration:   3380, Loss function: 2.737, Average Loss: 4.020, avg. samples / sec: 66003.06
Iteration:   3380, Loss function: 3.142, Average Loss: 3.998, avg. samples / sec: 66012.46
Iteration:   3380, Loss function: 2.912, Average Loss: 4.015, avg. samples / sec: 66131.94
Iteration:   3380, Loss function: 1.660, Average Loss: 4.007, avg. samples / sec: 66097.29
Iteration:   3380, Loss function: 4.553, Average Loss: 4.023, avg. samples / sec: 66180.73
Iteration:   3380, Loss function: 3.194, Average Loss: 4.018, avg. samples / sec: 65940.28
Iteration:   3380, Loss function: 2.712, Average Loss: 4.020, avg. samples / sec: 66105.01
Iteration:   3380, Loss function: 2.793, Average Loss: 4.020, avg. samples / sec: 65920.97
Iteration:   3380, Loss function: 4.266, Average Loss: 3.999, avg. samples / sec: 65973.89
Iteration:   3380, Loss function: 2.913, Average Loss: 4.022, avg. samples / sec: 65978.74
Iteration:   3400, Loss function: 3.223, Average Loss: 4.041, avg. samples / sec: 66038.97
Iteration:   3400, Loss function: 3.967, Average Loss: 4.027, avg. samples / sec: 65906.57
Iteration:   3400, Loss function: 4.232, Average Loss: 3.996, avg. samples / sec: 66026.47
Iteration:   3400, Loss function: 3.590, Average Loss: 4.006, avg. samples / sec: 65823.61
Iteration:   3400, Loss function: 3.387, Average Loss: 3.976, avg. samples / sec: 65930.34
Iteration:   3400, Loss function: 4.332, Average Loss: 4.013, avg. samples / sec: 66048.35
Iteration:   3400, Loss function: 3.726, Average Loss: 4.006, avg. samples / sec: 66029.25
Iteration:   3400, Loss function: 4.132, Average Loss: 4.016, avg. samples / sec: 65913.94
Iteration:   3400, Loss function: 4.271, Average Loss: 4.016, avg. samples / sec: 65910.82
Iteration:   3400, Loss function: 2.359, Average Loss: 3.999, avg. samples / sec: 65918.59
Iteration:   3400, Loss function: 3.780, Average Loss: 4.040, avg. samples / sec: 65763.19
Iteration:   3400, Loss function: 3.446, Average Loss: 4.011, avg. samples / sec: 65933.03
Iteration:   3400, Loss function: 3.395, Average Loss: 4.017, avg. samples / sec: 65767.15
Iteration:   3400, Loss function: 3.950, Average Loss: 4.006, avg. samples / sec: 65877.30
Iteration:   3400, Loss function: 2.992, Average Loss: 4.020, avg. samples / sec: 65793.07
Iteration:   3400, Loss function: 3.324, Average Loss: 4.001, avg. samples / sec: 65896.19
Iteration:   3400, Loss function: 3.765, Average Loss: 4.043, avg. samples / sec: 65851.75
Iteration:   3400, Loss function: 3.501, Average Loss: 4.009, avg. samples / sec: 65925.29
Iteration:   3400, Loss function: 4.275, Average Loss: 4.018, avg. samples / sec: 65774.70
Iteration:   3400, Loss function: 2.991, Average Loss: 4.001, avg. samples / sec: 65764.97
Iteration:   3400, Loss function: 2.081, Average Loss: 3.997, avg. samples / sec: 65615.40
Iteration:   3400, Loss function: 4.493, Average Loss: 4.045, avg. samples / sec: 65778.29
Iteration:   3400, Loss function: 4.033, Average Loss: 4.004, avg. samples / sec: 65888.42
Iteration:   3400, Loss function: 2.536, Average Loss: 3.986, avg. samples / sec: 65813.84
Iteration:   3400, Loss function: 3.003, Average Loss: 4.011, avg. samples / sec: 65916.96
Iteration:   3400, Loss function: 3.212, Average Loss: 4.002, avg. samples / sec: 65834.99
Iteration:   3400, Loss function: 4.326, Average Loss: 3.988, avg. samples / sec: 65841.94
Iteration:   3400, Loss function: 4.238, Average Loss: 4.012, avg. samples / sec: 65851.02
Iteration:   3400, Loss function: 3.287, Average Loss: 4.010, avg. samples / sec: 65762.00
Iteration:   3400, Loss function: 4.692, Average Loss: 3.993, avg. samples / sec: 65866.31
Iteration:   3420, Loss function: 2.796, Average Loss: 3.987, avg. samples / sec: 66370.45
Iteration:   3420, Loss function: 3.928, Average Loss: 3.997, avg. samples / sec: 66244.37
Iteration:   3420, Loss function: 3.532, Average Loss: 4.029, avg. samples / sec: 66103.43
Iteration:   3420, Loss function: 4.316, Average Loss: 3.990, avg. samples / sec: 66254.78
Iteration:   3420, Loss function: 3.629, Average Loss: 4.008, avg. samples / sec: 66199.53
Iteration:   3420, Loss function: 3.429, Average Loss: 4.016, avg. samples / sec: 66076.28
Iteration:   3420, Loss function: 3.530, Average Loss: 4.033, avg. samples / sec: 66245.99
Iteration:   3420, Loss function: 3.503, Average Loss: 4.000, avg. samples / sec: 66188.44
Iteration:   3420, Loss function: 2.611, Average Loss: 3.978, avg. samples / sec: 66240.26
Iteration:   3420, Loss function: 4.515, Average Loss: 4.007, avg. samples / sec: 66182.59
Iteration:   3420, Loss function: 3.039, Average Loss: 3.993, avg. samples / sec: 66113.01
Iteration:   3420, Loss function: 2.420, Average Loss: 4.026, avg. samples / sec: 66138.52
Iteration:   3420, Loss function: 3.568, Average Loss: 3.985, avg. samples / sec: 66111.77
Iteration:   3420, Loss function: 2.591, Average Loss: 3.961, avg. samples / sec: 66106.19
Iteration:   3420, Loss function: 3.032, Average Loss: 4.003, avg. samples / sec: 66110.41
Iteration:   3420, Loss function: 3.351, Average Loss: 3.992, avg. samples / sec: 66143.67
Iteration:   3420, Loss function: 2.861, Average Loss: 4.011, avg. samples / sec: 66136.19
Iteration:   3420, Loss function: 2.900, Average Loss: 4.006, avg. samples / sec: 66066.34
Iteration:   3420, Loss function: 3.681, Average Loss: 3.993, avg. samples / sec: 66175.16
Iteration:   3420, Loss function: 3.162, Average Loss: 3.986, avg. samples / sec: 66220.97
Iteration:   3420, Loss function: 2.605, Average Loss: 3.998, avg. samples / sec: 66018.06
Iteration:   3420, Loss function: 3.106, Average Loss: 4.000, avg. samples / sec: 66172.43
Iteration:   3420, Loss function: 3.581, Average Loss: 3.997, avg. samples / sec: 66057.64
Iteration:   3420, Loss function: 3.005, Average Loss: 4.025, avg. samples / sec: 66067.17
Iteration:   3420, Loss function: 2.746, Average Loss: 3.983, avg. samples / sec: 66117.73
Iteration:   3420, Loss function: 3.455, Average Loss: 3.992, avg. samples / sec: 65944.84
Iteration:   3420, Loss function: 3.927, Average Loss: 3.996, avg. samples / sec: 66064.51
Iteration:   3420, Loss function: 3.182, Average Loss: 3.999, avg. samples / sec: 66047.17
Iteration:   3420, Loss function: 2.167, Average Loss: 4.001, avg. samples / sec: 66041.85
Iteration:   3420, Loss function: 2.332, Average Loss: 3.998, avg. samples / sec: 66083.31
:::MLL 1558651953.412 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.57 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=2.47s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22272
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38258
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22760
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05940
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23348
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36252
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21873
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31733
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09811
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.35872
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52231
Current AP: 0.22272 AP goal: 0.23000
:::MLL 1558651957.008 eval_accuracy: {"value": 0.22271794083492344, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558651957.061 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558651957.067 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558651957.068 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558651957.093 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558651957.093 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.415, Average Loss: 3.972, avg. samples / sec: 8045.65
Iteration:   3440, Loss function: 2.585, Average Loss: 3.997, avg. samples / sec: 8048.02
Iteration:   3440, Loss function: 4.256, Average Loss: 4.010, avg. samples / sec: 8047.28
Iteration:   3440, Loss function: 3.632, Average Loss: 3.980, avg. samples / sec: 8048.26
Iteration:   3440, Loss function: 2.381, Average Loss: 4.015, avg. samples / sec: 8045.61
Iteration:   3440, Loss function: 3.747, Average Loss: 3.970, avg. samples / sec: 8049.01
Iteration:   3440, Loss function: 4.190, Average Loss: 4.016, avg. samples / sec: 8048.47
Iteration:   3440, Loss function: 4.057, Average Loss: 4.000, avg. samples / sec: 8047.19
Iteration:   3440, Loss function: 3.292, Average Loss: 3.992, avg. samples / sec: 8046.19
Iteration:   3440, Loss function: 2.589, Average Loss: 3.949, avg. samples / sec: 8046.77
Iteration:   3440, Loss function: 3.709, Average Loss: 3.988, avg. samples / sec: 8044.13
Iteration:   3440, Loss function: 4.164, Average Loss: 3.993, avg. samples / sec: 8046.80
Iteration:   3440, Loss function: 4.717, Average Loss: 3.987, avg. samples / sec: 8047.44
Iteration:   3440, Loss function: 3.527, Average Loss: 4.021, avg. samples / sec: 8045.41
Iteration:   3440, Loss function: 3.490, Average Loss: 4.021, avg. samples / sec: 8045.93
Iteration:   3440, Loss function: 4.507, Average Loss: 3.994, avg. samples / sec: 8048.43
Iteration:   3440, Loss function: 5.472, Average Loss: 3.970, avg. samples / sec: 8045.78
Iteration:   3440, Loss function: 4.775, Average Loss: 3.994, avg. samples / sec: 8044.96
Iteration:   3440, Loss function: 3.336, Average Loss: 3.981, avg. samples / sec: 8047.20
Iteration:   3440, Loss function: 3.464, Average Loss: 3.984, avg. samples / sec: 8044.51
Iteration:   3440, Loss function: 2.665, Average Loss: 3.968, avg. samples / sec: 8044.43
Iteration:   3440, Loss function: 3.614, Average Loss: 3.985, avg. samples / sec: 8045.18
Iteration:   3440, Loss function: 3.936, Average Loss: 3.983, avg. samples / sec: 8046.79
Iteration:   3440, Loss function: 2.710, Average Loss: 3.984, avg. samples / sec: 8046.02
Iteration:   3440, Loss function: 2.978, Average Loss: 3.983, avg. samples / sec: 8046.46
Iteration:   3440, Loss function: 3.812, Average Loss: 3.976, avg. samples / sec: 8045.18
Iteration:   3440, Loss function: 3.481, Average Loss: 3.992, avg. samples / sec: 8046.26
Iteration:   3440, Loss function: 2.801, Average Loss: 3.981, avg. samples / sec: 8043.19
Iteration:   3440, Loss function: 2.719, Average Loss: 3.990, avg. samples / sec: 8043.24
Iteration:   3440, Loss function: 3.754, Average Loss: 3.986, avg. samples / sec: 8044.25
Iteration:   3460, Loss function: 2.171, Average Loss: 3.991, avg. samples / sec: 66259.89
Iteration:   3460, Loss function: 3.505, Average Loss: 4.005, avg. samples / sec: 66179.64
Iteration:   3460, Loss function: 3.857, Average Loss: 3.977, avg. samples / sec: 66275.75
Iteration:   3460, Loss function: 3.919, Average Loss: 4.000, avg. samples / sec: 66101.97
Iteration:   3460, Loss function: 4.343, Average Loss: 3.977, avg. samples / sec: 66397.56
Iteration:   3460, Loss function: 3.692, Average Loss: 4.008, avg. samples / sec: 66214.90
Iteration:   3460, Loss function: 2.030, Average Loss: 3.983, avg. samples / sec: 66078.67
Iteration:   3460, Loss function: 2.975, Average Loss: 3.968, avg. samples / sec: 66097.29
Iteration:   3460, Loss function: 3.934, Average Loss: 3.985, avg. samples / sec: 66177.03
Iteration:   3460, Loss function: 3.408, Average Loss: 3.963, avg. samples / sec: 66197.64
Iteration:   3460, Loss function: 3.805, Average Loss: 3.986, avg. samples / sec: 66184.98
Iteration:   3460, Loss function: 4.188, Average Loss: 3.978, avg. samples / sec: 66134.02
Iteration:   3460, Loss function: 5.315, Average Loss: 3.978, avg. samples / sec: 66150.47
Iteration:   3460, Loss function: 3.039, Average Loss: 4.004, avg. samples / sec: 66078.23
Iteration:   3460, Loss function: 3.496, Average Loss: 3.984, avg. samples / sec: 66167.77
Iteration:   3460, Loss function: 3.935, Average Loss: 3.950, avg. samples / sec: 66238.46
Iteration:   3460, Loss function: 2.744, Average Loss: 3.973, avg. samples / sec: 66231.05
Iteration:   3460, Loss function: 5.204, Average Loss: 3.980, avg. samples / sec: 66099.49
Iteration:   3460, Loss function: 2.295, Average Loss: 4.013, avg. samples / sec: 66130.48
Iteration:   3460, Loss function: 3.724, Average Loss: 3.982, avg. samples / sec: 66281.39
Iteration:   3460, Loss function: 3.205, Average Loss: 3.974, avg. samples / sec: 66213.69
Iteration:   3460, Loss function: 2.911, Average Loss: 3.974, avg. samples / sec: 66153.02
Iteration:   3460, Loss function: 2.752, Average Loss: 3.975, avg. samples / sec: 66206.13
Iteration:   3460, Loss function: 4.135, Average Loss: 3.963, avg. samples / sec: 65972.84
Iteration:   3460, Loss function: 2.813, Average Loss: 3.970, avg. samples / sec: 66278.43
Iteration:   3460, Loss function: 3.725, Average Loss: 3.938, avg. samples / sec: 66014.10
Iteration:   3460, Loss function: 3.382, Average Loss: 3.973, avg. samples / sec: 66164.57
Iteration:   3460, Loss function: 4.213, Average Loss: 3.962, avg. samples / sec: 65969.01
Iteration:   3460, Loss function: 3.052, Average Loss: 3.977, avg. samples / sec: 66251.66
Iteration:   3460, Loss function: 3.655, Average Loss: 3.969, avg. samples / sec: 66157.74
Iteration:   3480, Loss function: 3.806, Average Loss: 3.999, avg. samples / sec: 66196.11
Iteration:   3480, Loss function: 3.054, Average Loss: 3.992, avg. samples / sec: 66222.87
Iteration:   3480, Loss function: 3.337, Average Loss: 3.971, avg. samples / sec: 66171.68
Iteration:   3480, Loss function: 3.698, Average Loss: 3.966, avg. samples / sec: 66104.02
Iteration:   3480, Loss function: 3.531, Average Loss: 3.975, avg. samples / sec: 66102.62
Iteration:   3480, Loss function: 3.027, Average Loss: 3.950, avg. samples / sec: 66132.68
Iteration:   3480, Loss function: 3.828, Average Loss: 3.961, avg. samples / sec: 66177.46
Iteration:   3480, Loss function: 2.993, Average Loss: 3.964, avg. samples / sec: 66248.73
Iteration:   3480, Loss function: 3.611, Average Loss: 3.961, avg. samples / sec: 66122.85
Iteration:   3480, Loss function: 2.653, Average Loss: 4.003, avg. samples / sec: 66156.15
Iteration:   3480, Loss function: 3.090, Average Loss: 3.992, avg. samples / sec: 66043.98
Iteration:   3480, Loss function: 3.763, Average Loss: 3.927, avg. samples / sec: 66214.71
Iteration:   3480, Loss function: 4.361, Average Loss: 3.974, avg. samples / sec: 65953.95
Iteration:   3480, Loss function: 3.441, Average Loss: 3.946, avg. samples / sec: 66097.63
Iteration:   3480, Loss function: 3.124, Average Loss: 3.975, avg. samples / sec: 66091.06
Iteration:   3480, Loss function: 2.800, Average Loss: 3.969, avg. samples / sec: 66205.44
Iteration:   3480, Loss function: 4.858, Average Loss: 3.962, avg. samples / sec: 66209.80
Iteration:   3480, Loss function: 3.217, Average Loss: 3.969, avg. samples / sec: 66040.86
Iteration:   3480, Loss function: 3.678, Average Loss: 3.964, avg. samples / sec: 66086.29
Iteration:   3480, Loss function: 3.299, Average Loss: 3.958, avg. samples / sec: 66148.95
Iteration:   3480, Loss function: 3.052, Average Loss: 3.970, avg. samples / sec: 66070.21
Iteration:   3480, Loss function: 2.867, Average Loss: 3.954, avg. samples / sec: 66106.22
Iteration:   3480, Loss function: 4.486, Average Loss: 3.964, avg. samples / sec: 66099.40
Iteration:   3480, Loss function: 4.262, Average Loss: 3.955, avg. samples / sec: 66025.63
Iteration:   3480, Loss function: 3.522, Average Loss: 3.994, avg. samples / sec: 65967.28
Iteration:   3480, Loss function: 2.577, Average Loss: 3.945, avg. samples / sec: 66149.63
Iteration:   3480, Loss function: 3.410, Average Loss: 3.969, avg. samples / sec: 66047.11
Iteration:   3480, Loss function: 2.766, Average Loss: 3.969, avg. samples / sec: 66027.49
Iteration:   3480, Loss function: 3.766, Average Loss: 3.968, avg. samples / sec: 65986.65
Iteration:   3480, Loss function: 2.945, Average Loss: 3.972, avg. samples / sec: 65789.66
:::MLL 1558651958.877 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558651958.877 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 3.512, Average Loss: 3.982, avg. samples / sec: 65705.92
Iteration:   3500, Loss function: 2.927, Average Loss: 3.983, avg. samples / sec: 65590.32
Iteration:   3500, Loss function: 3.656, Average Loss: 3.965, avg. samples / sec: 65643.94
Iteration:   3500, Loss function: 5.170, Average Loss: 3.960, avg. samples / sec: 65685.98
Iteration:   3500, Loss function: 4.314, Average Loss: 3.960, avg. samples / sec: 65673.46
Iteration:   3500, Loss function: 3.062, Average Loss: 3.950, avg. samples / sec: 65603.27
Iteration:   3500, Loss function: 5.266, Average Loss: 3.943, avg. samples / sec: 65570.21
Iteration:   3500, Loss function: 3.633, Average Loss: 3.954, avg. samples / sec: 65652.66
Iteration:   3500, Loss function: 3.484, Average Loss: 3.968, avg. samples / sec: 65615.52
Iteration:   3500, Loss function: 4.399, Average Loss: 3.949, avg. samples / sec: 65630.55
Iteration:   3500, Loss function: 3.048, Average Loss: 3.952, avg. samples / sec: 65559.84
Iteration:   3500, Loss function: 2.999, Average Loss: 3.961, avg. samples / sec: 65516.90
Iteration:   3500, Loss function: 3.463, Average Loss: 3.957, avg. samples / sec: 65675.88
Iteration:   3500, Loss function: 3.813, Average Loss: 3.987, avg. samples / sec: 65431.91
Iteration:   3500, Loss function: 3.389, Average Loss: 3.914, avg. samples / sec: 65563.26
Iteration:   3500, Loss function: 4.528, Average Loss: 3.997, avg. samples / sec: 65525.37
Iteration:   3500, Loss function: 3.580, Average Loss: 3.952, avg. samples / sec: 65506.76
Iteration:   3500, Loss function: 5.105, Average Loss: 3.987, avg. samples / sec: 65596.00
Iteration:   3500, Loss function: 2.892, Average Loss: 3.962, avg. samples / sec: 65532.37
Iteration:   3500, Loss function: 2.920, Average Loss: 3.961, avg. samples / sec: 65598.81
Iteration:   3500, Loss function: 3.384, Average Loss: 3.953, avg. samples / sec: 65541.15
Iteration:   3500, Loss function: 4.026, Average Loss: 3.946, avg. samples / sec: 65567.83
Iteration:   3500, Loss function: 3.022, Average Loss: 3.956, avg. samples / sec: 65479.27
Iteration:   3500, Loss function: 3.825, Average Loss: 3.934, avg. samples / sec: 65473.83
Iteration:   3500, Loss function: 2.952, Average Loss: 3.945, avg. samples / sec: 65477.78
Iteration:   3500, Loss function: 2.446, Average Loss: 3.934, avg. samples / sec: 65514.67
Iteration:   3500, Loss function: 4.884, Average Loss: 3.963, avg. samples / sec: 65748.28
Iteration:   3500, Loss function: 2.931, Average Loss: 3.960, avg. samples / sec: 65442.02
Iteration:   3500, Loss function: 3.998, Average Loss: 3.963, avg. samples / sec: 65297.21
Iteration:   3500, Loss function: 3.587, Average Loss: 3.955, avg. samples / sec: 65529.94
Iteration:   3520, Loss function: 3.618, Average Loss: 3.973, avg. samples / sec: 65360.59
Iteration:   3520, Loss function: 3.110, Average Loss: 3.948, avg. samples / sec: 65390.53
Iteration:   3520, Loss function: 3.481, Average Loss: 3.939, avg. samples / sec: 65293.70
Iteration:   3520, Loss function: 2.091, Average Loss: 3.970, avg. samples / sec: 65218.07
Iteration:   3520, Loss function: 3.388, Average Loss: 3.922, avg. samples / sec: 65468.96
Iteration:   3520, Loss function: 3.505, Average Loss: 3.955, avg. samples / sec: 65211.85
Iteration:   3520, Loss function: 4.613, Average Loss: 3.975, avg. samples / sec: 65363.32
Iteration:   3520, Loss function: 2.890, Average Loss: 3.948, avg. samples / sec: 65526.58
Iteration:   3520, Loss function: 3.648, Average Loss: 3.956, avg. samples / sec: 65312.46
Iteration:   3520, Loss function: 3.622, Average Loss: 3.946, avg. samples / sec: 65306.95
Iteration:   3520, Loss function: 2.895, Average Loss: 3.939, avg. samples / sec: 65471.73
Iteration:   3520, Loss function: 3.313, Average Loss: 3.953, avg. samples / sec: 65218.73
Iteration:   3520, Loss function: 3.228, Average Loss: 3.906, avg. samples / sec: 65278.82
Iteration:   3520, Loss function: 3.111, Average Loss: 3.968, avg. samples / sec: 65136.65
Iteration:   3520, Loss function: 3.338, Average Loss: 3.942, avg. samples / sec: 65332.63
Iteration:   3520, Loss function: 3.555, Average Loss: 3.946, avg. samples / sec: 65250.77
Iteration:   3520, Loss function: 2.386, Average Loss: 3.941, avg. samples / sec: 65308.92
Iteration:   3520, Loss function: 3.128, Average Loss: 3.924, avg. samples / sec: 65377.57
Iteration:   3520, Loss function: 3.609, Average Loss: 3.935, avg. samples / sec: 65193.99
Iteration:   3520, Loss function: 2.334, Average Loss: 3.939, avg. samples / sec: 65220.45
Iteration:   3520, Loss function: 3.609, Average Loss: 3.957, avg. samples / sec: 65380.79
Iteration:   3520, Loss function: 2.538, Average Loss: 3.944, avg. samples / sec: 65131.53
Iteration:   3520, Loss function: 2.981, Average Loss: 3.988, avg. samples / sec: 65261.26
Iteration:   3520, Loss function: 4.137, Average Loss: 3.956, avg. samples / sec: 65393.83
Iteration:   3520, Loss function: 2.956, Average Loss: 3.956, avg. samples / sec: 65161.92
Iteration:   3520, Loss function: 4.633, Average Loss: 3.947, avg. samples / sec: 65301.38
Iteration:   3520, Loss function: 4.408, Average Loss: 3.952, avg. samples / sec: 65325.36
Iteration:   3520, Loss function: 3.548, Average Loss: 3.955, avg. samples / sec: 65205.00
Iteration:   3520, Loss function: 3.568, Average Loss: 3.938, avg. samples / sec: 65064.42
Iteration:   3520, Loss function: 3.887, Average Loss: 3.946, avg. samples / sec: 65074.99
Iteration:   3540, Loss function: 3.828, Average Loss: 3.929, avg. samples / sec: 65588.74
Iteration:   3540, Loss function: 2.318, Average Loss: 3.947, avg. samples / sec: 65568.05
Iteration:   3540, Loss function: 2.568, Average Loss: 3.943, avg. samples / sec: 65534.60
Iteration:   3540, Loss function: 3.711, Average Loss: 3.942, avg. samples / sec: 65512.24
Iteration:   3540, Loss function: 2.288, Average Loss: 3.963, avg. samples / sec: 65493.94
Iteration:   3540, Loss function: 2.836, Average Loss: 3.946, avg. samples / sec: 65625.45
Iteration:   3540, Loss function: 2.354, Average Loss: 3.923, avg. samples / sec: 65740.86
Iteration:   3540, Loss function: 3.330, Average Loss: 3.939, avg. samples / sec: 65520.73
Iteration:   3540, Loss function: 3.362, Average Loss: 3.938, avg. samples / sec: 65648.22
Iteration:   3540, Loss function: 4.707, Average Loss: 3.934, avg. samples / sec: 65559.87
Iteration:   3540, Loss function: 3.527, Average Loss: 3.910, avg. samples / sec: 65531.15
Iteration:   3540, Loss function: 3.063, Average Loss: 3.927, avg. samples / sec: 65455.09
Iteration:   3540, Loss function: 2.240, Average Loss: 3.909, avg. samples / sec: 65428.38
Iteration:   3540, Loss function: 3.671, Average Loss: 3.964, avg. samples / sec: 65407.43
Iteration:   3540, Loss function: 3.927, Average Loss: 3.966, avg. samples / sec: 65425.86
Iteration:   3540, Loss function: 3.320, Average Loss: 3.933, avg. samples / sec: 65545.24
Iteration:   3540, Loss function: 2.362, Average Loss: 3.923, avg. samples / sec: 65528.66
Iteration:   3540, Loss function: 3.378, Average Loss: 3.937, avg. samples / sec: 65510.50
Iteration:   3540, Loss function: 2.845, Average Loss: 3.929, avg. samples / sec: 65489.86
Iteration:   3540, Loss function: 3.897, Average Loss: 3.946, avg. samples / sec: 65507.64
Iteration:   3540, Loss function: 2.606, Average Loss: 3.927, avg. samples / sec: 65491.14
Iteration:   3540, Loss function: 2.806, Average Loss: 3.938, avg. samples / sec: 65576.77
Iteration:   3540, Loss function: 4.273, Average Loss: 3.946, avg. samples / sec: 65543.53
Iteration:   3540, Loss function: 3.635, Average Loss: 3.953, avg. samples / sec: 65456.04
Iteration:   3540, Loss function: 4.567, Average Loss: 3.942, avg. samples / sec: 65570.55
Iteration:   3540, Loss function: 3.093, Average Loss: 3.900, avg. samples / sec: 65431.03
Iteration:   3540, Loss function: 3.745, Average Loss: 3.938, avg. samples / sec: 65633.33
Iteration:   3540, Loss function: 3.196, Average Loss: 3.981, avg. samples / sec: 65452.48
Iteration:   3540, Loss function: 2.622, Average Loss: 3.938, avg. samples / sec: 65323.36
Iteration:   3540, Loss function: 3.349, Average Loss: 3.939, avg. samples / sec: 65321.03
:::MLL 1558651960.417 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558651960.417 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 3.383, Average Loss: 3.928, avg. samples / sec: 65770.93
Iteration:   3560, Loss function: 2.737, Average Loss: 3.918, avg. samples / sec: 65807.54
Iteration:   3560, Loss function: 3.302, Average Loss: 3.925, avg. samples / sec: 65662.23
Iteration:   3560, Loss function: 3.359, Average Loss: 3.946, avg. samples / sec: 65771.69
Iteration:   3560, Loss function: 3.699, Average Loss: 3.934, avg. samples / sec: 65587.61
Iteration:   3560, Loss function: 3.391, Average Loss: 3.915, avg. samples / sec: 65740.74
Iteration:   3560, Loss function: 3.391, Average Loss: 3.923, avg. samples / sec: 65706.62
Iteration:   3560, Loss function: 3.349, Average Loss: 3.900, avg. samples / sec: 65662.81
Iteration:   3560, Loss function: 2.673, Average Loss: 3.933, avg. samples / sec: 65611.94
Iteration:   3560, Loss function: 2.410, Average Loss: 3.916, avg. samples / sec: 65672.36
Iteration:   3560, Loss function: 2.300, Average Loss: 3.955, avg. samples / sec: 65671.44
Iteration:   3560, Loss function: 3.728, Average Loss: 3.927, avg. samples / sec: 65834.00
Iteration:   3560, Loss function: 2.523, Average Loss: 3.938, avg. samples / sec: 65694.89
Iteration:   3560, Loss function: 3.504, Average Loss: 3.928, avg. samples / sec: 65607.45
Iteration:   3560, Loss function: 3.734, Average Loss: 3.964, avg. samples / sec: 65730.59
Iteration:   3560, Loss function: 3.145, Average Loss: 3.896, avg. samples / sec: 65661.19
Iteration:   3560, Loss function: 2.611, Average Loss: 3.944, avg. samples / sec: 65573.11
Iteration:   3560, Loss function: 3.388, Average Loss: 3.954, avg. samples / sec: 65648.53
Iteration:   3560, Loss function: 3.410, Average Loss: 3.890, avg. samples / sec: 65714.37
Iteration:   3560, Loss function: 3.355, Average Loss: 3.920, avg. samples / sec: 65452.18
Iteration:   3560, Loss function: 3.755, Average Loss: 3.922, avg. samples / sec: 65584.00
Iteration:   3560, Loss function: 3.127, Average Loss: 3.928, avg. samples / sec: 65535.30
Iteration:   3560, Loss function: 4.045, Average Loss: 3.919, avg. samples / sec: 65608.55
Iteration:   3560, Loss function: 3.401, Average Loss: 3.932, avg. samples / sec: 65673.61
Iteration:   3560, Loss function: 3.654, Average Loss: 3.928, avg. samples / sec: 65664.59
Iteration:   3560, Loss function: 3.082, Average Loss: 3.930, avg. samples / sec: 65604.95
Iteration:   3560, Loss function: 3.772, Average Loss: 3.934, avg. samples / sec: 65574.09
Iteration:   3560, Loss function: 4.522, Average Loss: 3.912, avg. samples / sec: 65483.44
Iteration:   3560, Loss function: 2.133, Average Loss: 3.915, avg. samples / sec: 65511.32
Iteration:   3560, Loss function: 3.894, Average Loss: 3.930, avg. samples / sec: 65590.99
Iteration:   3580, Loss function: 2.862, Average Loss: 3.913, avg. samples / sec: 65348.62
Iteration:   3580, Loss function: 3.028, Average Loss: 3.933, avg. samples / sec: 65486.76
Iteration:   3580, Loss function: 3.441, Average Loss: 3.922, avg. samples / sec: 65429.05
Iteration:   3580, Loss function: 2.978, Average Loss: 3.902, avg. samples / sec: 65609.10
Iteration:   3580, Loss function: 4.281, Average Loss: 3.947, avg. samples / sec: 65464.40
Iteration:   3580, Loss function: 3.456, Average Loss: 3.938, avg. samples / sec: 65482.62
Iteration:   3580, Loss function: 3.811, Average Loss: 3.919, avg. samples / sec: 65532.10
Iteration:   3580, Loss function: 3.096, Average Loss: 3.922, avg. samples / sec: 65442.12
Iteration:   3580, Loss function: 3.737, Average Loss: 3.920, avg. samples / sec: 65426.23
Iteration:   3580, Loss function: 4.605, Average Loss: 3.890, avg. samples / sec: 65443.09
Iteration:   3580, Loss function: 3.932, Average Loss: 3.918, avg. samples / sec: 65338.23
Iteration:   3580, Loss function: 3.030, Average Loss: 3.901, avg. samples / sec: 65538.13
Iteration:   3580, Loss function: 3.928, Average Loss: 3.909, avg. samples / sec: 65479.61
Iteration:   3580, Loss function: 3.418, Average Loss: 3.892, avg. samples / sec: 65385.40
Iteration:   3580, Loss function: 5.313, Average Loss: 3.911, avg. samples / sec: 65403.67
Iteration:   3580, Loss function: 4.028, Average Loss: 3.934, avg. samples / sec: 65349.77
Iteration:   3580, Loss function: 4.900, Average Loss: 3.914, avg. samples / sec: 65454.09
Iteration:   3580, Loss function: 4.280, Average Loss: 3.921, avg. samples / sec: 65563.41
Iteration:   3580, Loss function: 3.706, Average Loss: 3.919, avg. samples / sec: 65375.78
Iteration:   3580, Loss function: 3.927, Average Loss: 3.915, avg. samples / sec: 65358.05
Iteration:   3580, Loss function: 3.065, Average Loss: 3.949, avg. samples / sec: 65388.71
Iteration:   3580, Loss function: 3.039, Average Loss: 3.911, avg. samples / sec: 65416.93
Iteration:   3580, Loss function: 3.664, Average Loss: 3.921, avg. samples / sec: 65425.44
Iteration:   3580, Loss function: 3.074, Average Loss: 3.917, avg. samples / sec: 65425.22
Iteration:   3580, Loss function: 3.914, Average Loss: 3.951, avg. samples / sec: 65334.47
Iteration:   3580, Loss function: 3.892, Average Loss: 3.909, avg. samples / sec: 65180.51
Iteration:   3580, Loss function: 2.458, Average Loss: 3.920, avg. samples / sec: 65426.29
Iteration:   3580, Loss function: 4.384, Average Loss: 3.879, avg. samples / sec: 65285.96
Iteration:   3580, Loss function: 3.389, Average Loss: 3.919, avg. samples / sec: 65339.50
Iteration:   3580, Loss function: 2.057, Average Loss: 3.903, avg. samples / sec: 65180.15
Iteration:   3600, Loss function: 4.101, Average Loss: 3.905, avg. samples / sec: 65833.54
Iteration:   3600, Loss function: 3.229, Average Loss: 3.921, avg. samples / sec: 65803.57
Iteration:   3600, Loss function: 2.845, Average Loss: 3.902, avg. samples / sec: 65708.18
Iteration:   3600, Loss function: 3.461, Average Loss: 3.896, avg. samples / sec: 65765.71
Iteration:   3600, Loss function: 2.993, Average Loss: 3.919, avg. samples / sec: 65747.15
Iteration:   3600, Loss function: 2.706, Average Loss: 3.943, avg. samples / sec: 65892.80
Iteration:   3600, Loss function: 3.182, Average Loss: 3.890, avg. samples / sec: 65786.80
Iteration:   3600, Loss function: 2.648, Average Loss: 3.909, avg. samples / sec: 65851.91
Iteration:   3600, Loss function: 3.514, Average Loss: 3.912, avg. samples / sec: 65741.84
Iteration:   3600, Loss function: 3.962, Average Loss: 3.923, avg. samples / sec: 65790.06
Iteration:   3600, Loss function: 2.851, Average Loss: 3.937, avg. samples / sec: 65713.61
Iteration:   3600, Loss function: 3.310, Average Loss: 3.900, avg. samples / sec: 65869.70
Iteration:   3600, Loss function: 2.433, Average Loss: 3.914, avg. samples / sec: 65685.67
Iteration:   3600, Loss function: 2.204, Average Loss: 3.940, avg. samples / sec: 65807.78
Iteration:   3600, Loss function: 4.434, Average Loss: 3.904, avg. samples / sec: 65778.05
Iteration:   3600, Loss function: 4.246, Average Loss: 3.890, avg. samples / sec: 65926.06
Iteration:   3600, Loss function: 2.283, Average Loss: 3.910, avg. samples / sec: 65769.67
Iteration:   3600, Loss function: 2.516, Average Loss: 3.883, avg. samples / sec: 65736.35
Iteration:   3600, Loss function: 4.295, Average Loss: 3.916, avg. samples / sec: 65719.52
Iteration:   3600, Loss function: 3.461, Average Loss: 3.899, avg. samples / sec: 65731.81
Iteration:   3600, Loss function: 3.634, Average Loss: 3.917, avg. samples / sec: 65638.07
Iteration:   3600, Loss function: 3.512, Average Loss: 3.867, avg. samples / sec: 65802.22
Iteration:   3600, Loss function: 4.063, Average Loss: 3.900, avg. samples / sec: 65655.96
Iteration:   3600, Loss function: 3.531, Average Loss: 3.911, avg. samples / sec: 65835.85
Iteration:   3600, Loss function: 2.932, Average Loss: 3.876, avg. samples / sec: 65618.79
Iteration:   3600, Loss function: 3.123, Average Loss: 3.899, avg. samples / sec: 65647.15
Iteration:   3600, Loss function: 3.067, Average Loss: 3.909, avg. samples / sec: 65734.45
Iteration:   3600, Loss function: 2.583, Average Loss: 3.913, avg. samples / sec: 65689.01
Iteration:   3600, Loss function: 3.688, Average Loss: 3.913, avg. samples / sec: 65605.38
Iteration:   3600, Loss function: 2.885, Average Loss: 3.902, avg. samples / sec: 65622.73
Iteration:   3620, Loss function: 3.302, Average Loss: 3.914, avg. samples / sec: 66066.09
Iteration:   3620, Loss function: 3.689, Average Loss: 3.891, avg. samples / sec: 66055.25
Iteration:   3620, Loss function: 3.245, Average Loss: 3.888, avg. samples / sec: 66208.65
Iteration:   3620, Loss function: 3.209, Average Loss: 3.888, avg. samples / sec: 66118.35
Iteration:   3620, Loss function: 2.888, Average Loss: 3.888, avg. samples / sec: 66003.93
Iteration:   3620, Loss function: 2.312, Average Loss: 3.899, avg. samples / sec: 66109.57
Iteration:   3620, Loss function: 3.487, Average Loss: 3.913, avg. samples / sec: 66054.69
Iteration:   3620, Loss function: 2.390, Average Loss: 3.913, avg. samples / sec: 65981.65
Iteration:   3620, Loss function: 3.784, Average Loss: 3.892, avg. samples / sec: 65994.28
Iteration:   3620, Loss function: 2.640, Average Loss: 3.929, avg. samples / sec: 66031.48
Iteration:   3620, Loss function: 2.789, Average Loss: 3.935, avg. samples / sec: 66046.49
Iteration:   3620, Loss function: 4.325, Average Loss: 3.907, avg. samples / sec: 66134.92
Iteration:   3620, Loss function: 3.377, Average Loss: 3.909, avg. samples / sec: 66117.14
Iteration:   3620, Loss function: 3.622, Average Loss: 3.858, avg. samples / sec: 66095.37
Iteration:   3620, Loss function: 2.284, Average Loss: 3.894, avg. samples / sec: 66124.15
Iteration:   3620, Loss function: 2.971, Average Loss: 3.873, avg. samples / sec: 66026.13
Iteration:   3620, Loss function: 3.339, Average Loss: 3.891, avg. samples / sec: 66096.92
Iteration:   3620, Loss function: 3.994, Average Loss: 3.906, avg. samples / sec: 65976.06
Iteration:   3620, Loss function: 3.978, Average Loss: 3.880, avg. samples / sec: 66006.31
Iteration:   3620, Loss function: 3.145, Average Loss: 3.893, avg. samples / sec: 66003.03
Iteration:   3620, Loss function: 3.050, Average Loss: 3.880, avg. samples / sec: 65937.31
Iteration:   3620, Loss function: 2.821, Average Loss: 3.891, avg. samples / sec: 66118.63
Iteration:   3620, Loss function: 2.527, Average Loss: 3.924, avg. samples / sec: 65946.51
Iteration:   3620, Loss function: 2.643, Average Loss: 3.868, avg. samples / sec: 66071.85
Iteration:   3620, Loss function: 3.850, Average Loss: 3.890, avg. samples / sec: 66056.12
Iteration:   3620, Loss function: 4.079, Average Loss: 3.900, avg. samples / sec: 66064.60
Iteration:   3620, Loss function: 3.419, Average Loss: 3.902, avg. samples / sec: 66048.50
Iteration:   3620, Loss function: 4.217, Average Loss: 3.905, avg. samples / sec: 65916.56
Iteration:   3620, Loss function: 2.440, Average Loss: 3.900, avg. samples / sec: 65807.69
Iteration:   3620, Loss function: 4.672, Average Loss: 3.903, avg. samples / sec: 65858.68
:::MLL 1558651962.208 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558651962.208 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 3.204, Average Loss: 3.901, avg. samples / sec: 65586.66
Iteration:   3640, Loss function: 3.024, Average Loss: 3.884, avg. samples / sec: 65789.99
Iteration:   3640, Loss function: 3.354, Average Loss: 3.889, avg. samples / sec: 65605.53
Iteration:   3640, Loss function: 3.588, Average Loss: 3.882, avg. samples / sec: 65614.14
Iteration:   3640, Loss function: 4.539, Average Loss: 3.919, avg. samples / sec: 65697.34
Iteration:   3640, Loss function: 2.827, Average Loss: 3.895, avg. samples / sec: 65753.31
Iteration:   3640, Loss function: 3.285, Average Loss: 3.881, avg. samples / sec: 65518.42
Iteration:   3640, Loss function: 3.219, Average Loss: 3.887, avg. samples / sec: 65638.10
Iteration:   3640, Loss function: 4.213, Average Loss: 3.880, avg. samples / sec: 65483.04
Iteration:   3640, Loss function: 3.056, Average Loss: 3.881, avg. samples / sec: 65448.50
Iteration:   3640, Loss function: 3.306, Average Loss: 3.918, avg. samples / sec: 65512.33
Iteration:   3640, Loss function: 2.756, Average Loss: 3.881, avg. samples / sec: 65591.61
Iteration:   3640, Loss function: 3.463, Average Loss: 3.867, avg. samples / sec: 65598.38
Iteration:   3640, Loss function: 4.316, Average Loss: 3.897, avg. samples / sec: 65585.47
Iteration:   3640, Loss function: 2.599, Average Loss: 3.850, avg. samples / sec: 65593.38
Iteration:   3640, Loss function: 2.946, Average Loss: 3.881, avg. samples / sec: 65493.70
Iteration:   3640, Loss function: 3.269, Average Loss: 3.869, avg. samples / sec: 65569.42
Iteration:   3640, Loss function: 3.411, Average Loss: 3.890, avg. samples / sec: 65618.30
Iteration:   3640, Loss function: 2.772, Average Loss: 3.888, avg. samples / sec: 65710.18
Iteration:   3640, Loss function: 3.071, Average Loss: 3.859, avg. samples / sec: 65591.91
Iteration:   3640, Loss function: 3.884, Average Loss: 3.928, avg. samples / sec: 65505.32
Iteration:   3640, Loss function: 4.375, Average Loss: 3.885, avg. samples / sec: 65551.06
Iteration:   3640, Loss function: 3.503, Average Loss: 3.890, avg. samples / sec: 65622.73
Iteration:   3640, Loss function: 3.457, Average Loss: 3.874, avg. samples / sec: 65552.80
Iteration:   3640, Loss function: 2.310, Average Loss: 3.902, avg. samples / sec: 65449.41
Iteration:   3640, Loss function: 3.289, Average Loss: 3.892, avg. samples / sec: 65686.10
Iteration:   3640, Loss function: 2.854, Average Loss: 3.899, avg. samples / sec: 65402.09
Iteration:   3640, Loss function: 3.817, Average Loss: 3.908, avg. samples / sec: 65357.08
Iteration:   3640, Loss function: 3.274, Average Loss: 3.897, avg. samples / sec: 65391.41
Iteration:   3640, Loss function: 3.592, Average Loss: 3.887, avg. samples / sec: 65459.50
Iteration:   3660, Loss function: 3.165, Average Loss: 3.871, avg. samples / sec: 63888.66
Iteration:   3660, Loss function: 3.238, Average Loss: 3.887, avg. samples / sec: 63747.40
Iteration:   3660, Loss function: 3.729, Average Loss: 3.884, avg. samples / sec: 63790.95
Iteration:   3660, Loss function: 2.423, Average Loss: 3.870, avg. samples / sec: 63845.91
Iteration:   3660, Loss function: 2.554, Average Loss: 3.895, avg. samples / sec: 63977.06
Iteration:   3660, Loss function: 2.770, Average Loss: 3.876, avg. samples / sec: 63828.94
Iteration:   3660, Loss function: 3.568, Average Loss: 3.912, avg. samples / sec: 63742.99
Iteration:   3660, Loss function: 3.691, Average Loss: 3.882, avg. samples / sec: 63857.74
Iteration:   3660, Loss function: 2.931, Average Loss: 3.880, avg. samples / sec: 63694.07
Iteration:   3660, Loss function: 2.717, Average Loss: 3.877, avg. samples / sec: 63831.11
Iteration:   3660, Loss function: 4.033, Average Loss: 3.876, avg. samples / sec: 63651.76
Iteration:   3660, Loss function: 4.977, Average Loss: 3.890, avg. samples / sec: 63927.21
Iteration:   3660, Loss function: 3.042, Average Loss: 3.888, avg. samples / sec: 63872.97
Iteration:   3660, Loss function: 2.728, Average Loss: 3.839, avg. samples / sec: 63781.39
Iteration:   3660, Loss function: 3.564, Average Loss: 3.886, avg. samples / sec: 63789.53
Iteration:   3660, Loss function: 3.118, Average Loss: 3.882, avg. samples / sec: 63899.73
Iteration:   3660, Loss function: 3.687, Average Loss: 3.874, avg. samples / sec: 63712.13
Iteration:   3660, Loss function: 3.567, Average Loss: 3.880, avg. samples / sec: 63929.87
Iteration:   3660, Loss function: 2.921, Average Loss: 3.875, avg. samples / sec: 63687.02
Iteration:   3660, Loss function: 3.028, Average Loss: 3.909, avg. samples / sec: 63768.29
Iteration:   3660, Loss function: 4.364, Average Loss: 3.881, avg. samples / sec: 63802.06
Iteration:   3660, Loss function: 3.651, Average Loss: 3.864, avg. samples / sec: 63780.70
Iteration:   3660, Loss function: 2.442, Average Loss: 3.855, avg. samples / sec: 63748.04
Iteration:   3660, Loss function: 3.751, Average Loss: 3.866, avg. samples / sec: 63806.54
Iteration:   3660, Loss function: 4.688, Average Loss: 3.888, avg. samples / sec: 63878.67
Iteration:   3660, Loss function: 3.441, Average Loss: 3.874, avg. samples / sec: 63726.82
Iteration:   3660, Loss function: 4.261, Average Loss: 3.884, avg. samples / sec: 63703.80
Iteration:   3660, Loss function: 2.936, Average Loss: 3.916, avg. samples / sec: 63737.25
Iteration:   3660, Loss function: 2.933, Average Loss: 3.878, avg. samples / sec: 63741.52
Iteration:   3660, Loss function: 4.441, Average Loss: 3.854, avg. samples / sec: 63726.33
Iteration:   3680, Loss function: 3.317, Average Loss: 3.897, avg. samples / sec: 66246.31
Iteration:   3680, Loss function: 3.099, Average Loss: 3.865, avg. samples / sec: 66280.86
Iteration:   3680, Loss function: 3.367, Average Loss: 3.847, avg. samples / sec: 66287.78
Iteration:   3680, Loss function: 4.288, Average Loss: 3.862, avg. samples / sec: 66199.66
Iteration:   3680, Loss function: 4.626, Average Loss: 3.871, avg. samples / sec: 66171.22
Iteration:   3680, Loss function: 3.904, Average Loss: 3.857, avg. samples / sec: 66287.47
Iteration:   3680, Loss function: 3.378, Average Loss: 3.846, avg. samples / sec: 66342.14
Iteration:   3680, Loss function: 3.673, Average Loss: 3.863, avg. samples / sec: 66277.90
Iteration:   3680, Loss function: 2.848, Average Loss: 3.883, avg. samples / sec: 66211.79
Iteration:   3680, Loss function: 4.433, Average Loss: 3.860, avg. samples / sec: 66224.39
Iteration:   3680, Loss function: 3.625, Average Loss: 3.898, avg. samples / sec: 66230.09
Iteration:   3680, Loss function: 3.668, Average Loss: 3.871, avg. samples / sec: 66216.61
Iteration:   3680, Loss function: 4.860, Average Loss: 3.867, avg. samples / sec: 66183.12
Iteration:   3680, Loss function: 3.599, Average Loss: 3.888, avg. samples / sec: 66125.67
Iteration:   3680, Loss function: 2.933, Average Loss: 3.862, avg. samples / sec: 66207.09
Iteration:   3680, Loss function: 2.823, Average Loss: 3.861, avg. samples / sec: 66052.77
Iteration:   3680, Loss function: 3.444, Average Loss: 3.876, avg. samples / sec: 66192.57
Iteration:   3680, Loss function: 3.414, Average Loss: 3.875, avg. samples / sec: 66015.46
Iteration:   3680, Loss function: 3.837, Average Loss: 3.870, avg. samples / sec: 66176.22
Iteration:   3680, Loss function: 4.350, Average Loss: 3.875, avg. samples / sec: 66154.29
Iteration:   3680, Loss function: 2.517, Average Loss: 3.830, avg. samples / sec: 66118.19
Iteration:   3680, Loss function: 3.403, Average Loss: 3.868, avg. samples / sec: 66111.87
Iteration:   3680, Loss function: 3.570, Average Loss: 3.880, avg. samples / sec: 66111.68
Iteration:   3680, Loss function: 3.650, Average Loss: 3.880, avg. samples / sec: 66123.37
Iteration:   3680, Loss function: 3.359, Average Loss: 3.907, avg. samples / sec: 66178.18
Iteration:   3680, Loss function: 3.900, Average Loss: 3.871, avg. samples / sec: 66160.78
Iteration:   3680, Loss function: 3.659, Average Loss: 3.870, avg. samples / sec: 66066.89
Iteration:   3680, Loss function: 3.508, Average Loss: 3.880, avg. samples / sec: 66017.25
Iteration:   3680, Loss function: 3.717, Average Loss: 3.873, avg. samples / sec: 65983.72
Iteration:   3680, Loss function: 2.780, Average Loss: 3.862, avg. samples / sec: 65958.05
:::MLL 1558651964.012 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558651964.012 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 2.870, Average Loss: 3.850, avg. samples / sec: 65413.87
Iteration:   3700, Loss function: 2.698, Average Loss: 3.860, avg. samples / sec: 65489.62
Iteration:   3700, Loss function: 3.383, Average Loss: 3.852, avg. samples / sec: 65367.99
Iteration:   3700, Loss function: 3.483, Average Loss: 3.854, avg. samples / sec: 65369.78
Iteration:   3700, Loss function: 4.387, Average Loss: 3.892, avg. samples / sec: 65343.26
Iteration:   3700, Loss function: 3.966, Average Loss: 3.855, avg. samples / sec: 65414.53
Iteration:   3700, Loss function: 3.489, Average Loss: 3.868, avg. samples / sec: 65530.09
Iteration:   3700, Loss function: 3.667, Average Loss: 3.874, avg. samples / sec: 65365.26
Iteration:   3700, Loss function: 2.678, Average Loss: 3.855, avg. samples / sec: 65336.44
Iteration:   3700, Loss function: 3.492, Average Loss: 3.859, avg. samples / sec: 65345.38
Iteration:   3700, Loss function: 3.237, Average Loss: 3.862, avg. samples / sec: 65413.26
Iteration:   3700, Loss function: 3.396, Average Loss: 3.855, avg. samples / sec: 65336.56
Iteration:   3700, Loss function: 2.481, Average Loss: 3.885, avg. samples / sec: 65311.01
Iteration:   3700, Loss function: 4.061, Average Loss: 3.847, avg. samples / sec: 65510.29
Iteration:   3700, Loss function: 3.267, Average Loss: 3.859, avg. samples / sec: 65255.76
Iteration:   3700, Loss function: 3.667, Average Loss: 3.898, avg. samples / sec: 65410.89
Iteration:   3700, Loss function: 1.727, Average Loss: 3.870, avg. samples / sec: 65274.77
Iteration:   3700, Loss function: 3.038, Average Loss: 3.849, avg. samples / sec: 65227.18
Iteration:   3700, Loss function: 3.299, Average Loss: 3.841, avg. samples / sec: 65199.27
Iteration:   3700, Loss function: 3.001, Average Loss: 3.824, avg. samples / sec: 65334.29
Iteration:   3700, Loss function: 3.849, Average Loss: 3.864, avg. samples / sec: 65251.92
Iteration:   3700, Loss function: 4.282, Average Loss: 3.865, avg. samples / sec: 65295.39
Iteration:   3700, Loss function: 3.162, Average Loss: 3.861, avg. samples / sec: 65368.38
Iteration:   3700, Loss function: 3.715, Average Loss: 3.857, avg. samples / sec: 65278.64
Iteration:   3700, Loss function: 3.760, Average Loss: 3.864, avg. samples / sec: 65371.33
Iteration:   3700, Loss function: 3.508, Average Loss: 3.863, avg. samples / sec: 65403.88
Iteration:   3700, Loss function: 4.413, Average Loss: 3.839, avg. samples / sec: 65175.90
Iteration:   3700, Loss function: 2.663, Average Loss: 3.871, avg. samples / sec: 65279.88
Iteration:   3700, Loss function: 4.423, Average Loss: 3.856, avg. samples / sec: 65215.32
Iteration:   3700, Loss function: 2.532, Average Loss: 3.868, avg. samples / sec: 65257.60
Iteration:   3720, Loss function: 3.110, Average Loss: 3.842, avg. samples / sec: 65597.25
Iteration:   3720, Loss function: 3.705, Average Loss: 3.844, avg. samples / sec: 65541.30
Iteration:   3720, Loss function: 3.469, Average Loss: 3.849, avg. samples / sec: 65577.50
Iteration:   3720, Loss function: 3.936, Average Loss: 3.849, avg. samples / sec: 65480.61
Iteration:   3720, Loss function: 2.407, Average Loss: 3.840, avg. samples / sec: 65628.17
Iteration:   3720, Loss function: 3.506, Average Loss: 3.860, avg. samples / sec: 65609.84
Iteration:   3720, Loss function: 3.608, Average Loss: 3.866, avg. samples / sec: 65711.19
Iteration:   3720, Loss function: 3.552, Average Loss: 3.830, avg. samples / sec: 65637.73
Iteration:   3720, Loss function: 3.464, Average Loss: 3.862, avg. samples / sec: 65503.71
Iteration:   3720, Loss function: 2.775, Average Loss: 3.869, avg. samples / sec: 65548.68
Iteration:   3720, Loss function: 3.673, Average Loss: 3.889, avg. samples / sec: 65560.51
Iteration:   3720, Loss function: 3.964, Average Loss: 3.841, avg. samples / sec: 65401.78
Iteration:   3720, Loss function: 4.208, Average Loss: 3.854, avg. samples / sec: 65534.26
Iteration:   3720, Loss function: 3.283, Average Loss: 3.880, avg. samples / sec: 65422.58
Iteration:   3720, Loss function: 3.588, Average Loss: 3.867, avg. samples / sec: 65482.16
Iteration:   3720, Loss function: 4.246, Average Loss: 3.859, avg. samples / sec: 65585.81
Iteration:   3720, Loss function: 4.095, Average Loss: 3.853, avg. samples / sec: 65641.98
Iteration:   3720, Loss function: 3.880, Average Loss: 3.844, avg. samples / sec: 65499.66
Iteration:   3720, Loss function: 3.517, Average Loss: 3.853, avg. samples / sec: 65588.67
Iteration:   3720, Loss function: 3.966, Average Loss: 3.853, avg. samples / sec: 65581.62
Iteration:   3720, Loss function: 2.720, Average Loss: 3.855, avg. samples / sec: 65489.34
Iteration:   3720, Loss function: 3.608, Average Loss: 3.861, avg. samples / sec: 65670.71
Iteration:   3720, Loss function: 3.633, Average Loss: 3.839, avg. samples / sec: 65462.73
Iteration:   3720, Loss function: 4.567, Average Loss: 3.850, avg. samples / sec: 65389.40
Iteration:   3720, Loss function: 3.384, Average Loss: 3.845, avg. samples / sec: 65525.97
Iteration:   3720, Loss function: 3.035, Average Loss: 3.851, avg. samples / sec: 65543.16
Iteration:   3720, Loss function: 3.339, Average Loss: 3.849, avg. samples / sec: 65419.67
Iteration:   3720, Loss function: 4.052, Average Loss: 3.817, avg. samples / sec: 65472.46
Iteration:   3720, Loss function: 3.928, Average Loss: 3.862, avg. samples / sec: 65468.63
Iteration:   3720, Loss function: 2.368, Average Loss: 3.826, avg. samples / sec: 65499.54
Iteration:   3740, Loss function: 2.746, Average Loss: 3.833, avg. samples / sec: 66042.78
Iteration:   3740, Loss function: 2.140, Average Loss: 3.831, avg. samples / sec: 65922.82
Iteration:   3740, Loss function: 3.554, Average Loss: 3.849, avg. samples / sec: 66104.05
Iteration:   3740, Loss function: 3.227, Average Loss: 3.831, avg. samples / sec: 66074.95
Iteration:   3740, Loss function: 3.895, Average Loss: 3.849, avg. samples / sec: 66064.05
Iteration:   3740, Loss function: 4.055, Average Loss: 3.871, avg. samples / sec: 66066.96
Iteration:   3740, Loss function: 3.610, Average Loss: 3.823, avg. samples / sec: 66024.40
Iteration:   3740, Loss function: 3.819, Average Loss: 3.842, avg. samples / sec: 65979.17
Iteration:   3740, Loss function: 3.207, Average Loss: 3.839, avg. samples / sec: 65959.63
Iteration:   3740, Loss function: 2.561, Average Loss: 3.828, avg. samples / sec: 65970.96
Iteration:   3740, Loss function: 3.518, Average Loss: 3.858, avg. samples / sec: 66038.91
Iteration:   3740, Loss function: 3.083, Average Loss: 3.838, avg. samples / sec: 66095.46
Iteration:   3740, Loss function: 3.478, Average Loss: 3.840, avg. samples / sec: 66040.89
Iteration:   3740, Loss function: 3.382, Average Loss: 3.857, avg. samples / sec: 65956.29
Iteration:   3740, Loss function: 2.176, Average Loss: 3.832, avg. samples / sec: 66086.75
Iteration:   3740, Loss function: 4.398, Average Loss: 3.884, avg. samples / sec: 65990.64
Iteration:   3740, Loss function: 3.919, Average Loss: 3.857, avg. samples / sec: 66041.72
Iteration:   3740, Loss function: 3.809, Average Loss: 3.860, avg. samples / sec: 65942.19
Iteration:   3740, Loss function: 4.111, Average Loss: 3.853, avg. samples / sec: 65971.95
Iteration:   3740, Loss function: 4.132, Average Loss: 3.842, avg. samples / sec: 66045.07
Iteration:   3740, Loss function: 3.614, Average Loss: 3.852, avg. samples / sec: 65908.39
Iteration:   3740, Loss function: 4.598, Average Loss: 3.845, avg. samples / sec: 65964.94
Iteration:   3740, Loss function: 3.932, Average Loss: 3.842, avg. samples / sec: 66040.49
Iteration:   3740, Loss function: 2.475, Average Loss: 3.818, avg. samples / sec: 66074.89
Iteration:   3740, Loss function: 3.993, Average Loss: 3.854, avg. samples / sec: 65848.28
Iteration:   3740, Loss function: 2.833, Average Loss: 3.826, avg. samples / sec: 65978.16
Iteration:   3740, Loss function: 3.029, Average Loss: 3.808, avg. samples / sec: 66032.84
Iteration:   3740, Loss function: 1.792, Average Loss: 3.843, avg. samples / sec: 65922.26
Iteration:   3740, Loss function: 4.381, Average Loss: 3.857, avg. samples / sec: 66033.00
Iteration:   3740, Loss function: 2.688, Average Loss: 3.847, avg. samples / sec: 65898.37
Iteration:   3760, Loss function: 2.108, Average Loss: 3.832, avg. samples / sec: 66284.79
Iteration:   3760, Loss function: 4.071, Average Loss: 3.847, avg. samples / sec: 66213.47
Iteration:   3760, Loss function: 3.750, Average Loss: 3.848, avg. samples / sec: 66268.52
Iteration:   3760, Loss function: 4.154, Average Loss: 3.829, avg. samples / sec: 66152.74
Iteration:   3760, Loss function: 2.925, Average Loss: 3.861, avg. samples / sec: 66158.45
Iteration:   3760, Loss function: 4.309, Average Loss: 3.823, avg. samples / sec: 66090.53
Iteration:   3760, Loss function: 2.839, Average Loss: 3.840, avg. samples / sec: 66282.20
Iteration:   3760, Loss function: 2.921, Average Loss: 3.840, avg. samples / sec: 66093.60
Iteration:   3760, Loss function: 2.636, Average Loss: 3.813, avg. samples / sec: 66082.07
Iteration:   3760, Loss function: 4.323, Average Loss: 3.795, avg. samples / sec: 66238.86
Iteration:   3760, Loss function: 3.540, Average Loss: 3.837, avg. samples / sec: 66254.22
Iteration:   3760, Loss function: 4.429, Average Loss: 3.824, avg. samples / sec: 65954.07
Iteration:   3760, Loss function: 3.985, Average Loss: 3.830, avg. samples / sec: 66077.55
Iteration:   3760, Loss function: 2.805, Average Loss: 3.833, avg. samples / sec: 66176.62
Iteration:   3760, Loss function: 2.769, Average Loss: 3.838, avg. samples / sec: 66168.61
Iteration:   3760, Loss function: 3.298, Average Loss: 3.833, avg. samples / sec: 66161.12
Iteration:   3760, Loss function: 3.497, Average Loss: 3.846, avg. samples / sec: 66098.72
Iteration:   3760, Loss function: 4.356, Average Loss: 3.827, avg. samples / sec: 66082.29
Iteration:   3760, Loss function: 2.708, Average Loss: 3.842, avg. samples / sec: 66017.62
Iteration:   3760, Loss function: 3.319, Average Loss: 3.837, avg. samples / sec: 66130.45
Iteration:   3760, Loss function: 3.489, Average Loss: 3.815, avg. samples / sec: 66023.87
Iteration:   3760, Loss function: 3.471, Average Loss: 3.808, avg. samples / sec: 66153.54
Iteration:   3760, Loss function: 3.156, Average Loss: 3.849, avg. samples / sec: 66037.11
Iteration:   3760, Loss function: 4.048, Average Loss: 3.841, avg. samples / sec: 66079.10
Iteration:   3760, Loss function: 3.440, Average Loss: 3.831, avg. samples / sec: 65993.11
Iteration:   3760, Loss function: 3.842, Average Loss: 3.818, avg. samples / sec: 66101.42
Iteration:   3760, Loss function: 4.355, Average Loss: 3.835, avg. samples / sec: 66141.44
Iteration:   3760, Loss function: 2.594, Average Loss: 3.816, avg. samples / sec: 65942.84
Iteration:   3760, Loss function: 3.492, Average Loss: 3.847, avg. samples / sec: 66066.77
Iteration:   3760, Loss function: 3.291, Average Loss: 3.878, avg. samples / sec: 65945.77
:::MLL 1558651965.800 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558651965.801 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 4.106, Average Loss: 3.837, avg. samples / sec: 65231.59
Iteration:   3780, Loss function: 3.414, Average Loss: 3.820, avg. samples / sec: 65232.77
Iteration:   3780, Loss function: 3.588, Average Loss: 3.840, avg. samples / sec: 65187.36
Iteration:   3780, Loss function: 2.837, Average Loss: 3.810, avg. samples / sec: 65203.61
Iteration:   3780, Loss function: 3.280, Average Loss: 3.840, avg. samples / sec: 65419.67
Iteration:   3780, Loss function: 3.791, Average Loss: 3.833, avg. samples / sec: 65197.67
Iteration:   3780, Loss function: 3.445, Average Loss: 3.811, avg. samples / sec: 65361.08
Iteration:   3780, Loss function: 3.080, Average Loss: 3.850, avg. samples / sec: 65134.81
Iteration:   3780, Loss function: 2.949, Average Loss: 3.828, avg. samples / sec: 65206.39
Iteration:   3780, Loss function: 2.824, Average Loss: 3.817, avg. samples / sec: 65213.33
Iteration:   3780, Loss function: 3.297, Average Loss: 3.814, avg. samples / sec: 65202.86
Iteration:   3780, Loss function: 3.187, Average Loss: 3.806, avg. samples / sec: 65175.84
Iteration:   3780, Loss function: 2.360, Average Loss: 3.829, avg. samples / sec: 65300.90
Iteration:   3780, Loss function: 2.024, Average Loss: 3.827, avg. samples / sec: 65221.36
Iteration:   3780, Loss function: 3.357, Average Loss: 3.803, avg. samples / sec: 65249.68
Iteration:   3780, Loss function: 3.458, Average Loss: 3.821, avg. samples / sec: 65300.60
Iteration:   3780, Loss function: 3.912, Average Loss: 3.827, avg. samples / sec: 65211.13
Iteration:   3780, Loss function: 3.380, Average Loss: 3.832, avg. samples / sec: 65145.17
Iteration:   3780, Loss function: 3.582, Average Loss: 3.829, avg. samples / sec: 65016.21
Iteration:   3780, Loss function: 3.348, Average Loss: 3.799, avg. samples / sec: 65214.17
Iteration:   3780, Loss function: 4.336, Average Loss: 3.828, avg. samples / sec: 65192.51
Iteration:   3780, Loss function: 4.280, Average Loss: 3.786, avg. samples / sec: 65132.74
Iteration:   3780, Loss function: 3.298, Average Loss: 3.820, avg. samples / sec: 65159.96
Iteration:   3780, Loss function: 3.282, Average Loss: 3.838, avg. samples / sec: 65165.72
Iteration:   3780, Loss function: 3.207, Average Loss: 3.806, avg. samples / sec: 65228.24
Iteration:   3780, Loss function: 2.769, Average Loss: 3.832, avg. samples / sec: 65103.58
Iteration:   3780, Loss function: 3.167, Average Loss: 3.837, avg. samples / sec: 65142.37
Iteration:   3780, Loss function: 3.840, Average Loss: 3.822, avg. samples / sec: 65102.83
Iteration:   3780, Loss function: 3.951, Average Loss: 3.821, avg. samples / sec: 65102.80
Iteration:   3780, Loss function: 3.152, Average Loss: 3.867, avg. samples / sec: 65047.69
Iteration:   3800, Loss function: 3.015, Average Loss: 3.800, avg. samples / sec: 65608.28
Iteration:   3800, Loss function: 2.430, Average Loss: 3.813, avg. samples / sec: 65503.59
Iteration:   3800, Loss function: 2.867, Average Loss: 3.837, avg. samples / sec: 65569.02
Iteration:   3800, Loss function: 2.618, Average Loss: 3.819, avg. samples / sec: 65583.67
Iteration:   3800, Loss function: 3.291, Average Loss: 3.828, avg. samples / sec: 65444.43
Iteration:   3800, Loss function: 3.227, Average Loss: 3.809, avg. samples / sec: 65558.38
Iteration:   3800, Loss function: 3.876, Average Loss: 3.793, avg. samples / sec: 65593.35
Iteration:   3800, Loss function: 2.543, Average Loss: 3.826, avg. samples / sec: 65675.73
Iteration:   3800, Loss function: 3.292, Average Loss: 3.822, avg. samples / sec: 65552.10
Iteration:   3800, Loss function: 2.912, Average Loss: 3.822, avg. samples / sec: 65513.88
Iteration:   3800, Loss function: 2.731, Average Loss: 3.817, avg. samples / sec: 65520.16
Iteration:   3800, Loss function: 2.254, Average Loss: 3.817, avg. samples / sec: 65527.04
Iteration:   3800, Loss function: 2.988, Average Loss: 3.807, avg. samples / sec: 65570.97
Iteration:   3800, Loss function: 2.697, Average Loss: 3.831, avg. samples / sec: 65422.92
Iteration:   3800, Loss function: 2.944, Average Loss: 3.823, avg. samples / sec: 65532.89
Iteration:   3800, Loss function: 3.755, Average Loss: 3.799, avg. samples / sec: 65631.71
Iteration:   3800, Loss function: 4.003, Average Loss: 3.822, avg. samples / sec: 65523.69
Iteration:   3800, Loss function: 4.829, Average Loss: 3.814, avg. samples / sec: 65616.43
Iteration:   3800, Loss function: 3.095, Average Loss: 3.805, avg. samples / sec: 65475.07
Iteration:   3800, Loss function: 3.962, Average Loss: 3.860, avg. samples / sec: 65804.62
Iteration:   3800, Loss function: 3.302, Average Loss: 3.830, avg. samples / sec: 65595.79
Iteration:   3800, Loss function: 3.229, Average Loss: 3.800, avg. samples / sec: 65454.52
Iteration:   3800, Loss function: 3.402, Average Loss: 3.794, avg. samples / sec: 65443.03
Iteration:   3800, Loss function: 3.158, Average Loss: 3.800, avg. samples / sec: 65401.51
Iteration:   3800, Loss function: 2.665, Average Loss: 3.816, avg. samples / sec: 65464.58
Iteration:   3800, Loss function: 3.644, Average Loss: 3.826, avg. samples / sec: 65354.23
Iteration:   3800, Loss function: 3.001, Average Loss: 3.831, avg. samples / sec: 65489.25
Iteration:   3800, Loss function: 3.325, Average Loss: 3.775, avg. samples / sec: 65465.86
Iteration:   3800, Loss function: 2.685, Average Loss: 3.831, avg. samples / sec: 65339.11
Iteration:   3800, Loss function: 3.098, Average Loss: 3.812, avg. samples / sec: 65597.44
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558651966.833 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=2.48s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22562
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38588
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23049
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05905
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23600
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21921
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31975
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09920
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36391
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52157
Current AP: 0.22562 AP goal: 0.23000
:::MLL 1558651970.483 eval_accuracy: {"value": 0.2256218675226601, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558651970.611 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558651970.618 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558651970.618 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 3.050, Average Loss: 3.821, avg. samples / sec: 7809.88
Iteration:   3820, Loss function: 3.772, Average Loss: 3.812, avg. samples / sec: 7809.10
Iteration:   3820, Loss function: 3.545, Average Loss: 3.797, avg. samples / sec: 7809.51
Iteration:   3820, Loss function: 3.216, Average Loss: 3.792, avg. samples / sec: 7805.85
Iteration:   3820, Loss function: 2.574, Average Loss: 3.823, avg. samples / sec: 7807.36
Iteration:   3820, Loss function: 3.075, Average Loss: 3.797, avg. samples / sec: 7809.10
Iteration:   3820, Loss function: 5.056, Average Loss: 3.801, avg. samples / sec: 7807.45
Iteration:   3820, Loss function: 4.474, Average Loss: 3.799, avg. samples / sec: 7806.49
Iteration:   3820, Loss function: 2.856, Average Loss: 3.805, avg. samples / sec: 7807.58
Iteration:   3820, Loss function: 2.743, Average Loss: 3.815, avg. samples / sec: 7806.88
Iteration:   3820, Loss function: 3.621, Average Loss: 3.853, avg. samples / sec: 7807.90
Iteration:   3820, Loss function: 2.885, Average Loss: 3.785, avg. samples / sec: 7806.85
Iteration:   3820, Loss function: 2.727, Average Loss: 3.814, avg. samples / sec: 7807.00
Iteration:   3820, Loss function: 3.454, Average Loss: 3.820, avg. samples / sec: 7808.65
Iteration:   3820, Loss function: 3.733, Average Loss: 3.829, avg. samples / sec: 7805.74
Iteration:   3820, Loss function: 4.176, Average Loss: 3.817, avg. samples / sec: 7808.34
Iteration:   3820, Loss function: 4.878, Average Loss: 3.814, avg. samples / sec: 7806.49
Iteration:   3820, Loss function: 4.520, Average Loss: 3.813, avg. samples / sec: 7805.71
Iteration:   3820, Loss function: 2.644, Average Loss: 3.789, avg. samples / sec: 7807.56
Iteration:   3820, Loss function: 2.794, Average Loss: 3.811, avg. samples / sec: 7807.81
Iteration:   3820, Loss function: 2.679, Average Loss: 3.817, avg. samples / sec: 7807.90
Iteration:   3820, Loss function: 3.529, Average Loss: 3.788, avg. samples / sec: 7806.51
Iteration:   3820, Loss function: 3.036, Average Loss: 3.822, avg. samples / sec: 7807.09
Iteration:   3820, Loss function: 3.556, Average Loss: 3.806, avg. samples / sec: 7806.16
Iteration:   3820, Loss function: 2.820, Average Loss: 3.801, avg. samples / sec: 7806.06
Iteration:   3820, Loss function: 3.241, Average Loss: 3.816, avg. samples / sec: 7806.10
Iteration:   3820, Loss function: 4.626, Average Loss: 3.807, avg. samples / sec: 7807.84
Iteration:   3820, Loss function: 4.094, Average Loss: 3.768, avg. samples / sec: 7806.80
Iteration:   3820, Loss function: 3.739, Average Loss: 3.789, avg. samples / sec: 7805.91
Iteration:   3820, Loss function: 4.495, Average Loss: 3.811, avg. samples / sec: 7804.63
:::MLL 1558651971.387 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558651971.388 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 3.156, Average Loss: 3.786, avg. samples / sec: 65656.79
Iteration:   3840, Loss function: 3.927, Average Loss: 3.781, avg. samples / sec: 65587.51
Iteration:   3840, Loss function: 2.821, Average Loss: 3.802, avg. samples / sec: 65680.81
Iteration:   3840, Loss function: 3.748, Average Loss: 3.805, avg. samples / sec: 65451.81
Iteration:   3840, Loss function: 4.363, Average Loss: 3.775, avg. samples / sec: 65547.98
Iteration:   3840, Loss function: 3.842, Average Loss: 3.847, avg. samples / sec: 65535.60
Iteration:   3840, Loss function: 3.950, Average Loss: 3.786, avg. samples / sec: 65579.58
Iteration:   3840, Loss function: 3.263, Average Loss: 3.805, avg. samples / sec: 65511.93
Iteration:   3840, Loss function: 4.134, Average Loss: 3.818, avg. samples / sec: 65558.59
Iteration:   3840, Loss function: 3.705, Average Loss: 3.808, avg. samples / sec: 65541.36
Iteration:   3840, Loss function: 3.230, Average Loss: 3.815, avg. samples / sec: 65409.40
Iteration:   3840, Loss function: 3.467, Average Loss: 3.784, avg. samples / sec: 65636.60
Iteration:   3840, Loss function: 4.582, Average Loss: 3.778, avg. samples / sec: 65556.52
Iteration:   3840, Loss function: 3.054, Average Loss: 3.759, avg. samples / sec: 65607.94
Iteration:   3840, Loss function: 4.245, Average Loss: 3.799, avg. samples / sec: 65536.98
Iteration:   3840, Loss function: 2.981, Average Loss: 3.813, avg. samples / sec: 65277.43
Iteration:   3840, Loss function: 2.726, Average Loss: 3.792, avg. samples / sec: 65329.63
Iteration:   3840, Loss function: 3.607, Average Loss: 3.801, avg. samples / sec: 65655.04
Iteration:   3840, Loss function: 3.271, Average Loss: 3.794, avg. samples / sec: 65512.94
Iteration:   3840, Loss function: 3.797, Average Loss: 3.807, avg. samples / sec: 65478.88
Iteration:   3840, Loss function: 3.557, Average Loss: 3.809, avg. samples / sec: 65504.53
Iteration:   3840, Loss function: 4.324, Average Loss: 3.802, avg. samples / sec: 65401.57
Iteration:   3840, Loss function: 3.556, Average Loss: 3.794, avg. samples / sec: 65367.75
Iteration:   3840, Loss function: 4.107, Average Loss: 3.806, avg. samples / sec: 65442.91
Iteration:   3840, Loss function: 3.805, Average Loss: 3.794, avg. samples / sec: 65379.21
Iteration:   3840, Loss function: 2.592, Average Loss: 3.814, avg. samples / sec: 65416.26
Iteration:   3840, Loss function: 4.381, Average Loss: 3.802, avg. samples / sec: 65463.88
Iteration:   3840, Loss function: 2.646, Average Loss: 3.812, avg. samples / sec: 65398.63
Iteration:   3840, Loss function: 3.472, Average Loss: 3.812, avg. samples / sec: 65319.06
Iteration:   3840, Loss function: 3.036, Average Loss: 3.789, avg. samples / sec: 65225.01
Iteration:   3860, Loss function: 3.981, Average Loss: 3.783, avg. samples / sec: 65763.41
Iteration:   3860, Loss function: 2.832, Average Loss: 3.771, avg. samples / sec: 65857.29
Iteration:   3860, Loss function: 3.308, Average Loss: 3.801, avg. samples / sec: 65927.81
Iteration:   3860, Loss function: 3.218, Average Loss: 3.781, avg. samples / sec: 66132.96
Iteration:   3860, Loss function: 3.196, Average Loss: 3.780, avg. samples / sec: 65928.55
Iteration:   3860, Loss function: 3.172, Average Loss: 3.839, avg. samples / sec: 65862.13
Iteration:   3860, Loss function: 4.516, Average Loss: 3.788, avg. samples / sec: 65935.34
Iteration:   3860, Loss function: 3.215, Average Loss: 3.806, avg. samples / sec: 65854.59
Iteration:   3860, Loss function: 3.403, Average Loss: 3.801, avg. samples / sec: 65919.67
Iteration:   3860, Loss function: 3.469, Average Loss: 3.775, avg. samples / sec: 65680.59
Iteration:   3860, Loss function: 3.379, Average Loss: 3.794, avg. samples / sec: 65744.39
Iteration:   3860, Loss function: 2.380, Average Loss: 3.796, avg. samples / sec: 65939.47
Iteration:   3860, Loss function: 3.502, Average Loss: 3.784, avg. samples / sec: 65932.75
Iteration:   3860, Loss function: 2.427, Average Loss: 3.809, avg. samples / sec: 65845.97
Iteration:   3860, Loss function: 4.066, Average Loss: 3.787, avg. samples / sec: 65885.03
Iteration:   3860, Loss function: 3.298, Average Loss: 3.808, avg. samples / sec: 65905.12
Iteration:   3860, Loss function: 3.122, Average Loss: 3.802, avg. samples / sec: 65911.13
Iteration:   3860, Loss function: 3.121, Average Loss: 3.781, avg. samples / sec: 65773.60
Iteration:   3860, Loss function: 4.276, Average Loss: 3.797, avg. samples / sec: 65917.30
Iteration:   3860, Loss function: 3.789, Average Loss: 3.795, avg. samples / sec: 65763.35
Iteration:   3860, Loss function: 3.065, Average Loss: 3.801, avg. samples / sec: 65977.32
Iteration:   3860, Loss function: 4.851, Average Loss: 3.804, avg. samples / sec: 65831.76
Iteration:   3860, Loss function: 3.460, Average Loss: 3.751, avg. samples / sec: 65785.23
Iteration:   3860, Loss function: 3.371, Average Loss: 3.789, avg. samples / sec: 65799.18
Iteration:   3860, Loss function: 3.605, Average Loss: 3.801, avg. samples / sec: 65817.34
Iteration:   3860, Loss function: 3.594, Average Loss: 3.791, avg. samples / sec: 65826.65
Iteration:   3860, Loss function: 2.815, Average Loss: 3.794, avg. samples / sec: 65644.34
Iteration:   3860, Loss function: 3.207, Average Loss: 3.788, avg. samples / sec: 65730.53
Iteration:   3860, Loss function: 4.299, Average Loss: 3.772, avg. samples / sec: 65714.47
Iteration:   3860, Loss function: 3.397, Average Loss: 3.803, avg. samples / sec: 65852.22
Iteration:   3880, Loss function: 3.400, Average Loss: 3.794, avg. samples / sec: 66039.87
Iteration:   3880, Loss function: 1.772, Average Loss: 3.773, avg. samples / sec: 65931.45
Iteration:   3880, Loss function: 3.168, Average Loss: 3.776, avg. samples / sec: 65872.32
Iteration:   3880, Loss function: 3.469, Average Loss: 3.803, avg. samples / sec: 66008.78
Iteration:   3880, Loss function: 2.877, Average Loss: 3.781, avg. samples / sec: 66083.38
Iteration:   3880, Loss function: 3.668, Average Loss: 3.774, avg. samples / sec: 66116.21
Iteration:   3880, Loss function: 3.375, Average Loss: 3.791, avg. samples / sec: 66117.98
Iteration:   3880, Loss function: 2.135, Average Loss: 3.762, avg. samples / sec: 65942.90
Iteration:   3880, Loss function: 4.058, Average Loss: 3.829, avg. samples / sec: 65877.18
Iteration:   3880, Loss function: 3.211, Average Loss: 3.741, avg. samples / sec: 66025.48
Iteration:   3880, Loss function: 2.214, Average Loss: 3.773, avg. samples / sec: 65852.89
Iteration:   3880, Loss function: 4.878, Average Loss: 3.765, avg. samples / sec: 66063.52
Iteration:   3880, Loss function: 3.395, Average Loss: 3.791, avg. samples / sec: 65829.18
Iteration:   3880, Loss function: 3.362, Average Loss: 3.800, avg. samples / sec: 65864.90
Iteration:   3880, Loss function: 3.497, Average Loss: 3.790, avg. samples / sec: 65948.76
Iteration:   3880, Loss function: 3.952, Average Loss: 3.787, avg. samples / sec: 66024.30
Iteration:   3880, Loss function: 3.300, Average Loss: 3.762, avg. samples / sec: 65831.08
Iteration:   3880, Loss function: 3.333, Average Loss: 3.792, avg. samples / sec: 65945.89
Iteration:   3880, Loss function: 4.222, Average Loss: 3.774, avg. samples / sec: 65920.51
Iteration:   3880, Loss function: 2.716, Average Loss: 3.786, avg. samples / sec: 65881.86
Iteration:   3880, Loss function: 2.677, Average Loss: 3.780, avg. samples / sec: 65971.36
Iteration:   3880, Loss function: 2.691, Average Loss: 3.787, avg. samples / sec: 65912.49
Iteration:   3880, Loss function: 3.494, Average Loss: 3.782, avg. samples / sec: 65800.59
Iteration:   3880, Loss function: 3.038, Average Loss: 3.776, avg. samples / sec: 65857.02
Iteration:   3880, Loss function: 3.835, Average Loss: 3.785, avg. samples / sec: 65812.42
Iteration:   3880, Loss function: 3.410, Average Loss: 3.795, avg. samples / sec: 65912.95
Iteration:   3880, Loss function: 3.944, Average Loss: 3.789, avg. samples / sec: 65859.29
Iteration:   3880, Loss function: 3.629, Average Loss: 3.779, avg. samples / sec: 65804.99
Iteration:   3880, Loss function: 2.579, Average Loss: 3.794, avg. samples / sec: 65847.42
Iteration:   3880, Loss function: 3.383, Average Loss: 3.799, avg. samples / sec: 65735.49
Iteration:   3900, Loss function: 3.035, Average Loss: 3.787, avg. samples / sec: 65184.83
Iteration:   3900, Loss function: 3.396, Average Loss: 3.770, avg. samples / sec: 65225.07
Iteration:   3900, Loss function: 2.755, Average Loss: 3.756, avg. samples / sec: 65315.82
Iteration:   3900, Loss function: 2.479, Average Loss: 3.775, avg. samples / sec: 65305.35
Iteration:   3900, Loss function: 2.948, Average Loss: 3.770, avg. samples / sec: 65342.86
Iteration:   3900, Loss function: 2.317, Average Loss: 3.766, avg. samples / sec: 65219.94
Iteration:   3900, Loss function: 3.509, Average Loss: 3.821, avg. samples / sec: 65234.01
Iteration:   3900, Loss function: 3.795, Average Loss: 3.764, avg. samples / sec: 65151.22
Iteration:   3900, Loss function: 3.077, Average Loss: 3.782, avg. samples / sec: 65269.05
Iteration:   3900, Loss function: 3.514, Average Loss: 3.775, avg. samples / sec: 65345.65
Iteration:   3900, Loss function: 3.637, Average Loss: 3.768, avg. samples / sec: 65248.57
Iteration:   3900, Loss function: 2.842, Average Loss: 3.765, avg. samples / sec: 65235.28
Iteration:   3900, Loss function: 3.848, Average Loss: 3.782, avg. samples / sec: 65340.80
Iteration:   3900, Loss function: 2.980, Average Loss: 3.761, avg. samples / sec: 65149.60
Iteration:   3900, Loss function: 1.921, Average Loss: 3.793, avg. samples / sec: 65194.29
Iteration:   3900, Loss function: 3.645, Average Loss: 3.782, avg. samples / sec: 65190.34
Iteration:   3900, Loss function: 2.700, Average Loss: 3.741, avg. samples / sec: 65155.38
Iteration:   3900, Loss function: 4.765, Average Loss: 3.799, avg. samples / sec: 65117.36
Iteration:   3900, Loss function: 3.949, Average Loss: 3.789, avg. samples / sec: 65190.37
Iteration:   3900, Loss function: 3.308, Average Loss: 3.774, avg. samples / sec: 65078.81
Iteration:   3900, Loss function: 3.107, Average Loss: 3.789, avg. samples / sec: 65242.83
Iteration:   3900, Loss function: 2.772, Average Loss: 3.777, avg. samples / sec: 65233.62
Iteration:   3900, Loss function: 1.528, Average Loss: 3.762, avg. samples / sec: 65119.40
Iteration:   3900, Loss function: 3.613, Average Loss: 3.789, avg. samples / sec: 65333.87
Iteration:   3900, Loss function: 3.180, Average Loss: 3.766, avg. samples / sec: 65191.91
Iteration:   3900, Loss function: 4.253, Average Loss: 3.782, avg. samples / sec: 65123.23
Iteration:   3900, Loss function: 2.709, Average Loss: 3.786, avg. samples / sec: 65064.57
Iteration:   3900, Loss function: 2.317, Average Loss: 3.754, avg. samples / sec: 65063.97
Iteration:   3900, Loss function: 2.893, Average Loss: 3.778, avg. samples / sec: 65172.04
Iteration:   3900, Loss function: 2.141, Average Loss: 3.778, avg. samples / sec: 65115.40
:::MLL 1558651973.179 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558651973.179 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 4.416, Average Loss: 3.764, avg. samples / sec: 65616.13
Iteration:   3920, Loss function: 2.567, Average Loss: 3.746, avg. samples / sec: 65639.78
Iteration:   3920, Loss function: 3.857, Average Loss: 3.765, avg. samples / sec: 65554.20
Iteration:   3920, Loss function: 3.144, Average Loss: 3.781, avg. samples / sec: 65685.40
Iteration:   3920, Loss function: 3.519, Average Loss: 3.811, avg. samples / sec: 65546.06
Iteration:   3920, Loss function: 3.234, Average Loss: 3.749, avg. samples / sec: 65709.72
Iteration:   3920, Loss function: 3.813, Average Loss: 3.734, avg. samples / sec: 65606.60
Iteration:   3920, Loss function: 3.842, Average Loss: 3.794, avg. samples / sec: 65604.15
Iteration:   3920, Loss function: 2.630, Average Loss: 3.754, avg. samples / sec: 65587.33
Iteration:   3920, Loss function: 3.558, Average Loss: 3.784, avg. samples / sec: 65576.68
Iteration:   3920, Loss function: 3.398, Average Loss: 3.763, avg. samples / sec: 65553.86
Iteration:   3920, Loss function: 4.105, Average Loss: 3.767, avg. samples / sec: 65701.94
Iteration:   3920, Loss function: 1.933, Average Loss: 3.753, avg. samples / sec: 65493.21
Iteration:   3920, Loss function: 3.274, Average Loss: 3.765, avg. samples / sec: 65611.88
Iteration:   3920, Loss function: 4.213, Average Loss: 3.775, avg. samples / sec: 65493.27
Iteration:   3920, Loss function: 3.901, Average Loss: 3.785, avg. samples / sec: 65567.50
Iteration:   3920, Loss function: 4.335, Average Loss: 3.781, avg. samples / sec: 65615.12
Iteration:   3920, Loss function: 2.701, Average Loss: 3.764, avg. samples / sec: 65438.96
Iteration:   3920, Loss function: 3.068, Average Loss: 3.767, avg. samples / sec: 65472.18
Iteration:   3920, Loss function: 3.482, Average Loss: 3.760, avg. samples / sec: 65415.17
Iteration:   3920, Loss function: 2.873, Average Loss: 3.776, avg. samples / sec: 65488.22
Iteration:   3920, Loss function: 3.378, Average Loss: 3.754, avg. samples / sec: 65467.50
Iteration:   3920, Loss function: 3.061, Average Loss: 3.775, avg. samples / sec: 65557.34
Iteration:   3920, Loss function: 2.790, Average Loss: 3.776, avg. samples / sec: 65544.05
Iteration:   3920, Loss function: 2.479, Average Loss: 3.751, avg. samples / sec: 65521.80
Iteration:   3920, Loss function: 4.516, Average Loss: 3.771, avg. samples / sec: 65557.98
Iteration:   3920, Loss function: 2.616, Average Loss: 3.776, avg. samples / sec: 65258.75
Iteration:   3920, Loss function: 4.678, Average Loss: 3.775, avg. samples / sec: 65402.06
Iteration:   3920, Loss function: 4.014, Average Loss: 3.775, avg. samples / sec: 65421.82
Iteration:   3920, Loss function: 4.305, Average Loss: 3.761, avg. samples / sec: 65457.31
Iteration:   3940, Loss function: 3.248, Average Loss: 3.757, avg. samples / sec: 65029.74
Iteration:   3940, Loss function: 3.022, Average Loss: 3.735, avg. samples / sec: 64992.97
Iteration:   3940, Loss function: 2.876, Average Loss: 3.806, avg. samples / sec: 65115.43
Iteration:   3940, Loss function: 3.639, Average Loss: 3.770, avg. samples / sec: 65299.54
Iteration:   3940, Loss function: 3.130, Average Loss: 3.756, avg. samples / sec: 65183.71
Iteration:   3940, Loss function: 2.857, Average Loss: 3.744, avg. samples / sec: 65223.59
Iteration:   3940, Loss function: 2.710, Average Loss: 3.749, avg. samples / sec: 65091.49
Iteration:   3940, Loss function: 2.461, Average Loss: 3.767, avg. samples / sec: 65236.85
Iteration:   3940, Loss function: 2.704, Average Loss: 3.770, avg. samples / sec: 65042.92
Iteration:   3940, Loss function: 3.150, Average Loss: 3.751, avg. samples / sec: 65013.12
Iteration:   3940, Loss function: 3.310, Average Loss: 3.746, avg. samples / sec: 65087.16
Iteration:   3940, Loss function: 3.181, Average Loss: 3.766, avg. samples / sec: 65155.86
Iteration:   3940, Loss function: 3.622, Average Loss: 3.744, avg. samples / sec: 65156.92
Iteration:   3940, Loss function: 2.191, Average Loss: 3.761, avg. samples / sec: 65108.36
Iteration:   3940, Loss function: 3.789, Average Loss: 3.742, avg. samples / sec: 65004.87
Iteration:   3940, Loss function: 2.858, Average Loss: 3.751, avg. samples / sec: 65100.96
Iteration:   3940, Loss function: 3.301, Average Loss: 3.754, avg. samples / sec: 65029.38
Iteration:   3940, Loss function: 3.687, Average Loss: 3.759, avg. samples / sec: 65008.53
Iteration:   3940, Loss function: 5.115, Average Loss: 3.768, avg. samples / sec: 65099.40
Iteration:   3940, Loss function: 2.917, Average Loss: 3.783, avg. samples / sec: 64943.91
Iteration:   3940, Loss function: 3.356, Average Loss: 3.750, avg. samples / sec: 65204.22
Iteration:   3940, Loss function: 2.169, Average Loss: 3.729, avg. samples / sec: 64968.79
Iteration:   3940, Loss function: 2.841, Average Loss: 3.781, avg. samples / sec: 65026.86
Iteration:   3940, Loss function: 4.346, Average Loss: 3.766, avg. samples / sec: 65193.21
Iteration:   3940, Loss function: 4.436, Average Loss: 3.755, avg. samples / sec: 64988.21
Iteration:   3940, Loss function: 4.033, Average Loss: 3.768, avg. samples / sec: 65067.99
Iteration:   3940, Loss function: 2.730, Average Loss: 3.776, avg. samples / sec: 64975.29
Iteration:   3940, Loss function: 3.324, Average Loss: 3.770, avg. samples / sec: 64992.58
Iteration:   3940, Loss function: 2.693, Average Loss: 3.774, avg. samples / sec: 64969.36
Iteration:   3940, Loss function: 3.320, Average Loss: 3.765, avg. samples / sec: 65056.19
Iteration:   3960, Loss function: 3.452, Average Loss: 3.744, avg. samples / sec: 65971.42
Iteration:   3960, Loss function: 3.165, Average Loss: 3.741, avg. samples / sec: 65939.38
Iteration:   3960, Loss function: 3.164, Average Loss: 3.746, avg. samples / sec: 65783.54
Iteration:   3960, Loss function: 3.062, Average Loss: 3.729, avg. samples / sec: 65778.94
Iteration:   3960, Loss function: 3.951, Average Loss: 3.766, avg. samples / sec: 66035.26
Iteration:   3960, Loss function: 3.290, Average Loss: 3.769, avg. samples / sec: 65992.52
Iteration:   3960, Loss function: 3.245, Average Loss: 3.736, avg. samples / sec: 65891.81
Iteration:   3960, Loss function: 4.024, Average Loss: 3.763, avg. samples / sec: 65973.95
Iteration:   3960, Loss function: 2.818, Average Loss: 3.749, avg. samples / sec: 65951.42
Iteration:   3960, Loss function: 2.757, Average Loss: 3.749, avg. samples / sec: 65778.39
Iteration:   3960, Loss function: 2.930, Average Loss: 3.726, avg. samples / sec: 65786.37
Iteration:   3960, Loss function: 3.643, Average Loss: 3.762, avg. samples / sec: 65781.03
Iteration:   3960, Loss function: 3.695, Average Loss: 3.753, avg. samples / sec: 65844.15
Iteration:   3960, Loss function: 3.956, Average Loss: 3.741, avg. samples / sec: 65835.88
Iteration:   3960, Loss function: 2.602, Average Loss: 3.763, avg. samples / sec: 65939.47
Iteration:   3960, Loss function: 4.159, Average Loss: 3.757, avg. samples / sec: 65788.61
Iteration:   3960, Loss function: 3.366, Average Loss: 3.736, avg. samples / sec: 65859.08
Iteration:   3960, Loss function: 2.586, Average Loss: 3.798, avg. samples / sec: 65717.53
Iteration:   3960, Loss function: 2.822, Average Loss: 3.764, avg. samples / sec: 65903.89
Iteration:   3960, Loss function: 2.474, Average Loss: 3.755, avg. samples / sec: 65831.14
Iteration:   3960, Loss function: 2.952, Average Loss: 3.758, avg. samples / sec: 65875.36
Iteration:   3960, Loss function: 3.332, Average Loss: 3.739, avg. samples / sec: 65847.78
Iteration:   3960, Loss function: 3.414, Average Loss: 3.750, avg. samples / sec: 65866.62
Iteration:   3960, Loss function: 3.637, Average Loss: 3.763, avg. samples / sec: 65838.74
Iteration:   3960, Loss function: 4.051, Average Loss: 3.775, avg. samples / sec: 65847.57
Iteration:   3960, Loss function: 3.245, Average Loss: 3.725, avg. samples / sec: 65833.48
Iteration:   3960, Loss function: 4.567, Average Loss: 3.744, avg. samples / sec: 65796.94
Iteration:   3960, Loss function: 4.534, Average Loss: 3.757, avg. samples / sec: 65898.99
Iteration:   3960, Loss function: 3.992, Average Loss: 3.761, avg. samples / sec: 65673.25
Iteration:   3960, Loss function: 4.577, Average Loss: 3.749, avg. samples / sec: 65714.59
:::MLL 1558651974.974 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558651974.974 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.015, Average Loss: 3.725, avg. samples / sec: 65860.28
Iteration:   3980, Loss function: 3.551, Average Loss: 3.728, avg. samples / sec: 65760.68
Iteration:   3980, Loss function: 3.411, Average Loss: 3.771, avg. samples / sec: 65838.80
Iteration:   3980, Loss function: 2.979, Average Loss: 3.736, avg. samples / sec: 65783.97
Iteration:   3980, Loss function: 2.896, Average Loss: 3.745, avg. samples / sec: 65805.69
Iteration:   3980, Loss function: 3.106, Average Loss: 3.738, avg. samples / sec: 65725.50
Iteration:   3980, Loss function: 2.814, Average Loss: 3.729, avg. samples / sec: 65762.89
Iteration:   3980, Loss function: 2.317, Average Loss: 3.752, avg. samples / sec: 65687.14
Iteration:   3980, Loss function: 3.697, Average Loss: 3.758, avg. samples / sec: 65664.40
Iteration:   3980, Loss function: 3.101, Average Loss: 3.735, avg. samples / sec: 65585.71
Iteration:   3980, Loss function: 3.232, Average Loss: 3.756, avg. samples / sec: 65653.36
Iteration:   3980, Loss function: 4.298, Average Loss: 3.791, avg. samples / sec: 65733.22
Iteration:   3980, Loss function: 3.448, Average Loss: 3.735, avg. samples / sec: 65735.80
Iteration:   3980, Loss function: 3.518, Average Loss: 3.712, avg. samples / sec: 65767.89
Iteration:   3980, Loss function: 3.284, Average Loss: 3.739, avg. samples / sec: 65770.44
Iteration:   3980, Loss function: 3.335, Average Loss: 3.737, avg. samples / sec: 65586.45
Iteration:   3980, Loss function: 3.568, Average Loss: 3.756, avg. samples / sec: 65649.81
Iteration:   3980, Loss function: 3.219, Average Loss: 3.734, avg. samples / sec: 65481.58
Iteration:   3980, Loss function: 2.731, Average Loss: 3.719, avg. samples / sec: 65640.64
Iteration:   3980, Loss function: 4.361, Average Loss: 3.744, avg. samples / sec: 65610.78
Iteration:   3980, Loss function: 3.651, Average Loss: 3.740, avg. samples / sec: 65702.49
Iteration:   3980, Loss function: 2.364, Average Loss: 3.756, avg. samples / sec: 65744.23
Iteration:   3980, Loss function: 3.784, Average Loss: 3.757, avg. samples / sec: 65651.19
Iteration:   3980, Loss function: 3.517, Average Loss: 3.751, avg. samples / sec: 65654.06
Iteration:   3980, Loss function: 3.291, Average Loss: 3.754, avg. samples / sec: 65668.66
Iteration:   3980, Loss function: 3.974, Average Loss: 3.757, avg. samples / sec: 65591.42
Iteration:   3980, Loss function: 2.766, Average Loss: 3.745, avg. samples / sec: 65759.23
Iteration:   3980, Loss function: 2.348, Average Loss: 3.749, avg. samples / sec: 65565.42
Iteration:   3980, Loss function: 3.751, Average Loss: 3.754, avg. samples / sec: 65621.38
Iteration:   3980, Loss function: 3.854, Average Loss: 3.744, avg. samples / sec: 65472.64
Iteration:   4000, Loss function: 4.355, Average Loss: 3.732, avg. samples / sec: 66146.99
Iteration:   4000, Loss function: 3.392, Average Loss: 3.740, avg. samples / sec: 66265.90
Iteration:   4000, Loss function: 2.974, Average Loss: 3.752, avg. samples / sec: 66057.51
Iteration:   4000, Loss function: 2.824, Average Loss: 3.745, avg. samples / sec: 65996.60
Iteration:   4000, Loss function: 3.612, Average Loss: 3.713, avg. samples / sec: 66050.24
Iteration:   4000, Loss function: 4.053, Average Loss: 3.737, avg. samples / sec: 66098.97
Iteration:   4000, Loss function: 2.248, Average Loss: 3.727, avg. samples / sec: 66000.46
Iteration:   4000, Loss function: 3.422, Average Loss: 3.742, avg. samples / sec: 65957.03
Iteration:   4000, Loss function: 2.885, Average Loss: 3.726, avg. samples / sec: 65891.10
Iteration:   4000, Loss function: 3.081, Average Loss: 3.764, avg. samples / sec: 65884.23
Iteration:   4000, Loss function: 2.915, Average Loss: 3.738, avg. samples / sec: 65883.68
Iteration:   4000, Loss function: 4.870, Average Loss: 3.731, avg. samples / sec: 65896.86
Iteration:   4000, Loss function: 4.294, Average Loss: 3.730, avg. samples / sec: 65913.91
Iteration:   4000, Loss function: 2.713, Average Loss: 3.725, avg. samples / sec: 65978.19
Iteration:   4000, Loss function: 2.120, Average Loss: 3.749, avg. samples / sec: 66004.70
Iteration:   4000, Loss function: 2.923, Average Loss: 3.729, avg. samples / sec: 65938.89
Iteration:   4000, Loss function: 3.556, Average Loss: 3.790, avg. samples / sec: 65918.22
Iteration:   4000, Loss function: 3.985, Average Loss: 3.740, avg. samples / sec: 65965.62
Iteration:   4000, Loss function: 3.540, Average Loss: 3.720, avg. samples / sec: 65787.14
Iteration:   4000, Loss function: 5.009, Average Loss: 3.750, avg. samples / sec: 66079.35
Iteration:   4000, Loss function: 2.746, Average Loss: 3.747, avg. samples / sec: 65994.41
Iteration:   4000, Loss function: 3.639, Average Loss: 3.719, avg. samples / sec: 65662.75
Iteration:   4000, Loss function: 3.894, Average Loss: 3.724, avg. samples / sec: 65832.71
Iteration:   4000, Loss function: 2.505, Average Loss: 3.741, avg. samples / sec: 65998.15
Iteration:   4000, Loss function: 3.293, Average Loss: 3.744, avg. samples / sec: 65929.57
Iteration:   4000, Loss function: 3.033, Average Loss: 3.749, avg. samples / sec: 65918.66
Iteration:   4000, Loss function: 3.490, Average Loss: 3.735, avg. samples / sec: 65875.43
Iteration:   4000, Loss function: 2.964, Average Loss: 3.704, avg. samples / sec: 65814.42
Iteration:   4000, Loss function: 3.559, Average Loss: 3.754, avg. samples / sec: 65751.01
Iteration:   4000, Loss function: 3.826, Average Loss: 3.747, avg. samples / sec: 65763.78
Iteration:   4020, Loss function: 2.534, Average Loss: 3.723, avg. samples / sec: 65980.60
Iteration:   4020, Loss function: 3.647, Average Loss: 3.719, avg. samples / sec: 65992.86
Iteration:   4020, Loss function: 3.142, Average Loss: 3.720, avg. samples / sec: 66008.32
Iteration:   4020, Loss function: 2.440, Average Loss: 3.776, avg. samples / sec: 66023.81
Iteration:   4020, Loss function: 3.628, Average Loss: 3.748, avg. samples / sec: 65992.74
Iteration:   4020, Loss function: 3.575, Average Loss: 3.710, avg. samples / sec: 66039.06
Iteration:   4020, Loss function: 3.523, Average Loss: 3.724, avg. samples / sec: 65984.61
Iteration:   4020, Loss function: 4.547, Average Loss: 3.714, avg. samples / sec: 66027.68
Iteration:   4020, Loss function: 4.617, Average Loss: 3.706, avg. samples / sec: 65887.90
Iteration:   4020, Loss function: 4.260, Average Loss: 3.727, avg. samples / sec: 65799.73
Iteration:   4020, Loss function: 2.550, Average Loss: 3.722, avg. samples / sec: 66028.17
Iteration:   4020, Loss function: 3.522, Average Loss: 3.742, avg. samples / sec: 65870.34
Iteration:   4020, Loss function: 2.923, Average Loss: 3.721, avg. samples / sec: 65939.54
Iteration:   4020, Loss function: 2.607, Average Loss: 3.732, avg. samples / sec: 65937.28
Iteration:   4020, Loss function: 2.843, Average Loss: 3.745, avg. samples / sec: 66020.13
Iteration:   4020, Loss function: 3.271, Average Loss: 3.738, avg. samples / sec: 65823.95
Iteration:   4020, Loss function: 3.829, Average Loss: 3.744, avg. samples / sec: 66069.19
Iteration:   4020, Loss function: 3.184, Average Loss: 3.738, avg. samples / sec: 65855.51
Iteration:   4020, Loss function: 4.185, Average Loss: 3.730, avg. samples / sec: 65925.13
Iteration:   4020, Loss function: 3.826, Average Loss: 3.727, avg. samples / sec: 66004.30
Iteration:   4020, Loss function: 4.288, Average Loss: 3.739, avg. samples / sec: 66168.58
Iteration:   4020, Loss function: 2.940, Average Loss: 3.734, avg. samples / sec: 65800.35
Iteration:   4020, Loss function: 3.127, Average Loss: 3.744, avg. samples / sec: 65911.93
Iteration:   4020, Loss function: 3.027, Average Loss: 3.741, avg. samples / sec: 65923.62
Iteration:   4020, Loss function: 3.405, Average Loss: 3.698, avg. samples / sec: 65981.92
Iteration:   4020, Loss function: 3.480, Average Loss: 3.731, avg. samples / sec: 65924.27
Iteration:   4020, Loss function: 3.134, Average Loss: 3.730, avg. samples / sec: 65785.69
Iteration:   4020, Loss function: 3.495, Average Loss: 3.759, avg. samples / sec: 65823.06
Iteration:   4020, Loss function: 3.709, Average Loss: 3.724, avg. samples / sec: 65819.83
Iteration:   4020, Loss function: 4.504, Average Loss: 3.735, avg. samples / sec: 65846.22
Iteration:   4040, Loss function: 2.623, Average Loss: 3.723, avg. samples / sec: 66168.64
Iteration:   4040, Loss function: 3.718, Average Loss: 3.716, avg. samples / sec: 66019.20
Iteration:   4040, Loss function: 3.220, Average Loss: 3.714, avg. samples / sec: 66016.14
Iteration:   4040, Loss function: 2.589, Average Loss: 3.720, avg. samples / sec: 65981.00
Iteration:   4040, Loss function: 4.285, Average Loss: 3.737, avg. samples / sec: 66047.14
Iteration:   4040, Loss function: 3.452, Average Loss: 3.702, avg. samples / sec: 65966.64
Iteration:   4040, Loss function: 4.296, Average Loss: 3.702, avg. samples / sec: 65969.85
Iteration:   4040, Loss function: 3.711, Average Loss: 3.714, avg. samples / sec: 65950.27
Iteration:   4040, Loss function: 3.671, Average Loss: 3.728, avg. samples / sec: 66036.77
Iteration:   4040, Loss function: 3.331, Average Loss: 3.727, avg. samples / sec: 65968.18
Iteration:   4040, Loss function: 3.762, Average Loss: 3.719, avg. samples / sec: 66001.30
Iteration:   4040, Loss function: 3.469, Average Loss: 3.739, avg. samples / sec: 65956.42
Iteration:   4040, Loss function: 4.686, Average Loss: 3.719, avg. samples / sec: 65847.02
Iteration:   4040, Loss function: 2.158, Average Loss: 3.716, avg. samples / sec: 66066.24
Iteration:   4040, Loss function: 3.479, Average Loss: 3.714, avg. samples / sec: 65843.42
Iteration:   4040, Loss function: 4.246, Average Loss: 3.717, avg. samples / sec: 65900.07
Iteration:   4040, Loss function: 2.795, Average Loss: 3.739, avg. samples / sec: 65864.06
Iteration:   4040, Loss function: 2.697, Average Loss: 3.763, avg. samples / sec: 65843.14
Iteration:   4040, Loss function: 2.978, Average Loss: 3.704, avg. samples / sec: 65840.68
Iteration:   4040, Loss function: 3.389, Average Loss: 3.694, avg. samples / sec: 65970.53
Iteration:   4040, Loss function: 3.052, Average Loss: 3.749, avg. samples / sec: 65988.01
Iteration:   4040, Loss function: 3.570, Average Loss: 3.731, avg. samples / sec: 66041.48
Iteration:   4040, Loss function: 3.275, Average Loss: 3.732, avg. samples / sec: 65899.36
Iteration:   4040, Loss function: 3.032, Average Loss: 3.726, avg. samples / sec: 65879.09
Iteration:   4040, Loss function: 2.502, Average Loss: 3.717, avg. samples / sec: 65890.39
Iteration:   4040, Loss function: 3.203, Average Loss: 3.735, avg. samples / sec: 65797.67
Iteration:   4040, Loss function: 3.678, Average Loss: 3.730, avg. samples / sec: 65824.99
Iteration:   4040, Loss function: 3.684, Average Loss: 3.738, avg. samples / sec: 65820.26
Iteration:   4040, Loss function: 2.967, Average Loss: 3.724, avg. samples / sec: 65891.04
Iteration:   4040, Loss function: 3.007, Average Loss: 3.736, avg. samples / sec: 65751.04
:::MLL 1558651976.759 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558651976.760 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 3.343, Average Loss: 3.695, avg. samples / sec: 65630.37
Iteration:   4060, Loss function: 3.200, Average Loss: 3.705, avg. samples / sec: 65594.14
Iteration:   4060, Loss function: 2.852, Average Loss: 3.732, avg. samples / sec: 65776.21
Iteration:   4060, Loss function: 2.032, Average Loss: 3.723, avg. samples / sec: 65611.09
Iteration:   4060, Loss function: 2.755, Average Loss: 3.705, avg. samples / sec: 65521.65
Iteration:   4060, Loss function: 3.007, Average Loss: 3.711, avg. samples / sec: 65624.96
Iteration:   4060, Loss function: 3.601, Average Loss: 3.697, avg. samples / sec: 65661.10
Iteration:   4060, Loss function: 3.475, Average Loss: 3.711, avg. samples / sec: 65699.70
Iteration:   4060, Loss function: 3.205, Average Loss: 3.717, avg. samples / sec: 65497.20
Iteration:   4060, Loss function: 2.783, Average Loss: 3.720, avg. samples / sec: 65709.81
Iteration:   4060, Loss function: 4.047, Average Loss: 3.712, avg. samples / sec: 65545.63
Iteration:   4060, Loss function: 2.800, Average Loss: 3.692, avg. samples / sec: 65492.45
Iteration:   4060, Loss function: 2.522, Average Loss: 3.725, avg. samples / sec: 65598.81
Iteration:   4060, Loss function: 3.984, Average Loss: 3.731, avg. samples / sec: 65548.47
Iteration:   4060, Loss function: 4.123, Average Loss: 3.708, avg. samples / sec: 65450.75
Iteration:   4060, Loss function: 3.269, Average Loss: 3.727, avg. samples / sec: 65774.24
Iteration:   4060, Loss function: 3.170, Average Loss: 3.731, avg. samples / sec: 65449.53
Iteration:   4060, Loss function: 3.693, Average Loss: 3.722, avg. samples / sec: 65592.77
Iteration:   4060, Loss function: 3.239, Average Loss: 3.733, avg. samples / sec: 65480.85
Iteration:   4060, Loss function: 2.793, Average Loss: 3.720, avg. samples / sec: 65436.46
Iteration:   4060, Loss function: 1.688, Average Loss: 3.728, avg. samples / sec: 65621.90
Iteration:   4060, Loss function: 2.982, Average Loss: 3.709, avg. samples / sec: 65461.18
Iteration:   4060, Loss function: 3.109, Average Loss: 3.687, avg. samples / sec: 65520.37
Iteration:   4060, Loss function: 3.087, Average Loss: 3.719, avg. samples / sec: 65571.59
Iteration:   4060, Loss function: 3.732, Average Loss: 3.727, avg. samples / sec: 65566.67
Iteration:   4060, Loss function: 2.404, Average Loss: 3.708, avg. samples / sec: 65443.09
Iteration:   4060, Loss function: 4.368, Average Loss: 3.711, avg. samples / sec: 65411.41
Iteration:   4060, Loss function: 3.595, Average Loss: 3.720, avg. samples / sec: 65293.09
Iteration:   4060, Loss function: 2.356, Average Loss: 3.743, avg. samples / sec: 65435.04
Iteration:   4060, Loss function: 3.697, Average Loss: 3.758, avg. samples / sec: 65401.84
Iteration:   4080, Loss function: 3.193, Average Loss: 3.698, avg. samples / sec: 66098.25
Iteration:   4080, Loss function: 3.760, Average Loss: 3.696, avg. samples / sec: 66041.20
Iteration:   4080, Loss function: 2.881, Average Loss: 3.713, avg. samples / sec: 66199.19
Iteration:   4080, Loss function: 3.555, Average Loss: 3.698, avg. samples / sec: 66147.86
Iteration:   4080, Loss function: 2.848, Average Loss: 3.714, avg. samples / sec: 66055.93
Iteration:   4080, Loss function: 1.962, Average Loss: 3.690, avg. samples / sec: 65945.99
Iteration:   4080, Loss function: 3.160, Average Loss: 3.687, avg. samples / sec: 66004.02
Iteration:   4080, Loss function: 3.497, Average Loss: 3.687, avg. samples / sec: 66048.01
Iteration:   4080, Loss function: 2.272, Average Loss: 3.723, avg. samples / sec: 65940.43
Iteration:   4080, Loss function: 2.242, Average Loss: 3.701, avg. samples / sec: 66204.82
Iteration:   4080, Loss function: 3.534, Average Loss: 3.749, avg. samples / sec: 66231.14
Iteration:   4080, Loss function: 3.630, Average Loss: 3.699, avg. samples / sec: 66154.48
Iteration:   4080, Loss function: 4.276, Average Loss: 3.702, avg. samples / sec: 66108.21
Iteration:   4080, Loss function: 4.153, Average Loss: 3.705, avg. samples / sec: 65954.23
Iteration:   4080, Loss function: 3.965, Average Loss: 3.723, avg. samples / sec: 66039.03
Iteration:   4080, Loss function: 3.047, Average Loss: 3.715, avg. samples / sec: 66045.16
Iteration:   4080, Loss function: 2.776, Average Loss: 3.721, avg. samples / sec: 65911.63
Iteration:   4080, Loss function: 2.948, Average Loss: 3.729, avg. samples / sec: 66035.04
Iteration:   4080, Loss function: 4.122, Average Loss: 3.709, avg. samples / sec: 65937.72
Iteration:   4080, Loss function: 2.925, Average Loss: 3.700, avg. samples / sec: 65894.03
Iteration:   4080, Loss function: 3.486, Average Loss: 3.680, avg. samples / sec: 66005.75
Iteration:   4080, Loss function: 3.014, Average Loss: 3.722, avg. samples / sec: 65972.44
Iteration:   4080, Loss function: 2.059, Average Loss: 3.736, avg. samples / sec: 66093.26
Iteration:   4080, Loss function: 3.884, Average Loss: 3.718, avg. samples / sec: 66056.68
Iteration:   4080, Loss function: 3.219, Average Loss: 3.719, avg. samples / sec: 65949.04
Iteration:   4080, Loss function: 4.305, Average Loss: 3.715, avg. samples / sec: 65899.95
Iteration:   4080, Loss function: 2.687, Average Loss: 3.717, avg. samples / sec: 65969.97
Iteration:   4080, Loss function: 3.660, Average Loss: 3.712, avg. samples / sec: 65998.36
Iteration:   4080, Loss function: 2.875, Average Loss: 3.718, avg. samples / sec: 65993.42
Iteration:   4080, Loss function: 3.444, Average Loss: 3.718, avg. samples / sec: 65876.01
Iteration:   4100, Loss function: 2.305, Average Loss: 3.715, avg. samples / sec: 65718.23
Iteration:   4100, Loss function: 3.535, Average Loss: 3.685, avg. samples / sec: 65713.67
Iteration:   4100, Loss function: 3.646, Average Loss: 3.709, avg. samples / sec: 65626.39
Iteration:   4100, Loss function: 4.328, Average Loss: 3.690, avg. samples / sec: 65559.35
Iteration:   4100, Loss function: 4.187, Average Loss: 3.691, avg. samples / sec: 65459.20
Iteration:   4100, Loss function: 3.261, Average Loss: 3.708, avg. samples / sec: 65794.97
Iteration:   4100, Loss function: 3.214, Average Loss: 3.714, avg. samples / sec: 65748.04
Iteration:   4100, Loss function: 3.077, Average Loss: 3.739, avg. samples / sec: 65601.59
Iteration:   4100, Loss function: 3.303, Average Loss: 3.717, avg. samples / sec: 65682.22
Iteration:   4100, Loss function: 2.441, Average Loss: 3.678, avg. samples / sec: 65556.21
Iteration:   4100, Loss function: 3.025, Average Loss: 3.689, avg. samples / sec: 65607.73
Iteration:   4100, Loss function: 2.327, Average Loss: 3.694, avg. samples / sec: 65589.41
Iteration:   4100, Loss function: 3.969, Average Loss: 3.694, avg. samples / sec: 65478.02
Iteration:   4100, Loss function: 4.382, Average Loss: 3.674, avg. samples / sec: 65706.99
Iteration:   4100, Loss function: 3.089, Average Loss: 3.702, avg. samples / sec: 65585.53
Iteration:   4100, Loss function: 2.951, Average Loss: 3.711, avg. samples / sec: 65732.34
Iteration:   4100, Loss function: 4.829, Average Loss: 3.714, avg. samples / sec: 65786.68
Iteration:   4100, Loss function: 2.663, Average Loss: 3.699, avg. samples / sec: 65471.61
Iteration:   4100, Loss function: 4.003, Average Loss: 3.712, avg. samples / sec: 65681.82
Iteration:   4100, Loss function: 3.135, Average Loss: 3.696, avg. samples / sec: 65567.50
Iteration:   4100, Loss function: 2.537, Average Loss: 3.679, avg. samples / sec: 65517.84
Iteration:   4100, Loss function: 4.056, Average Loss: 3.702, avg. samples / sec: 65610.32
Iteration:   4100, Loss function: 3.884, Average Loss: 3.712, avg. samples / sec: 65641.74
Iteration:   4100, Loss function: 2.912, Average Loss: 3.720, avg. samples / sec: 65543.62
Iteration:   4100, Loss function: 3.136, Average Loss: 3.696, avg. samples / sec: 65597.74
Iteration:   4100, Loss function: 3.245, Average Loss: 3.718, avg. samples / sec: 65516.29
Iteration:   4100, Loss function: 3.051, Average Loss: 3.707, avg. samples / sec: 65501.43
Iteration:   4100, Loss function: 3.440, Average Loss: 3.714, avg. samples / sec: 65574.54
Iteration:   4100, Loss function: 2.271, Average Loss: 3.709, avg. samples / sec: 65549.44
Iteration:   4100, Loss function: 2.765, Average Loss: 3.728, avg. samples / sec: 65509.07
:::MLL 1558651978.548 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558651978.549 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 3.185, Average Loss: 3.702, avg. samples / sec: 65679.70
Iteration:   4120, Loss function: 4.249, Average Loss: 3.698, avg. samples / sec: 65763.93
Iteration:   4120, Loss function: 3.309, Average Loss: 3.677, avg. samples / sec: 65750.95
Iteration:   4120, Loss function: 2.525, Average Loss: 3.682, avg. samples / sec: 65724.00
Iteration:   4120, Loss function: 3.438, Average Loss: 3.710, avg. samples / sec: 65667.86
Iteration:   4120, Loss function: 3.551, Average Loss: 3.669, avg. samples / sec: 65704.05
Iteration:   4120, Loss function: 2.430, Average Loss: 3.691, avg. samples / sec: 65698.90
Iteration:   4120, Loss function: 3.588, Average Loss: 3.684, avg. samples / sec: 65659.02
Iteration:   4120, Loss function: 2.809, Average Loss: 3.681, avg. samples / sec: 65474.31
Iteration:   4120, Loss function: 2.903, Average Loss: 3.667, avg. samples / sec: 65672.79
Iteration:   4120, Loss function: 3.395, Average Loss: 3.709, avg. samples / sec: 65478.09
Iteration:   4120, Loss function: 3.848, Average Loss: 3.682, avg. samples / sec: 65553.80
Iteration:   4120, Loss function: 4.142, Average Loss: 3.705, avg. samples / sec: 65540.85
Iteration:   4120, Loss function: 3.109, Average Loss: 3.707, avg. samples / sec: 65663.09
Iteration:   4120, Loss function: 2.839, Average Loss: 3.717, avg. samples / sec: 65803.33
Iteration:   4120, Loss function: 3.325, Average Loss: 3.733, avg. samples / sec: 65556.39
Iteration:   4120, Loss function: 3.810, Average Loss: 3.686, avg. samples / sec: 65518.08
Iteration:   4120, Loss function: 4.028, Average Loss: 3.711, avg. samples / sec: 65551.24
Iteration:   4120, Loss function: 2.999, Average Loss: 3.706, avg. samples / sec: 65716.76
Iteration:   4120, Loss function: 3.404, Average Loss: 3.685, avg. samples / sec: 65564.48
Iteration:   4120, Loss function: 3.953, Average Loss: 3.709, avg. samples / sec: 65604.49
Iteration:   4120, Loss function: 3.760, Average Loss: 3.714, avg. samples / sec: 65652.69
Iteration:   4120, Loss function: 3.647, Average Loss: 3.697, avg. samples / sec: 65615.67
Iteration:   4120, Loss function: 3.019, Average Loss: 3.694, avg. samples / sec: 65658.19
Iteration:   4120, Loss function: 4.026, Average Loss: 3.706, avg. samples / sec: 65567.07
Iteration:   4120, Loss function: 3.555, Average Loss: 3.693, avg. samples / sec: 65585.01
Iteration:   4120, Loss function: 2.448, Average Loss: 3.699, avg. samples / sec: 65652.93
Iteration:   4120, Loss function: 4.713, Average Loss: 3.707, avg. samples / sec: 65690.24
Iteration:   4120, Loss function: 2.916, Average Loss: 3.715, avg. samples / sec: 65558.44
Iteration:   4120, Loss function: 3.246, Average Loss: 3.709, avg. samples / sec: 65542.49
Iteration:   4140, Loss function: 2.893, Average Loss: 3.676, avg. samples / sec: 65906.94
Iteration:   4140, Loss function: 4.005, Average Loss: 3.666, avg. samples / sec: 65692.07
Iteration:   4140, Loss function: 3.500, Average Loss: 3.673, avg. samples / sec: 65676.92
Iteration:   4140, Loss function: 2.947, Average Loss: 3.692, avg. samples / sec: 65665.87
Iteration:   4140, Loss function: 3.161, Average Loss: 3.668, avg. samples / sec: 65816.85
Iteration:   4140, Loss function: 3.059, Average Loss: 3.680, avg. samples / sec: 65745.74
Iteration:   4140, Loss function: 3.696, Average Loss: 3.698, avg. samples / sec: 65631.07
Iteration:   4140, Loss function: 2.929, Average Loss: 3.707, avg. samples / sec: 65884.20
Iteration:   4140, Loss function: 3.296, Average Loss: 3.701, avg. samples / sec: 65766.17
Iteration:   4140, Loss function: 2.682, Average Loss: 3.681, avg. samples / sec: 65696.91
Iteration:   4140, Loss function: 2.270, Average Loss: 3.712, avg. samples / sec: 65781.49
Iteration:   4140, Loss function: 4.000, Average Loss: 3.697, avg. samples / sec: 65794.02
Iteration:   4140, Loss function: 4.130, Average Loss: 3.706, avg. samples / sec: 65717.50
Iteration:   4140, Loss function: 3.978, Average Loss: 3.686, avg. samples / sec: 65723.35
Iteration:   4140, Loss function: 3.773, Average Loss: 3.729, avg. samples / sec: 65730.22
Iteration:   4140, Loss function: 5.191, Average Loss: 3.688, avg. samples / sec: 65755.74
Iteration:   4140, Loss function: 4.080, Average Loss: 3.698, avg. samples / sec: 65761.32
Iteration:   4140, Loss function: 2.805, Average Loss: 3.679, avg. samples / sec: 65732.64
Iteration:   4140, Loss function: 4.351, Average Loss: 3.704, avg. samples / sec: 65700.62
Iteration:   4140, Loss function: 2.625, Average Loss: 3.697, avg. samples / sec: 65702.30
Iteration:   4140, Loss function: 3.277, Average Loss: 3.699, avg. samples / sec: 65543.01
Iteration:   4140, Loss function: 2.539, Average Loss: 3.685, avg. samples / sec: 65667.49
Iteration:   4140, Loss function: 3.328, Average Loss: 3.702, avg. samples / sec: 65731.23
Iteration:   4140, Loss function: 3.724, Average Loss: 3.679, avg. samples / sec: 65604.25
Iteration:   4140, Loss function: 3.977, Average Loss: 3.710, avg. samples / sec: 65629.91
Iteration:   4140, Loss function: 3.558, Average Loss: 3.701, avg. samples / sec: 65626.06
Iteration:   4140, Loss function: 3.655, Average Loss: 3.694, avg. samples / sec: 65673.55
Iteration:   4140, Loss function: 3.297, Average Loss: 3.662, avg. samples / sec: 65570.64
Iteration:   4140, Loss function: 3.474, Average Loss: 3.701, avg. samples / sec: 65566.67
Iteration:   4140, Loss function: 3.383, Average Loss: 3.664, avg. samples / sec: 65474.04
Iteration:   4160, Loss function: 3.912, Average Loss: 3.688, avg. samples / sec: 65977.26
Iteration:   4160, Loss function: 3.575, Average Loss: 3.703, avg. samples / sec: 66016.79
Iteration:   4160, Loss function: 3.317, Average Loss: 3.671, avg. samples / sec: 65935.59
Iteration:   4160, Loss function: 3.143, Average Loss: 3.667, avg. samples / sec: 65905.37
Iteration:   4160, Loss function: 3.575, Average Loss: 3.697, avg. samples / sec: 66139.14
Iteration:   4160, Loss function: 3.642, Average Loss: 3.691, avg. samples / sec: 65958.58
Iteration:   4160, Loss function: 4.183, Average Loss: 3.665, avg. samples / sec: 65847.17
Iteration:   4160, Loss function: 3.272, Average Loss: 3.658, avg. samples / sec: 66100.27
Iteration:   4160, Loss function: 3.161, Average Loss: 3.666, avg. samples / sec: 65805.08
Iteration:   4160, Loss function: 3.192, Average Loss: 3.704, avg. samples / sec: 65930.74
Iteration:   4160, Loss function: 3.988, Average Loss: 3.699, avg. samples / sec: 65894.24
Iteration:   4160, Loss function: 3.873, Average Loss: 3.689, avg. samples / sec: 65845.11
Iteration:   4160, Loss function: 2.608, Average Loss: 3.688, avg. samples / sec: 65975.99
Iteration:   4160, Loss function: 4.238, Average Loss: 3.695, avg. samples / sec: 65880.48
Iteration:   4160, Loss function: 3.055, Average Loss: 3.689, avg. samples / sec: 65969.97
Iteration:   4160, Loss function: 2.972, Average Loss: 3.656, avg. samples / sec: 66070.08
Iteration:   4160, Loss function: 2.613, Average Loss: 3.675, avg. samples / sec: 65877.18
Iteration:   4160, Loss function: 3.231, Average Loss: 3.720, avg. samples / sec: 65919.03
Iteration:   4160, Loss function: 2.535, Average Loss: 3.695, avg. samples / sec: 65952.65
Iteration:   4160, Loss function: 2.337, Average Loss: 3.689, avg. samples / sec: 65948.98
Iteration:   4160, Loss function: 3.786, Average Loss: 3.681, avg. samples / sec: 65974.57
Iteration:   4160, Loss function: 3.229, Average Loss: 3.691, avg. samples / sec: 65937.10
Iteration:   4160, Loss function: 3.298, Average Loss: 3.677, avg. samples / sec: 65900.01
Iteration:   4160, Loss function: 3.526, Average Loss: 3.662, avg. samples / sec: 65764.51
Iteration:   4160, Loss function: 3.113, Average Loss: 3.694, avg. samples / sec: 65963.05
Iteration:   4160, Loss function: 3.742, Average Loss: 3.681, avg. samples / sec: 65859.17
Iteration:   4160, Loss function: 3.929, Average Loss: 3.703, avg. samples / sec: 65913.60
Iteration:   4160, Loss function: 3.357, Average Loss: 3.694, avg. samples / sec: 65872.28
Iteration:   4160, Loss function: 4.203, Average Loss: 3.687, avg. samples / sec: 65834.90
Iteration:   4160, Loss function: 3.424, Average Loss: 3.674, avg. samples / sec: 65824.93
Iteration:   4180, Loss function: 4.408, Average Loss: 3.679, avg. samples / sec: 65860.56
Iteration:   4180, Loss function: 2.795, Average Loss: 3.676, avg. samples / sec: 65990.36
Iteration:   4180, Loss function: 2.555, Average Loss: 3.661, avg. samples / sec: 65892.95
Iteration:   4180, Loss function: 4.679, Average Loss: 3.663, avg. samples / sec: 65831.51
Iteration:   4180, Loss function: 3.426, Average Loss: 3.698, avg. samples / sec: 65845.42
Iteration:   4180, Loss function: 2.551, Average Loss: 3.713, avg. samples / sec: 65882.35
Iteration:   4180, Loss function: 3.689, Average Loss: 3.694, avg. samples / sec: 65743.56
Iteration:   4180, Loss function: 5.219, Average Loss: 3.692, avg. samples / sec: 65825.61
Iteration:   4180, Loss function: 4.393, Average Loss: 3.657, avg. samples / sec: 65864.56
Iteration:   4180, Loss function: 3.235, Average Loss: 3.685, avg. samples / sec: 65837.79
Iteration:   4180, Loss function: 2.743, Average Loss: 3.683, avg. samples / sec: 65749.78
Iteration:   4180, Loss function: 3.511, Average Loss: 3.671, avg. samples / sec: 65838.56
Iteration:   4180, Loss function: 3.262, Average Loss: 3.681, avg. samples / sec: 65769.21
Iteration:   4180, Loss function: 3.004, Average Loss: 3.665, avg. samples / sec: 65700.31
Iteration:   4180, Loss function: 4.148, Average Loss: 3.692, avg. samples / sec: 65717.16
Iteration:   4180, Loss function: 4.027, Average Loss: 3.697, avg. samples / sec: 65738.44
Iteration:   4180, Loss function: 2.536, Average Loss: 3.667, avg. samples / sec: 65961.60
Iteration:   4180, Loss function: 2.897, Average Loss: 3.671, avg. samples / sec: 65770.50
Iteration:   4180, Loss function: 4.083, Average Loss: 3.654, avg. samples / sec: 65679.70
Iteration:   4180, Loss function: 3.724, Average Loss: 3.650, avg. samples / sec: 65762.06
Iteration:   4180, Loss function: 3.603, Average Loss: 3.678, avg. samples / sec: 65729.58
Iteration:   4180, Loss function: 3.417, Average Loss: 3.685, avg. samples / sec: 65903.06
Iteration:   4180, Loss function: 2.078, Average Loss: 3.676, avg. samples / sec: 65941.39
Iteration:   4180, Loss function: 4.098, Average Loss: 3.683, avg. samples / sec: 65784.90
Iteration:   4180, Loss function: 4.366, Average Loss: 3.693, avg. samples / sec: 65730.96
Iteration:   4180, Loss function: 4.488, Average Loss: 3.682, avg. samples / sec: 65672.79
Iteration:   4180, Loss function: 3.631, Average Loss: 3.691, avg. samples / sec: 65747.33
Iteration:   4180, Loss function: 3.360, Average Loss: 3.650, avg. samples / sec: 65619.12
Iteration:   4180, Loss function: 3.110, Average Loss: 3.676, avg. samples / sec: 65753.40
Iteration:   4180, Loss function: 3.277, Average Loss: 3.697, avg. samples / sec: 65633.52
:::MLL 1558651980.337 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558651980.337 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558651980.389 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.63 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=2.50s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22972
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39201
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23285
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06013
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24078
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37220
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22314
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32452
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34085
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10237
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36767
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53045
Current AP: 0.22972 AP goal: 0.23000
:::MLL 1558651984.095 eval_accuracy: {"value": 0.2297222930678287, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558651984.249 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558651984.256 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558651984.257 block_start: {"value": null, "metadata": {"first_epoch_num": 61, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   4200, Loss function: 3.245, Average Loss: 3.673, avg. samples / sec: 7656.76
Iteration:   4200, Loss function: 3.874, Average Loss: 3.689, avg. samples / sec: 7659.94
Iteration:   4200, Loss function: 2.915, Average Loss: 3.648, avg. samples / sec: 7659.13
Iteration:   4200, Loss function: 3.553, Average Loss: 3.669, avg. samples / sec: 7656.50
Iteration:   4200, Loss function: 3.029, Average Loss: 3.693, avg. samples / sec: 7657.24
Iteration:   4200, Loss function: 2.905, Average Loss: 3.650, avg. samples / sec: 7658.77
Iteration:   4200, Loss function: 2.913, Average Loss: 3.653, avg. samples / sec: 7657.17
Iteration:   4200, Loss function: 2.756, Average Loss: 3.674, avg. samples / sec: 7657.80
Iteration:   4200, Loss function: 3.497, Average Loss: 3.643, avg. samples / sec: 7657.58
Iteration:   4200, Loss function: 3.008, Average Loss: 3.678, avg. samples / sec: 7658.58
Iteration:   4200, Loss function: 3.693, Average Loss: 3.685, avg. samples / sec: 7659.42
Iteration:   4200, Loss function: 2.715, Average Loss: 3.672, avg. samples / sec: 7659.22
Iteration:   4200, Loss function: 3.360, Average Loss: 3.686, avg. samples / sec: 7657.78
Iteration:   4200, Loss function: 3.527, Average Loss: 3.683, avg. samples / sec: 7658.42
Iteration:   4200, Loss function: 1.974, Average Loss: 3.690, avg. samples / sec: 7660.64
Iteration:   4200, Loss function: 3.575, Average Loss: 3.647, avg. samples / sec: 7658.89
Iteration:   4200, Loss function: 3.670, Average Loss: 3.694, avg. samples / sec: 7656.03
Iteration:   4200, Loss function: 3.379, Average Loss: 3.675, avg. samples / sec: 7657.03
Iteration:   4200, Loss function: 4.164, Average Loss: 3.668, avg. samples / sec: 7657.17
Iteration:   4200, Loss function: 3.173, Average Loss: 3.679, avg. samples / sec: 7656.51
Iteration:   4200, Loss function: 3.679, Average Loss: 3.656, avg. samples / sec: 7653.98
Iteration:   4200, Loss function: 3.346, Average Loss: 3.681, avg. samples / sec: 7655.98
Iteration:   4200, Loss function: 3.128, Average Loss: 3.660, avg. samples / sec: 7656.00
Iteration:   4200, Loss function: 2.080, Average Loss: 3.661, avg. samples / sec: 7655.97
Iteration:   4200, Loss function: 2.294, Average Loss: 3.671, avg. samples / sec: 7656.26
Iteration:   4200, Loss function: 2.993, Average Loss: 3.665, avg. samples / sec: 7655.60
Iteration:   4200, Loss function: 3.432, Average Loss: 3.702, avg. samples / sec: 7654.40
Iteration:   4200, Loss function: 3.619, Average Loss: 3.661, avg. samples / sec: 7655.72
Iteration:   4200, Loss function: 3.471, Average Loss: 3.684, avg. samples / sec: 7654.37
Iteration:   4200, Loss function: 2.942, Average Loss: 3.687, avg. samples / sec: 7653.53
Iteration:   4220, Loss function: 2.257, Average Loss: 3.666, avg. samples / sec: 66026.25
Iteration:   4220, Loss function: 4.448, Average Loss: 3.639, avg. samples / sec: 66061.17
Iteration:   4220, Loss function: 2.559, Average Loss: 3.666, avg. samples / sec: 66125.24
Iteration:   4220, Loss function: 2.399, Average Loss: 3.683, avg. samples / sec: 65983.69
Iteration:   4220, Loss function: 3.157, Average Loss: 3.641, avg. samples / sec: 65973.52
Iteration:   4220, Loss function: 3.319, Average Loss: 3.684, avg. samples / sec: 65935.53
Iteration:   4220, Loss function: 3.022, Average Loss: 3.642, avg. samples / sec: 65961.11
Iteration:   4220, Loss function: 3.788, Average Loss: 3.656, avg. samples / sec: 66175.04
Iteration:   4220, Loss function: 2.071, Average Loss: 3.663, avg. samples / sec: 66031.02
Iteration:   4220, Loss function: 3.429, Average Loss: 3.688, avg. samples / sec: 66069.90
Iteration:   4220, Loss function: 3.616, Average Loss: 3.698, avg. samples / sec: 66156.74
Iteration:   4220, Loss function: 4.387, Average Loss: 3.686, avg. samples / sec: 66002.26
Iteration:   4220, Loss function: 3.164, Average Loss: 3.671, avg. samples / sec: 65991.84
Iteration:   4220, Loss function: 2.846, Average Loss: 3.655, avg. samples / sec: 66083.62
Iteration:   4220, Loss function: 2.682, Average Loss: 3.664, avg. samples / sec: 65881.52
Iteration:   4220, Loss function: 4.098, Average Loss: 3.669, avg. samples / sec: 65919.21
Iteration:   4220, Loss function: 3.258, Average Loss: 3.681, avg. samples / sec: 65944.20
Iteration:   4220, Loss function: 2.854, Average Loss: 3.678, avg. samples / sec: 66146.65
Iteration:   4220, Loss function: 3.129, Average Loss: 3.676, avg. samples / sec: 65903.06
Iteration:   4220, Loss function: 3.272, Average Loss: 3.654, avg. samples / sec: 66047.23
Iteration:   4220, Loss function: 3.860, Average Loss: 3.677, avg. samples / sec: 66032.66
Iteration:   4220, Loss function: 3.686, Average Loss: 3.642, avg. samples / sec: 65837.69
Iteration:   4220, Loss function: 3.677, Average Loss: 3.656, avg. samples / sec: 66041.23
Iteration:   4220, Loss function: 2.461, Average Loss: 3.662, avg. samples / sec: 65846.98
Iteration:   4220, Loss function: 3.564, Average Loss: 3.663, avg. samples / sec: 66008.44
Iteration:   4220, Loss function: 3.787, Average Loss: 3.637, avg. samples / sec: 65889.78
Iteration:   4220, Loss function: 3.883, Average Loss: 3.660, avg. samples / sec: 65933.64
Iteration:   4220, Loss function: 3.008, Average Loss: 3.651, avg. samples / sec: 65966.30
Iteration:   4220, Loss function: 2.746, Average Loss: 3.677, avg. samples / sec: 65940.34
Iteration:   4220, Loss function: 2.677, Average Loss: 3.681, avg. samples / sec: 66079.16
Iteration:   4240, Loss function: 3.821, Average Loss: 3.657, avg. samples / sec: 65882.17
Iteration:   4240, Loss function: 3.771, Average Loss: 3.671, avg. samples / sec: 65914.15
Iteration:   4240, Loss function: 3.244, Average Loss: 3.648, avg. samples / sec: 66087.00
Iteration:   4240, Loss function: 5.082, Average Loss: 3.655, avg. samples / sec: 65910.49
Iteration:   4240, Loss function: 3.102, Average Loss: 3.650, avg. samples / sec: 65949.66
Iteration:   4240, Loss function: 4.297, Average Loss: 3.660, avg. samples / sec: 65942.04
Iteration:   4240, Loss function: 5.645, Average Loss: 3.665, avg. samples / sec: 66016.57
Iteration:   4240, Loss function: 3.555, Average Loss: 3.634, avg. samples / sec: 65817.19
Iteration:   4240, Loss function: 2.724, Average Loss: 3.690, avg. samples / sec: 65895.51
Iteration:   4240, Loss function: 3.157, Average Loss: 3.678, avg. samples / sec: 65833.57
Iteration:   4240, Loss function: 3.136, Average Loss: 3.671, avg. samples / sec: 65945.83
Iteration:   4240, Loss function: 3.460, Average Loss: 3.684, avg. samples / sec: 65885.06
Iteration:   4240, Loss function: 3.357, Average Loss: 3.657, avg. samples / sec: 65778.42
Iteration:   4240, Loss function: 1.675, Average Loss: 3.636, avg. samples / sec: 65773.38
Iteration:   4240, Loss function: 4.490, Average Loss: 3.655, avg. samples / sec: 65925.22
Iteration:   4240, Loss function: 4.413, Average Loss: 3.635, avg. samples / sec: 65919.40
Iteration:   4240, Loss function: 3.356, Average Loss: 3.631, avg. samples / sec: 65774.36
Iteration:   4240, Loss function: 3.122, Average Loss: 3.657, avg. samples / sec: 65784.56
Iteration:   4240, Loss function: 3.980, Average Loss: 3.678, avg. samples / sec: 65850.98
Iteration:   4240, Loss function: 4.081, Average Loss: 3.666, avg. samples / sec: 65836.13
Iteration:   4240, Loss function: 2.840, Average Loss: 3.648, avg. samples / sec: 65911.97
Iteration:   4240, Loss function: 3.789, Average Loss: 3.641, avg. samples / sec: 65855.32
Iteration:   4240, Loss function: 3.100, Average Loss: 3.672, avg. samples / sec: 65849.05
Iteration:   4240, Loss function: 2.344, Average Loss: 3.629, avg. samples / sec: 65889.04
Iteration:   4240, Loss function: 2.878, Average Loss: 3.664, avg. samples / sec: 65769.45
Iteration:   4240, Loss function: 4.460, Average Loss: 3.678, avg. samples / sec: 65904.97
Iteration:   4240, Loss function: 2.900, Average Loss: 3.681, avg. samples / sec: 65720.87
Iteration:   4240, Loss function: 2.665, Average Loss: 3.676, avg. samples / sec: 65784.80
Iteration:   4240, Loss function: 3.186, Average Loss: 3.671, avg. samples / sec: 65872.75
Iteration:   4240, Loss function: 3.673, Average Loss: 3.654, avg. samples / sec: 65761.17
:::MLL 1558651985.999 epoch_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 819}}
:::MLL 1558651986.000 epoch_start: {"value": null, "metadata": {"epoch_num": 62, "file": "train.py", "lineno": 673}}
Iteration:   4260, Loss function: 3.727, Average Loss: 3.659, avg. samples / sec: 65999.75
Iteration:   4260, Loss function: 2.954, Average Loss: 3.650, avg. samples / sec: 65684.82
Iteration:   4260, Loss function: 3.510, Average Loss: 3.629, avg. samples / sec: 65875.70
Iteration:   4260, Loss function: 4.229, Average Loss: 3.656, avg. samples / sec: 65842.83
Iteration:   4260, Loss function: 3.445, Average Loss: 3.620, avg. samples / sec: 65877.00
Iteration:   4260, Loss function: 3.841, Average Loss: 3.632, avg. samples / sec: 65801.42
Iteration:   4260, Loss function: 3.270, Average Loss: 3.677, avg. samples / sec: 65877.30
Iteration:   4260, Loss function: 3.724, Average Loss: 3.643, avg. samples / sec: 65690.51
Iteration:   4260, Loss function: 3.823, Average Loss: 3.669, avg. samples / sec: 65720.53
Iteration:   4260, Loss function: 3.288, Average Loss: 3.671, avg. samples / sec: 65856.09
Iteration:   4260, Loss function: 3.370, Average Loss: 3.653, avg. samples / sec: 65717.10
Iteration:   4260, Loss function: 2.682, Average Loss: 3.648, avg. samples / sec: 65656.82
Iteration:   4260, Loss function: 3.044, Average Loss: 3.626, avg. samples / sec: 65699.48
Iteration:   4260, Loss function: 3.051, Average Loss: 3.664, avg. samples / sec: 65714.16
Iteration:   4260, Loss function: 4.711, Average Loss: 3.660, avg. samples / sec: 65631.65
Iteration:   4260, Loss function: 5.233, Average Loss: 3.642, avg. samples / sec: 65812.24
Iteration:   4260, Loss function: 4.150, Average Loss: 3.681, avg. samples / sec: 65672.88
Iteration:   4260, Loss function: 2.777, Average Loss: 3.664, avg. samples / sec: 65769.55
Iteration:   4260, Loss function: 4.240, Average Loss: 3.624, avg. samples / sec: 65778.05
Iteration:   4260, Loss function: 2.888, Average Loss: 3.640, avg. samples / sec: 65740.40
Iteration:   4260, Loss function: 2.964, Average Loss: 3.638, avg. samples / sec: 65559.96
Iteration:   4260, Loss function: 3.775, Average Loss: 3.654, avg. samples / sec: 65692.10
Iteration:   4260, Loss function: 3.749, Average Loss: 3.645, avg. samples / sec: 65687.27
Iteration:   4260, Loss function: 2.871, Average Loss: 3.654, avg. samples / sec: 65595.97
Iteration:   4260, Loss function: 3.152, Average Loss: 3.646, avg. samples / sec: 65822.07
Iteration:   4260, Loss function: 4.042, Average Loss: 3.659, avg. samples / sec: 65719.52
Iteration:   4260, Loss function: 3.152, Average Loss: 3.676, avg. samples / sec: 65600.61
Iteration:   4260, Loss function: 4.128, Average Loss: 3.669, avg. samples / sec: 65751.72
Iteration:   4260, Loss function: 2.472, Average Loss: 3.673, avg. samples / sec: 65639.26
Iteration:   4260, Loss function: 3.010, Average Loss: 3.672, avg. samples / sec: 65553.35
Iteration:   4280, Loss function: 2.877, Average Loss: 3.669, avg. samples / sec: 66107.65
Iteration:   4280, Loss function: 4.117, Average Loss: 3.646, avg. samples / sec: 65957.74
Iteration:   4280, Loss function: 3.367, Average Loss: 3.648, avg. samples / sec: 66190.64
Iteration:   4280, Loss function: 3.185, Average Loss: 3.638, avg. samples / sec: 66094.38
Iteration:   4280, Loss function: 3.228, Average Loss: 3.663, avg. samples / sec: 66050.73
Iteration:   4280, Loss function: 4.216, Average Loss: 3.658, avg. samples / sec: 66105.63
Iteration:   4280, Loss function: 3.476, Average Loss: 3.622, avg. samples / sec: 66039.90
Iteration:   4280, Loss function: 3.631, Average Loss: 3.653, avg. samples / sec: 66165.75
Iteration:   4280, Loss function: 2.724, Average Loss: 3.644, avg. samples / sec: 66027.77
Iteration:   4280, Loss function: 1.696, Average Loss: 3.647, avg. samples / sec: 65816.33
Iteration:   4280, Loss function: 3.641, Average Loss: 3.617, avg. samples / sec: 65906.69
Iteration:   4280, Loss function: 3.110, Average Loss: 3.639, avg. samples / sec: 66132.03
Iteration:   4280, Loss function: 2.459, Average Loss: 3.646, avg. samples / sec: 65900.22
Iteration:   4280, Loss function: 2.470, Average Loss: 3.650, avg. samples / sec: 65988.88
Iteration:   4280, Loss function: 3.992, Average Loss: 3.637, avg. samples / sec: 66080.09
Iteration:   4280, Loss function: 3.293, Average Loss: 3.665, avg. samples / sec: 66227.07
Iteration:   4280, Loss function: 3.071, Average Loss: 3.653, avg. samples / sec: 66064.66
Iteration:   4280, Loss function: 3.040, Average Loss: 3.667, avg. samples / sec: 65967.69
Iteration:   4280, Loss function: 3.323, Average Loss: 3.637, avg. samples / sec: 65970.40
Iteration:   4280, Loss function: 2.779, Average Loss: 3.625, avg. samples / sec: 65920.47
Iteration:   4280, Loss function: 3.401, Average Loss: 3.633, avg. samples / sec: 66024.89
Iteration:   4280, Loss function: 3.946, Average Loss: 3.639, avg. samples / sec: 66014.10
Iteration:   4280, Loss function: 3.381, Average Loss: 3.668, avg. samples / sec: 66154.13
Iteration:   4280, Loss function: 3.091, Average Loss: 3.663, avg. samples / sec: 66048.13
Iteration:   4280, Loss function: 3.075, Average Loss: 3.619, avg. samples / sec: 65977.60
Iteration:   4280, Loss function: 3.413, Average Loss: 3.677, avg. samples / sec: 65924.27
Iteration:   4280, Loss function: 2.541, Average Loss: 3.669, avg. samples / sec: 66025.36
Iteration:   4280, Loss function: 3.131, Average Loss: 3.649, avg. samples / sec: 65885.43
Iteration:   4280, Loss function: 3.872, Average Loss: 3.623, avg. samples / sec: 65788.21
Iteration:   4280, Loss function: 3.170, Average Loss: 3.657, avg. samples / sec: 65878.57
Iteration:   4300, Loss function: 4.316, Average Loss: 3.662, avg. samples / sec: 65901.05
Iteration:   4300, Loss function: 3.561, Average Loss: 3.659, avg. samples / sec: 65870.07
Iteration:   4300, Loss function: 3.844, Average Loss: 3.622, avg. samples / sec: 65926.80
Iteration:   4300, Loss function: 3.864, Average Loss: 3.642, avg. samples / sec: 65800.96
Iteration:   4300, Loss function: 2.658, Average Loss: 3.654, avg. samples / sec: 65742.55
Iteration:   4300, Loss function: 2.906, Average Loss: 3.609, avg. samples / sec: 65777.56
Iteration:   4300, Loss function: 2.551, Average Loss: 3.661, avg. samples / sec: 65829.61
Iteration:   4300, Loss function: 3.327, Average Loss: 3.638, avg. samples / sec: 65666.70
Iteration:   4300, Loss function: 3.176, Average Loss: 3.643, avg. samples / sec: 65760.03
Iteration:   4300, Loss function: 2.551, Average Loss: 3.657, avg. samples / sec: 65882.88
Iteration:   4300, Loss function: 2.431, Average Loss: 3.629, avg. samples / sec: 65752.51
Iteration:   4300, Loss function: 3.638, Average Loss: 3.657, avg. samples / sec: 65842.89
Iteration:   4300, Loss function: 3.252, Average Loss: 3.631, avg. samples / sec: 65784.40
Iteration:   4300, Loss function: 3.281, Average Loss: 3.625, avg. samples / sec: 65796.01
Iteration:   4300, Loss function: 1.951, Average Loss: 3.637, avg. samples / sec: 65732.06
Iteration:   4300, Loss function: 3.558, Average Loss: 3.612, avg. samples / sec: 65819.61
Iteration:   4300, Loss function: 3.175, Average Loss: 3.641, avg. samples / sec: 65638.90
Iteration:   4300, Loss function: 3.146, Average Loss: 3.648, avg. samples / sec: 65855.57
Iteration:   4300, Loss function: 2.971, Average Loss: 3.648, avg. samples / sec: 65721.48
Iteration:   4300, Loss function: 4.233, Average Loss: 3.619, avg. samples / sec: 65754.23
Iteration:   4300, Loss function: 2.976, Average Loss: 3.663, avg. samples / sec: 65578.36
Iteration:   4300, Loss function: 3.009, Average Loss: 3.636, avg. samples / sec: 65722.92
Iteration:   4300, Loss function: 3.246, Average Loss: 3.662, avg. samples / sec: 65632.78
Iteration:   4300, Loss function: 2.852, Average Loss: 3.631, avg. samples / sec: 65735.13
Iteration:   4300, Loss function: 4.216, Average Loss: 3.648, avg. samples / sec: 65690.79
Iteration:   4300, Loss function: 2.378, Average Loss: 3.643, avg. samples / sec: 65626.36
Iteration:   4300, Loss function: 2.490, Average Loss: 3.626, avg. samples / sec: 65544.81
Iteration:   4300, Loss function: 2.601, Average Loss: 3.623, avg. samples / sec: 65589.53
Iteration:   4300, Loss function: 2.486, Average Loss: 3.642, avg. samples / sec: 65700.68
Iteration:   4300, Loss function: 3.663, Average Loss: 3.674, avg. samples / sec: 65655.38
Iteration:   4320, Loss function: 4.002, Average Loss: 3.637, avg. samples / sec: 66414.92
Iteration:   4320, Loss function: 5.438, Average Loss: 3.645, avg. samples / sec: 66451.81
Iteration:   4320, Loss function: 4.719, Average Loss: 3.618, avg. samples / sec: 66294.76
Iteration:   4320, Loss function: 3.557, Average Loss: 3.642, avg. samples / sec: 66377.89
Iteration:   4320, Loss function: 3.263, Average Loss: 3.666, avg. samples / sec: 66540.42
Iteration:   4320, Loss function: 4.576, Average Loss: 3.661, avg. samples / sec: 66352.35
Iteration:   4320, Loss function: 2.689, Average Loss: 3.657, avg. samples / sec: 66165.22
Iteration:   4320, Loss function: 3.238, Average Loss: 3.617, avg. samples / sec: 66267.89
Iteration:   4320, Loss function: 4.317, Average Loss: 3.642, avg. samples / sec: 66342.45
Iteration:   4320, Loss function: 2.850, Average Loss: 3.634, avg. samples / sec: 66221.03
Iteration:   4320, Loss function: 2.970, Average Loss: 3.653, avg. samples / sec: 66184.55
Iteration:   4320, Loss function: 3.514, Average Loss: 3.651, avg. samples / sec: 66332.05
Iteration:   4320, Loss function: 2.469, Average Loss: 3.630, avg. samples / sec: 66304.62
Iteration:   4320, Loss function: 3.249, Average Loss: 3.637, avg. samples / sec: 66193.75
Iteration:   4320, Loss function: 3.669, Average Loss: 3.637, avg. samples / sec: 66244.31
Iteration:   4320, Loss function: 4.437, Average Loss: 3.646, avg. samples / sec: 66192.41
Iteration:   4320, Loss function: 2.571, Average Loss: 3.620, avg. samples / sec: 66321.44
Iteration:   4320, Loss function: 3.045, Average Loss: 3.604, avg. samples / sec: 66184.08
Iteration:   4320, Loss function: 3.152, Average Loss: 3.634, avg. samples / sec: 66379.61
Iteration:   4320, Loss function: 4.511, Average Loss: 3.616, avg. samples / sec: 66246.46
Iteration:   4320, Loss function: 3.239, Average Loss: 3.650, avg. samples / sec: 66179.51
Iteration:   4320, Loss function: 3.399, Average Loss: 3.632, avg. samples / sec: 66276.87
Iteration:   4320, Loss function: 4.069, Average Loss: 3.620, avg. samples / sec: 66323.00
Iteration:   4320, Loss function: 3.885, Average Loss: 3.637, avg. samples / sec: 66174.82
Iteration:   4320, Loss function: 4.013, Average Loss: 3.664, avg. samples / sec: 66144.38
Iteration:   4320, Loss function: 3.969, Average Loss: 3.622, avg. samples / sec: 66234.19
Iteration:   4320, Loss function: 2.731, Average Loss: 3.603, avg. samples / sec: 66162.74
Iteration:   4320, Loss function: 4.611, Average Loss: 3.626, avg. samples / sec: 66106.00
Iteration:   4320, Loss function: 3.435, Average Loss: 3.651, avg. samples / sec: 66074.02
Iteration:   4320, Loss function: 3.539, Average Loss: 3.624, avg. samples / sec: 66098.10
:::MLL 1558651987.783 epoch_stop: {"value": null, "metadata": {"epoch_num": 62, "file": "train.py", "lineno": 819}}
:::MLL 1558651987.783 epoch_start: {"value": null, "metadata": {"epoch_num": 63, "file": "train.py", "lineno": 673}}
Iteration:   4340, Loss function: 3.594, Average Loss: 3.637, avg. samples / sec: 65540.85
Iteration:   4340, Loss function: 3.339, Average Loss: 3.618, avg. samples / sec: 65812.85
Iteration:   4340, Loss function: 2.568, Average Loss: 3.625, avg. samples / sec: 65670.68
Iteration:   4340, Loss function: 3.342, Average Loss: 3.609, avg. samples / sec: 65697.37
Iteration:   4340, Loss function: 2.952, Average Loss: 3.599, avg. samples / sec: 65674.62
Iteration:   4340, Loss function: 4.515, Average Loss: 3.628, avg. samples / sec: 65599.85
Iteration:   4340, Loss function: 4.151, Average Loss: 3.614, avg. samples / sec: 65517.32
Iteration:   4340, Loss function: 4.496, Average Loss: 3.658, avg. samples / sec: 65531.98
Iteration:   4340, Loss function: 3.574, Average Loss: 3.630, avg. samples / sec: 65646.97
Iteration:   4340, Loss function: 3.837, Average Loss: 3.640, avg. samples / sec: 65434.31
Iteration:   4340, Loss function: 3.888, Average Loss: 3.627, avg. samples / sec: 65679.31
Iteration:   4340, Loss function: 3.080, Average Loss: 3.618, avg. samples / sec: 65634.10
Iteration:   4340, Loss function: 2.394, Average Loss: 3.641, avg. samples / sec: 65630.28
Iteration:   4340, Loss function: 3.308, Average Loss: 3.620, avg. samples / sec: 65736.35
Iteration:   4340, Loss function: 2.068, Average Loss: 3.654, avg. samples / sec: 65515.50
Iteration:   4340, Loss function: 3.611, Average Loss: 3.656, avg. samples / sec: 65524.27
Iteration:   4340, Loss function: 3.699, Average Loss: 3.645, avg. samples / sec: 65547.70
Iteration:   4340, Loss function: 3.195, Average Loss: 3.634, avg. samples / sec: 65463.15
Iteration:   4340, Loss function: 3.444, Average Loss: 3.628, avg. samples / sec: 65589.65
Iteration:   4340, Loss function: 3.544, Average Loss: 3.656, avg. samples / sec: 65635.50
Iteration:   4340, Loss function: 4.891, Average Loss: 3.617, avg. samples / sec: 65639.48
Iteration:   4340, Loss function: 3.553, Average Loss: 3.610, avg. samples / sec: 65507.61
Iteration:   4340, Loss function: 3.007, Average Loss: 3.632, avg. samples / sec: 65606.20
Iteration:   4340, Loss function: 2.922, Average Loss: 3.602, avg. samples / sec: 65647.46
Iteration:   4340, Loss function: 2.702, Average Loss: 3.643, avg. samples / sec: 65513.73
Iteration:   4340, Loss function: 2.875, Average Loss: 3.614, avg. samples / sec: 65567.25
Iteration:   4340, Loss function: 2.474, Average Loss: 3.634, avg. samples / sec: 65474.22
Iteration:   4340, Loss function: 3.283, Average Loss: 3.643, avg. samples / sec: 65600.31
Iteration:   4340, Loss function: 3.290, Average Loss: 3.629, avg. samples / sec: 65466.56
Iteration:   4340, Loss function: 3.953, Average Loss: 3.641, avg. samples / sec: 65481.74
Iteration:   4360, Loss function: 4.006, Average Loss: 3.628, avg. samples / sec: 66030.55
Iteration:   4360, Loss function: 3.544, Average Loss: 3.596, avg. samples / sec: 65937.44
Iteration:   4360, Loss function: 3.508, Average Loss: 3.628, avg. samples / sec: 65844.00
Iteration:   4360, Loss function: 3.834, Average Loss: 3.623, avg. samples / sec: 65879.58
Iteration:   4360, Loss function: 3.280, Average Loss: 3.631, avg. samples / sec: 65953.58
Iteration:   4360, Loss function: 4.838, Average Loss: 3.607, avg. samples / sec: 65941.14
Iteration:   4360, Loss function: 2.798, Average Loss: 3.623, avg. samples / sec: 66053.80
Iteration:   4360, Loss function: 3.621, Average Loss: 3.615, avg. samples / sec: 65782.16
Iteration:   4360, Loss function: 3.015, Average Loss: 3.604, avg. samples / sec: 65908.94
Iteration:   4360, Loss function: 3.749, Average Loss: 3.602, avg. samples / sec: 65774.15
Iteration:   4360, Loss function: 2.350, Average Loss: 3.625, avg. samples / sec: 65868.47
Iteration:   4360, Loss function: 4.042, Average Loss: 3.632, avg. samples / sec: 65953.21
Iteration:   4360, Loss function: 3.278, Average Loss: 3.599, avg. samples / sec: 65886.17
Iteration:   4360, Loss function: 3.077, Average Loss: 3.655, avg. samples / sec: 65812.42
Iteration:   4360, Loss function: 3.572, Average Loss: 3.636, avg. samples / sec: 65873.76
Iteration:   4360, Loss function: 3.265, Average Loss: 3.624, avg. samples / sec: 65764.45
Iteration:   4360, Loss function: 2.283, Average Loss: 3.613, avg. samples / sec: 65806.49
Iteration:   4360, Loss function: 4.333, Average Loss: 3.606, avg. samples / sec: 65758.99
Iteration:   4360, Loss function: 2.775, Average Loss: 3.624, avg. samples / sec: 65793.50
Iteration:   4360, Loss function: 3.441, Average Loss: 3.606, avg. samples / sec: 65883.56
Iteration:   4360, Loss function: 4.385, Average Loss: 3.640, avg. samples / sec: 65897.73
Iteration:   4360, Loss function: 4.367, Average Loss: 3.612, avg. samples / sec: 65758.28
Iteration:   4360, Loss function: 3.288, Average Loss: 3.639, avg. samples / sec: 65746.81
Iteration:   4360, Loss function: 3.552, Average Loss: 3.651, avg. samples / sec: 65794.97
Iteration:   4360, Loss function: 2.942, Average Loss: 3.651, avg. samples / sec: 65767.34
Iteration:   4360, Loss function: 3.336, Average Loss: 3.642, avg. samples / sec: 65904.91
Iteration:   4360, Loss function: 3.826, Average Loss: 3.637, avg. samples / sec: 65729.58
Iteration:   4360, Loss function: 2.696, Average Loss: 3.645, avg. samples / sec: 65757.27
Iteration:   4360, Loss function: 3.817, Average Loss: 3.638, avg. samples / sec: 65740.49
Iteration:   4360, Loss function: 2.786, Average Loss: 3.619, avg. samples / sec: 65545.11
Iteration:   4380, Loss function: 5.160, Average Loss: 3.623, avg. samples / sec: 65846.98
Iteration:   4380, Loss function: 4.572, Average Loss: 3.604, avg. samples / sec: 66053.89
Iteration:   4380, Loss function: 4.187, Average Loss: 3.623, avg. samples / sec: 65800.47
Iteration:   4380, Loss function: 3.120, Average Loss: 3.587, avg. samples / sec: 65808.43
Iteration:   4380, Loss function: 3.021, Average Loss: 3.619, avg. samples / sec: 65862.74
Iteration:   4380, Loss function: 3.546, Average Loss: 3.597, avg. samples / sec: 65949.16
Iteration:   4380, Loss function: 2.925, Average Loss: 3.598, avg. samples / sec: 65978.56
Iteration:   4380, Loss function: 3.887, Average Loss: 3.630, avg. samples / sec: 66047.42
Iteration:   4380, Loss function: 3.640, Average Loss: 3.631, avg. samples / sec: 66013.26
Iteration:   4380, Loss function: 3.937, Average Loss: 3.608, avg. samples / sec: 65894.98
Iteration:   4380, Loss function: 2.583, Average Loss: 3.623, avg. samples / sec: 65866.43
Iteration:   4380, Loss function: 4.556, Average Loss: 3.605, avg. samples / sec: 65864.77
Iteration:   4380, Loss function: 2.738, Average Loss: 3.630, avg. samples / sec: 65980.13
Iteration:   4380, Loss function: 3.537, Average Loss: 3.620, avg. samples / sec: 65967.38
Iteration:   4380, Loss function: 3.085, Average Loss: 3.606, avg. samples / sec: 65917.73
Iteration:   4380, Loss function: 2.882, Average Loss: 3.645, avg. samples / sec: 65861.66
Iteration:   4380, Loss function: 4.268, Average Loss: 3.638, avg. samples / sec: 65978.93
Iteration:   4380, Loss function: 3.818, Average Loss: 3.646, avg. samples / sec: 65921.00
Iteration:   4380, Loss function: 3.252, Average Loss: 3.640, avg. samples / sec: 65957.81
Iteration:   4380, Loss function: 2.705, Average Loss: 3.630, avg. samples / sec: 65885.16
Iteration:   4380, Loss function: 3.501, Average Loss: 3.604, avg. samples / sec: 65914.40
Iteration:   4380, Loss function: 3.257, Average Loss: 3.631, avg. samples / sec: 65925.78
Iteration:   4380, Loss function: 2.651, Average Loss: 3.618, avg. samples / sec: 65796.17
Iteration:   4380, Loss function: 3.574, Average Loss: 3.641, avg. samples / sec: 65887.87
Iteration:   4380, Loss function: 3.498, Average Loss: 3.617, avg. samples / sec: 66023.47
Iteration:   4380, Loss function: 3.778, Average Loss: 3.623, avg. samples / sec: 65838.68
Iteration:   4380, Loss function: 2.430, Average Loss: 3.622, avg. samples / sec: 65794.05
Iteration:   4380, Loss function: 5.139, Average Loss: 3.598, avg. samples / sec: 65747.58
Iteration:   4380, Loss function: 3.936, Average Loss: 3.595, avg. samples / sec: 65782.10
Iteration:   4380, Loss function: 3.025, Average Loss: 3.615, avg. samples / sec: 65718.48
:::MLL 1558651989.580 epoch_stop: {"value": null, "metadata": {"epoch_num": 63, "file": "train.py", "lineno": 819}}
:::MLL 1558651989.581 epoch_start: {"value": null, "metadata": {"epoch_num": 64, "file": "train.py", "lineno": 673}}
Iteration:   4400, Loss function: 3.835, Average Loss: 3.579, avg. samples / sec: 64564.83
Iteration:   4400, Loss function: 3.421, Average Loss: 3.606, avg. samples / sec: 64694.76
Iteration:   4400, Loss function: 3.792, Average Loss: 3.600, avg. samples / sec: 64586.48
Iteration:   4400, Loss function: 3.370, Average Loss: 3.618, avg. samples / sec: 64560.48
Iteration:   4400, Loss function: 3.124, Average Loss: 3.632, avg. samples / sec: 64599.01
Iteration:   4400, Loss function: 3.585, Average Loss: 3.593, avg. samples / sec: 64661.61
Iteration:   4400, Loss function: 3.835, Average Loss: 3.617, avg. samples / sec: 64445.60
Iteration:   4400, Loss function: 3.413, Average Loss: 3.624, avg. samples / sec: 64505.43
Iteration:   4400, Loss function: 2.389, Average Loss: 3.635, avg. samples / sec: 64568.49
Iteration:   4400, Loss function: 2.791, Average Loss: 3.636, avg. samples / sec: 64557.96
Iteration:   4400, Loss function: 4.002, Average Loss: 3.619, avg. samples / sec: 64586.72
Iteration:   4400, Loss function: 4.095, Average Loss: 3.605, avg. samples / sec: 64455.09
Iteration:   4400, Loss function: 3.393, Average Loss: 3.624, avg. samples / sec: 64436.70
Iteration:   4400, Loss function: 2.522, Average Loss: 3.588, avg. samples / sec: 64464.41
Iteration:   4400, Loss function: 4.528, Average Loss: 3.614, avg. samples / sec: 64621.88
Iteration:   4400, Loss function: 2.834, Average Loss: 3.614, avg. samples / sec: 64595.28
Iteration:   4400, Loss function: 3.159, Average Loss: 3.646, avg. samples / sec: 64555.04
Iteration:   4400, Loss function: 3.111, Average Loss: 3.586, avg. samples / sec: 64619.45
Iteration:   4400, Loss function: 2.781, Average Loss: 3.600, avg. samples / sec: 64463.17
Iteration:   4400, Loss function: 2.607, Average Loss: 3.595, avg. samples / sec: 64438.71
Iteration:   4400, Loss function: 2.511, Average Loss: 3.628, avg. samples / sec: 64507.43
Iteration:   4400, Loss function: 2.245, Average Loss: 3.593, avg. samples / sec: 64519.63
Iteration:   4400, Loss function: 3.063, Average Loss: 3.635, avg. samples / sec: 64517.03
Iteration:   4400, Loss function: 4.116, Average Loss: 3.625, avg. samples / sec: 64493.26
Iteration:   4400, Loss function: 2.595, Average Loss: 3.624, avg. samples / sec: 64405.46
Iteration:   4400, Loss function: 2.760, Average Loss: 3.629, avg. samples / sec: 64354.93
Iteration:   4400, Loss function: 4.092, Average Loss: 3.618, avg. samples / sec: 64342.18
Iteration:   4400, Loss function: 3.443, Average Loss: 3.594, avg. samples / sec: 64273.02
Iteration:   4400, Loss function: 2.978, Average Loss: 3.614, avg. samples / sec: 64304.87
Iteration:   4400, Loss function: 3.410, Average Loss: 3.619, avg. samples / sec: 64370.04
Iteration:   4420, Loss function: 3.427, Average Loss: 3.618, avg. samples / sec: 63861.71
Iteration:   4420, Loss function: 2.701, Average Loss: 3.601, avg. samples / sec: 63916.33
Iteration:   4420, Loss function: 3.559, Average Loss: 3.574, avg. samples / sec: 63764.82
Iteration:   4420, Loss function: 2.941, Average Loss: 3.609, avg. samples / sec: 63978.81
Iteration:   4420, Loss function: 3.498, Average Loss: 3.626, avg. samples / sec: 63806.51
Iteration:   4420, Loss function: 3.184, Average Loss: 3.620, avg. samples / sec: 63854.04
Iteration:   4420, Loss function: 3.183, Average Loss: 3.598, avg. samples / sec: 63827.23
Iteration:   4420, Loss function: 3.113, Average Loss: 3.628, avg. samples / sec: 63769.47
Iteration:   4420, Loss function: 3.697, Average Loss: 3.587, avg. samples / sec: 63931.27
Iteration:   4420, Loss function: 3.241, Average Loss: 3.590, avg. samples / sec: 63837.70
Iteration:   4420, Loss function: 2.311, Average Loss: 3.614, avg. samples / sec: 63754.53
Iteration:   4420, Loss function: 3.878, Average Loss: 3.625, avg. samples / sec: 63872.82
Iteration:   4420, Loss function: 3.113, Average Loss: 3.615, avg. samples / sec: 63786.79
Iteration:   4420, Loss function: 2.790, Average Loss: 3.620, avg. samples / sec: 63851.21
Iteration:   4420, Loss function: 3.506, Average Loss: 3.595, avg. samples / sec: 63691.51
Iteration:   4420, Loss function: 2.971, Average Loss: 3.639, avg. samples / sec: 63755.54
Iteration:   4420, Loss function: 3.189, Average Loss: 3.618, avg. samples / sec: 63759.34
Iteration:   4420, Loss function: 4.139, Average Loss: 3.606, avg. samples / sec: 63639.31
Iteration:   4420, Loss function: 2.229, Average Loss: 3.590, avg. samples / sec: 63727.60
Iteration:   4420, Loss function: 3.316, Average Loss: 3.582, avg. samples / sec: 63708.47
Iteration:   4420, Loss function: 3.882, Average Loss: 3.626, avg. samples / sec: 63772.79
Iteration:   4420, Loss function: 2.618, Average Loss: 3.588, avg. samples / sec: 63708.30
Iteration:   4420, Loss function: 5.405, Average Loss: 3.616, avg. samples / sec: 63873.84
Iteration:   4420, Loss function: 3.024, Average Loss: 3.611, avg. samples / sec: 63689.76
Iteration:   4420, Loss function: 3.885, Average Loss: 3.613, avg. samples / sec: 63613.28
Iteration:   4420, Loss function: 3.805, Average Loss: 3.591, avg. samples / sec: 63693.55
Iteration:   4420, Loss function: 3.099, Average Loss: 3.624, avg. samples / sec: 63607.46
Iteration:   4420, Loss function: 4.125, Average Loss: 3.617, avg. samples / sec: 63870.19
Iteration:   4420, Loss function: 3.310, Average Loss: 3.619, avg. samples / sec: 63744.66
Iteration:   4420, Loss function: 3.176, Average Loss: 3.609, avg. samples / sec: 63623.71
Iteration:   4440, Loss function: 4.980, Average Loss: 3.612, avg. samples / sec: 63635.49
Iteration:   4440, Loss function: 2.972, Average Loss: 3.604, avg. samples / sec: 63555.28
Iteration:   4440, Loss function: 3.010, Average Loss: 3.567, avg. samples / sec: 63415.49
Iteration:   4440, Loss function: 3.157, Average Loss: 3.603, avg. samples / sec: 63592.64
Iteration:   4440, Loss function: 4.550, Average Loss: 3.622, avg. samples / sec: 63492.74
Iteration:   4440, Loss function: 2.568, Average Loss: 3.612, avg. samples / sec: 63538.43
Iteration:   4440, Loss function: 2.490, Average Loss: 3.583, avg. samples / sec: 63429.39
Iteration:   4440, Loss function: 3.766, Average Loss: 3.602, avg. samples / sec: 63355.79
Iteration:   4440, Loss function: 3.293, Average Loss: 3.612, avg. samples / sec: 63545.13
Iteration:   4440, Loss function: 4.131, Average Loss: 3.592, avg. samples / sec: 63464.29
Iteration:   4440, Loss function: 2.960, Average Loss: 3.619, avg. samples / sec: 63385.74
Iteration:   4440, Loss function: 3.675, Average Loss: 3.582, avg. samples / sec: 63402.65
Iteration:   4440, Loss function: 4.139, Average Loss: 3.612, avg. samples / sec: 63582.80
Iteration:   4440, Loss function: 2.859, Average Loss: 3.611, avg. samples / sec: 63574.86
Iteration:   4440, Loss function: 3.309, Average Loss: 3.612, avg. samples / sec: 63307.32
Iteration:   4440, Loss function: 2.897, Average Loss: 3.621, avg. samples / sec: 63507.36
Iteration:   4440, Loss function: 2.640, Average Loss: 3.612, avg. samples / sec: 63419.02
Iteration:   4440, Loss function: 2.873, Average Loss: 3.593, avg. samples / sec: 63378.10
Iteration:   4440, Loss function: 4.200, Average Loss: 3.588, avg. samples / sec: 63512.00
Iteration:   4440, Loss function: 2.948, Average Loss: 3.580, avg. samples / sec: 63475.93
Iteration:   4440, Loss function: 3.552, Average Loss: 3.572, avg. samples / sec: 63472.32
Iteration:   4440, Loss function: 4.408, Average Loss: 3.607, avg. samples / sec: 63563.33
Iteration:   4440, Loss function: 4.226, Average Loss: 3.613, avg. samples / sec: 63501.27
Iteration:   4440, Loss function: 3.416, Average Loss: 3.622, avg. samples / sec: 63361.91
Iteration:   4440, Loss function: 4.020, Average Loss: 3.635, avg. samples / sec: 63400.79
Iteration:   4440, Loss function: 3.369, Average Loss: 3.587, avg. samples / sec: 63358.38
Iteration:   4440, Loss function: 3.499, Average Loss: 3.608, avg. samples / sec: 63355.10
Iteration:   4440, Loss function: 3.540, Average Loss: 3.618, avg. samples / sec: 63311.78
Iteration:   4440, Loss function: 3.431, Average Loss: 3.598, avg. samples / sec: 63226.32
Iteration:   4440, Loss function: 3.461, Average Loss: 3.615, avg. samples / sec: 63325.53
Iteration:   4460, Loss function: 4.381, Average Loss: 3.612, avg. samples / sec: 66080.68
Iteration:   4460, Loss function: 3.109, Average Loss: 3.606, avg. samples / sec: 66026.81
Iteration:   4460, Loss function: 3.181, Average Loss: 3.600, avg. samples / sec: 65979.64
Iteration:   4460, Loss function: 3.533, Average Loss: 3.608, avg. samples / sec: 66049.28
Iteration:   4460, Loss function: 3.855, Average Loss: 3.603, avg. samples / sec: 66004.70
Iteration:   4460, Loss function: 2.890, Average Loss: 3.587, avg. samples / sec: 66036.34
Iteration:   4460, Loss function: 2.773, Average Loss: 3.568, avg. samples / sec: 65928.28
Iteration:   4460, Loss function: 2.967, Average Loss: 3.603, avg. samples / sec: 66019.76
Iteration:   4460, Loss function: 3.308, Average Loss: 3.606, avg. samples / sec: 66043.80
Iteration:   4460, Loss function: 3.176, Average Loss: 3.603, avg. samples / sec: 65784.80
Iteration:   4460, Loss function: 2.701, Average Loss: 3.632, avg. samples / sec: 66055.72
Iteration:   4460, Loss function: 2.546, Average Loss: 3.609, avg. samples / sec: 65986.22
Iteration:   4460, Loss function: 2.912, Average Loss: 3.609, avg. samples / sec: 66036.46
Iteration:   4460, Loss function: 3.323, Average Loss: 3.574, avg. samples / sec: 65966.39
Iteration:   4460, Loss function: 3.673, Average Loss: 3.612, avg. samples / sec: 66051.16
Iteration:   4460, Loss function: 2.632, Average Loss: 3.590, avg. samples / sec: 65947.99
Iteration:   4460, Loss function: 3.488, Average Loss: 3.608, avg. samples / sec: 66050.17
Iteration:   4460, Loss function: 3.679, Average Loss: 3.613, avg. samples / sec: 65975.53
Iteration:   4460, Loss function: 2.685, Average Loss: 3.601, avg. samples / sec: 66010.85
Iteration:   4460, Loss function: 2.166, Average Loss: 3.595, avg. samples / sec: 66007.45
Iteration:   4460, Loss function: 3.116, Average Loss: 3.585, avg. samples / sec: 65995.52
Iteration:   4460, Loss function: 3.330, Average Loss: 3.608, avg. samples / sec: 65894.55
Iteration:   4460, Loss function: 2.434, Average Loss: 3.624, avg. samples / sec: 65811.78
Iteration:   4460, Loss function: 3.965, Average Loss: 3.596, avg. samples / sec: 65789.78
Iteration:   4460, Loss function: 2.614, Average Loss: 3.604, avg. samples / sec: 65828.35
Iteration:   4460, Loss function: 2.381, Average Loss: 3.574, avg. samples / sec: 65870.44
Iteration:   4460, Loss function: 3.347, Average Loss: 3.591, avg. samples / sec: 65859.97
Iteration:   4460, Loss function: 3.691, Average Loss: 3.576, avg. samples / sec: 65859.72
Iteration:   4460, Loss function: 4.066, Average Loss: 3.606, avg. samples / sec: 65803.36
Iteration:   4460, Loss function: 3.647, Average Loss: 3.570, avg. samples / sec: 65825.21
:::MLL 1558651991.404 epoch_stop: {"value": null, "metadata": {"epoch_num": 64, "file": "train.py", "lineno": 819}}
:::MLL 1558651991.404 epoch_start: {"value": null, "metadata": {"epoch_num": 65, "file": "train.py", "lineno": 673}}
Iteration:   4480, Loss function: 4.177, Average Loss: 3.606, avg. samples / sec: 65544.96
Iteration:   4480, Loss function: 3.690, Average Loss: 3.590, avg. samples / sec: 65705.00
Iteration:   4480, Loss function: 3.055, Average Loss: 3.602, avg. samples / sec: 65571.71
Iteration:   4480, Loss function: 4.089, Average Loss: 3.565, avg. samples / sec: 65533.26
Iteration:   4480, Loss function: 4.104, Average Loss: 3.573, avg. samples / sec: 65567.74
Iteration:   4480, Loss function: 3.470, Average Loss: 3.608, avg. samples / sec: 65460.99
Iteration:   4480, Loss function: 2.741, Average Loss: 3.592, avg. samples / sec: 65669.02
Iteration:   4480, Loss function: 3.026, Average Loss: 3.591, avg. samples / sec: 65454.49
Iteration:   4480, Loss function: 2.849, Average Loss: 3.586, avg. samples / sec: 65536.21
Iteration:   4480, Loss function: 2.411, Average Loss: 3.600, avg. samples / sec: 65602.99
Iteration:   4480, Loss function: 2.415, Average Loss: 3.605, avg. samples / sec: 65496.59
Iteration:   4480, Loss function: 3.857, Average Loss: 3.588, avg. samples / sec: 65568.75
Iteration:   4480, Loss function: 2.995, Average Loss: 3.578, avg. samples / sec: 65635.04
Iteration:   4480, Loss function: 3.684, Average Loss: 3.592, avg. samples / sec: 65496.16
Iteration:   4480, Loss function: 2.382, Average Loss: 3.603, avg. samples / sec: 65550.02
Iteration:   4480, Loss function: 2.883, Average Loss: 3.595, avg. samples / sec: 65475.50
Iteration:   4480, Loss function: 3.685, Average Loss: 3.601, avg. samples / sec: 65445.43
Iteration:   4480, Loss function: 3.142, Average Loss: 3.572, avg. samples / sec: 65640.61
Iteration:   4480, Loss function: 3.047, Average Loss: 3.603, avg. samples / sec: 65495.28
Iteration:   4480, Loss function: 3.217, Average Loss: 3.611, avg. samples / sec: 65530.85
Iteration:   4480, Loss function: 2.995, Average Loss: 3.601, avg. samples / sec: 65432.33
Iteration:   4480, Loss function: 3.957, Average Loss: 3.630, avg. samples / sec: 65434.12
Iteration:   4480, Loss function: 5.174, Average Loss: 3.602, avg. samples / sec: 65612.49
Iteration:   4480, Loss function: 2.665, Average Loss: 3.598, avg. samples / sec: 65377.30
Iteration:   4480, Loss function: 3.087, Average Loss: 3.615, avg. samples / sec: 65504.78
Iteration:   4480, Loss function: 2.710, Average Loss: 3.564, avg. samples / sec: 65514.43
Iteration:   4480, Loss function: 3.047, Average Loss: 3.585, avg. samples / sec: 65459.69
Iteration:   4480, Loss function: 2.950, Average Loss: 3.597, avg. samples / sec: 65409.65
Iteration:   4480, Loss function: 2.745, Average Loss: 3.562, avg. samples / sec: 65563.59
Iteration:   4480, Loss function: 2.913, Average Loss: 3.584, avg. samples / sec: 65267.27
Iteration:   4500, Loss function: 3.655, Average Loss: 3.593, avg. samples / sec: 65791.90
Iteration:   4500, Loss function: 4.413, Average Loss: 3.603, avg. samples / sec: 65758.01
Iteration:   4500, Loss function: 2.633, Average Loss: 3.560, avg. samples / sec: 65794.72
Iteration:   4500, Loss function: 4.116, Average Loss: 3.588, avg. samples / sec: 65818.17
Iteration:   4500, Loss function: 4.233, Average Loss: 3.569, avg. samples / sec: 65759.60
Iteration:   4500, Loss function: 3.058, Average Loss: 3.598, avg. samples / sec: 65819.09
Iteration:   4500, Loss function: 2.363, Average Loss: 3.590, avg. samples / sec: 65874.44
Iteration:   4500, Loss function: 2.901, Average Loss: 3.628, avg. samples / sec: 65866.71
Iteration:   4500, Loss function: 4.718, Average Loss: 3.562, avg. samples / sec: 65927.51
Iteration:   4500, Loss function: 2.883, Average Loss: 3.597, avg. samples / sec: 65840.89
Iteration:   4500, Loss function: 3.258, Average Loss: 3.579, avg. samples / sec: 65983.62
Iteration:   4500, Loss function: 3.376, Average Loss: 3.582, avg. samples / sec: 65772.74
Iteration:   4500, Loss function: 4.188, Average Loss: 3.596, avg. samples / sec: 65784.56
Iteration:   4500, Loss function: 2.792, Average Loss: 3.601, avg. samples / sec: 65770.59
Iteration:   4500, Loss function: 2.733, Average Loss: 3.600, avg. samples / sec: 65831.45
Iteration:   4500, Loss function: 5.499, Average Loss: 3.591, avg. samples / sec: 65665.57
Iteration:   4500, Loss function: 3.485, Average Loss: 3.589, avg. samples / sec: 65917.42
Iteration:   4500, Loss function: 4.515, Average Loss: 3.581, avg. samples / sec: 65853.51
Iteration:   4500, Loss function: 3.113, Average Loss: 3.600, avg. samples / sec: 65666.88
Iteration:   4500, Loss function: 3.295, Average Loss: 3.605, avg. samples / sec: 65755.03
Iteration:   4500, Loss function: 3.729, Average Loss: 3.566, avg. samples / sec: 65742.94
Iteration:   4500, Loss function: 3.176, Average Loss: 3.597, avg. samples / sec: 65699.67
Iteration:   4500, Loss function: 3.582, Average Loss: 3.586, avg. samples / sec: 65662.63
Iteration:   4500, Loss function: 3.080, Average Loss: 3.566, avg. samples / sec: 65700.53
Iteration:   4500, Loss function: 2.415, Average Loss: 3.603, avg. samples / sec: 65612.28
Iteration:   4500, Loss function: 3.800, Average Loss: 3.609, avg. samples / sec: 65740.74
Iteration:   4500, Loss function: 3.496, Average Loss: 3.603, avg. samples / sec: 65663.21
Iteration:   4500, Loss function: 3.078, Average Loss: 3.596, avg. samples / sec: 65679.58
Iteration:   4500, Loss function: 3.455, Average Loss: 3.585, avg. samples / sec: 65606.23
Iteration:   4500, Loss function: 2.934, Average Loss: 3.558, avg. samples / sec: 65718.45
Iteration:   4520, Loss function: 3.691, Average Loss: 3.599, avg. samples / sec: 66047.11
Iteration:   4520, Loss function: 2.850, Average Loss: 3.585, avg. samples / sec: 66071.70
Iteration:   4520, Loss function: 3.592, Average Loss: 3.553, avg. samples / sec: 66039.37
Iteration:   4520, Loss function: 2.805, Average Loss: 3.592, avg. samples / sec: 66019.88
Iteration:   4520, Loss function: 3.022, Average Loss: 3.582, avg. samples / sec: 66161.71
Iteration:   4520, Loss function: 3.635, Average Loss: 3.584, avg. samples / sec: 66107.03
Iteration:   4520, Loss function: 2.562, Average Loss: 3.573, avg. samples / sec: 66066.77
Iteration:   4520, Loss function: 3.755, Average Loss: 3.575, avg. samples / sec: 66044.76
Iteration:   4520, Loss function: 3.196, Average Loss: 3.590, avg. samples / sec: 66108.02
Iteration:   4520, Loss function: 3.672, Average Loss: 3.589, avg. samples / sec: 65984.15
Iteration:   4520, Loss function: 2.564, Average Loss: 3.602, avg. samples / sec: 66150.94
Iteration:   4520, Loss function: 2.941, Average Loss: 3.585, avg. samples / sec: 66009.58
Iteration:   4520, Loss function: 4.437, Average Loss: 3.592, avg. samples / sec: 66137.06
Iteration:   4520, Loss function: 3.513, Average Loss: 3.585, avg. samples / sec: 65975.90
Iteration:   4520, Loss function: 3.377, Average Loss: 3.596, avg. samples / sec: 66011.35
Iteration:   4520, Loss function: 3.015, Average Loss: 3.594, avg. samples / sec: 66082.76
Iteration:   4520, Loss function: 3.607, Average Loss: 3.561, avg. samples / sec: 65993.17
Iteration:   4520, Loss function: 2.511, Average Loss: 3.600, avg. samples / sec: 66018.68
Iteration:   4520, Loss function: 2.777, Average Loss: 3.563, avg. samples / sec: 65912.21
Iteration:   4520, Loss function: 3.365, Average Loss: 3.549, avg. samples / sec: 66123.13
Iteration:   4520, Loss function: 3.051, Average Loss: 3.596, avg. samples / sec: 65943.18
Iteration:   4520, Loss function: 3.677, Average Loss: 3.576, avg. samples / sec: 65951.11
Iteration:   4520, Loss function: 4.080, Average Loss: 3.585, avg. samples / sec: 65880.32
Iteration:   4520, Loss function: 2.681, Average Loss: 3.554, avg. samples / sec: 65890.92
Iteration:   4520, Loss function: 2.820, Average Loss: 3.600, avg. samples / sec: 65914.09
Iteration:   4520, Loss function: 2.700, Average Loss: 3.590, avg. samples / sec: 66016.11
Iteration:   4520, Loss function: 3.613, Average Loss: 3.581, avg. samples / sec: 66033.96
Iteration:   4520, Loss function: 2.500, Average Loss: 3.561, avg. samples / sec: 65960.31
Iteration:   4520, Loss function: 3.810, Average Loss: 3.590, avg. samples / sec: 65798.20
Iteration:   4520, Loss function: 3.356, Average Loss: 3.624, avg. samples / sec: 65789.78
:::MLL 1558651993.190 epoch_stop: {"value": null, "metadata": {"epoch_num": 65, "file": "train.py", "lineno": 819}}
:::MLL 1558651993.190 epoch_start: {"value": null, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 673}}
Iteration:   4540, Loss function: 4.283, Average Loss: 3.582, avg. samples / sec: 65907.62
Iteration:   4540, Loss function: 4.525, Average Loss: 3.583, avg. samples / sec: 65933.15
Iteration:   4540, Loss function: 3.441, Average Loss: 3.549, avg. samples / sec: 65752.88
Iteration:   4540, Loss function: 4.260, Average Loss: 3.587, avg. samples / sec: 66032.56
Iteration:   4540, Loss function: 2.852, Average Loss: 3.589, avg. samples / sec: 65905.62
Iteration:   4540, Loss function: 3.044, Average Loss: 3.574, avg. samples / sec: 65735.03
Iteration:   4540, Loss function: 2.501, Average Loss: 3.581, avg. samples / sec: 65947.19
Iteration:   4540, Loss function: 4.145, Average Loss: 3.572, avg. samples / sec: 65801.11
Iteration:   4540, Loss function: 2.479, Average Loss: 3.581, avg. samples / sec: 65816.17
Iteration:   4540, Loss function: 2.867, Average Loss: 3.588, avg. samples / sec: 65853.97
Iteration:   4540, Loss function: 3.093, Average Loss: 3.578, avg. samples / sec: 65737.03
Iteration:   4540, Loss function: 2.491, Average Loss: 3.560, avg. samples / sec: 65967.65
Iteration:   4540, Loss function: 4.152, Average Loss: 3.598, avg. samples / sec: 65682.83
Iteration:   4540, Loss function: 2.484, Average Loss: 3.598, avg. samples / sec: 65867.05
Iteration:   4540, Loss function: 3.533, Average Loss: 3.546, avg. samples / sec: 65880.38
Iteration:   4540, Loss function: 3.049, Average Loss: 3.578, avg. samples / sec: 65718.11
Iteration:   4540, Loss function: 2.610, Average Loss: 3.575, avg. samples / sec: 65914.37
Iteration:   4540, Loss function: 2.411, Average Loss: 3.588, avg. samples / sec: 65814.30
Iteration:   4540, Loss function: 4.362, Average Loss: 3.600, avg. samples / sec: 65859.76
Iteration:   4540, Loss function: 3.095, Average Loss: 3.551, avg. samples / sec: 65846.71
Iteration:   4540, Loss function: 3.112, Average Loss: 3.586, avg. samples / sec: 65858.89
Iteration:   4540, Loss function: 4.434, Average Loss: 3.621, avg. samples / sec: 65917.02
Iteration:   4540, Loss function: 3.329, Average Loss: 3.594, avg. samples / sec: 65718.94
Iteration:   4540, Loss function: 3.752, Average Loss: 3.573, avg. samples / sec: 65652.26
Iteration:   4540, Loss function: 3.818, Average Loss: 3.573, avg. samples / sec: 65820.38
Iteration:   4540, Loss function: 3.844, Average Loss: 3.560, avg. samples / sec: 65749.17
Iteration:   4540, Loss function: 3.460, Average Loss: 3.591, avg. samples / sec: 65776.11
Iteration:   4540, Loss function: 5.109, Average Loss: 3.569, avg. samples / sec: 65631.65
Iteration:   4540, Loss function: 3.833, Average Loss: 3.558, avg. samples / sec: 65709.50
Iteration:   4540, Loss function: 3.832, Average Loss: 3.584, avg. samples / sec: 65611.61
Iteration:   4560, Loss function: 4.511, Average Loss: 3.571, avg. samples / sec: 66068.44
Iteration:   4560, Loss function: 2.772, Average Loss: 3.574, avg. samples / sec: 65931.42
Iteration:   4560, Loss function: 2.591, Average Loss: 3.579, avg. samples / sec: 65970.84
Iteration:   4560, Loss function: 4.072, Average Loss: 3.596, avg. samples / sec: 65949.16
Iteration:   4560, Loss function: 3.959, Average Loss: 3.576, avg. samples / sec: 65855.29
Iteration:   4560, Loss function: 3.277, Average Loss: 3.566, avg. samples / sec: 65896.62
Iteration:   4560, Loss function: 2.749, Average Loss: 3.570, avg. samples / sec: 65905.92
Iteration:   4560, Loss function: 3.073, Average Loss: 3.544, avg. samples / sec: 65856.52
Iteration:   4560, Loss function: 3.853, Average Loss: 3.596, avg. samples / sec: 65967.81
Iteration:   4560, Loss function: 3.915, Average Loss: 3.592, avg. samples / sec: 65901.76
Iteration:   4560, Loss function: 4.285, Average Loss: 3.591, avg. samples / sec: 65991.66
Iteration:   4560, Loss function: 3.072, Average Loss: 3.566, avg. samples / sec: 65962.71
Iteration:   4560, Loss function: 2.569, Average Loss: 3.543, avg. samples / sec: 65910.33
Iteration:   4560, Loss function: 2.372, Average Loss: 3.543, avg. samples / sec: 65859.79
Iteration:   4560, Loss function: 3.393, Average Loss: 3.559, avg. samples / sec: 65854.80
Iteration:   4560, Loss function: 3.108, Average Loss: 3.574, avg. samples / sec: 65815.68
Iteration:   4560, Loss function: 3.219, Average Loss: 3.568, avg. samples / sec: 65871.51
Iteration:   4560, Loss function: 3.799, Average Loss: 3.572, avg. samples / sec: 65813.84
Iteration:   4560, Loss function: 3.323, Average Loss: 3.586, avg. samples / sec: 65939.66
Iteration:   4560, Loss function: 4.310, Average Loss: 3.583, avg. samples / sec: 65727.89
Iteration:   4560, Loss function: 2.254, Average Loss: 3.554, avg. samples / sec: 65932.35
Iteration:   4560, Loss function: 2.399, Average Loss: 3.583, avg. samples / sec: 65773.17
Iteration:   4560, Loss function: 5.261, Average Loss: 3.580, avg. samples / sec: 65818.88
Iteration:   4560, Loss function: 3.988, Average Loss: 3.614, avg. samples / sec: 65885.43
Iteration:   4560, Loss function: 3.020, Average Loss: 3.561, avg. samples / sec: 65932.72
Iteration:   4560, Loss function: 2.633, Average Loss: 3.576, avg. samples / sec: 65995.24
Iteration:   4560, Loss function: 2.923, Average Loss: 3.556, avg. samples / sec: 65962.75
Iteration:   4560, Loss function: 3.392, Average Loss: 3.585, avg. samples / sec: 65845.39
Iteration:   4560, Loss function: 2.608, Average Loss: 3.584, avg. samples / sec: 65712.99
Iteration:   4560, Loss function: 2.487, Average Loss: 3.589, avg. samples / sec: 65741.96
:::MLL 1558651994.028 eval_start: {"value": null, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.64 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=2.49s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22988
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39227
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23367
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06106
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24110
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37243
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34085
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10197
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36838
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53122
Current AP: 0.22988 AP goal: 0.23000
:::MLL 1558651997.731 eval_accuracy: {"value": 0.2298752720042005, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 389}}
:::MLL 1558651997.939 eval_stop: {"value": null, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 392}}
:::MLL 1558651997.946 block_stop: {"value": null, "metadata": {"first_epoch_num": 61, "file": "train.py", "lineno": 804}}
:::MLL 1558651997.947 block_start: {"value": null, "metadata": {"first_epoch_num": 66, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   4580, Loss function: 4.909, Average Loss: 3.592, avg. samples / sec: 7576.62
Iteration:   4580, Loss function: 3.451, Average Loss: 3.573, avg. samples / sec: 7578.27
Iteration:   4580, Loss function: 2.854, Average Loss: 3.565, avg. samples / sec: 7575.65
Iteration:   4580, Loss function: 2.987, Average Loss: 3.574, avg. samples / sec: 7578.23
Iteration:   4580, Loss function: 3.177, Average Loss: 3.560, avg. samples / sec: 7575.74
Iteration:   4580, Loss function: 3.876, Average Loss: 3.571, avg. samples / sec: 7575.32
Iteration:   4580, Loss function: 2.722, Average Loss: 3.589, avg. samples / sec: 7575.92
Iteration:   4580, Loss function: 3.834, Average Loss: 3.541, avg. samples / sec: 7575.99
Iteration:   4580, Loss function: 4.249, Average Loss: 3.609, avg. samples / sec: 7577.07
Iteration:   4580, Loss function: 2.875, Average Loss: 3.553, avg. samples / sec: 7577.41
Iteration:   4580, Loss function: 2.542, Average Loss: 3.582, avg. samples / sec: 7576.92
Iteration:   4580, Loss function: 3.043, Average Loss: 3.571, avg. samples / sec: 7574.72
Iteration:   4580, Loss function: 3.181, Average Loss: 3.565, avg. samples / sec: 7576.47
Iteration:   4580, Loss function: 3.173, Average Loss: 3.582, avg. samples / sec: 7575.30
Iteration:   4580, Loss function: 3.577, Average Loss: 3.559, avg. samples / sec: 7576.32
Iteration:   4580, Loss function: 3.412, Average Loss: 3.540, avg. samples / sec: 7575.73
Iteration:   4580, Loss function: 3.218, Average Loss: 3.578, avg. samples / sec: 7576.11
Iteration:   4580, Loss function: 2.919, Average Loss: 3.564, avg. samples / sec: 7575.37
Iteration:   4580, Loss function: 2.892, Average Loss: 3.576, avg. samples / sec: 7575.77
Iteration:   4580, Loss function: 3.933, Average Loss: 3.570, avg. samples / sec: 7576.23
Iteration:   4580, Loss function: 3.558, Average Loss: 3.585, avg. samples / sec: 7576.20
Iteration:   4580, Loss function: 4.218, Average Loss: 3.579, avg. samples / sec: 7576.08
Iteration:   4580, Loss function: 3.706, Average Loss: 3.548, avg. samples / sec: 7575.47
Iteration:   4580, Loss function: 3.826, Average Loss: 3.537, avg. samples / sec: 7574.51
Iteration:   4580, Loss function: 2.017, Average Loss: 3.593, avg. samples / sec: 7573.69
Iteration:   4580, Loss function: 2.749, Average Loss: 3.572, avg. samples / sec: 7573.27
Iteration:   4580, Loss function: 3.027, Average Loss: 3.551, avg. samples / sec: 7574.56
Iteration:   4580, Loss function: 3.193, Average Loss: 3.570, avg. samples / sec: 7572.62
Iteration:   4580, Loss function: 4.040, Average Loss: 3.568, avg. samples / sec: 7573.88
Iteration:   4580, Loss function: 3.671, Average Loss: 3.561, avg. samples / sec: 7572.79
Iteration:   4600, Loss function: 3.928, Average Loss: 3.536, avg. samples / sec: 65866.99
Iteration:   4600, Loss function: 3.733, Average Loss: 3.563, avg. samples / sec: 65773.38
Iteration:   4600, Loss function: 3.162, Average Loss: 3.584, avg. samples / sec: 65733.68
Iteration:   4600, Loss function: 3.308, Average Loss: 3.540, avg. samples / sec: 65986.81
Iteration:   4600, Loss function: 3.036, Average Loss: 3.570, avg. samples / sec: 65980.41
Iteration:   4600, Loss function: 2.751, Average Loss: 3.580, avg. samples / sec: 65794.05
Iteration:   4600, Loss function: 5.369, Average Loss: 3.569, avg. samples / sec: 65998.18
Iteration:   4600, Loss function: 3.024, Average Loss: 3.574, avg. samples / sec: 65834.22
Iteration:   4600, Loss function: 4.038, Average Loss: 3.567, avg. samples / sec: 65776.54
Iteration:   4600, Loss function: 3.730, Average Loss: 3.563, avg. samples / sec: 65705.79
Iteration:   4600, Loss function: 3.647, Average Loss: 3.594, avg. samples / sec: 65914.12
Iteration:   4600, Loss function: 3.585, Average Loss: 3.549, avg. samples / sec: 65736.14
Iteration:   4600, Loss function: 2.783, Average Loss: 3.540, avg. samples / sec: 65797.80
Iteration:   4600, Loss function: 3.970, Average Loss: 3.606, avg. samples / sec: 65730.04
Iteration:   4600, Loss function: 4.062, Average Loss: 3.576, avg. samples / sec: 65820.32
Iteration:   4600, Loss function: 3.600, Average Loss: 3.547, avg. samples / sec: 65862.83
Iteration:   4600, Loss function: 3.113, Average Loss: 3.566, avg. samples / sec: 65642.29
Iteration:   4600, Loss function: 3.925, Average Loss: 3.539, avg. samples / sec: 65811.32
Iteration:   4600, Loss function: 2.451, Average Loss: 3.580, avg. samples / sec: 65674.47
Iteration:   4600, Loss function: 4.258, Average Loss: 3.568, avg. samples / sec: 65755.95
Iteration:   4600, Loss function: 2.928, Average Loss: 3.562, avg. samples / sec: 65707.30
Iteration:   4600, Loss function: 4.321, Average Loss: 3.558, avg. samples / sec: 65654.89
Iteration:   4600, Loss function: 3.599, Average Loss: 3.574, avg. samples / sec: 65716.30
Iteration:   4600, Loss function: 3.149, Average Loss: 3.581, avg. samples / sec: 65776.58
Iteration:   4600, Loss function: 3.178, Average Loss: 3.556, avg. samples / sec: 65696.58
Iteration:   4600, Loss function: 5.072, Average Loss: 3.579, avg. samples / sec: 65753.77
Iteration:   4600, Loss function: 4.499, Average Loss: 3.564, avg. samples / sec: 65725.87
Iteration:   4600, Loss function: 4.415, Average Loss: 3.562, avg. samples / sec: 65839.69
Iteration:   4600, Loss function: 4.289, Average Loss: 3.565, avg. samples / sec: 65673.49
Iteration:   4600, Loss function: 3.873, Average Loss: 3.553, avg. samples / sec: 65762.24
:::MLL 1558651998.904 epoch_stop: {"value": null, "metadata": {"epoch_num": 66, "file": "train.py", "lineno": 819}}
:::MLL 1558651998.904 epoch_start: {"value": null, "metadata": {"epoch_num": 67, "file": "train.py", "lineno": 673}}
Iteration:   4620, Loss function: 2.904, Average Loss: 3.563, avg. samples / sec: 65194.99
Iteration:   4620, Loss function: 4.341, Average Loss: 3.565, avg. samples / sec: 65153.57
Iteration:   4620, Loss function: 1.758, Average Loss: 3.577, avg. samples / sec: 65037.66
Iteration:   4620, Loss function: 2.971, Average Loss: 3.541, avg. samples / sec: 65189.35
Iteration:   4620, Loss function: 3.283, Average Loss: 3.565, avg. samples / sec: 65035.32
Iteration:   4620, Loss function: 3.869, Average Loss: 3.552, avg. samples / sec: 65149.36
Iteration:   4620, Loss function: 2.979, Average Loss: 3.540, avg. samples / sec: 65060.96
Iteration:   4620, Loss function: 3.815, Average Loss: 3.566, avg. samples / sec: 65145.05
Iteration:   4620, Loss function: 2.645, Average Loss: 3.555, avg. samples / sec: 65126.57
Iteration:   4620, Loss function: 3.042, Average Loss: 3.543, avg. samples / sec: 65071.42
Iteration:   4620, Loss function: 2.393, Average Loss: 3.602, avg. samples / sec: 65038.80
Iteration:   4620, Loss function: 3.910, Average Loss: 3.564, avg. samples / sec: 65134.12
Iteration:   4620, Loss function: 3.604, Average Loss: 3.570, avg. samples / sec: 65104.54
Iteration:   4620, Loss function: 4.074, Average Loss: 3.535, avg. samples / sec: 65020.74
Iteration:   4620, Loss function: 3.045, Average Loss: 3.551, avg. samples / sec: 65110.71
Iteration:   4620, Loss function: 3.776, Average Loss: 3.561, avg. samples / sec: 64957.62
Iteration:   4620, Loss function: 3.045, Average Loss: 3.552, avg. samples / sec: 65232.53
Iteration:   4620, Loss function: 2.446, Average Loss: 3.563, avg. samples / sec: 64857.18
Iteration:   4620, Loss function: 3.784, Average Loss: 3.570, avg. samples / sec: 64915.67
Iteration:   4620, Loss function: 3.666, Average Loss: 3.562, avg. samples / sec: 65031.99
Iteration:   4620, Loss function: 2.568, Average Loss: 3.581, avg. samples / sec: 65054.80
Iteration:   4620, Loss function: 3.359, Average Loss: 3.533, avg. samples / sec: 64868.97
Iteration:   4620, Loss function: 3.392, Average Loss: 3.531, avg. samples / sec: 64841.63
Iteration:   4620, Loss function: 3.520, Average Loss: 3.580, avg. samples / sec: 65048.95
Iteration:   4620, Loss function: 2.659, Average Loss: 3.564, avg. samples / sec: 64976.58
Iteration:   4620, Loss function: 3.869, Average Loss: 3.577, avg. samples / sec: 65053.66
Iteration:   4620, Loss function: 3.448, Average Loss: 3.579, avg. samples / sec: 64880.02
Iteration:   4620, Loss function: 4.694, Average Loss: 3.562, avg. samples / sec: 65021.82
Iteration:   4620, Loss function: 2.836, Average Loss: 3.561, avg. samples / sec: 64997.20
Iteration:   4620, Loss function: 3.164, Average Loss: 3.593, avg. samples / sec: 64832.03
Iteration:   4640, Loss function: 3.122, Average Loss: 3.572, avg. samples / sec: 65991.72
Iteration:   4640, Loss function: 3.840, Average Loss: 3.566, avg. samples / sec: 66081.67
Iteration:   4640, Loss function: 3.090, Average Loss: 3.555, avg. samples / sec: 65888.76
Iteration:   4640, Loss function: 3.203, Average Loss: 3.559, avg. samples / sec: 66046.06
Iteration:   4640, Loss function: 2.371, Average Loss: 3.561, avg. samples / sec: 66117.11
Iteration:   4640, Loss function: 3.213, Average Loss: 3.563, avg. samples / sec: 65961.82
Iteration:   4640, Loss function: 3.059, Average Loss: 3.544, avg. samples / sec: 65984.02
Iteration:   4640, Loss function: 2.578, Average Loss: 3.597, avg. samples / sec: 66015.99
Iteration:   4640, Loss function: 3.437, Average Loss: 3.551, avg. samples / sec: 65979.61
Iteration:   4640, Loss function: 3.342, Average Loss: 3.564, avg. samples / sec: 65819.34
Iteration:   4640, Loss function: 3.418, Average Loss: 3.555, avg. samples / sec: 66109.07
Iteration:   4640, Loss function: 2.984, Average Loss: 3.537, avg. samples / sec: 65977.54
Iteration:   4640, Loss function: 2.838, Average Loss: 3.576, avg. samples / sec: 66070.83
Iteration:   4640, Loss function: 2.841, Average Loss: 3.541, avg. samples / sec: 65923.50
Iteration:   4640, Loss function: 4.210, Average Loss: 3.571, avg. samples / sec: 66040.73
Iteration:   4640, Loss function: 2.763, Average Loss: 3.560, avg. samples / sec: 66013.26
Iteration:   4640, Loss function: 3.626, Average Loss: 3.535, avg. samples / sec: 66015.58
Iteration:   4640, Loss function: 2.291, Average Loss: 3.556, avg. samples / sec: 66076.62
Iteration:   4640, Loss function: 3.134, Average Loss: 3.576, avg. samples / sec: 66006.89
Iteration:   4640, Loss function: 4.081, Average Loss: 3.552, avg. samples / sec: 65971.61
Iteration:   4640, Loss function: 3.791, Average Loss: 3.533, avg. samples / sec: 65931.05
Iteration:   4640, Loss function: 4.357, Average Loss: 3.579, avg. samples / sec: 65960.21
Iteration:   4640, Loss function: 2.672, Average Loss: 3.557, avg. samples / sec: 65853.78
Iteration:   4640, Loss function: 2.659, Average Loss: 3.526, avg. samples / sec: 65945.80
Iteration:   4640, Loss function: 4.529, Average Loss: 3.589, avg. samples / sec: 66068.16
Iteration:   4640, Loss function: 3.449, Average Loss: 3.574, avg. samples / sec: 65941.39
Iteration:   4640, Loss function: 2.957, Average Loss: 3.557, avg. samples / sec: 65900.62
Iteration:   4640, Loss function: 3.246, Average Loss: 3.564, avg. samples / sec: 65905.71
Iteration:   4640, Loss function: 3.158, Average Loss: 3.535, avg. samples / sec: 65689.90
Iteration:   4640, Loss function: 4.118, Average Loss: 3.546, avg. samples / sec: 65703.68
Iteration:   4660, Loss function: 2.487, Average Loss: 3.569, avg. samples / sec: 65866.43
Iteration:   4660, Loss function: 2.593, Average Loss: 3.571, avg. samples / sec: 65961.73
Iteration:   4660, Loss function: 3.376, Average Loss: 3.549, avg. samples / sec: 65910.76
Iteration:   4660, Loss function: 4.448, Average Loss: 3.548, avg. samples / sec: 65841.14
Iteration:   4660, Loss function: 3.286, Average Loss: 3.541, avg. samples / sec: 65848.49
Iteration:   4660, Loss function: 4.088, Average Loss: 3.590, avg. samples / sec: 65854.52
Iteration:   4660, Loss function: 2.802, Average Loss: 3.560, avg. samples / sec: 65886.76
Iteration:   4660, Loss function: 2.690, Average Loss: 3.556, avg. samples / sec: 65824.44
Iteration:   4660, Loss function: 3.021, Average Loss: 3.540, avg. samples / sec: 65904.23
Iteration:   4660, Loss function: 4.463, Average Loss: 3.527, avg. samples / sec: 65974.05
Iteration:   4660, Loss function: 3.667, Average Loss: 3.530, avg. samples / sec: 65928.18
Iteration:   4660, Loss function: 3.445, Average Loss: 3.561, avg. samples / sec: 65776.08
Iteration:   4660, Loss function: 2.731, Average Loss: 3.558, avg. samples / sec: 65791.35
Iteration:   4660, Loss function: 2.807, Average Loss: 3.571, avg. samples / sec: 65855.72
Iteration:   4660, Loss function: 3.368, Average Loss: 3.532, avg. samples / sec: 66012.77
Iteration:   4660, Loss function: 3.059, Average Loss: 3.532, avg. samples / sec: 65854.55
Iteration:   4660, Loss function: 3.379, Average Loss: 3.544, avg. samples / sec: 65876.56
Iteration:   4660, Loss function: 2.150, Average Loss: 3.543, avg. samples / sec: 66101.26
Iteration:   4660, Loss function: 3.574, Average Loss: 3.589, avg. samples / sec: 65886.54
Iteration:   4660, Loss function: 3.207, Average Loss: 3.563, avg. samples / sec: 65927.60
Iteration:   4660, Loss function: 2.755, Average Loss: 3.551, avg. samples / sec: 65846.31
Iteration:   4660, Loss function: 5.160, Average Loss: 3.554, avg. samples / sec: 65893.14
Iteration:   4660, Loss function: 2.890, Average Loss: 3.551, avg. samples / sec: 65800.13
Iteration:   4660, Loss function: 4.325, Average Loss: 3.571, avg. samples / sec: 65882.35
Iteration:   4660, Loss function: 2.998, Average Loss: 3.568, avg. samples / sec: 65822.53
Iteration:   4660, Loss function: 3.714, Average Loss: 3.529, avg. samples / sec: 65733.01
Iteration:   4660, Loss function: 3.975, Average Loss: 3.552, avg. samples / sec: 65706.53
Iteration:   4660, Loss function: 2.500, Average Loss: 3.551, avg. samples / sec: 65736.08
Iteration:   4660, Loss function: 4.257, Average Loss: 3.579, avg. samples / sec: 65767.34
Iteration:   4660, Loss function: 2.947, Average Loss: 3.556, avg. samples / sec: 65586.60
:::MLL 1558652000.694 epoch_stop: {"value": null, "metadata": {"epoch_num": 67, "file": "train.py", "lineno": 819}}
:::MLL 1558652000.695 epoch_start: {"value": null, "metadata": {"epoch_num": 68, "file": "train.py", "lineno": 673}}
Iteration:   4680, Loss function: 4.124, Average Loss: 3.547, avg. samples / sec: 65886.39
Iteration:   4680, Loss function: 3.257, Average Loss: 3.564, avg. samples / sec: 65591.15
Iteration:   4680, Loss function: 2.618, Average Loss: 3.564, avg. samples / sec: 65787.91
Iteration:   4680, Loss function: 3.320, Average Loss: 3.545, avg. samples / sec: 65814.33
Iteration:   4680, Loss function: 3.547, Average Loss: 3.553, avg. samples / sec: 65680.38
Iteration:   4680, Loss function: 2.828, Average Loss: 3.537, avg. samples / sec: 65672.88
Iteration:   4680, Loss function: 3.720, Average Loss: 3.562, avg. samples / sec: 65803.23
Iteration:   4680, Loss function: 3.141, Average Loss: 3.558, avg. samples / sec: 65677.53
Iteration:   4680, Loss function: 4.565, Average Loss: 3.528, avg. samples / sec: 65668.01
Iteration:   4680, Loss function: 3.772, Average Loss: 3.548, avg. samples / sec: 65605.83
Iteration:   4680, Loss function: 2.585, Average Loss: 3.586, avg. samples / sec: 65649.97
Iteration:   4680, Loss function: 2.570, Average Loss: 3.538, avg. samples / sec: 65630.49
Iteration:   4680, Loss function: 2.709, Average Loss: 3.524, avg. samples / sec: 65666.30
Iteration:   4680, Loss function: 4.256, Average Loss: 3.576, avg. samples / sec: 65819.31
Iteration:   4680, Loss function: 3.158, Average Loss: 3.549, avg. samples / sec: 65791.71
Iteration:   4680, Loss function: 2.965, Average Loss: 3.581, avg. samples / sec: 65711.49
Iteration:   4680, Loss function: 1.994, Average Loss: 3.547, avg. samples / sec: 65562.95
Iteration:   4680, Loss function: 2.964, Average Loss: 3.565, avg. samples / sec: 65658.16
Iteration:   4680, Loss function: 4.060, Average Loss: 3.553, avg. samples / sec: 65830.47
Iteration:   4680, Loss function: 3.406, Average Loss: 3.548, avg. samples / sec: 65795.71
Iteration:   4680, Loss function: 3.697, Average Loss: 3.526, avg. samples / sec: 65746.50
Iteration:   4680, Loss function: 3.589, Average Loss: 3.526, avg. samples / sec: 65644.40
Iteration:   4680, Loss function: 2.982, Average Loss: 3.557, avg. samples / sec: 65565.03
Iteration:   4680, Loss function: 2.861, Average Loss: 3.565, avg. samples / sec: 65507.33
Iteration:   4680, Loss function: 2.690, Average Loss: 3.541, avg. samples / sec: 65658.35
Iteration:   4680, Loss function: 2.943, Average Loss: 3.562, avg. samples / sec: 65600.12
Iteration:   4680, Loss function: 4.249, Average Loss: 3.546, avg. samples / sec: 65676.06
Iteration:   4680, Loss function: 4.244, Average Loss: 3.540, avg. samples / sec: 65597.96
Iteration:   4680, Loss function: 2.794, Average Loss: 3.530, avg. samples / sec: 65553.22
Iteration:   4680, Loss function: 4.085, Average Loss: 3.568, avg. samples / sec: 64467.74
Iteration:   4700, Loss function: 4.039, Average Loss: 3.546, avg. samples / sec: 64981.10
Iteration:   4700, Loss function: 3.083, Average Loss: 3.538, avg. samples / sec: 64991.35
Iteration:   4700, Loss function: 2.098, Average Loss: 3.539, avg. samples / sec: 64874.46
Iteration:   4700, Loss function: 3.093, Average Loss: 3.539, avg. samples / sec: 64958.55
Iteration:   4700, Loss function: 3.072, Average Loss: 3.518, avg. samples / sec: 64941.34
Iteration:   4700, Loss function: 2.897, Average Loss: 3.560, avg. samples / sec: 64912.47
Iteration:   4700, Loss function: 3.250, Average Loss: 3.579, avg. samples / sec: 64973.55
Iteration:   4700, Loss function: 3.497, Average Loss: 3.525, avg. samples / sec: 64914.87
Iteration:   4700, Loss function: 3.160, Average Loss: 3.558, avg. samples / sec: 64882.80
Iteration:   4700, Loss function: 4.648, Average Loss: 3.539, avg. samples / sec: 64899.02
Iteration:   4700, Loss function: 2.627, Average Loss: 3.539, avg. samples / sec: 65024.73
Iteration:   4700, Loss function: 2.427, Average Loss: 3.562, avg. samples / sec: 64937.63
Iteration:   4700, Loss function: 3.883, Average Loss: 3.524, avg. samples / sec: 64958.34
Iteration:   4700, Loss function: 2.206, Average Loss: 3.535, avg. samples / sec: 64974.30
Iteration:   4700, Loss function: 2.523, Average Loss: 3.546, avg. samples / sec: 64930.12
Iteration:   4700, Loss function: 3.322, Average Loss: 3.561, avg. samples / sec: 66217.05
Iteration:   4700, Loss function: 3.648, Average Loss: 3.541, avg. samples / sec: 64898.84
Iteration:   4700, Loss function: 4.143, Average Loss: 3.555, avg. samples / sec: 64933.26
Iteration:   4700, Loss function: 2.604, Average Loss: 3.559, avg. samples / sec: 64938.77
Iteration:   4700, Loss function: 3.681, Average Loss: 3.527, avg. samples / sec: 64917.53
Iteration:   4700, Loss function: 3.174, Average Loss: 3.547, avg. samples / sec: 64907.90
Iteration:   4700, Loss function: 4.323, Average Loss: 3.555, avg. samples / sec: 64849.57
Iteration:   4700, Loss function: 3.638, Average Loss: 3.544, avg. samples / sec: 64947.35
Iteration:   4700, Loss function: 3.530, Average Loss: 3.558, avg. samples / sec: 64905.96
Iteration:   4700, Loss function: 3.367, Average Loss: 3.571, avg. samples / sec: 64858.49
Iteration:   4700, Loss function: 2.838, Average Loss: 3.550, avg. samples / sec: 64853.27
Iteration:   4700, Loss function: 2.639, Average Loss: 3.561, avg. samples / sec: 64787.47
Iteration:   4700, Loss function: 3.535, Average Loss: 3.526, avg. samples / sec: 64961.96
Iteration:   4700, Loss function: 3.743, Average Loss: 3.543, avg. samples / sec: 64765.73
Iteration:   4700, Loss function: 2.927, Average Loss: 3.578, avg. samples / sec: 64683.09
Iteration:   4720, Loss function: 3.294, Average Loss: 3.556, avg. samples / sec: 65997.90
Iteration:   4720, Loss function: 3.556, Average Loss: 3.525, avg. samples / sec: 65976.43
Iteration:   4720, Loss function: 2.986, Average Loss: 3.550, avg. samples / sec: 65990.30
Iteration:   4720, Loss function: 2.315, Average Loss: 3.543, avg. samples / sec: 65930.13
Iteration:   4720, Loss function: 3.782, Average Loss: 3.535, avg. samples / sec: 65833.05
Iteration:   4720, Loss function: 3.279, Average Loss: 3.572, avg. samples / sec: 66132.19
Iteration:   4720, Loss function: 3.836, Average Loss: 3.532, avg. samples / sec: 65902.53
Iteration:   4720, Loss function: 3.964, Average Loss: 3.571, avg. samples / sec: 65980.19
Iteration:   4720, Loss function: 3.202, Average Loss: 3.536, avg. samples / sec: 65879.55
Iteration:   4720, Loss function: 2.104, Average Loss: 3.533, avg. samples / sec: 65795.61
Iteration:   4720, Loss function: 3.465, Average Loss: 3.521, avg. samples / sec: 65866.22
Iteration:   4720, Loss function: 2.669, Average Loss: 3.555, avg. samples / sec: 65889.07
Iteration:   4720, Loss function: 2.857, Average Loss: 3.552, avg. samples / sec: 65813.96
Iteration:   4720, Loss function: 3.054, Average Loss: 3.552, avg. samples / sec: 65843.14
Iteration:   4720, Loss function: 3.393, Average Loss: 3.513, avg. samples / sec: 65775.19
Iteration:   4720, Loss function: 2.336, Average Loss: 3.574, avg. samples / sec: 65768.90
Iteration:   4720, Loss function: 2.847, Average Loss: 3.547, avg. samples / sec: 65859.60
Iteration:   4720, Loss function: 1.982, Average Loss: 3.539, avg. samples / sec: 65685.28
Iteration:   4720, Loss function: 2.709, Average Loss: 3.537, avg. samples / sec: 65912.21
Iteration:   4720, Loss function: 3.753, Average Loss: 3.536, avg. samples / sec: 65734.05
Iteration:   4720, Loss function: 2.417, Average Loss: 3.523, avg. samples / sec: 65889.16
Iteration:   4720, Loss function: 4.327, Average Loss: 3.559, avg. samples / sec: 65849.85
Iteration:   4720, Loss function: 4.023, Average Loss: 3.537, avg. samples / sec: 65799.42
Iteration:   4720, Loss function: 3.819, Average Loss: 3.559, avg. samples / sec: 65751.47
Iteration:   4720, Loss function: 2.846, Average Loss: 3.543, avg. samples / sec: 65772.55
Iteration:   4720, Loss function: 2.263, Average Loss: 3.535, avg. samples / sec: 65712.20
Iteration:   4720, Loss function: 2.842, Average Loss: 3.557, avg. samples / sec: 65814.76
Iteration:   4720, Loss function: 3.182, Average Loss: 3.539, avg. samples / sec: 65763.71
Iteration:   4720, Loss function: 3.214, Average Loss: 3.525, avg. samples / sec: 65743.19
Iteration:   4720, Loss function: 3.130, Average Loss: 3.547, avg. samples / sec: 65768.99
Iteration:   4740, Loss function: 3.257, Average Loss: 3.530, avg. samples / sec: 66103.46
Iteration:   4740, Loss function: 1.650, Average Loss: 3.532, avg. samples / sec: 66172.37
Iteration:   4740, Loss function: 2.723, Average Loss: 3.518, avg. samples / sec: 66256.71
Iteration:   4740, Loss function: 4.367, Average Loss: 3.547, avg. samples / sec: 65989.49
Iteration:   4740, Loss function: 3.422, Average Loss: 3.549, avg. samples / sec: 65881.46
Iteration:   4740, Loss function: 3.802, Average Loss: 3.521, avg. samples / sec: 65938.21
Iteration:   4740, Loss function: 2.500, Average Loss: 3.566, avg. samples / sec: 65998.08
Iteration:   4740, Loss function: 3.383, Average Loss: 3.517, avg. samples / sec: 66019.26
Iteration:   4740, Loss function: 2.384, Average Loss: 3.531, avg. samples / sec: 66181.94
Iteration:   4740, Loss function: 2.883, Average Loss: 3.553, avg. samples / sec: 66045.19
Iteration:   4740, Loss function: 2.515, Average Loss: 3.558, avg. samples / sec: 66094.29
Iteration:   4740, Loss function: 2.962, Average Loss: 3.541, avg. samples / sec: 66104.80
Iteration:   4740, Loss function: 3.920, Average Loss: 3.536, avg. samples / sec: 66123.59
Iteration:   4740, Loss function: 2.312, Average Loss: 3.570, avg. samples / sec: 66027.65
Iteration:   4740, Loss function: 2.803, Average Loss: 3.532, avg. samples / sec: 66022.39
Iteration:   4740, Loss function: 3.300, Average Loss: 3.549, avg. samples / sec: 65982.14
Iteration:   4740, Loss function: 2.540, Average Loss: 3.531, avg. samples / sec: 66054.38
Iteration:   4740, Loss function: 4.409, Average Loss: 3.537, avg. samples / sec: 65899.42
Iteration:   4740, Loss function: 2.490, Average Loss: 3.545, avg. samples / sec: 65967.62
Iteration:   4740, Loss function: 2.398, Average Loss: 3.538, avg. samples / sec: 65873.39
Iteration:   4740, Loss function: 2.725, Average Loss: 3.537, avg. samples / sec: 65846.92
Iteration:   4740, Loss function: 2.726, Average Loss: 3.551, avg. samples / sec: 66013.48
Iteration:   4740, Loss function: 3.104, Average Loss: 3.541, avg. samples / sec: 66058.47
Iteration:   4740, Loss function: 3.191, Average Loss: 3.537, avg. samples / sec: 65951.57
Iteration:   4740, Loss function: 4.055, Average Loss: 3.549, avg. samples / sec: 66035.38
Iteration:   4740, Loss function: 2.909, Average Loss: 3.545, avg. samples / sec: 65897.73
Iteration:   4740, Loss function: 3.101, Average Loss: 3.521, avg. samples / sec: 65930.03
Iteration:   4740, Loss function: 3.439, Average Loss: 3.570, avg. samples / sec: 65808.55
Iteration:   4740, Loss function: 3.875, Average Loss: 3.511, avg. samples / sec: 65907.37
Iteration:   4740, Loss function: 3.691, Average Loss: 3.528, avg. samples / sec: 65724.82
:::MLL 1558652002.489 epoch_stop: {"value": null, "metadata": {"epoch_num": 68, "file": "train.py", "lineno": 819}}
:::MLL 1558652002.490 epoch_start: {"value": null, "metadata": {"epoch_num": 69, "file": "train.py", "lineno": 673}}
Iteration:   4760, Loss function: 2.880, Average Loss: 3.546, avg. samples / sec: 65515.01
Iteration:   4760, Loss function: 3.257, Average Loss: 3.525, avg. samples / sec: 65493.94
Iteration:   4760, Loss function: 3.366, Average Loss: 3.525, avg. samples / sec: 65561.76
Iteration:   4760, Loss function: 2.370, Average Loss: 3.553, avg. samples / sec: 65496.86
Iteration:   4760, Loss function: 2.595, Average Loss: 3.514, avg. samples / sec: 65459.26
Iteration:   4760, Loss function: 2.059, Average Loss: 3.537, avg. samples / sec: 65606.08
Iteration:   4760, Loss function: 2.878, Average Loss: 3.547, avg. samples / sec: 65585.26
Iteration:   4760, Loss function: 3.585, Average Loss: 3.532, avg. samples / sec: 65576.77
Iteration:   4760, Loss function: 1.967, Average Loss: 3.529, avg. samples / sec: 65341.20
Iteration:   4760, Loss function: 2.658, Average Loss: 3.566, avg. samples / sec: 65479.33
Iteration:   4760, Loss function: 2.514, Average Loss: 3.516, avg. samples / sec: 65357.53
Iteration:   4760, Loss function: 2.444, Average Loss: 3.559, avg. samples / sec: 65403.64
Iteration:   4760, Loss function: 4.258, Average Loss: 3.526, avg. samples / sec: 65675.17
Iteration:   4760, Loss function: 3.544, Average Loss: 3.534, avg. samples / sec: 65491.50
Iteration:   4760, Loss function: 2.665, Average Loss: 3.508, avg. samples / sec: 65573.93
Iteration:   4760, Loss function: 2.434, Average Loss: 3.527, avg. samples / sec: 65465.31
Iteration:   4760, Loss function: 3.544, Average Loss: 3.542, avg. samples / sec: 65443.54
Iteration:   4760, Loss function: 3.398, Average Loss: 3.516, avg. samples / sec: 65555.54
Iteration:   4760, Loss function: 3.079, Average Loss: 3.535, avg. samples / sec: 65480.00
Iteration:   4760, Loss function: 2.982, Average Loss: 3.543, avg. samples / sec: 65489.98
Iteration:   4760, Loss function: 3.534, Average Loss: 3.541, avg. samples / sec: 65317.27
Iteration:   4760, Loss function: 2.884, Average Loss: 3.564, avg. samples / sec: 65528.20
Iteration:   4760, Loss function: 3.148, Average Loss: 3.532, avg. samples / sec: 65399.57
Iteration:   4760, Loss function: 4.127, Average Loss: 3.529, avg. samples / sec: 65249.11
Iteration:   4760, Loss function: 4.236, Average Loss: 3.535, avg. samples / sec: 65474.62
Iteration:   4760, Loss function: 2.501, Average Loss: 3.548, avg. samples / sec: 65323.48
Iteration:   4760, Loss function: 2.647, Average Loss: 3.542, avg. samples / sec: 65403.51
Iteration:   4760, Loss function: 3.667, Average Loss: 3.546, avg. samples / sec: 65409.71
Iteration:   4760, Loss function: 4.310, Average Loss: 3.544, avg. samples / sec: 65444.15
Iteration:   4760, Loss function: 3.238, Average Loss: 3.521, avg. samples / sec: 65249.53
Iteration:   4780, Loss function: 3.364, Average Loss: 3.535, avg. samples / sec: 65421.97
Iteration:   4780, Loss function: 3.230, Average Loss: 3.524, avg. samples / sec: 65315.43
Iteration:   4780, Loss function: 3.192, Average Loss: 3.519, avg. samples / sec: 65323.09
Iteration:   4780, Loss function: 3.131, Average Loss: 3.561, avg. samples / sec: 65379.57
Iteration:   4780, Loss function: 3.415, Average Loss: 3.522, avg. samples / sec: 65241.23
Iteration:   4780, Loss function: 3.369, Average Loss: 3.545, avg. samples / sec: 65239.05
Iteration:   4780, Loss function: 3.482, Average Loss: 3.535, avg. samples / sec: 65357.11
Iteration:   4780, Loss function: 4.870, Average Loss: 3.529, avg. samples / sec: 65303.90
Iteration:   4780, Loss function: 3.910, Average Loss: 3.515, avg. samples / sec: 65183.98
Iteration:   4780, Loss function: 2.815, Average Loss: 3.541, avg. samples / sec: 65306.17
Iteration:   4780, Loss function: 2.276, Average Loss: 3.538, avg. samples / sec: 65296.60
Iteration:   4780, Loss function: 3.445, Average Loss: 3.520, avg. samples / sec: 65419.82
Iteration:   4780, Loss function: 3.093, Average Loss: 3.546, avg. samples / sec: 65342.14
Iteration:   4780, Loss function: 3.122, Average Loss: 3.529, avg. samples / sec: 65314.06
Iteration:   4780, Loss function: 4.511, Average Loss: 3.541, avg. samples / sec: 65379.18
Iteration:   4780, Loss function: 3.477, Average Loss: 3.527, avg. samples / sec: 65321.66
Iteration:   4780, Loss function: 3.440, Average Loss: 3.540, avg. samples / sec: 65119.89
Iteration:   4780, Loss function: 3.067, Average Loss: 3.551, avg. samples / sec: 65156.65
Iteration:   4780, Loss function: 2.815, Average Loss: 3.534, avg. samples / sec: 65163.67
Iteration:   4780, Loss function: 2.961, Average Loss: 3.507, avg. samples / sec: 65154.03
Iteration:   4780, Loss function: 2.868, Average Loss: 3.532, avg. samples / sec: 65233.19
Iteration:   4780, Loss function: 3.644, Average Loss: 3.538, avg. samples / sec: 65289.80
Iteration:   4780, Loss function: 1.756, Average Loss: 3.536, avg. samples / sec: 65318.30
Iteration:   4780, Loss function: 3.494, Average Loss: 3.515, avg. samples / sec: 65212.76
Iteration:   4780, Loss function: 4.201, Average Loss: 3.527, avg. samples / sec: 65165.11
Iteration:   4780, Loss function: 3.514, Average Loss: 3.553, avg. samples / sec: 65146.92
Iteration:   4780, Loss function: 3.417, Average Loss: 3.507, avg. samples / sec: 65160.02
Iteration:   4780, Loss function: 4.170, Average Loss: 3.510, avg. samples / sec: 65111.07
Iteration:   4780, Loss function: 3.715, Average Loss: 3.566, avg. samples / sec: 65101.08
Iteration:   4780, Loss function: 4.192, Average Loss: 3.531, avg. samples / sec: 65020.59
Iteration:   4800, Loss function: 2.629, Average Loss: 3.519, avg. samples / sec: 66085.08
Iteration:   4800, Loss function: 2.886, Average Loss: 3.523, avg. samples / sec: 66099.15
Iteration:   4800, Loss function: 3.084, Average Loss: 3.532, avg. samples / sec: 66089.76
Iteration:   4800, Loss function: 3.358, Average Loss: 3.531, avg. samples / sec: 66005.13
Iteration:   4800, Loss function: 2.535, Average Loss: 3.536, avg. samples / sec: 66026.04
Iteration:   4800, Loss function: 4.235, Average Loss: 3.530, avg. samples / sec: 66060.89
Iteration:   4800, Loss function: 3.272, Average Loss: 3.521, avg. samples / sec: 65941.76
Iteration:   4800, Loss function: 3.523, Average Loss: 3.504, avg. samples / sec: 66118.26
Iteration:   4800, Loss function: 3.771, Average Loss: 3.509, avg. samples / sec: 66027.52
Iteration:   4800, Loss function: 4.096, Average Loss: 3.542, avg. samples / sec: 65995.27
Iteration:   4800, Loss function: 3.856, Average Loss: 3.530, avg. samples / sec: 65962.16
Iteration:   4800, Loss function: 2.561, Average Loss: 3.560, avg. samples / sec: 65924.64
Iteration:   4800, Loss function: 2.787, Average Loss: 3.523, avg. samples / sec: 66061.78
Iteration:   4800, Loss function: 3.604, Average Loss: 3.528, avg. samples / sec: 66167.49
Iteration:   4800, Loss function: 2.844, Average Loss: 3.559, avg. samples / sec: 66122.26
Iteration:   4800, Loss function: 2.010, Average Loss: 3.530, avg. samples / sec: 65837.73
Iteration:   4800, Loss function: 3.847, Average Loss: 3.547, avg. samples / sec: 65926.52
Iteration:   4800, Loss function: 3.304, Average Loss: 3.546, avg. samples / sec: 66050.89
Iteration:   4800, Loss function: 2.991, Average Loss: 3.540, avg. samples / sec: 65990.20
Iteration:   4800, Loss function: 3.408, Average Loss: 3.537, avg. samples / sec: 65949.94
Iteration:   4800, Loss function: 2.836, Average Loss: 3.525, avg. samples / sec: 65932.50
Iteration:   4800, Loss function: 3.497, Average Loss: 3.530, avg. samples / sec: 65978.59
Iteration:   4800, Loss function: 3.054, Average Loss: 3.509, avg. samples / sec: 66050.79
Iteration:   4800, Loss function: 3.446, Average Loss: 3.515, avg. samples / sec: 65849.17
Iteration:   4800, Loss function: 3.190, Average Loss: 3.517, avg. samples / sec: 65846.98
Iteration:   4800, Loss function: 3.065, Average Loss: 3.510, avg. samples / sec: 65887.93
Iteration:   4800, Loss function: 2.482, Average Loss: 3.512, avg. samples / sec: 65959.50
Iteration:   4800, Loss function: 2.565, Average Loss: 3.527, avg. samples / sec: 65913.54
Iteration:   4800, Loss function: 3.461, Average Loss: 3.536, avg. samples / sec: 65867.20
Iteration:   4800, Loss function: 2.290, Average Loss: 3.523, avg. samples / sec: 65751.04
:::MLL 1558652004.280 epoch_stop: {"value": null, "metadata": {"epoch_num": 69, "file": "train.py", "lineno": 819}}
:::MLL 1558652004.281 epoch_start: {"value": null, "metadata": {"epoch_num": 70, "file": "train.py", "lineno": 673}}
Iteration:   4820, Loss function: 3.712, Average Loss: 3.514, avg. samples / sec: 65803.05
Iteration:   4820, Loss function: 3.136, Average Loss: 3.503, avg. samples / sec: 65918.50
Iteration:   4820, Loss function: 4.486, Average Loss: 3.518, avg. samples / sec: 65699.82
Iteration:   4820, Loss function: 3.315, Average Loss: 3.513, avg. samples / sec: 65697.83
Iteration:   4820, Loss function: 3.627, Average Loss: 3.531, avg. samples / sec: 65706.90
Iteration:   4820, Loss function: 2.945, Average Loss: 3.530, avg. samples / sec: 65973.24
Iteration:   4820, Loss function: 3.627, Average Loss: 3.513, avg. samples / sec: 65878.81
Iteration:   4820, Loss function: 3.549, Average Loss: 3.532, avg. samples / sec: 65721.39
Iteration:   4820, Loss function: 2.788, Average Loss: 3.522, avg. samples / sec: 65788.06
Iteration:   4820, Loss function: 3.397, Average Loss: 3.529, avg. samples / sec: 65712.08
Iteration:   4820, Loss function: 3.389, Average Loss: 3.544, avg. samples / sec: 65778.20
Iteration:   4820, Loss function: 4.237, Average Loss: 3.508, avg. samples / sec: 65828.35
Iteration:   4820, Loss function: 4.633, Average Loss: 3.526, avg. samples / sec: 65690.36
Iteration:   4820, Loss function: 4.173, Average Loss: 3.517, avg. samples / sec: 65940.80
Iteration:   4820, Loss function: 2.218, Average Loss: 3.531, avg. samples / sec: 65760.58
Iteration:   4820, Loss function: 2.784, Average Loss: 3.502, avg. samples / sec: 65711.10
Iteration:   4820, Loss function: 3.432, Average Loss: 3.526, avg. samples / sec: 65792.45
Iteration:   4820, Loss function: 3.402, Average Loss: 3.513, avg. samples / sec: 65802.83
Iteration:   4820, Loss function: 2.981, Average Loss: 3.511, avg. samples / sec: 65803.82
Iteration:   4820, Loss function: 3.936, Average Loss: 3.512, avg. samples / sec: 65675.97
Iteration:   4820, Loss function: 2.799, Average Loss: 3.521, avg. samples / sec: 65720.29
Iteration:   4820, Loss function: 2.529, Average Loss: 3.524, avg. samples / sec: 65649.14
Iteration:   4820, Loss function: 3.633, Average Loss: 3.540, avg. samples / sec: 65639.94
Iteration:   4820, Loss function: 3.004, Average Loss: 3.553, avg. samples / sec: 65660.37
Iteration:   4820, Loss function: 2.913, Average Loss: 3.520, avg. samples / sec: 65679.28
Iteration:   4820, Loss function: 3.901, Average Loss: 3.556, avg. samples / sec: 65651.53
Iteration:   4820, Loss function: 2.824, Average Loss: 3.534, avg. samples / sec: 65655.41
Iteration:   4820, Loss function: 2.841, Average Loss: 3.518, avg. samples / sec: 65753.40
Iteration:   4820, Loss function: 3.339, Average Loss: 3.524, avg. samples / sec: 65607.48
Iteration:   4820, Loss function: 3.785, Average Loss: 3.536, avg. samples / sec: 65600.15
Iteration:   4840, Loss function: 2.683, Average Loss: 3.510, avg. samples / sec: 65776.18
Iteration:   4840, Loss function: 2.998, Average Loss: 3.519, avg. samples / sec: 65812.70
Iteration:   4840, Loss function: 3.657, Average Loss: 3.508, avg. samples / sec: 65870.19
Iteration:   4840, Loss function: 2.754, Average Loss: 3.519, avg. samples / sec: 65872.87
Iteration:   4840, Loss function: 3.081, Average Loss: 3.512, avg. samples / sec: 65778.94
Iteration:   4840, Loss function: 1.922, Average Loss: 3.513, avg. samples / sec: 65695.38
Iteration:   4840, Loss function: 2.812, Average Loss: 3.507, avg. samples / sec: 65810.15
Iteration:   4840, Loss function: 3.825, Average Loss: 3.504, avg. samples / sec: 65762.82
Iteration:   4840, Loss function: 2.634, Average Loss: 3.516, avg. samples / sec: 65845.20
Iteration:   4840, Loss function: 2.911, Average Loss: 3.509, avg. samples / sec: 65775.62
Iteration:   4840, Loss function: 2.913, Average Loss: 3.504, avg. samples / sec: 65676.86
Iteration:   4840, Loss function: 2.471, Average Loss: 3.521, avg. samples / sec: 65713.30
Iteration:   4840, Loss function: 2.690, Average Loss: 3.496, avg. samples / sec: 65629.24
Iteration:   4840, Loss function: 2.369, Average Loss: 3.529, avg. samples / sec: 65824.13
Iteration:   4840, Loss function: 3.610, Average Loss: 3.516, avg. samples / sec: 65813.31
Iteration:   4840, Loss function: 3.373, Average Loss: 3.535, avg. samples / sec: 65881.92
Iteration:   4840, Loss function: 2.977, Average Loss: 3.530, avg. samples / sec: 65613.56
Iteration:   4840, Loss function: 3.161, Average Loss: 3.527, avg. samples / sec: 65609.01
Iteration:   4840, Loss function: 2.424, Average Loss: 3.525, avg. samples / sec: 65683.35
Iteration:   4840, Loss function: 2.330, Average Loss: 3.540, avg. samples / sec: 65643.15
Iteration:   4840, Loss function: 4.117, Average Loss: 3.538, avg. samples / sec: 65748.47
Iteration:   4840, Loss function: 2.335, Average Loss: 3.512, avg. samples / sec: 65597.68
Iteration:   4840, Loss function: 3.513, Average Loss: 3.547, avg. samples / sec: 65748.96
Iteration:   4840, Loss function: 3.730, Average Loss: 3.501, avg. samples / sec: 65651.34
Iteration:   4840, Loss function: 3.659, Average Loss: 3.522, avg. samples / sec: 65704.02
Iteration:   4840, Loss function: 3.048, Average Loss: 3.555, avg. samples / sec: 65735.95
Iteration:   4840, Loss function: 4.213, Average Loss: 3.525, avg. samples / sec: 65661.53
Iteration:   4840, Loss function: 2.319, Average Loss: 3.517, avg. samples / sec: 65740.00
Iteration:   4840, Loss function: 4.151, Average Loss: 3.529, avg. samples / sec: 65529.36
Iteration:   4840, Loss function: 2.517, Average Loss: 3.522, avg. samples / sec: 65522.72
Iteration:   4860, Loss function: 3.254, Average Loss: 3.524, avg. samples / sec: 66227.66
Iteration:   4860, Loss function: 3.122, Average Loss: 3.510, avg. samples / sec: 66080.40
Iteration:   4860, Loss function: 2.551, Average Loss: 3.523, avg. samples / sec: 66297.04
Iteration:   4860, Loss function: 3.868, Average Loss: 3.509, avg. samples / sec: 65982.33
Iteration:   4860, Loss function: 4.394, Average Loss: 3.499, avg. samples / sec: 66174.82
Iteration:   4860, Loss function: 3.407, Average Loss: 3.508, avg. samples / sec: 66030.89
Iteration:   4860, Loss function: 2.735, Average Loss: 3.531, avg. samples / sec: 66151.71
Iteration:   4860, Loss function: 3.349, Average Loss: 3.512, avg. samples / sec: 66028.45
Iteration:   4860, Loss function: 2.667, Average Loss: 3.533, avg. samples / sec: 66142.12
Iteration:   4860, Loss function: 2.835, Average Loss: 3.508, avg. samples / sec: 66030.03
Iteration:   4860, Loss function: 2.902, Average Loss: 3.521, avg. samples / sec: 66109.04
Iteration:   4860, Loss function: 3.472, Average Loss: 3.492, avg. samples / sec: 66046.27
Iteration:   4860, Loss function: 3.848, Average Loss: 3.517, avg. samples / sec: 66194.59
Iteration:   4860, Loss function: 3.132, Average Loss: 3.507, avg. samples / sec: 66011.90
Iteration:   4860, Loss function: 3.398, Average Loss: 3.527, avg. samples / sec: 66059.34
Iteration:   4860, Loss function: 3.386, Average Loss: 3.503, avg. samples / sec: 66010.51
Iteration:   4860, Loss function: 2.869, Average Loss: 3.502, avg. samples / sec: 65980.87
Iteration:   4860, Loss function: 4.554, Average Loss: 3.518, avg. samples / sec: 66114.91
Iteration:   4860, Loss function: 2.848, Average Loss: 3.516, avg. samples / sec: 66109.45
Iteration:   4860, Loss function: 4.325, Average Loss: 3.510, avg. samples / sec: 65945.46
Iteration:   4860, Loss function: 3.058, Average Loss: 3.501, avg. samples / sec: 65907.80
Iteration:   4860, Loss function: 3.267, Average Loss: 3.517, avg. samples / sec: 66185.23
Iteration:   4860, Loss function: 3.124, Average Loss: 3.507, avg. samples / sec: 66054.04
Iteration:   4860, Loss function: 2.289, Average Loss: 3.540, avg. samples / sec: 66040.86
Iteration:   4860, Loss function: 1.965, Average Loss: 3.527, avg. samples / sec: 65998.12
Iteration:   4860, Loss function: 2.932, Average Loss: 3.509, avg. samples / sec: 65901.39
Iteration:   4860, Loss function: 4.604, Average Loss: 3.514, avg. samples / sec: 65963.27
Iteration:   4860, Loss function: 4.280, Average Loss: 3.519, avg. samples / sec: 66005.53
Iteration:   4860, Loss function: 4.122, Average Loss: 3.550, avg. samples / sec: 66008.90
Iteration:   4860, Loss function: 3.684, Average Loss: 3.514, avg. samples / sec: 65913.20
Iteration:   4880, Loss function: 3.041, Average Loss: 3.518, avg. samples / sec: 66066.89
Iteration:   4880, Loss function: 3.554, Average Loss: 3.509, avg. samples / sec: 66229.53
Iteration:   4880, Loss function: 2.838, Average Loss: 3.501, avg. samples / sec: 66169.07
Iteration:   4880, Loss function: 2.625, Average Loss: 3.505, avg. samples / sec: 66033.71
Iteration:   4880, Loss function: 3.825, Average Loss: 3.513, avg. samples / sec: 66081.80
Iteration:   4880, Loss function: 4.249, Average Loss: 3.514, avg. samples / sec: 66108.92
Iteration:   4880, Loss function: 4.244, Average Loss: 3.517, avg. samples / sec: 66156.31
Iteration:   4880, Loss function: 3.066, Average Loss: 3.510, avg. samples / sec: 65920.44
Iteration:   4880, Loss function: 2.404, Average Loss: 3.492, avg. samples / sec: 66008.19
Iteration:   4880, Loss function: 3.917, Average Loss: 3.524, avg. samples / sec: 66044.85
Iteration:   4880, Loss function: 3.030, Average Loss: 3.526, avg. samples / sec: 66003.37
Iteration:   4880, Loss function: 2.680, Average Loss: 3.499, avg. samples / sec: 66032.22
Iteration:   4880, Loss function: 4.193, Average Loss: 3.509, avg. samples / sec: 66024.68
Iteration:   4880, Loss function: 3.144, Average Loss: 3.507, avg. samples / sec: 66046.15
Iteration:   4880, Loss function: 3.439, Average Loss: 3.519, avg. samples / sec: 65916.25
Iteration:   4880, Loss function: 3.096, Average Loss: 3.515, avg. samples / sec: 66016.54
Iteration:   4880, Loss function: 3.879, Average Loss: 3.512, avg. samples / sec: 65939.72
Iteration:   4880, Loss function: 3.749, Average Loss: 3.502, avg. samples / sec: 66029.81
Iteration:   4880, Loss function: 2.793, Average Loss: 3.492, avg. samples / sec: 65970.65
Iteration:   4880, Loss function: 3.294, Average Loss: 3.512, avg. samples / sec: 66021.43
Iteration:   4880, Loss function: 3.194, Average Loss: 3.537, avg. samples / sec: 66035.35
Iteration:   4880, Loss function: 4.206, Average Loss: 3.506, avg. samples / sec: 66045.00
Iteration:   4880, Loss function: 3.162, Average Loss: 3.525, avg. samples / sec: 65920.14
Iteration:   4880, Loss function: 3.323, Average Loss: 3.520, avg. samples / sec: 66016.02
Iteration:   4880, Loss function: 3.841, Average Loss: 3.508, avg. samples / sec: 65925.38
Iteration:   4880, Loss function: 3.384, Average Loss: 3.504, avg. samples / sec: 65979.02
Iteration:   4880, Loss function: 3.719, Average Loss: 3.521, avg. samples / sec: 65913.66
Iteration:   4880, Loss function: 3.473, Average Loss: 3.512, avg. samples / sec: 66054.63
Iteration:   4880, Loss function: 3.210, Average Loss: 3.545, avg. samples / sec: 66014.69
Iteration:   4880, Loss function: 3.302, Average Loss: 3.504, avg. samples / sec: 65765.37
:::MLL 1558652006.067 epoch_stop: {"value": null, "metadata": {"epoch_num": 70, "file": "train.py", "lineno": 819}}
:::MLL 1558652006.067 epoch_start: {"value": null, "metadata": {"epoch_num": 71, "file": "train.py", "lineno": 673}}
Iteration:   4900, Loss function: 3.584, Average Loss: 3.497, avg. samples / sec: 65509.71
Iteration:   4900, Loss function: 4.471, Average Loss: 3.499, avg. samples / sec: 65615.03
Iteration:   4900, Loss function: 3.072, Average Loss: 3.509, avg. samples / sec: 65429.63
Iteration:   4900, Loss function: 3.992, Average Loss: 3.504, avg. samples / sec: 65655.96
Iteration:   4900, Loss function: 4.264, Average Loss: 3.502, avg. samples / sec: 65513.09
Iteration:   4900, Loss function: 2.689, Average Loss: 3.514, avg. samples / sec: 65512.82
Iteration:   4900, Loss function: 3.295, Average Loss: 3.518, avg. samples / sec: 65541.79
Iteration:   4900, Loss function: 2.921, Average Loss: 3.506, avg. samples / sec: 65521.80
Iteration:   4900, Loss function: 2.774, Average Loss: 3.506, avg. samples / sec: 65504.84
Iteration:   4900, Loss function: 3.296, Average Loss: 3.506, avg. samples / sec: 65368.69
Iteration:   4900, Loss function: 4.598, Average Loss: 3.510, avg. samples / sec: 65421.67
Iteration:   4900, Loss function: 4.086, Average Loss: 3.514, avg. samples / sec: 65537.95
Iteration:   4900, Loss function: 3.399, Average Loss: 3.517, avg. samples / sec: 65553.96
Iteration:   4900, Loss function: 3.209, Average Loss: 3.533, avg. samples / sec: 65518.08
Iteration:   4900, Loss function: 3.611, Average Loss: 3.502, avg. samples / sec: 65584.25
Iteration:   4900, Loss function: 4.057, Average Loss: 3.519, avg. samples / sec: 65452.75
Iteration:   4900, Loss function: 4.920, Average Loss: 3.509, avg. samples / sec: 65414.75
Iteration:   4900, Loss function: 2.924, Average Loss: 3.512, avg. samples / sec: 65477.99
Iteration:   4900, Loss function: 2.984, Average Loss: 3.505, avg. samples / sec: 65523.20
Iteration:   4900, Loss function: 3.204, Average Loss: 3.507, avg. samples / sec: 65479.82
Iteration:   4900, Loss function: 3.141, Average Loss: 3.501, avg. samples / sec: 65504.29
Iteration:   4900, Loss function: 3.441, Average Loss: 3.502, avg. samples / sec: 65654.09
Iteration:   4900, Loss function: 2.586, Average Loss: 3.540, avg. samples / sec: 65567.86
Iteration:   4900, Loss function: 2.888, Average Loss: 3.507, avg. samples / sec: 65375.27
Iteration:   4900, Loss function: 4.111, Average Loss: 3.520, avg. samples / sec: 65523.08
Iteration:   4900, Loss function: 3.645, Average Loss: 3.516, avg. samples / sec: 65491.47
Iteration:   4900, Loss function: 3.714, Average Loss: 3.507, avg. samples / sec: 65507.46
Iteration:   4900, Loss function: 3.259, Average Loss: 3.515, avg. samples / sec: 65404.33
Iteration:   4900, Loss function: 2.770, Average Loss: 3.486, avg. samples / sec: 65370.20
Iteration:   4900, Loss function: 5.117, Average Loss: 3.490, avg. samples / sec: 65282.90
Iteration:   4920, Loss function: 3.654, Average Loss: 3.494, avg. samples / sec: 66013.36
Iteration:   4920, Loss function: 4.296, Average Loss: 3.499, avg. samples / sec: 66079.81
Iteration:   4920, Loss function: 3.383, Average Loss: 3.493, avg. samples / sec: 66128.80
Iteration:   4920, Loss function: 3.386, Average Loss: 3.505, avg. samples / sec: 65920.97
Iteration:   4920, Loss function: 3.463, Average Loss: 3.511, avg. samples / sec: 66028.88
Iteration:   4920, Loss function: 2.835, Average Loss: 3.513, avg. samples / sec: 65937.93
Iteration:   4920, Loss function: 3.308, Average Loss: 3.496, avg. samples / sec: 65874.41
Iteration:   4920, Loss function: 3.351, Average Loss: 3.500, avg. samples / sec: 65827.67
Iteration:   4920, Loss function: 3.782, Average Loss: 3.504, avg. samples / sec: 65995.33
Iteration:   4920, Loss function: 3.014, Average Loss: 3.504, avg. samples / sec: 66063.49
Iteration:   4920, Loss function: 4.386, Average Loss: 3.512, avg. samples / sec: 66018.58
Iteration:   4920, Loss function: 3.063, Average Loss: 3.516, avg. samples / sec: 65966.30
Iteration:   4920, Loss function: 3.562, Average Loss: 3.513, avg. samples / sec: 66068.04
Iteration:   4920, Loss function: 3.605, Average Loss: 3.512, avg. samples / sec: 65898.99
Iteration:   4920, Loss function: 5.228, Average Loss: 3.515, avg. samples / sec: 66046.24
Iteration:   4920, Loss function: 2.671, Average Loss: 3.493, avg. samples / sec: 65815.96
Iteration:   4920, Loss function: 3.487, Average Loss: 3.490, avg. samples / sec: 66116.61
Iteration:   4920, Loss function: 3.720, Average Loss: 3.511, avg. samples / sec: 65931.39
Iteration:   4920, Loss function: 3.415, Average Loss: 3.533, avg. samples / sec: 65997.68
Iteration:   4920, Loss function: 3.483, Average Loss: 3.503, avg. samples / sec: 66027.80
Iteration:   4920, Loss function: 3.048, Average Loss: 3.502, avg. samples / sec: 65921.65
Iteration:   4920, Loss function: 3.833, Average Loss: 3.527, avg. samples / sec: 65963.09
Iteration:   4920, Loss function: 3.133, Average Loss: 3.502, avg. samples / sec: 65886.79
Iteration:   4920, Loss function: 4.108, Average Loss: 3.508, avg. samples / sec: 65950.58
Iteration:   4920, Loss function: 3.351, Average Loss: 3.507, avg. samples / sec: 65935.12
Iteration:   4920, Loss function: 3.612, Average Loss: 3.497, avg. samples / sec: 65912.43
Iteration:   4920, Loss function: 3.188, Average Loss: 3.515, avg. samples / sec: 65930.34
Iteration:   4920, Loss function: 2.720, Average Loss: 3.485, avg. samples / sec: 66021.46
Iteration:   4920, Loss function: 2.963, Average Loss: 3.498, avg. samples / sec: 65878.26
Iteration:   4920, Loss function: 3.371, Average Loss: 3.500, avg. samples / sec: 65776.54
Iteration:   4940, Loss function: 3.841, Average Loss: 3.488, avg. samples / sec: 66220.19
Iteration:   4940, Loss function: 2.786, Average Loss: 3.505, avg. samples / sec: 66280.08
Iteration:   4940, Loss function: 3.518, Average Loss: 3.503, avg. samples / sec: 66084.55
Iteration:   4940, Loss function: 3.525, Average Loss: 3.492, avg. samples / sec: 66268.73
Iteration:   4940, Loss function: 4.216, Average Loss: 3.502, avg. samples / sec: 66157.08
Iteration:   4940, Loss function: 2.352, Average Loss: 3.489, avg. samples / sec: 66011.16
Iteration:   4940, Loss function: 4.104, Average Loss: 3.492, avg. samples / sec: 65953.67
Iteration:   4940, Loss function: 3.074, Average Loss: 3.497, avg. samples / sec: 66071.57
Iteration:   4940, Loss function: 3.237, Average Loss: 3.513, avg. samples / sec: 66098.10
Iteration:   4940, Loss function: 3.318, Average Loss: 3.508, avg. samples / sec: 66037.76
Iteration:   4940, Loss function: 3.423, Average Loss: 3.509, avg. samples / sec: 66065.07
Iteration:   4940, Loss function: 3.673, Average Loss: 3.492, avg. samples / sec: 66171.81
Iteration:   4940, Loss function: 2.527, Average Loss: 3.500, avg. samples / sec: 66062.71
Iteration:   4940, Loss function: 3.074, Average Loss: 3.493, avg. samples / sec: 66012.00
Iteration:   4940, Loss function: 2.087, Average Loss: 3.505, avg. samples / sec: 66089.17
Iteration:   4940, Loss function: 3.070, Average Loss: 3.513, avg. samples / sec: 66023.10
Iteration:   4940, Loss function: 3.392, Average Loss: 3.499, avg. samples / sec: 66054.20
Iteration:   4940, Loss function: 2.999, Average Loss: 3.507, avg. samples / sec: 66070.86
Iteration:   4940, Loss function: 3.234, Average Loss: 3.484, avg. samples / sec: 66130.45
Iteration:   4940, Loss function: 3.158, Average Loss: 3.505, avg. samples / sec: 66014.56
Iteration:   4940, Loss function: 3.422, Average Loss: 3.494, avg. samples / sec: 65889.78
Iteration:   4940, Loss function: 2.494, Average Loss: 3.499, avg. samples / sec: 65993.91
Iteration:   4940, Loss function: 4.251, Average Loss: 3.516, avg. samples / sec: 66106.47
Iteration:   4940, Loss function: 2.333, Average Loss: 3.508, avg. samples / sec: 65918.53
Iteration:   4940, Loss function: 3.200, Average Loss: 3.487, avg. samples / sec: 65986.65
Iteration:   4940, Loss function: 2.405, Average Loss: 3.528, avg. samples / sec: 65978.74
Iteration:   4940, Loss function: 3.935, Average Loss: 3.507, avg. samples / sec: 65909.96
Iteration:   4940, Loss function: 3.049, Average Loss: 3.507, avg. samples / sec: 65904.32
Iteration:   4940, Loss function: 4.354, Average Loss: 3.495, avg. samples / sec: 66097.73
Iteration:   4940, Loss function: 3.253, Average Loss: 3.525, avg. samples / sec: 65796.20
:::MLL 1558652007.698 eval_start: {"value": null, "metadata": {"epoch_num": 71, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.65 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=0.56s)
DONE (t=2.50s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23075
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39282
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23567
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24103
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34231
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36898
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53327
Current AP: 0.23075 AP goal: 0.23000
:::MLL 1558652011.433 eval_accuracy: {"value": 0.23075304767339608, "metadata": {"epoch_num": 71, "file": "train.py", "lineno": 389}}
:::MLL 1558652011.489 eval_stop: {"value": null, "metadata": {"epoch_num": 71, "file": "train.py", "lineno": 392}}
:::MLL 1558652011.496 block_stop: {"value": null, "metadata": {"first_epoch_num": 66, "file": "train.py", "lineno": 804}}
:::MLL 1558652012.139 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 10:50:27 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 10:50:27 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 10:50:27 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 10:50:27 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 10:50:27 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 10:50:27 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,191,nvidia,2019-05-23 10:50:27 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
ENDING TIMING RUN AT 2019-05-23 10:53:38 PM
RESULT,SINGLE_STAGE_DETECTOR,,190,nvidia,2019-05-23 10:50:28 PM
