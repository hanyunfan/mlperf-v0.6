Beginning trial 1 of 5
Gathering sys log on circe-n001
:::MLL 1558651158.032 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1558651158.032 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1558651158.033 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1558651158.033 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1558651158.033 submission_platform: {"value": "30xNVIDIA DGX-2H", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1558651158.034 submission_entry: {"value": "{'hardware': 'NVIDIA DGX-2H', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.1 LTS / NVIDIA DGX Server 4.0.4 4.0.5', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-2.0.7', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '30', 'cpu': '2x Intel(R) Xeon(R) Platinum 8174 CPU @ 3.10GHz', 'num_cores': '48', 'num_vcpus': '96', 'accelerator': 'Tesla V100-SXM3-32GB-H', 'num_accelerators': '8', 'sys_mem_size': '1510 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '2x 894.3G + 8x 3.5T', 'cpu_accel_interconnect': 'UPI', 'network_card': 'Mellanox Technologies MT27800 Family [ConnectX-5]', 'num_network_cards': '10', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1558651158.034 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1558651158.034 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
:::MLL 1558651159.362 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.366 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.377 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.399 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.428 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.409 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.382 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.396 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.418 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.392 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.408 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.384 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.428 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.391 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.391 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.440 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.419 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.403 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.425 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.390 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.428 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.427 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.418 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.422 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.422 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.421 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.444 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.457 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.451 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
:::MLL 1558651159.458 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node circe-n001
+ pids+=($!)
+ set +x
Launching on node circe-n002
+ pids+=($!)
+ set +x
Launching on node circe-n003
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n001
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
Launching on node circe-n004
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n002
+ srun --mem=0 -N 1 -n 1 -w circe-n001 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ srun --mem=0 -N 1 -n 1 -w circe-n002 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n003
Launching on node circe-n005
+ srun --mem=0 -N 1 -n 1 -w circe-n003 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n004
Launching on node circe-n006
+ pids+=($!)
+ set +x
Launching on node circe-n007
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n005
+ srun --mem=0 -N 1 -n 1 -w circe-n004 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n008
+ srun --mem=0 -N 1 -n 1 -w circe-n005 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n006
+ pids+=($!)
+ set +x
Launching on node circe-n009
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n007
+ srun --mem=0 -N 1 -n 1 -w circe-n006 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n010
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n008
+ srun --mem=0 -N 1 -n 1 -w circe-n007 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n011
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n009
+ srun --mem=0 -N 1 -n 1 -w circe-n008 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n012
+ srun --mem=0 -N 1 -n 1 -w circe-n009 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n010
+ pids+=($!)
+ set +x
Launching on node circe-n013
+ srun --mem=0 -N 1 -n 1 -w circe-n010 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n011
+ pids+=($!)
+ set +x
Launching on node circe-n014
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n012
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n013
+ pids+=($!)
+ set +x
Launching on node circe-n015
+ srun --mem=0 -N 1 -n 1 -w circe-n012 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n011 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n013 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n016
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n014
+ pids+=($!)
+ set +x
Launching on node circe-n017
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n015
+ srun --mem=0 -N 1 -n 1 -w circe-n014 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n018
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n016
+ srun --mem=0 -N 1 -n 1 -w circe-n015 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n019
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n017
+ srun --mem=0 -N 1 -n 1 -w circe-n016 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n020
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n018
+ srun --mem=0 -N 1 -n 1 -w circe-n017 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n021
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n019
+ srun --mem=0 -N 1 -n 1 -w circe-n018 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n022
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n020
+ srun --mem=0 -N 1 -n 1 -w circe-n019 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n021
+ pids+=($!)
+ set +x
Launching on node circe-n023
+ srun --mem=0 -N 1 -n 1 -w circe-n020 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
+ srun --mem=0 -N 1 -n 1 -w circe-n021 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
Launching on node circe-n024
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n022
+ pids+=($!)
+ set +x
Launching on node circe-n025
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n023
+ srun --mem=0 -N 1 -n 1 -w circe-n022 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n026
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n024
+ srun --mem=0 -N 1 -n 1 -w circe-n023 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
Launching on node circe-n027
+ srun --mem=0 -N 1 -n 1 -w circe-n024 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n025
+ pids+=($!)
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+ set +x
Launching on node circe-n028
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n026
+ pids+=($!)
+ set +x
Launching on node circe-n029
+ srun --mem=0 -N 1 -n 1 -w circe-n025 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n026 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n027
+ pids+=($!)
+ set +x
Launching on node circe-n030
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n028
+ srun --mem=0 -N 1 -n 1 -w circe-n027 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n029
+ srun --mem=0 -N 1 -n 1 -w circe-n028 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w circe-n030
+ srun --mem=0 -N 1 -n 1 -w circe-n029 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w circe-n030 docker exec -e DGXSYSTEM=DGX2_multi_even_30x8x7 -e 'MULTI_NODE= --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489' -e SLURM_JOB_ID=89794 -e SLURM_NTASKS_PER_NODE=8 cont_89794 ./run_and_time.sh
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489
Run vars: id 89794 gpus 8 mparams  --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=0 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=3 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
running benchmark
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=6 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=5 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=2 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=4 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=15 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ echo 'running benchmark'
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ export DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ DATASET_DIR=/data/coco2017
running benchmark
+ NUMEPOCHS=80
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ echo 'running benchmark'
+ NUMEPOCHS=80
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=11 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=7 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=14 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=13 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=9 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=20 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=8 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ DATASET_DIR=/data/coco2017
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ TORCH_MODEL_ZOO=/data/torchvision
+ export DATASET_DIR=/data/coco2017
+ echo 'running benchmark'
+ DATASET_DIR=/data/coco2017
+ export DATASET_DIR=/data/coco2017
running benchmark
+ export TORCH_MODEL_ZOO=/data/torchvision
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ TORCH_MODEL_ZOO=/data/torchvision
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=21 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=16 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=19 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=12 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=24 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=1 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ NUMEPOCHS=80
+ echo 'running benchmark'
running benchmark
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=28 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=18 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=10 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=22 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=23 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=17 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
+ export TORCH_MODEL_ZOO=/data/torchvision
running benchmark
+ TORCH_MODEL_ZOO=/data/torchvision
+ NUMEPOCHS=80
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=25 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=29 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=26 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2019-05-23 10:39:19 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 24 --nproc_per_node 8 --nnodes=30 --node_rank=27 --master_addr=10.0.1.1 --master_port=4489 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 7 --eval-batch-size 40 --warmup 1250 --bn-group 4 --lr 3.1e-3 --wd 2e-4 --input-batch-multiplier 10 --use-nvjpeg --use-roi-decode
:::MLL 1558651163.026 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.026 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.026 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.026 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.026 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.026 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.026 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.026 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.064 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.054 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.054 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.054 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.054 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.054 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.054 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.054 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.054 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.059 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.059 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.059 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.059 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.060 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.081 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.081 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.081 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.082 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.082 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.082 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.082 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.108 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.108 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.108 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.108 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.108 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.108 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.086 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.075 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.075 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.075 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.075 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.080 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651163.081 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.081 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.081 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.081 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.061 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.061 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.062 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.088 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.088 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.088 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.088 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.062 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.062 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.062 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.063 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.063 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.071 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.071 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.071 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.072 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.072 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.072 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.072 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651163.072 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651163.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.089 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.077 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.078 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.078 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.078 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.078 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.078 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.083 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.083 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.083 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.084 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
:::MLL 1558651163.084 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.084 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.085 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.085 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.112 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.112 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.112 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.112 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.113 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.113 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.113 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.113 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.090 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.087 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.091 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.092 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.093 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.093 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.093 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.094 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.094 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.094 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.094 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
:::MLL 1558651163.094 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.124 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.124 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.124 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.124 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.124 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.129 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.124 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.124 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.124 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.122 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.122 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.106 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.106 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.106 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.122 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.123 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.107 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.114 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.114 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.114 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.114 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.115 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.115 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.115 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.115 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.130 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
:::MLL 1558651163.177 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.177 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.178 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.178 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.178 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.178 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.178 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1558651163.178 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
BN group: 4
0 Using seed = 2326038631
2 Using seed = 2326038633
1 Using seed = 2326038632
:::MLL 1558651176.680 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
4 Using seed = 2326038635
3 Using seed = 2326038634
9 Using seed = 2326038640
8 Using seed = 2326038639
10 Using seed = 2326038641
14 Using seed = 2326038645
13 Using seed = 2326038644
15 Using seed = 2326038646
12 Using seed = 2326038643
11 Using seed = 2326038642
18 Using seed = 2326038649
17 Using seed = 2326038648
16 Using seed = 2326038647
23 Using seed = 2326038654
21 Using seed = 2326038652
22 Using seed = 2326038653
20 Using seed = 2326038651
19 Using seed = 2326038650
29 Using seed = 2326038660
30 Using seed = 2326038661
31 Using seed = 2326038662
25 Using seed = 2326038656
24 Using seed = 2326038655
26 Using seed = 2326038657
28 Using seed = 2326038659
27 Using seed = 2326038658
32 Using seed = 2326038663
33 Using seed = 2326038664
35 Using seed = 2326038666
34 Using seed = 2326038665
37 Using seed = 2326038668
39 Using seed = 2326038670
38 Using seed = 2326038669
36 Using seed = 2326038667
43 Using seed = 2326038674
41 Using seed = 2326038672
40 Using seed = 2326038671
47 Using seed = 2326038678
45 Using seed = 2326038676
46 Using seed = 2326038677
44 Using seed = 2326038675
42 Using seed = 2326038673
49 Using seed = 2326038680
51 Using seed = 2326038682
48 Using seed = 2326038679
50 Using seed = 2326038681
54 Using seed = 2326038685
53 Using seed = 2326038684
55 Using seed = 2326038686
52 Using seed = 2326038683
63 Using seed = 2326038694
61 Using seed = 2326038692
57 Using seed = 2326038688
62 Using seed = 2326038693
60 Using seed = 2326038691
59 Using seed = 2326038690
56 Using seed = 2326038687
58 Using seed = 2326038689
71 Using seed = 2326038702
67 Using seed = 2326038698
69 Using seed = 2326038700
65 Using seed = 2326038696
70 Using seed = 2326038701
66 Using seed = 2326038697
68 Using seed = 2326038699
64 Using seed = 2326038695
77 Using seed = 2326038708
79 Using seed = 2326038710
78 Using seed = 2326038709
72 Using seed = 2326038703
73 Using seed = 2326038704
74 Using seed = 2326038705
76 Using seed = 2326038707
75 Using seed = 2326038706
81 Using seed = 2326038712
80 Using seed = 2326038711
82 Using seed = 2326038713
87 Using seed = 2326038718
86 Using seed = 2326038717
85 Using seed = 2326038716
84 Using seed = 2326038715
83 Using seed = 2326038714
88 Using seed = 2326038719
89 Using seed = 2326038720
95 Using seed = 2326038726
93 Using seed = 2326038724
94 Using seed = 2326038725
90 Using seed = 2326038721
92 Using seed = 2326038723
91 Using seed = 2326038722
101 Using seed = 2326038732
103 Using seed = 2326038734
102 Using seed = 2326038733
97 Using seed = 2326038728
98 Using seed = 2326038729
99 Using seed = 2326038730
96 Using seed = 2326038727
100 Using seed = 2326038731
105 Using seed = 2326038736
107 Using seed = 2326038738
108 Using seed = 2326038739
111 Using seed = 2326038742
106 Using seed = 2326038737
109 Using seed = 2326038740
110 Using seed = 2326038741
104 Using seed = 2326038735
114 Using seed = 2326038745
115 Using seed = 2326038746
113 Using seed = 2326038744
112 Using seed = 2326038743
118 Using seed = 2326038749
117 Using seed = 2326038748
119 Using seed = 2326038750
116 Using seed = 2326038747
123 Using seed = 2326038754
120 Using seed = 2326038751
121 Using seed = 2326038752
122 Using seed = 2326038753
126 Using seed = 2326038757
127 Using seed = 2326038758
125 Using seed = 2326038756
124 Using seed = 2326038755
131 Using seed = 2326038762
135 Using seed = 2326038766
130 Using seed = 2326038761
128 Using seed = 2326038759
133 Using seed = 2326038764
129 Using seed = 2326038760
134 Using seed = 2326038765
132 Using seed = 2326038763
143 Using seed = 2326038774
142 Using seed = 2326038773
140 Using seed = 2326038771
137 Using seed = 2326038768
141 Using seed = 2326038772
136 Using seed = 2326038767
139 Using seed = 2326038770
138 Using seed = 2326038769
151 Using seed = 2326038782
147 Using seed = 2326038778
150 Using seed = 2326038781
144 Using seed = 2326038775
145 Using seed = 2326038776
146 Using seed = 2326038777
149 Using seed = 2326038780
148 Using seed = 2326038779
158 Using seed = 2326038789
153 Using seed = 2326038784
159 Using seed = 2326038790
156 Using seed = 2326038787
157 Using seed = 2326038788
152 Using seed = 2326038783
155 Using seed = 2326038786
154 Using seed = 2326038785
161 Using seed = 2326038792
163 Using seed = 2326038794
160 Using seed = 2326038791
162 Using seed = 2326038793
165 Using seed = 2326038796
167 Using seed = 2326038798
166 Using seed = 2326038797
164 Using seed = 2326038795
171 Using seed = 2326038802
170 Using seed = 2326038801
175 Using seed = 2326038806
168 Using seed = 2326038799
173 Using seed = 2326038804
174 Using seed = 2326038805
169 Using seed = 2326038800
172 Using seed = 2326038803
183 Using seed = 2326038814
181 Using seed = 2326038812
182 Using seed = 2326038813
176 Using seed = 2326038807
178 Using seed = 2326038809
180 Using seed = 2326038811
179 Using seed = 2326038810
177 Using seed = 2326038808
184 Using seed = 2326038815
186 Using seed = 2326038817
185 Using seed = 2326038816
187 Using seed = 2326038818
189 Using seed = 2326038820
190 Using seed = 2326038821
191 Using seed = 2326038822
188 Using seed = 2326038819
194 Using seed = 2326038825
198 Using seed = 2326038829
192 Using seed = 2326038823
193 Using seed = 2326038824
195 Using seed = 2326038826
197 Using seed = 2326038828
199 Using seed = 2326038830
196 Using seed = 2326038827
203 Using seed = 2326038834
204 Using seed = 2326038835
202 Using seed = 2326038833
206 Using seed = 2326038837
207 Using seed = 2326038838
201 Using seed = 2326038832
205 Using seed = 2326038836
200 Using seed = 2326038831
213 Using seed = 2326038844
215 Using seed = 2326038846
214 Using seed = 2326038845
208 Using seed = 2326038839
210 Using seed = 2326038841
211 Using seed = 2326038842
209 Using seed = 2326038840
212 Using seed = 2326038843
221 Using seed = 2326038852
223 Using seed = 2326038854
222 Using seed = 2326038853
220 Using seed = 2326038851
219 Using seed = 2326038850
217 Using seed = 2326038848
216 Using seed = 2326038847
218 Using seed = 2326038849
231 Using seed = 2326038862
229 Using seed = 2326038860
227 Using seed = 2326038858
225 Using seed = 2326038856
224 Using seed = 2326038855
226 Using seed = 2326038857
230 Using seed = 2326038861
228 Using seed = 2326038859
235 Using seed = 2326038866
234 Using seed = 2326038865
233 Using seed = 2326038864
239 Using seed = 2326038870
236 Using seed = 2326038867
238 Using seed = 2326038869
237 Using seed = 2326038868
232 Using seed = 2326038863
7 Using seed = 2326038638
6 Using seed = 2326038637
5 Using seed = 2326038636
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651178.727 model_bn_span: {"value": 28, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1558651178.727 global_batch_size: {"value": 1680, "metadata": {"file": "train.py", "lineno": 481}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651178.745 opt_base_learning_rate: {"value": 0.1625, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1558651178.745 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1558651178.746 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1558651178.746 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
epoch nbatch loss
:::MLL 1558651182.618 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1558651182.619 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.42s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.42s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
Done (t=0.43s)
creating index...
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.43s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.44s)
creating index...
Done (t=0.45s)
creating index...
Done (t=0.45s)
creating index...
time_check a: 1558651184.247214317
time_check a: 1558651184.287735701
time_check a: 1558651184.272921324
time_check a: 1558651184.269345284
time_check a: 1558651184.252971888
time_check a: 1558651184.283522367
time_check a: 1558651184.289362907
time_check a: 1558651184.259673119
time_check a: 1558651184.259183407
time_check a: 1558651184.276532173
time_check a: 1558651184.289003372
time_check a: 1558651184.280252695
time_check a: 1558651184.309650183
time_check a: 1558651184.274559021
time_check a: 1558651184.256354094
time_check a: 1558651184.269327402
time_check a: 1558651184.266067505
time_check a: 1558651184.292990685
time_check a: 1558651184.296794176
time_check a: 1558651184.291366339
time_check a: 1558651184.276627779
time_check a: 1558651184.283108711
time_check a: 1558651184.287828922
time_check a: 1558651184.316114902
time_check a: 1558651184.281347513
time_check a: 1558651184.294756413
time_check a: 1558651184.271934032
time_check a: 1558651184.289862394
time_check a: 1558651184.271082163
time_check a: 1558651184.275517941
time_check b: 1558651188.060862064
time_check b: 1558651188.076843739
time_check b: 1558651188.101099014
time_check b: 1558651188.109350920
time_check b: 1558651188.109173775
time_check b: 1558651188.095407724
time_check b: 1558651188.126211643
time_check b: 1558651188.125798702
time_check b: 1558651188.118119001
time_check b: 1558651188.160329103
time_check b: 1558651188.141031027
time_check b: 1558651188.146419525
time_check b: 1558651188.119755030
time_check b: 1558651188.118302107
time_check b: 1558651188.169365168
time_check b: 1558651188.130531788
time_check b: 1558651188.149669886
time_check b: 1558651188.149756193
time_check b: 1558651188.147271872
time_check b: 1558651188.181356907
time_check b: 1558651188.176662683
time_check b: 1558651188.188537121
time_check b: 1558651188.210507870
time_check b: 1558651188.216710091
time_check b: 1558651188.197437286
time_check b: 1558651188.214621782
time_check b: 1558651188.209435701
time_check b: 1558651188.259289265
time_check b: 1558651188.253583670
time_check b: 1558651188.310065746
:::MLL 1558651188.897 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1558651188.898 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 23.013, Average Loss: 0.023, avg. samples / sec: 176.11
Iteration:      0, Loss function: 24.168, Average Loss: 0.024, avg. samples / sec: 178.43
Iteration:      0, Loss function: 23.031, Average Loss: 0.023, avg. samples / sec: 176.81
Iteration:      0, Loss function: 23.250, Average Loss: 0.023, avg. samples / sec: 177.49
Iteration:      0, Loss function: 23.086, Average Loss: 0.023, avg. samples / sec: 179.37
Iteration:      0, Loss function: 24.054, Average Loss: 0.024, avg. samples / sec: 177.13
Iteration:      0, Loss function: 22.850, Average Loss: 0.023, avg. samples / sec: 177.44
Iteration:      0, Loss function: 23.384, Average Loss: 0.023, avg. samples / sec: 177.37
Iteration:      0, Loss function: 23.043, Average Loss: 0.023, avg. samples / sec: 173.21
Iteration:      0, Loss function: 23.060, Average Loss: 0.023, avg. samples / sec: 176.06
Iteration:      0, Loss function: 22.690, Average Loss: 0.023, avg. samples / sec: 176.15
Iteration:      0, Loss function: 22.929, Average Loss: 0.023, avg. samples / sec: 176.43
Iteration:      0, Loss function: 22.852, Average Loss: 0.023, avg. samples / sec: 177.73
Iteration:      0, Loss function: 22.985, Average Loss: 0.023, avg. samples / sec: 175.60
Iteration:      0, Loss function: 23.067, Average Loss: 0.023, avg. samples / sec: 177.94
Iteration:      0, Loss function: 24.057, Average Loss: 0.024, avg. samples / sec: 177.25
Iteration:      0, Loss function: 22.934, Average Loss: 0.023, avg. samples / sec: 176.95
Iteration:      0, Loss function: 23.448, Average Loss: 0.023, avg. samples / sec: 176.94
Iteration:      0, Loss function: 23.259, Average Loss: 0.023, avg. samples / sec: 174.30
Iteration:      0, Loss function: 23.207, Average Loss: 0.023, avg. samples / sec: 173.70
Iteration:      0, Loss function: 24.480, Average Loss: 0.024, avg. samples / sec: 175.86
Iteration:      0, Loss function: 23.033, Average Loss: 0.023, avg. samples / sec: 175.01
Iteration:      0, Loss function: 23.375, Average Loss: 0.023, avg. samples / sec: 176.60
Iteration:      0, Loss function: 22.818, Average Loss: 0.023, avg. samples / sec: 179.55
Iteration:      0, Loss function: 23.025, Average Loss: 0.023, avg. samples / sec: 177.62
Iteration:      0, Loss function: 22.990, Average Loss: 0.023, avg. samples / sec: 174.83
Iteration:      0, Loss function: 22.842, Average Loss: 0.023, avg. samples / sec: 176.38
Iteration:      0, Loss function: 23.286, Average Loss: 0.023, avg. samples / sec: 180.51
Iteration:      0, Loss function: 22.851, Average Loss: 0.023, avg. samples / sec: 179.07
Iteration:      0, Loss function: 23.467, Average Loss: 0.023, avg. samples / sec: 178.91
Iteration:     20, Loss function: 20.169, Average Loss: 0.446, avg. samples / sec: 42959.99
Iteration:     20, Loss function: 20.656, Average Loss: 0.447, avg. samples / sec: 42939.41
Iteration:     20, Loss function: 20.551, Average Loss: 0.447, avg. samples / sec: 42864.41
Iteration:     20, Loss function: 20.810, Average Loss: 0.449, avg. samples / sec: 43049.95
Iteration:     20, Loss function: 20.757, Average Loss: 0.445, avg. samples / sec: 42890.09
Iteration:     20, Loss function: 21.643, Average Loss: 0.448, avg. samples / sec: 42618.98
Iteration:     20, Loss function: 20.375, Average Loss: 0.449, avg. samples / sec: 43047.40
Iteration:     20, Loss function: 20.414, Average Loss: 0.450, avg. samples / sec: 42878.14
Iteration:     20, Loss function: 20.407, Average Loss: 0.445, avg. samples / sec: 42820.41
Iteration:     20, Loss function: 20.586, Average Loss: 0.449, avg. samples / sec: 42676.66
Iteration:     20, Loss function: 20.613, Average Loss: 0.452, avg. samples / sec: 42633.63
Iteration:     20, Loss function: 22.081, Average Loss: 0.448, avg. samples / sec: 42712.80
Iteration:     20, Loss function: 20.297, Average Loss: 0.448, avg. samples / sec: 42784.94
Iteration:     20, Loss function: 20.930, Average Loss: 0.447, avg. samples / sec: 42536.62
Iteration:     20, Loss function: 21.366, Average Loss: 0.445, avg. samples / sec: 43289.83
Iteration:     20, Loss function: 20.390, Average Loss: 0.447, avg. samples / sec: 42834.01
Iteration:     20, Loss function: 20.558, Average Loss: 0.447, avg. samples / sec: 42915.39
Iteration:     20, Loss function: 21.256, Average Loss: 0.450, avg. samples / sec: 42472.72
Iteration:     20, Loss function: 20.962, Average Loss: 0.454, avg. samples / sec: 43323.66
Iteration:     20, Loss function: 20.641, Average Loss: 0.449, avg. samples / sec: 42942.00
Iteration:     20, Loss function: 20.595, Average Loss: 0.447, avg. samples / sec: 42744.93
Iteration:     20, Loss function: 20.552, Average Loss: 0.449, avg. samples / sec: 42758.22
Iteration:     20, Loss function: 20.646, Average Loss: 0.447, avg. samples / sec: 42592.10
Iteration:     20, Loss function: 20.698, Average Loss: 0.445, avg. samples / sec: 41855.78
Iteration:     20, Loss function: 20.569, Average Loss: 0.447, avg. samples / sec: 42475.00
Iteration:     20, Loss function: 21.034, Average Loss: 0.448, avg. samples / sec: 42706.49
Iteration:     20, Loss function: 20.603, Average Loss: 0.447, avg. samples / sec: 42610.27
Iteration:     20, Loss function: 22.798, Average Loss: 0.450, avg. samples / sec: 43130.82
Iteration:     20, Loss function: 20.454, Average Loss: 0.445, avg. samples / sec: 42566.44
Iteration:     20, Loss function: 20.388, Average Loss: 0.445, avg. samples / sec: 42635.68
Iteration:     40, Loss function: 19.115, Average Loss: 0.838, avg. samples / sec: 63079.44
Iteration:     40, Loss function: 19.322, Average Loss: 0.838, avg. samples / sec: 62487.39
Iteration:     40, Loss function: 19.492, Average Loss: 0.839, avg. samples / sec: 62945.61
Iteration:     40, Loss function: 19.914, Average Loss: 0.846, avg. samples / sec: 62716.69
Iteration:     40, Loss function: 19.308, Average Loss: 0.838, avg. samples / sec: 62540.43
Iteration:     40, Loss function: 19.012, Average Loss: 0.834, avg. samples / sec: 63514.66
Iteration:     40, Loss function: 18.584, Average Loss: 0.833, avg. samples / sec: 62513.03
Iteration:     40, Loss function: 19.427, Average Loss: 0.837, avg. samples / sec: 62981.84
Iteration:     40, Loss function: 18.755, Average Loss: 0.836, avg. samples / sec: 62943.67
Iteration:     40, Loss function: 18.783, Average Loss: 0.840, avg. samples / sec: 62677.64
Iteration:     40, Loss function: 18.842, Average Loss: 0.837, avg. samples / sec: 62948.20
Iteration:     40, Loss function: 19.590, Average Loss: 0.838, avg. samples / sec: 62718.09
Iteration:     40, Loss function: 19.005, Average Loss: 0.847, avg. samples / sec: 62820.41
Iteration:     40, Loss function: 18.970, Average Loss: 0.838, avg. samples / sec: 63020.03
Iteration:     40, Loss function: 18.973, Average Loss: 0.841, avg. samples / sec: 63026.07
Iteration:     40, Loss function: 20.981, Average Loss: 0.845, avg. samples / sec: 62361.99
Iteration:     40, Loss function: 18.896, Average Loss: 0.839, avg. samples / sec: 62291.04
Iteration:     40, Loss function: 18.911, Average Loss: 0.834, avg. samples / sec: 63431.30
Iteration:     40, Loss function: 19.494, Average Loss: 0.836, avg. samples / sec: 62256.15
Iteration:     40, Loss function: 19.090, Average Loss: 0.842, avg. samples / sec: 62367.48
Iteration:     40, Loss function: 19.047, Average Loss: 0.839, avg. samples / sec: 62584.57
Iteration:     40, Loss function: 19.637, Average Loss: 0.837, avg. samples / sec: 62529.03
Iteration:     40, Loss function: 18.610, Average Loss: 0.840, avg. samples / sec: 62747.91
Iteration:     40, Loss function: 19.099, Average Loss: 0.840, avg. samples / sec: 62406.42
Iteration:     40, Loss function: 18.872, Average Loss: 0.839, avg. samples / sec: 62555.17
Iteration:     40, Loss function: 19.143, Average Loss: 0.839, avg. samples / sec: 62161.79
Iteration:     40, Loss function: 19.882, Average Loss: 0.838, avg. samples / sec: 62173.36
Iteration:     40, Loss function: 19.085, Average Loss: 0.838, avg. samples / sec: 62307.67
Iteration:     40, Loss function: 19.412, Average Loss: 0.844, avg. samples / sec: 62443.89
Iteration:     40, Loss function: 20.111, Average Loss: 0.842, avg. samples / sec: 60582.04
Iteration:     60, Loss function: 16.802, Average Loss: 1.120, avg. samples / sec: 62798.86
Iteration:     60, Loss function: 12.618, Average Loss: 1.113, avg. samples / sec: 62609.01
Iteration:     60, Loss function: 13.171, Average Loss: 1.105, avg. samples / sec: 62784.37
Iteration:     60, Loss function: 13.440, Average Loss: 1.113, avg. samples / sec: 62700.87
Iteration:     60, Loss function: 14.117, Average Loss: 1.106, avg. samples / sec: 62686.51
Iteration:     60, Loss function: 14.571, Average Loss: 1.109, avg. samples / sec: 63040.90
Iteration:     60, Loss function: 12.909, Average Loss: 1.103, avg. samples / sec: 62796.20
Iteration:     60, Loss function: 13.091, Average Loss: 1.116, avg. samples / sec: 62746.77
Iteration:     60, Loss function: 12.858, Average Loss: 1.112, avg. samples / sec: 62752.41
Iteration:     60, Loss function: 14.629, Average Loss: 1.119, avg. samples / sec: 62900.60
Iteration:     60, Loss function: 13.982, Average Loss: 1.105, avg. samples / sec: 62659.73
Iteration:     60, Loss function: 13.721, Average Loss: 1.106, avg. samples / sec: 62598.97
Iteration:     60, Loss function: 13.082, Average Loss: 1.108, avg. samples / sec: 63030.97
Iteration:     60, Loss function: 11.842, Average Loss: 1.106, avg. samples / sec: 62640.23
Iteration:     60, Loss function: 11.678, Average Loss: 1.113, avg. samples / sec: 62712.23
Iteration:     60, Loss function: 15.238, Average Loss: 1.116, avg. samples / sec: 62816.05
Iteration:     60, Loss function: 14.198, Average Loss: 1.122, avg. samples / sec: 62529.00
Iteration:     60, Loss function: 12.216, Average Loss: 1.104, avg. samples / sec: 62714.91
Iteration:     60, Loss function: 16.423, Average Loss: 1.104, avg. samples / sec: 62781.32
Iteration:     60, Loss function: 13.159, Average Loss: 1.118, avg. samples / sec: 62478.72
Iteration:     60, Loss function: 12.770, Average Loss: 1.112, avg. samples / sec: 64877.27
Iteration:     60, Loss function: 14.570, Average Loss: 1.108, avg. samples / sec: 62458.83
Iteration:     60, Loss function: 15.214, Average Loss: 1.116, avg. samples / sec: 62666.66
Iteration:     60, Loss function: 12.050, Average Loss: 1.103, avg. samples / sec: 62388.85
Iteration:     60, Loss function: 11.583, Average Loss: 1.103, avg. samples / sec: 62635.02
Iteration:     60, Loss function: 13.311, Average Loss: 1.110, avg. samples / sec: 62778.05
Iteration:     60, Loss function: 14.449, Average Loss: 1.106, avg. samples / sec: 62449.95
Iteration:     60, Loss function: 12.852, Average Loss: 1.110, avg. samples / sec: 62685.26
Iteration:     60, Loss function: 14.316, Average Loss: 1.113, avg. samples / sec: 62025.22
Iteration:     60, Loss function: 12.736, Average Loss: 1.113, avg. samples / sec: 61896.20
:::MLL 1558651191.696 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1558651191.697 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 11.013, Average Loss: 1.307, avg. samples / sec: 62556.70
Iteration:     80, Loss function: 9.543, Average Loss: 1.305, avg. samples / sec: 62447.43
Iteration:     80, Loss function: 9.966, Average Loss: 1.304, avg. samples / sec: 62493.81
Iteration:     80, Loss function: 11.172, Average Loss: 1.327, avg. samples / sec: 62405.98
Iteration:     80, Loss function: 10.418, Average Loss: 1.308, avg. samples / sec: 62451.22
Iteration:     80, Loss function: 10.370, Average Loss: 1.313, avg. samples / sec: 63030.80
Iteration:     80, Loss function: 10.020, Average Loss: 1.311, avg. samples / sec: 62650.11
Iteration:     80, Loss function: 10.145, Average Loss: 1.306, avg. samples / sec: 62685.42
Iteration:     80, Loss function: 9.970, Average Loss: 1.311, avg. samples / sec: 62573.95
Iteration:     80, Loss function: 10.947, Average Loss: 1.323, avg. samples / sec: 62449.87
Iteration:     80, Loss function: 10.551, Average Loss: 1.310, avg. samples / sec: 62500.19
Iteration:     80, Loss function: 10.004, Average Loss: 1.308, avg. samples / sec: 62901.75
Iteration:     80, Loss function: 10.112, Average Loss: 1.304, avg. samples / sec: 62472.73
Iteration:     80, Loss function: 10.451, Average Loss: 1.309, avg. samples / sec: 62498.25
Iteration:     80, Loss function: 9.150, Average Loss: 1.317, avg. samples / sec: 62586.46
Iteration:     80, Loss function: 9.962, Average Loss: 1.307, avg. samples / sec: 62673.41
Iteration:     80, Loss function: 10.473, Average Loss: 1.318, avg. samples / sec: 62501.96
Iteration:     80, Loss function: 10.661, Average Loss: 1.316, avg. samples / sec: 63149.71
Iteration:     80, Loss function: 10.232, Average Loss: 1.306, avg. samples / sec: 62438.91
Iteration:     80, Loss function: 10.935, Average Loss: 1.322, avg. samples / sec: 62305.66
Iteration:     80, Loss function: 10.368, Average Loss: 1.313, avg. samples / sec: 62316.38
Iteration:     80, Loss function: 10.700, Average Loss: 1.315, avg. samples / sec: 62999.92
Iteration:     80, Loss function: 9.761, Average Loss: 1.312, avg. samples / sec: 62225.14
Iteration:     80, Loss function: 10.587, Average Loss: 1.316, avg. samples / sec: 62298.39
Iteration:     80, Loss function: 10.217, Average Loss: 1.317, avg. samples / sec: 62354.87
Iteration:     80, Loss function: 10.610, Average Loss: 1.305, avg. samples / sec: 62475.81
Iteration:     80, Loss function: 11.084, Average Loss: 1.316, avg. samples / sec: 62361.44
Iteration:     80, Loss function: 11.590, Average Loss: 1.321, avg. samples / sec: 62100.24
Iteration:     80, Loss function: 10.356, Average Loss: 1.330, avg. samples / sec: 62132.52
Iteration:     80, Loss function: 10.277, Average Loss: 1.308, avg. samples / sec: 62055.59
Iteration:    100, Loss function: 9.485, Average Loss: 1.484, avg. samples / sec: 64767.22
Iteration:    100, Loss function: 9.786, Average Loss: 1.477, avg. samples / sec: 64513.07
Iteration:    100, Loss function: 9.705, Average Loss: 1.480, avg. samples / sec: 64494.21
Iteration:    100, Loss function: 10.222, Average Loss: 1.488, avg. samples / sec: 64446.90
Iteration:    100, Loss function: 9.855, Average Loss: 1.477, avg. samples / sec: 64409.05
Iteration:    100, Loss function: 8.918, Average Loss: 1.481, avg. samples / sec: 64565.18
Iteration:    100, Loss function: 9.272, Average Loss: 1.487, avg. samples / sec: 64650.07
Iteration:    100, Loss function: 9.432, Average Loss: 1.486, avg. samples / sec: 64574.11
Iteration:    100, Loss function: 9.588, Average Loss: 1.477, avg. samples / sec: 64366.40
Iteration:    100, Loss function: 10.101, Average Loss: 1.493, avg. samples / sec: 64785.92
Iteration:    100, Loss function: 9.572, Average Loss: 1.473, avg. samples / sec: 64334.49
Iteration:    100, Loss function: 10.102, Average Loss: 1.488, avg. samples / sec: 64583.85
Iteration:    100, Loss function: 10.036, Average Loss: 1.477, avg. samples / sec: 64610.11
Iteration:    100, Loss function: 9.347, Average Loss: 1.494, avg. samples / sec: 64470.96
Iteration:    100, Loss function: 9.239, Average Loss: 1.481, avg. samples / sec: 64392.69
Iteration:    100, Loss function: 9.454, Average Loss: 1.481, avg. samples / sec: 64457.22
Iteration:    100, Loss function: 10.101, Average Loss: 1.484, avg. samples / sec: 64307.86
Iteration:    100, Loss function: 9.560, Average Loss: 1.501, avg. samples / sec: 64803.38
Iteration:    100, Loss function: 8.441, Average Loss: 1.471, avg. samples / sec: 64261.73
Iteration:    100, Loss function: 10.455, Average Loss: 1.483, avg. samples / sec: 64447.87
Iteration:    100, Loss function: 8.936, Average Loss: 1.475, avg. samples / sec: 64238.21
Iteration:    100, Loss function: 10.313, Average Loss: 1.488, avg. samples / sec: 64359.14
Iteration:    100, Loss function: 9.902, Average Loss: 1.487, avg. samples / sec: 64372.95
Iteration:    100, Loss function: 9.667, Average Loss: 1.473, avg. samples / sec: 64299.41
Iteration:    100, Loss function: 9.778, Average Loss: 1.493, avg. samples / sec: 64207.48
Iteration:    100, Loss function: 9.861, Average Loss: 1.492, avg. samples / sec: 64267.80
Iteration:    100, Loss function: 9.180, Average Loss: 1.487, avg. samples / sec: 64261.44
Iteration:    100, Loss function: 9.905, Average Loss: 1.479, avg. samples / sec: 64190.37
Iteration:    100, Loss function: 9.812, Average Loss: 1.480, avg. samples / sec: 64032.76
Iteration:    100, Loss function: 9.874, Average Loss: 1.477, avg. samples / sec: 64426.34
Iteration:    120, Loss function: 9.709, Average Loss: 1.637, avg. samples / sec: 65734.60
Iteration:    120, Loss function: 9.524, Average Loss: 1.646, avg. samples / sec: 65920.84
Iteration:    120, Loss function: 8.453, Average Loss: 1.625, avg. samples / sec: 65869.91
Iteration:    120, Loss function: 10.239, Average Loss: 1.633, avg. samples / sec: 65791.87
Iteration:    120, Loss function: 8.465, Average Loss: 1.640, avg. samples / sec: 65740.58
Iteration:    120, Loss function: 9.339, Average Loss: 1.647, avg. samples / sec: 65722.13
Iteration:    120, Loss function: 9.359, Average Loss: 1.624, avg. samples / sec: 65863.20
Iteration:    120, Loss function: 9.249, Average Loss: 1.630, avg. samples / sec: 66257.64
Iteration:    120, Loss function: 9.136, Average Loss: 1.632, avg. samples / sec: 65623.00
Iteration:    120, Loss function: 8.860, Average Loss: 1.643, avg. samples / sec: 65632.32
Iteration:    120, Loss function: 8.724, Average Loss: 1.639, avg. samples / sec: 65731.81
Iteration:    120, Loss function: 9.171, Average Loss: 1.630, avg. samples / sec: 65459.47
Iteration:    120, Loss function: 8.779, Average Loss: 1.632, avg. samples / sec: 65614.81
Iteration:    120, Loss function: 9.307, Average Loss: 1.643, avg. samples / sec: 65733.93
Iteration:    120, Loss function: 9.444, Average Loss: 1.626, avg. samples / sec: 65654.43
Iteration:    120, Loss function: 8.609, Average Loss: 1.624, avg. samples / sec: 65545.72
Iteration:    120, Loss function: 9.508, Average Loss: 1.633, avg. samples / sec: 65889.32
Iteration:    120, Loss function: 8.912, Average Loss: 1.631, avg. samples / sec: 65614.36
Iteration:    120, Loss function: 9.118, Average Loss: 1.653, avg. samples / sec: 65623.00
Iteration:    120, Loss function: 11.426, Average Loss: 1.647, avg. samples / sec: 65567.50
Iteration:    120, Loss function: 7.702, Average Loss: 1.641, avg. samples / sec: 65783.85
Iteration:    120, Loss function: 8.482, Average Loss: 1.634, avg. samples / sec: 65634.68
Iteration:    120, Loss function: 8.902, Average Loss: 1.629, avg. samples / sec: 65572.93
Iteration:    120, Loss function: 9.314, Average Loss: 1.631, avg. samples / sec: 65934.48
Iteration:    120, Loss function: 8.881, Average Loss: 1.644, avg. samples / sec: 65670.77
Iteration:    120, Loss function: 9.312, Average Loss: 1.637, avg. samples / sec: 65400.30
Iteration:    120, Loss function: 9.538, Average Loss: 1.635, avg. samples / sec: 65250.29
Iteration:    120, Loss function: 9.690, Average Loss: 1.649, avg. samples / sec: 65491.32
Iteration:    120, Loss function: 9.089, Average Loss: 1.637, avg. samples / sec: 65372.45
Iteration:    120, Loss function: 10.181, Average Loss: 1.628, avg. samples / sec: 65310.22
:::MLL 1558651193.513 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1558651193.514 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 9.449, Average Loss: 1.768, avg. samples / sec: 65053.75
Iteration:    140, Loss function: 9.166, Average Loss: 1.787, avg. samples / sec: 65295.79
Iteration:    140, Loss function: 8.719, Average Loss: 1.783, avg. samples / sec: 65057.21
Iteration:    140, Loss function: 7.900, Average Loss: 1.778, avg. samples / sec: 65134.54
Iteration:    140, Loss function: 8.672, Average Loss: 1.780, avg. samples / sec: 65312.70
Iteration:    140, Loss function: 9.081, Average Loss: 1.776, avg. samples / sec: 65073.37
Iteration:    140, Loss function: 9.117, Average Loss: 1.781, avg. samples / sec: 64954.27
Iteration:    140, Loss function: 8.012, Average Loss: 1.805, avg. samples / sec: 65204.52
Iteration:    140, Loss function: 7.896, Average Loss: 1.778, avg. samples / sec: 65151.22
Iteration:    140, Loss function: 8.667, Average Loss: 1.793, avg. samples / sec: 64979.82
Iteration:    140, Loss function: 8.367, Average Loss: 1.789, avg. samples / sec: 65026.41
Iteration:    140, Loss function: 8.910, Average Loss: 1.780, avg. samples / sec: 65002.50
Iteration:    140, Loss function: 10.093, Average Loss: 1.769, avg. samples / sec: 65148.03
Iteration:    140, Loss function: 8.831, Average Loss: 1.790, avg. samples / sec: 65093.60
Iteration:    140, Loss function: 8.748, Average Loss: 1.786, avg. samples / sec: 65171.86
Iteration:    140, Loss function: 8.612, Average Loss: 1.782, avg. samples / sec: 65242.98
Iteration:    140, Loss function: 9.917, Average Loss: 1.778, avg. samples / sec: 65075.95
Iteration:    140, Loss function: 9.015, Average Loss: 1.767, avg. samples / sec: 64971.61
Iteration:    140, Loss function: 8.480, Average Loss: 1.791, avg. samples / sec: 65262.71
Iteration:    140, Loss function: 8.369, Average Loss: 1.776, avg. samples / sec: 65165.63
Iteration:    140, Loss function: 9.037, Average Loss: 1.778, avg. samples / sec: 65385.34
Iteration:    140, Loss function: 8.760, Average Loss: 1.770, avg. samples / sec: 65104.03
Iteration:    140, Loss function: 9.005, Average Loss: 1.779, avg. samples / sec: 65339.26
Iteration:    140, Loss function: 9.284, Average Loss: 1.790, avg. samples / sec: 65090.77
Iteration:    140, Loss function: 8.897, Average Loss: 1.792, avg. samples / sec: 65035.74
Iteration:    140, Loss function: 8.769, Average Loss: 1.776, avg. samples / sec: 64995.97
Iteration:    140, Loss function: 9.273, Average Loss: 1.779, avg. samples / sec: 64946.13
Iteration:    140, Loss function: 8.932, Average Loss: 1.779, avg. samples / sec: 64909.93
Iteration:    140, Loss function: 8.409, Average Loss: 1.785, avg. samples / sec: 64843.39
Iteration:    140, Loss function: 8.967, Average Loss: 1.780, avg. samples / sec: 64853.36
Iteration:    160, Loss function: 8.117, Average Loss: 1.918, avg. samples / sec: 65823.27
Iteration:    160, Loss function: 8.864, Average Loss: 1.908, avg. samples / sec: 65737.88
Iteration:    160, Loss function: 7.770, Average Loss: 1.906, avg. samples / sec: 65775.81
Iteration:    160, Loss function: 8.545, Average Loss: 1.917, avg. samples / sec: 65774.40
Iteration:    160, Loss function: 7.892, Average Loss: 1.927, avg. samples / sec: 65837.94
Iteration:    160, Loss function: 9.365, Average Loss: 1.921, avg. samples / sec: 66058.41
Iteration:    160, Loss function: 8.282, Average Loss: 1.924, avg. samples / sec: 65703.77
Iteration:    160, Loss function: 8.171, Average Loss: 1.943, avg. samples / sec: 65680.62
Iteration:    160, Loss function: 8.456, Average Loss: 1.911, avg. samples / sec: 65765.37
Iteration:    160, Loss function: 7.579, Average Loss: 1.918, avg. samples / sec: 65728.07
Iteration:    160, Loss function: 8.821, Average Loss: 1.937, avg. samples / sec: 65681.73
Iteration:    160, Loss function: 8.422, Average Loss: 1.923, avg. samples / sec: 65700.71
Iteration:    160, Loss function: 9.006, Average Loss: 1.915, avg. samples / sec: 65895.26
Iteration:    160, Loss function: 8.429, Average Loss: 1.924, avg. samples / sec: 65685.64
Iteration:    160, Loss function: 8.141, Average Loss: 1.906, avg. samples / sec: 65685.34
Iteration:    160, Loss function: 8.667, Average Loss: 1.913, avg. samples / sec: 65691.12
Iteration:    160, Loss function: 8.966, Average Loss: 1.919, avg. samples / sec: 65893.38
Iteration:    160, Loss function: 8.272, Average Loss: 1.921, avg. samples / sec: 65901.39
Iteration:    160, Loss function: 7.657, Average Loss: 1.904, avg. samples / sec: 65692.13
Iteration:    160, Loss function: 8.669, Average Loss: 1.920, avg. samples / sec: 65539.81
Iteration:    160, Loss function: 9.028, Average Loss: 1.920, avg. samples / sec: 65571.74
Iteration:    160, Loss function: 9.130, Average Loss: 1.916, avg. samples / sec: 65607.24
Iteration:    160, Loss function: 8.380, Average Loss: 1.928, avg. samples / sec: 65718.73
Iteration:    160, Loss function: 8.269, Average Loss: 1.917, avg. samples / sec: 65570.91
Iteration:    160, Loss function: 8.509, Average Loss: 1.919, avg. samples / sec: 65550.69
Iteration:    160, Loss function: 8.353, Average Loss: 1.923, avg. samples / sec: 65591.24
Iteration:    160, Loss function: 8.942, Average Loss: 1.915, avg. samples / sec: 65543.41
Iteration:    160, Loss function: 8.528, Average Loss: 1.911, avg. samples / sec: 65730.53
Iteration:    160, Loss function: 8.922, Average Loss: 1.911, avg. samples / sec: 65447.01
Iteration:    160, Loss function: 8.712, Average Loss: 1.916, avg. samples / sec: 65547.89
Iteration:    180, Loss function: 9.087, Average Loss: 2.053, avg. samples / sec: 65619.03
Iteration:    180, Loss function: 9.650, Average Loss: 2.038, avg. samples / sec: 65375.54
Iteration:    180, Loss function: 7.323, Average Loss: 2.041, avg. samples / sec: 65548.25
Iteration:    180, Loss function: 7.837, Average Loss: 2.049, avg. samples / sec: 65554.57
Iteration:    180, Loss function: 8.238, Average Loss: 2.049, avg. samples / sec: 65536.76
Iteration:    180, Loss function: 9.172, Average Loss: 2.057, avg. samples / sec: 65483.50
Iteration:    180, Loss function: 8.203, Average Loss: 2.035, avg. samples / sec: 65497.20
Iteration:    180, Loss function: 8.665, Average Loss: 2.050, avg. samples / sec: 65392.65
Iteration:    180, Loss function: 8.588, Average Loss: 2.051, avg. samples / sec: 65530.18
Iteration:    180, Loss function: 8.435, Average Loss: 2.053, avg. samples / sec: 65483.20
Iteration:    180, Loss function: 10.181, Average Loss: 2.056, avg. samples / sec: 65387.70
Iteration:    180, Loss function: 8.000, Average Loss: 2.047, avg. samples / sec: 65511.38
Iteration:    180, Loss function: 8.926, Average Loss: 2.046, avg. samples / sec: 65404.79
Iteration:    180, Loss function: 8.882, Average Loss: 2.041, avg. samples / sec: 65595.02
Iteration:    180, Loss function: 7.859, Average Loss: 2.041, avg. samples / sec: 65398.81
Iteration:    180, Loss function: 8.364, Average Loss: 2.052, avg. samples / sec: 65218.79
Iteration:    180, Loss function: 8.414, Average Loss: 2.057, avg. samples / sec: 65318.91
Iteration:    180, Loss function: 8.489, Average Loss: 2.057, avg. samples / sec: 65387.89
Iteration:    180, Loss function: 8.621, Average Loss: 2.045, avg. samples / sec: 65495.49
Iteration:    180, Loss function: 8.742, Average Loss: 2.050, avg. samples / sec: 65482.53
Iteration:    180, Loss function: 8.604, Average Loss: 2.049, avg. samples / sec: 65326.30
Iteration:    180, Loss function: 8.730, Average Loss: 2.039, avg. samples / sec: 65190.01
Iteration:    180, Loss function: 8.683, Average Loss: 2.055, avg. samples / sec: 65362.35
Iteration:    180, Loss function: 8.558, Average Loss: 2.054, avg. samples / sec: 65352.74
Iteration:    180, Loss function: 9.424, Average Loss: 2.074, avg. samples / sec: 65283.87
Iteration:    180, Loss function: 8.241, Average Loss: 2.057, avg. samples / sec: 65292.82
Iteration:    180, Loss function: 8.450, Average Loss: 2.072, avg. samples / sec: 65182.65
Iteration:    180, Loss function: 8.595, Average Loss: 2.046, avg. samples / sec: 65247.48
Iteration:    180, Loss function: 8.301, Average Loss: 2.062, avg. samples / sec: 65141.86
Iteration:    180, Loss function: 8.721, Average Loss: 2.051, avg. samples / sec: 64898.07
Iteration:    200, Loss function: 7.005, Average Loss: 2.177, avg. samples / sec: 65769.82
Iteration:    200, Loss function: 7.882, Average Loss: 2.170, avg. samples / sec: 65836.06
Iteration:    200, Loss function: 8.350, Average Loss: 2.174, avg. samples / sec: 65927.32
Iteration:    200, Loss function: 7.526, Average Loss: 2.181, avg. samples / sec: 65832.59
Iteration:    200, Loss function: 8.391, Average Loss: 2.171, avg. samples / sec: 65868.87
Iteration:    200, Loss function: 8.657, Average Loss: 2.182, avg. samples / sec: 65999.48
Iteration:    200, Loss function: 8.171, Average Loss: 2.166, avg. samples / sec: 65754.82
Iteration:    200, Loss function: 7.946, Average Loss: 2.200, avg. samples / sec: 66061.69
Iteration:    200, Loss function: 8.498, Average Loss: 2.172, avg. samples / sec: 65813.50
Iteration:    200, Loss function: 8.424, Average Loss: 2.174, avg. samples / sec: 65855.35
Iteration:    200, Loss function: 8.134, Average Loss: 2.199, avg. samples / sec: 65973.49
Iteration:    200, Loss function: 7.633, Average Loss: 2.164, avg. samples / sec: 65850.52
Iteration:    200, Loss function: 8.397, Average Loss: 2.178, avg. samples / sec: 65872.62
Iteration:    200, Loss function: 8.984, Average Loss: 2.166, avg. samples / sec: 65704.45
Iteration:    200, Loss function: 8.725, Average Loss: 2.171, avg. samples / sec: 65910.95
Iteration:    200, Loss function: 8.159, Average Loss: 2.171, avg. samples / sec: 65722.43
Iteration:    200, Loss function: 8.328, Average Loss: 2.180, avg. samples / sec: 65784.28
Iteration:    200, Loss function: 8.659, Average Loss: 2.184, avg. samples / sec: 65827.45
Iteration:    200, Loss function: 8.511, Average Loss: 2.165, avg. samples / sec: 65905.71
Iteration:    200, Loss function: 8.494, Average Loss: 2.167, avg. samples / sec: 65857.66
Iteration:    200, Loss function: 8.165, Average Loss: 2.187, avg. samples / sec: 65992.15
Iteration:    200, Loss function: 9.159, Average Loss: 2.180, avg. samples / sec: 65751.53
Iteration:    200, Loss function: 8.075, Average Loss: 2.155, avg. samples / sec: 65723.45
Iteration:    200, Loss function: 8.139, Average Loss: 2.163, avg. samples / sec: 65776.05
Iteration:    200, Loss function: 7.940, Average Loss: 2.172, avg. samples / sec: 65685.49
Iteration:    200, Loss function: 7.149, Average Loss: 2.174, avg. samples / sec: 65845.08
Iteration:    200, Loss function: 8.482, Average Loss: 2.174, avg. samples / sec: 65794.54
Iteration:    200, Loss function: 8.395, Average Loss: 2.172, avg. samples / sec: 66247.58
Iteration:    200, Loss function: 7.874, Average Loss: 2.167, avg. samples / sec: 65715.75
Iteration:    200, Loss function: 8.719, Average Loss: 2.181, avg. samples / sec: 65665.02
:::MLL 1558651195.305 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1558651195.306 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    220, Loss function: 7.934, Average Loss: 2.294, avg. samples / sec: 65107.40
Iteration:    220, Loss function: 8.398, Average Loss: 2.286, avg. samples / sec: 65164.63
Iteration:    220, Loss function: 8.775, Average Loss: 2.300, avg. samples / sec: 65084.91
Iteration:    220, Loss function: 7.387, Average Loss: 2.303, avg. samples / sec: 65005.11
Iteration:    220, Loss function: 7.972, Average Loss: 2.270, avg. samples / sec: 65100.96
Iteration:    220, Loss function: 8.935, Average Loss: 2.290, avg. samples / sec: 64990.51
Iteration:    220, Loss function: 9.060, Average Loss: 2.322, avg. samples / sec: 65031.48
Iteration:    220, Loss function: 8.364, Average Loss: 2.289, avg. samples / sec: 65022.72
Iteration:    220, Loss function: 7.807, Average Loss: 2.305, avg. samples / sec: 65063.61
Iteration:    220, Loss function: 8.079, Average Loss: 2.293, avg. samples / sec: 65030.94
Iteration:    220, Loss function: 7.890, Average Loss: 2.290, avg. samples / sec: 65163.55
Iteration:    220, Loss function: 8.978, Average Loss: 2.289, avg. samples / sec: 64936.55
Iteration:    220, Loss function: 9.018, Average Loss: 2.293, avg. samples / sec: 65147.04
Iteration:    220, Loss function: 8.673, Average Loss: 2.319, avg. samples / sec: 64981.61
Iteration:    220, Loss function: 8.594, Average Loss: 2.283, avg. samples / sec: 65088.73
Iteration:    220, Loss function: 8.201, Average Loss: 2.291, avg. samples / sec: 65111.25
Iteration:    220, Loss function: 8.364, Average Loss: 2.284, avg. samples / sec: 64971.19
Iteration:    220, Loss function: 7.875, Average Loss: 2.293, avg. samples / sec: 64879.18
Iteration:    220, Loss function: 8.121, Average Loss: 2.284, avg. samples / sec: 64903.03
Iteration:    220, Loss function: 7.798, Average Loss: 2.282, avg. samples / sec: 64980.39
Iteration:    220, Loss function: 7.672, Average Loss: 2.300, avg. samples / sec: 64846.67
Iteration:    220, Loss function: 8.020, Average Loss: 2.289, avg. samples / sec: 64920.19
Iteration:    220, Loss function: 8.268, Average Loss: 2.284, avg. samples / sec: 64906.91
Iteration:    220, Loss function: 8.326, Average Loss: 2.294, avg. samples / sec: 64916.63
Iteration:    220, Loss function: 8.521, Average Loss: 2.291, avg. samples / sec: 64827.94
Iteration:    220, Loss function: 8.925, Average Loss: 2.303, avg. samples / sec: 65136.44
Iteration:    220, Loss function: 8.356, Average Loss: 2.287, avg. samples / sec: 64801.53
Iteration:    220, Loss function: 7.851, Average Loss: 2.290, avg. samples / sec: 64774.90
Iteration:    220, Loss function: 8.870, Average Loss: 2.302, avg. samples / sec: 64665.20
Iteration:    220, Loss function: 8.755, Average Loss: 2.285, avg. samples / sec: 64885.40
Iteration:    240, Loss function: 8.334, Average Loss: 2.403, avg. samples / sec: 66291.96
Iteration:    240, Loss function: 6.346, Average Loss: 2.401, avg. samples / sec: 66094.63
Iteration:    240, Loss function: 7.850, Average Loss: 2.402, avg. samples / sec: 66210.51
Iteration:    240, Loss function: 7.115, Average Loss: 2.429, avg. samples / sec: 66199.10
Iteration:    240, Loss function: 7.367, Average Loss: 2.403, avg. samples / sec: 66258.73
Iteration:    240, Loss function: 8.815, Average Loss: 2.395, avg. samples / sec: 66268.58
Iteration:    240, Loss function: 7.183, Average Loss: 2.412, avg. samples / sec: 66156.68
Iteration:    240, Loss function: 7.996, Average Loss: 2.403, avg. samples / sec: 66166.90
Iteration:    240, Loss function: 8.437, Average Loss: 2.382, avg. samples / sec: 66132.25
Iteration:    240, Loss function: 7.636, Average Loss: 2.403, avg. samples / sec: 66319.69
Iteration:    240, Loss function: 8.236, Average Loss: 2.391, avg. samples / sec: 66292.11
Iteration:    240, Loss function: 7.155, Average Loss: 2.432, avg. samples / sec: 66153.79
Iteration:    240, Loss function: 7.459, Average Loss: 2.414, avg. samples / sec: 66126.72
Iteration:    240, Loss function: 8.051, Average Loss: 2.400, avg. samples / sec: 66105.04
Iteration:    240, Loss function: 7.196, Average Loss: 2.410, avg. samples / sec: 66233.42
Iteration:    240, Loss function: 8.216, Average Loss: 2.402, avg. samples / sec: 66265.49
Iteration:    240, Loss function: 8.195, Average Loss: 2.403, avg. samples / sec: 66100.36
Iteration:    240, Loss function: 8.488, Average Loss: 2.403, avg. samples / sec: 66357.60
Iteration:    240, Loss function: 8.395, Average Loss: 2.399, avg. samples / sec: 66091.50
Iteration:    240, Loss function: 7.278, Average Loss: 2.396, avg. samples / sec: 66194.28
Iteration:    240, Loss function: 8.415, Average Loss: 2.414, avg. samples / sec: 66028.05
Iteration:    240, Loss function: 6.841, Average Loss: 2.399, avg. samples / sec: 66039.31
Iteration:    240, Loss function: 8.288, Average Loss: 2.392, avg. samples / sec: 66482.28
Iteration:    240, Loss function: 8.541, Average Loss: 2.402, avg. samples / sec: 65932.29
Iteration:    240, Loss function: 7.965, Average Loss: 2.411, avg. samples / sec: 66452.22
Iteration:    240, Loss function: 7.717, Average Loss: 2.397, avg. samples / sec: 66056.64
Iteration:    240, Loss function: 7.553, Average Loss: 2.415, avg. samples / sec: 66222.43
Iteration:    240, Loss function: 7.584, Average Loss: 2.407, avg. samples / sec: 66133.80
Iteration:    240, Loss function: 7.223, Average Loss: 2.403, avg. samples / sec: 66342.73
Iteration:    240, Loss function: 8.059, Average Loss: 2.392, avg. samples / sec: 65563.38
Iteration:    260, Loss function: 7.497, Average Loss: 2.513, avg. samples / sec: 65211.94
Iteration:    260, Loss function: 7.960, Average Loss: 2.503, avg. samples / sec: 65377.27
Iteration:    260, Loss function: 7.591, Average Loss: 2.507, avg. samples / sec: 65190.22
Iteration:    260, Loss function: 7.604, Average Loss: 2.522, avg. samples / sec: 65364.29
Iteration:    260, Loss function: 6.901, Average Loss: 2.512, avg. samples / sec: 65364.47
Iteration:    260, Loss function: 8.012, Average Loss: 2.511, avg. samples / sec: 65174.46
Iteration:    260, Loss function: 6.899, Average Loss: 2.511, avg. samples / sec: 65180.54
Iteration:    260, Loss function: 7.382, Average Loss: 2.501, avg. samples / sec: 65207.39
Iteration:    260, Loss function: 7.644, Average Loss: 2.520, avg. samples / sec: 65247.60
Iteration:    260, Loss function: 8.141, Average Loss: 2.518, avg. samples / sec: 65252.79
Iteration:    260, Loss function: 7.361, Average Loss: 2.512, avg. samples / sec: 65220.57
Iteration:    260, Loss function: 6.418, Average Loss: 2.497, avg. samples / sec: 65211.49
Iteration:    260, Loss function: 7.889, Average Loss: 2.522, avg. samples / sec: 65385.40
Iteration:    260, Loss function: 8.963, Average Loss: 2.512, avg. samples / sec: 65222.87
Iteration:    260, Loss function: 8.143, Average Loss: 2.513, avg. samples / sec: 65156.80
Iteration:    260, Loss function: 7.632, Average Loss: 2.522, avg. samples / sec: 65148.54
Iteration:    260, Loss function: 7.118, Average Loss: 2.537, avg. samples / sec: 65116.46
Iteration:    260, Loss function: 7.321, Average Loss: 2.507, avg. samples / sec: 65214.39
Iteration:    260, Loss function: 7.666, Average Loss: 2.513, avg. samples / sec: 65267.60
Iteration:    260, Loss function: 8.513, Average Loss: 2.506, avg. samples / sec: 65252.73
Iteration:    260, Loss function: 6.977, Average Loss: 2.509, avg. samples / sec: 65361.29
Iteration:    260, Loss function: 7.019, Average Loss: 2.513, avg. samples / sec: 65168.19
Iteration:    260, Loss function: 7.320, Average Loss: 2.518, avg. samples / sec: 65236.18
Iteration:    260, Loss function: 7.442, Average Loss: 2.504, avg. samples / sec: 65217.13
Iteration:    260, Loss function: 7.745, Average Loss: 2.508, avg. samples / sec: 65119.43
Iteration:    260, Loss function: 7.843, Average Loss: 2.502, avg. samples / sec: 65653.57
Iteration:    260, Loss function: 7.486, Average Loss: 2.537, avg. samples / sec: 65062.10
Iteration:    260, Loss function: 7.905, Average Loss: 2.492, avg. samples / sec: 64934.61
Iteration:    260, Loss function: 8.100, Average Loss: 2.521, avg. samples / sec: 65085.33
Iteration:    260, Loss function: 7.495, Average Loss: 2.506, avg. samples / sec: 64938.47
:::MLL 1558651197.098 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1558651197.099 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    280, Loss function: 8.069, Average Loss: 2.618, avg. samples / sec: 66099.83
Iteration:    280, Loss function: 8.419, Average Loss: 2.609, avg. samples / sec: 66137.99
Iteration:    280, Loss function: 7.168, Average Loss: 2.606, avg. samples / sec: 66074.39
Iteration:    280, Loss function: 7.184, Average Loss: 2.634, avg. samples / sec: 66246.24
Iteration:    280, Loss function: 7.521, Average Loss: 2.610, avg. samples / sec: 65940.03
Iteration:    280, Loss function: 8.207, Average Loss: 2.640, avg. samples / sec: 66103.24
Iteration:    280, Loss function: 7.939, Average Loss: 2.598, avg. samples / sec: 66028.91
Iteration:    280, Loss function: 7.078, Average Loss: 2.614, avg. samples / sec: 66066.52
Iteration:    280, Loss function: 7.333, Average Loss: 2.590, avg. samples / sec: 66326.40
Iteration:    280, Loss function: 7.839, Average Loss: 2.611, avg. samples / sec: 66118.91
Iteration:    280, Loss function: 8.424, Average Loss: 2.618, avg. samples / sec: 65977.41
Iteration:    280, Loss function: 8.514, Average Loss: 2.603, avg. samples / sec: 66124.46
Iteration:    280, Loss function: 7.984, Average Loss: 2.608, avg. samples / sec: 65979.17
Iteration:    280, Loss function: 8.319, Average Loss: 2.622, avg. samples / sec: 65983.47
Iteration:    280, Loss function: 8.932, Average Loss: 2.610, avg. samples / sec: 65976.46
Iteration:    280, Loss function: 8.329, Average Loss: 2.605, avg. samples / sec: 66069.84
Iteration:    280, Loss function: 8.723, Average Loss: 2.611, avg. samples / sec: 66089.51
Iteration:    280, Loss function: 8.461, Average Loss: 2.618, avg. samples / sec: 65910.33
Iteration:    280, Loss function: 8.340, Average Loss: 2.613, avg. samples / sec: 65893.35
Iteration:    280, Loss function: 8.088, Average Loss: 2.617, avg. samples / sec: 66052.46
Iteration:    280, Loss function: 11.072, Average Loss: 2.607, avg. samples / sec: 65814.63
Iteration:    280, Loss function: 7.276, Average Loss: 2.609, avg. samples / sec: 65826.16
Iteration:    280, Loss function: 7.387, Average Loss: 2.621, avg. samples / sec: 66231.58
Iteration:    280, Loss function: 7.976, Average Loss: 2.600, avg. samples / sec: 65908.14
Iteration:    280, Loss function: 7.228, Average Loss: 2.609, avg. samples / sec: 65946.36
Iteration:    280, Loss function: 7.510, Average Loss: 2.601, avg. samples / sec: 65990.48
Iteration:    280, Loss function: 9.079, Average Loss: 2.602, avg. samples / sec: 65987.39
Iteration:    280, Loss function: 8.386, Average Loss: 2.613, avg. samples / sec: 65944.69
Iteration:    280, Loss function: 7.454, Average Loss: 2.618, avg. samples / sec: 65809.87
Iteration:    280, Loss function: 7.903, Average Loss: 2.602, avg. samples / sec: 66093.14
Iteration:    300, Loss function: 7.825, Average Loss: 2.723, avg. samples / sec: 65993.14
Iteration:    300, Loss function: 7.306, Average Loss: 2.710, avg. samples / sec: 66014.59
Iteration:    300, Loss function: 7.607, Average Loss: 2.720, avg. samples / sec: 65872.68
Iteration:    300, Loss function: 7.492, Average Loss: 2.718, avg. samples / sec: 66033.86
Iteration:    300, Loss function: 7.312, Average Loss: 2.728, avg. samples / sec: 65830.59
Iteration:    300, Loss function: 9.006, Average Loss: 2.717, avg. samples / sec: 66001.02
Iteration:    300, Loss function: 8.381, Average Loss: 2.721, avg. samples / sec: 66080.28
Iteration:    300, Loss function: 8.462, Average Loss: 2.703, avg. samples / sec: 65960.49
Iteration:    300, Loss function: 7.469, Average Loss: 2.729, avg. samples / sec: 65942.75
Iteration:    300, Loss function: 8.410, Average Loss: 2.723, avg. samples / sec: 66079.69
Iteration:    300, Loss function: 8.789, Average Loss: 2.728, avg. samples / sec: 66019.26
Iteration:    300, Loss function: 8.447, Average Loss: 2.725, avg. samples / sec: 65964.72
Iteration:    300, Loss function: 6.931, Average Loss: 2.712, avg. samples / sec: 66052.19
Iteration:    300, Loss function: 7.617, Average Loss: 2.720, avg. samples / sec: 65977.85
Iteration:    300, Loss function: 8.187, Average Loss: 2.746, avg. samples / sec: 65859.82
Iteration:    300, Loss function: 7.552, Average Loss: 2.735, avg. samples / sec: 65960.28
Iteration:    300, Loss function: 7.456, Average Loss: 2.716, avg. samples / sec: 65841.23
Iteration:    300, Loss function: 8.035, Average Loss: 2.726, avg. samples / sec: 66152.33
Iteration:    300, Loss function: 6.970, Average Loss: 2.712, avg. samples / sec: 66031.51
Iteration:    300, Loss function: 7.960, Average Loss: 2.727, avg. samples / sec: 65969.20
Iteration:    300, Loss function: 8.213, Average Loss: 2.714, avg. samples / sec: 66133.43
Iteration:    300, Loss function: 8.047, Average Loss: 2.714, avg. samples / sec: 66017.75
Iteration:    300, Loss function: 7.296, Average Loss: 2.749, avg. samples / sec: 65833.97
Iteration:    300, Loss function: 7.395, Average Loss: 2.730, avg. samples / sec: 65942.16
Iteration:    300, Loss function: 7.973, Average Loss: 2.733, avg. samples / sec: 65888.73
Iteration:    300, Loss function: 7.289, Average Loss: 2.725, avg. samples / sec: 65992.06
Iteration:    300, Loss function: 8.876, Average Loss: 2.722, avg. samples / sec: 65841.57
Iteration:    300, Loss function: 7.920, Average Loss: 2.715, avg. samples / sec: 65868.00
Iteration:    300, Loss function: 7.767, Average Loss: 2.730, avg. samples / sec: 65850.15
Iteration:    300, Loss function: 8.478, Average Loss: 2.723, avg. samples / sec: 65801.79
Iteration:    320, Loss function: 6.838, Average Loss: 2.816, avg. samples / sec: 66792.17
Iteration:    320, Loss function: 7.451, Average Loss: 2.844, avg. samples / sec: 66498.50
Iteration:    320, Loss function: 6.223, Average Loss: 2.808, avg. samples / sec: 66383.61
Iteration:    320, Loss function: 9.357, Average Loss: 2.821, avg. samples / sec: 66533.13
Iteration:    320, Loss function: 8.237, Average Loss: 2.814, avg. samples / sec: 66313.76
Iteration:    320, Loss function: 8.109, Average Loss: 2.807, avg. samples / sec: 66298.41
Iteration:    320, Loss function: 8.074, Average Loss: 2.820, avg. samples / sec: 66372.76
Iteration:    320, Loss function: 7.734, Average Loss: 2.825, avg. samples / sec: 66467.42
Iteration:    320, Loss function: 7.478, Average Loss: 2.814, avg. samples / sec: 66379.64
Iteration:    320, Loss function: 6.457, Average Loss: 2.820, avg. samples / sec: 66412.04
Iteration:    320, Loss function: 7.345, Average Loss: 2.827, avg. samples / sec: 66354.57
Iteration:    320, Loss function: 8.069, Average Loss: 2.805, avg. samples / sec: 66423.22
Iteration:    320, Loss function: 8.170, Average Loss: 2.805, avg. samples / sec: 66368.98
Iteration:    320, Loss function: 7.544, Average Loss: 2.844, avg. samples / sec: 66373.23
Iteration:    320, Loss function: 7.252, Average Loss: 2.822, avg. samples / sec: 66348.01
Iteration:    320, Loss function: 7.820, Average Loss: 2.826, avg. samples / sec: 66424.47
Iteration:    320, Loss function: 6.304, Average Loss: 2.810, avg. samples / sec: 66474.79
Iteration:    320, Loss function: 7.640, Average Loss: 2.810, avg. samples / sec: 66295.64
Iteration:    320, Loss function: 7.916, Average Loss: 2.816, avg. samples / sec: 66294.39
Iteration:    320, Loss function: 7.007, Average Loss: 2.811, avg. samples / sec: 66356.63
Iteration:    320, Loss function: 8.355, Average Loss: 2.831, avg. samples / sec: 66317.10
Iteration:    320, Loss function: 6.911, Average Loss: 2.824, avg. samples / sec: 66492.67
Iteration:    320, Loss function: 6.668, Average Loss: 2.823, avg. samples / sec: 66311.30
Iteration:    320, Loss function: 6.566, Average Loss: 2.799, avg. samples / sec: 66221.74
Iteration:    320, Loss function: 7.611, Average Loss: 2.811, avg. samples / sec: 66268.36
Iteration:    320, Loss function: 7.287, Average Loss: 2.814, avg. samples / sec: 66142.89
Iteration:    320, Loss function: 8.407, Average Loss: 2.820, avg. samples / sec: 66201.46
Iteration:    320, Loss function: 7.097, Average Loss: 2.819, avg. samples / sec: 66301.28
Iteration:    320, Loss function: 7.598, Average Loss: 2.808, avg. samples / sec: 66187.35
Iteration:    320, Loss function: 7.118, Average Loss: 2.807, avg. samples / sec: 66115.96
Iteration:    340, Loss function: 6.940, Average Loss: 2.907, avg. samples / sec: 65572.04
Iteration:    340, Loss function: 7.517, Average Loss: 2.898, avg. samples / sec: 65556.76
Iteration:    340, Loss function: 8.183, Average Loss: 2.903, avg. samples / sec: 65498.75
Iteration:    340, Loss function: 6.446, Average Loss: 2.893, avg. samples / sec: 65833.91
Iteration:    340, Loss function: 7.707, Average Loss: 2.934, avg. samples / sec: 65458.65
Iteration:    340, Loss function: 7.436, Average Loss: 2.906, avg. samples / sec: 65511.72
Iteration:    340, Loss function: 7.513, Average Loss: 2.898, avg. samples / sec: 65308.95
Iteration:    340, Loss function: 6.617, Average Loss: 2.896, avg. samples / sec: 65628.08
Iteration:    340, Loss function: 7.698, Average Loss: 2.893, avg. samples / sec: 65435.31
Iteration:    340, Loss function: 6.989, Average Loss: 2.933, avg. samples / sec: 65460.81
Iteration:    340, Loss function: 6.961, Average Loss: 2.897, avg. samples / sec: 65372.36
Iteration:    340, Loss function: 8.538, Average Loss: 2.892, avg. samples / sec: 65439.11
Iteration:    340, Loss function: 6.538, Average Loss: 2.913, avg. samples / sec: 65418.06
Iteration:    340, Loss function: 6.665, Average Loss: 2.903, avg. samples / sec: 65587.45
Iteration:    340, Loss function: 7.248, Average Loss: 2.902, avg. samples / sec: 65455.06
Iteration:    340, Loss function: 6.661, Average Loss: 2.896, avg. samples / sec: 65513.33
Iteration:    340, Loss function: 7.889, Average Loss: 2.900, avg. samples / sec: 65439.35
Iteration:    340, Loss function: 7.489, Average Loss: 2.902, avg. samples / sec: 65573.69
Iteration:    340, Loss function: 7.667, Average Loss: 2.892, avg. samples / sec: 65383.73
Iteration:    340, Loss function: 6.721, Average Loss: 2.900, avg. samples / sec: 65374.57
Iteration:    340, Loss function: 6.993, Average Loss: 2.910, avg. samples / sec: 65370.45
Iteration:    340, Loss function: 7.381, Average Loss: 2.917, avg. samples / sec: 65439.87
Iteration:    340, Loss function: 6.541, Average Loss: 2.883, avg. samples / sec: 65479.36
Iteration:    340, Loss function: 6.677, Average Loss: 2.907, avg. samples / sec: 65297.39
Iteration:    340, Loss function: 6.026, Average Loss: 2.907, avg. samples / sec: 65458.10
Iteration:    340, Loss function: 7.006, Average Loss: 2.911, avg. samples / sec: 65428.44
Iteration:    340, Loss function: 7.096, Average Loss: 2.896, avg. samples / sec: 65264.46
Iteration:    340, Loss function: 6.308, Average Loss: 2.892, avg. samples / sec: 65551.36
Iteration:    340, Loss function: 6.877, Average Loss: 2.903, avg. samples / sec: 65199.12
Iteration:    340, Loss function: 6.074, Average Loss: 2.897, avg. samples / sec: 65128.82
:::MLL 1558651198.883 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1558651198.883 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    360, Loss function: 7.355, Average Loss: 2.982, avg. samples / sec: 66114.38
Iteration:    360, Loss function: 8.413, Average Loss: 2.983, avg. samples / sec: 65951.54
Iteration:    360, Loss function: 7.659, Average Loss: 2.982, avg. samples / sec: 66091.03
Iteration:    360, Loss function: 7.383, Average Loss: 3.020, avg. samples / sec: 65956.94
Iteration:    360, Loss function: 7.719, Average Loss: 2.978, avg. samples / sec: 65999.48
Iteration:    360, Loss function: 7.720, Average Loss: 2.987, avg. samples / sec: 65948.36
Iteration:    360, Loss function: 8.420, Average Loss: 3.002, avg. samples / sec: 66056.15
Iteration:    360, Loss function: 7.180, Average Loss: 2.974, avg. samples / sec: 65991.22
Iteration:    360, Loss function: 7.428, Average Loss: 2.978, avg. samples / sec: 65917.61
Iteration:    360, Loss function: 6.575, Average Loss: 2.988, avg. samples / sec: 66040.55
Iteration:    360, Loss function: 7.238, Average Loss: 2.973, avg. samples / sec: 65925.07
Iteration:    360, Loss function: 8.426, Average Loss: 2.987, avg. samples / sec: 65840.65
Iteration:    360, Loss function: 7.138, Average Loss: 2.978, avg. samples / sec: 65954.01
Iteration:    360, Loss function: 6.741, Average Loss: 2.993, avg. samples / sec: 65989.03
Iteration:    360, Loss function: 6.586, Average Loss: 2.975, avg. samples / sec: 66027.46
Iteration:    360, Loss function: 6.852, Average Loss: 2.974, avg. samples / sec: 65835.66
Iteration:    360, Loss function: 7.739, Average Loss: 2.986, avg. samples / sec: 65969.23
Iteration:    360, Loss function: 7.750, Average Loss: 2.990, avg. samples / sec: 65791.65
Iteration:    360, Loss function: 7.071, Average Loss: 2.980, avg. samples / sec: 65944.78
Iteration:    360, Loss function: 8.513, Average Loss: 2.990, avg. samples / sec: 65944.66
Iteration:    360, Loss function: 6.862, Average Loss: 2.989, avg. samples / sec: 65976.58
Iteration:    360, Loss function: 7.192, Average Loss: 2.985, avg. samples / sec: 65905.92
Iteration:    360, Loss function: 8.568, Average Loss: 2.982, avg. samples / sec: 66212.91
Iteration:    360, Loss function: 7.808, Average Loss: 2.986, avg. samples / sec: 65904.38
Iteration:    360, Loss function: 7.140, Average Loss: 2.989, avg. samples / sec: 66097.60
Iteration:    360, Loss function: 7.302, Average Loss: 3.014, avg. samples / sec: 65859.05
Iteration:    360, Loss function: 8.193, Average Loss: 2.996, avg. samples / sec: 65881.55
Iteration:    360, Loss function: 7.867, Average Loss: 2.979, avg. samples / sec: 65911.10
Iteration:    360, Loss function: 7.481, Average Loss: 2.981, avg. samples / sec: 65824.41
Iteration:    360, Loss function: 7.834, Average Loss: 2.958, avg. samples / sec: 65844.00
Iteration:    380, Loss function: 6.517, Average Loss: 3.063, avg. samples / sec: 66284.76
Iteration:    380, Loss function: 7.022, Average Loss: 3.060, avg. samples / sec: 66214.99
Iteration:    380, Loss function: 6.980, Average Loss: 3.073, avg. samples / sec: 66149.29
Iteration:    380, Loss function: 7.272, Average Loss: 3.053, avg. samples / sec: 66204.70
Iteration:    380, Loss function: 7.236, Average Loss: 3.107, avg. samples / sec: 66114.87
Iteration:    380, Loss function: 6.347, Average Loss: 3.057, avg. samples / sec: 66101.07
Iteration:    380, Loss function: 7.348, Average Loss: 3.071, avg. samples / sec: 66048.16
Iteration:    380, Loss function: 6.640, Average Loss: 3.077, avg. samples / sec: 66265.52
Iteration:    380, Loss function: 7.010, Average Loss: 3.079, avg. samples / sec: 66224.17
Iteration:    380, Loss function: 6.755, Average Loss: 3.072, avg. samples / sec: 66177.21
Iteration:    380, Loss function: 7.020, Average Loss: 3.080, avg. samples / sec: 66184.27
Iteration:    380, Loss function: 7.276, Average Loss: 3.065, avg. samples / sec: 66166.62
Iteration:    380, Loss function: 7.528, Average Loss: 3.069, avg. samples / sec: 66293.21
Iteration:    380, Loss function: 6.979, Average Loss: 3.077, avg. samples / sec: 66163.79
Iteration:    380, Loss function: 6.591, Average Loss: 3.063, avg. samples / sec: 66086.32
Iteration:    380, Loss function: 7.391, Average Loss: 3.078, avg. samples / sec: 66178.15
Iteration:    380, Loss function: 7.473, Average Loss: 3.066, avg. samples / sec: 66281.39
Iteration:    380, Loss function: 6.556, Average Loss: 3.076, avg. samples / sec: 66146.87
Iteration:    380, Loss function: 6.930, Average Loss: 3.064, avg. samples / sec: 66135.38
Iteration:    380, Loss function: 6.875, Average Loss: 3.071, avg. samples / sec: 66131.78
Iteration:    380, Loss function: 6.973, Average Loss: 3.101, avg. samples / sec: 66186.82
Iteration:    380, Loss function: 6.470, Average Loss: 3.061, avg. samples / sec: 66107.06
Iteration:    380, Loss function: 6.183, Average Loss: 3.071, avg. samples / sec: 66124.65
Iteration:    380, Loss function: 6.549, Average Loss: 3.063, avg. samples / sec: 66126.41
Iteration:    380, Loss function: 7.120, Average Loss: 3.087, avg. samples / sec: 65971.79
Iteration:    380, Loss function: 7.769, Average Loss: 3.044, avg. samples / sec: 66195.31
Iteration:    380, Loss function: 6.439, Average Loss: 3.071, avg. samples / sec: 66009.74
Iteration:    380, Loss function: 7.183, Average Loss: 3.069, avg. samples / sec: 65830.41
Iteration:    380, Loss function: 7.033, Average Loss: 3.076, avg. samples / sec: 65920.75
Iteration:    380, Loss function: 7.217, Average Loss: 3.069, avg. samples / sec: 65821.43
Iteration:    400, Loss function: 7.133, Average Loss: 3.136, avg. samples / sec: 65301.99
Iteration:    400, Loss function: 6.839, Average Loss: 3.130, avg. samples / sec: 65202.98
Iteration:    400, Loss function: 6.398, Average Loss: 3.151, avg. samples / sec: 65283.69
Iteration:    400, Loss function: 8.866, Average Loss: 3.147, avg. samples / sec: 65106.20
Iteration:    400, Loss function: 6.330, Average Loss: 3.149, avg. samples / sec: 65236.45
Iteration:    400, Loss function: 7.094, Average Loss: 3.143, avg. samples / sec: 65440.35
Iteration:    400, Loss function: 7.104, Average Loss: 3.151, avg. samples / sec: 65226.64
Iteration:    400, Loss function: 6.535, Average Loss: 3.143, avg. samples / sec: 65259.23
Iteration:    400, Loss function: 5.371, Average Loss: 3.141, avg. samples / sec: 65172.62
Iteration:    400, Loss function: 6.429, Average Loss: 3.136, avg. samples / sec: 65078.24
Iteration:    400, Loss function: 6.279, Average Loss: 3.118, avg. samples / sec: 65314.22
Iteration:    400, Loss function: 5.755, Average Loss: 3.157, avg. samples / sec: 65374.33
Iteration:    400, Loss function: 7.223, Average Loss: 3.140, avg. samples / sec: 65181.72
Iteration:    400, Loss function: 8.286, Average Loss: 3.146, avg. samples / sec: 65383.06
Iteration:    400, Loss function: 7.437, Average Loss: 3.149, avg. samples / sec: 65130.78
Iteration:    400, Loss function: 6.915, Average Loss: 3.158, avg. samples / sec: 65181.39
Iteration:    400, Loss function: 7.278, Average Loss: 3.153, avg. samples / sec: 65142.25
Iteration:    400, Loss function: 7.614, Average Loss: 3.152, avg. samples / sec: 65153.97
Iteration:    400, Loss function: 5.973, Average Loss: 3.147, avg. samples / sec: 65260.80
Iteration:    400, Loss function: 7.357, Average Loss: 3.134, avg. samples / sec: 65195.44
Iteration:    400, Loss function: 6.371, Average Loss: 3.139, avg. samples / sec: 65204.88
Iteration:    400, Loss function: 6.638, Average Loss: 3.176, avg. samples / sec: 65156.74
Iteration:    400, Loss function: 5.732, Average Loss: 3.143, avg. samples / sec: 65105.72
Iteration:    400, Loss function: 6.643, Average Loss: 3.128, avg. samples / sec: 65016.81
Iteration:    400, Loss function: 6.831, Average Loss: 3.149, avg. samples / sec: 65159.30
Iteration:    400, Loss function: 6.345, Average Loss: 3.183, avg. samples / sec: 65003.31
Iteration:    400, Loss function: 7.496, Average Loss: 3.150, avg. samples / sec: 65106.38
Iteration:    400, Loss function: 7.274, Average Loss: 3.146, avg. samples / sec: 64949.84
Iteration:    400, Loss function: 6.725, Average Loss: 3.138, avg. samples / sec: 65056.94
Iteration:    400, Loss function: 8.019, Average Loss: 3.160, avg. samples / sec: 65116.52
:::MLL 1558651200.668 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1558651200.669 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    420, Loss function: 6.044, Average Loss: 3.222, avg. samples / sec: 66375.92
Iteration:    420, Loss function: 6.783, Average Loss: 3.247, avg. samples / sec: 66431.58
Iteration:    420, Loss function: 6.224, Average Loss: 3.221, avg. samples / sec: 66377.82
Iteration:    420, Loss function: 5.776, Average Loss: 3.257, avg. samples / sec: 66440.72
Iteration:    420, Loss function: 5.887, Average Loss: 3.208, avg. samples / sec: 66284.76
Iteration:    420, Loss function: 7.863, Average Loss: 3.216, avg. samples / sec: 66379.64
Iteration:    420, Loss function: 6.981, Average Loss: 3.200, avg. samples / sec: 66190.21
Iteration:    420, Loss function: 5.555, Average Loss: 3.221, avg. samples / sec: 66192.17
Iteration:    420, Loss function: 5.309, Average Loss: 3.214, avg. samples / sec: 66185.79
Iteration:    420, Loss function: 7.021, Average Loss: 3.207, avg. samples / sec: 66317.41
Iteration:    420, Loss function: 5.751, Average Loss: 3.207, avg. samples / sec: 66151.68
Iteration:    420, Loss function: 6.229, Average Loss: 3.217, avg. samples / sec: 66188.68
Iteration:    420, Loss function: 7.155, Average Loss: 3.207, avg. samples / sec: 66410.07
Iteration:    420, Loss function: 6.218, Average Loss: 3.229, avg. samples / sec: 66431.14
Iteration:    420, Loss function: 6.791, Average Loss: 3.230, avg. samples / sec: 66263.94
Iteration:    420, Loss function: 7.911, Average Loss: 3.188, avg. samples / sec: 66214.34
Iteration:    420, Loss function: 6.375, Average Loss: 3.221, avg. samples / sec: 66261.13
Iteration:    420, Loss function: 6.679, Average Loss: 3.220, avg. samples / sec: 66213.25
Iteration:    420, Loss function: 7.181, Average Loss: 3.220, avg. samples / sec: 66325.43
Iteration:    420, Loss function: 6.446, Average Loss: 3.218, avg. samples / sec: 66256.93
Iteration:    420, Loss function: 5.519, Average Loss: 3.223, avg. samples / sec: 66154.66
Iteration:    420, Loss function: 6.749, Average Loss: 3.222, avg. samples / sec: 66298.16
Iteration:    420, Loss function: 6.020, Average Loss: 3.207, avg. samples / sec: 66170.66
Iteration:    420, Loss function: 7.943, Average Loss: 3.211, avg. samples / sec: 66206.25
Iteration:    420, Loss function: 7.006, Average Loss: 3.203, avg. samples / sec: 66221.43
Iteration:    420, Loss function: 6.019, Average Loss: 3.213, avg. samples / sec: 66111.28
Iteration:    420, Loss function: 6.545, Average Loss: 3.217, avg. samples / sec: 66101.29
Iteration:    420, Loss function: 6.222, Average Loss: 3.228, avg. samples / sec: 66099.34
Iteration:    420, Loss function: 6.215, Average Loss: 3.215, avg. samples / sec: 66207.34
Iteration:    420, Loss function: 6.931, Average Loss: 3.199, avg. samples / sec: 66106.10
Iteration:    440, Loss function: 5.882, Average Loss: 3.282, avg. samples / sec: 66620.47
Iteration:    440, Loss function: 6.415, Average Loss: 3.276, avg. samples / sec: 66448.77
Iteration:    440, Loss function: 6.400, Average Loss: 3.296, avg. samples / sec: 66373.04
Iteration:    440, Loss function: 7.039, Average Loss: 3.265, avg. samples / sec: 66679.20
Iteration:    440, Loss function: 6.341, Average Loss: 3.290, avg. samples / sec: 66476.86
Iteration:    440, Loss function: 6.245, Average Loss: 3.287, avg. samples / sec: 66462.37
Iteration:    440, Loss function: 5.786, Average Loss: 3.283, avg. samples / sec: 66402.59
Iteration:    440, Loss function: 6.612, Average Loss: 3.279, avg. samples / sec: 66327.46
Iteration:    440, Loss function: 6.474, Average Loss: 3.330, avg. samples / sec: 66311.52
Iteration:    440, Loss function: 6.844, Average Loss: 3.274, avg. samples / sec: 66354.23
Iteration:    440, Loss function: 7.310, Average Loss: 3.258, avg. samples / sec: 66377.82
Iteration:    440, Loss function: 6.963, Average Loss: 3.294, avg. samples / sec: 66409.26
Iteration:    440, Loss function: 8.417, Average Loss: 3.277, avg. samples / sec: 66416.58
Iteration:    440, Loss function: 6.326, Average Loss: 3.302, avg. samples / sec: 66390.42
Iteration:    440, Loss function: 7.495, Average Loss: 3.291, avg. samples / sec: 66220.10
Iteration:    440, Loss function: 5.837, Average Loss: 3.276, avg. samples / sec: 66405.07
Iteration:    440, Loss function: 9.069, Average Loss: 3.286, avg. samples / sec: 66371.38
Iteration:    440, Loss function: 6.238, Average Loss: 3.286, avg. samples / sec: 66307.33
Iteration:    440, Loss function: 5.281, Average Loss: 3.273, avg. samples / sec: 66300.00
Iteration:    440, Loss function: 6.496, Average Loss: 3.301, avg. samples / sec: 66292.27
Iteration:    440, Loss function: 6.988, Average Loss: 3.290, avg. samples / sec: 66391.33
Iteration:    440, Loss function: 7.424, Average Loss: 3.296, avg. samples / sec: 66238.55
Iteration:    440, Loss function: 6.959, Average Loss: 3.297, avg. samples / sec: 66299.54
Iteration:    440, Loss function: 7.433, Average Loss: 3.288, avg. samples / sec: 66213.34
Iteration:    440, Loss function: 6.988, Average Loss: 3.298, avg. samples / sec: 66415.27
Iteration:    440, Loss function: 6.275, Average Loss: 3.286, avg. samples / sec: 66276.09
Iteration:    440, Loss function: 6.822, Average Loss: 3.284, avg. samples / sec: 66208.30
Iteration:    440, Loss function: 6.735, Average Loss: 3.316, avg. samples / sec: 66105.29
Iteration:    440, Loss function: 7.594, Average Loss: 3.287, avg. samples / sec: 66428.70
Iteration:    440, Loss function: 6.210, Average Loss: 3.295, avg. samples / sec: 66234.26
Iteration:    460, Loss function: 6.874, Average Loss: 3.368, avg. samples / sec: 66291.77
Iteration:    460, Loss function: 6.560, Average Loss: 3.354, avg. samples / sec: 66490.31
Iteration:    460, Loss function: 6.906, Average Loss: 3.358, avg. samples / sec: 66425.38
Iteration:    460, Loss function: 7.186, Average Loss: 3.362, avg. samples / sec: 66442.60
Iteration:    460, Loss function: 6.447, Average Loss: 3.352, avg. samples / sec: 66321.38
Iteration:    460, Loss function: 6.908, Average Loss: 3.328, avg. samples / sec: 66253.00
Iteration:    460, Loss function: 6.904, Average Loss: 3.321, avg. samples / sec: 66320.28
Iteration:    460, Loss function: 6.360, Average Loss: 3.344, avg. samples / sec: 66279.67
Iteration:    460, Loss function: 5.786, Average Loss: 3.341, avg. samples / sec: 66317.41
Iteration:    460, Loss function: 5.558, Average Loss: 3.340, avg. samples / sec: 66157.71
Iteration:    460, Loss function: 5.373, Average Loss: 3.342, avg. samples / sec: 66282.64
Iteration:    460, Loss function: 7.183, Average Loss: 3.347, avg. samples / sec: 66072.10
Iteration:    460, Loss function: 6.251, Average Loss: 3.354, avg. samples / sec: 66261.91
Iteration:    460, Loss function: 6.463, Average Loss: 3.356, avg. samples / sec: 66183.90
Iteration:    460, Loss function: 7.139, Average Loss: 3.399, avg. samples / sec: 66226.32
Iteration:    460, Loss function: 7.149, Average Loss: 3.343, avg. samples / sec: 66229.74
Iteration:    460, Loss function: 7.028, Average Loss: 3.369, avg. samples / sec: 66228.47
Iteration:    460, Loss function: 7.539, Average Loss: 3.358, avg. samples / sec: 66292.39
Iteration:    460, Loss function: 6.112, Average Loss: 3.353, avg. samples / sec: 66252.41
Iteration:    460, Loss function: 7.428, Average Loss: 3.354, avg. samples / sec: 66329.34
Iteration:    460, Loss function: 6.309, Average Loss: 3.352, avg. samples / sec: 66331.68
Iteration:    460, Loss function: 6.273, Average Loss: 3.350, avg. samples / sec: 66341.20
Iteration:    460, Loss function: 6.400, Average Loss: 3.352, avg. samples / sec: 66107.80
Iteration:    460, Loss function: 8.180, Average Loss: 3.344, avg. samples / sec: 66237.37
Iteration:    460, Loss function: 6.462, Average Loss: 3.357, avg. samples / sec: 66193.97
Iteration:    460, Loss function: 5.071, Average Loss: 3.365, avg. samples / sec: 66289.43
Iteration:    460, Loss function: 5.873, Average Loss: 3.364, avg. samples / sec: 66242.26
Iteration:    460, Loss function: 6.163, Average Loss: 3.365, avg. samples / sec: 66307.77
Iteration:    460, Loss function: 5.594, Average Loss: 3.384, avg. samples / sec: 66263.50
Iteration:    460, Loss function: 6.018, Average Loss: 3.362, avg. samples / sec: 66114.87
Iteration:    480, Loss function: 7.042, Average Loss: 3.432, avg. samples / sec: 66412.07
Iteration:    480, Loss function: 7.574, Average Loss: 3.419, avg. samples / sec: 66553.30
Iteration:    480, Loss function: 7.904, Average Loss: 3.450, avg. samples / sec: 66616.00
Iteration:    480, Loss function: 6.138, Average Loss: 3.422, avg. samples / sec: 66353.13
Iteration:    480, Loss function: 7.318, Average Loss: 3.425, avg. samples / sec: 66679.86
Iteration:    480, Loss function: 6.197, Average Loss: 3.404, avg. samples / sec: 66437.90
Iteration:    480, Loss function: 6.191, Average Loss: 3.406, avg. samples / sec: 66466.98
Iteration:    480, Loss function: 5.863, Average Loss: 3.460, avg. samples / sec: 66439.53
Iteration:    480, Loss function: 5.541, Average Loss: 3.404, avg. samples / sec: 66405.82
Iteration:    480, Loss function: 6.695, Average Loss: 3.409, avg. samples / sec: 66427.04
Iteration:    480, Loss function: 7.333, Average Loss: 3.418, avg. samples / sec: 66335.39
Iteration:    480, Loss function: 7.086, Average Loss: 3.418, avg. samples / sec: 66447.99
Iteration:    480, Loss function: 7.552, Average Loss: 3.417, avg. samples / sec: 66478.33
Iteration:    480, Loss function: 5.975, Average Loss: 3.408, avg. samples / sec: 66394.49
Iteration:    480, Loss function: 6.839, Average Loss: 3.415, avg. samples / sec: 66458.71
Iteration:    480, Loss function: 7.315, Average Loss: 3.419, avg. samples / sec: 66486.39
Iteration:    480, Loss function: 6.591, Average Loss: 3.394, avg. samples / sec: 66309.61
Iteration:    480, Loss function: 6.700, Average Loss: 3.420, avg. samples / sec: 66433.21
Iteration:    480, Loss function: 5.954, Average Loss: 3.423, avg. samples / sec: 66401.15
Iteration:    480, Loss function: 6.840, Average Loss: 3.437, avg. samples / sec: 66364.88
Iteration:    480, Loss function: 7.461, Average Loss: 3.411, avg. samples / sec: 66273.38
Iteration:    480, Loss function: 7.069, Average Loss: 3.404, avg. samples / sec: 66412.11
Iteration:    480, Loss function: 7.395, Average Loss: 3.383, avg. samples / sec: 66275.75
Iteration:    480, Loss function: 6.726, Average Loss: 3.420, avg. samples / sec: 66192.13
Iteration:    480, Loss function: 5.731, Average Loss: 3.415, avg. samples / sec: 66333.33
Iteration:    480, Loss function: 5.787, Average Loss: 3.429, avg. samples / sec: 66194.78
Iteration:    480, Loss function: 5.919, Average Loss: 3.429, avg. samples / sec: 66376.92
Iteration:    480, Loss function: 7.411, Average Loss: 3.429, avg. samples / sec: 66312.73
Iteration:    480, Loss function: 8.522, Average Loss: 3.432, avg. samples / sec: 66289.74
Iteration:    480, Loss function: 6.482, Average Loss: 3.426, avg. samples / sec: 66234.38
:::MLL 1558651202.443 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1558651202.443 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 6.065, Average Loss: 3.514, avg. samples / sec: 65993.05
Iteration:    500, Loss function: 5.970, Average Loss: 3.487, avg. samples / sec: 66009.06
Iteration:    500, Loss function: 6.739, Average Loss: 3.475, avg. samples / sec: 66093.94
Iteration:    500, Loss function: 6.360, Average Loss: 3.456, avg. samples / sec: 66038.54
Iteration:    500, Loss function: 6.331, Average Loss: 3.487, avg. samples / sec: 65950.58
Iteration:    500, Loss function: 6.984, Average Loss: 3.467, avg. samples / sec: 65957.00
Iteration:    500, Loss function: 6.445, Average Loss: 3.483, avg. samples / sec: 65914.06
Iteration:    500, Loss function: 6.588, Average Loss: 3.497, avg. samples / sec: 65852.28
Iteration:    500, Loss function: 7.049, Average Loss: 3.470, avg. samples / sec: 65940.65
Iteration:    500, Loss function: 6.468, Average Loss: 3.486, avg. samples / sec: 66033.52
Iteration:    500, Loss function: 6.236, Average Loss: 3.477, avg. samples / sec: 66035.69
Iteration:    500, Loss function: 6.827, Average Loss: 3.479, avg. samples / sec: 65954.94
Iteration:    500, Loss function: 6.109, Average Loss: 3.466, avg. samples / sec: 65904.48
Iteration:    500, Loss function: 6.467, Average Loss: 3.479, avg. samples / sec: 65907.90
Iteration:    500, Loss function: 6.223, Average Loss: 3.482, avg. samples / sec: 65872.53
Iteration:    500, Loss function: 6.601, Average Loss: 3.467, avg. samples / sec: 65987.58
Iteration:    500, Loss function: 5.932, Average Loss: 3.527, avg. samples / sec: 65868.50
Iteration:    500, Loss function: 6.889, Average Loss: 3.488, avg. samples / sec: 66005.63
Iteration:    500, Loss function: 7.010, Average Loss: 3.478, avg. samples / sec: 65915.73
Iteration:    500, Loss function: 8.600, Average Loss: 3.468, avg. samples / sec: 65860.74
Iteration:    500, Loss function: 5.942, Average Loss: 3.484, avg. samples / sec: 65904.78
Iteration:    500, Loss function: 5.275, Average Loss: 3.442, avg. samples / sec: 65942.00
Iteration:    500, Loss function: 5.266, Average Loss: 3.485, avg. samples / sec: 65925.04
Iteration:    500, Loss function: 5.213, Average Loss: 3.486, avg. samples / sec: 66084.12
Iteration:    500, Loss function: 6.483, Average Loss: 3.490, avg. samples / sec: 66056.12
Iteration:    500, Loss function: 7.293, Average Loss: 3.494, avg. samples / sec: 65976.70
Iteration:    500, Loss function: 5.884, Average Loss: 3.498, avg. samples / sec: 65925.93
Iteration:    500, Loss function: 6.018, Average Loss: 3.492, avg. samples / sec: 66057.05
Iteration:    500, Loss function: 6.584, Average Loss: 3.484, avg. samples / sec: 65896.34
Iteration:    500, Loss function: 6.504, Average Loss: 3.468, avg. samples / sec: 65817.19
Iteration:    520, Loss function: 6.434, Average Loss: 3.521, avg. samples / sec: 66625.89
Iteration:    520, Loss function: 6.081, Average Loss: 3.536, avg. samples / sec: 66619.15
Iteration:    520, Loss function: 5.306, Average Loss: 3.530, avg. samples / sec: 66573.71
Iteration:    520, Loss function: 6.810, Average Loss: 3.525, avg. samples / sec: 66636.03
Iteration:    520, Loss function: 6.085, Average Loss: 3.545, avg. samples / sec: 66500.67
Iteration:    520, Loss function: 5.546, Average Loss: 3.575, avg. samples / sec: 66648.54
Iteration:    520, Loss function: 6.866, Average Loss: 3.534, avg. samples / sec: 66621.10
Iteration:    520, Loss function: 6.396, Average Loss: 3.510, avg. samples / sec: 66491.16
Iteration:    520, Loss function: 6.403, Average Loss: 3.557, avg. samples / sec: 66643.66
Iteration:    520, Loss function: 6.570, Average Loss: 3.537, avg. samples / sec: 66561.51
Iteration:    520, Loss function: 5.956, Average Loss: 3.566, avg. samples / sec: 66402.37
Iteration:    520, Loss function: 5.799, Average Loss: 3.552, avg. samples / sec: 66481.59
Iteration:    520, Loss function: 7.318, Average Loss: 3.528, avg. samples / sec: 66470.40
Iteration:    520, Loss function: 5.975, Average Loss: 3.531, avg. samples / sec: 66484.32
Iteration:    520, Loss function: 6.342, Average Loss: 3.539, avg. samples / sec: 66492.20
Iteration:    520, Loss function: 5.979, Average Loss: 3.525, avg. samples / sec: 66541.24
Iteration:    520, Loss function: 5.985, Average Loss: 3.523, avg. samples / sec: 66600.80
Iteration:    520, Loss function: 6.512, Average Loss: 3.527, avg. samples / sec: 66482.13
Iteration:    520, Loss function: 6.612, Average Loss: 3.496, avg. samples / sec: 66538.44
Iteration:    520, Loss function: 5.724, Average Loss: 3.543, avg. samples / sec: 66492.04
Iteration:    520, Loss function: 5.599, Average Loss: 3.541, avg. samples / sec: 66476.64
Iteration:    520, Loss function: 5.476, Average Loss: 3.545, avg. samples / sec: 66478.65
Iteration:    520, Loss function: 5.223, Average Loss: 3.541, avg. samples / sec: 66550.60
Iteration:    520, Loss function: 6.801, Average Loss: 3.544, avg. samples / sec: 66503.59
Iteration:    520, Loss function: 5.779, Average Loss: 3.545, avg. samples / sec: 66422.91
Iteration:    520, Loss function: 7.325, Average Loss: 3.547, avg. samples / sec: 66496.06
Iteration:    520, Loss function: 6.140, Average Loss: 3.548, avg. samples / sec: 66429.26
Iteration:    520, Loss function: 5.507, Average Loss: 3.539, avg. samples / sec: 66372.26
Iteration:    520, Loss function: 6.279, Average Loss: 3.547, avg. samples / sec: 66296.35
Iteration:    520, Loss function: 5.794, Average Loss: 3.539, avg. samples / sec: 66239.21
Iteration:    540, Loss function: 6.494, Average Loss: 3.587, avg. samples / sec: 66396.90
Iteration:    540, Loss function: 6.729, Average Loss: 3.580, avg. samples / sec: 66399.78
Iteration:    540, Loss function: 6.266, Average Loss: 3.607, avg. samples / sec: 66491.07
Iteration:    540, Loss function: 6.589, Average Loss: 3.572, avg. samples / sec: 66355.10
Iteration:    540, Loss function: 6.973, Average Loss: 3.562, avg. samples / sec: 66453.19
Iteration:    540, Loss function: 6.452, Average Loss: 3.594, avg. samples / sec: 66490.91
Iteration:    540, Loss function: 6.918, Average Loss: 3.597, avg. samples / sec: 66599.57
Iteration:    540, Loss function: 7.868, Average Loss: 3.582, avg. samples / sec: 66478.49
Iteration:    540, Loss function: 6.235, Average Loss: 3.592, avg. samples / sec: 66358.32
Iteration:    540, Loss function: 5.878, Average Loss: 3.601, avg. samples / sec: 66602.15
Iteration:    540, Loss function: 7.190, Average Loss: 3.603, avg. samples / sec: 66611.75
Iteration:    540, Loss function: 7.105, Average Loss: 3.584, avg. samples / sec: 66468.27
Iteration:    540, Loss function: 6.582, Average Loss: 3.585, avg. samples / sec: 66531.50
Iteration:    540, Loss function: 8.059, Average Loss: 3.611, avg. samples / sec: 66373.35
Iteration:    540, Loss function: 6.608, Average Loss: 3.574, avg. samples / sec: 66465.92
Iteration:    540, Loss function: 5.670, Average Loss: 3.595, avg. samples / sec: 66373.23
Iteration:    540, Loss function: 5.832, Average Loss: 3.624, avg. samples / sec: 66326.62
Iteration:    540, Loss function: 6.522, Average Loss: 3.582, avg. samples / sec: 66420.84
Iteration:    540, Loss function: 6.588, Average Loss: 3.579, avg. samples / sec: 66247.55
Iteration:    540, Loss function: 6.001, Average Loss: 3.601, avg. samples / sec: 66534.64
Iteration:    540, Loss function: 6.460, Average Loss: 3.595, avg. samples / sec: 66534.26
Iteration:    540, Loss function: 7.119, Average Loss: 3.593, avg. samples / sec: 66486.68
Iteration:    540, Loss function: 5.743, Average Loss: 3.618, avg. samples / sec: 66366.26
Iteration:    540, Loss function: 6.883, Average Loss: 3.592, avg. samples / sec: 66625.20
Iteration:    540, Loss function: 7.908, Average Loss: 3.596, avg. samples / sec: 66448.15
Iteration:    540, Loss function: 6.038, Average Loss: 3.598, avg. samples / sec: 66453.88
Iteration:    540, Loss function: 6.637, Average Loss: 3.593, avg. samples / sec: 66436.87
Iteration:    540, Loss function: 6.344, Average Loss: 3.579, avg. samples / sec: 66384.64
Iteration:    540, Loss function: 5.549, Average Loss: 3.587, avg. samples / sec: 66230.27
Iteration:    540, Loss function: 6.969, Average Loss: 3.551, avg. samples / sec: 66333.83
:::MLL 1558651204.220 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1558651204.220 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 5.242, Average Loss: 3.644, avg. samples / sec: 65807.07
Iteration:    560, Loss function: 5.948, Average Loss: 3.662, avg. samples / sec: 65768.35
Iteration:    560, Loss function: 7.321, Average Loss: 3.612, avg. samples / sec: 65967.47
Iteration:    560, Loss function: 4.603, Average Loss: 3.650, avg. samples / sec: 65853.42
Iteration:    560, Loss function: 6.677, Average Loss: 3.659, avg. samples / sec: 65780.47
Iteration:    560, Loss function: 6.821, Average Loss: 3.626, avg. samples / sec: 65714.13
Iteration:    560, Loss function: 4.767, Average Loss: 3.635, avg. samples / sec: 65694.74
Iteration:    560, Loss function: 5.867, Average Loss: 3.650, avg. samples / sec: 65719.34
Iteration:    560, Loss function: 6.576, Average Loss: 3.656, avg. samples / sec: 65834.59
Iteration:    560, Loss function: 5.113, Average Loss: 3.654, avg. samples / sec: 65806.86
Iteration:    560, Loss function: 5.635, Average Loss: 3.638, avg. samples / sec: 65887.50
Iteration:    560, Loss function: 5.223, Average Loss: 3.637, avg. samples / sec: 65754.51
Iteration:    560, Loss function: 6.442, Average Loss: 3.642, avg. samples / sec: 65627.10
Iteration:    560, Loss function: 5.755, Average Loss: 3.677, avg. samples / sec: 65763.01
Iteration:    560, Loss function: 5.898, Average Loss: 3.668, avg. samples / sec: 65726.23
Iteration:    560, Loss function: 4.976, Average Loss: 3.640, avg. samples / sec: 65708.83
Iteration:    560, Loss function: 5.282, Average Loss: 3.650, avg. samples / sec: 65732.27
Iteration:    560, Loss function: 6.488, Average Loss: 3.650, avg. samples / sec: 65649.45
Iteration:    560, Loss function: 6.236, Average Loss: 3.635, avg. samples / sec: 65733.22
Iteration:    560, Loss function: 6.327, Average Loss: 3.642, avg. samples / sec: 65717.41
Iteration:    560, Loss function: 5.429, Average Loss: 3.651, avg. samples / sec: 65729.09
Iteration:    560, Loss function: 5.035, Average Loss: 3.651, avg. samples / sec: 65754.42
Iteration:    560, Loss function: 7.034, Average Loss: 3.636, avg. samples / sec: 65756.78
Iteration:    560, Loss function: 6.504, Average Loss: 3.616, avg. samples / sec: 65592.00
Iteration:    560, Loss function: 6.355, Average Loss: 3.676, avg. samples / sec: 65700.34
Iteration:    560, Loss function: 5.874, Average Loss: 3.643, avg. samples / sec: 65646.08
Iteration:    560, Loss function: 5.791, Average Loss: 3.634, avg. samples / sec: 65608.98
Iteration:    560, Loss function: 5.148, Average Loss: 3.651, avg. samples / sec: 65674.84
Iteration:    560, Loss function: 7.337, Average Loss: 3.659, avg. samples / sec: 65606.84
Iteration:    560, Loss function: 5.965, Average Loss: 3.650, avg. samples / sec: 65535.76
Iteration:    580, Loss function: 6.171, Average Loss: 3.676, avg. samples / sec: 65432.00
Iteration:    580, Loss function: 6.036, Average Loss: 3.682, avg. samples / sec: 65569.79
Iteration:    580, Loss function: 5.317, Average Loss: 3.661, avg. samples / sec: 65403.97
Iteration:    580, Loss function: 6.377, Average Loss: 3.679, avg. samples / sec: 65390.07
Iteration:    580, Loss function: 6.447, Average Loss: 3.711, avg. samples / sec: 65304.29
Iteration:    580, Loss function: 5.670, Average Loss: 3.703, avg. samples / sec: 65297.75
Iteration:    580, Loss function: 6.256, Average Loss: 3.703, avg. samples / sec: 65375.45
Iteration:    580, Loss function: 5.752, Average Loss: 3.727, avg. samples / sec: 65464.92
Iteration:    580, Loss function: 5.704, Average Loss: 3.691, avg. samples / sec: 65263.19
Iteration:    580, Loss function: 5.504, Average Loss: 3.695, avg. samples / sec: 65632.90
Iteration:    580, Loss function: 5.757, Average Loss: 3.696, avg. samples / sec: 65428.08
Iteration:    580, Loss function: 6.024, Average Loss: 3.677, avg. samples / sec: 65400.81
Iteration:    580, Loss function: 6.031, Average Loss: 3.700, avg. samples / sec: 65393.68
Iteration:    580, Loss function: 6.166, Average Loss: 3.687, avg. samples / sec: 65364.99
Iteration:    580, Loss function: 5.410, Average Loss: 3.715, avg. samples / sec: 65357.20
Iteration:    580, Loss function: 6.119, Average Loss: 3.659, avg. samples / sec: 65407.04
Iteration:    580, Loss function: 6.395, Average Loss: 3.686, avg. samples / sec: 65307.89
Iteration:    580, Loss function: 6.688, Average Loss: 3.707, avg. samples / sec: 65238.54
Iteration:    580, Loss function: 5.908, Average Loss: 3.700, avg. samples / sec: 65382.76
Iteration:    580, Loss function: 5.679, Average Loss: 3.703, avg. samples / sec: 65414.05
Iteration:    580, Loss function: 6.601, Average Loss: 3.726, avg. samples / sec: 65250.80
Iteration:    580, Loss function: 5.161, Average Loss: 3.700, avg. samples / sec: 65311.85
Iteration:    580, Loss function: 6.405, Average Loss: 3.699, avg. samples / sec: 65302.05
Iteration:    580, Loss function: 6.694, Average Loss: 3.688, avg. samples / sec: 65322.03
Iteration:    580, Loss function: 4.896, Average Loss: 3.700, avg. samples / sec: 65284.53
Iteration:    580, Loss function: 5.908, Average Loss: 3.693, avg. samples / sec: 65294.03
Iteration:    580, Loss function: 5.124, Average Loss: 3.701, avg. samples / sec: 65211.52
Iteration:    580, Loss function: 5.174, Average Loss: 3.680, avg. samples / sec: 65179.52
Iteration:    580, Loss function: 6.495, Average Loss: 3.693, avg. samples / sec: 65130.00
Iteration:    580, Loss function: 6.172, Average Loss: 3.688, avg. samples / sec: 65105.45
Iteration:    600, Loss function: 6.784, Average Loss: 3.728, avg. samples / sec: 66006.89
Iteration:    600, Loss function: 6.790, Average Loss: 3.710, avg. samples / sec: 66150.13
Iteration:    600, Loss function: 6.937, Average Loss: 3.725, avg. samples / sec: 66048.44
Iteration:    600, Loss function: 6.125, Average Loss: 3.711, avg. samples / sec: 65910.92
Iteration:    600, Loss function: 5.361, Average Loss: 3.744, avg. samples / sec: 66225.70
Iteration:    600, Loss function: 5.116, Average Loss: 3.720, avg. samples / sec: 65868.04
Iteration:    600, Loss function: 6.161, Average Loss: 3.773, avg. samples / sec: 66096.15
Iteration:    600, Loss function: 6.130, Average Loss: 3.749, avg. samples / sec: 65950.40
Iteration:    600, Loss function: 5.439, Average Loss: 3.749, avg. samples / sec: 66112.33
Iteration:    600, Loss function: 5.847, Average Loss: 3.752, avg. samples / sec: 65939.41
Iteration:    600, Loss function: 6.644, Average Loss: 3.757, avg. samples / sec: 65929.85
Iteration:    600, Loss function: 5.919, Average Loss: 3.734, avg. samples / sec: 65968.43
Iteration:    600, Loss function: 6.024, Average Loss: 3.732, avg. samples / sec: 65880.01
Iteration:    600, Loss function: 6.186, Average Loss: 3.728, avg. samples / sec: 66001.67
Iteration:    600, Loss function: 5.971, Average Loss: 3.742, avg. samples / sec: 66085.05
Iteration:    600, Loss function: 6.540, Average Loss: 3.760, avg. samples / sec: 65966.91
Iteration:    600, Loss function: 6.094, Average Loss: 3.746, avg. samples / sec: 66047.05
Iteration:    600, Loss function: 6.036, Average Loss: 3.739, avg. samples / sec: 65934.85
Iteration:    600, Loss function: 5.585, Average Loss: 3.771, avg. samples / sec: 65913.60
Iteration:    600, Loss function: 6.556, Average Loss: 3.747, avg. samples / sec: 65993.94
Iteration:    600, Loss function: 6.023, Average Loss: 3.756, avg. samples / sec: 65975.78
Iteration:    600, Loss function: 6.476, Average Loss: 3.749, avg. samples / sec: 65923.31
Iteration:    600, Loss function: 5.129, Average Loss: 3.740, avg. samples / sec: 65951.08
Iteration:    600, Loss function: 5.345, Average Loss: 3.737, avg. samples / sec: 66142.58
Iteration:    600, Loss function: 4.963, Average Loss: 3.733, avg. samples / sec: 66005.47
Iteration:    600, Loss function: 6.406, Average Loss: 3.728, avg. samples / sec: 66048.94
Iteration:    600, Loss function: 7.830, Average Loss: 3.740, avg. samples / sec: 65990.45
Iteration:    600, Loss function: 7.083, Average Loss: 3.745, avg. samples / sec: 65867.82
Iteration:    600, Loss function: 5.583, Average Loss: 3.736, avg. samples / sec: 65807.87
Iteration:    600, Loss function: 8.416, Average Loss: 3.747, avg. samples / sec: 65930.31
Iteration:    620, Loss function: 5.880, Average Loss: 3.780, avg. samples / sec: 66487.40
Iteration:    620, Loss function: 7.519, Average Loss: 3.818, avg. samples / sec: 66416.05
Iteration:    620, Loss function: 6.068, Average Loss: 3.789, avg. samples / sec: 66403.28
Iteration:    620, Loss function: 6.013, Average Loss: 3.762, avg. samples / sec: 66381.11
Iteration:    620, Loss function: 4.609, Average Loss: 3.755, avg. samples / sec: 66327.06
Iteration:    620, Loss function: 6.553, Average Loss: 3.782, avg. samples / sec: 66469.62
Iteration:    620, Loss function: 4.956, Average Loss: 3.776, avg. samples / sec: 66532.03
Iteration:    620, Loss function: 5.801, Average Loss: 3.771, avg. samples / sec: 66208.55
Iteration:    620, Loss function: 5.784, Average Loss: 3.797, avg. samples / sec: 66398.65
Iteration:    620, Loss function: 5.793, Average Loss: 3.782, avg. samples / sec: 66363.54
Iteration:    620, Loss function: 5.680, Average Loss: 3.795, avg. samples / sec: 66315.79
Iteration:    620, Loss function: 5.667, Average Loss: 3.784, avg. samples / sec: 66259.82
Iteration:    620, Loss function: 6.136, Average Loss: 3.791, avg. samples / sec: 66333.36
Iteration:    620, Loss function: 5.685, Average Loss: 3.805, avg. samples / sec: 66336.99
Iteration:    620, Loss function: 7.130, Average Loss: 3.789, avg. samples / sec: 66348.79
Iteration:    620, Loss function: 5.931, Average Loss: 3.799, avg. samples / sec: 66292.99
Iteration:    620, Loss function: 6.819, Average Loss: 3.754, avg. samples / sec: 66137.83
Iteration:    620, Loss function: 5.468, Average Loss: 3.766, avg. samples / sec: 66219.69
Iteration:    620, Loss function: 6.409, Average Loss: 3.779, avg. samples / sec: 66368.04
Iteration:    620, Loss function: 5.477, Average Loss: 3.793, avg. samples / sec: 66342.36
Iteration:    620, Loss function: 6.150, Average Loss: 3.776, avg. samples / sec: 66281.26
Iteration:    620, Loss function: 5.081, Average Loss: 3.790, avg. samples / sec: 66268.95
Iteration:    620, Loss function: 6.847, Average Loss: 3.798, avg. samples / sec: 66241.14
Iteration:    620, Loss function: 5.644, Average Loss: 3.770, avg. samples / sec: 66272.41
Iteration:    620, Loss function: 6.532, Average Loss: 3.771, avg. samples / sec: 66317.57
Iteration:    620, Loss function: 5.388, Average Loss: 3.805, avg. samples / sec: 66248.11
Iteration:    620, Loss function: 6.681, Average Loss: 3.791, avg. samples / sec: 66360.10
Iteration:    620, Loss function: 4.900, Average Loss: 3.782, avg. samples / sec: 66293.39
Iteration:    620, Loss function: 5.527, Average Loss: 3.789, avg. samples / sec: 66323.25
Iteration:    620, Loss function: 6.683, Average Loss: 3.783, avg. samples / sec: 66293.80
:::MLL 1558651206.004 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1558651206.005 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    640, Loss function: 4.656, Average Loss: 3.824, avg. samples / sec: 66129.14
Iteration:    640, Loss function: 5.996, Average Loss: 3.800, avg. samples / sec: 65976.67
Iteration:    640, Loss function: 6.875, Average Loss: 3.804, avg. samples / sec: 66058.10
Iteration:    640, Loss function: 4.855, Average Loss: 3.793, avg. samples / sec: 65953.18
Iteration:    640, Loss function: 5.870, Average Loss: 3.797, avg. samples / sec: 66052.22
Iteration:    640, Loss function: 5.659, Average Loss: 3.835, avg. samples / sec: 65985.66
Iteration:    640, Loss function: 5.613, Average Loss: 3.858, avg. samples / sec: 65871.91
Iteration:    640, Loss function: 4.702, Average Loss: 3.808, avg. samples / sec: 66037.82
Iteration:    640, Loss function: 5.731, Average Loss: 3.813, avg. samples / sec: 66031.48
Iteration:    640, Loss function: 5.377, Average Loss: 3.842, avg. samples / sec: 66081.02
Iteration:    640, Loss function: 5.545, Average Loss: 3.826, avg. samples / sec: 66080.37
Iteration:    640, Loss function: 5.527, Average Loss: 3.818, avg. samples / sec: 65802.10
Iteration:    640, Loss function: 4.834, Average Loss: 3.834, avg. samples / sec: 65976.36
Iteration:    640, Loss function: 6.432, Average Loss: 3.822, avg. samples / sec: 65894.21
Iteration:    640, Loss function: 5.545, Average Loss: 3.822, avg. samples / sec: 65877.18
Iteration:    640, Loss function: 4.986, Average Loss: 3.820, avg. samples / sec: 65990.88
Iteration:    640, Loss function: 5.136, Average Loss: 3.833, avg. samples / sec: 65969.20
Iteration:    640, Loss function: 6.367, Average Loss: 3.821, avg. samples / sec: 65918.87
Iteration:    640, Loss function: 6.324, Average Loss: 3.831, avg. samples / sec: 65939.17
Iteration:    640, Loss function: 5.953, Average Loss: 3.847, avg. samples / sec: 65958.67
Iteration:    640, Loss function: 5.064, Average Loss: 3.836, avg. samples / sec: 65980.16
Iteration:    640, Loss function: 6.492, Average Loss: 3.840, avg. samples / sec: 65895.54
Iteration:    640, Loss function: 5.334, Average Loss: 3.809, avg. samples / sec: 65873.98
Iteration:    640, Loss function: 5.024, Average Loss: 3.830, avg. samples / sec: 66024.68
Iteration:    640, Loss function: 5.546, Average Loss: 3.820, avg. samples / sec: 66014.47
Iteration:    640, Loss function: 5.078, Average Loss: 3.827, avg. samples / sec: 65898.19
Iteration:    640, Loss function: 5.525, Average Loss: 3.828, avg. samples / sec: 65867.36
Iteration:    640, Loss function: 5.303, Average Loss: 3.832, avg. samples / sec: 65727.25
Iteration:    640, Loss function: 5.715, Average Loss: 3.810, avg. samples / sec: 65898.53
Iteration:    640, Loss function: 6.237, Average Loss: 3.829, avg. samples / sec: 65902.38
Iteration:    660, Loss function: 6.892, Average Loss: 3.840, avg. samples / sec: 66411.32
Iteration:    660, Loss function: 5.481, Average Loss: 3.828, avg. samples / sec: 66465.82
Iteration:    660, Loss function: 6.960, Average Loss: 3.859, avg. samples / sec: 66484.32
Iteration:    660, Loss function: 5.598, Average Loss: 3.851, avg. samples / sec: 66481.09
Iteration:    660, Loss function: 4.929, Average Loss: 3.829, avg. samples / sec: 66428.54
Iteration:    660, Loss function: 5.460, Average Loss: 3.858, avg. samples / sec: 66510.59
Iteration:    660, Loss function: 5.971, Average Loss: 3.874, avg. samples / sec: 66493.98
Iteration:    660, Loss function: 6.537, Average Loss: 3.877, avg. samples / sec: 66615.09
Iteration:    660, Loss function: 6.967, Average Loss: 3.880, avg. samples / sec: 66522.01
Iteration:    660, Loss function: 5.355, Average Loss: 3.848, avg. samples / sec: 66523.21
Iteration:    660, Loss function: 6.955, Average Loss: 3.857, avg. samples / sec: 66478.80
Iteration:    660, Loss function: 5.171, Average Loss: 3.870, avg. samples / sec: 66521.67
Iteration:    660, Loss function: 6.847, Average Loss: 3.843, avg. samples / sec: 66387.08
Iteration:    660, Loss function: 4.983, Average Loss: 3.889, avg. samples / sec: 66425.13
Iteration:    660, Loss function: 5.872, Average Loss: 3.863, avg. samples / sec: 66449.59
Iteration:    660, Loss function: 5.295, Average Loss: 3.853, avg. samples / sec: 66411.42
Iteration:    660, Loss function: 5.951, Average Loss: 3.879, avg. samples / sec: 66446.68
Iteration:    660, Loss function: 3.660, Average Loss: 3.864, avg. samples / sec: 66497.53
Iteration:    660, Loss function: 5.671, Average Loss: 3.889, avg. samples / sec: 66413.92
Iteration:    660, Loss function: 5.344, Average Loss: 3.857, avg. samples / sec: 66391.02
Iteration:    660, Loss function: 6.266, Average Loss: 3.870, avg. samples / sec: 66394.93
Iteration:    660, Loss function: 6.403, Average Loss: 3.870, avg. samples / sec: 66546.04
Iteration:    660, Loss function: 5.188, Average Loss: 3.865, avg. samples / sec: 66384.70
Iteration:    660, Loss function: 6.422, Average Loss: 3.861, avg. samples / sec: 66239.70
Iteration:    660, Loss function: 5.901, Average Loss: 3.860, avg. samples / sec: 66353.91
Iteration:    660, Loss function: 5.351, Average Loss: 3.874, avg. samples / sec: 66304.59
Iteration:    660, Loss function: 5.262, Average Loss: 3.851, avg. samples / sec: 66509.24
Iteration:    660, Loss function: 5.545, Average Loss: 3.856, avg. samples / sec: 66367.82
Iteration:    660, Loss function: 5.431, Average Loss: 3.866, avg. samples / sec: 66345.20
Iteration:    660, Loss function: 5.837, Average Loss: 3.880, avg. samples / sec: 66216.77
Iteration:    680, Loss function: 6.844, Average Loss: 3.895, avg. samples / sec: 66871.06
Iteration:    680, Loss function: 5.491, Average Loss: 3.902, avg. samples / sec: 66937.19
Iteration:    680, Loss function: 7.724, Average Loss: 3.908, avg. samples / sec: 66851.20
Iteration:    680, Loss function: 5.012, Average Loss: 3.883, avg. samples / sec: 66725.04
Iteration:    680, Loss function: 6.323, Average Loss: 3.907, avg. samples / sec: 66809.40
Iteration:    680, Loss function: 6.177, Average Loss: 3.916, avg. samples / sec: 66699.65
Iteration:    680, Loss function: 7.043, Average Loss: 3.894, avg. samples / sec: 66866.49
Iteration:    680, Loss function: 7.079, Average Loss: 3.916, avg. samples / sec: 66648.13
Iteration:    680, Loss function: 6.072, Average Loss: 3.893, avg. samples / sec: 66632.13
Iteration:    680, Loss function: 4.898, Average Loss: 3.913, avg. samples / sec: 66704.29
Iteration:    680, Loss function: 5.659, Average Loss: 3.883, avg. samples / sec: 66591.35
Iteration:    680, Loss function: 6.367, Average Loss: 3.901, avg. samples / sec: 66609.07
Iteration:    680, Loss function: 7.344, Average Loss: 3.888, avg. samples / sec: 66624.85
Iteration:    680, Loss function: 7.053, Average Loss: 3.908, avg. samples / sec: 66616.10
Iteration:    680, Loss function: 6.403, Average Loss: 3.926, avg. samples / sec: 66695.98
Iteration:    680, Loss function: 5.570, Average Loss: 3.892, avg. samples / sec: 66605.30
Iteration:    680, Loss function: 6.630, Average Loss: 3.899, avg. samples / sec: 66728.39
Iteration:    680, Loss function: 4.708, Average Loss: 3.928, avg. samples / sec: 66601.11
Iteration:    680, Loss function: 5.051, Average Loss: 3.869, avg. samples / sec: 66530.30
Iteration:    680, Loss function: 6.125, Average Loss: 3.902, avg. samples / sec: 66591.73
Iteration:    680, Loss function: 5.217, Average Loss: 3.897, avg. samples / sec: 66686.93
Iteration:    680, Loss function: 5.721, Average Loss: 3.903, avg. samples / sec: 66655.73
Iteration:    680, Loss function: 5.963, Average Loss: 3.903, avg. samples / sec: 66521.82
Iteration:    680, Loss function: 6.237, Average Loss: 3.920, avg. samples / sec: 66526.50
Iteration:    680, Loss function: 5.747, Average Loss: 3.919, avg. samples / sec: 66736.22
Iteration:    680, Loss function: 6.265, Average Loss: 3.891, avg. samples / sec: 66540.36
Iteration:    680, Loss function: 5.899, Average Loss: 3.869, avg. samples / sec: 66466.89
Iteration:    680, Loss function: 5.927, Average Loss: 3.913, avg. samples / sec: 66622.17
Iteration:    680, Loss function: 5.653, Average Loss: 3.892, avg. samples / sec: 66618.87
Iteration:    680, Loss function: 4.773, Average Loss: 3.909, avg. samples / sec: 66532.66
:::MLL 1558651207.785 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1558651207.785 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    700, Loss function: 5.677, Average Loss: 3.922, avg. samples / sec: 65326.72
Iteration:    700, Loss function: 5.348, Average Loss: 3.969, avg. samples / sec: 65340.11
Iteration:    700, Loss function: 6.104, Average Loss: 3.949, avg. samples / sec: 65251.13
Iteration:    700, Loss function: 5.756, Average Loss: 3.926, avg. samples / sec: 65425.28
Iteration:    700, Loss function: 5.684, Average Loss: 3.909, avg. samples / sec: 65409.92
Iteration:    700, Loss function: 6.161, Average Loss: 3.901, avg. samples / sec: 65321.78
Iteration:    700, Loss function: 6.758, Average Loss: 3.962, avg. samples / sec: 65288.22
Iteration:    700, Loss function: 5.736, Average Loss: 3.938, avg. samples / sec: 65166.35
Iteration:    700, Loss function: 5.433, Average Loss: 3.950, avg. samples / sec: 65256.00
Iteration:    700, Loss function: 5.504, Average Loss: 3.942, avg. samples / sec: 65211.40
Iteration:    700, Loss function: 5.689, Average Loss: 3.956, avg. samples / sec: 65180.27
Iteration:    700, Loss function: 5.055, Average Loss: 3.932, avg. samples / sec: 65223.89
Iteration:    700, Loss function: 6.588, Average Loss: 3.941, avg. samples / sec: 65325.51
Iteration:    700, Loss function: 5.472, Average Loss: 3.939, avg. samples / sec: 65235.61
Iteration:    700, Loss function: 7.221, Average Loss: 3.924, avg. samples / sec: 65136.59
Iteration:    700, Loss function: 5.422, Average Loss: 3.923, avg. samples / sec: 65232.59
Iteration:    700, Loss function: 5.480, Average Loss: 3.957, avg. samples / sec: 65301.93
Iteration:    700, Loss function: 5.761, Average Loss: 3.939, avg. samples / sec: 65107.91
Iteration:    700, Loss function: 6.025, Average Loss: 3.934, avg. samples / sec: 65224.56
Iteration:    700, Loss function: 4.960, Average Loss: 3.930, avg. samples / sec: 65320.88
Iteration:    700, Loss function: 5.943, Average Loss: 3.959, avg. samples / sec: 65285.14
Iteration:    700, Loss function: 6.696, Average Loss: 3.944, avg. samples / sec: 65152.34
Iteration:    700, Loss function: 6.152, Average Loss: 3.947, avg. samples / sec: 65032.23
Iteration:    700, Loss function: 5.914, Average Loss: 3.933, avg. samples / sec: 65146.47
Iteration:    700, Loss function: 5.742, Average Loss: 3.945, avg. samples / sec: 65327.36
Iteration:    700, Loss function: 6.446, Average Loss: 3.933, avg. samples / sec: 65183.26
Iteration:    700, Loss function: 5.936, Average Loss: 3.931, avg. samples / sec: 65025.09
Iteration:    700, Loss function: 5.188, Average Loss: 3.943, avg. samples / sec: 65151.13
Iteration:    700, Loss function: 6.377, Average Loss: 3.940, avg. samples / sec: 65092.48
Iteration:    700, Loss function: 5.589, Average Loss: 3.952, avg. samples / sec: 65161.62
Iteration:    720, Loss function: 5.574, Average Loss: 3.971, avg. samples / sec: 66538.16
Iteration:    720, Loss function: 6.146, Average Loss: 3.987, avg. samples / sec: 66459.55
Iteration:    720, Loss function: 5.713, Average Loss: 3.973, avg. samples / sec: 66667.46
Iteration:    720, Loss function: 5.764, Average Loss: 3.956, avg. samples / sec: 66480.34
Iteration:    720, Loss function: 5.839, Average Loss: 3.965, avg. samples / sec: 66520.03
Iteration:    720, Loss function: 5.127, Average Loss: 3.946, avg. samples / sec: 66405.69
Iteration:    720, Loss function: 5.421, Average Loss: 3.959, avg. samples / sec: 66461.31
Iteration:    720, Loss function: 4.814, Average Loss: 3.958, avg. samples / sec: 66510.90
Iteration:    720, Loss function: 5.638, Average Loss: 4.002, avg. samples / sec: 66370.95
Iteration:    720, Loss function: 5.470, Average Loss: 3.988, avg. samples / sec: 66426.38
Iteration:    720, Loss function: 6.374, Average Loss: 3.978, avg. samples / sec: 66570.28
Iteration:    720, Loss function: 4.673, Average Loss: 3.963, avg. samples / sec: 66546.55
Iteration:    720, Loss function: 4.143, Average Loss: 3.969, avg. samples / sec: 66415.42
Iteration:    720, Loss function: 5.087, Average Loss: 3.992, avg. samples / sec: 66378.35
Iteration:    720, Loss function: 5.917, Average Loss: 3.974, avg. samples / sec: 66388.74
Iteration:    720, Loss function: 4.274, Average Loss: 3.934, avg. samples / sec: 66380.36
Iteration:    720, Loss function: 4.703, Average Loss: 3.980, avg. samples / sec: 66502.36
Iteration:    720, Loss function: 5.023, Average Loss: 3.966, avg. samples / sec: 66352.73
Iteration:    720, Loss function: 5.695, Average Loss: 3.957, avg. samples / sec: 66266.09
Iteration:    720, Loss function: 4.617, Average Loss: 3.997, avg. samples / sec: 66458.77
Iteration:    720, Loss function: 6.052, Average Loss: 3.990, avg. samples / sec: 66335.14
Iteration:    720, Loss function: 5.571, Average Loss: 3.989, avg. samples / sec: 66598.94
Iteration:    720, Loss function: 6.082, Average Loss: 3.977, avg. samples / sec: 66533.41
Iteration:    720, Loss function: 5.793, Average Loss: 3.967, avg. samples / sec: 66448.18
Iteration:    720, Loss function: 5.376, Average Loss: 3.961, avg. samples / sec: 66277.90
Iteration:    720, Loss function: 5.371, Average Loss: 3.964, avg. samples / sec: 66315.67
Iteration:    720, Loss function: 4.326, Average Loss: 3.959, avg. samples / sec: 66479.90
Iteration:    720, Loss function: 5.736, Average Loss: 3.986, avg. samples / sec: 66342.83
Iteration:    720, Loss function: 5.785, Average Loss: 3.982, avg. samples / sec: 66326.03
Iteration:    720, Loss function: 6.526, Average Loss: 3.978, avg. samples / sec: 66304.56
Iteration:    740, Loss function: 4.884, Average Loss: 4.022, avg. samples / sec: 66592.83
Iteration:    740, Loss function: 6.601, Average Loss: 4.013, avg. samples / sec: 66697.66
Iteration:    740, Loss function: 5.127, Average Loss: 4.025, avg. samples / sec: 66536.33
Iteration:    740, Loss function: 5.058, Average Loss: 3.998, avg. samples / sec: 66422.59
Iteration:    740, Loss function: 4.517, Average Loss: 3.999, avg. samples / sec: 66557.29
Iteration:    740, Loss function: 6.093, Average Loss: 3.988, avg. samples / sec: 66602.34
Iteration:    740, Loss function: 5.585, Average Loss: 4.018, avg. samples / sec: 66432.55
Iteration:    740, Loss function: 6.063, Average Loss: 3.989, avg. samples / sec: 66480.65
Iteration:    740, Loss function: 5.576, Average Loss: 3.998, avg. samples / sec: 66571.73
Iteration:    740, Loss function: 4.157, Average Loss: 4.015, avg. samples / sec: 66566.41
Iteration:    740, Loss function: 5.304, Average Loss: 3.990, avg. samples / sec: 66473.38
Iteration:    740, Loss function: 5.879, Average Loss: 3.992, avg. samples / sec: 66498.35
Iteration:    740, Loss function: 5.048, Average Loss: 3.971, avg. samples / sec: 66484.95
Iteration:    740, Loss function: 4.684, Average Loss: 4.009, avg. samples / sec: 66477.11
Iteration:    740, Loss function: 5.005, Average Loss: 4.023, avg. samples / sec: 66549.25
Iteration:    740, Loss function: 5.932, Average Loss: 3.964, avg. samples / sec: 66490.75
Iteration:    740, Loss function: 5.103, Average Loss: 3.991, avg. samples / sec: 66572.64
Iteration:    740, Loss function: 5.434, Average Loss: 4.029, avg. samples / sec: 66504.94
Iteration:    740, Loss function: 4.747, Average Loss: 4.031, avg. samples / sec: 66429.79
Iteration:    740, Loss function: 5.895, Average Loss: 4.009, avg. samples / sec: 66463.60
Iteration:    740, Loss function: 5.924, Average Loss: 3.995, avg. samples / sec: 66521.32
Iteration:    740, Loss function: 6.165, Average Loss: 3.997, avg. samples / sec: 66354.23
Iteration:    740, Loss function: 6.209, Average Loss: 3.992, avg. samples / sec: 66506.82
Iteration:    740, Loss function: 6.010, Average Loss: 4.019, avg. samples / sec: 66533.82
Iteration:    740, Loss function: 6.030, Average Loss: 3.986, avg. samples / sec: 66472.81
Iteration:    740, Loss function: 6.447, Average Loss: 3.990, avg. samples / sec: 66362.32
Iteration:    740, Loss function: 6.137, Average Loss: 4.007, avg. samples / sec: 66414.23
Iteration:    740, Loss function: 5.818, Average Loss: 4.005, avg. samples / sec: 66289.90
Iteration:    740, Loss function: 5.135, Average Loss: 4.004, avg. samples / sec: 66521.45
Iteration:    740, Loss function: 5.270, Average Loss: 4.007, avg. samples / sec: 66080.65
Iteration:    760, Loss function: 5.319, Average Loss: 4.024, avg. samples / sec: 66281.39
Iteration:    760, Loss function: 5.816, Average Loss: 4.031, avg. samples / sec: 66241.23
Iteration:    760, Loss function: 5.359, Average Loss: 4.059, avg. samples / sec: 66326.81
Iteration:    760, Loss function: 6.112, Average Loss: 4.041, avg. samples / sec: 66266.55
Iteration:    760, Loss function: 5.794, Average Loss: 4.000, avg. samples / sec: 66289.56
Iteration:    760, Loss function: 4.920, Average Loss: 4.050, avg. samples / sec: 66364.98
Iteration:    760, Loss function: 3.543, Average Loss: 4.019, avg. samples / sec: 66277.24
Iteration:    760, Loss function: 6.688, Average Loss: 4.033, avg. samples / sec: 66213.10
Iteration:    760, Loss function: 6.014, Average Loss: 3.999, avg. samples / sec: 66278.21
Iteration:    760, Loss function: 6.228, Average Loss: 4.042, avg. samples / sec: 66174.05
Iteration:    760, Loss function: 5.749, Average Loss: 4.035, avg. samples / sec: 66405.47
Iteration:    760, Loss function: 4.988, Average Loss: 4.026, avg. samples / sec: 66226.51
Iteration:    760, Loss function: 4.998, Average Loss: 4.054, avg. samples / sec: 66230.55
Iteration:    760, Loss function: 5.897, Average Loss: 4.019, avg. samples / sec: 66158.92
Iteration:    760, Loss function: 6.232, Average Loss: 4.029, avg. samples / sec: 66194.31
Iteration:    760, Loss function: 5.708, Average Loss: 4.027, avg. samples / sec: 66301.88
Iteration:    760, Loss function: 4.929, Average Loss: 4.052, avg. samples / sec: 66159.48
Iteration:    760, Loss function: 5.634, Average Loss: 4.048, avg. samples / sec: 66147.64
Iteration:    760, Loss function: 5.357, Average Loss: 4.020, avg. samples / sec: 66318.63
Iteration:    760, Loss function: 4.669, Average Loss: 4.012, avg. samples / sec: 66305.24
Iteration:    760, Loss function: 6.524, Average Loss: 4.035, avg. samples / sec: 66393.99
Iteration:    760, Loss function: 4.724, Average Loss: 4.020, avg. samples / sec: 66214.59
Iteration:    760, Loss function: 5.999, Average Loss: 4.061, avg. samples / sec: 66247.36
Iteration:    760, Loss function: 6.268, Average Loss: 4.035, avg. samples / sec: 66245.46
Iteration:    760, Loss function: 5.586, Average Loss: 4.029, avg. samples / sec: 66266.18
Iteration:    760, Loss function: 5.316, Average Loss: 4.036, avg. samples / sec: 66169.01
Iteration:    760, Loss function: 4.976, Average Loss: 4.048, avg. samples / sec: 66114.72
Iteration:    760, Loss function: 5.786, Average Loss: 4.028, avg. samples / sec: 66173.49
Iteration:    760, Loss function: 4.971, Average Loss: 4.031, avg. samples / sec: 66230.89
Iteration:    760, Loss function: 5.561, Average Loss: 4.036, avg. samples / sec: 66476.51
:::MLL 1558651209.561 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1558651209.562 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    780, Loss function: 5.068, Average Loss: 4.032, avg. samples / sec: 65726.94
Iteration:    780, Loss function: 4.176, Average Loss: 4.061, avg. samples / sec: 65796.01
Iteration:    780, Loss function: 5.048, Average Loss: 4.055, avg. samples / sec: 65774.76
Iteration:    780, Loss function: 6.939, Average Loss: 4.051, avg. samples / sec: 65701.84
Iteration:    780, Loss function: 6.265, Average Loss: 4.071, avg. samples / sec: 65684.45
Iteration:    780, Loss function: 6.144, Average Loss: 4.071, avg. samples / sec: 65671.41
Iteration:    780, Loss function: 6.236, Average Loss: 4.032, avg. samples / sec: 65694.83
Iteration:    780, Loss function: 4.317, Average Loss: 4.058, avg. samples / sec: 65636.02
Iteration:    780, Loss function: 6.276, Average Loss: 4.059, avg. samples / sec: 65607.18
Iteration:    780, Loss function: 4.777, Average Loss: 4.081, avg. samples / sec: 65607.27
Iteration:    780, Loss function: 5.397, Average Loss: 4.056, avg. samples / sec: 65692.50
Iteration:    780, Loss function: 6.181, Average Loss: 4.077, avg. samples / sec: 65639.72
Iteration:    780, Loss function: 4.881, Average Loss: 4.053, avg. samples / sec: 65781.67
Iteration:    780, Loss function: 4.403, Average Loss: 4.061, avg. samples / sec: 65660.76
Iteration:    780, Loss function: 5.772, Average Loss: 4.088, avg. samples / sec: 65647.40
Iteration:    780, Loss function: 5.036, Average Loss: 4.062, avg. samples / sec: 65817.65
Iteration:    780, Loss function: 5.376, Average Loss: 4.060, avg. samples / sec: 65775.04
Iteration:    780, Loss function: 6.341, Average Loss: 4.099, avg. samples / sec: 65662.29
Iteration:    780, Loss function: 5.796, Average Loss: 4.065, avg. samples / sec: 65605.10
Iteration:    780, Loss function: 5.319, Average Loss: 4.066, avg. samples / sec: 65685.37
Iteration:    780, Loss function: 5.564, Average Loss: 4.057, avg. samples / sec: 65645.35
Iteration:    780, Loss function: 5.723, Average Loss: 4.085, avg. samples / sec: 65603.06
Iteration:    780, Loss function: 5.775, Average Loss: 4.059, avg. samples / sec: 65645.44
Iteration:    780, Loss function: 5.830, Average Loss: 4.084, avg. samples / sec: 65594.41
Iteration:    780, Loss function: 5.239, Average Loss: 4.043, avg. samples / sec: 65610.94
Iteration:    780, Loss function: 6.498, Average Loss: 4.077, avg. samples / sec: 65672.21
Iteration:    780, Loss function: 4.741, Average Loss: 4.064, avg. samples / sec: 65597.77
Iteration:    780, Loss function: 5.163, Average Loss: 4.068, avg. samples / sec: 65573.05
Iteration:    780, Loss function: 5.895, Average Loss: 4.052, avg. samples / sec: 65524.30
Iteration:    780, Loss function: 5.226, Average Loss: 4.088, avg. samples / sec: 65450.69
Iteration:    800, Loss function: 6.254, Average Loss: 4.124, avg. samples / sec: 66838.30
Iteration:    800, Loss function: 5.558, Average Loss: 4.085, avg. samples / sec: 66723.24
Iteration:    800, Loss function: 4.699, Average Loss: 4.073, avg. samples / sec: 66723.30
Iteration:    800, Loss function: 6.041, Average Loss: 4.099, avg. samples / sec: 66749.05
Iteration:    800, Loss function: 5.415, Average Loss: 4.115, avg. samples / sec: 66772.02
Iteration:    800, Loss function: 4.992, Average Loss: 4.059, avg. samples / sec: 66700.34
Iteration:    800, Loss function: 5.166, Average Loss: 4.083, avg. samples / sec: 66771.79
Iteration:    800, Loss function: 5.101, Average Loss: 4.075, avg. samples / sec: 66885.21
Iteration:    800, Loss function: 5.433, Average Loss: 4.095, avg. samples / sec: 66784.93
Iteration:    800, Loss function: 5.956, Average Loss: 4.097, avg. samples / sec: 66668.12
Iteration:    800, Loss function: 5.588, Average Loss: 4.108, avg. samples / sec: 66720.33
Iteration:    800, Loss function: 6.399, Average Loss: 4.089, avg. samples / sec: 66750.51
Iteration:    800, Loss function: 4.454, Average Loss: 4.113, avg. samples / sec: 66795.85
Iteration:    800, Loss function: 4.693, Average Loss: 4.081, avg. samples / sec: 66702.08
Iteration:    800, Loss function: 5.495, Average Loss: 4.091, avg. samples / sec: 66663.39
Iteration:    800, Loss function: 5.962, Average Loss: 4.086, avg. samples / sec: 66586.85
Iteration:    800, Loss function: 6.063, Average Loss: 4.103, avg. samples / sec: 66694.56
Iteration:    800, Loss function: 5.508, Average Loss: 4.069, avg. samples / sec: 66760.34
Iteration:    800, Loss function: 5.381, Average Loss: 4.088, avg. samples / sec: 66682.48
Iteration:    800, Loss function: 5.728, Average Loss: 4.084, avg. samples / sec: 66653.65
Iteration:    800, Loss function: 4.314, Average Loss: 4.058, avg. samples / sec: 66532.00
Iteration:    800, Loss function: 5.580, Average Loss: 4.085, avg. samples / sec: 66684.81
Iteration:    800, Loss function: 5.385, Average Loss: 4.101, avg. samples / sec: 66725.86
Iteration:    800, Loss function: 5.112, Average Loss: 4.088, avg. samples / sec: 66713.82
Iteration:    800, Loss function: 4.478, Average Loss: 4.098, avg. samples / sec: 66736.41
Iteration:    800, Loss function: 5.348, Average Loss: 4.094, avg. samples / sec: 66654.41
Iteration:    800, Loss function: 5.463, Average Loss: 4.114, avg. samples / sec: 66679.83
Iteration:    800, Loss function: 6.607, Average Loss: 4.091, avg. samples / sec: 66625.39
Iteration:    800, Loss function: 5.088, Average Loss: 4.118, avg. samples / sec: 66754.37
Iteration:    800, Loss function: 5.275, Average Loss: 4.084, avg. samples / sec: 66578.96
Iteration:    820, Loss function: 5.700, Average Loss: 4.123, avg. samples / sec: 66569.21
Iteration:    820, Loss function: 5.005, Average Loss: 4.124, avg. samples / sec: 66631.37
Iteration:    820, Loss function: 4.809, Average Loss: 4.109, avg. samples / sec: 66626.55
Iteration:    820, Loss function: 4.670, Average Loss: 4.109, avg. samples / sec: 66593.75
Iteration:    820, Loss function: 4.800, Average Loss: 4.113, avg. samples / sec: 66663.80
Iteration:    820, Loss function: 5.548, Average Loss: 4.082, avg. samples / sec: 66565.41
Iteration:    820, Loss function: 4.453, Average Loss: 4.134, avg. samples / sec: 66714.90
Iteration:    820, Loss function: 5.452, Average Loss: 4.139, avg. samples / sec: 66588.40
Iteration:    820, Loss function: 6.169, Average Loss: 4.140, avg. samples / sec: 66722.48
Iteration:    820, Loss function: 4.818, Average Loss: 4.119, avg. samples / sec: 66696.49
Iteration:    820, Loss function: 5.222, Average Loss: 4.109, avg. samples / sec: 66651.41
Iteration:    820, Loss function: 5.399, Average Loss: 4.113, avg. samples / sec: 66671.09
Iteration:    820, Loss function: 5.170, Average Loss: 4.145, avg. samples / sec: 66479.68
Iteration:    820, Loss function: 4.876, Average Loss: 4.128, avg. samples / sec: 66667.65
Iteration:    820, Loss function: 5.921, Average Loss: 4.123, avg. samples / sec: 66529.86
Iteration:    820, Loss function: 5.021, Average Loss: 4.097, avg. samples / sec: 66448.37
Iteration:    820, Loss function: 5.058, Average Loss: 4.084, avg. samples / sec: 66605.17
Iteration:    820, Loss function: 5.617, Average Loss: 4.139, avg. samples / sec: 66506.60
Iteration:    820, Loss function: 5.351, Average Loss: 4.121, avg. samples / sec: 66512.91
Iteration:    820, Loss function: 5.146, Average Loss: 4.115, avg. samples / sec: 66529.08
Iteration:    820, Loss function: 5.049, Average Loss: 4.114, avg. samples / sec: 66506.91
Iteration:    820, Loss function: 5.911, Average Loss: 4.115, avg. samples / sec: 66462.41
Iteration:    820, Loss function: 4.700, Average Loss: 4.124, avg. samples / sec: 66524.46
Iteration:    820, Loss function: 5.870, Average Loss: 4.116, avg. samples / sec: 66605.80
Iteration:    820, Loss function: 5.188, Average Loss: 4.141, avg. samples / sec: 66447.62
Iteration:    820, Loss function: 5.175, Average Loss: 4.110, avg. samples / sec: 66375.54
Iteration:    820, Loss function: 6.037, Average Loss: 4.093, avg. samples / sec: 66481.85
Iteration:    820, Loss function: 4.646, Average Loss: 4.118, avg. samples / sec: 66523.71
Iteration:    820, Loss function: 4.210, Average Loss: 4.117, avg. samples / sec: 66497.50
Iteration:    820, Loss function: 5.444, Average Loss: 4.109, avg. samples / sec: 66547.14
:::MLL 1558651211.330 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1558651211.331 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    840, Loss function: 5.240, Average Loss: 4.164, avg. samples / sec: 66609.70
Iteration:    840, Loss function: 5.971, Average Loss: 4.162, avg. samples / sec: 66357.19
Iteration:    840, Loss function: 4.467, Average Loss: 4.162, avg. samples / sec: 66368.07
Iteration:    840, Loss function: 5.052, Average Loss: 4.137, avg. samples / sec: 66477.30
Iteration:    840, Loss function: 6.076, Average Loss: 4.132, avg. samples / sec: 66575.40
Iteration:    840, Loss function: 5.723, Average Loss: 4.129, avg. samples / sec: 66266.15
Iteration:    840, Loss function: 5.946, Average Loss: 4.142, avg. samples / sec: 66386.48
Iteration:    840, Loss function: 4.993, Average Loss: 4.135, avg. samples / sec: 66389.74
Iteration:    840, Loss function: 5.551, Average Loss: 4.167, avg. samples / sec: 66370.66
Iteration:    840, Loss function: 5.110, Average Loss: 4.130, avg. samples / sec: 66260.32
Iteration:    840, Loss function: 5.677, Average Loss: 4.144, avg. samples / sec: 66319.82
Iteration:    840, Loss function: 4.400, Average Loss: 4.117, avg. samples / sec: 66434.58
Iteration:    840, Loss function: 5.469, Average Loss: 4.156, avg. samples / sec: 66254.75
Iteration:    840, Loss function: 4.497, Average Loss: 4.141, avg. samples / sec: 66417.87
Iteration:    840, Loss function: 5.669, Average Loss: 4.139, avg. samples / sec: 66222.71
Iteration:    840, Loss function: 5.642, Average Loss: 4.121, avg. samples / sec: 66297.23
Iteration:    840, Loss function: 5.052, Average Loss: 4.132, avg. samples / sec: 66249.98
Iteration:    840, Loss function: 5.054, Average Loss: 4.105, avg. samples / sec: 66260.01
Iteration:    840, Loss function: 4.440, Average Loss: 4.145, avg. samples / sec: 66159.97
Iteration:    840, Loss function: 6.144, Average Loss: 4.169, avg. samples / sec: 66238.80
Iteration:    840, Loss function: 5.073, Average Loss: 4.148, avg. samples / sec: 66127.78
Iteration:    840, Loss function: 6.210, Average Loss: 4.145, avg. samples / sec: 66241.29
Iteration:    840, Loss function: 4.908, Average Loss: 4.140, avg. samples / sec: 66270.42
Iteration:    840, Loss function: 5.381, Average Loss: 4.141, avg. samples / sec: 66351.92
Iteration:    840, Loss function: 5.748, Average Loss: 4.106, avg. samples / sec: 66180.42
Iteration:    840, Loss function: 5.623, Average Loss: 4.147, avg. samples / sec: 66278.43
Iteration:    840, Loss function: 5.350, Average Loss: 4.149, avg. samples / sec: 66247.15
Iteration:    840, Loss function: 5.916, Average Loss: 4.137, avg. samples / sec: 66259.70
Iteration:    840, Loss function: 5.881, Average Loss: 4.135, avg. samples / sec: 66177.65
Iteration:    840, Loss function: 5.421, Average Loss: 4.147, avg. samples / sec: 66117.32
Iteration:    860, Loss function: 4.791, Average Loss: 4.186, avg. samples / sec: 66211.04
Iteration:    860, Loss function: 4.237, Average Loss: 4.122, avg. samples / sec: 66483.01
Iteration:    860, Loss function: 4.687, Average Loss: 4.164, avg. samples / sec: 66489.87
Iteration:    860, Loss function: 4.648, Average Loss: 4.159, avg. samples / sec: 66302.87
Iteration:    860, Loss function: 3.480, Average Loss: 4.188, avg. samples / sec: 66358.63
Iteration:    860, Loss function: 4.254, Average Loss: 4.174, avg. samples / sec: 66426.29
Iteration:    860, Loss function: 3.758, Average Loss: 4.170, avg. samples / sec: 66380.89
Iteration:    860, Loss function: 4.857, Average Loss: 4.157, avg. samples / sec: 66335.39
Iteration:    860, Loss function: 4.308, Average Loss: 4.168, avg. samples / sec: 66326.12
Iteration:    860, Loss function: 3.947, Average Loss: 4.167, avg. samples / sec: 66420.93
Iteration:    860, Loss function: 5.660, Average Loss: 4.127, avg. samples / sec: 66420.81
Iteration:    860, Loss function: 6.135, Average Loss: 4.152, avg. samples / sec: 66306.24
Iteration:    860, Loss function: 5.420, Average Loss: 4.144, avg. samples / sec: 66293.42
Iteration:    860, Loss function: 5.602, Average Loss: 4.139, avg. samples / sec: 66317.29
Iteration:    860, Loss function: 6.330, Average Loss: 4.164, avg. samples / sec: 66360.29
Iteration:    860, Loss function: 6.023, Average Loss: 4.168, avg. samples / sec: 66405.91
Iteration:    860, Loss function: 4.837, Average Loss: 4.182, avg. samples / sec: 66187.10
Iteration:    860, Loss function: 4.236, Average Loss: 4.160, avg. samples / sec: 66296.23
Iteration:    860, Loss function: 5.190, Average Loss: 4.168, avg. samples / sec: 66273.81
Iteration:    860, Loss function: 5.969, Average Loss: 4.179, avg. samples / sec: 66183.77
Iteration:    860, Loss function: 5.323, Average Loss: 4.195, avg. samples / sec: 66325.65
Iteration:    860, Loss function: 4.606, Average Loss: 4.174, avg. samples / sec: 66428.32
Iteration:    860, Loss function: 5.528, Average Loss: 4.184, avg. samples / sec: 66274.09
Iteration:    860, Loss function: 5.365, Average Loss: 4.156, avg. samples / sec: 66218.88
Iteration:    860, Loss function: 5.496, Average Loss: 4.152, avg. samples / sec: 66233.38
Iteration:    860, Loss function: 5.934, Average Loss: 4.175, avg. samples / sec: 66326.65
Iteration:    860, Loss function: 3.618, Average Loss: 4.153, avg. samples / sec: 66275.37
Iteration:    860, Loss function: 6.115, Average Loss: 4.167, avg. samples / sec: 66319.66
Iteration:    860, Loss function: 5.448, Average Loss: 4.158, avg. samples / sec: 66293.86
Iteration:    860, Loss function: 6.278, Average Loss: 4.175, avg. samples / sec: 66219.82
Iteration:    880, Loss function: 4.683, Average Loss: 4.177, avg. samples / sec: 66587.80
Iteration:    880, Loss function: 4.899, Average Loss: 4.183, avg. samples / sec: 66516.52
Iteration:    880, Loss function: 5.288, Average Loss: 4.176, avg. samples / sec: 66556.70
Iteration:    880, Loss function: 5.964, Average Loss: 4.179, avg. samples / sec: 66521.20
Iteration:    880, Loss function: 4.663, Average Loss: 4.179, avg. samples / sec: 66605.36
Iteration:    880, Loss function: 5.874, Average Loss: 4.170, avg. samples / sec: 66589.03
Iteration:    880, Loss function: 5.838, Average Loss: 4.188, avg. samples / sec: 66413.55
Iteration:    880, Loss function: 5.675, Average Loss: 4.213, avg. samples / sec: 66562.04
Iteration:    880, Loss function: 4.855, Average Loss: 4.184, avg. samples / sec: 66557.45
Iteration:    880, Loss function: 4.307, Average Loss: 4.193, avg. samples / sec: 66531.50
Iteration:    880, Loss function: 5.134, Average Loss: 4.203, avg. samples / sec: 66349.17
Iteration:    880, Loss function: 4.958, Average Loss: 4.146, avg. samples / sec: 66463.00
Iteration:    880, Loss function: 5.824, Average Loss: 4.191, avg. samples / sec: 66433.55
Iteration:    880, Loss function: 4.731, Average Loss: 4.148, avg. samples / sec: 66372.88
Iteration:    880, Loss function: 4.924, Average Loss: 4.182, avg. samples / sec: 66443.39
Iteration:    880, Loss function: 4.351, Average Loss: 4.186, avg. samples / sec: 66507.23
Iteration:    880, Loss function: 4.157, Average Loss: 4.160, avg. samples / sec: 66485.92
Iteration:    880, Loss function: 3.876, Average Loss: 4.176, avg. samples / sec: 66540.80
Iteration:    880, Loss function: 5.882, Average Loss: 4.206, avg. samples / sec: 66491.60
Iteration:    880, Loss function: 5.330, Average Loss: 4.198, avg. samples / sec: 66466.51
Iteration:    880, Loss function: 5.895, Average Loss: 4.199, avg. samples / sec: 66511.84
Iteration:    880, Loss function: 5.079, Average Loss: 4.190, avg. samples / sec: 66462.12
Iteration:    880, Loss function: 4.088, Average Loss: 4.179, avg. samples / sec: 66489.28
Iteration:    880, Loss function: 5.941, Average Loss: 4.187, avg. samples / sec: 66449.34
Iteration:    880, Loss function: 4.799, Average Loss: 4.177, avg. samples / sec: 66488.75
Iteration:    880, Loss function: 4.623, Average Loss: 4.189, avg. samples / sec: 66355.63
Iteration:    880, Loss function: 6.556, Average Loss: 4.180, avg. samples / sec: 66521.92
Iteration:    880, Loss function: 5.797, Average Loss: 4.207, avg. samples / sec: 66276.49
Iteration:    880, Loss function: 4.439, Average Loss: 4.201, avg. samples / sec: 66373.45
Iteration:    880, Loss function: 5.660, Average Loss: 4.201, avg. samples / sec: 66488.84
Iteration:    900, Loss function: 6.309, Average Loss: 4.202, avg. samples / sec: 66285.57
Iteration:    900, Loss function: 5.718, Average Loss: 4.205, avg. samples / sec: 66387.11
Iteration:    900, Loss function: 4.836, Average Loss: 4.169, avg. samples / sec: 66348.14
Iteration:    900, Loss function: 5.401, Average Loss: 4.198, avg. samples / sec: 66220.44
Iteration:    900, Loss function: 5.435, Average Loss: 4.228, avg. samples / sec: 66330.24
Iteration:    900, Loss function: 3.408, Average Loss: 4.196, avg. samples / sec: 66197.76
Iteration:    900, Loss function: 5.059, Average Loss: 4.213, avg. samples / sec: 66378.76
Iteration:    900, Loss function: 5.173, Average Loss: 4.231, avg. samples / sec: 66240.61
Iteration:    900, Loss function: 3.683, Average Loss: 4.209, avg. samples / sec: 66243.13
Iteration:    900, Loss function: 5.475, Average Loss: 4.213, avg. samples / sec: 66240.14
Iteration:    900, Loss function: 5.846, Average Loss: 4.168, avg. samples / sec: 66262.60
Iteration:    900, Loss function: 5.353, Average Loss: 4.233, avg. samples / sec: 66403.69
Iteration:    900, Loss function: 5.626, Average Loss: 4.212, avg. samples / sec: 66272.88
Iteration:    900, Loss function: 5.566, Average Loss: 4.216, avg. samples / sec: 66337.58
Iteration:    900, Loss function: 5.325, Average Loss: 4.180, avg. samples / sec: 66262.04
Iteration:    900, Loss function: 4.531, Average Loss: 4.210, avg. samples / sec: 66308.64
Iteration:    900, Loss function: 5.288, Average Loss: 4.221, avg. samples / sec: 66423.12
Iteration:    900, Loss function: 6.259, Average Loss: 4.223, avg. samples / sec: 66281.98
Iteration:    900, Loss function: 5.308, Average Loss: 4.224, avg. samples / sec: 66382.26
Iteration:    900, Loss function: 4.895, Average Loss: 4.206, avg. samples / sec: 66194.87
Iteration:    900, Loss function: 5.886, Average Loss: 4.205, avg. samples / sec: 66282.70
Iteration:    900, Loss function: 4.997, Average Loss: 4.222, avg. samples / sec: 66271.35
Iteration:    900, Loss function: 5.433, Average Loss: 4.204, avg. samples / sec: 66142.30
Iteration:    900, Loss function: 3.875, Average Loss: 4.203, avg. samples / sec: 66208.52
Iteration:    900, Loss function: 4.994, Average Loss: 4.227, avg. samples / sec: 66240.89
Iteration:    900, Loss function: 5.136, Average Loss: 4.190, avg. samples / sec: 66135.60
Iteration:    900, Loss function: 4.636, Average Loss: 4.204, avg. samples / sec: 66206.87
Iteration:    900, Loss function: 3.707, Average Loss: 4.203, avg. samples / sec: 66242.54
Iteration:    900, Loss function: 5.762, Average Loss: 4.203, avg. samples / sec: 66072.84
Iteration:    900, Loss function: 5.593, Average Loss: 4.201, avg. samples / sec: 66187.81
:::MLL 1558651213.105 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1558651213.106 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 4.237, Average Loss: 4.224, avg. samples / sec: 66034.54
Iteration:    920, Loss function: 5.188, Average Loss: 4.246, avg. samples / sec: 66166.53
Iteration:    920, Loss function: 3.827, Average Loss: 4.238, avg. samples / sec: 66080.40
Iteration:    920, Loss function: 4.835, Average Loss: 4.186, avg. samples / sec: 66075.60
Iteration:    920, Loss function: 4.289, Average Loss: 4.249, avg. samples / sec: 66075.20
Iteration:    920, Loss function: 4.317, Average Loss: 4.228, avg. samples / sec: 66106.69
Iteration:    920, Loss function: 5.682, Average Loss: 4.194, avg. samples / sec: 65976.83
Iteration:    920, Loss function: 4.651, Average Loss: 4.232, avg. samples / sec: 66068.78
Iteration:    920, Loss function: 4.748, Average Loss: 4.216, avg. samples / sec: 66000.80
Iteration:    920, Loss function: 4.093, Average Loss: 4.234, avg. samples / sec: 66047.54
Iteration:    920, Loss function: 5.336, Average Loss: 4.227, avg. samples / sec: 66158.05
Iteration:    920, Loss function: 4.862, Average Loss: 4.223, avg. samples / sec: 65917.61
Iteration:    920, Loss function: 5.165, Average Loss: 4.245, avg. samples / sec: 66042.96
Iteration:    920, Loss function: 4.300, Average Loss: 4.247, avg. samples / sec: 65950.77
Iteration:    920, Loss function: 4.161, Average Loss: 4.234, avg. samples / sec: 66037.21
Iteration:    920, Loss function: 5.525, Average Loss: 4.207, avg. samples / sec: 66072.04
Iteration:    920, Loss function: 5.260, Average Loss: 4.246, avg. samples / sec: 66030.62
Iteration:    920, Loss function: 6.077, Average Loss: 4.245, avg. samples / sec: 66023.25
Iteration:    920, Loss function: 5.092, Average Loss: 4.228, avg. samples / sec: 66013.67
Iteration:    920, Loss function: 5.323, Average Loss: 4.220, avg. samples / sec: 66160.16
Iteration:    920, Loss function: 4.570, Average Loss: 4.218, avg. samples / sec: 65901.15
Iteration:    920, Loss function: 5.532, Average Loss: 4.223, avg. samples / sec: 66048.16
Iteration:    920, Loss function: 4.914, Average Loss: 4.249, avg. samples / sec: 65977.82
Iteration:    920, Loss function: 5.406, Average Loss: 4.230, avg. samples / sec: 65899.30
Iteration:    920, Loss function: 4.288, Average Loss: 4.221, avg. samples / sec: 66037.48
Iteration:    920, Loss function: 4.455, Average Loss: 4.229, avg. samples / sec: 65954.35
Iteration:    920, Loss function: 4.598, Average Loss: 4.226, avg. samples / sec: 65985.32
Iteration:    920, Loss function: 4.764, Average Loss: 4.222, avg. samples / sec: 65958.76
Iteration:    920, Loss function: 4.750, Average Loss: 4.202, avg. samples / sec: 65928.12
Iteration:    920, Loss function: 5.261, Average Loss: 4.220, avg. samples / sec: 65908.45
Iteration:    940, Loss function: 4.908, Average Loss: 4.247, avg. samples / sec: 66408.07
Iteration:    940, Loss function: 6.130, Average Loss: 4.266, avg. samples / sec: 66562.29
Iteration:    940, Loss function: 4.901, Average Loss: 4.212, avg. samples / sec: 66458.21
Iteration:    940, Loss function: 4.377, Average Loss: 4.237, avg. samples / sec: 66470.93
Iteration:    940, Loss function: 5.694, Average Loss: 4.234, avg. samples / sec: 66415.61
Iteration:    940, Loss function: 4.402, Average Loss: 4.224, avg. samples / sec: 66427.98
Iteration:    940, Loss function: 5.051, Average Loss: 4.237, avg. samples / sec: 66446.49
Iteration:    940, Loss function: 5.237, Average Loss: 4.238, avg. samples / sec: 66473.72
Iteration:    940, Loss function: 4.131, Average Loss: 4.263, avg. samples / sec: 66388.55
Iteration:    940, Loss function: 4.655, Average Loss: 4.240, avg. samples / sec: 66433.99
Iteration:    940, Loss function: 4.720, Average Loss: 4.240, avg. samples / sec: 66387.02
Iteration:    940, Loss function: 5.262, Average Loss: 4.250, avg. samples / sec: 66312.42
Iteration:    940, Loss function: 5.119, Average Loss: 4.247, avg. samples / sec: 66318.75
Iteration:    940, Loss function: 5.580, Average Loss: 4.234, avg. samples / sec: 66519.09
Iteration:    940, Loss function: 4.014, Average Loss: 4.237, avg. samples / sec: 66402.47
Iteration:    940, Loss function: 6.275, Average Loss: 4.243, avg. samples / sec: 66282.11
Iteration:    940, Loss function: 6.087, Average Loss: 4.253, avg. samples / sec: 66259.98
Iteration:    940, Loss function: 5.716, Average Loss: 4.271, avg. samples / sec: 66261.85
Iteration:    940, Loss function: 4.388, Average Loss: 4.260, avg. samples / sec: 66315.13
Iteration:    940, Loss function: 5.468, Average Loss: 4.247, avg. samples / sec: 66373.13
Iteration:    940, Loss function: 5.105, Average Loss: 4.231, avg. samples / sec: 66315.10
Iteration:    940, Loss function: 5.451, Average Loss: 4.247, avg. samples / sec: 66345.45
Iteration:    940, Loss function: 5.801, Average Loss: 4.201, avg. samples / sec: 66230.05
Iteration:    940, Loss function: 4.783, Average Loss: 4.250, avg. samples / sec: 66275.09
Iteration:    940, Loss function: 3.657, Average Loss: 4.213, avg. samples / sec: 66337.61
Iteration:    940, Loss function: 5.327, Average Loss: 4.264, avg. samples / sec: 66256.27
Iteration:    940, Loss function: 5.029, Average Loss: 4.241, avg. samples / sec: 66264.93
Iteration:    940, Loss function: 4.722, Average Loss: 4.250, avg. samples / sec: 66165.22
Iteration:    940, Loss function: 4.910, Average Loss: 4.256, avg. samples / sec: 66237.43
Iteration:    940, Loss function: 5.896, Average Loss: 4.257, avg. samples / sec: 66032.84
Iteration:    960, Loss function: 7.029, Average Loss: 4.263, avg. samples / sec: 66521.79
Iteration:    960, Loss function: 5.876, Average Loss: 4.264, avg. samples / sec: 66678.69
Iteration:    960, Loss function: 5.496, Average Loss: 4.262, avg. samples / sec: 66606.37
Iteration:    960, Loss function: 5.658, Average Loss: 4.245, avg. samples / sec: 66659.86
Iteration:    960, Loss function: 6.387, Average Loss: 4.255, avg. samples / sec: 66618.21
Iteration:    960, Loss function: 6.457, Average Loss: 4.219, avg. samples / sec: 66774.07
Iteration:    960, Loss function: 4.265, Average Loss: 4.269, avg. samples / sec: 66674.09
Iteration:    960, Loss function: 4.645, Average Loss: 4.256, avg. samples / sec: 66700.85
Iteration:    960, Loss function: 5.366, Average Loss: 4.258, avg. samples / sec: 66779.07
Iteration:    960, Loss function: 4.869, Average Loss: 4.284, avg. samples / sec: 66471.37
Iteration:    960, Loss function: 5.267, Average Loss: 4.268, avg. samples / sec: 66705.49
Iteration:    960, Loss function: 3.879, Average Loss: 4.285, avg. samples / sec: 66683.11
Iteration:    960, Loss function: 5.502, Average Loss: 4.266, avg. samples / sec: 66622.68
Iteration:    960, Loss function: 5.626, Average Loss: 4.264, avg. samples / sec: 66626.46
Iteration:    960, Loss function: 4.967, Average Loss: 4.274, avg. samples / sec: 66617.39
Iteration:    960, Loss function: 5.085, Average Loss: 4.279, avg. samples / sec: 66803.64
Iteration:    960, Loss function: 4.904, Average Loss: 4.228, avg. samples / sec: 66415.99
Iteration:    960, Loss function: 5.292, Average Loss: 4.264, avg. samples / sec: 66620.00
Iteration:    960, Loss function: 3.651, Average Loss: 4.234, avg. samples / sec: 66687.24
Iteration:    960, Loss function: 4.328, Average Loss: 4.267, avg. samples / sec: 66720.30
Iteration:    960, Loss function: 5.183, Average Loss: 4.273, avg. samples / sec: 66667.84
Iteration:    960, Loss function: 6.147, Average Loss: 4.256, avg. samples / sec: 66549.09
Iteration:    960, Loss function: 6.784, Average Loss: 4.281, avg. samples / sec: 66670.74
Iteration:    960, Loss function: 6.141, Average Loss: 4.251, avg. samples / sec: 66615.59
Iteration:    960, Loss function: 4.901, Average Loss: 4.258, avg. samples / sec: 66544.38
Iteration:    960, Loss function: 5.321, Average Loss: 4.279, avg. samples / sec: 66580.50
Iteration:    960, Loss function: 4.161, Average Loss: 4.279, avg. samples / sec: 66500.42
Iteration:    960, Loss function: 5.098, Average Loss: 4.253, avg. samples / sec: 66543.97
Iteration:    960, Loss function: 4.788, Average Loss: 4.262, avg. samples / sec: 66520.95
Iteration:    960, Loss function: 5.349, Average Loss: 4.273, avg. samples / sec: 66656.55
:::MLL 1558651214.881 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1558651214.881 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 4.594, Average Loss: 4.296, avg. samples / sec: 66015.40
Iteration:    980, Loss function: 3.942, Average Loss: 4.267, avg. samples / sec: 65785.94
Iteration:    980, Loss function: 4.810, Average Loss: 4.270, avg. samples / sec: 65781.12
Iteration:    980, Loss function: 4.279, Average Loss: 4.278, avg. samples / sec: 65711.10
Iteration:    980, Loss function: 6.274, Average Loss: 4.305, avg. samples / sec: 65788.34
Iteration:    980, Loss function: 4.695, Average Loss: 4.292, avg. samples / sec: 65903.98
Iteration:    980, Loss function: 5.287, Average Loss: 4.299, avg. samples / sec: 65774.18
Iteration:    980, Loss function: 5.406, Average Loss: 4.284, avg. samples / sec: 65809.20
Iteration:    980, Loss function: 4.778, Average Loss: 4.277, avg. samples / sec: 65698.17
Iteration:    980, Loss function: 4.776, Average Loss: 4.236, avg. samples / sec: 65722.28
Iteration:    980, Loss function: 3.947, Average Loss: 4.283, avg. samples / sec: 65763.32
Iteration:    980, Loss function: 4.553, Average Loss: 4.281, avg. samples / sec: 65858.22
Iteration:    980, Loss function: 4.323, Average Loss: 4.297, avg. samples / sec: 65834.83
Iteration:    980, Loss function: 4.140, Average Loss: 4.288, avg. samples / sec: 65721.85
Iteration:    980, Loss function: 5.403, Average Loss: 4.247, avg. samples / sec: 65813.71
Iteration:    980, Loss function: 5.216, Average Loss: 4.272, avg. samples / sec: 65709.96
Iteration:    980, Loss function: 3.630, Average Loss: 4.278, avg. samples / sec: 65796.84
Iteration:    980, Loss function: 5.047, Average Loss: 4.290, avg. samples / sec: 65806.61
Iteration:    980, Loss function: 4.752, Average Loss: 4.269, avg. samples / sec: 65810.02
Iteration:    980, Loss function: 6.543, Average Loss: 4.253, avg. samples / sec: 65768.16
Iteration:    980, Loss function: 4.579, Average Loss: 4.284, avg. samples / sec: 65760.09
Iteration:    980, Loss function: 4.808, Average Loss: 4.275, avg. samples / sec: 65685.40
Iteration:    980, Loss function: 4.597, Average Loss: 4.281, avg. samples / sec: 65730.31
Iteration:    980, Loss function: 5.609, Average Loss: 4.287, avg. samples / sec: 65810.36
Iteration:    980, Loss function: 4.427, Average Loss: 4.281, avg. samples / sec: 65585.29
Iteration:    980, Loss function: 4.487, Average Loss: 4.277, avg. samples / sec: 65737.21
Iteration:    980, Loss function: 4.731, Average Loss: 4.305, avg. samples / sec: 65727.52
Iteration:    980, Loss function: 5.684, Average Loss: 4.284, avg. samples / sec: 65725.77
Iteration:    980, Loss function: 4.833, Average Loss: 4.288, avg. samples / sec: 65653.42
Iteration:    980, Loss function: 5.579, Average Loss: 4.269, avg. samples / sec: 65676.18
Iteration:   1000, Loss function: 4.690, Average Loss: 4.293, avg. samples / sec: 66217.70
Iteration:   1000, Loss function: 5.230, Average Loss: 4.317, avg. samples / sec: 66154.75
Iteration:   1000, Loss function: 6.351, Average Loss: 4.312, avg. samples / sec: 66057.98
Iteration:   1000, Loss function: 5.195, Average Loss: 4.292, avg. samples / sec: 66284.13
Iteration:   1000, Loss function: 5.239, Average Loss: 4.297, avg. samples / sec: 66136.25
Iteration:   1000, Loss function: 5.639, Average Loss: 4.299, avg. samples / sec: 66157.30
Iteration:   1000, Loss function: 5.569, Average Loss: 4.263, avg. samples / sec: 66188.19
Iteration:   1000, Loss function: 5.657, Average Loss: 4.315, avg. samples / sec: 66141.65
Iteration:   1000, Loss function: 5.376, Average Loss: 4.303, avg. samples / sec: 66161.21
Iteration:   1000, Loss function: 4.687, Average Loss: 4.288, avg. samples / sec: 66047.26
Iteration:   1000, Loss function: 5.791, Average Loss: 4.301, avg. samples / sec: 66115.18
Iteration:   1000, Loss function: 5.766, Average Loss: 4.311, avg. samples / sec: 66079.35
Iteration:   1000, Loss function: 5.882, Average Loss: 4.289, avg. samples / sec: 66100.86
Iteration:   1000, Loss function: 5.330, Average Loss: 4.324, avg. samples / sec: 66223.49
Iteration:   1000, Loss function: 4.115, Average Loss: 4.312, avg. samples / sec: 66065.19
Iteration:   1000, Loss function: 5.740, Average Loss: 4.303, avg. samples / sec: 66147.46
Iteration:   1000, Loss function: 4.423, Average Loss: 4.308, avg. samples / sec: 66110.25
Iteration:   1000, Loss function: 4.477, Average Loss: 4.264, avg. samples / sec: 66128.43
Iteration:   1000, Loss function: 5.469, Average Loss: 4.296, avg. samples / sec: 66146.81
Iteration:   1000, Loss function: 4.673, Average Loss: 4.292, avg. samples / sec: 66133.02
Iteration:   1000, Loss function: 5.099, Average Loss: 4.282, avg. samples / sec: 65950.92
Iteration:   1000, Loss function: 5.432, Average Loss: 4.299, avg. samples / sec: 66187.53
Iteration:   1000, Loss function: 5.125, Average Loss: 4.288, avg. samples / sec: 66057.36
Iteration:   1000, Loss function: 6.443, Average Loss: 4.293, avg. samples / sec: 66119.90
Iteration:   1000, Loss function: 4.881, Average Loss: 4.295, avg. samples / sec: 65996.35
Iteration:   1000, Loss function: 5.390, Average Loss: 4.279, avg. samples / sec: 66189.09
Iteration:   1000, Loss function: 4.057, Average Loss: 4.282, avg. samples / sec: 66048.50
Iteration:   1000, Loss function: 6.730, Average Loss: 4.252, avg. samples / sec: 65966.08
Iteration:   1000, Loss function: 3.969, Average Loss: 4.305, avg. samples / sec: 66150.56
Iteration:   1000, Loss function: 4.512, Average Loss: 4.303, avg. samples / sec: 65928.86
Iteration:   1020, Loss function: 3.623, Average Loss: 4.328, avg. samples / sec: 66342.42
Iteration:   1020, Loss function: 4.600, Average Loss: 4.337, avg. samples / sec: 66334.43
Iteration:   1020, Loss function: 6.054, Average Loss: 4.298, avg. samples / sec: 66439.38
Iteration:   1020, Loss function: 4.569, Average Loss: 4.319, avg. samples / sec: 66289.90
Iteration:   1020, Loss function: 4.632, Average Loss: 4.267, avg. samples / sec: 66478.83
Iteration:   1020, Loss function: 5.149, Average Loss: 4.311, avg. samples / sec: 66291.40
Iteration:   1020, Loss function: 4.215, Average Loss: 4.311, avg. samples / sec: 66310.83
Iteration:   1020, Loss function: 5.634, Average Loss: 4.309, avg. samples / sec: 66177.68
Iteration:   1020, Loss function: 4.612, Average Loss: 4.280, avg. samples / sec: 66244.41
Iteration:   1020, Loss function: 6.470, Average Loss: 4.330, avg. samples / sec: 66422.40
Iteration:   1020, Loss function: 5.690, Average Loss: 4.320, avg. samples / sec: 66226.26
Iteration:   1020, Loss function: 5.101, Average Loss: 4.325, avg. samples / sec: 66553.84
Iteration:   1020, Loss function: 4.650, Average Loss: 4.282, avg. samples / sec: 66352.38
Iteration:   1020, Loss function: 4.375, Average Loss: 4.313, avg. samples / sec: 66376.60
Iteration:   1020, Loss function: 4.092, Average Loss: 4.317, avg. samples / sec: 66379.70
Iteration:   1020, Loss function: 5.479, Average Loss: 4.333, avg. samples / sec: 66260.23
Iteration:   1020, Loss function: 5.095, Average Loss: 4.323, avg. samples / sec: 66208.52
Iteration:   1020, Loss function: 4.489, Average Loss: 4.345, avg. samples / sec: 66290.46
Iteration:   1020, Loss function: 5.317, Average Loss: 4.308, avg. samples / sec: 66268.61
Iteration:   1020, Loss function: 5.242, Average Loss: 4.338, avg. samples / sec: 66159.10
Iteration:   1020, Loss function: 6.274, Average Loss: 4.317, avg. samples / sec: 66216.83
Iteration:   1020, Loss function: 5.133, Average Loss: 4.300, avg. samples / sec: 66341.23
Iteration:   1020, Loss function: 5.016, Average Loss: 4.320, avg. samples / sec: 66272.79
Iteration:   1020, Loss function: 5.840, Average Loss: 4.305, avg. samples / sec: 66333.52
Iteration:   1020, Loss function: 5.115, Average Loss: 4.333, avg. samples / sec: 66251.66
Iteration:   1020, Loss function: 5.751, Average Loss: 4.326, avg. samples / sec: 66260.79
Iteration:   1020, Loss function: 5.612, Average Loss: 4.307, avg. samples / sec: 66278.77
Iteration:   1020, Loss function: 5.180, Average Loss: 4.311, avg. samples / sec: 66235.10
Iteration:   1020, Loss function: 4.921, Average Loss: 4.325, avg. samples / sec: 66218.79
Iteration:   1020, Loss function: 4.700, Average Loss: 4.308, avg. samples / sec: 66208.46
Iteration:   1040, Loss function: 4.438, Average Loss: 4.342, avg. samples / sec: 66528.95
Iteration:   1040, Loss function: 5.244, Average Loss: 4.326, avg. samples / sec: 66386.92
Iteration:   1040, Loss function: 4.470, Average Loss: 4.300, avg. samples / sec: 66411.51
Iteration:   1040, Loss function: 3.932, Average Loss: 4.314, avg. samples / sec: 66477.05
Iteration:   1040, Loss function: 5.305, Average Loss: 4.333, avg. samples / sec: 66458.24
Iteration:   1040, Loss function: 6.315, Average Loss: 4.338, avg. samples / sec: 66429.01
Iteration:   1040, Loss function: 4.745, Average Loss: 4.329, avg. samples / sec: 66392.58
Iteration:   1040, Loss function: 5.029, Average Loss: 4.335, avg. samples / sec: 66294.36
Iteration:   1040, Loss function: 4.248, Average Loss: 4.355, avg. samples / sec: 66255.59
Iteration:   1040, Loss function: 4.091, Average Loss: 4.325, avg. samples / sec: 66457.89
Iteration:   1040, Loss function: 5.035, Average Loss: 4.280, avg. samples / sec: 66292.49
Iteration:   1040, Loss function: 4.703, Average Loss: 4.323, avg. samples / sec: 66458.90
Iteration:   1040, Loss function: 5.187, Average Loss: 4.339, avg. samples / sec: 66380.45
Iteration:   1040, Loss function: 4.637, Average Loss: 4.297, avg. samples / sec: 66338.33
Iteration:   1040, Loss function: 4.799, Average Loss: 4.326, avg. samples / sec: 66372.95
Iteration:   1040, Loss function: 4.534, Average Loss: 4.349, avg. samples / sec: 66395.80
Iteration:   1040, Loss function: 5.011, Average Loss: 4.339, avg. samples / sec: 66454.98
Iteration:   1040, Loss function: 3.845, Average Loss: 4.314, avg. samples / sec: 66235.81
Iteration:   1040, Loss function: 4.812, Average Loss: 4.340, avg. samples / sec: 66342.61
Iteration:   1040, Loss function: 5.367, Average Loss: 4.321, avg. samples / sec: 66277.02
Iteration:   1040, Loss function: 3.919, Average Loss: 4.340, avg. samples / sec: 66303.72
Iteration:   1040, Loss function: 5.056, Average Loss: 4.347, avg. samples / sec: 66285.97
Iteration:   1040, Loss function: 5.746, Average Loss: 4.327, avg. samples / sec: 66367.66
Iteration:   1040, Loss function: 6.100, Average Loss: 4.341, avg. samples / sec: 66279.67
Iteration:   1040, Loss function: 5.305, Average Loss: 4.325, avg. samples / sec: 66330.09
Iteration:   1040, Loss function: 5.205, Average Loss: 4.326, avg. samples / sec: 66216.02
Iteration:   1040, Loss function: 4.824, Average Loss: 4.355, avg. samples / sec: 66340.05
Iteration:   1040, Loss function: 4.650, Average Loss: 4.339, avg. samples / sec: 66135.23
Iteration:   1040, Loss function: 5.525, Average Loss: 4.350, avg. samples / sec: 66301.41
Iteration:   1040, Loss function: 6.077, Average Loss: 4.322, avg. samples / sec: 66392.71
:::MLL 1558651216.657 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1558651216.657 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1060, Loss function: 3.997, Average Loss: 4.373, avg. samples / sec: 66317.10
Iteration:   1060, Loss function: 5.753, Average Loss: 4.359, avg. samples / sec: 66283.23
Iteration:   1060, Loss function: 5.655, Average Loss: 4.341, avg. samples / sec: 66187.25
Iteration:   1060, Loss function: 4.652, Average Loss: 4.324, avg. samples / sec: 66241.70
Iteration:   1060, Loss function: 5.169, Average Loss: 4.316, avg. samples / sec: 66116.58
Iteration:   1060, Loss function: 6.422, Average Loss: 4.350, avg. samples / sec: 66185.89
Iteration:   1060, Loss function: 5.141, Average Loss: 4.333, avg. samples / sec: 66279.49
Iteration:   1060, Loss function: 3.986, Average Loss: 4.335, avg. samples / sec: 66188.37
Iteration:   1060, Loss function: 4.448, Average Loss: 4.350, avg. samples / sec: 66163.20
Iteration:   1060, Loss function: 4.755, Average Loss: 4.327, avg. samples / sec: 66120.95
Iteration:   1060, Loss function: 4.619, Average Loss: 4.350, avg. samples / sec: 66134.20
Iteration:   1060, Loss function: 4.248, Average Loss: 4.290, avg. samples / sec: 66169.29
Iteration:   1060, Loss function: 5.132, Average Loss: 4.349, avg. samples / sec: 66179.11
Iteration:   1060, Loss function: 4.014, Average Loss: 4.370, avg. samples / sec: 66155.34
Iteration:   1060, Loss function: 4.926, Average Loss: 4.310, avg. samples / sec: 66156.21
Iteration:   1060, Loss function: 5.936, Average Loss: 4.338, avg. samples / sec: 66134.30
Iteration:   1060, Loss function: 5.302, Average Loss: 4.336, avg. samples / sec: 66140.85
Iteration:   1060, Loss function: 4.692, Average Loss: 4.347, avg. samples / sec: 66157.12
Iteration:   1060, Loss function: 5.153, Average Loss: 4.362, avg. samples / sec: 66026.50
Iteration:   1060, Loss function: 4.484, Average Loss: 4.352, avg. samples / sec: 66157.49
Iteration:   1060, Loss function: 4.491, Average Loss: 4.363, avg. samples / sec: 66089.14
Iteration:   1060, Loss function: 5.743, Average Loss: 4.336, avg. samples / sec: 66133.80
Iteration:   1060, Loss function: 5.494, Average Loss: 4.355, avg. samples / sec: 66144.73
Iteration:   1060, Loss function: 4.661, Average Loss: 4.360, avg. samples / sec: 66120.71
Iteration:   1060, Loss function: 4.585, Average Loss: 4.360, avg. samples / sec: 66131.01
Iteration:   1060, Loss function: 4.155, Average Loss: 4.342, avg. samples / sec: 66126.07
Iteration:   1060, Loss function: 4.245, Average Loss: 4.340, avg. samples / sec: 65999.57
Iteration:   1060, Loss function: 4.952, Average Loss: 4.336, avg. samples / sec: 65996.94
Iteration:   1060, Loss function: 4.914, Average Loss: 4.346, avg. samples / sec: 66008.84
Iteration:   1060, Loss function: 5.222, Average Loss: 4.336, avg. samples / sec: 66002.10
Iteration:   1080, Loss function: 5.528, Average Loss: 4.355, avg. samples / sec: 66491.95
Iteration:   1080, Loss function: 4.578, Average Loss: 4.333, avg. samples / sec: 66408.48
Iteration:   1080, Loss function: 4.623, Average Loss: 4.384, avg. samples / sec: 66403.16
Iteration:   1080, Loss function: 4.903, Average Loss: 4.357, avg. samples / sec: 66310.33
Iteration:   1080, Loss function: 5.018, Average Loss: 4.359, avg. samples / sec: 66459.27
Iteration:   1080, Loss function: 3.827, Average Loss: 4.363, avg. samples / sec: 66348.95
Iteration:   1080, Loss function: 5.305, Average Loss: 4.386, avg. samples / sec: 66281.45
Iteration:   1080, Loss function: 4.770, Average Loss: 4.301, avg. samples / sec: 66356.95
Iteration:   1080, Loss function: 4.852, Average Loss: 4.369, avg. samples / sec: 66256.49
Iteration:   1080, Loss function: 4.024, Average Loss: 4.360, avg. samples / sec: 66316.60
Iteration:   1080, Loss function: 3.865, Average Loss: 4.341, avg. samples / sec: 66288.31
Iteration:   1080, Loss function: 5.365, Average Loss: 4.357, avg. samples / sec: 66427.48
Iteration:   1080, Loss function: 3.756, Average Loss: 4.335, avg. samples / sec: 66297.54
Iteration:   1080, Loss function: 5.468, Average Loss: 4.346, avg. samples / sec: 66276.56
Iteration:   1080, Loss function: 5.593, Average Loss: 4.373, avg. samples / sec: 66408.44
Iteration:   1080, Loss function: 4.332, Average Loss: 4.336, avg. samples / sec: 66230.27
Iteration:   1080, Loss function: 4.679, Average Loss: 4.370, avg. samples / sec: 66402.00
Iteration:   1080, Loss function: 4.864, Average Loss: 4.368, avg. samples / sec: 66379.39
Iteration:   1080, Loss function: 5.242, Average Loss: 4.365, avg. samples / sec: 66257.05
Iteration:   1080, Loss function: 4.436, Average Loss: 4.357, avg. samples / sec: 66258.30
Iteration:   1080, Loss function: 5.589, Average Loss: 4.376, avg. samples / sec: 66308.02
Iteration:   1080, Loss function: 4.489, Average Loss: 4.344, avg. samples / sec: 66475.92
Iteration:   1080, Loss function: 4.188, Average Loss: 4.353, avg. samples / sec: 66385.11
Iteration:   1080, Loss function: 4.248, Average Loss: 4.350, avg. samples / sec: 66268.11
Iteration:   1080, Loss function: 3.592, Average Loss: 4.375, avg. samples / sec: 66329.71
Iteration:   1080, Loss function: 4.627, Average Loss: 4.344, avg. samples / sec: 66296.92
Iteration:   1080, Loss function: 5.091, Average Loss: 4.343, avg. samples / sec: 66342.36
Iteration:   1080, Loss function: 3.937, Average Loss: 4.323, avg. samples / sec: 66201.37
Iteration:   1080, Loss function: 6.206, Average Loss: 4.358, avg. samples / sec: 66326.68
Iteration:   1080, Loss function: 4.478, Average Loss: 4.362, avg. samples / sec: 66141.28
Iteration:   1100, Loss function: 4.767, Average Loss: 4.377, avg. samples / sec: 66607.81
Iteration:   1100, Loss function: 5.153, Average Loss: 4.393, avg. samples / sec: 66572.89
Iteration:   1100, Loss function: 5.266, Average Loss: 4.373, avg. samples / sec: 66486.24
Iteration:   1100, Loss function: 4.637, Average Loss: 4.393, avg. samples / sec: 66500.29
Iteration:   1100, Loss function: 5.543, Average Loss: 4.373, avg. samples / sec: 66808.23
Iteration:   1100, Loss function: 3.860, Average Loss: 4.382, avg. samples / sec: 66640.89
Iteration:   1100, Loss function: 4.913, Average Loss: 4.357, avg. samples / sec: 66536.52
Iteration:   1100, Loss function: 4.779, Average Loss: 4.369, avg. samples / sec: 66427.48
Iteration:   1100, Loss function: 4.746, Average Loss: 4.312, avg. samples / sec: 66475.17
Iteration:   1100, Loss function: 3.830, Average Loss: 4.365, avg. samples / sec: 66661.25
Iteration:   1100, Loss function: 5.265, Average Loss: 4.346, avg. samples / sec: 66378.20
Iteration:   1100, Loss function: 4.885, Average Loss: 4.373, avg. samples / sec: 66486.80
Iteration:   1100, Loss function: 5.130, Average Loss: 4.391, avg. samples / sec: 66507.26
Iteration:   1100, Loss function: 5.230, Average Loss: 4.371, avg. samples / sec: 66406.66
Iteration:   1100, Loss function: 5.446, Average Loss: 4.378, avg. samples / sec: 66535.11
Iteration:   1100, Loss function: 6.516, Average Loss: 4.388, avg. samples / sec: 66499.48
Iteration:   1100, Loss function: 4.974, Average Loss: 4.389, avg. samples / sec: 66564.68
Iteration:   1100, Loss function: 4.860, Average Loss: 4.363, avg. samples / sec: 66559.56
Iteration:   1100, Loss function: 5.738, Average Loss: 4.385, avg. samples / sec: 66436.18
Iteration:   1100, Loss function: 3.771, Average Loss: 4.351, avg. samples / sec: 66602.02
Iteration:   1100, Loss function: 5.831, Average Loss: 4.350, avg. samples / sec: 66490.28
Iteration:   1100, Loss function: 4.607, Average Loss: 4.367, avg. samples / sec: 66498.19
Iteration:   1100, Loss function: 5.607, Average Loss: 4.369, avg. samples / sec: 66485.58
Iteration:   1100, Loss function: 4.115, Average Loss: 4.346, avg. samples / sec: 66407.04
Iteration:   1100, Loss function: 5.254, Average Loss: 4.373, avg. samples / sec: 66391.64
Iteration:   1100, Loss function: 5.026, Average Loss: 4.358, avg. samples / sec: 66439.09
Iteration:   1100, Loss function: 4.099, Average Loss: 4.331, avg. samples / sec: 66478.08
Iteration:   1100, Loss function: 6.119, Average Loss: 4.380, avg. samples / sec: 66310.70
Iteration:   1100, Loss function: 5.629, Average Loss: 4.346, avg. samples / sec: 66251.16
Iteration:   1100, Loss function: 4.605, Average Loss: 4.357, avg. samples / sec: 66311.52
:::MLL 1558651218.431 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1558651218.431 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1120, Loss function: 3.517, Average Loss: 4.377, avg. samples / sec: 66230.49
Iteration:   1120, Loss function: 4.469, Average Loss: 4.364, avg. samples / sec: 66198.94
Iteration:   1120, Loss function: 4.290, Average Loss: 4.382, avg. samples / sec: 66166.00
Iteration:   1120, Loss function: 5.767, Average Loss: 4.357, avg. samples / sec: 66203.67
Iteration:   1120, Loss function: 5.524, Average Loss: 4.384, avg. samples / sec: 66038.20
Iteration:   1120, Loss function: 4.736, Average Loss: 4.398, avg. samples / sec: 65974.51
Iteration:   1120, Loss function: 4.044, Average Loss: 4.320, avg. samples / sec: 66066.09
Iteration:   1120, Loss function: 6.988, Average Loss: 4.368, avg. samples / sec: 66193.91
Iteration:   1120, Loss function: 3.468, Average Loss: 4.358, avg. samples / sec: 66102.66
Iteration:   1120, Loss function: 3.945, Average Loss: 4.389, avg. samples / sec: 65896.12
Iteration:   1120, Loss function: 4.308, Average Loss: 4.402, avg. samples / sec: 66076.90
Iteration:   1120, Loss function: 4.311, Average Loss: 4.403, avg. samples / sec: 65978.19
Iteration:   1120, Loss function: 4.299, Average Loss: 4.370, avg. samples / sec: 66350.51
Iteration:   1120, Loss function: 4.369, Average Loss: 4.357, avg. samples / sec: 66063.36
Iteration:   1120, Loss function: 5.364, Average Loss: 4.390, avg. samples / sec: 66256.40
Iteration:   1120, Loss function: 3.756, Average Loss: 4.363, avg. samples / sec: 66278.21
Iteration:   1120, Loss function: 3.542, Average Loss: 4.388, avg. samples / sec: 66129.14
Iteration:   1120, Loss function: 5.812, Average Loss: 4.368, avg. samples / sec: 65991.19
Iteration:   1120, Loss function: 5.184, Average Loss: 4.376, avg. samples / sec: 66035.91
Iteration:   1120, Loss function: 6.252, Average Loss: 4.381, avg. samples / sec: 66103.77
Iteration:   1120, Loss function: 5.870, Average Loss: 4.402, avg. samples / sec: 66009.52
Iteration:   1120, Loss function: 4.490, Average Loss: 4.391, avg. samples / sec: 65928.68
Iteration:   1120, Loss function: 3.494, Average Loss: 4.386, avg. samples / sec: 65861.51
Iteration:   1120, Loss function: 5.364, Average Loss: 4.380, avg. samples / sec: 65996.17
Iteration:   1120, Loss function: 3.636, Average Loss: 4.375, avg. samples / sec: 65956.14
Iteration:   1120, Loss function: 4.896, Average Loss: 4.343, avg. samples / sec: 66087.81
Iteration:   1120, Loss function: 4.827, Average Loss: 4.379, avg. samples / sec: 65971.61
Iteration:   1120, Loss function: 5.811, Average Loss: 4.403, avg. samples / sec: 65965.52
Iteration:   1120, Loss function: 3.870, Average Loss: 4.398, avg. samples / sec: 65844.46
Iteration:   1120, Loss function: 5.285, Average Loss: 4.393, avg. samples / sec: 65673.49
Iteration:   1140, Loss function: 5.015, Average Loss: 4.367, avg. samples / sec: 66434.99
Iteration:   1140, Loss function: 3.879, Average Loss: 4.399, avg. samples / sec: 66453.69
Iteration:   1140, Loss function: 5.073, Average Loss: 4.391, avg. samples / sec: 66480.21
Iteration:   1140, Loss function: 4.666, Average Loss: 4.410, avg. samples / sec: 66365.07
Iteration:   1140, Loss function: 5.883, Average Loss: 4.399, avg. samples / sec: 66355.60
Iteration:   1140, Loss function: 4.692, Average Loss: 4.375, avg. samples / sec: 66225.95
Iteration:   1140, Loss function: 5.799, Average Loss: 4.409, avg. samples / sec: 66250.48
Iteration:   1140, Loss function: 4.046, Average Loss: 4.383, avg. samples / sec: 66111.15
Iteration:   1140, Loss function: 3.765, Average Loss: 4.384, avg. samples / sec: 66424.88
Iteration:   1140, Loss function: 4.635, Average Loss: 4.383, avg. samples / sec: 66387.64
Iteration:   1140, Loss function: 5.448, Average Loss: 4.400, avg. samples / sec: 66245.22
Iteration:   1140, Loss function: 4.825, Average Loss: 4.365, avg. samples / sec: 66216.74
Iteration:   1140, Loss function: 4.765, Average Loss: 4.402, avg. samples / sec: 66673.83
Iteration:   1140, Loss function: 4.531, Average Loss: 4.387, avg. samples / sec: 66292.92
Iteration:   1140, Loss function: 4.527, Average Loss: 4.363, avg. samples / sec: 66235.19
Iteration:   1140, Loss function: 5.402, Average Loss: 4.412, avg. samples / sec: 66345.07
Iteration:   1140, Loss function: 5.705, Average Loss: 4.374, avg. samples / sec: 66259.45
Iteration:   1140, Loss function: 5.484, Average Loss: 4.378, avg. samples / sec: 66253.06
Iteration:   1140, Loss function: 4.252, Average Loss: 4.408, avg. samples / sec: 66208.58
Iteration:   1140, Loss function: 5.997, Average Loss: 4.389, avg. samples / sec: 66285.07
Iteration:   1140, Loss function: 4.414, Average Loss: 4.404, avg. samples / sec: 66446.83
Iteration:   1140, Loss function: 5.159, Average Loss: 4.409, avg. samples / sec: 66258.05
Iteration:   1140, Loss function: 5.087, Average Loss: 4.387, avg. samples / sec: 66141.90
Iteration:   1140, Loss function: 4.888, Average Loss: 4.400, avg. samples / sec: 66234.72
Iteration:   1140, Loss function: 5.125, Average Loss: 4.378, avg. samples / sec: 66163.08
Iteration:   1140, Loss function: 4.299, Average Loss: 4.386, avg. samples / sec: 66181.53
Iteration:   1140, Loss function: 5.985, Average Loss: 4.324, avg. samples / sec: 66106.69
Iteration:   1140, Loss function: 4.213, Average Loss: 4.376, avg. samples / sec: 66114.32
Iteration:   1140, Loss function: 3.966, Average Loss: 4.389, avg. samples / sec: 66028.98
Iteration:   1140, Loss function: 5.529, Average Loss: 4.358, avg. samples / sec: 66222.09
Iteration:   1160, Loss function: 4.708, Average Loss: 4.399, avg. samples / sec: 66538.41
Iteration:   1160, Loss function: 4.362, Average Loss: 4.406, avg. samples / sec: 66665.79
Iteration:   1160, Loss function: 3.898, Average Loss: 4.334, avg. samples / sec: 66730.57
Iteration:   1160, Loss function: 5.253, Average Loss: 4.393, avg. samples / sec: 66652.36
Iteration:   1160, Loss function: 4.935, Average Loss: 4.408, avg. samples / sec: 66454.54
Iteration:   1160, Loss function: 4.945, Average Loss: 4.391, avg. samples / sec: 66573.39
Iteration:   1160, Loss function: 5.096, Average Loss: 4.375, avg. samples / sec: 66406.29
Iteration:   1160, Loss function: 4.729, Average Loss: 4.381, avg. samples / sec: 66596.61
Iteration:   1160, Loss function: 5.336, Average Loss: 4.395, avg. samples / sec: 66684.15
Iteration:   1160, Loss function: 4.953, Average Loss: 4.394, avg. samples / sec: 66512.72
Iteration:   1160, Loss function: 4.441, Average Loss: 4.416, avg. samples / sec: 66512.12
Iteration:   1160, Loss function: 4.392, Average Loss: 4.383, avg. samples / sec: 66634.43
Iteration:   1160, Loss function: 3.486, Average Loss: 4.396, avg. samples / sec: 66516.58
Iteration:   1160, Loss function: 4.689, Average Loss: 4.398, avg. samples / sec: 66549.28
Iteration:   1160, Loss function: 4.734, Average Loss: 4.386, avg. samples / sec: 66552.11
Iteration:   1160, Loss function: 5.509, Average Loss: 4.417, avg. samples / sec: 66405.13
Iteration:   1160, Loss function: 4.548, Average Loss: 4.400, avg. samples / sec: 66622.24
Iteration:   1160, Loss function: 4.998, Average Loss: 4.385, avg. samples / sec: 66435.99
Iteration:   1160, Loss function: 3.916, Average Loss: 4.366, avg. samples / sec: 66481.44
Iteration:   1160, Loss function: 4.678, Average Loss: 4.373, avg. samples / sec: 66498.35
Iteration:   1160, Loss function: 4.731, Average Loss: 4.416, avg. samples / sec: 66535.64
Iteration:   1160, Loss function: 5.016, Average Loss: 4.407, avg. samples / sec: 66407.04
Iteration:   1160, Loss function: 4.368, Average Loss: 4.412, avg. samples / sec: 66525.09
Iteration:   1160, Loss function: 4.519, Average Loss: 4.395, avg. samples / sec: 66533.04
Iteration:   1160, Loss function: 5.349, Average Loss: 4.418, avg. samples / sec: 66501.67
Iteration:   1160, Loss function: 5.335, Average Loss: 4.409, avg. samples / sec: 66517.33
Iteration:   1160, Loss function: 4.805, Average Loss: 4.368, avg. samples / sec: 66616.22
Iteration:   1160, Loss function: 4.791, Average Loss: 4.412, avg. samples / sec: 66442.88
Iteration:   1160, Loss function: 4.407, Average Loss: 4.410, avg. samples / sec: 66479.43
Iteration:   1160, Loss function: 4.811, Average Loss: 4.385, avg. samples / sec: 66479.78
Iteration:   1180, Loss function: 5.146, Average Loss: 4.414, avg. samples / sec: 66392.74
Iteration:   1180, Loss function: 4.270, Average Loss: 4.403, avg. samples / sec: 66423.69
Iteration:   1180, Loss function: 5.174, Average Loss: 4.408, avg. samples / sec: 66427.44
Iteration:   1180, Loss function: 5.659, Average Loss: 4.415, avg. samples / sec: 66278.96
Iteration:   1180, Loss function: 5.434, Average Loss: 4.386, avg. samples / sec: 66375.45
Iteration:   1180, Loss function: 4.420, Average Loss: 4.421, avg. samples / sec: 66384.58
Iteration:   1180, Loss function: 4.686, Average Loss: 4.417, avg. samples / sec: 66261.63
Iteration:   1180, Loss function: 5.638, Average Loss: 4.403, avg. samples / sec: 66449.15
Iteration:   1180, Loss function: 4.232, Average Loss: 4.401, avg. samples / sec: 66298.85
Iteration:   1180, Loss function: 5.831, Average Loss: 4.420, avg. samples / sec: 66451.09
Iteration:   1180, Loss function: 5.363, Average Loss: 4.412, avg. samples / sec: 66407.51
Iteration:   1180, Loss function: 3.753, Average Loss: 4.371, avg. samples / sec: 66442.04
Iteration:   1180, Loss function: 4.001, Average Loss: 4.401, avg. samples / sec: 66325.37
Iteration:   1180, Loss function: 4.416, Average Loss: 4.395, avg. samples / sec: 66368.13
Iteration:   1180, Loss function: 4.822, Average Loss: 4.349, avg. samples / sec: 66266.77
Iteration:   1180, Loss function: 4.889, Average Loss: 4.429, avg. samples / sec: 66350.79
Iteration:   1180, Loss function: 5.626, Average Loss: 4.418, avg. samples / sec: 66366.94
Iteration:   1180, Loss function: 4.652, Average Loss: 4.423, avg. samples / sec: 66374.85
Iteration:   1180, Loss function: 6.821, Average Loss: 4.394, avg. samples / sec: 66292.92
Iteration:   1180, Loss function: 5.395, Average Loss: 4.423, avg. samples / sec: 66444.83
Iteration:   1180, Loss function: 4.469, Average Loss: 4.424, avg. samples / sec: 66375.63
Iteration:   1180, Loss function: 4.586, Average Loss: 4.428, avg. samples / sec: 66333.64
Iteration:   1180, Loss function: 4.183, Average Loss: 4.406, avg. samples / sec: 66195.12
Iteration:   1180, Loss function: 4.717, Average Loss: 4.390, avg. samples / sec: 66222.65
Iteration:   1180, Loss function: 4.093, Average Loss: 4.391, avg. samples / sec: 66444.73
Iteration:   1180, Loss function: 4.172, Average Loss: 4.381, avg. samples / sec: 66300.81
Iteration:   1180, Loss function: 4.882, Average Loss: 4.394, avg. samples / sec: 66266.49
Iteration:   1180, Loss function: 4.846, Average Loss: 4.379, avg. samples / sec: 66259.76
Iteration:   1180, Loss function: 5.906, Average Loss: 4.408, avg. samples / sec: 66219.85
Iteration:   1180, Loss function: 3.805, Average Loss: 4.431, avg. samples / sec: 66248.30
:::MLL 1558651220.206 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1558651220.206 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1200, Loss function: 5.684, Average Loss: 4.422, avg. samples / sec: 65959.53
Iteration:   1200, Loss function: 4.854, Average Loss: 4.438, avg. samples / sec: 66187.50
Iteration:   1200, Loss function: 5.716, Average Loss: 4.400, avg. samples / sec: 66018.00
Iteration:   1200, Loss function: 4.520, Average Loss: 4.411, avg. samples / sec: 65915.70
Iteration:   1200, Loss function: 4.801, Average Loss: 4.414, avg. samples / sec: 66088.64
Iteration:   1200, Loss function: 4.727, Average Loss: 4.410, avg. samples / sec: 65959.53
Iteration:   1200, Loss function: 4.685, Average Loss: 4.429, avg. samples / sec: 65942.84
Iteration:   1200, Loss function: 5.374, Average Loss: 4.427, avg. samples / sec: 65985.45
Iteration:   1200, Loss function: 5.124, Average Loss: 4.431, avg. samples / sec: 65924.73
Iteration:   1200, Loss function: 5.633, Average Loss: 4.407, avg. samples / sec: 65983.41
Iteration:   1200, Loss function: 4.412, Average Loss: 4.418, avg. samples / sec: 65823.58
Iteration:   1200, Loss function: 3.873, Average Loss: 4.359, avg. samples / sec: 65952.90
Iteration:   1200, Loss function: 4.671, Average Loss: 4.400, avg. samples / sec: 65855.08
Iteration:   1200, Loss function: 5.070, Average Loss: 4.421, avg. samples / sec: 65866.53
Iteration:   1200, Loss function: 4.888, Average Loss: 4.411, avg. samples / sec: 65911.90
Iteration:   1200, Loss function: 5.213, Average Loss: 4.417, avg. samples / sec: 66026.13
Iteration:   1200, Loss function: 4.627, Average Loss: 4.390, avg. samples / sec: 66026.07
Iteration:   1200, Loss function: 4.722, Average Loss: 4.398, avg. samples / sec: 65973.46
Iteration:   1200, Loss function: 3.659, Average Loss: 4.432, avg. samples / sec: 65964.17
Iteration:   1200, Loss function: 6.063, Average Loss: 4.419, avg. samples / sec: 65770.04
Iteration:   1200, Loss function: 3.757, Average Loss: 4.431, avg. samples / sec: 65883.52
Iteration:   1200, Loss function: 4.581, Average Loss: 4.419, avg. samples / sec: 65833.91
Iteration:   1200, Loss function: 4.357, Average Loss: 4.397, avg. samples / sec: 65926.09
Iteration:   1200, Loss function: 4.349, Average Loss: 4.378, avg. samples / sec: 65816.79
Iteration:   1200, Loss function: 5.425, Average Loss: 4.413, avg. samples / sec: 65782.69
Iteration:   1200, Loss function: 4.456, Average Loss: 4.386, avg. samples / sec: 65914.49
Iteration:   1200, Loss function: 4.278, Average Loss: 4.428, avg. samples / sec: 65879.89
Iteration:   1200, Loss function: 4.830, Average Loss: 4.439, avg. samples / sec: 65826.50
Iteration:   1200, Loss function: 5.199, Average Loss: 4.430, avg. samples / sec: 65860.83
Iteration:   1200, Loss function: 5.287, Average Loss: 4.402, avg. samples / sec: 65907.99
Iteration:   1220, Loss function: 5.323, Average Loss: 4.408, avg. samples / sec: 66862.68
Iteration:   1220, Loss function: 4.897, Average Loss: 4.422, avg. samples / sec: 66776.35
Iteration:   1220, Loss function: 4.480, Average Loss: 4.405, avg. samples / sec: 66736.32
Iteration:   1220, Loss function: 5.730, Average Loss: 4.437, avg. samples / sec: 66812.25
Iteration:   1220, Loss function: 3.604, Average Loss: 4.437, avg. samples / sec: 66762.81
Iteration:   1220, Loss function: 3.738, Average Loss: 4.428, avg. samples / sec: 66775.46
Iteration:   1220, Loss function: 4.291, Average Loss: 4.438, avg. samples / sec: 66850.19
Iteration:   1220, Loss function: 5.689, Average Loss: 4.389, avg. samples / sec: 66883.69
Iteration:   1220, Loss function: 5.563, Average Loss: 4.436, avg. samples / sec: 66680.87
Iteration:   1220, Loss function: 4.872, Average Loss: 4.437, avg. samples / sec: 66877.79
Iteration:   1220, Loss function: 4.113, Average Loss: 4.429, avg. samples / sec: 66641.99
Iteration:   1220, Loss function: 4.876, Average Loss: 4.432, avg. samples / sec: 66826.22
Iteration:   1220, Loss function: 4.601, Average Loss: 4.418, avg. samples / sec: 66659.23
Iteration:   1220, Loss function: 4.567, Average Loss: 4.446, avg. samples / sec: 66626.02
Iteration:   1220, Loss function: 6.554, Average Loss: 4.421, avg. samples / sec: 66830.02
Iteration:   1220, Loss function: 3.853, Average Loss: 4.452, avg. samples / sec: 66848.41
Iteration:   1220, Loss function: 5.206, Average Loss: 4.430, avg. samples / sec: 66727.06
Iteration:   1220, Loss function: 3.428, Average Loss: 4.367, avg. samples / sec: 66667.24
Iteration:   1220, Loss function: 4.163, Average Loss: 4.421, avg. samples / sec: 66607.59
Iteration:   1220, Loss function: 5.428, Average Loss: 4.417, avg. samples / sec: 66631.72
Iteration:   1220, Loss function: 4.731, Average Loss: 4.410, avg. samples / sec: 66766.13
Iteration:   1220, Loss function: 4.902, Average Loss: 4.398, avg. samples / sec: 66657.25
Iteration:   1220, Loss function: 4.714, Average Loss: 4.447, avg. samples / sec: 66667.78
Iteration:   1220, Loss function: 4.356, Average Loss: 4.387, avg. samples / sec: 66716.51
Iteration:   1220, Loss function: 5.539, Average Loss: 4.405, avg. samples / sec: 66654.19
Iteration:   1220, Loss function: 5.298, Average Loss: 4.424, avg. samples / sec: 66620.82
Iteration:   1220, Loss function: 4.951, Average Loss: 4.440, avg. samples / sec: 66688.03
Iteration:   1220, Loss function: 5.838, Average Loss: 4.425, avg. samples / sec: 66633.17
Iteration:   1220, Loss function: 5.972, Average Loss: 4.440, avg. samples / sec: 66515.42
Iteration:   1220, Loss function: 5.565, Average Loss: 4.413, avg. samples / sec: 66628.50
Iteration:   1240, Loss function: 4.610, Average Loss: 4.418, avg. samples / sec: 66539.00
Iteration:   1240, Loss function: 5.419, Average Loss: 4.413, avg. samples / sec: 66486.83
Iteration:   1240, Loss function: 5.921, Average Loss: 4.440, avg. samples / sec: 66491.16
Iteration:   1240, Loss function: 4.641, Average Loss: 4.428, avg. samples / sec: 66566.66
Iteration:   1240, Loss function: 4.825, Average Loss: 4.424, avg. samples / sec: 66714.08
Iteration:   1240, Loss function: 4.994, Average Loss: 4.438, avg. samples / sec: 66497.62
Iteration:   1240, Loss function: 4.500, Average Loss: 4.438, avg. samples / sec: 66506.38
Iteration:   1240, Loss function: 4.697, Average Loss: 4.430, avg. samples / sec: 66396.27
Iteration:   1240, Loss function: 4.534, Average Loss: 4.461, avg. samples / sec: 66530.68
Iteration:   1240, Loss function: 5.204, Average Loss: 4.446, avg. samples / sec: 66485.42
Iteration:   1240, Loss function: 4.617, Average Loss: 4.401, avg. samples / sec: 66465.95
Iteration:   1240, Loss function: 3.859, Average Loss: 4.443, avg. samples / sec: 66692.80
Iteration:   1240, Loss function: 5.429, Average Loss: 4.445, avg. samples / sec: 66492.70
Iteration:   1240, Loss function: 5.396, Average Loss: 4.426, avg. samples / sec: 66497.31
Iteration:   1240, Loss function: 4.061, Average Loss: 4.434, avg. samples / sec: 66467.26
Iteration:   1240, Loss function: 6.005, Average Loss: 4.447, avg. samples / sec: 66424.88
Iteration:   1240, Loss function: 4.774, Average Loss: 4.452, avg. samples / sec: 66486.49
Iteration:   1240, Loss function: 5.495, Average Loss: 4.458, avg. samples / sec: 66589.40
Iteration:   1240, Loss function: 4.246, Average Loss: 4.435, avg. samples / sec: 66511.68
Iteration:   1240, Loss function: 4.401, Average Loss: 4.367, avg. samples / sec: 66536.55
Iteration:   1240, Loss function: 5.255, Average Loss: 4.444, avg. samples / sec: 66625.86
Iteration:   1240, Loss function: 3.411, Average Loss: 4.428, avg. samples / sec: 66527.10
Iteration:   1240, Loss function: 4.597, Average Loss: 4.444, avg. samples / sec: 66398.65
Iteration:   1240, Loss function: 4.877, Average Loss: 4.425, avg. samples / sec: 66621.04
Iteration:   1240, Loss function: 3.861, Average Loss: 4.408, avg. samples / sec: 66526.75
Iteration:   1240, Loss function: 4.331, Average Loss: 4.416, avg. samples / sec: 66551.79
Iteration:   1240, Loss function: 5.039, Average Loss: 4.432, avg. samples / sec: 66456.11
Iteration:   1240, Loss function: 4.350, Average Loss: 4.428, avg. samples / sec: 66501.14
Iteration:   1240, Loss function: 5.076, Average Loss: 4.416, avg. samples / sec: 66461.22
Iteration:   1240, Loss function: 5.109, Average Loss: 4.398, avg. samples / sec: 66465.04
:::MLL 1558651221.975 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1558651221.975 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1260, Loss function: 4.059, Average Loss: 4.444, avg. samples / sec: 66396.40
Iteration:   1260, Loss function: 4.600, Average Loss: 4.440, avg. samples / sec: 66401.75
Iteration:   1260, Loss function: 4.244, Average Loss: 4.440, avg. samples / sec: 66376.76
Iteration:   1260, Loss function: 5.840, Average Loss: 4.440, avg. samples / sec: 66441.69
Iteration:   1260, Loss function: 4.001, Average Loss: 4.446, avg. samples / sec: 66380.86
Iteration:   1260, Loss function: 5.120, Average Loss: 4.368, avg. samples / sec: 66436.46
Iteration:   1260, Loss function: 4.359, Average Loss: 4.457, avg. samples / sec: 66408.10
Iteration:   1260, Loss function: 3.749, Average Loss: 4.411, avg. samples / sec: 66424.97
Iteration:   1260, Loss function: 3.842, Average Loss: 4.421, avg. samples / sec: 66405.03
Iteration:   1260, Loss function: 5.203, Average Loss: 4.433, avg. samples / sec: 66459.18
Iteration:   1260, Loss function: 6.826, Average Loss: 4.438, avg. samples / sec: 66344.76
Iteration:   1260, Loss function: 5.412, Average Loss: 4.431, avg. samples / sec: 66400.28
Iteration:   1260, Loss function: 5.245, Average Loss: 4.455, avg. samples / sec: 66342.20
Iteration:   1260, Loss function: 5.186, Average Loss: 4.421, avg. samples / sec: 66258.58
Iteration:   1260, Loss function: 4.005, Average Loss: 4.449, avg. samples / sec: 66326.21
Iteration:   1260, Loss function: 5.062, Average Loss: 4.434, avg. samples / sec: 66288.50
Iteration:   1260, Loss function: 4.990, Average Loss: 4.422, avg. samples / sec: 66281.73
Iteration:   1260, Loss function: 4.098, Average Loss: 4.449, avg. samples / sec: 66383.14
Iteration:   1260, Loss function: 4.544, Average Loss: 4.403, avg. samples / sec: 66469.40
Iteration:   1260, Loss function: 4.706, Average Loss: 4.440, avg. samples / sec: 66331.58
Iteration:   1260, Loss function: 6.213, Average Loss: 4.452, avg. samples / sec: 66286.88
Iteration:   1260, Loss function: 3.705, Average Loss: 4.430, avg. samples / sec: 66114.72
Iteration:   1260, Loss function: 4.675, Average Loss: 4.405, avg. samples / sec: 66278.33
Iteration:   1260, Loss function: 5.035, Average Loss: 4.462, avg. samples / sec: 66271.01
Iteration:   1260, Loss function: 2.790, Average Loss: 4.436, avg. samples / sec: 66295.48
Iteration:   1260, Loss function: 4.928, Average Loss: 4.453, avg. samples / sec: 66268.45
Iteration:   1260, Loss function: 3.839, Average Loss: 4.424, avg. samples / sec: 66333.58
Iteration:   1260, Loss function: 3.880, Average Loss: 4.431, avg. samples / sec: 66346.01
Iteration:   1260, Loss function: 4.453, Average Loss: 4.446, avg. samples / sec: 66214.00
Iteration:   1260, Loss function: 4.293, Average Loss: 4.464, avg. samples / sec: 66181.41
Iteration:   1280, Loss function: 4.720, Average Loss: 4.438, avg. samples / sec: 66231.30
Iteration:   1280, Loss function: 4.742, Average Loss: 4.448, avg. samples / sec: 66018.03
Iteration:   1280, Loss function: 3.658, Average Loss: 4.445, avg. samples / sec: 66039.16
Iteration:   1280, Loss function: 4.364, Average Loss: 4.446, avg. samples / sec: 66024.74
Iteration:   1280, Loss function: 5.837, Average Loss: 4.437, avg. samples / sec: 66138.80
Iteration:   1280, Loss function: 3.823, Average Loss: 4.446, avg. samples / sec: 66057.20
Iteration:   1280, Loss function: 4.168, Average Loss: 4.469, avg. samples / sec: 66123.56
Iteration:   1280, Loss function: 4.350, Average Loss: 4.419, avg. samples / sec: 66016.94
Iteration:   1280, Loss function: 4.870, Average Loss: 4.459, avg. samples / sec: 66171.03
Iteration:   1280, Loss function: 4.778, Average Loss: 4.462, avg. samples / sec: 66027.49
Iteration:   1280, Loss function: 4.478, Average Loss: 4.429, avg. samples / sec: 66025.82
Iteration:   1280, Loss function: 4.475, Average Loss: 4.447, avg. samples / sec: 66054.79
Iteration:   1280, Loss function: 5.392, Average Loss: 4.468, avg. samples / sec: 66111.96
Iteration:   1280, Loss function: 4.537, Average Loss: 4.458, avg. samples / sec: 65986.28
Iteration:   1280, Loss function: 5.055, Average Loss: 4.459, avg. samples / sec: 66012.43
Iteration:   1280, Loss function: 4.606, Average Loss: 4.445, avg. samples / sec: 65958.45
Iteration:   1280, Loss function: 5.653, Average Loss: 4.460, avg. samples / sec: 65902.87
Iteration:   1280, Loss function: 3.870, Average Loss: 4.471, avg. samples / sec: 66100.70
Iteration:   1280, Loss function: 5.106, Average Loss: 4.431, avg. samples / sec: 65966.98
Iteration:   1280, Loss function: 4.055, Average Loss: 4.441, avg. samples / sec: 65863.76
Iteration:   1280, Loss function: 4.100, Average Loss: 4.448, avg. samples / sec: 65851.32
Iteration:   1280, Loss function: 5.501, Average Loss: 4.429, avg. samples / sec: 65945.65
Iteration:   1280, Loss function: 4.660, Average Loss: 4.429, avg. samples / sec: 66049.68
Iteration:   1280, Loss function: 4.227, Average Loss: 4.455, avg. samples / sec: 65959.41
Iteration:   1280, Loss function: 4.427, Average Loss: 4.369, avg. samples / sec: 65850.31
Iteration:   1280, Loss function: 5.489, Average Loss: 4.436, avg. samples / sec: 65905.31
Iteration:   1280, Loss function: 5.930, Average Loss: 4.441, avg. samples / sec: 65872.72
Iteration:   1280, Loss function: 6.154, Average Loss: 4.414, avg. samples / sec: 65903.24
Iteration:   1280, Loss function: 4.787, Average Loss: 4.440, avg. samples / sec: 65945.12
Iteration:   1280, Loss function: 4.915, Average Loss: 4.410, avg. samples / sec: 65749.72
Iteration:   1300, Loss function: 3.142, Average Loss: 4.449, avg. samples / sec: 66166.56
Iteration:   1300, Loss function: 4.223, Average Loss: 4.441, avg. samples / sec: 66159.23
Iteration:   1300, Loss function: 5.112, Average Loss: 4.466, avg. samples / sec: 66221.28
Iteration:   1300, Loss function: 4.450, Average Loss: 4.443, avg. samples / sec: 66172.80
Iteration:   1300, Loss function: 4.716, Average Loss: 4.449, avg. samples / sec: 66301.91
Iteration:   1300, Loss function: 4.241, Average Loss: 4.438, avg. samples / sec: 66303.09
Iteration:   1300, Loss function: 4.643, Average Loss: 4.478, avg. samples / sec: 66274.16
Iteration:   1300, Loss function: 5.713, Average Loss: 4.465, avg. samples / sec: 66276.65
Iteration:   1300, Loss function: 4.368, Average Loss: 4.456, avg. samples / sec: 66094.60
Iteration:   1300, Loss function: 5.041, Average Loss: 4.377, avg. samples / sec: 66284.16
Iteration:   1300, Loss function: 6.260, Average Loss: 4.433, avg. samples / sec: 66189.03
Iteration:   1300, Loss function: 5.030, Average Loss: 4.453, avg. samples / sec: 66142.30
Iteration:   1300, Loss function: 3.776, Average Loss: 4.428, avg. samples / sec: 66161.96
Iteration:   1300, Loss function: 4.751, Average Loss: 4.445, avg. samples / sec: 66295.01
Iteration:   1300, Loss function: 4.405, Average Loss: 4.471, avg. samples / sec: 66143.48
Iteration:   1300, Loss function: 5.074, Average Loss: 4.465, avg. samples / sec: 66178.83
Iteration:   1300, Loss function: 4.036, Average Loss: 4.450, avg. samples / sec: 66322.72
Iteration:   1300, Loss function: 5.913, Average Loss: 4.436, avg. samples / sec: 66232.08
Iteration:   1300, Loss function: 4.480, Average Loss: 4.464, avg. samples / sec: 66210.76
Iteration:   1300, Loss function: 4.549, Average Loss: 4.450, avg. samples / sec: 66053.30
Iteration:   1300, Loss function: 5.436, Average Loss: 4.464, avg. samples / sec: 66221.68
Iteration:   1300, Loss function: 4.202, Average Loss: 4.454, avg. samples / sec: 66115.40
Iteration:   1300, Loss function: 6.976, Average Loss: 4.455, avg. samples / sec: 66148.27
Iteration:   1300, Loss function: 4.366, Average Loss: 4.449, avg. samples / sec: 66248.86
Iteration:   1300, Loss function: 5.071, Average Loss: 4.468, avg. samples / sec: 66093.63
Iteration:   1300, Loss function: 5.840, Average Loss: 4.472, avg. samples / sec: 66008.29
Iteration:   1300, Loss function: 4.963, Average Loss: 4.413, avg. samples / sec: 66345.51
Iteration:   1300, Loss function: 4.852, Average Loss: 4.440, avg. samples / sec: 66087.65
Iteration:   1300, Loss function: 3.895, Average Loss: 4.474, avg. samples / sec: 66002.63
Iteration:   1300, Loss function: 5.131, Average Loss: 4.426, avg. samples / sec: 66132.25
Iteration:   1320, Loss function: 5.117, Average Loss: 4.474, avg. samples / sec: 66497.56
Iteration:   1320, Loss function: 4.724, Average Loss: 4.479, avg. samples / sec: 66420.65
Iteration:   1320, Loss function: 4.485, Average Loss: 4.453, avg. samples / sec: 66487.49
Iteration:   1320, Loss function: 5.368, Average Loss: 4.467, avg. samples / sec: 66438.75
Iteration:   1320, Loss function: 4.818, Average Loss: 4.445, avg. samples / sec: 66368.48
Iteration:   1320, Loss function: 3.511, Average Loss: 4.458, avg. samples / sec: 66334.92
Iteration:   1320, Loss function: 5.199, Average Loss: 4.459, avg. samples / sec: 66439.56
Iteration:   1320, Loss function: 5.111, Average Loss: 4.446, avg. samples / sec: 66398.28
Iteration:   1320, Loss function: 3.663, Average Loss: 4.442, avg. samples / sec: 66584.75
Iteration:   1320, Loss function: 5.119, Average Loss: 4.453, avg. samples / sec: 66399.46
Iteration:   1320, Loss function: 4.321, Average Loss: 4.456, avg. samples / sec: 66474.79
Iteration:   1320, Loss function: 4.486, Average Loss: 4.475, avg. samples / sec: 66325.81
Iteration:   1320, Loss function: 4.691, Average Loss: 4.486, avg. samples / sec: 66585.66
Iteration:   1320, Loss function: 5.958, Average Loss: 4.438, avg. samples / sec: 66369.07
Iteration:   1320, Loss function: 4.543, Average Loss: 4.442, avg. samples / sec: 66380.11
Iteration:   1320, Loss function: 4.524, Average Loss: 4.441, avg. samples / sec: 66386.61
Iteration:   1320, Loss function: 4.970, Average Loss: 4.472, avg. samples / sec: 66401.15
Iteration:   1320, Loss function: 6.192, Average Loss: 4.455, avg. samples / sec: 66322.41
Iteration:   1320, Loss function: 4.293, Average Loss: 4.473, avg. samples / sec: 66513.19
Iteration:   1320, Loss function: 3.856, Average Loss: 4.455, avg. samples / sec: 66435.21
Iteration:   1320, Loss function: 3.401, Average Loss: 4.472, avg. samples / sec: 66378.48
Iteration:   1320, Loss function: 5.308, Average Loss: 4.469, avg. samples / sec: 66325.40
Iteration:   1320, Loss function: 4.787, Average Loss: 4.456, avg. samples / sec: 66341.55
Iteration:   1320, Loss function: 4.312, Average Loss: 4.425, avg. samples / sec: 66527.32
Iteration:   1320, Loss function: 3.921, Average Loss: 4.475, avg. samples / sec: 66446.36
Iteration:   1320, Loss function: 5.032, Average Loss: 4.469, avg. samples / sec: 66399.03
Iteration:   1320, Loss function: 4.499, Average Loss: 4.442, avg. samples / sec: 66256.93
Iteration:   1320, Loss function: 4.859, Average Loss: 4.457, avg. samples / sec: 66383.51
Iteration:   1320, Loss function: 4.163, Average Loss: 4.414, avg. samples / sec: 66472.69
Iteration:   1320, Loss function: 6.572, Average Loss: 4.387, avg. samples / sec: 66279.27
:::MLL 1558651223.753 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1558651223.753 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1340, Loss function: 4.260, Average Loss: 4.439, avg. samples / sec: 66068.20
Iteration:   1340, Loss function: 4.901, Average Loss: 4.443, avg. samples / sec: 66103.37
Iteration:   1340, Loss function: 4.699, Average Loss: 4.457, avg. samples / sec: 65958.42
Iteration:   1340, Loss function: 3.764, Average Loss: 4.459, avg. samples / sec: 66053.36
Iteration:   1340, Loss function: 4.155, Average Loss: 4.463, avg. samples / sec: 65980.01
Iteration:   1340, Loss function: 3.544, Average Loss: 4.479, avg. samples / sec: 65929.79
Iteration:   1340, Loss function: 4.476, Average Loss: 4.474, avg. samples / sec: 66032.66
Iteration:   1340, Loss function: 4.629, Average Loss: 4.466, avg. samples / sec: 65923.90
Iteration:   1340, Loss function: 4.979, Average Loss: 4.448, avg. samples / sec: 65993.26
Iteration:   1340, Loss function: 3.130, Average Loss: 4.452, avg. samples / sec: 65967.50
Iteration:   1340, Loss function: 4.539, Average Loss: 4.477, avg. samples / sec: 66016.05
Iteration:   1340, Loss function: 3.632, Average Loss: 4.469, avg. samples / sec: 65998.95
Iteration:   1340, Loss function: 5.344, Average Loss: 4.430, avg. samples / sec: 66006.99
Iteration:   1340, Loss function: 4.051, Average Loss: 4.476, avg. samples / sec: 65982.70
Iteration:   1340, Loss function: 4.508, Average Loss: 4.446, avg. samples / sec: 65914.25
Iteration:   1340, Loss function: 5.186, Average Loss: 4.464, avg. samples / sec: 65912.80
Iteration:   1340, Loss function: 4.137, Average Loss: 4.458, avg. samples / sec: 65977.01
Iteration:   1340, Loss function: 4.505, Average Loss: 4.418, avg. samples / sec: 66015.52
Iteration:   1340, Loss function: 5.514, Average Loss: 4.449, avg. samples / sec: 65936.88
Iteration:   1340, Loss function: 4.194, Average Loss: 4.481, avg. samples / sec: 65834.00
Iteration:   1340, Loss function: 5.413, Average Loss: 4.486, avg. samples / sec: 65905.80
Iteration:   1340, Loss function: 3.568, Average Loss: 4.471, avg. samples / sec: 65935.53
Iteration:   1340, Loss function: 4.470, Average Loss: 4.455, avg. samples / sec: 65954.10
Iteration:   1340, Loss function: 4.098, Average Loss: 4.459, avg. samples / sec: 65882.88
Iteration:   1340, Loss function: 5.447, Average Loss: 4.476, avg. samples / sec: 65887.28
Iteration:   1340, Loss function: 3.292, Average Loss: 4.473, avg. samples / sec: 65911.07
Iteration:   1340, Loss function: 5.930, Average Loss: 4.449, avg. samples / sec: 65835.63
Iteration:   1340, Loss function: 4.714, Average Loss: 4.389, avg. samples / sec: 65978.84
Iteration:   1340, Loss function: 5.771, Average Loss: 4.465, avg. samples / sec: 65863.26
Iteration:   1340, Loss function: 3.725, Average Loss: 4.444, avg. samples / sec: 65778.75
Iteration:   1360, Loss function: 5.074, Average Loss: 4.455, avg. samples / sec: 66891.56
Iteration:   1360, Loss function: 4.848, Average Loss: 4.461, avg. samples / sec: 66693.17
Iteration:   1360, Loss function: 3.369, Average Loss: 4.439, avg. samples / sec: 66596.23
Iteration:   1360, Loss function: 4.541, Average Loss: 4.486, avg. samples / sec: 66735.15
Iteration:   1360, Loss function: 4.215, Average Loss: 4.473, avg. samples / sec: 66628.69
Iteration:   1360, Loss function: 4.406, Average Loss: 4.443, avg. samples / sec: 66559.24
Iteration:   1360, Loss function: 4.289, Average Loss: 4.475, avg. samples / sec: 66594.47
Iteration:   1360, Loss function: 5.295, Average Loss: 4.476, avg. samples / sec: 66615.28
Iteration:   1360, Loss function: 5.416, Average Loss: 4.476, avg. samples / sec: 66689.04
Iteration:   1360, Loss function: 3.914, Average Loss: 4.455, avg. samples / sec: 66613.51
Iteration:   1360, Loss function: 4.087, Average Loss: 4.484, avg. samples / sec: 66569.30
Iteration:   1360, Loss function: 4.774, Average Loss: 4.467, avg. samples / sec: 66620.06
Iteration:   1360, Loss function: 3.760, Average Loss: 4.461, avg. samples / sec: 66666.55
Iteration:   1360, Loss function: 4.511, Average Loss: 4.424, avg. samples / sec: 66635.47
Iteration:   1360, Loss function: 4.626, Average Loss: 4.468, avg. samples / sec: 66552.39
Iteration:   1360, Loss function: 5.954, Average Loss: 4.454, avg. samples / sec: 66638.27
Iteration:   1360, Loss function: 4.153, Average Loss: 4.445, avg. samples / sec: 66757.34
Iteration:   1360, Loss function: 4.720, Average Loss: 4.473, avg. samples / sec: 66666.36
Iteration:   1360, Loss function: 3.761, Average Loss: 4.491, avg. samples / sec: 66633.39
Iteration:   1360, Loss function: 4.685, Average Loss: 4.472, avg. samples / sec: 66670.33
Iteration:   1360, Loss function: 4.303, Average Loss: 4.393, avg. samples / sec: 66668.85
Iteration:   1360, Loss function: 3.798, Average Loss: 4.436, avg. samples / sec: 66580.15
Iteration:   1360, Loss function: 3.985, Average Loss: 4.483, avg. samples / sec: 66571.06
Iteration:   1360, Loss function: 5.107, Average Loss: 4.460, avg. samples / sec: 66555.22
Iteration:   1360, Loss function: 4.454, Average Loss: 4.470, avg. samples / sec: 66574.15
Iteration:   1360, Loss function: 4.385, Average Loss: 4.449, avg. samples / sec: 66490.38
Iteration:   1360, Loss function: 4.519, Average Loss: 4.460, avg. samples / sec: 66558.87
Iteration:   1360, Loss function: 4.223, Average Loss: 4.480, avg. samples / sec: 66470.49
Iteration:   1360, Loss function: 4.837, Average Loss: 4.466, avg. samples / sec: 66394.71
Iteration:   1360, Loss function: 3.960, Average Loss: 4.452, avg. samples / sec: 66446.02
Iteration:   1380, Loss function: 5.527, Average Loss: 4.470, avg. samples / sec: 66675.03
Iteration:   1380, Loss function: 4.088, Average Loss: 4.459, avg. samples / sec: 66664.12
Iteration:   1380, Loss function: 4.556, Average Loss: 4.474, avg. samples / sec: 66571.95
Iteration:   1380, Loss function: 4.638, Average Loss: 4.474, avg. samples / sec: 66578.30
Iteration:   1380, Loss function: 5.554, Average Loss: 4.474, avg. samples / sec: 66667.52
Iteration:   1380, Loss function: 5.007, Average Loss: 4.461, avg. samples / sec: 66591.73
Iteration:   1380, Loss function: 4.610, Average Loss: 4.460, avg. samples / sec: 66382.39
Iteration:   1380, Loss function: 4.232, Average Loss: 4.473, avg. samples / sec: 66618.11
Iteration:   1380, Loss function: 4.673, Average Loss: 4.467, avg. samples / sec: 66700.53
Iteration:   1380, Loss function: 3.584, Average Loss: 4.480, avg. samples / sec: 66538.97
Iteration:   1380, Loss function: 4.480, Average Loss: 4.477, avg. samples / sec: 66526.19
Iteration:   1380, Loss function: 4.046, Average Loss: 4.469, avg. samples / sec: 66606.46
Iteration:   1380, Loss function: 4.179, Average Loss: 4.488, avg. samples / sec: 66446.71
Iteration:   1380, Loss function: 4.047, Average Loss: 4.456, avg. samples / sec: 66535.55
Iteration:   1380, Loss function: 4.718, Average Loss: 4.455, avg. samples / sec: 66674.37
Iteration:   1380, Loss function: 4.871, Average Loss: 4.461, avg. samples / sec: 66621.17
Iteration:   1380, Loss function: 4.772, Average Loss: 4.448, avg. samples / sec: 66509.71
Iteration:   1380, Loss function: 4.470, Average Loss: 4.448, avg. samples / sec: 66381.92
Iteration:   1380, Loss function: 3.323, Average Loss: 4.478, avg. samples / sec: 66610.99
Iteration:   1380, Loss function: 4.908, Average Loss: 4.482, avg. samples / sec: 66516.20
Iteration:   1380, Loss function: 4.898, Average Loss: 4.469, avg. samples / sec: 66294.05
Iteration:   1380, Loss function: 3.982, Average Loss: 4.453, avg. samples / sec: 66552.11
Iteration:   1380, Loss function: 4.448, Average Loss: 4.398, avg. samples / sec: 66498.50
Iteration:   1380, Loss function: 4.672, Average Loss: 4.444, avg. samples / sec: 66479.34
Iteration:   1380, Loss function: 5.186, Average Loss: 4.465, avg. samples / sec: 66441.82
Iteration:   1380, Loss function: 5.220, Average Loss: 4.491, avg. samples / sec: 66463.50
Iteration:   1380, Loss function: 5.964, Average Loss: 4.485, avg. samples / sec: 66421.06
Iteration:   1380, Loss function: 4.717, Average Loss: 4.452, avg. samples / sec: 66411.86
Iteration:   1380, Loss function: 4.480, Average Loss: 4.433, avg. samples / sec: 66428.38
Iteration:   1380, Loss function: 5.294, Average Loss: 4.478, avg. samples / sec: 66400.34
:::MLL 1558651225.525 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1558651225.526 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1400, Loss function: 4.044, Average Loss: 4.479, avg. samples / sec: 66268.05
Iteration:   1400, Loss function: 4.202, Average Loss: 4.477, avg. samples / sec: 66115.96
Iteration:   1400, Loss function: 4.165, Average Loss: 4.488, avg. samples / sec: 66256.49
Iteration:   1400, Loss function: 5.538, Average Loss: 4.468, avg. samples / sec: 66223.18
Iteration:   1400, Loss function: 4.580, Average Loss: 4.466, avg. samples / sec: 66093.60
Iteration:   1400, Loss function: 4.694, Average Loss: 4.453, avg. samples / sec: 66176.59
Iteration:   1400, Loss function: 4.584, Average Loss: 4.457, avg. samples / sec: 66182.90
Iteration:   1400, Loss function: 3.952, Average Loss: 4.472, avg. samples / sec: 66104.64
Iteration:   1400, Loss function: 4.832, Average Loss: 4.479, avg. samples / sec: 66055.13
Iteration:   1400, Loss function: 3.247, Average Loss: 4.399, avg. samples / sec: 66200.72
Iteration:   1400, Loss function: 4.562, Average Loss: 4.466, avg. samples / sec: 66177.56
Iteration:   1400, Loss function: 4.357, Average Loss: 4.461, avg. samples / sec: 66125.70
Iteration:   1400, Loss function: 4.532, Average Loss: 4.453, avg. samples / sec: 66132.19
Iteration:   1400, Loss function: 4.199, Average Loss: 4.485, avg. samples / sec: 66084.40
Iteration:   1400, Loss function: 4.697, Average Loss: 4.476, avg. samples / sec: 65934.85
Iteration:   1400, Loss function: 5.480, Average Loss: 4.473, avg. samples / sec: 66065.07
Iteration:   1400, Loss function: 5.009, Average Loss: 4.458, avg. samples / sec: 66076.78
Iteration:   1400, Loss function: 5.828, Average Loss: 4.490, avg. samples / sec: 66082.76
Iteration:   1400, Loss function: 4.088, Average Loss: 4.457, avg. samples / sec: 65938.02
Iteration:   1400, Loss function: 5.556, Average Loss: 4.493, avg. samples / sec: 66155.16
Iteration:   1400, Loss function: 5.592, Average Loss: 4.487, avg. samples / sec: 66087.78
Iteration:   1400, Loss function: 4.807, Average Loss: 4.479, avg. samples / sec: 66011.81
Iteration:   1400, Loss function: 5.107, Average Loss: 4.486, avg. samples / sec: 65978.77
Iteration:   1400, Loss function: 4.901, Average Loss: 4.459, avg. samples / sec: 66016.63
Iteration:   1400, Loss function: 3.891, Average Loss: 4.448, avg. samples / sec: 66084.77
Iteration:   1400, Loss function: 4.280, Average Loss: 4.472, avg. samples / sec: 65951.69
Iteration:   1400, Loss function: 4.246, Average Loss: 4.463, avg. samples / sec: 65917.30
Iteration:   1400, Loss function: 4.430, Average Loss: 4.478, avg. samples / sec: 66081.83
Iteration:   1400, Loss function: 4.467, Average Loss: 4.439, avg. samples / sec: 66010.82
Iteration:   1400, Loss function: 3.908, Average Loss: 4.454, avg. samples / sec: 65982.14
Iteration:   1420, Loss function: 3.642, Average Loss: 4.474, avg. samples / sec: 66225.35
Iteration:   1420, Loss function: 3.978, Average Loss: 4.473, avg. samples / sec: 66162.49
Iteration:   1420, Loss function: 4.072, Average Loss: 4.487, avg. samples / sec: 66257.08
Iteration:   1420, Loss function: 4.319, Average Loss: 4.472, avg. samples / sec: 66200.44
Iteration:   1420, Loss function: 5.094, Average Loss: 4.480, avg. samples / sec: 66275.37
Iteration:   1420, Loss function: 6.001, Average Loss: 4.490, avg. samples / sec: 66185.98
Iteration:   1420, Loss function: 4.130, Average Loss: 4.473, avg. samples / sec: 66169.48
Iteration:   1420, Loss function: 4.858, Average Loss: 4.482, avg. samples / sec: 66177.65
Iteration:   1420, Loss function: 4.801, Average Loss: 4.407, avg. samples / sec: 66149.88
Iteration:   1420, Loss function: 4.110, Average Loss: 4.497, avg. samples / sec: 66215.27
Iteration:   1420, Loss function: 4.818, Average Loss: 4.451, avg. samples / sec: 66267.86
Iteration:   1420, Loss function: 4.924, Average Loss: 4.492, avg. samples / sec: 66166.12
Iteration:   1420, Loss function: 6.305, Average Loss: 4.456, avg. samples / sec: 66104.11
Iteration:   1420, Loss function: 4.635, Average Loss: 4.461, avg. samples / sec: 66355.70
Iteration:   1420, Loss function: 4.295, Average Loss: 4.459, avg. samples / sec: 66130.48
Iteration:   1420, Loss function: 4.171, Average Loss: 4.461, avg. samples / sec: 66114.84
Iteration:   1420, Loss function: 4.253, Average Loss: 4.473, avg. samples / sec: 66236.75
Iteration:   1420, Loss function: 4.563, Average Loss: 4.462, avg. samples / sec: 66235.28
Iteration:   1420, Loss function: 3.174, Average Loss: 4.468, avg. samples / sec: 66119.06
Iteration:   1420, Loss function: 4.871, Average Loss: 4.490, avg. samples / sec: 66057.17
Iteration:   1420, Loss function: 3.730, Average Loss: 4.460, avg. samples / sec: 66187.91
Iteration:   1420, Loss function: 4.274, Average Loss: 4.458, avg. samples / sec: 66112.73
Iteration:   1420, Loss function: 5.540, Average Loss: 4.485, avg. samples / sec: 66156.65
Iteration:   1420, Loss function: 4.234, Average Loss: 4.482, avg. samples / sec: 66253.47
Iteration:   1420, Loss function: 4.052, Average Loss: 4.465, avg. samples / sec: 66038.57
Iteration:   1420, Loss function: 3.784, Average Loss: 4.478, avg. samples / sec: 65960.15
Iteration:   1420, Loss function: 3.006, Average Loss: 4.481, avg. samples / sec: 65943.15
Iteration:   1420, Loss function: 4.919, Average Loss: 4.462, avg. samples / sec: 66088.55
Iteration:   1420, Loss function: 5.437, Average Loss: 4.467, avg. samples / sec: 66060.21
Iteration:   1420, Loss function: 4.728, Average Loss: 4.447, avg. samples / sec: 66178.58
Iteration:   1440, Loss function: 5.337, Average Loss: 4.483, avg. samples / sec: 66557.55
Iteration:   1440, Loss function: 4.741, Average Loss: 4.497, avg. samples / sec: 66493.20
Iteration:   1440, Loss function: 3.891, Average Loss: 4.464, avg. samples / sec: 66485.95
Iteration:   1440, Loss function: 5.355, Average Loss: 4.492, avg. samples / sec: 66401.69
Iteration:   1440, Loss function: 5.051, Average Loss: 4.480, avg. samples / sec: 66402.47
Iteration:   1440, Loss function: 4.351, Average Loss: 4.469, avg. samples / sec: 66451.50
Iteration:   1440, Loss function: 3.776, Average Loss: 4.474, avg. samples / sec: 66385.05
Iteration:   1440, Loss function: 3.948, Average Loss: 4.464, avg. samples / sec: 66495.43
Iteration:   1440, Loss function: 4.043, Average Loss: 4.473, avg. samples / sec: 66345.64
Iteration:   1440, Loss function: 5.319, Average Loss: 4.486, avg. samples / sec: 66469.96
Iteration:   1440, Loss function: 4.979, Average Loss: 4.478, avg. samples / sec: 66317.91
Iteration:   1440, Loss function: 3.478, Average Loss: 4.473, avg. samples / sec: 66342.73
Iteration:   1440, Loss function: 4.271, Average Loss: 4.468, avg. samples / sec: 66403.59
Iteration:   1440, Loss function: 4.614, Average Loss: 4.493, avg. samples / sec: 66426.51
Iteration:   1440, Loss function: 5.008, Average Loss: 4.470, avg. samples / sec: 66445.52
Iteration:   1440, Loss function: 4.007, Average Loss: 4.482, avg. samples / sec: 66425.32
Iteration:   1440, Loss function: 5.144, Average Loss: 4.483, avg. samples / sec: 66304.00
Iteration:   1440, Loss function: 4.629, Average Loss: 4.498, avg. samples / sec: 66332.46
Iteration:   1440, Loss function: 5.148, Average Loss: 4.471, avg. samples / sec: 66447.18
Iteration:   1440, Loss function: 5.003, Average Loss: 4.451, avg. samples / sec: 66348.85
Iteration:   1440, Loss function: 4.366, Average Loss: 4.457, avg. samples / sec: 66394.93
Iteration:   1440, Loss function: 4.485, Average Loss: 4.448, avg. samples / sec: 66507.60
Iteration:   1440, Loss function: 3.477, Average Loss: 4.454, avg. samples / sec: 66398.21
Iteration:   1440, Loss function: 4.256, Average Loss: 4.461, avg. samples / sec: 66339.98
Iteration:   1440, Loss function: 4.130, Average Loss: 4.486, avg. samples / sec: 66404.60
Iteration:   1440, Loss function: 3.155, Average Loss: 4.414, avg. samples / sec: 66282.54
Iteration:   1440, Loss function: 5.366, Average Loss: 4.495, avg. samples / sec: 66266.86
Iteration:   1440, Loss function: 4.956, Average Loss: 4.460, avg. samples / sec: 66301.00
Iteration:   1440, Loss function: 4.217, Average Loss: 4.477, avg. samples / sec: 66257.05
Iteration:   1440, Loss function: 5.264, Average Loss: 4.463, avg. samples / sec: 66223.58
Iteration:   1460, Loss function: 3.660, Average Loss: 4.487, avg. samples / sec: 66542.87
Iteration:   1460, Loss function: 4.238, Average Loss: 4.472, avg. samples / sec: 66533.26
Iteration:   1460, Loss function: 4.248, Average Loss: 4.483, avg. samples / sec: 66459.80
Iteration:   1460, Loss function: 3.941, Average Loss: 4.475, avg. samples / sec: 66538.41
Iteration:   1460, Loss function: 4.008, Average Loss: 4.492, avg. samples / sec: 66421.72
Iteration:   1460, Loss function: 4.887, Average Loss: 4.493, avg. samples / sec: 66554.06
Iteration:   1460, Loss function: 5.167, Average Loss: 4.478, avg. samples / sec: 66474.76
Iteration:   1460, Loss function: 4.216, Average Loss: 4.491, avg. samples / sec: 66431.42
Iteration:   1460, Loss function: 3.621, Average Loss: 4.503, avg. samples / sec: 66328.24
Iteration:   1460, Loss function: 4.535, Average Loss: 4.505, avg. samples / sec: 66478.24
Iteration:   1460, Loss function: 4.337, Average Loss: 4.464, avg. samples / sec: 66350.73
Iteration:   1460, Loss function: 4.502, Average Loss: 4.463, avg. samples / sec: 66604.32
Iteration:   1460, Loss function: 3.528, Average Loss: 4.476, avg. samples / sec: 66389.96
Iteration:   1460, Loss function: 4.556, Average Loss: 4.497, avg. samples / sec: 66488.62
Iteration:   1460, Loss function: 3.953, Average Loss: 4.471, avg. samples / sec: 66373.57
Iteration:   1460, Loss function: 3.354, Average Loss: 4.494, avg. samples / sec: 66403.75
Iteration:   1460, Loss function: 4.800, Average Loss: 4.476, avg. samples / sec: 66425.44
Iteration:   1460, Loss function: 5.163, Average Loss: 4.488, avg. samples / sec: 66432.83
Iteration:   1460, Loss function: 3.686, Average Loss: 4.460, avg. samples / sec: 66373.88
Iteration:   1460, Loss function: 4.294, Average Loss: 4.460, avg. samples / sec: 66427.35
Iteration:   1460, Loss function: 4.167, Average Loss: 4.457, avg. samples / sec: 66409.10
Iteration:   1460, Loss function: 4.335, Average Loss: 4.414, avg. samples / sec: 66449.81
Iteration:   1460, Loss function: 4.619, Average Loss: 4.469, avg. samples / sec: 66436.84
Iteration:   1460, Loss function: 4.754, Average Loss: 4.490, avg. samples / sec: 66361.01
Iteration:   1460, Loss function: 4.567, Average Loss: 4.471, avg. samples / sec: 66313.54
Iteration:   1460, Loss function: 4.561, Average Loss: 4.472, avg. samples / sec: 66255.31
Iteration:   1460, Loss function: 3.952, Average Loss: 4.452, avg. samples / sec: 66344.36
Iteration:   1460, Loss function: 3.382, Average Loss: 4.455, avg. samples / sec: 66335.39
Iteration:   1460, Loss function: 5.260, Average Loss: 4.467, avg. samples / sec: 66370.38
Iteration:   1460, Loss function: 4.681, Average Loss: 4.477, avg. samples / sec: 66375.10
:::MLL 1558651227.300 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1558651227.301 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 3.118, Average Loss: 4.471, avg. samples / sec: 65929.36
Iteration:   1480, Loss function: 4.064, Average Loss: 4.474, avg. samples / sec: 65998.42
Iteration:   1480, Loss function: 4.405, Average Loss: 4.472, avg. samples / sec: 66085.92
Iteration:   1480, Loss function: 4.559, Average Loss: 4.489, avg. samples / sec: 65971.02
Iteration:   1480, Loss function: 3.511, Average Loss: 4.494, avg. samples / sec: 65882.69
Iteration:   1480, Loss function: 5.090, Average Loss: 4.495, avg. samples / sec: 66040.80
Iteration:   1480, Loss function: 3.896, Average Loss: 4.486, avg. samples / sec: 65876.75
Iteration:   1480, Loss function: 4.735, Average Loss: 4.491, avg. samples / sec: 65713.61
Iteration:   1480, Loss function: 4.879, Average Loss: 4.466, avg. samples / sec: 65936.45
Iteration:   1480, Loss function: 3.877, Average Loss: 4.456, avg. samples / sec: 65938.18
Iteration:   1480, Loss function: 4.750, Average Loss: 4.505, avg. samples / sec: 65871.79
Iteration:   1480, Loss function: 3.165, Average Loss: 4.466, avg. samples / sec: 66042.31
Iteration:   1480, Loss function: 3.630, Average Loss: 4.477, avg. samples / sec: 65793.80
Iteration:   1480, Loss function: 4.320, Average Loss: 4.492, avg. samples / sec: 65805.14
Iteration:   1480, Loss function: 4.314, Average Loss: 4.477, avg. samples / sec: 66074.36
Iteration:   1480, Loss function: 3.851, Average Loss: 4.478, avg. samples / sec: 65804.46
Iteration:   1480, Loss function: 4.008, Average Loss: 4.501, avg. samples / sec: 65850.12
Iteration:   1480, Loss function: 4.092, Average Loss: 4.456, avg. samples / sec: 65986.43
Iteration:   1480, Loss function: 4.131, Average Loss: 4.497, avg. samples / sec: 65856.86
Iteration:   1480, Loss function: 4.604, Average Loss: 4.473, avg. samples / sec: 65853.26
Iteration:   1480, Loss function: 4.330, Average Loss: 4.476, avg. samples / sec: 65832.74
Iteration:   1480, Loss function: 4.836, Average Loss: 4.475, avg. samples / sec: 65825.27
Iteration:   1480, Loss function: 4.665, Average Loss: 4.468, avg. samples / sec: 65857.82
Iteration:   1480, Loss function: 4.003, Average Loss: 4.498, avg. samples / sec: 65831.61
Iteration:   1480, Loss function: 4.916, Average Loss: 4.459, avg. samples / sec: 65934.17
Iteration:   1480, Loss function: 3.601, Average Loss: 4.476, avg. samples / sec: 65909.41
Iteration:   1480, Loss function: 4.181, Average Loss: 4.410, avg. samples / sec: 65832.71
Iteration:   1480, Loss function: 5.167, Average Loss: 4.470, avg. samples / sec: 65831.76
Iteration:   1480, Loss function: 4.416, Average Loss: 4.463, avg. samples / sec: 65780.47
Iteration:   1480, Loss function: 4.202, Average Loss: 4.495, avg. samples / sec: 65675.30
Iteration:   1500, Loss function: 5.396, Average Loss: 4.475, avg. samples / sec: 66473.69
Iteration:   1500, Loss function: 4.052, Average Loss: 4.465, avg. samples / sec: 66548.84
Iteration:   1500, Loss function: 4.159, Average Loss: 4.497, avg. samples / sec: 66507.38
Iteration:   1500, Loss function: 3.910, Average Loss: 4.489, avg. samples / sec: 66465.92
Iteration:   1500, Loss function: 4.633, Average Loss: 4.495, avg. samples / sec: 66516.20
Iteration:   1500, Loss function: 4.528, Average Loss: 4.480, avg. samples / sec: 66513.66
Iteration:   1500, Loss function: 4.942, Average Loss: 4.460, avg. samples / sec: 66489.53
Iteration:   1500, Loss function: 3.554, Average Loss: 4.457, avg. samples / sec: 66459.93
Iteration:   1500, Loss function: 4.503, Average Loss: 4.482, avg. samples / sec: 66509.46
Iteration:   1500, Loss function: 4.475, Average Loss: 4.483, avg. samples / sec: 66482.94
Iteration:   1500, Loss function: 4.956, Average Loss: 4.484, avg. samples / sec: 66471.65
Iteration:   1500, Loss function: 4.428, Average Loss: 4.412, avg. samples / sec: 66553.40
Iteration:   1500, Loss function: 3.855, Average Loss: 4.505, avg. samples / sec: 66514.07
Iteration:   1500, Loss function: 4.253, Average Loss: 4.472, avg. samples / sec: 66492.32
Iteration:   1500, Loss function: 4.194, Average Loss: 4.480, avg. samples / sec: 66425.94
Iteration:   1500, Loss function: 4.138, Average Loss: 4.474, avg. samples / sec: 66529.68
Iteration:   1500, Loss function: 4.263, Average Loss: 4.489, avg. samples / sec: 66343.86
Iteration:   1500, Loss function: 5.007, Average Loss: 4.495, avg. samples / sec: 66432.33
Iteration:   1500, Loss function: 5.389, Average Loss: 4.494, avg. samples / sec: 66341.01
Iteration:   1500, Loss function: 3.647, Average Loss: 4.500, avg. samples / sec: 66586.57
Iteration:   1500, Loss function: 4.034, Average Loss: 4.489, avg. samples / sec: 66352.13
Iteration:   1500, Loss function: 4.888, Average Loss: 4.473, avg. samples / sec: 66300.19
Iteration:   1500, Loss function: 4.823, Average Loss: 4.472, avg. samples / sec: 66473.10
Iteration:   1500, Loss function: 5.212, Average Loss: 4.465, avg. samples / sec: 66365.38
Iteration:   1500, Loss function: 5.286, Average Loss: 4.461, avg. samples / sec: 66446.02
Iteration:   1500, Loss function: 4.560, Average Loss: 4.505, avg. samples / sec: 66334.52
Iteration:   1500, Loss function: 5.043, Average Loss: 4.468, avg. samples / sec: 66434.87
Iteration:   1500, Loss function: 5.447, Average Loss: 4.499, avg. samples / sec: 66365.10
Iteration:   1500, Loss function: 3.643, Average Loss: 4.486, avg. samples / sec: 66201.00
Iteration:   1500, Loss function: 5.620, Average Loss: 4.467, avg. samples / sec: 66339.45
Iteration:   1520, Loss function: 5.715, Average Loss: 4.470, avg. samples / sec: 66517.15
Iteration:   1520, Loss function: 3.455, Average Loss: 4.496, avg. samples / sec: 66444.33
Iteration:   1520, Loss function: 5.386, Average Loss: 4.493, avg. samples / sec: 66503.93
Iteration:   1520, Loss function: 4.459, Average Loss: 4.485, avg. samples / sec: 66532.41
Iteration:   1520, Loss function: 4.753, Average Loss: 4.469, avg. samples / sec: 66607.12
Iteration:   1520, Loss function: 3.182, Average Loss: 4.490, avg. samples / sec: 66655.54
Iteration:   1520, Loss function: 4.708, Average Loss: 4.481, avg. samples / sec: 66499.63
Iteration:   1520, Loss function: 3.549, Average Loss: 4.470, avg. samples / sec: 66583.55
Iteration:   1520, Loss function: 5.001, Average Loss: 4.478, avg. samples / sec: 66349.23
Iteration:   1520, Loss function: 4.842, Average Loss: 4.481, avg. samples / sec: 66523.65
Iteration:   1520, Loss function: 4.974, Average Loss: 4.509, avg. samples / sec: 66591.01
Iteration:   1520, Loss function: 4.058, Average Loss: 4.414, avg. samples / sec: 66468.39
Iteration:   1520, Loss function: 4.024, Average Loss: 4.479, avg. samples / sec: 66504.15
Iteration:   1520, Loss function: 3.956, Average Loss: 4.469, avg. samples / sec: 66451.31
Iteration:   1520, Loss function: 5.144, Average Loss: 4.477, avg. samples / sec: 66626.90
Iteration:   1520, Loss function: 4.402, Average Loss: 4.486, avg. samples / sec: 66448.24
Iteration:   1520, Loss function: 3.998, Average Loss: 4.495, avg. samples / sec: 66465.79
Iteration:   1520, Loss function: 4.283, Average Loss: 4.490, avg. samples / sec: 66462.59
Iteration:   1520, Loss function: 4.555, Average Loss: 4.489, avg. samples / sec: 66327.74
Iteration:   1520, Loss function: 3.827, Average Loss: 4.469, avg. samples / sec: 66525.88
Iteration:   1520, Loss function: 4.372, Average Loss: 4.462, avg. samples / sec: 66382.29
Iteration:   1520, Loss function: 4.032, Average Loss: 4.500, avg. samples / sec: 66418.24
Iteration:   1520, Loss function: 3.684, Average Loss: 4.498, avg. samples / sec: 66442.63
Iteration:   1520, Loss function: 4.383, Average Loss: 4.477, avg. samples / sec: 66448.40
Iteration:   1520, Loss function: 4.673, Average Loss: 4.480, avg. samples / sec: 66352.91
Iteration:   1520, Loss function: 4.504, Average Loss: 4.458, avg. samples / sec: 66355.95
Iteration:   1520, Loss function: 4.418, Average Loss: 4.463, avg. samples / sec: 66444.01
Iteration:   1520, Loss function: 3.977, Average Loss: 4.503, avg. samples / sec: 66346.14
Iteration:   1520, Loss function: 5.378, Average Loss: 4.485, avg. samples / sec: 66436.71
Iteration:   1520, Loss function: 4.965, Average Loss: 4.484, avg. samples / sec: 66235.07
:::MLL 1558651229.075 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1558651229.075 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.753, Average Loss: 4.488, avg. samples / sec: 66256.43
Iteration:   1540, Loss function: 4.942, Average Loss: 4.496, avg. samples / sec: 66200.50
Iteration:   1540, Loss function: 4.621, Average Loss: 4.509, avg. samples / sec: 66241.92
Iteration:   1540, Loss function: 5.205, Average Loss: 4.466, avg. samples / sec: 66088.40
Iteration:   1540, Loss function: 3.625, Average Loss: 4.491, avg. samples / sec: 66283.57
Iteration:   1540, Loss function: 4.822, Average Loss: 4.478, avg. samples / sec: 66197.95
Iteration:   1540, Loss function: 4.213, Average Loss: 4.457, avg. samples / sec: 66339.58
Iteration:   1540, Loss function: 4.819, Average Loss: 4.488, avg. samples / sec: 66392.99
Iteration:   1540, Loss function: 5.021, Average Loss: 4.418, avg. samples / sec: 66196.18
Iteration:   1540, Loss function: 4.979, Average Loss: 4.497, avg. samples / sec: 66109.23
Iteration:   1540, Loss function: 4.867, Average Loss: 4.473, avg. samples / sec: 66203.20
Iteration:   1540, Loss function: 4.435, Average Loss: 4.477, avg. samples / sec: 66116.46
Iteration:   1540, Loss function: 4.204, Average Loss: 4.486, avg. samples / sec: 66181.94
Iteration:   1540, Loss function: 5.324, Average Loss: 4.475, avg. samples / sec: 66151.06
Iteration:   1540, Loss function: 4.298, Average Loss: 4.468, avg. samples / sec: 66104.02
Iteration:   1540, Loss function: 4.055, Average Loss: 4.460, avg. samples / sec: 66211.23
Iteration:   1540, Loss function: 3.552, Average Loss: 4.488, avg. samples / sec: 66194.87
Iteration:   1540, Loss function: 4.263, Average Loss: 4.496, avg. samples / sec: 66188.68
Iteration:   1540, Loss function: 4.055, Average Loss: 4.487, avg. samples / sec: 66058.66
Iteration:   1540, Loss function: 4.260, Average Loss: 4.506, avg. samples / sec: 66235.59
Iteration:   1540, Loss function: 4.366, Average Loss: 4.490, avg. samples / sec: 66128.90
Iteration:   1540, Loss function: 4.609, Average Loss: 4.469, avg. samples / sec: 66035.63
Iteration:   1540, Loss function: 4.750, Average Loss: 4.500, avg. samples / sec: 66146.53
Iteration:   1540, Loss function: 4.790, Average Loss: 4.474, avg. samples / sec: 66071.70
Iteration:   1540, Loss function: 4.150, Average Loss: 4.481, avg. samples / sec: 66156.15
Iteration:   1540, Loss function: 4.250, Average Loss: 4.480, avg. samples / sec: 66138.98
Iteration:   1540, Loss function: 4.294, Average Loss: 4.488, avg. samples / sec: 66281.11
Iteration:   1540, Loss function: 4.373, Average Loss: 4.458, avg. samples / sec: 66111.74
Iteration:   1540, Loss function: 4.848, Average Loss: 4.465, avg. samples / sec: 66063.67
Iteration:   1540, Loss function: 4.747, Average Loss: 4.480, avg. samples / sec: 65954.90
Iteration:   1560, Loss function: 3.831, Average Loss: 4.463, avg. samples / sec: 66599.91
Iteration:   1560, Loss function: 5.285, Average Loss: 4.482, avg. samples / sec: 66544.25
Iteration:   1560, Loss function: 3.876, Average Loss: 4.487, avg. samples / sec: 66656.39
Iteration:   1560, Loss function: 3.382, Average Loss: 4.491, avg. samples / sec: 66610.74
Iteration:   1560, Loss function: 4.778, Average Loss: 4.468, avg. samples / sec: 66564.34
Iteration:   1560, Loss function: 5.145, Average Loss: 4.489, avg. samples / sec: 66360.16
Iteration:   1560, Loss function: 4.084, Average Loss: 4.470, avg. samples / sec: 66488.09
Iteration:   1560, Loss function: 4.034, Average Loss: 4.481, avg. samples / sec: 66713.22
Iteration:   1560, Loss function: 5.776, Average Loss: 4.486, avg. samples / sec: 66504.21
Iteration:   1560, Loss function: 3.749, Average Loss: 4.496, avg. samples / sec: 66387.80
Iteration:   1560, Loss function: 4.724, Average Loss: 4.491, avg. samples / sec: 66541.17
Iteration:   1560, Loss function: 4.148, Average Loss: 4.457, avg. samples / sec: 66514.70
Iteration:   1560, Loss function: 4.343, Average Loss: 4.472, avg. samples / sec: 66482.72
Iteration:   1560, Loss function: 4.263, Average Loss: 4.509, avg. samples / sec: 66401.69
Iteration:   1560, Loss function: 3.443, Average Loss: 4.493, avg. samples / sec: 66448.15
Iteration:   1560, Loss function: 5.509, Average Loss: 4.459, avg. samples / sec: 66424.06
Iteration:   1560, Loss function: 3.632, Average Loss: 4.485, avg. samples / sec: 66421.34
Iteration:   1560, Loss function: 5.309, Average Loss: 4.485, avg. samples / sec: 66513.44
Iteration:   1560, Loss function: 3.564, Average Loss: 4.474, avg. samples / sec: 66464.26
Iteration:   1560, Loss function: 4.337, Average Loss: 4.494, avg. samples / sec: 66387.27
Iteration:   1560, Loss function: 4.461, Average Loss: 4.472, avg. samples / sec: 66558.49
Iteration:   1560, Loss function: 5.643, Average Loss: 4.485, avg. samples / sec: 66531.91
Iteration:   1560, Loss function: 4.082, Average Loss: 4.463, avg. samples / sec: 66597.77
Iteration:   1560, Loss function: 3.522, Average Loss: 4.452, avg. samples / sec: 66579.93
Iteration:   1560, Loss function: 6.312, Average Loss: 4.483, avg. samples / sec: 66522.52
Iteration:   1560, Loss function: 4.624, Average Loss: 4.423, avg. samples / sec: 66375.35
Iteration:   1560, Loss function: 5.552, Average Loss: 4.473, avg. samples / sec: 66470.06
Iteration:   1560, Loss function: 5.571, Average Loss: 4.502, avg. samples / sec: 66491.47
Iteration:   1560, Loss function: 4.671, Average Loss: 4.507, avg. samples / sec: 66399.03
Iteration:   1560, Loss function: 4.129, Average Loss: 4.490, avg. samples / sec: 66452.94
Iteration:   1580, Loss function: 4.058, Average Loss: 4.496, avg. samples / sec: 66622.27
Iteration:   1580, Loss function: 4.320, Average Loss: 4.477, avg. samples / sec: 66606.56
Iteration:   1580, Loss function: 4.041, Average Loss: 4.494, avg. samples / sec: 66612.38
Iteration:   1580, Loss function: 5.036, Average Loss: 4.482, avg. samples / sec: 66492.45
Iteration:   1580, Loss function: 4.076, Average Loss: 4.497, avg. samples / sec: 66588.36
Iteration:   1580, Loss function: 4.605, Average Loss: 4.486, avg. samples / sec: 66624.47
Iteration:   1580, Loss function: 4.868, Average Loss: 4.466, avg. samples / sec: 66606.27
Iteration:   1580, Loss function: 5.339, Average Loss: 4.492, avg. samples / sec: 66512.12
Iteration:   1580, Loss function: 4.999, Average Loss: 4.463, avg. samples / sec: 66350.63
Iteration:   1580, Loss function: 4.625, Average Loss: 4.503, avg. samples / sec: 66634.84
Iteration:   1580, Loss function: 5.474, Average Loss: 4.490, avg. samples / sec: 66613.32
Iteration:   1580, Loss function: 3.914, Average Loss: 4.497, avg. samples / sec: 66568.93
Iteration:   1580, Loss function: 3.822, Average Loss: 4.480, avg. samples / sec: 66502.11
Iteration:   1580, Loss function: 4.093, Average Loss: 4.457, avg. samples / sec: 66504.15
Iteration:   1580, Loss function: 4.443, Average Loss: 4.486, avg. samples / sec: 66407.07
Iteration:   1580, Loss function: 4.120, Average Loss: 4.492, avg. samples / sec: 66483.57
Iteration:   1580, Loss function: 4.424, Average Loss: 4.492, avg. samples / sec: 66379.76
Iteration:   1580, Loss function: 4.789, Average Loss: 4.462, avg. samples / sec: 66451.09
Iteration:   1580, Loss function: 3.962, Average Loss: 4.474, avg. samples / sec: 66467.83
Iteration:   1580, Loss function: 4.749, Average Loss: 4.419, avg. samples / sec: 66505.41
Iteration:   1580, Loss function: 4.586, Average Loss: 4.470, avg. samples / sec: 66442.76
Iteration:   1580, Loss function: 4.984, Average Loss: 4.490, avg. samples / sec: 66616.06
Iteration:   1580, Loss function: 4.064, Average Loss: 4.502, avg. samples / sec: 66554.18
Iteration:   1580, Loss function: 4.612, Average Loss: 4.456, avg. samples / sec: 66471.31
Iteration:   1580, Loss function: 4.031, Average Loss: 4.483, avg. samples / sec: 66382.64
Iteration:   1580, Loss function: 4.351, Average Loss: 4.470, avg. samples / sec: 66452.28
Iteration:   1580, Loss function: 4.018, Average Loss: 4.469, avg. samples / sec: 66342.29
Iteration:   1580, Loss function: 4.156, Average Loss: 4.473, avg. samples / sec: 66456.11
Iteration:   1580, Loss function: 4.389, Average Loss: 4.512, avg. samples / sec: 66384.51
Iteration:   1580, Loss function: 4.313, Average Loss: 4.484, avg. samples / sec: 66418.05
Iteration:   1600, Loss function: 3.997, Average Loss: 4.478, avg. samples / sec: 66524.12
Iteration:   1600, Loss function: 4.634, Average Loss: 4.497, avg. samples / sec: 66492.26
Iteration:   1600, Loss function: 3.182, Average Loss: 4.474, avg. samples / sec: 66597.30
Iteration:   1600, Loss function: 3.613, Average Loss: 4.473, avg. samples / sec: 66607.91
Iteration:   1600, Loss function: 3.630, Average Loss: 4.469, avg. samples / sec: 66492.51
Iteration:   1600, Loss function: 6.100, Average Loss: 4.492, avg. samples / sec: 66473.82
Iteration:   1600, Loss function: 5.050, Average Loss: 4.482, avg. samples / sec: 66362.98
Iteration:   1600, Loss function: 3.760, Average Loss: 4.494, avg. samples / sec: 66376.42
Iteration:   1600, Loss function: 4.297, Average Loss: 4.468, avg. samples / sec: 66439.13
Iteration:   1600, Loss function: 5.738, Average Loss: 4.424, avg. samples / sec: 66554.15
Iteration:   1600, Loss function: 4.353, Average Loss: 4.499, avg. samples / sec: 66391.49
Iteration:   1600, Loss function: 5.587, Average Loss: 4.468, avg. samples / sec: 66556.35
Iteration:   1600, Loss function: 4.112, Average Loss: 4.455, avg. samples / sec: 66540.51
Iteration:   1600, Loss function: 3.317, Average Loss: 4.511, avg. samples / sec: 66551.45
Iteration:   1600, Loss function: 4.445, Average Loss: 4.457, avg. samples / sec: 66429.57
Iteration:   1600, Loss function: 4.358, Average Loss: 4.498, avg. samples / sec: 66407.54
Iteration:   1600, Loss function: 4.821, Average Loss: 4.486, avg. samples / sec: 66530.18
Iteration:   1600, Loss function: 4.133, Average Loss: 4.491, avg. samples / sec: 66448.99
Iteration:   1600, Loss function: 5.022, Average Loss: 4.483, avg. samples / sec: 66376.79
Iteration:   1600, Loss function: 4.994, Average Loss: 4.492, avg. samples / sec: 66403.81
Iteration:   1600, Loss function: 5.223, Average Loss: 4.477, avg. samples / sec: 66485.01
Iteration:   1600, Loss function: 4.171, Average Loss: 4.504, avg. samples / sec: 66459.77
Iteration:   1600, Loss function: 4.243, Average Loss: 4.487, avg. samples / sec: 66309.24
Iteration:   1600, Loss function: 4.054, Average Loss: 4.494, avg. samples / sec: 66324.03
Iteration:   1600, Loss function: 3.206, Average Loss: 4.464, avg. samples / sec: 66408.76
Iteration:   1600, Loss function: 4.902, Average Loss: 4.501, avg. samples / sec: 66303.68
Iteration:   1600, Loss function: 4.040, Average Loss: 4.495, avg. samples / sec: 66415.52
Iteration:   1600, Loss function: 3.424, Average Loss: 4.468, avg. samples / sec: 66483.82
Iteration:   1600, Loss function: 5.623, Average Loss: 4.490, avg. samples / sec: 66316.85
Iteration:   1600, Loss function: 4.037, Average Loss: 4.472, avg. samples / sec: 66295.54
:::MLL 1558651230.846 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1558651230.847 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1620, Loss function: 3.857, Average Loss: 4.485, avg. samples / sec: 65895.94
Iteration:   1620, Loss function: 4.883, Average Loss: 4.494, avg. samples / sec: 65752.42
Iteration:   1620, Loss function: 3.780, Average Loss: 4.509, avg. samples / sec: 65950.61
Iteration:   1620, Loss function: 4.303, Average Loss: 4.477, avg. samples / sec: 65872.04
Iteration:   1620, Loss function: 3.852, Average Loss: 4.473, avg. samples / sec: 65709.01
Iteration:   1620, Loss function: 4.277, Average Loss: 4.497, avg. samples / sec: 65830.41
Iteration:   1620, Loss function: 3.130, Average Loss: 4.489, avg. samples / sec: 65875.89
Iteration:   1620, Loss function: 3.860, Average Loss: 4.502, avg. samples / sec: 65894.89
Iteration:   1620, Loss function: 4.348, Average Loss: 4.482, avg. samples / sec: 65900.93
Iteration:   1620, Loss function: 4.916, Average Loss: 4.487, avg. samples / sec: 65846.55
Iteration:   1620, Loss function: 3.558, Average Loss: 4.456, avg. samples / sec: 65834.87
Iteration:   1620, Loss function: 4.421, Average Loss: 4.474, avg. samples / sec: 65733.59
Iteration:   1620, Loss function: 4.894, Average Loss: 4.476, avg. samples / sec: 65856.68
Iteration:   1620, Loss function: 3.911, Average Loss: 4.491, avg. samples / sec: 65744.75
Iteration:   1620, Loss function: 4.379, Average Loss: 4.467, avg. samples / sec: 65687.66
Iteration:   1620, Loss function: 4.103, Average Loss: 4.473, avg. samples / sec: 66025.39
Iteration:   1620, Loss function: 3.849, Average Loss: 4.494, avg. samples / sec: 65944.50
Iteration:   1620, Loss function: 4.668, Average Loss: 4.479, avg. samples / sec: 65807.90
Iteration:   1620, Loss function: 4.434, Average Loss: 4.493, avg. samples / sec: 65874.22
Iteration:   1620, Loss function: 4.530, Average Loss: 4.468, avg. samples / sec: 65726.66
Iteration:   1620, Loss function: 3.672, Average Loss: 4.501, avg. samples / sec: 65838.65
Iteration:   1620, Loss function: 5.313, Average Loss: 4.452, avg. samples / sec: 65755.77
Iteration:   1620, Loss function: 4.182, Average Loss: 4.428, avg. samples / sec: 65720.78
Iteration:   1620, Loss function: 4.638, Average Loss: 4.489, avg. samples / sec: 65806.64
Iteration:   1620, Loss function: 2.976, Average Loss: 4.467, avg. samples / sec: 65711.77
Iteration:   1620, Loss function: 5.209, Average Loss: 4.467, avg. samples / sec: 65813.53
Iteration:   1620, Loss function: 3.813, Average Loss: 4.470, avg. samples / sec: 65630.98
Iteration:   1620, Loss function: 3.958, Average Loss: 4.494, avg. samples / sec: 65698.05
Iteration:   1620, Loss function: 3.450, Average Loss: 4.482, avg. samples / sec: 65714.31
Iteration:   1620, Loss function: 4.570, Average Loss: 4.465, avg. samples / sec: 65781.98
Iteration:   1640, Loss function: 4.574, Average Loss: 4.492, avg. samples / sec: 66623.53
Iteration:   1640, Loss function: 4.016, Average Loss: 4.476, avg. samples / sec: 66590.69
Iteration:   1640, Loss function: 4.811, Average Loss: 4.478, avg. samples / sec: 66559.05
Iteration:   1640, Loss function: 5.432, Average Loss: 4.484, avg. samples / sec: 66482.91
Iteration:   1640, Loss function: 5.007, Average Loss: 4.501, avg. samples / sec: 66625.61
Iteration:   1640, Loss function: 4.109, Average Loss: 4.478, avg. samples / sec: 66647.66
Iteration:   1640, Loss function: 4.873, Average Loss: 4.491, avg. samples / sec: 66660.75
Iteration:   1640, Loss function: 5.219, Average Loss: 4.478, avg. samples / sec: 66609.29
Iteration:   1640, Loss function: 6.638, Average Loss: 4.486, avg. samples / sec: 66708.01
Iteration:   1640, Loss function: 4.832, Average Loss: 4.484, avg. samples / sec: 66601.46
Iteration:   1640, Loss function: 4.970, Average Loss: 4.495, avg. samples / sec: 66578.39
Iteration:   1640, Loss function: 5.551, Average Loss: 4.431, avg. samples / sec: 66664.84
Iteration:   1640, Loss function: 4.608, Average Loss: 4.469, avg. samples / sec: 66639.15
Iteration:   1640, Loss function: 4.555, Average Loss: 4.499, avg. samples / sec: 66722.10
Iteration:   1640, Loss function: 3.941, Average Loss: 4.465, avg. samples / sec: 66684.12
Iteration:   1640, Loss function: 3.286, Average Loss: 4.470, avg. samples / sec: 66590.60
Iteration:   1640, Loss function: 5.036, Average Loss: 4.480, avg. samples / sec: 66612.63
Iteration:   1640, Loss function: 4.859, Average Loss: 4.459, avg. samples / sec: 66546.73
Iteration:   1640, Loss function: 4.634, Average Loss: 4.467, avg. samples / sec: 66699.33
Iteration:   1640, Loss function: 5.152, Average Loss: 4.507, avg. samples / sec: 66439.38
Iteration:   1640, Loss function: 4.934, Average Loss: 4.452, avg. samples / sec: 66597.33
Iteration:   1640, Loss function: 3.547, Average Loss: 4.481, avg. samples / sec: 66545.10
Iteration:   1640, Loss function: 3.309, Average Loss: 4.475, avg. samples / sec: 66645.11
Iteration:   1640, Loss function: 4.931, Average Loss: 4.484, avg. samples / sec: 66532.72
Iteration:   1640, Loss function: 4.861, Average Loss: 4.494, avg. samples / sec: 66524.65
Iteration:   1640, Loss function: 4.236, Average Loss: 4.466, avg. samples / sec: 66540.73
Iteration:   1640, Loss function: 4.287, Average Loss: 4.486, avg. samples / sec: 66616.19
Iteration:   1640, Loss function: 4.763, Average Loss: 4.493, avg. samples / sec: 66529.08
Iteration:   1640, Loss function: 4.507, Average Loss: 4.465, avg. samples / sec: 66538.00
Iteration:   1640, Loss function: 3.165, Average Loss: 4.501, avg. samples / sec: 66455.48
Iteration:   1660, Loss function: 3.574, Average Loss: 4.478, avg. samples / sec: 66538.03
Iteration:   1660, Loss function: 5.660, Average Loss: 4.484, avg. samples / sec: 66558.33
Iteration:   1660, Loss function: 3.825, Average Loss: 4.468, avg. samples / sec: 66689.29
Iteration:   1660, Loss function: 4.578, Average Loss: 4.488, avg. samples / sec: 66690.11
Iteration:   1660, Loss function: 4.221, Average Loss: 4.502, avg. samples / sec: 66490.94
Iteration:   1660, Loss function: 5.768, Average Loss: 4.471, avg. samples / sec: 66429.35
Iteration:   1660, Loss function: 5.449, Average Loss: 4.428, avg. samples / sec: 66501.67
Iteration:   1660, Loss function: 4.267, Average Loss: 4.480, avg. samples / sec: 66477.42
Iteration:   1660, Loss function: 3.516, Average Loss: 4.513, avg. samples / sec: 66537.25
Iteration:   1660, Loss function: 3.622, Average Loss: 4.498, avg. samples / sec: 66340.55
Iteration:   1660, Loss function: 4.587, Average Loss: 4.460, avg. samples / sec: 66525.62
Iteration:   1660, Loss function: 5.784, Average Loss: 4.478, avg. samples / sec: 66512.09
Iteration:   1660, Loss function: 3.647, Average Loss: 4.477, avg. samples / sec: 66501.77
Iteration:   1660, Loss function: 4.879, Average Loss: 4.488, avg. samples / sec: 66484.10
Iteration:   1660, Loss function: 5.228, Average Loss: 4.491, avg. samples / sec: 66420.71
Iteration:   1660, Loss function: 4.061, Average Loss: 4.494, avg. samples / sec: 66409.20
Iteration:   1660, Loss function: 2.853, Average Loss: 4.465, avg. samples / sec: 66437.56
Iteration:   1660, Loss function: 5.024, Average Loss: 4.502, avg. samples / sec: 66658.63
Iteration:   1660, Loss function: 4.639, Average Loss: 4.484, avg. samples / sec: 66408.07
Iteration:   1660, Loss function: 3.040, Average Loss: 4.464, avg. samples / sec: 66583.87
Iteration:   1660, Loss function: 2.894, Average Loss: 4.484, avg. samples / sec: 66477.96
Iteration:   1660, Loss function: 4.680, Average Loss: 4.481, avg. samples / sec: 66382.48
Iteration:   1660, Loss function: 4.249, Average Loss: 4.496, avg. samples / sec: 66502.86
Iteration:   1660, Loss function: 5.080, Average Loss: 4.499, avg. samples / sec: 66471.18
Iteration:   1660, Loss function: 4.035, Average Loss: 4.499, avg. samples / sec: 66366.19
Iteration:   1660, Loss function: 3.859, Average Loss: 4.468, avg. samples / sec: 66393.77
Iteration:   1660, Loss function: 3.963, Average Loss: 4.463, avg. samples / sec: 66397.02
Iteration:   1660, Loss function: 5.569, Average Loss: 4.485, avg. samples / sec: 66293.42
Iteration:   1660, Loss function: 3.521, Average Loss: 4.468, avg. samples / sec: 66326.21
Iteration:   1660, Loss function: 4.627, Average Loss: 4.486, avg. samples / sec: 66351.29
:::MLL 1558651232.619 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1558651232.620 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1680, Loss function: 3.556, Average Loss: 4.465, avg. samples / sec: 66387.83
Iteration:   1680, Loss function: 4.537, Average Loss: 4.495, avg. samples / sec: 66383.98
Iteration:   1680, Loss function: 2.995, Average Loss: 4.481, avg. samples / sec: 66264.47
Iteration:   1680, Loss function: 4.582, Average Loss: 4.514, avg. samples / sec: 66316.79
Iteration:   1680, Loss function: 5.448, Average Loss: 4.478, avg. samples / sec: 66369.79
Iteration:   1680, Loss function: 4.406, Average Loss: 4.483, avg. samples / sec: 66358.82
Iteration:   1680, Loss function: 4.415, Average Loss: 4.461, avg. samples / sec: 66218.32
Iteration:   1680, Loss function: 3.760, Average Loss: 4.476, avg. samples / sec: 66180.38
Iteration:   1680, Loss function: 5.082, Average Loss: 4.479, avg. samples / sec: 66270.48
Iteration:   1680, Loss function: 3.898, Average Loss: 4.473, avg. samples / sec: 66352.66
Iteration:   1680, Loss function: 5.582, Average Loss: 4.467, avg. samples / sec: 66417.90
Iteration:   1680, Loss function: 5.838, Average Loss: 4.424, avg. samples / sec: 66229.77
Iteration:   1680, Loss function: 4.171, Average Loss: 4.462, avg. samples / sec: 66278.74
Iteration:   1680, Loss function: 4.302, Average Loss: 4.503, avg. samples / sec: 66204.67
Iteration:   1680, Loss function: 3.585, Average Loss: 4.456, avg. samples / sec: 66392.05
Iteration:   1680, Loss function: 2.408, Average Loss: 4.486, avg. samples / sec: 66291.30
Iteration:   1680, Loss function: 4.463, Average Loss: 4.482, avg. samples / sec: 66296.98
Iteration:   1680, Loss function: 3.761, Average Loss: 4.458, avg. samples / sec: 66215.43
Iteration:   1680, Loss function: 4.262, Average Loss: 4.497, avg. samples / sec: 66347.23
Iteration:   1680, Loss function: 5.038, Average Loss: 4.475, avg. samples / sec: 66236.19
Iteration:   1680, Loss function: 3.541, Average Loss: 4.484, avg. samples / sec: 66237.09
Iteration:   1680, Loss function: 3.657, Average Loss: 4.490, avg. samples / sec: 66216.42
Iteration:   1680, Loss function: 4.042, Average Loss: 4.501, avg. samples / sec: 66266.02
Iteration:   1680, Loss function: 4.290, Average Loss: 4.462, avg. samples / sec: 66271.94
Iteration:   1680, Loss function: 4.901, Average Loss: 4.505, avg. samples / sec: 66178.58
Iteration:   1680, Loss function: 3.635, Average Loss: 4.461, avg. samples / sec: 66218.94
Iteration:   1680, Loss function: 5.044, Average Loss: 4.483, avg. samples / sec: 66309.74
Iteration:   1680, Loss function: 4.008, Average Loss: 4.484, avg. samples / sec: 66303.00
Iteration:   1680, Loss function: 4.372, Average Loss: 4.493, avg. samples / sec: 66190.77
Iteration:   1680, Loss function: 3.700, Average Loss: 4.485, avg. samples / sec: 65872.44
Iteration:   1700, Loss function: 3.408, Average Loss: 4.471, avg. samples / sec: 66430.01
Iteration:   1700, Loss function: 5.464, Average Loss: 4.479, avg. samples / sec: 66293.95
Iteration:   1700, Loss function: 4.585, Average Loss: 4.488, avg. samples / sec: 66480.34
Iteration:   1700, Loss function: 5.251, Average Loss: 4.509, avg. samples / sec: 66408.23
Iteration:   1700, Loss function: 4.507, Average Loss: 4.480, avg. samples / sec: 66407.10
Iteration:   1700, Loss function: 5.073, Average Loss: 4.497, avg. samples / sec: 66216.67
Iteration:   1700, Loss function: 3.988, Average Loss: 4.457, avg. samples / sec: 66454.73
Iteration:   1700, Loss function: 5.069, Average Loss: 4.463, avg. samples / sec: 66179.39
Iteration:   1700, Loss function: 4.296, Average Loss: 4.452, avg. samples / sec: 66359.10
Iteration:   1700, Loss function: 5.028, Average Loss: 4.481, avg. samples / sec: 66308.77
Iteration:   1700, Loss function: 3.813, Average Loss: 4.480, avg. samples / sec: 66270.29
Iteration:   1700, Loss function: 3.281, Average Loss: 4.457, avg. samples / sec: 66335.92
Iteration:   1700, Loss function: 4.357, Average Loss: 4.510, avg. samples / sec: 66254.50
Iteration:   1700, Loss function: 3.592, Average Loss: 4.472, avg. samples / sec: 66314.39
Iteration:   1700, Loss function: 4.041, Average Loss: 4.483, avg. samples / sec: 66449.37
Iteration:   1700, Loss function: 4.308, Average Loss: 4.500, avg. samples / sec: 66435.68
Iteration:   1700, Loss function: 5.025, Average Loss: 4.483, avg. samples / sec: 66322.75
Iteration:   1700, Loss function: 5.907, Average Loss: 4.482, avg. samples / sec: 66342.89
Iteration:   1700, Loss function: 3.860, Average Loss: 4.499, avg. samples / sec: 66382.33
Iteration:   1700, Loss function: 3.884, Average Loss: 4.488, avg. samples / sec: 66579.53
Iteration:   1700, Loss function: 3.745, Average Loss: 4.478, avg. samples / sec: 66389.14
Iteration:   1700, Loss function: 4.362, Average Loss: 4.454, avg. samples / sec: 66314.29
Iteration:   1700, Loss function: 4.541, Average Loss: 4.493, avg. samples / sec: 66426.13
Iteration:   1700, Loss function: 3.696, Average Loss: 4.496, avg. samples / sec: 66295.51
Iteration:   1700, Loss function: 3.781, Average Loss: 4.458, avg. samples / sec: 66216.42
Iteration:   1700, Loss function: 4.750, Average Loss: 4.462, avg. samples / sec: 66357.60
Iteration:   1700, Loss function: 4.235, Average Loss: 4.472, avg. samples / sec: 66193.91
Iteration:   1700, Loss function: 4.599, Average Loss: 4.420, avg. samples / sec: 66221.22
Iteration:   1700, Loss function: 4.839, Average Loss: 4.461, avg. samples / sec: 66201.77
Iteration:   1700, Loss function: 5.804, Average Loss: 4.475, avg. samples / sec: 66253.56
Iteration:   1720, Loss function: 4.258, Average Loss: 4.500, avg. samples / sec: 66688.31
Iteration:   1720, Loss function: 3.666, Average Loss: 4.479, avg. samples / sec: 66593.24
Iteration:   1720, Loss function: 4.611, Average Loss: 4.479, avg. samples / sec: 66652.20
Iteration:   1720, Loss function: 3.679, Average Loss: 4.461, avg. samples / sec: 66601.58
Iteration:   1720, Loss function: 3.455, Average Loss: 4.477, avg. samples / sec: 66605.36
Iteration:   1720, Loss function: 4.131, Average Loss: 4.419, avg. samples / sec: 66716.73
Iteration:   1720, Loss function: 3.465, Average Loss: 4.470, avg. samples / sec: 66456.08
Iteration:   1720, Loss function: 5.069, Average Loss: 4.492, avg. samples / sec: 66653.71
Iteration:   1720, Loss function: 4.499, Average Loss: 4.489, avg. samples / sec: 66507.73
Iteration:   1720, Loss function: 4.380, Average Loss: 4.490, avg. samples / sec: 66625.86
Iteration:   1720, Loss function: 4.110, Average Loss: 4.507, avg. samples / sec: 66577.48
Iteration:   1720, Loss function: 3.330, Average Loss: 4.456, avg. samples / sec: 66587.67
Iteration:   1720, Loss function: 4.655, Average Loss: 4.478, avg. samples / sec: 66562.36
Iteration:   1720, Loss function: 4.263, Average Loss: 4.453, avg. samples / sec: 66591.26
Iteration:   1720, Loss function: 3.194, Average Loss: 4.463, avg. samples / sec: 66554.21
Iteration:   1720, Loss function: 4.506, Average Loss: 4.507, avg. samples / sec: 66467.83
Iteration:   1720, Loss function: 4.054, Average Loss: 4.486, avg. samples / sec: 66556.16
Iteration:   1720, Loss function: 4.041, Average Loss: 4.466, avg. samples / sec: 66592.80
Iteration:   1720, Loss function: 5.050, Average Loss: 4.476, avg. samples / sec: 66624.31
Iteration:   1720, Loss function: 4.357, Average Loss: 4.494, avg. samples / sec: 66514.10
Iteration:   1720, Loss function: 5.153, Average Loss: 4.457, avg. samples / sec: 66555.75
Iteration:   1720, Loss function: 4.193, Average Loss: 4.477, avg. samples / sec: 66530.65
Iteration:   1720, Loss function: 5.318, Average Loss: 4.481, avg. samples / sec: 66514.10
Iteration:   1720, Loss function: 5.268, Average Loss: 4.458, avg. samples / sec: 66544.88
Iteration:   1720, Loss function: 3.583, Average Loss: 4.494, avg. samples / sec: 66487.87
Iteration:   1720, Loss function: 4.636, Average Loss: 4.454, avg. samples / sec: 66444.26
Iteration:   1720, Loss function: 5.068, Average Loss: 4.491, avg. samples / sec: 66447.83
Iteration:   1720, Loss function: 4.214, Average Loss: 4.451, avg. samples / sec: 66381.79
Iteration:   1720, Loss function: 4.534, Average Loss: 4.464, avg. samples / sec: 66490.00
Iteration:   1720, Loss function: 4.248, Average Loss: 4.484, avg. samples / sec: 66264.75
Iteration:   1740, Loss function: 4.335, Average Loss: 4.463, avg. samples / sec: 66662.70
Iteration:   1740, Loss function: 5.623, Average Loss: 4.477, avg. samples / sec: 66572.35
Iteration:   1740, Loss function: 3.789, Average Loss: 4.458, avg. samples / sec: 66615.59
Iteration:   1740, Loss function: 4.796, Average Loss: 4.485, avg. samples / sec: 66645.55
Iteration:   1740, Loss function: 5.334, Average Loss: 4.465, avg. samples / sec: 66802.02
Iteration:   1740, Loss function: 4.191, Average Loss: 4.479, avg. samples / sec: 66676.77
Iteration:   1740, Loss function: 4.184, Average Loss: 4.454, avg. samples / sec: 66597.27
Iteration:   1740, Loss function: 4.438, Average Loss: 4.465, avg. samples / sec: 66616.00
Iteration:   1740, Loss function: 5.759, Average Loss: 4.489, avg. samples / sec: 66680.52
Iteration:   1740, Loss function: 5.945, Average Loss: 4.451, avg. samples / sec: 66744.41
Iteration:   1740, Loss function: 3.286, Average Loss: 4.479, avg. samples / sec: 66460.02
Iteration:   1740, Loss function: 4.276, Average Loss: 4.483, avg. samples / sec: 66539.19
Iteration:   1740, Loss function: 3.957, Average Loss: 4.506, avg. samples / sec: 66562.17
Iteration:   1740, Loss function: 4.593, Average Loss: 4.485, avg. samples / sec: 66503.84
Iteration:   1740, Loss function: 4.543, Average Loss: 4.491, avg. samples / sec: 66594.60
Iteration:   1740, Loss function: 3.647, Average Loss: 4.472, avg. samples / sec: 66498.50
Iteration:   1740, Loss function: 5.363, Average Loss: 4.450, avg. samples / sec: 66620.06
Iteration:   1740, Loss function: 4.759, Average Loss: 4.484, avg. samples / sec: 66510.93
Iteration:   1740, Loss function: 4.629, Average Loss: 4.453, avg. samples / sec: 66617.86
Iteration:   1740, Loss function: 3.106, Average Loss: 4.485, avg. samples / sec: 66743.68
Iteration:   1740, Loss function: 4.561, Average Loss: 4.489, avg. samples / sec: 66671.72
Iteration:   1740, Loss function: 4.411, Average Loss: 4.417, avg. samples / sec: 66456.51
Iteration:   1740, Loss function: 4.802, Average Loss: 4.462, avg. samples / sec: 66503.84
Iteration:   1740, Loss function: 3.817, Average Loss: 4.497, avg. samples / sec: 66325.96
Iteration:   1740, Loss function: 5.258, Average Loss: 4.458, avg. samples / sec: 66538.88
Iteration:   1740, Loss function: 3.642, Average Loss: 4.472, avg. samples / sec: 66500.32
Iteration:   1740, Loss function: 3.045, Average Loss: 4.455, avg. samples / sec: 66425.63
Iteration:   1740, Loss function: 4.865, Average Loss: 4.508, avg. samples / sec: 66432.52
Iteration:   1740, Loss function: 4.186, Average Loss: 4.474, avg. samples / sec: 66522.23
Iteration:   1740, Loss function: 3.788, Average Loss: 4.483, avg. samples / sec: 66409.35
:::MLL 1558651234.390 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1558651234.391 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1760, Loss function: 4.969, Average Loss: 4.453, avg. samples / sec: 65942.10
Iteration:   1760, Loss function: 4.403, Average Loss: 4.493, avg. samples / sec: 66040.89
Iteration:   1760, Loss function: 4.572, Average Loss: 4.463, avg. samples / sec: 65827.98
Iteration:   1760, Loss function: 5.661, Average Loss: 4.473, avg. samples / sec: 65947.37
Iteration:   1760, Loss function: 4.742, Average Loss: 4.478, avg. samples / sec: 65884.85
Iteration:   1760, Loss function: 3.854, Average Loss: 4.479, avg. samples / sec: 65912.71
Iteration:   1760, Loss function: 3.993, Average Loss: 4.449, avg. samples / sec: 65882.29
Iteration:   1760, Loss function: 4.548, Average Loss: 4.486, avg. samples / sec: 66008.56
Iteration:   1760, Loss function: 3.777, Average Loss: 4.490, avg. samples / sec: 65913.60
Iteration:   1760, Loss function: 3.341, Average Loss: 4.487, avg. samples / sec: 65894.49
Iteration:   1760, Loss function: 3.875, Average Loss: 4.491, avg. samples / sec: 65928.46
Iteration:   1760, Loss function: 4.403, Average Loss: 4.453, avg. samples / sec: 65987.45
Iteration:   1760, Loss function: 4.247, Average Loss: 4.505, avg. samples / sec: 65985.57
Iteration:   1760, Loss function: 4.344, Average Loss: 4.486, avg. samples / sec: 65897.42
Iteration:   1760, Loss function: 5.690, Average Loss: 4.460, avg. samples / sec: 65840.71
Iteration:   1760, Loss function: 4.721, Average Loss: 4.481, avg. samples / sec: 65789.84
Iteration:   1760, Loss function: 3.971, Average Loss: 4.469, avg. samples / sec: 65956.63
Iteration:   1760, Loss function: 4.144, Average Loss: 4.463, avg. samples / sec: 65925.38
Iteration:   1760, Loss function: 3.918, Average Loss: 4.462, avg. samples / sec: 65792.82
Iteration:   1760, Loss function: 4.593, Average Loss: 4.457, avg. samples / sec: 65929.05
Iteration:   1760, Loss function: 5.074, Average Loss: 4.481, avg. samples / sec: 65841.97
Iteration:   1760, Loss function: 4.402, Average Loss: 4.463, avg. samples / sec: 65821.06
Iteration:   1760, Loss function: 4.062, Average Loss: 4.477, avg. samples / sec: 65876.19
Iteration:   1760, Loss function: 5.216, Average Loss: 4.482, avg. samples / sec: 65876.04
Iteration:   1760, Loss function: 4.859, Average Loss: 4.500, avg. samples / sec: 65833.30
Iteration:   1760, Loss function: 4.160, Average Loss: 4.469, avg. samples / sec: 65681.82
Iteration:   1760, Loss function: 4.249, Average Loss: 4.448, avg. samples / sec: 65846.77
Iteration:   1760, Loss function: 5.480, Average Loss: 4.452, avg. samples / sec: 65820.63
Iteration:   1760, Loss function: 4.217, Average Loss: 4.418, avg. samples / sec: 65837.97
Iteration:   1760, Loss function: 4.418, Average Loss: 4.470, avg. samples / sec: 65901.12
Iteration:   1780, Loss function: 2.806, Average Loss: 4.459, avg. samples / sec: 66460.06
Iteration:   1780, Loss function: 4.113, Average Loss: 4.493, avg. samples / sec: 66421.47
Iteration:   1780, Loss function: 4.188, Average Loss: 4.456, avg. samples / sec: 66336.70
Iteration:   1780, Loss function: 3.352, Average Loss: 4.450, avg. samples / sec: 66443.07
Iteration:   1780, Loss function: 5.755, Average Loss: 4.473, avg. samples / sec: 66440.94
Iteration:   1780, Loss function: 4.498, Average Loss: 4.467, avg. samples / sec: 66370.01
Iteration:   1780, Loss function: 3.973, Average Loss: 4.484, avg. samples / sec: 66386.02
Iteration:   1780, Loss function: 3.922, Average Loss: 4.475, avg. samples / sec: 66457.36
Iteration:   1780, Loss function: 4.642, Average Loss: 4.485, avg. samples / sec: 66471.65
Iteration:   1780, Loss function: 4.442, Average Loss: 4.475, avg. samples / sec: 66347.82
Iteration:   1780, Loss function: 4.825, Average Loss: 4.463, avg. samples / sec: 66415.36
Iteration:   1780, Loss function: 4.885, Average Loss: 4.467, avg. samples / sec: 66426.32
Iteration:   1780, Loss function: 3.500, Average Loss: 4.503, avg. samples / sec: 66391.89
Iteration:   1780, Loss function: 4.774, Average Loss: 4.471, avg. samples / sec: 66411.76
Iteration:   1780, Loss function: 4.283, Average Loss: 4.416, avg. samples / sec: 66455.29
Iteration:   1780, Loss function: 3.454, Average Loss: 4.456, avg. samples / sec: 66369.23
Iteration:   1780, Loss function: 4.819, Average Loss: 4.501, avg. samples / sec: 66411.67
Iteration:   1780, Loss function: 3.266, Average Loss: 4.461, avg. samples / sec: 66347.01
Iteration:   1780, Loss function: 4.193, Average Loss: 4.475, avg. samples / sec: 66287.72
Iteration:   1780, Loss function: 4.034, Average Loss: 4.477, avg. samples / sec: 66350.32
Iteration:   1780, Loss function: 4.159, Average Loss: 4.446, avg. samples / sec: 66396.02
Iteration:   1780, Loss function: 4.137, Average Loss: 4.459, avg. samples / sec: 66341.98
Iteration:   1780, Loss function: 2.903, Average Loss: 4.484, avg. samples / sec: 66309.49
Iteration:   1780, Loss function: 5.540, Average Loss: 4.490, avg. samples / sec: 66281.51
Iteration:   1780, Loss function: 4.488, Average Loss: 4.439, avg. samples / sec: 66256.68
Iteration:   1780, Loss function: 4.049, Average Loss: 4.466, avg. samples / sec: 66370.13
Iteration:   1780, Loss function: 4.121, Average Loss: 4.481, avg. samples / sec: 66262.47
Iteration:   1780, Loss function: 5.261, Average Loss: 4.485, avg. samples / sec: 66241.98
Iteration:   1780, Loss function: 3.039, Average Loss: 4.456, avg. samples / sec: 66284.91
Iteration:   1780, Loss function: 4.440, Average Loss: 4.446, avg. samples / sec: 66303.00
Iteration:   1800, Loss function: 4.985, Average Loss: 4.453, avg. samples / sec: 66290.49
Iteration:   1800, Loss function: 3.999, Average Loss: 4.487, avg. samples / sec: 66247.08
Iteration:   1800, Loss function: 3.125, Average Loss: 4.491, avg. samples / sec: 66432.58
Iteration:   1800, Loss function: 4.283, Average Loss: 4.472, avg. samples / sec: 66351.51
Iteration:   1800, Loss function: 4.998, Average Loss: 4.456, avg. samples / sec: 66146.19
Iteration:   1800, Loss function: 5.147, Average Loss: 4.459, avg. samples / sec: 66322.78
Iteration:   1800, Loss function: 4.140, Average Loss: 4.476, avg. samples / sec: 66433.30
Iteration:   1800, Loss function: 4.248, Average Loss: 4.481, avg. samples / sec: 66376.04
Iteration:   1800, Loss function: 3.584, Average Loss: 4.468, avg. samples / sec: 66244.37
Iteration:   1800, Loss function: 5.167, Average Loss: 4.461, avg. samples / sec: 66314.73
Iteration:   1800, Loss function: 4.981, Average Loss: 4.469, avg. samples / sec: 66259.57
Iteration:   1800, Loss function: 4.191, Average Loss: 4.489, avg. samples / sec: 66227.81
Iteration:   1800, Loss function: 4.274, Average Loss: 4.434, avg. samples / sec: 66354.01
Iteration:   1800, Loss function: 3.915, Average Loss: 4.441, avg. samples / sec: 66393.27
Iteration:   1800, Loss function: 3.618, Average Loss: 4.501, avg. samples / sec: 66277.21
Iteration:   1800, Loss function: 4.065, Average Loss: 4.471, avg. samples / sec: 66271.85
Iteration:   1800, Loss function: 4.299, Average Loss: 4.456, avg. samples / sec: 66298.57
Iteration:   1800, Loss function: 4.285, Average Loss: 4.504, avg. samples / sec: 66194.22
Iteration:   1800, Loss function: 4.363, Average Loss: 4.466, avg. samples / sec: 66185.98
Iteration:   1800, Loss function: 3.992, Average Loss: 4.463, avg. samples / sec: 66301.47
Iteration:   1800, Loss function: 4.257, Average Loss: 4.407, avg. samples / sec: 66227.25
Iteration:   1800, Loss function: 3.319, Average Loss: 4.459, avg. samples / sec: 66234.35
Iteration:   1800, Loss function: 4.248, Average Loss: 4.467, avg. samples / sec: 66144.63
Iteration:   1800, Loss function: 4.087, Average Loss: 4.448, avg. samples / sec: 66115.96
Iteration:   1800, Loss function: 3.484, Average Loss: 4.483, avg. samples / sec: 66277.87
Iteration:   1800, Loss function: 4.228, Average Loss: 4.477, avg. samples / sec: 66128.28
Iteration:   1800, Loss function: 4.996, Average Loss: 4.473, avg. samples / sec: 66211.42
Iteration:   1800, Loss function: 4.555, Average Loss: 4.466, avg. samples / sec: 66072.53
Iteration:   1800, Loss function: 4.919, Average Loss: 4.444, avg. samples / sec: 66167.92
Iteration:   1800, Loss function: 3.938, Average Loss: 4.453, avg. samples / sec: 66217.79
:::MLL 1558651236.166 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1558651236.167 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1820, Loss function: 4.870, Average Loss: 4.411, avg. samples / sec: 66517.87
Iteration:   1820, Loss function: 4.135, Average Loss: 4.481, avg. samples / sec: 66282.07
Iteration:   1820, Loss function: 3.777, Average Loss: 4.449, avg. samples / sec: 66232.39
Iteration:   1820, Loss function: 5.377, Average Loss: 4.454, avg. samples / sec: 66287.47
Iteration:   1820, Loss function: 3.768, Average Loss: 4.462, avg. samples / sec: 66401.56
Iteration:   1820, Loss function: 4.370, Average Loss: 4.473, avg. samples / sec: 66271.38
Iteration:   1820, Loss function: 4.628, Average Loss: 4.465, avg. samples / sec: 66288.03
Iteration:   1820, Loss function: 4.028, Average Loss: 4.500, avg. samples / sec: 66313.89
Iteration:   1820, Loss function: 5.243, Average Loss: 4.460, avg. samples / sec: 66284.01
Iteration:   1820, Loss function: 5.745, Average Loss: 4.477, avg. samples / sec: 66253.75
Iteration:   1820, Loss function: 3.323, Average Loss: 4.457, avg. samples / sec: 66351.73
Iteration:   1820, Loss function: 5.879, Average Loss: 4.470, avg. samples / sec: 66388.27
Iteration:   1820, Loss function: 4.870, Average Loss: 4.464, avg. samples / sec: 66331.24
Iteration:   1820, Loss function: 5.057, Average Loss: 4.480, avg. samples / sec: 66372.10
Iteration:   1820, Loss function: 4.785, Average Loss: 4.457, avg. samples / sec: 66196.46
Iteration:   1820, Loss function: 4.013, Average Loss: 4.496, avg. samples / sec: 66318.32
Iteration:   1820, Loss function: 5.468, Average Loss: 4.445, avg. samples / sec: 66416.02
Iteration:   1820, Loss function: 4.072, Average Loss: 4.427, avg. samples / sec: 66269.51
Iteration:   1820, Loss function: 4.578, Average Loss: 4.460, avg. samples / sec: 66397.24
Iteration:   1820, Loss function: 4.936, Average Loss: 4.452, avg. samples / sec: 66406.66
Iteration:   1820, Loss function: 3.731, Average Loss: 4.462, avg. samples / sec: 66305.59
Iteration:   1820, Loss function: 2.842, Average Loss: 4.439, avg. samples / sec: 66239.80
Iteration:   1820, Loss function: 3.312, Average Loss: 4.458, avg. samples / sec: 66290.84
Iteration:   1820, Loss function: 4.017, Average Loss: 4.470, avg. samples / sec: 66152.49
Iteration:   1820, Loss function: 4.785, Average Loss: 4.475, avg. samples / sec: 66311.20
Iteration:   1820, Loss function: 4.979, Average Loss: 4.487, avg. samples / sec: 66102.97
Iteration:   1820, Loss function: 4.591, Average Loss: 4.466, avg. samples / sec: 66172.65
Iteration:   1820, Loss function: 4.603, Average Loss: 4.455, avg. samples / sec: 66234.32
Iteration:   1820, Loss function: 4.260, Average Loss: 4.450, avg. samples / sec: 66204.82
Iteration:   1820, Loss function: 5.409, Average Loss: 4.488, avg. samples / sec: 66108.76
Iteration:   1840, Loss function: 3.840, Average Loss: 4.447, avg. samples / sec: 66377.26
Iteration:   1840, Loss function: 4.651, Average Loss: 4.479, avg. samples / sec: 66348.92
Iteration:   1840, Loss function: 4.147, Average Loss: 4.467, avg. samples / sec: 66513.07
Iteration:   1840, Loss function: 4.165, Average Loss: 4.407, avg. samples / sec: 66258.58
Iteration:   1840, Loss function: 4.295, Average Loss: 4.471, avg. samples / sec: 66378.92
Iteration:   1840, Loss function: 4.764, Average Loss: 4.460, avg. samples / sec: 66344.98
Iteration:   1840, Loss function: 3.954, Average Loss: 4.460, avg. samples / sec: 66376.29
Iteration:   1840, Loss function: 5.329, Average Loss: 4.452, avg. samples / sec: 66315.82
Iteration:   1840, Loss function: 4.399, Average Loss: 4.447, avg. samples / sec: 66500.79
Iteration:   1840, Loss function: 3.928, Average Loss: 4.446, avg. samples / sec: 66514.48
Iteration:   1840, Loss function: 3.918, Average Loss: 4.454, avg. samples / sec: 66377.70
Iteration:   1840, Loss function: 4.522, Average Loss: 4.452, avg. samples / sec: 66353.73
Iteration:   1840, Loss function: 4.012, Average Loss: 4.487, avg. samples / sec: 66515.61
Iteration:   1840, Loss function: 4.601, Average Loss: 4.450, avg. samples / sec: 66384.14
Iteration:   1840, Loss function: 4.071, Average Loss: 4.483, avg. samples / sec: 66431.33
Iteration:   1840, Loss function: 4.621, Average Loss: 4.459, avg. samples / sec: 66315.95
Iteration:   1840, Loss function: 3.769, Average Loss: 4.466, avg. samples / sec: 66321.35
Iteration:   1840, Loss function: 4.515, Average Loss: 4.495, avg. samples / sec: 66339.52
Iteration:   1840, Loss function: 3.987, Average Loss: 4.493, avg. samples / sec: 66292.52
Iteration:   1840, Loss function: 4.623, Average Loss: 4.458, avg. samples / sec: 66328.62
Iteration:   1840, Loss function: 5.399, Average Loss: 4.422, avg. samples / sec: 66322.13
Iteration:   1840, Loss function: 4.797, Average Loss: 4.476, avg. samples / sec: 66299.66
Iteration:   1840, Loss function: 4.700, Average Loss: 4.464, avg. samples / sec: 66284.38
Iteration:   1840, Loss function: 3.943, Average Loss: 4.457, avg. samples / sec: 66311.27
Iteration:   1840, Loss function: 5.618, Average Loss: 4.475, avg. samples / sec: 66328.81
Iteration:   1840, Loss function: 4.008, Average Loss: 4.441, avg. samples / sec: 66275.75
Iteration:   1840, Loss function: 3.983, Average Loss: 4.442, avg. samples / sec: 66243.75
Iteration:   1840, Loss function: 5.297, Average Loss: 4.460, avg. samples / sec: 66221.65
Iteration:   1840, Loss function: 4.939, Average Loss: 4.473, avg. samples / sec: 66258.08
Iteration:   1840, Loss function: 3.431, Average Loss: 4.461, avg. samples / sec: 66360.16
Iteration:   1860, Loss function: 3.289, Average Loss: 4.455, avg. samples / sec: 66519.50
Iteration:   1860, Loss function: 4.628, Average Loss: 4.469, avg. samples / sec: 66441.22
Iteration:   1860, Loss function: 3.478, Average Loss: 4.444, avg. samples / sec: 66618.68
Iteration:   1860, Loss function: 3.280, Average Loss: 4.418, avg. samples / sec: 66525.81
Iteration:   1860, Loss function: 4.590, Average Loss: 4.464, avg. samples / sec: 66543.78
Iteration:   1860, Loss function: 4.796, Average Loss: 4.444, avg. samples / sec: 66298.73
Iteration:   1860, Loss function: 4.254, Average Loss: 4.455, avg. samples / sec: 66397.46
Iteration:   1860, Loss function: 3.984, Average Loss: 4.445, avg. samples / sec: 66422.00
Iteration:   1860, Loss function: 4.128, Average Loss: 4.405, avg. samples / sec: 66357.88
Iteration:   1860, Loss function: 4.353, Average Loss: 4.461, avg. samples / sec: 66473.60
Iteration:   1860, Loss function: 4.350, Average Loss: 4.465, avg. samples / sec: 66509.42
Iteration:   1860, Loss function: 3.922, Average Loss: 4.455, avg. samples / sec: 66373.45
Iteration:   1860, Loss function: 3.515, Average Loss: 4.456, avg. samples / sec: 66498.47
Iteration:   1860, Loss function: 2.458, Average Loss: 4.454, avg. samples / sec: 66598.62
Iteration:   1860, Loss function: 4.103, Average Loss: 4.471, avg. samples / sec: 66321.38
Iteration:   1860, Loss function: 5.505, Average Loss: 4.448, avg. samples / sec: 66392.65
Iteration:   1860, Loss function: 5.064, Average Loss: 4.454, avg. samples / sec: 66446.68
Iteration:   1860, Loss function: 2.960, Average Loss: 4.474, avg. samples / sec: 66263.03
Iteration:   1860, Loss function: 4.329, Average Loss: 4.482, avg. samples / sec: 66397.65
Iteration:   1860, Loss function: 5.130, Average Loss: 4.441, avg. samples / sec: 66333.40
Iteration:   1860, Loss function: 3.444, Average Loss: 4.485, avg. samples / sec: 66408.57
Iteration:   1860, Loss function: 4.107, Average Loss: 4.472, avg. samples / sec: 66426.10
Iteration:   1860, Loss function: 3.900, Average Loss: 4.442, avg. samples / sec: 66361.66
Iteration:   1860, Loss function: 4.649, Average Loss: 4.483, avg. samples / sec: 66342.39
Iteration:   1860, Loss function: 4.611, Average Loss: 4.447, avg. samples / sec: 66326.53
Iteration:   1860, Loss function: 4.816, Average Loss: 4.459, avg. samples / sec: 66352.73
Iteration:   1860, Loss function: 3.674, Average Loss: 4.444, avg. samples / sec: 66483.19
Iteration:   1860, Loss function: 4.662, Average Loss: 4.496, avg. samples / sec: 66362.76
Iteration:   1860, Loss function: 5.595, Average Loss: 4.468, avg. samples / sec: 66371.79
Iteration:   1860, Loss function: 4.271, Average Loss: 4.451, avg. samples / sec: 66353.95
Iteration:   1880, Loss function: 4.188, Average Loss: 4.473, avg. samples / sec: 66581.79
Iteration:   1880, Loss function: 3.105, Average Loss: 4.457, avg. samples / sec: 66639.00
Iteration:   1880, Loss function: 5.870, Average Loss: 4.452, avg. samples / sec: 66496.59
Iteration:   1880, Loss function: 3.087, Average Loss: 4.467, avg. samples / sec: 66635.50
Iteration:   1880, Loss function: 4.815, Average Loss: 4.446, avg. samples / sec: 66565.97
Iteration:   1880, Loss function: 5.369, Average Loss: 4.485, avg. samples / sec: 66627.12
Iteration:   1880, Loss function: 5.036, Average Loss: 4.447, avg. samples / sec: 66652.30
Iteration:   1880, Loss function: 4.696, Average Loss: 4.457, avg. samples / sec: 66560.47
Iteration:   1880, Loss function: 3.628, Average Loss: 4.401, avg. samples / sec: 66525.00
Iteration:   1880, Loss function: 4.017, Average Loss: 4.418, avg. samples / sec: 66494.08
Iteration:   1880, Loss function: 4.496, Average Loss: 4.486, avg. samples / sec: 66633.64
Iteration:   1880, Loss function: 4.857, Average Loss: 4.447, avg. samples / sec: 66543.84
Iteration:   1880, Loss function: 5.189, Average Loss: 4.452, avg. samples / sec: 66531.78
Iteration:   1880, Loss function: 4.058, Average Loss: 4.441, avg. samples / sec: 66570.09
Iteration:   1880, Loss function: 4.238, Average Loss: 4.445, avg. samples / sec: 66545.04
Iteration:   1880, Loss function: 4.411, Average Loss: 4.439, avg. samples / sec: 66479.62
Iteration:   1880, Loss function: 5.258, Average Loss: 4.476, avg. samples / sec: 66551.92
Iteration:   1880, Loss function: 3.904, Average Loss: 4.439, avg. samples / sec: 66539.57
Iteration:   1880, Loss function: 5.194, Average Loss: 4.467, avg. samples / sec: 66470.87
Iteration:   1880, Loss function: 4.805, Average Loss: 4.445, avg. samples / sec: 66620.47
Iteration:   1880, Loss function: 3.737, Average Loss: 4.452, avg. samples / sec: 66558.71
Iteration:   1880, Loss function: 6.077, Average Loss: 4.449, avg. samples / sec: 66423.25
Iteration:   1880, Loss function: 4.404, Average Loss: 4.474, avg. samples / sec: 66488.84
Iteration:   1880, Loss function: 3.883, Average Loss: 4.457, avg. samples / sec: 66428.54
Iteration:   1880, Loss function: 4.158, Average Loss: 4.468, avg. samples / sec: 66490.78
Iteration:   1880, Loss function: 5.208, Average Loss: 4.458, avg. samples / sec: 66417.43
Iteration:   1880, Loss function: 4.514, Average Loss: 4.450, avg. samples / sec: 66428.42
Iteration:   1880, Loss function: 5.141, Average Loss: 4.465, avg. samples / sec: 66379.07
Iteration:   1880, Loss function: 4.095, Average Loss: 4.442, avg. samples / sec: 66357.13
Iteration:   1880, Loss function: 4.730, Average Loss: 4.466, avg. samples / sec: 66531.15
:::MLL 1558651237.939 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1558651237.940 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 3.716, Average Loss: 4.439, avg. samples / sec: 65861.94
Iteration:   1900, Loss function: 4.140, Average Loss: 4.466, avg. samples / sec: 66012.43
Iteration:   1900, Loss function: 4.067, Average Loss: 4.452, avg. samples / sec: 65810.27
Iteration:   1900, Loss function: 4.110, Average Loss: 4.454, avg. samples / sec: 66011.56
Iteration:   1900, Loss function: 3.141, Average Loss: 4.438, avg. samples / sec: 65919.64
Iteration:   1900, Loss function: 3.920, Average Loss: 4.445, avg. samples / sec: 65930.47
Iteration:   1900, Loss function: 4.166, Average Loss: 4.469, avg. samples / sec: 65674.04
Iteration:   1900, Loss function: 4.153, Average Loss: 4.465, avg. samples / sec: 65767.15
Iteration:   1900, Loss function: 4.442, Average Loss: 4.450, avg. samples / sec: 65928.31
Iteration:   1900, Loss function: 4.154, Average Loss: 4.458, avg. samples / sec: 65928.62
Iteration:   1900, Loss function: 5.092, Average Loss: 4.476, avg. samples / sec: 65774.67
Iteration:   1900, Loss function: 3.859, Average Loss: 4.473, avg. samples / sec: 65882.20
Iteration:   1900, Loss function: 3.892, Average Loss: 4.441, avg. samples / sec: 65835.39
Iteration:   1900, Loss function: 5.499, Average Loss: 4.439, avg. samples / sec: 65812.51
Iteration:   1900, Loss function: 2.686, Average Loss: 4.478, avg. samples / sec: 65796.29
Iteration:   1900, Loss function: 4.629, Average Loss: 4.462, avg. samples / sec: 65863.33
Iteration:   1900, Loss function: 4.029, Average Loss: 4.454, avg. samples / sec: 65767.86
Iteration:   1900, Loss function: 4.373, Average Loss: 4.469, avg. samples / sec: 65830.71
Iteration:   1900, Loss function: 4.747, Average Loss: 4.454, avg. samples / sec: 65660.40
Iteration:   1900, Loss function: 4.665, Average Loss: 4.447, avg. samples / sec: 65781.73
Iteration:   1900, Loss function: 5.218, Average Loss: 4.468, avg. samples / sec: 65885.31
Iteration:   1900, Loss function: 4.124, Average Loss: 4.447, avg. samples / sec: 65828.25
Iteration:   1900, Loss function: 3.190, Average Loss: 4.437, avg. samples / sec: 65844.37
Iteration:   1900, Loss function: 4.225, Average Loss: 4.443, avg. samples / sec: 65703.13
Iteration:   1900, Loss function: 3.296, Average Loss: 4.433, avg. samples / sec: 65793.43
Iteration:   1900, Loss function: 3.440, Average Loss: 4.399, avg. samples / sec: 65699.15
Iteration:   1900, Loss function: 4.102, Average Loss: 4.445, avg. samples / sec: 65775.84
Iteration:   1900, Loss function: 3.662, Average Loss: 4.440, avg. samples / sec: 65736.60
Iteration:   1900, Loss function: 4.211, Average Loss: 4.444, avg. samples / sec: 65736.66
Iteration:   1900, Loss function: 3.836, Average Loss: 4.414, avg. samples / sec: 65638.80
Iteration:   1920, Loss function: 4.955, Average Loss: 4.434, avg. samples / sec: 66642.40
Iteration:   1920, Loss function: 5.022, Average Loss: 4.464, avg. samples / sec: 66720.68
Iteration:   1920, Loss function: 4.185, Average Loss: 4.437, avg. samples / sec: 66743.21
Iteration:   1920, Loss function: 6.300, Average Loss: 4.441, avg. samples / sec: 66763.79
Iteration:   1920, Loss function: 4.208, Average Loss: 4.463, avg. samples / sec: 66714.27
Iteration:   1920, Loss function: 2.813, Average Loss: 4.436, avg. samples / sec: 66762.30
Iteration:   1920, Loss function: 3.433, Average Loss: 4.440, avg. samples / sec: 66593.84
Iteration:   1920, Loss function: 4.144, Average Loss: 4.462, avg. samples / sec: 66602.21
Iteration:   1920, Loss function: 6.303, Average Loss: 4.451, avg. samples / sec: 66650.34
Iteration:   1920, Loss function: 4.622, Average Loss: 4.462, avg. samples / sec: 66486.96
Iteration:   1920, Loss function: 4.043, Average Loss: 4.415, avg. samples / sec: 66752.82
Iteration:   1920, Loss function: 4.124, Average Loss: 4.474, avg. samples / sec: 66583.52
Iteration:   1920, Loss function: 2.659, Average Loss: 4.435, avg. samples / sec: 66722.29
Iteration:   1920, Loss function: 5.140, Average Loss: 4.451, avg. samples / sec: 66544.25
Iteration:   1920, Loss function: 4.000, Average Loss: 4.474, avg. samples / sec: 66585.03
Iteration:   1920, Loss function: 4.254, Average Loss: 4.440, avg. samples / sec: 66574.49
Iteration:   1920, Loss function: 5.054, Average Loss: 4.446, avg. samples / sec: 66434.96
Iteration:   1920, Loss function: 4.696, Average Loss: 4.437, avg. samples / sec: 66622.80
Iteration:   1920, Loss function: 3.477, Average Loss: 4.434, avg. samples / sec: 66622.24
Iteration:   1920, Loss function: 4.294, Average Loss: 4.441, avg. samples / sec: 66588.84
Iteration:   1920, Loss function: 4.402, Average Loss: 4.397, avg. samples / sec: 66632.22
Iteration:   1920, Loss function: 5.463, Average Loss: 4.449, avg. samples / sec: 66425.88
Iteration:   1920, Loss function: 3.427, Average Loss: 4.435, avg. samples / sec: 66629.17
Iteration:   1920, Loss function: 4.380, Average Loss: 4.469, avg. samples / sec: 66537.50
Iteration:   1920, Loss function: 4.098, Average Loss: 4.464, avg. samples / sec: 66551.39
Iteration:   1920, Loss function: 3.410, Average Loss: 4.455, avg. samples / sec: 66481.09
Iteration:   1920, Loss function: 4.749, Average Loss: 4.433, avg. samples / sec: 66393.96
Iteration:   1920, Loss function: 6.079, Average Loss: 4.431, avg. samples / sec: 66566.47
Iteration:   1920, Loss function: 4.973, Average Loss: 4.447, avg. samples / sec: 66480.56
Iteration:   1920, Loss function: 4.037, Average Loss: 4.457, avg. samples / sec: 66464.79
Iteration:   1940, Loss function: 4.052, Average Loss: 4.453, avg. samples / sec: 66595.48
Iteration:   1940, Loss function: 5.340, Average Loss: 4.442, avg. samples / sec: 66532.53
Iteration:   1940, Loss function: 4.747, Average Loss: 4.440, avg. samples / sec: 66509.20
Iteration:   1940, Loss function: 3.881, Average Loss: 4.434, avg. samples / sec: 66366.82
Iteration:   1940, Loss function: 4.383, Average Loss: 4.461, avg. samples / sec: 66346.89
Iteration:   1940, Loss function: 4.034, Average Loss: 4.413, avg. samples / sec: 66516.14
Iteration:   1940, Loss function: 4.673, Average Loss: 4.443, avg. samples / sec: 66638.71
Iteration:   1940, Loss function: 4.924, Average Loss: 4.400, avg. samples / sec: 66575.18
Iteration:   1940, Loss function: 4.180, Average Loss: 4.460, avg. samples / sec: 66446.74
Iteration:   1940, Loss function: 3.795, Average Loss: 4.462, avg. samples / sec: 66557.01
Iteration:   1940, Loss function: 3.829, Average Loss: 4.437, avg. samples / sec: 66514.63
Iteration:   1940, Loss function: 5.722, Average Loss: 4.440, avg. samples / sec: 66360.54
Iteration:   1940, Loss function: 4.765, Average Loss: 4.473, avg. samples / sec: 66531.09
Iteration:   1940, Loss function: 3.779, Average Loss: 4.456, avg. samples / sec: 66614.80
Iteration:   1940, Loss function: 3.586, Average Loss: 4.460, avg. samples / sec: 66442.54
Iteration:   1940, Loss function: 3.850, Average Loss: 4.439, avg. samples / sec: 66489.44
Iteration:   1940, Loss function: 4.111, Average Loss: 4.451, avg. samples / sec: 66511.72
Iteration:   1940, Loss function: 4.879, Average Loss: 4.462, avg. samples / sec: 66322.97
Iteration:   1940, Loss function: 4.923, Average Loss: 4.436, avg. samples / sec: 66443.76
Iteration:   1940, Loss function: 4.873, Average Loss: 4.450, avg. samples / sec: 66422.15
Iteration:   1940, Loss function: 3.739, Average Loss: 4.443, avg. samples / sec: 66448.96
Iteration:   1940, Loss function: 4.387, Average Loss: 4.446, avg. samples / sec: 66431.11
Iteration:   1940, Loss function: 5.311, Average Loss: 4.477, avg. samples / sec: 66382.17
Iteration:   1940, Loss function: 4.771, Average Loss: 4.473, avg. samples / sec: 66387.95
Iteration:   1940, Loss function: 5.535, Average Loss: 4.440, avg. samples / sec: 66370.91
Iteration:   1940, Loss function: 4.679, Average Loss: 4.433, avg. samples / sec: 66393.93
Iteration:   1940, Loss function: 4.784, Average Loss: 4.435, avg. samples / sec: 66186.35
Iteration:   1940, Loss function: 3.954, Average Loss: 4.433, avg. samples / sec: 66434.08
Iteration:   1940, Loss function: 3.736, Average Loss: 4.435, avg. samples / sec: 66416.58
Iteration:   1940, Loss function: 5.090, Average Loss: 4.435, avg. samples / sec: 66362.32
:::MLL 1558651239.712 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1558651239.712 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.640, Average Loss: 4.432, avg. samples / sec: 66373.82
Iteration:   1960, Loss function: 3.785, Average Loss: 4.397, avg. samples / sec: 66375.13
Iteration:   1960, Loss function: 5.149, Average Loss: 4.433, avg. samples / sec: 66433.80
Iteration:   1960, Loss function: 4.865, Average Loss: 4.439, avg. samples / sec: 66211.85
Iteration:   1960, Loss function: 3.350, Average Loss: 4.461, avg. samples / sec: 66287.59
Iteration:   1960, Loss function: 3.065, Average Loss: 4.456, avg. samples / sec: 66287.37
Iteration:   1960, Loss function: 5.044, Average Loss: 4.447, avg. samples / sec: 66341.05
Iteration:   1960, Loss function: 4.378, Average Loss: 4.408, avg. samples / sec: 66207.19
Iteration:   1960, Loss function: 4.211, Average Loss: 4.470, avg. samples / sec: 66340.73
Iteration:   1960, Loss function: 3.793, Average Loss: 4.461, avg. samples / sec: 66225.17
Iteration:   1960, Loss function: 5.013, Average Loss: 4.452, avg. samples / sec: 66248.45
Iteration:   1960, Loss function: 3.962, Average Loss: 4.443, avg. samples / sec: 66198.97
Iteration:   1960, Loss function: 5.904, Average Loss: 4.459, avg. samples / sec: 66241.29
Iteration:   1960, Loss function: 5.097, Average Loss: 4.450, avg. samples / sec: 66067.42
Iteration:   1960, Loss function: 4.059, Average Loss: 4.442, avg. samples / sec: 66292.55
Iteration:   1960, Loss function: 5.095, Average Loss: 4.470, avg. samples / sec: 66191.76
Iteration:   1960, Loss function: 3.221, Average Loss: 4.426, avg. samples / sec: 66342.42
Iteration:   1960, Loss function: 5.178, Average Loss: 4.443, avg. samples / sec: 66081.98
Iteration:   1960, Loss function: 3.622, Average Loss: 4.434, avg. samples / sec: 66198.35
Iteration:   1960, Loss function: 4.493, Average Loss: 4.443, avg. samples / sec: 66301.25
Iteration:   1960, Loss function: 4.728, Average Loss: 4.440, avg. samples / sec: 66255.74
Iteration:   1960, Loss function: 3.704, Average Loss: 4.431, avg. samples / sec: 66323.19
Iteration:   1960, Loss function: 4.168, Average Loss: 4.467, avg. samples / sec: 66282.07
Iteration:   1960, Loss function: 4.336, Average Loss: 4.432, avg. samples / sec: 66338.77
Iteration:   1960, Loss function: 4.055, Average Loss: 4.432, avg. samples / sec: 66166.53
Iteration:   1960, Loss function: 4.124, Average Loss: 4.430, avg. samples / sec: 66267.74
Iteration:   1960, Loss function: 4.074, Average Loss: 4.431, avg. samples / sec: 66116.30
Iteration:   1960, Loss function: 3.895, Average Loss: 4.454, avg. samples / sec: 66208.15
Iteration:   1960, Loss function: 3.521, Average Loss: 4.433, avg. samples / sec: 66251.13
Iteration:   1960, Loss function: 4.219, Average Loss: 4.444, avg. samples / sec: 66126.76
Iteration:   1980, Loss function: 4.096, Average Loss: 4.427, avg. samples / sec: 66177.25
Iteration:   1980, Loss function: 4.963, Average Loss: 4.429, avg. samples / sec: 66330.68
Iteration:   1980, Loss function: 3.180, Average Loss: 4.440, avg. samples / sec: 66230.02
Iteration:   1980, Loss function: 3.960, Average Loss: 4.426, avg. samples / sec: 66242.88
Iteration:   1980, Loss function: 3.684, Average Loss: 4.395, avg. samples / sec: 66011.07
Iteration:   1980, Loss function: 4.704, Average Loss: 4.456, avg. samples / sec: 66096.55
Iteration:   1980, Loss function: 4.983, Average Loss: 4.438, avg. samples / sec: 66334.89
Iteration:   1980, Loss function: 2.986, Average Loss: 4.433, avg. samples / sec: 66014.62
Iteration:   1980, Loss function: 2.686, Average Loss: 4.467, avg. samples / sec: 66091.06
Iteration:   1980, Loss function: 3.746, Average Loss: 4.467, avg. samples / sec: 66158.70
Iteration:   1980, Loss function: 4.806, Average Loss: 4.438, avg. samples / sec: 66030.65
Iteration:   1980, Loss function: 5.299, Average Loss: 4.439, avg. samples / sec: 66171.71
Iteration:   1980, Loss function: 3.688, Average Loss: 4.439, avg. samples / sec: 66108.92
Iteration:   1980, Loss function: 5.875, Average Loss: 4.439, avg. samples / sec: 66074.11
Iteration:   1980, Loss function: 3.140, Average Loss: 4.448, avg. samples / sec: 66188.84
Iteration:   1980, Loss function: 3.535, Average Loss: 4.455, avg. samples / sec: 66097.82
Iteration:   1980, Loss function: 4.172, Average Loss: 4.430, avg. samples / sec: 66157.43
Iteration:   1980, Loss function: 3.904, Average Loss: 4.461, avg. samples / sec: 66135.41
Iteration:   1980, Loss function: 4.918, Average Loss: 4.436, avg. samples / sec: 66124.61
Iteration:   1980, Loss function: 4.278, Average Loss: 4.452, avg. samples / sec: 65981.21
Iteration:   1980, Loss function: 4.587, Average Loss: 4.459, avg. samples / sec: 66048.38
Iteration:   1980, Loss function: 4.216, Average Loss: 4.427, avg. samples / sec: 66142.93
Iteration:   1980, Loss function: 4.317, Average Loss: 4.435, avg. samples / sec: 66186.82
Iteration:   1980, Loss function: 5.482, Average Loss: 4.432, avg. samples / sec: 66105.73
Iteration:   1980, Loss function: 3.935, Average Loss: 4.442, avg. samples / sec: 66060.55
Iteration:   1980, Loss function: 3.771, Average Loss: 4.430, avg. samples / sec: 66149.63
Iteration:   1980, Loss function: 4.056, Average Loss: 4.402, avg. samples / sec: 66005.19
Iteration:   1980, Loss function: 4.126, Average Loss: 4.449, avg. samples / sec: 66004.61
Iteration:   1980, Loss function: 3.844, Average Loss: 4.433, avg. samples / sec: 66013.39
Iteration:   1980, Loss function: 3.790, Average Loss: 4.426, avg. samples / sec: 66062.19
Iteration:   2000, Loss function: 4.564, Average Loss: 4.433, avg. samples / sec: 66412.54
Iteration:   2000, Loss function: 4.650, Average Loss: 4.445, avg. samples / sec: 66503.49
Iteration:   2000, Loss function: 4.148, Average Loss: 4.433, avg. samples / sec: 66453.91
Iteration:   2000, Loss function: 3.743, Average Loss: 4.433, avg. samples / sec: 66516.49
Iteration:   2000, Loss function: 3.589, Average Loss: 4.429, avg. samples / sec: 66283.54
Iteration:   2000, Loss function: 4.474, Average Loss: 4.425, avg. samples / sec: 66301.13
Iteration:   2000, Loss function: 2.867, Average Loss: 4.451, avg. samples / sec: 66314.64
Iteration:   2000, Loss function: 4.504, Average Loss: 4.440, avg. samples / sec: 66436.28
Iteration:   2000, Loss function: 3.604, Average Loss: 4.439, avg. samples / sec: 66449.68
Iteration:   2000, Loss function: 4.213, Average Loss: 4.435, avg. samples / sec: 66354.76
Iteration:   2000, Loss function: 4.154, Average Loss: 4.421, avg. samples / sec: 66079.84
Iteration:   2000, Loss function: 3.341, Average Loss: 4.430, avg. samples / sec: 66312.20
Iteration:   2000, Loss function: 5.132, Average Loss: 4.430, avg. samples / sec: 66340.83
Iteration:   2000, Loss function: 5.074, Average Loss: 4.423, avg. samples / sec: 66357.04
Iteration:   2000, Loss function: 3.332, Average Loss: 4.431, avg. samples / sec: 66275.37
Iteration:   2000, Loss function: 4.809, Average Loss: 4.460, avg. samples / sec: 66335.99
Iteration:   2000, Loss function: 4.928, Average Loss: 4.445, avg. samples / sec: 66322.69
Iteration:   2000, Loss function: 3.593, Average Loss: 4.387, avg. samples / sec: 66223.99
Iteration:   2000, Loss function: 3.502, Average Loss: 4.427, avg. samples / sec: 66378.89
Iteration:   2000, Loss function: 4.726, Average Loss: 4.452, avg. samples / sec: 66368.16
Iteration:   2000, Loss function: 4.135, Average Loss: 4.464, avg. samples / sec: 66296.14
Iteration:   2000, Loss function: 4.359, Average Loss: 4.419, avg. samples / sec: 66367.98
Iteration:   2000, Loss function: 2.538, Average Loss: 4.453, avg. samples / sec: 66308.77
Iteration:   2000, Loss function: 3.846, Average Loss: 4.400, avg. samples / sec: 66354.07
Iteration:   2000, Loss function: 5.716, Average Loss: 4.437, avg. samples / sec: 66260.32
Iteration:   2000, Loss function: 4.111, Average Loss: 4.451, avg. samples / sec: 66259.92
Iteration:   2000, Loss function: 3.550, Average Loss: 4.436, avg. samples / sec: 66274.09
Iteration:   2000, Loss function: 5.923, Average Loss: 4.430, avg. samples / sec: 66341.17
Iteration:   2000, Loss function: 3.456, Average Loss: 4.424, avg. samples / sec: 66294.95
Iteration:   2000, Loss function: 4.324, Average Loss: 4.417, avg. samples / sec: 66310.64
Iteration:   2020, Loss function: 4.259, Average Loss: 4.429, avg. samples / sec: 66733.47
Iteration:   2020, Loss function: 5.483, Average Loss: 4.387, avg. samples / sec: 66903.60
Iteration:   2020, Loss function: 5.758, Average Loss: 4.416, avg. samples / sec: 66844.76
Iteration:   2020, Loss function: 4.048, Average Loss: 4.429, avg. samples / sec: 66933.56
Iteration:   2020, Loss function: 3.891, Average Loss: 4.461, avg. samples / sec: 66843.65
Iteration:   2020, Loss function: 3.924, Average Loss: 4.436, avg. samples / sec: 66843.72
Iteration:   2020, Loss function: 5.396, Average Loss: 4.451, avg. samples / sec: 66873.47
Iteration:   2020, Loss function: 4.244, Average Loss: 4.440, avg. samples / sec: 66665.38
Iteration:   2020, Loss function: 5.019, Average Loss: 4.422, avg. samples / sec: 66832.69
Iteration:   2020, Loss function: 4.486, Average Loss: 4.428, avg. samples / sec: 66729.30
Iteration:   2020, Loss function: 4.657, Average Loss: 4.428, avg. samples / sec: 66707.89
Iteration:   2020, Loss function: 4.153, Average Loss: 4.433, avg. samples / sec: 66750.19
Iteration:   2020, Loss function: 5.162, Average Loss: 4.432, avg. samples / sec: 66627.21
Iteration:   2020, Loss function: 3.026, Average Loss: 4.427, avg. samples / sec: 66747.82
Iteration:   2020, Loss function: 4.219, Average Loss: 4.416, avg. samples / sec: 66873.72
Iteration:   2020, Loss function: 5.254, Average Loss: 4.416, avg. samples / sec: 66750.45
Iteration:   2020, Loss function: 3.928, Average Loss: 4.438, avg. samples / sec: 66840.23
Iteration:   2020, Loss function: 5.214, Average Loss: 4.449, avg. samples / sec: 66748.42
Iteration:   2020, Loss function: 4.751, Average Loss: 4.395, avg. samples / sec: 66811.43
Iteration:   2020, Loss function: 4.048, Average Loss: 4.438, avg. samples / sec: 66675.69
Iteration:   2020, Loss function: 6.935, Average Loss: 4.422, avg. samples / sec: 66752.22
Iteration:   2020, Loss function: 4.663, Average Loss: 4.419, avg. samples / sec: 66646.40
Iteration:   2020, Loss function: 4.862, Average Loss: 4.458, avg. samples / sec: 66731.23
Iteration:   2020, Loss function: 4.118, Average Loss: 4.432, avg. samples / sec: 66675.19
Iteration:   2020, Loss function: 5.044, Average Loss: 4.450, avg. samples / sec: 66791.29
Iteration:   2020, Loss function: 4.652, Average Loss: 4.442, avg. samples / sec: 66627.81
Iteration:   2020, Loss function: 4.337, Average Loss: 4.431, avg. samples / sec: 66767.05
Iteration:   2020, Loss function: 3.641, Average Loss: 4.421, avg. samples / sec: 66659.93
Iteration:   2020, Loss function: 3.149, Average Loss: 4.422, avg. samples / sec: 66782.36
Iteration:   2020, Loss function: 4.524, Average Loss: 4.427, avg. samples / sec: 66553.52
:::MLL 1558651241.486 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1558651241.486 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   2040, Loss function: 5.691, Average Loss: 4.426, avg. samples / sec: 65840.89
Iteration:   2040, Loss function: 5.213, Average Loss: 4.419, avg. samples / sec: 65716.64
Iteration:   2040, Loss function: 3.607, Average Loss: 4.439, avg. samples / sec: 65750.80
Iteration:   2040, Loss function: 4.555, Average Loss: 4.446, avg. samples / sec: 65812.30
Iteration:   2040, Loss function: 4.248, Average Loss: 4.437, avg. samples / sec: 65846.68
Iteration:   2040, Loss function: 4.123, Average Loss: 4.413, avg. samples / sec: 65773.14
Iteration:   2040, Loss function: 5.011, Average Loss: 4.458, avg. samples / sec: 65691.31
Iteration:   2040, Loss function: 4.514, Average Loss: 4.428, avg. samples / sec: 65733.90
Iteration:   2040, Loss function: 3.818, Average Loss: 4.426, avg. samples / sec: 65600.70
Iteration:   2040, Loss function: 4.577, Average Loss: 4.424, avg. samples / sec: 65701.84
Iteration:   2040, Loss function: 5.171, Average Loss: 4.457, avg. samples / sec: 65809.20
Iteration:   2040, Loss function: 3.625, Average Loss: 4.430, avg. samples / sec: 65819.31
Iteration:   2040, Loss function: 3.908, Average Loss: 4.423, avg. samples / sec: 65754.14
Iteration:   2040, Loss function: 3.903, Average Loss: 4.416, avg. samples / sec: 65831.82
Iteration:   2040, Loss function: 5.179, Average Loss: 4.416, avg. samples / sec: 65682.58
Iteration:   2040, Loss function: 5.097, Average Loss: 4.427, avg. samples / sec: 65901.92
Iteration:   2040, Loss function: 4.588, Average Loss: 4.433, avg. samples / sec: 65654.89
Iteration:   2040, Loss function: 3.935, Average Loss: 4.384, avg. samples / sec: 65611.18
Iteration:   2040, Loss function: 5.046, Average Loss: 4.414, avg. samples / sec: 65747.39
Iteration:   2040, Loss function: 5.167, Average Loss: 4.436, avg. samples / sec: 65750.46
Iteration:   2040, Loss function: 4.037, Average Loss: 4.423, avg. samples / sec: 65647.21
Iteration:   2040, Loss function: 4.244, Average Loss: 4.414, avg. samples / sec: 65697.19
Iteration:   2040, Loss function: 4.488, Average Loss: 4.423, avg. samples / sec: 65555.66
Iteration:   2040, Loss function: 4.431, Average Loss: 4.449, avg. samples / sec: 65597.01
Iteration:   2040, Loss function: 3.548, Average Loss: 4.419, avg. samples / sec: 65736.14
Iteration:   2040, Loss function: 4.537, Average Loss: 4.430, avg. samples / sec: 65645.59
Iteration:   2040, Loss function: 4.018, Average Loss: 4.408, avg. samples / sec: 65640.64
Iteration:   2040, Loss function: 4.165, Average Loss: 4.423, avg. samples / sec: 65692.29
Iteration:   2040, Loss function: 3.413, Average Loss: 4.391, avg. samples / sec: 65601.53
Iteration:   2040, Loss function: 4.162, Average Loss: 4.444, avg. samples / sec: 65573.69
Iteration:   2060, Loss function: 5.067, Average Loss: 4.420, avg. samples / sec: 66714.45
Iteration:   2060, Loss function: 4.087, Average Loss: 4.432, avg. samples / sec: 66543.00
Iteration:   2060, Loss function: 3.295, Average Loss: 4.412, avg. samples / sec: 66509.46
Iteration:   2060, Loss function: 5.325, Average Loss: 4.433, avg. samples / sec: 66547.39
Iteration:   2060, Loss function: 4.117, Average Loss: 4.457, avg. samples / sec: 66524.53
Iteration:   2060, Loss function: 5.467, Average Loss: 4.422, avg. samples / sec: 66530.34
Iteration:   2060, Loss function: 3.360, Average Loss: 4.450, avg. samples / sec: 66511.21
Iteration:   2060, Loss function: 3.353, Average Loss: 4.440, avg. samples / sec: 66482.69
Iteration:   2060, Loss function: 3.936, Average Loss: 4.419, avg. samples / sec: 66526.85
Iteration:   2060, Loss function: 4.389, Average Loss: 4.420, avg. samples / sec: 66583.05
Iteration:   2060, Loss function: 3.656, Average Loss: 4.417, avg. samples / sec: 66496.12
Iteration:   2060, Loss function: 4.120, Average Loss: 4.417, avg. samples / sec: 66520.19
Iteration:   2060, Loss function: 3.726, Average Loss: 4.422, avg. samples / sec: 66486.08
Iteration:   2060, Loss function: 3.904, Average Loss: 4.381, avg. samples / sec: 66519.19
Iteration:   2060, Loss function: 5.806, Average Loss: 4.442, avg. samples / sec: 66731.80
Iteration:   2060, Loss function: 5.090, Average Loss: 4.415, avg. samples / sec: 66592.74
Iteration:   2060, Loss function: 3.657, Average Loss: 4.422, avg. samples / sec: 66395.74
Iteration:   2060, Loss function: 5.221, Average Loss: 4.404, avg. samples / sec: 66610.02
Iteration:   2060, Loss function: 3.628, Average Loss: 4.427, avg. samples / sec: 66484.67
Iteration:   2060, Loss function: 4.562, Average Loss: 4.410, avg. samples / sec: 66520.35
Iteration:   2060, Loss function: 4.355, Average Loss: 4.412, avg. samples / sec: 66479.68
Iteration:   2060, Loss function: 4.209, Average Loss: 4.414, avg. samples / sec: 66614.84
Iteration:   2060, Loss function: 5.687, Average Loss: 4.447, avg. samples / sec: 66547.08
Iteration:   2060, Loss function: 4.115, Average Loss: 4.433, avg. samples / sec: 66474.16
Iteration:   2060, Loss function: 4.150, Average Loss: 4.432, avg. samples / sec: 66568.05
Iteration:   2060, Loss function: 3.755, Average Loss: 4.408, avg. samples / sec: 66405.13
Iteration:   2060, Loss function: 5.518, Average Loss: 4.414, avg. samples / sec: 66519.94
Iteration:   2060, Loss function: 2.984, Average Loss: 4.412, avg. samples / sec: 66481.85
Iteration:   2060, Loss function: 4.201, Average Loss: 4.422, avg. samples / sec: 66423.94
Iteration:   2060, Loss function: 3.601, Average Loss: 4.389, avg. samples / sec: 66533.60
Iteration:   2080, Loss function: 3.299, Average Loss: 4.411, avg. samples / sec: 66362.41
Iteration:   2080, Loss function: 3.372, Average Loss: 4.429, avg. samples / sec: 66488.84
Iteration:   2080, Loss function: 4.589, Average Loss: 4.403, avg. samples / sec: 66433.80
Iteration:   2080, Loss function: 5.500, Average Loss: 4.427, avg. samples / sec: 66525.94
Iteration:   2080, Loss function: 3.764, Average Loss: 4.408, avg. samples / sec: 66523.39
Iteration:   2080, Loss function: 5.104, Average Loss: 4.399, avg. samples / sec: 66499.91
Iteration:   2080, Loss function: 3.785, Average Loss: 4.412, avg. samples / sec: 66477.39
Iteration:   2080, Loss function: 4.146, Average Loss: 4.384, avg. samples / sec: 66605.36
Iteration:   2080, Loss function: 3.679, Average Loss: 4.415, avg. samples / sec: 66426.66
Iteration:   2080, Loss function: 3.442, Average Loss: 4.428, avg. samples / sec: 66514.32
Iteration:   2080, Loss function: 3.955, Average Loss: 4.449, avg. samples / sec: 66423.66
Iteration:   2080, Loss function: 4.632, Average Loss: 4.405, avg. samples / sec: 66510.49
Iteration:   2080, Loss function: 2.717, Average Loss: 4.409, avg. samples / sec: 66556.98
Iteration:   2080, Loss function: 3.828, Average Loss: 4.414, avg. samples / sec: 66428.60
Iteration:   2080, Loss function: 3.917, Average Loss: 4.416, avg. samples / sec: 66356.48
Iteration:   2080, Loss function: 2.922, Average Loss: 4.414, avg. samples / sec: 66381.76
Iteration:   2080, Loss function: 4.294, Average Loss: 4.451, avg. samples / sec: 66318.35
Iteration:   2080, Loss function: 4.173, Average Loss: 4.416, avg. samples / sec: 66496.46
Iteration:   2080, Loss function: 4.856, Average Loss: 4.407, avg. samples / sec: 66408.35
Iteration:   2080, Loss function: 4.861, Average Loss: 4.431, avg. samples / sec: 66427.98
Iteration:   2080, Loss function: 3.949, Average Loss: 4.424, avg. samples / sec: 66380.20
Iteration:   2080, Loss function: 4.414, Average Loss: 4.413, avg. samples / sec: 66331.33
Iteration:   2080, Loss function: 3.768, Average Loss: 4.410, avg. samples / sec: 66366.38
Iteration:   2080, Loss function: 3.474, Average Loss: 4.408, avg. samples / sec: 66438.56
Iteration:   2080, Loss function: 3.753, Average Loss: 4.404, avg. samples / sec: 66387.05
Iteration:   2080, Loss function: 4.198, Average Loss: 4.377, avg. samples / sec: 66356.10
Iteration:   2080, Loss function: 4.507, Average Loss: 4.439, avg. samples / sec: 66332.74
Iteration:   2080, Loss function: 3.496, Average Loss: 4.442, avg. samples / sec: 66356.82
Iteration:   2080, Loss function: 4.330, Average Loss: 4.430, avg. samples / sec: 66271.10
Iteration:   2080, Loss function: 6.159, Average Loss: 4.430, avg. samples / sec: 66203.64
:::MLL 1558651243.261 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1558651243.261 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   2100, Loss function: 6.364, Average Loss: 4.410, avg. samples / sec: 66356.16
Iteration:   2100, Loss function: 3.367, Average Loss: 4.402, avg. samples / sec: 66155.81
Iteration:   2100, Loss function: 3.172, Average Loss: 4.405, avg. samples / sec: 66253.41
Iteration:   2100, Loss function: 3.815, Average Loss: 4.373, avg. samples / sec: 66317.13
Iteration:   2100, Loss function: 4.380, Average Loss: 4.421, avg. samples / sec: 66047.67
Iteration:   2100, Loss function: 4.610, Average Loss: 4.423, avg. samples / sec: 66329.18
Iteration:   2100, Loss function: 4.883, Average Loss: 4.404, avg. samples / sec: 66125.14
Iteration:   2100, Loss function: 3.387, Average Loss: 4.426, avg. samples / sec: 66110.78
Iteration:   2100, Loss function: 2.434, Average Loss: 4.392, avg. samples / sec: 66125.33
Iteration:   2100, Loss function: 4.082, Average Loss: 4.445, avg. samples / sec: 66140.91
Iteration:   2100, Loss function: 5.007, Average Loss: 4.443, avg. samples / sec: 66197.92
Iteration:   2100, Loss function: 4.467, Average Loss: 4.416, avg. samples / sec: 66208.24
Iteration:   2100, Loss function: 5.151, Average Loss: 4.421, avg. samples / sec: 66200.97
Iteration:   2100, Loss function: 4.364, Average Loss: 4.413, avg. samples / sec: 66088.18
Iteration:   2100, Loss function: 4.358, Average Loss: 4.409, avg. samples / sec: 66180.57
Iteration:   2100, Loss function: 2.730, Average Loss: 4.397, avg. samples / sec: 66088.89
Iteration:   2100, Loss function: 3.805, Average Loss: 4.404, avg. samples / sec: 65939.57
Iteration:   2100, Loss function: 4.827, Average Loss: 4.406, avg. samples / sec: 66072.44
Iteration:   2100, Loss function: 3.795, Average Loss: 4.409, avg. samples / sec: 66107.59
Iteration:   2100, Loss function: 4.599, Average Loss: 4.408, avg. samples / sec: 66148.14
Iteration:   2100, Loss function: 3.504, Average Loss: 4.436, avg. samples / sec: 66214.84
Iteration:   2100, Loss function: 4.838, Average Loss: 4.406, avg. samples / sec: 66116.64
Iteration:   2100, Loss function: 4.388, Average Loss: 4.404, avg. samples / sec: 66070.33
Iteration:   2100, Loss function: 4.250, Average Loss: 4.425, avg. samples / sec: 66036.40
Iteration:   2100, Loss function: 4.487, Average Loss: 4.433, avg. samples / sec: 66139.29
Iteration:   2100, Loss function: 4.188, Average Loss: 4.380, avg. samples / sec: 65985.63
Iteration:   2100, Loss function: 3.983, Average Loss: 4.401, avg. samples / sec: 66095.62
Iteration:   2100, Loss function: 4.079, Average Loss: 4.408, avg. samples / sec: 66066.86
Iteration:   2100, Loss function: 3.287, Average Loss: 4.426, avg. samples / sec: 66083.90
Iteration:   2100, Loss function: 4.744, Average Loss: 4.408, avg. samples / sec: 65886.76
Iteration:   2120, Loss function: 4.998, Average Loss: 4.411, avg. samples / sec: 66551.42
Iteration:   2120, Loss function: 3.581, Average Loss: 4.399, avg. samples / sec: 66460.56
Iteration:   2120, Loss function: 3.837, Average Loss: 4.419, avg. samples / sec: 66497.81
Iteration:   2120, Loss function: 4.700, Average Loss: 4.400, avg. samples / sec: 66543.69
Iteration:   2120, Loss function: 3.972, Average Loss: 4.409, avg. samples / sec: 66562.45
Iteration:   2120, Loss function: 4.544, Average Loss: 4.406, avg. samples / sec: 66529.36
Iteration:   2120, Loss function: 3.979, Average Loss: 4.405, avg. samples / sec: 66508.45
Iteration:   2120, Loss function: 5.269, Average Loss: 4.440, avg. samples / sec: 66444.55
Iteration:   2120, Loss function: 5.248, Average Loss: 4.365, avg. samples / sec: 66387.02
Iteration:   2120, Loss function: 4.009, Average Loss: 4.407, avg. samples / sec: 66270.88
Iteration:   2120, Loss function: 4.230, Average Loss: 4.401, avg. samples / sec: 66336.95
Iteration:   2120, Loss function: 4.456, Average Loss: 4.427, avg. samples / sec: 66365.85
Iteration:   2120, Loss function: 3.655, Average Loss: 4.399, avg. samples / sec: 66458.21
Iteration:   2120, Loss function: 5.086, Average Loss: 4.400, avg. samples / sec: 66526.28
Iteration:   2120, Loss function: 3.537, Average Loss: 4.407, avg. samples / sec: 66352.04
Iteration:   2120, Loss function: 3.558, Average Loss: 4.436, avg. samples / sec: 66442.45
Iteration:   2120, Loss function: 3.346, Average Loss: 4.400, avg. samples / sec: 66466.32
Iteration:   2120, Loss function: 4.192, Average Loss: 4.391, avg. samples / sec: 66421.84
Iteration:   2120, Loss function: 4.826, Average Loss: 4.429, avg. samples / sec: 66557.89
Iteration:   2120, Loss function: 4.426, Average Loss: 4.432, avg. samples / sec: 66462.28
Iteration:   2120, Loss function: 5.012, Average Loss: 4.418, avg. samples / sec: 66275.37
Iteration:   2120, Loss function: 5.370, Average Loss: 4.407, avg. samples / sec: 66498.16
Iteration:   2120, Loss function: 5.005, Average Loss: 4.415, avg. samples / sec: 66363.19
Iteration:   2120, Loss function: 5.270, Average Loss: 4.375, avg. samples / sec: 66446.33
Iteration:   2120, Loss function: 4.286, Average Loss: 4.389, avg. samples / sec: 66274.69
Iteration:   2120, Loss function: 4.213, Average Loss: 4.437, avg. samples / sec: 66305.62
Iteration:   2120, Loss function: 4.693, Average Loss: 4.415, avg. samples / sec: 66305.59
Iteration:   2120, Loss function: 4.254, Average Loss: 4.418, avg. samples / sec: 66377.54
Iteration:   2120, Loss function: 4.521, Average Loss: 4.408, avg. samples / sec: 66288.90
Iteration:   2120, Loss function: 4.152, Average Loss: 4.400, avg. samples / sec: 66428.01
Iteration:   2140, Loss function: 3.747, Average Loss: 4.394, avg. samples / sec: 65766.88
Iteration:   2140, Loss function: 4.684, Average Loss: 4.418, avg. samples / sec: 65876.01
Iteration:   2140, Loss function: 3.667, Average Loss: 4.427, avg. samples / sec: 65790.52
Iteration:   2140, Loss function: 4.028, Average Loss: 4.393, avg. samples / sec: 65704.32
Iteration:   2140, Loss function: 4.832, Average Loss: 4.390, avg. samples / sec: 65708.52
Iteration:   2140, Loss function: 5.162, Average Loss: 4.413, avg. samples / sec: 65785.60
Iteration:   2140, Loss function: 4.442, Average Loss: 4.368, avg. samples / sec: 65661.62
Iteration:   2140, Loss function: 2.680, Average Loss: 4.432, avg. samples / sec: 65659.60
Iteration:   2140, Loss function: 5.129, Average Loss: 4.408, avg. samples / sec: 65661.34
Iteration:   2140, Loss function: 4.152, Average Loss: 4.410, avg. samples / sec: 65728.01
Iteration:   2140, Loss function: 4.435, Average Loss: 4.423, avg. samples / sec: 65675.39
Iteration:   2140, Loss function: 4.143, Average Loss: 4.384, avg. samples / sec: 65757.82
Iteration:   2140, Loss function: 3.278, Average Loss: 4.399, avg. samples / sec: 65663.27
Iteration:   2140, Loss function: 3.357, Average Loss: 4.396, avg. samples / sec: 65664.28
Iteration:   2140, Loss function: 4.462, Average Loss: 4.375, avg. samples / sec: 65717.87
Iteration:   2140, Loss function: 4.279, Average Loss: 4.404, avg. samples / sec: 65492.17
Iteration:   2140, Loss function: 5.598, Average Loss: 4.418, avg. samples / sec: 65488.25
Iteration:   2140, Loss function: 4.482, Average Loss: 4.399, avg. samples / sec: 65466.50
Iteration:   2140, Loss function: 4.582, Average Loss: 4.433, avg. samples / sec: 65703.50
Iteration:   2140, Loss function: 4.013, Average Loss: 4.396, avg. samples / sec: 65615.46
Iteration:   2140, Loss function: 5.722, Average Loss: 4.429, avg. samples / sec: 65646.39
Iteration:   2140, Loss function: 4.243, Average Loss: 4.430, avg. samples / sec: 65616.71
Iteration:   2140, Loss function: 4.302, Average Loss: 4.398, avg. samples / sec: 65498.84
Iteration:   2140, Loss function: 4.175, Average Loss: 4.403, avg. samples / sec: 65647.00
Iteration:   2140, Loss function: 4.551, Average Loss: 4.413, avg. samples / sec: 65685.98
Iteration:   2140, Loss function: 3.776, Average Loss: 4.404, avg. samples / sec: 65461.63
Iteration:   2140, Loss function: 3.788, Average Loss: 4.402, avg. samples / sec: 65703.50
Iteration:   2140, Loss function: 6.371, Average Loss: 4.385, avg. samples / sec: 65544.69
Iteration:   2140, Loss function: 3.541, Average Loss: 4.393, avg. samples / sec: 65693.27
Iteration:   2140, Loss function: 5.582, Average Loss: 4.403, avg. samples / sec: 65509.04
Iteration:   2160, Loss function: 4.688, Average Loss: 4.387, avg. samples / sec: 66513.85
Iteration:   2160, Loss function: 4.010, Average Loss: 4.411, avg. samples / sec: 66276.71
Iteration:   2160, Loss function: 3.171, Average Loss: 4.387, avg. samples / sec: 66120.86
Iteration:   2160, Loss function: 3.349, Average Loss: 4.417, avg. samples / sec: 66347.54
Iteration:   2160, Loss function: 4.821, Average Loss: 4.392, avg. samples / sec: 66369.51
Iteration:   2160, Loss function: 2.819, Average Loss: 4.395, avg. samples / sec: 66350.32
Iteration:   2160, Loss function: 4.719, Average Loss: 4.367, avg. samples / sec: 66248.08
Iteration:   2160, Loss function: 5.073, Average Loss: 4.409, avg. samples / sec: 66293.39
Iteration:   2160, Loss function: 4.347, Average Loss: 4.382, avg. samples / sec: 66216.55
Iteration:   2160, Loss function: 3.308, Average Loss: 4.396, avg. samples / sec: 66365.85
Iteration:   2160, Loss function: 3.830, Average Loss: 4.421, avg. samples / sec: 66174.57
Iteration:   2160, Loss function: 4.625, Average Loss: 4.401, avg. samples / sec: 66294.58
Iteration:   2160, Loss function: 4.433, Average Loss: 4.390, avg. samples / sec: 66170.69
Iteration:   2160, Loss function: 4.234, Average Loss: 4.402, avg. samples / sec: 66246.40
Iteration:   2160, Loss function: 4.045, Average Loss: 4.420, avg. samples / sec: 66251.26
Iteration:   2160, Loss function: 3.708, Average Loss: 4.422, avg. samples / sec: 66212.60
Iteration:   2160, Loss function: 3.797, Average Loss: 4.394, avg. samples / sec: 66264.75
Iteration:   2160, Loss function: 4.245, Average Loss: 4.401, avg. samples / sec: 66369.13
Iteration:   2160, Loss function: 2.913, Average Loss: 4.378, avg. samples / sec: 66391.52
Iteration:   2160, Loss function: 4.362, Average Loss: 4.428, avg. samples / sec: 66304.28
Iteration:   2160, Loss function: 4.082, Average Loss: 4.392, avg. samples / sec: 66242.54
Iteration:   2160, Loss function: 4.915, Average Loss: 4.403, avg. samples / sec: 66381.01
Iteration:   2160, Loss function: 4.267, Average Loss: 4.383, avg. samples / sec: 66227.38
Iteration:   2160, Loss function: 4.007, Average Loss: 4.416, avg. samples / sec: 66116.36
Iteration:   2160, Loss function: 3.988, Average Loss: 4.431, avg. samples / sec: 66267.33
Iteration:   2160, Loss function: 3.387, Average Loss: 4.371, avg. samples / sec: 66223.49
Iteration:   2160, Loss function: 5.257, Average Loss: 4.431, avg. samples / sec: 66245.12
Iteration:   2160, Loss function: 4.146, Average Loss: 4.410, avg. samples / sec: 66242.69
Iteration:   2160, Loss function: 4.285, Average Loss: 4.397, avg. samples / sec: 66247.08
Iteration:   2160, Loss function: 4.260, Average Loss: 4.396, avg. samples / sec: 66253.72
:::MLL 1558651245.040 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1558651245.041 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   2180, Loss function: 5.129, Average Loss: 4.382, avg. samples / sec: 65984.86
Iteration:   2180, Loss function: 3.736, Average Loss: 4.404, avg. samples / sec: 65990.36
Iteration:   2180, Loss function: 4.761, Average Loss: 4.391, avg. samples / sec: 65977.04
Iteration:   2180, Loss function: 5.090, Average Loss: 4.384, avg. samples / sec: 65974.48
Iteration:   2180, Loss function: 3.613, Average Loss: 4.420, avg. samples / sec: 65960.03
Iteration:   2180, Loss function: 5.003, Average Loss: 4.419, avg. samples / sec: 65920.29
Iteration:   2180, Loss function: 4.450, Average Loss: 4.397, avg. samples / sec: 66017.56
Iteration:   2180, Loss function: 4.927, Average Loss: 4.400, avg. samples / sec: 65893.91
Iteration:   2180, Loss function: 3.234, Average Loss: 4.380, avg. samples / sec: 65915.11
Iteration:   2180, Loss function: 2.904, Average Loss: 4.417, avg. samples / sec: 65908.54
Iteration:   2180, Loss function: 3.187, Average Loss: 4.403, avg. samples / sec: 65840.12
Iteration:   2180, Loss function: 5.627, Average Loss: 4.394, avg. samples / sec: 65843.42
Iteration:   2180, Loss function: 3.227, Average Loss: 4.360, avg. samples / sec: 65822.84
Iteration:   2180, Loss function: 3.598, Average Loss: 4.395, avg. samples / sec: 65862.28
Iteration:   2180, Loss function: 3.856, Average Loss: 4.414, avg. samples / sec: 65797.06
Iteration:   2180, Loss function: 5.258, Average Loss: 4.415, avg. samples / sec: 65831.79
Iteration:   2180, Loss function: 3.208, Average Loss: 4.387, avg. samples / sec: 65981.24
Iteration:   2180, Loss function: 3.879, Average Loss: 4.398, avg. samples / sec: 65834.13
Iteration:   2180, Loss function: 4.033, Average Loss: 4.374, avg. samples / sec: 65837.39
Iteration:   2180, Loss function: 3.846, Average Loss: 4.399, avg. samples / sec: 65873.27
Iteration:   2180, Loss function: 4.250, Average Loss: 4.383, avg. samples / sec: 65798.69
Iteration:   2180, Loss function: 3.842, Average Loss: 4.432, avg. samples / sec: 65883.37
Iteration:   2180, Loss function: 3.678, Average Loss: 4.423, avg. samples / sec: 65858.00
Iteration:   2180, Loss function: 4.746, Average Loss: 4.411, avg. samples / sec: 65798.07
Iteration:   2180, Loss function: 4.577, Average Loss: 4.385, avg. samples / sec: 65739.45
Iteration:   2180, Loss function: 5.016, Average Loss: 4.388, avg. samples / sec: 65678.91
Iteration:   2180, Loss function: 5.702, Average Loss: 4.366, avg. samples / sec: 65831.91
Iteration:   2180, Loss function: 4.296, Average Loss: 4.384, avg. samples / sec: 65789.47
Iteration:   2180, Loss function: 4.828, Average Loss: 4.403, avg. samples / sec: 65745.52
Iteration:   2180, Loss function: 4.476, Average Loss: 4.404, avg. samples / sec: 65834.47
Iteration:   2200, Loss function: 4.070, Average Loss: 4.377, avg. samples / sec: 66575.47
Iteration:   2200, Loss function: 3.740, Average Loss: 4.389, avg. samples / sec: 66696.46
Iteration:   2200, Loss function: 4.547, Average Loss: 4.373, avg. samples / sec: 66590.82
Iteration:   2200, Loss function: 4.695, Average Loss: 4.401, avg. samples / sec: 66403.88
Iteration:   2200, Loss function: 4.307, Average Loss: 4.385, avg. samples / sec: 66452.13
Iteration:   2200, Loss function: 3.957, Average Loss: 4.354, avg. samples / sec: 66597.49
Iteration:   2200, Loss function: 4.531, Average Loss: 4.399, avg. samples / sec: 66598.06
Iteration:   2200, Loss function: 3.944, Average Loss: 4.398, avg. samples / sec: 66726.87
Iteration:   2200, Loss function: 4.057, Average Loss: 4.364, avg. samples / sec: 66640.32
Iteration:   2200, Loss function: 4.223, Average Loss: 4.391, avg. samples / sec: 66628.98
Iteration:   2200, Loss function: 4.829, Average Loss: 4.410, avg. samples / sec: 66542.30
Iteration:   2200, Loss function: 3.836, Average Loss: 4.414, avg. samples / sec: 66593.30
Iteration:   2200, Loss function: 3.356, Average Loss: 4.407, avg. samples / sec: 66598.47
Iteration:   2200, Loss function: 4.000, Average Loss: 4.378, avg. samples / sec: 66658.57
Iteration:   2200, Loss function: 4.081, Average Loss: 4.410, avg. samples / sec: 66499.32
Iteration:   2200, Loss function: 3.582, Average Loss: 4.386, avg. samples / sec: 66453.07
Iteration:   2200, Loss function: 6.134, Average Loss: 4.410, avg. samples / sec: 66626.65
Iteration:   2200, Loss function: 4.535, Average Loss: 4.366, avg. samples / sec: 66650.97
Iteration:   2200, Loss function: 3.916, Average Loss: 4.394, avg. samples / sec: 66495.05
Iteration:   2200, Loss function: 3.652, Average Loss: 4.399, avg. samples / sec: 66653.59
Iteration:   2200, Loss function: 3.701, Average Loss: 4.409, avg. samples / sec: 66499.54
Iteration:   2200, Loss function: 2.701, Average Loss: 4.390, avg. samples / sec: 66522.55
Iteration:   2200, Loss function: 5.885, Average Loss: 4.396, avg. samples / sec: 66480.15
Iteration:   2200, Loss function: 4.715, Average Loss: 4.375, avg. samples / sec: 66498.75
Iteration:   2200, Loss function: 5.388, Average Loss: 4.399, avg. samples / sec: 66411.76
Iteration:   2200, Loss function: 4.581, Average Loss: 4.397, avg. samples / sec: 66470.62
Iteration:   2200, Loss function: 4.433, Average Loss: 4.377, avg. samples / sec: 66530.68
Iteration:   2200, Loss function: 5.113, Average Loss: 4.425, avg. samples / sec: 66495.62
Iteration:   2200, Loss function: 5.018, Average Loss: 4.384, avg. samples / sec: 66401.06
Iteration:   2200, Loss function: 2.819, Average Loss: 4.418, avg. samples / sec: 66384.89
Iteration:   2220, Loss function: 3.623, Average Loss: 4.374, avg. samples / sec: 66320.07
Iteration:   2220, Loss function: 4.828, Average Loss: 4.401, avg. samples / sec: 66604.19
Iteration:   2220, Loss function: 3.475, Average Loss: 4.387, avg. samples / sec: 66499.88
Iteration:   2220, Loss function: 3.492, Average Loss: 4.381, avg. samples / sec: 66413.51
Iteration:   2220, Loss function: 4.391, Average Loss: 4.371, avg. samples / sec: 66579.65
Iteration:   2220, Loss function: 3.875, Average Loss: 4.405, avg. samples / sec: 66411.95
Iteration:   2220, Loss function: 3.732, Average Loss: 4.392, avg. samples / sec: 66380.73
Iteration:   2220, Loss function: 3.922, Average Loss: 4.409, avg. samples / sec: 66444.26
Iteration:   2220, Loss function: 4.310, Average Loss: 4.414, avg. samples / sec: 66648.36
Iteration:   2220, Loss function: 5.561, Average Loss: 4.380, avg. samples / sec: 66412.20
Iteration:   2220, Loss function: 5.038, Average Loss: 4.396, avg. samples / sec: 66529.30
Iteration:   2220, Loss function: 3.926, Average Loss: 4.410, avg. samples / sec: 66460.68
Iteration:   2220, Loss function: 4.730, Average Loss: 4.398, avg. samples / sec: 66358.57
Iteration:   2220, Loss function: 4.541, Average Loss: 4.377, avg. samples / sec: 66579.30
Iteration:   2220, Loss function: 5.026, Average Loss: 4.407, avg. samples / sec: 66374.42
Iteration:   2220, Loss function: 4.434, Average Loss: 4.379, avg. samples / sec: 66467.77
Iteration:   2220, Loss function: 4.842, Average Loss: 4.358, avg. samples / sec: 66349.23
Iteration:   2220, Loss function: 3.995, Average Loss: 4.406, avg. samples / sec: 66335.33
Iteration:   2220, Loss function: 4.420, Average Loss: 4.401, avg. samples / sec: 66362.98
Iteration:   2220, Loss function: 5.108, Average Loss: 4.394, avg. samples / sec: 66336.52
Iteration:   2220, Loss function: 3.026, Average Loss: 4.350, avg. samples / sec: 66294.92
Iteration:   2220, Loss function: 3.035, Average Loss: 4.372, avg. samples / sec: 66332.30
Iteration:   2220, Loss function: 3.855, Average Loss: 4.371, avg. samples / sec: 66285.53
Iteration:   2220, Loss function: 3.888, Average Loss: 4.387, avg. samples / sec: 66302.97
Iteration:   2220, Loss function: 4.289, Average Loss: 4.388, avg. samples / sec: 66382.64
Iteration:   2220, Loss function: 4.767, Average Loss: 4.364, avg. samples / sec: 66318.63
Iteration:   2220, Loss function: 5.693, Average Loss: 4.379, avg. samples / sec: 66271.88
Iteration:   2220, Loss function: 5.109, Average Loss: 4.396, avg. samples / sec: 66342.64
Iteration:   2220, Loss function: 4.376, Average Loss: 4.413, avg. samples / sec: 66431.42
Iteration:   2220, Loss function: 4.997, Average Loss: 4.392, avg. samples / sec: 66317.51
:::MLL 1558651246.814 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1558651246.814 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   2240, Loss function: 4.914, Average Loss: 4.391, avg. samples / sec: 66352.26
Iteration:   2240, Loss function: 5.004, Average Loss: 4.394, avg. samples / sec: 66259.48
Iteration:   2240, Loss function: 3.498, Average Loss: 4.372, avg. samples / sec: 66212.91
Iteration:   2240, Loss function: 4.487, Average Loss: 4.374, avg. samples / sec: 66343.98
Iteration:   2240, Loss function: 4.023, Average Loss: 4.345, avg. samples / sec: 66365.60
Iteration:   2240, Loss function: 4.173, Average Loss: 4.380, avg. samples / sec: 66288.75
Iteration:   2240, Loss function: 3.784, Average Loss: 4.382, avg. samples / sec: 66254.96
Iteration:   2240, Loss function: 3.387, Average Loss: 4.382, avg. samples / sec: 66437.43
Iteration:   2240, Loss function: 2.927, Average Loss: 4.393, avg. samples / sec: 66259.14
Iteration:   2240, Loss function: 3.661, Average Loss: 4.361, avg. samples / sec: 66331.68
Iteration:   2240, Loss function: 4.297, Average Loss: 4.405, avg. samples / sec: 66243.19
Iteration:   2240, Loss function: 3.542, Average Loss: 4.408, avg. samples / sec: 66346.89
Iteration:   2240, Loss function: 3.239, Average Loss: 4.390, avg. samples / sec: 66331.21
Iteration:   2240, Loss function: 4.544, Average Loss: 4.407, avg. samples / sec: 66282.51
Iteration:   2240, Loss function: 4.317, Average Loss: 4.358, avg. samples / sec: 66339.23
Iteration:   2240, Loss function: 3.508, Average Loss: 4.361, avg. samples / sec: 66275.78
Iteration:   2240, Loss function: 3.894, Average Loss: 4.405, avg. samples / sec: 66186.26
Iteration:   2240, Loss function: 3.499, Average Loss: 4.404, avg. samples / sec: 66214.81
Iteration:   2240, Loss function: 3.384, Average Loss: 4.376, avg. samples / sec: 66137.59
Iteration:   2240, Loss function: 3.422, Average Loss: 4.391, avg. samples / sec: 66231.30
Iteration:   2240, Loss function: 3.326, Average Loss: 4.373, avg. samples / sec: 66270.54
Iteration:   2240, Loss function: 3.900, Average Loss: 4.380, avg. samples / sec: 66250.14
Iteration:   2240, Loss function: 4.557, Average Loss: 4.385, avg. samples / sec: 66091.93
Iteration:   2240, Loss function: 4.309, Average Loss: 4.351, avg. samples / sec: 66164.01
Iteration:   2240, Loss function: 5.117, Average Loss: 4.382, avg. samples / sec: 66219.60
Iteration:   2240, Loss function: 4.234, Average Loss: 4.399, avg. samples / sec: 66107.99
Iteration:   2240, Loss function: 4.669, Average Loss: 4.397, avg. samples / sec: 66156.00
Iteration:   2240, Loss function: 3.794, Average Loss: 4.364, avg. samples / sec: 66082.57
Iteration:   2240, Loss function: 3.736, Average Loss: 4.398, avg. samples / sec: 65997.28
Iteration:   2240, Loss function: 5.103, Average Loss: 4.373, avg. samples / sec: 65997.59
Iteration:   2260, Loss function: 4.227, Average Loss: 4.372, avg. samples / sec: 66235.22
Iteration:   2260, Loss function: 3.761, Average Loss: 4.390, avg. samples / sec: 66421.00
Iteration:   2260, Loss function: 4.116, Average Loss: 4.368, avg. samples / sec: 66066.52
Iteration:   2260, Loss function: 3.936, Average Loss: 4.400, avg. samples / sec: 66144.42
Iteration:   2260, Loss function: 4.808, Average Loss: 4.379, avg. samples / sec: 66093.01
Iteration:   2260, Loss function: 4.605, Average Loss: 4.401, avg. samples / sec: 66169.98
Iteration:   2260, Loss function: 5.182, Average Loss: 4.404, avg. samples / sec: 66156.59
Iteration:   2260, Loss function: 4.305, Average Loss: 4.391, avg. samples / sec: 66006.68
Iteration:   2260, Loss function: 3.980, Average Loss: 4.389, avg. samples / sec: 66106.13
Iteration:   2260, Loss function: 3.935, Average Loss: 4.376, avg. samples / sec: 66177.56
Iteration:   2260, Loss function: 5.238, Average Loss: 4.369, avg. samples / sec: 66374.70
Iteration:   2260, Loss function: 4.109, Average Loss: 4.357, avg. samples / sec: 66106.93
Iteration:   2260, Loss function: 3.311, Average Loss: 4.374, avg. samples / sec: 66172.96
Iteration:   2260, Loss function: 4.398, Average Loss: 4.396, avg. samples / sec: 66081.92
Iteration:   2260, Loss function: 5.185, Average Loss: 4.348, avg. samples / sec: 66178.08
Iteration:   2260, Loss function: 2.551, Average Loss: 4.338, avg. samples / sec: 66037.58
Iteration:   2260, Loss function: 4.475, Average Loss: 4.361, avg. samples / sec: 66199.07
Iteration:   2260, Loss function: 3.559, Average Loss: 4.404, avg. samples / sec: 66067.24
Iteration:   2260, Loss function: 5.315, Average Loss: 4.376, avg. samples / sec: 66012.12
Iteration:   2260, Loss function: 3.727, Average Loss: 4.374, avg. samples / sec: 66004.30
Iteration:   2260, Loss function: 4.674, Average Loss: 4.373, avg. samples / sec: 66107.80
Iteration:   2260, Loss function: 4.264, Average Loss: 4.395, avg. samples / sec: 66184.36
Iteration:   2260, Loss function: 4.126, Average Loss: 4.395, avg. samples / sec: 66161.62
Iteration:   2260, Loss function: 4.343, Average Loss: 4.385, avg. samples / sec: 65925.19
Iteration:   2260, Loss function: 4.101, Average Loss: 4.382, avg. samples / sec: 66004.55
Iteration:   2260, Loss function: 4.903, Average Loss: 4.376, avg. samples / sec: 66112.58
Iteration:   2260, Loss function: 4.663, Average Loss: 4.353, avg. samples / sec: 66044.14
Iteration:   2260, Loss function: 2.688, Average Loss: 4.385, avg. samples / sec: 66025.73
Iteration:   2260, Loss function: 4.028, Average Loss: 4.383, avg. samples / sec: 66035.60
Iteration:   2260, Loss function: 4.939, Average Loss: 4.361, avg. samples / sec: 65893.26
Iteration:   2280, Loss function: 3.845, Average Loss: 4.367, avg. samples / sec: 66604.95
Iteration:   2280, Loss function: 5.199, Average Loss: 4.397, avg. samples / sec: 66549.44
Iteration:   2280, Loss function: 3.047, Average Loss: 4.374, avg. samples / sec: 66663.84
Iteration:   2280, Loss function: 3.812, Average Loss: 4.393, avg. samples / sec: 66458.90
Iteration:   2280, Loss function: 3.723, Average Loss: 4.362, avg. samples / sec: 66556.63
Iteration:   2280, Loss function: 4.467, Average Loss: 4.388, avg. samples / sec: 66605.55
Iteration:   2280, Loss function: 3.761, Average Loss: 4.368, avg. samples / sec: 66600.42
Iteration:   2280, Loss function: 4.221, Average Loss: 4.393, avg. samples / sec: 66503.08
Iteration:   2280, Loss function: 3.231, Average Loss: 4.357, avg. samples / sec: 66569.52
Iteration:   2280, Loss function: 4.913, Average Loss: 4.389, avg. samples / sec: 66495.46
Iteration:   2280, Loss function: 3.885, Average Loss: 4.395, avg. samples / sec: 66562.83
Iteration:   2280, Loss function: 3.711, Average Loss: 4.369, avg. samples / sec: 66558.80
Iteration:   2280, Loss function: 4.305, Average Loss: 4.384, avg. samples / sec: 66552.77
Iteration:   2280, Loss function: 3.811, Average Loss: 4.372, avg. samples / sec: 66489.44
Iteration:   2280, Loss function: 5.426, Average Loss: 4.350, avg. samples / sec: 66535.89
Iteration:   2280, Loss function: 5.104, Average Loss: 4.382, avg. samples / sec: 66605.20
Iteration:   2280, Loss function: 3.117, Average Loss: 4.366, avg. samples / sec: 66316.54
Iteration:   2280, Loss function: 4.392, Average Loss: 4.363, avg. samples / sec: 66678.15
Iteration:   2280, Loss function: 4.318, Average Loss: 4.348, avg. samples / sec: 66559.84
Iteration:   2280, Loss function: 3.828, Average Loss: 4.381, avg. samples / sec: 66625.92
Iteration:   2280, Loss function: 5.146, Average Loss: 4.397, avg. samples / sec: 66469.84
Iteration:   2280, Loss function: 4.601, Average Loss: 4.389, avg. samples / sec: 66424.56
Iteration:   2280, Loss function: 4.200, Average Loss: 4.372, avg. samples / sec: 66425.32
Iteration:   2280, Loss function: 3.855, Average Loss: 4.372, avg. samples / sec: 66435.96
Iteration:   2280, Loss function: 5.224, Average Loss: 4.396, avg. samples / sec: 66425.22
Iteration:   2280, Loss function: 4.382, Average Loss: 4.351, avg. samples / sec: 66438.72
Iteration:   2280, Loss function: 4.218, Average Loss: 4.372, avg. samples / sec: 66452.75
Iteration:   2280, Loss function: 4.141, Average Loss: 4.403, avg. samples / sec: 66459.24
Iteration:   2280, Loss function: 3.832, Average Loss: 4.380, avg. samples / sec: 66533.04
Iteration:   2280, Loss function: 4.159, Average Loss: 4.336, avg. samples / sec: 66416.11
:::MLL 1558651247.995 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.75 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.38s)
DONE (t=0.38s)
DONE (t=0.38s)
DONE (t=0.38s)
DONE (t=0.38s)
DONE (t=0.38s)
DONE (t=0.38s)
DONE (t=0.38s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.38s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.39s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.40s)
DONE (t=0.41s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.44s)
DONE (t=0.45s)
DONE (t=2.64s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.14699
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.27815
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.14290
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03405
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.15076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.23846
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.16298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.23577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.24848
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24980
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38687
Current AP: 0.14699 AP goal: 0.23000
:::MLL 1558651251.842 eval_accuracy: {"value": 0.14698662312456492, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1558651251.854 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1558651251.860 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1558651251.860 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   2300, Loss function: 4.481, Average Loss: 4.365, avg. samples / sec: 7565.48
Iteration:   2300, Loss function: 4.370, Average Loss: 4.386, avg. samples / sec: 7564.48
Iteration:   2300, Loss function: 4.928, Average Loss: 4.364, avg. samples / sec: 7562.53
Iteration:   2300, Loss function: 3.388, Average Loss: 4.347, avg. samples / sec: 7565.49
Iteration:   2300, Loss function: 5.638, Average Loss: 4.386, avg. samples / sec: 7564.94
Iteration:   2300, Loss function: 4.438, Average Loss: 4.377, avg. samples / sec: 7564.69
Iteration:   2300, Loss function: 4.007, Average Loss: 4.342, avg. samples / sec: 7563.72
Iteration:   2300, Loss function: 4.147, Average Loss: 4.357, avg. samples / sec: 7564.18
Iteration:   2300, Loss function: 4.016, Average Loss: 4.365, avg. samples / sec: 7563.81
Iteration:   2300, Loss function: 3.141, Average Loss: 4.389, avg. samples / sec: 7562.88
Iteration:   2300, Loss function: 4.111, Average Loss: 4.370, avg. samples / sec: 7562.74
Iteration:   2300, Loss function: 3.489, Average Loss: 4.366, avg. samples / sec: 7564.56
Iteration:   2300, Loss function: 3.239, Average Loss: 4.387, avg. samples / sec: 7564.05
Iteration:   2300, Loss function: 4.960, Average Loss: 4.391, avg. samples / sec: 7563.12
Iteration:   2300, Loss function: 2.993, Average Loss: 4.391, avg. samples / sec: 7563.84
Iteration:   2300, Loss function: 4.272, Average Loss: 4.365, avg. samples / sec: 7562.17
Iteration:   2300, Loss function: 3.122, Average Loss: 4.384, avg. samples / sec: 7562.29
Iteration:   2300, Loss function: 4.231, Average Loss: 4.337, avg. samples / sec: 7564.07
Iteration:   2300, Loss function: 3.823, Average Loss: 4.395, avg. samples / sec: 7563.77
Iteration:   2300, Loss function: 3.557, Average Loss: 4.345, avg. samples / sec: 7562.19
Iteration:   2300, Loss function: 3.845, Average Loss: 4.371, avg. samples / sec: 7563.99
Iteration:   2300, Loss function: 4.093, Average Loss: 4.341, avg. samples / sec: 7562.78
Iteration:   2300, Loss function: 4.076, Average Loss: 4.370, avg. samples / sec: 7563.24
Iteration:   2300, Loss function: 4.241, Average Loss: 4.387, avg. samples / sec: 7562.15
Iteration:   2300, Loss function: 3.590, Average Loss: 4.353, avg. samples / sec: 7562.38
Iteration:   2300, Loss function: 3.755, Average Loss: 4.358, avg. samples / sec: 7561.29
Iteration:   2300, Loss function: 3.444, Average Loss: 4.382, avg. samples / sec: 7561.88
Iteration:   2300, Loss function: 4.514, Average Loss: 4.368, avg. samples / sec: 7562.38
Iteration:   2300, Loss function: 4.079, Average Loss: 4.394, avg. samples / sec: 7560.12
Iteration:   2300, Loss function: 3.688, Average Loss: 4.380, avg. samples / sec: 7561.08
:::MLL 1558651252.528 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1558651252.528 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2320, Loss function: 4.039, Average Loss: 4.361, avg. samples / sec: 65577.93
Iteration:   2320, Loss function: 3.863, Average Loss: 4.384, avg. samples / sec: 65511.99
Iteration:   2320, Loss function: 4.634, Average Loss: 4.387, avg. samples / sec: 65649.45
Iteration:   2320, Loss function: 5.373, Average Loss: 4.373, avg. samples / sec: 65489.83
Iteration:   2320, Loss function: 3.957, Average Loss: 4.387, avg. samples / sec: 65565.51
Iteration:   2320, Loss function: 3.948, Average Loss: 4.383, avg. samples / sec: 65637.89
Iteration:   2320, Loss function: 3.637, Average Loss: 4.385, avg. samples / sec: 65559.93
Iteration:   2320, Loss function: 4.809, Average Loss: 4.389, avg. samples / sec: 65459.38
Iteration:   2320, Loss function: 4.066, Average Loss: 4.365, avg. samples / sec: 65576.74
Iteration:   2320, Loss function: 4.964, Average Loss: 4.345, avg. samples / sec: 65406.46
Iteration:   2320, Loss function: 3.534, Average Loss: 4.362, avg. samples / sec: 65477.11
Iteration:   2320, Loss function: 3.407, Average Loss: 4.362, avg. samples / sec: 65463.82
Iteration:   2320, Loss function: 4.062, Average Loss: 4.349, avg. samples / sec: 65576.80
Iteration:   2320, Loss function: 3.960, Average Loss: 4.351, avg. samples / sec: 65592.95
Iteration:   2320, Loss function: 3.855, Average Loss: 4.342, avg. samples / sec: 65432.54
Iteration:   2320, Loss function: 3.731, Average Loss: 4.380, avg. samples / sec: 65412.11
Iteration:   2320, Loss function: 4.254, Average Loss: 4.377, avg. samples / sec: 65488.89
Iteration:   2320, Loss function: 4.535, Average Loss: 4.366, avg. samples / sec: 65540.63
Iteration:   2320, Loss function: 4.679, Average Loss: 4.366, avg. samples / sec: 65436.22
Iteration:   2320, Loss function: 5.260, Average Loss: 4.336, avg. samples / sec: 65514.22
Iteration:   2320, Loss function: 3.982, Average Loss: 4.352, avg. samples / sec: 65385.97
Iteration:   2320, Loss function: 4.890, Average Loss: 4.354, avg. samples / sec: 65464.06
Iteration:   2320, Loss function: 5.522, Average Loss: 4.339, avg. samples / sec: 65452.78
Iteration:   2320, Loss function: 4.296, Average Loss: 4.377, avg. samples / sec: 65504.93
Iteration:   2320, Loss function: 3.928, Average Loss: 4.391, avg. samples / sec: 65438.59
Iteration:   2320, Loss function: 4.319, Average Loss: 4.337, avg. samples / sec: 65450.23
Iteration:   2320, Loss function: 3.959, Average Loss: 4.398, avg. samples / sec: 65522.96
Iteration:   2320, Loss function: 3.353, Average Loss: 4.374, avg. samples / sec: 65538.62
Iteration:   2320, Loss function: 5.133, Average Loss: 4.360, avg. samples / sec: 65181.96
Iteration:   2320, Loss function: 5.041, Average Loss: 4.363, avg. samples / sec: 65446.55
Iteration:   2340, Loss function: 5.062, Average Loss: 4.365, avg. samples / sec: 66133.02
Iteration:   2340, Loss function: 3.534, Average Loss: 4.361, avg. samples / sec: 66056.99
Iteration:   2340, Loss function: 4.348, Average Loss: 4.356, avg. samples / sec: 66106.87
Iteration:   2340, Loss function: 5.558, Average Loss: 4.355, avg. samples / sec: 65844.25
Iteration:   2340, Loss function: 4.976, Average Loss: 4.348, avg. samples / sec: 66042.87
Iteration:   2340, Loss function: 4.424, Average Loss: 4.339, avg. samples / sec: 66142.83
Iteration:   2340, Loss function: 4.014, Average Loss: 4.354, avg. samples / sec: 66015.99
Iteration:   2340, Loss function: 4.039, Average Loss: 4.389, avg. samples / sec: 65874.38
Iteration:   2340, Loss function: 3.965, Average Loss: 4.358, avg. samples / sec: 66040.24
Iteration:   2340, Loss function: 4.059, Average Loss: 4.379, avg. samples / sec: 66032.90
Iteration:   2340, Loss function: 3.151, Average Loss: 4.340, avg. samples / sec: 65977.41
Iteration:   2340, Loss function: 4.880, Average Loss: 4.384, avg. samples / sec: 65952.37
Iteration:   2340, Loss function: 3.428, Average Loss: 4.380, avg. samples / sec: 65907.25
Iteration:   2340, Loss function: 3.429, Average Loss: 4.359, avg. samples / sec: 65943.15
Iteration:   2340, Loss function: 4.095, Average Loss: 4.367, avg. samples / sec: 65902.93
Iteration:   2340, Loss function: 2.978, Average Loss: 4.358, avg. samples / sec: 66105.45
Iteration:   2340, Loss function: 3.733, Average Loss: 4.378, avg. samples / sec: 65881.21
Iteration:   2340, Loss function: 4.227, Average Loss: 4.375, avg. samples / sec: 65761.32
Iteration:   2340, Loss function: 4.755, Average Loss: 4.338, avg. samples / sec: 66033.37
Iteration:   2340, Loss function: 3.380, Average Loss: 4.341, avg. samples / sec: 65932.41
Iteration:   2340, Loss function: 3.437, Average Loss: 4.380, avg. samples / sec: 65934.20
Iteration:   2340, Loss function: 3.863, Average Loss: 4.385, avg. samples / sec: 66000.93
Iteration:   2340, Loss function: 4.432, Average Loss: 4.338, avg. samples / sec: 65875.92
Iteration:   2340, Loss function: 3.941, Average Loss: 4.382, avg. samples / sec: 65807.44
Iteration:   2340, Loss function: 5.060, Average Loss: 4.373, avg. samples / sec: 65963.42
Iteration:   2340, Loss function: 3.474, Average Loss: 4.372, avg. samples / sec: 65989.46
Iteration:   2340, Loss function: 4.370, Average Loss: 4.332, avg. samples / sec: 65905.99
Iteration:   2340, Loss function: 3.598, Average Loss: 4.348, avg. samples / sec: 65893.66
Iteration:   2340, Loss function: 4.944, Average Loss: 4.398, avg. samples / sec: 65933.18
Iteration:   2340, Loss function: 3.871, Average Loss: 4.359, avg. samples / sec: 65965.15
Iteration:   2360, Loss function: 4.718, Average Loss: 4.345, avg. samples / sec: 66208.71
Iteration:   2360, Loss function: 4.339, Average Loss: 4.347, avg. samples / sec: 66140.81
Iteration:   2360, Loss function: 3.829, Average Loss: 4.363, avg. samples / sec: 66063.18
Iteration:   2360, Loss function: 3.973, Average Loss: 4.380, avg. samples / sec: 66216.14
Iteration:   2360, Loss function: 4.463, Average Loss: 4.356, avg. samples / sec: 66201.06
Iteration:   2360, Loss function: 2.305, Average Loss: 4.369, avg. samples / sec: 66215.83
Iteration:   2360, Loss function: 3.466, Average Loss: 4.350, avg. samples / sec: 66058.01
Iteration:   2360, Loss function: 3.397, Average Loss: 4.352, avg. samples / sec: 66320.47
Iteration:   2360, Loss function: 4.206, Average Loss: 4.334, avg. samples / sec: 66192.97
Iteration:   2360, Loss function: 4.362, Average Loss: 4.366, avg. samples / sec: 66212.63
Iteration:   2360, Loss function: 4.123, Average Loss: 4.370, avg. samples / sec: 66129.89
Iteration:   2360, Loss function: 4.057, Average Loss: 4.337, avg. samples / sec: 66116.80
Iteration:   2360, Loss function: 4.778, Average Loss: 4.383, avg. samples / sec: 66152.52
Iteration:   2360, Loss function: 3.753, Average Loss: 4.346, avg. samples / sec: 66023.90
Iteration:   2360, Loss function: 3.149, Average Loss: 4.353, avg. samples / sec: 66031.36
Iteration:   2360, Loss function: 4.150, Average Loss: 4.374, avg. samples / sec: 66080.90
Iteration:   2360, Loss function: 4.486, Average Loss: 4.375, avg. samples / sec: 66155.59
Iteration:   2360, Loss function: 4.564, Average Loss: 4.362, avg. samples / sec: 66069.74
Iteration:   2360, Loss function: 4.725, Average Loss: 4.371, avg. samples / sec: 66022.23
Iteration:   2360, Loss function: 3.633, Average Loss: 4.381, avg. samples / sec: 66010.45
Iteration:   2360, Loss function: 3.701, Average Loss: 4.335, avg. samples / sec: 65958.58
Iteration:   2360, Loss function: 4.062, Average Loss: 4.324, avg. samples / sec: 66136.59
Iteration:   2360, Loss function: 5.628, Average Loss: 4.355, avg. samples / sec: 65886.91
Iteration:   2360, Loss function: 5.159, Average Loss: 4.375, avg. samples / sec: 66059.21
Iteration:   2360, Loss function: 3.882, Average Loss: 4.337, avg. samples / sec: 66042.93
Iteration:   2360, Loss function: 5.373, Average Loss: 4.345, avg. samples / sec: 65943.64
Iteration:   2360, Loss function: 3.946, Average Loss: 4.351, avg. samples / sec: 66008.38
Iteration:   2360, Loss function: 3.839, Average Loss: 4.369, avg. samples / sec: 66107.46
Iteration:   2360, Loss function: 3.927, Average Loss: 4.340, avg. samples / sec: 66112.18
Iteration:   2360, Loss function: 4.282, Average Loss: 4.390, avg. samples / sec: 66078.79
:::MLL 1558651254.318 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1558651254.319 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2380, Loss function: 3.805, Average Loss: 4.359, avg. samples / sec: 65061.35
Iteration:   2380, Loss function: 4.096, Average Loss: 4.360, avg. samples / sec: 65019.39
Iteration:   2380, Loss function: 3.738, Average Loss: 4.342, avg. samples / sec: 64993.45
Iteration:   2380, Loss function: 3.907, Average Loss: 4.342, avg. samples / sec: 64975.02
Iteration:   2380, Loss function: 4.172, Average Loss: 4.366, avg. samples / sec: 65083.44
Iteration:   2380, Loss function: 5.334, Average Loss: 4.340, avg. samples / sec: 65073.28
Iteration:   2380, Loss function: 4.311, Average Loss: 4.371, avg. samples / sec: 65050.75
Iteration:   2380, Loss function: 4.026, Average Loss: 4.328, avg. samples / sec: 65109.93
Iteration:   2380, Loss function: 4.010, Average Loss: 4.331, avg. samples / sec: 65004.54
Iteration:   2380, Loss function: 4.827, Average Loss: 4.337, avg. samples / sec: 65070.27
Iteration:   2380, Loss function: 3.318, Average Loss: 4.382, avg. samples / sec: 65170.81
Iteration:   2380, Loss function: 3.933, Average Loss: 4.354, avg. samples / sec: 65013.18
Iteration:   2380, Loss function: 3.720, Average Loss: 4.362, avg. samples / sec: 65048.50
Iteration:   2380, Loss function: 3.888, Average Loss: 4.334, avg. samples / sec: 65092.70
Iteration:   2380, Loss function: 4.005, Average Loss: 4.365, avg. samples / sec: 64955.77
Iteration:   2380, Loss function: 4.636, Average Loss: 4.370, avg. samples / sec: 64994.83
Iteration:   2380, Loss function: 4.243, Average Loss: 4.368, avg. samples / sec: 64840.41
Iteration:   2380, Loss function: 3.434, Average Loss: 4.321, avg. samples / sec: 65015.10
Iteration:   2380, Loss function: 4.209, Average Loss: 4.345, avg. samples / sec: 64900.70
Iteration:   2380, Loss function: 3.374, Average Loss: 4.358, avg. samples / sec: 64833.93
Iteration:   2380, Loss function: 5.240, Average Loss: 4.333, avg. samples / sec: 64913.64
Iteration:   2380, Loss function: 3.534, Average Loss: 4.344, avg. samples / sec: 65019.09
Iteration:   2380, Loss function: 4.241, Average Loss: 4.364, avg. samples / sec: 64951.31
Iteration:   2380, Loss function: 5.594, Average Loss: 4.378, avg. samples / sec: 64921.77
Iteration:   2380, Loss function: 2.657, Average Loss: 4.350, avg. samples / sec: 64975.50
Iteration:   2380, Loss function: 4.490, Average Loss: 4.359, avg. samples / sec: 64866.25
Iteration:   2380, Loss function: 3.695, Average Loss: 4.349, avg. samples / sec: 64833.64
Iteration:   2380, Loss function: 3.643, Average Loss: 4.373, avg. samples / sec: 64899.53
Iteration:   2380, Loss function: 3.535, Average Loss: 4.350, avg. samples / sec: 64827.37
Iteration:   2380, Loss function: 3.889, Average Loss: 4.341, avg. samples / sec: 64856.70
Iteration:   2400, Loss function: 2.607, Average Loss: 4.343, avg. samples / sec: 65832.59
Iteration:   2400, Loss function: 3.422, Average Loss: 4.325, avg. samples / sec: 65926.73
Iteration:   2400, Loss function: 5.201, Average Loss: 4.339, avg. samples / sec: 65784.28
Iteration:   2400, Loss function: 5.760, Average Loss: 4.330, avg. samples / sec: 65872.16
Iteration:   2400, Loss function: 2.846, Average Loss: 4.348, avg. samples / sec: 65965.18
Iteration:   2400, Loss function: 4.062, Average Loss: 4.358, avg. samples / sec: 65767.21
Iteration:   2400, Loss function: 3.681, Average Loss: 4.355, avg. samples / sec: 65853.75
Iteration:   2400, Loss function: 3.708, Average Loss: 4.378, avg. samples / sec: 65886.51
Iteration:   2400, Loss function: 3.776, Average Loss: 4.316, avg. samples / sec: 65830.38
Iteration:   2400, Loss function: 3.536, Average Loss: 4.336, avg. samples / sec: 65839.54
Iteration:   2400, Loss function: 4.809, Average Loss: 4.363, avg. samples / sec: 65827.64
Iteration:   2400, Loss function: 3.745, Average Loss: 4.347, avg. samples / sec: 65959.04
Iteration:   2400, Loss function: 4.072, Average Loss: 4.364, avg. samples / sec: 65937.90
Iteration:   2400, Loss function: 3.990, Average Loss: 4.364, avg. samples / sec: 65791.22
Iteration:   2400, Loss function: 3.294, Average Loss: 4.339, avg. samples / sec: 65835.05
Iteration:   2400, Loss function: 4.718, Average Loss: 4.348, avg. samples / sec: 65760.40
Iteration:   2400, Loss function: 4.133, Average Loss: 4.340, avg. samples / sec: 65851.57
Iteration:   2400, Loss function: 5.402, Average Loss: 4.358, avg. samples / sec: 65587.76
Iteration:   2400, Loss function: 4.707, Average Loss: 4.365, avg. samples / sec: 65704.57
Iteration:   2400, Loss function: 3.367, Average Loss: 4.349, avg. samples / sec: 65605.47
Iteration:   2400, Loss function: 3.411, Average Loss: 4.346, avg. samples / sec: 65799.73
Iteration:   2400, Loss function: 4.037, Average Loss: 4.333, avg. samples / sec: 65955.43
Iteration:   2400, Loss function: 3.863, Average Loss: 4.372, avg. samples / sec: 65726.66
Iteration:   2400, Loss function: 2.926, Average Loss: 4.328, avg. samples / sec: 65646.17
Iteration:   2400, Loss function: 4.341, Average Loss: 4.341, avg. samples / sec: 65638.19
Iteration:   2400, Loss function: 4.093, Average Loss: 4.330, avg. samples / sec: 65774.55
Iteration:   2400, Loss function: 3.553, Average Loss: 4.364, avg. samples / sec: 65717.47
Iteration:   2400, Loss function: 2.999, Average Loss: 4.358, avg. samples / sec: 65712.41
Iteration:   2400, Loss function: 3.752, Average Loss: 4.325, avg. samples / sec: 65557.22
Iteration:   2400, Loss function: 3.311, Average Loss: 4.339, avg. samples / sec: 65709.29
Iteration:   2420, Loss function: 4.102, Average Loss: 4.339, avg. samples / sec: 66192.26
Iteration:   2420, Loss function: 4.700, Average Loss: 4.338, avg. samples / sec: 66018.06
Iteration:   2420, Loss function: 3.737, Average Loss: 4.343, avg. samples / sec: 66147.99
Iteration:   2420, Loss function: 4.768, Average Loss: 4.352, avg. samples / sec: 66160.97
Iteration:   2420, Loss function: 4.624, Average Loss: 4.357, avg. samples / sec: 66193.56
Iteration:   2420, Loss function: 4.457, Average Loss: 4.336, avg. samples / sec: 66142.49
Iteration:   2420, Loss function: 4.647, Average Loss: 4.355, avg. samples / sec: 66084.12
Iteration:   2420, Loss function: 4.675, Average Loss: 4.358, avg. samples / sec: 66092.86
Iteration:   2420, Loss function: 4.238, Average Loss: 4.353, avg. samples / sec: 65973.37
Iteration:   2420, Loss function: 4.506, Average Loss: 4.320, avg. samples / sec: 65901.21
Iteration:   2420, Loss function: 3.787, Average Loss: 4.354, avg. samples / sec: 66175.07
Iteration:   2420, Loss function: 4.140, Average Loss: 4.338, avg. samples / sec: 65863.20
Iteration:   2420, Loss function: 4.323, Average Loss: 4.327, avg. samples / sec: 66110.75
Iteration:   2420, Loss function: 4.412, Average Loss: 4.328, avg. samples / sec: 66097.76
Iteration:   2420, Loss function: 3.213, Average Loss: 4.346, avg. samples / sec: 66036.40
Iteration:   2420, Loss function: 5.250, Average Loss: 4.333, avg. samples / sec: 66034.54
Iteration:   2420, Loss function: 4.080, Average Loss: 4.359, avg. samples / sec: 66028.48
Iteration:   2420, Loss function: 4.152, Average Loss: 4.331, avg. samples / sec: 66002.16
Iteration:   2420, Loss function: 4.164, Average Loss: 4.333, avg. samples / sec: 66191.79
Iteration:   2420, Loss function: 3.942, Average Loss: 4.331, avg. samples / sec: 66036.00
Iteration:   2420, Loss function: 4.267, Average Loss: 4.373, avg. samples / sec: 65955.89
Iteration:   2420, Loss function: 3.555, Average Loss: 4.344, avg. samples / sec: 65885.37
Iteration:   2420, Loss function: 4.327, Average Loss: 4.314, avg. samples / sec: 65967.96
Iteration:   2420, Loss function: 3.527, Average Loss: 4.351, avg. samples / sec: 65940.46
Iteration:   2420, Loss function: 4.638, Average Loss: 4.318, avg. samples / sec: 66133.40
Iteration:   2420, Loss function: 6.140, Average Loss: 4.324, avg. samples / sec: 65880.35
Iteration:   2420, Loss function: 3.410, Average Loss: 4.352, avg. samples / sec: 65875.92
Iteration:   2420, Loss function: 4.938, Average Loss: 4.340, avg. samples / sec: 65917.36
Iteration:   2420, Loss function: 3.386, Average Loss: 4.335, avg. samples / sec: 65911.26
Iteration:   2420, Loss function: 4.617, Average Loss: 4.373, avg. samples / sec: 65930.47
Iteration:   2440, Loss function: 4.353, Average Loss: 4.340, avg. samples / sec: 66068.35
Iteration:   2440, Loss function: 3.993, Average Loss: 4.339, avg. samples / sec: 66139.39
Iteration:   2440, Loss function: 4.632, Average Loss: 4.336, avg. samples / sec: 66097.79
Iteration:   2440, Loss function: 4.616, Average Loss: 4.356, avg. samples / sec: 66022.85
Iteration:   2440, Loss function: 3.635, Average Loss: 4.349, avg. samples / sec: 66005.47
Iteration:   2440, Loss function: 4.503, Average Loss: 4.334, avg. samples / sec: 65972.19
Iteration:   2440, Loss function: 4.614, Average Loss: 4.351, avg. samples / sec: 66028.05
Iteration:   2440, Loss function: 4.661, Average Loss: 4.344, avg. samples / sec: 65981.40
Iteration:   2440, Loss function: 4.585, Average Loss: 4.356, avg. samples / sec: 66061.07
Iteration:   2440, Loss function: 4.218, Average Loss: 4.348, avg. samples / sec: 66146.43
Iteration:   2440, Loss function: 5.052, Average Loss: 4.343, avg. samples / sec: 66103.55
Iteration:   2440, Loss function: 4.379, Average Loss: 4.332, avg. samples / sec: 65912.43
Iteration:   2440, Loss function: 5.299, Average Loss: 4.316, avg. samples / sec: 65996.66
Iteration:   2440, Loss function: 3.085, Average Loss: 4.316, avg. samples / sec: 66083.53
Iteration:   2440, Loss function: 5.561, Average Loss: 4.326, avg. samples / sec: 66016.57
Iteration:   2440, Loss function: 4.374, Average Loss: 4.312, avg. samples / sec: 66043.67
Iteration:   2440, Loss function: 4.591, Average Loss: 4.371, avg. samples / sec: 66044.32
Iteration:   2440, Loss function: 4.645, Average Loss: 4.330, avg. samples / sec: 65917.82
Iteration:   2440, Loss function: 4.371, Average Loss: 4.333, avg. samples / sec: 65992.71
Iteration:   2440, Loss function: 3.929, Average Loss: 4.344, avg. samples / sec: 65963.52
Iteration:   2440, Loss function: 4.883, Average Loss: 4.368, avg. samples / sec: 66114.35
Iteration:   2440, Loss function: 4.438, Average Loss: 4.330, avg. samples / sec: 65996.32
Iteration:   2440, Loss function: 2.134, Average Loss: 4.349, avg. samples / sec: 65939.54
Iteration:   2440, Loss function: 5.291, Average Loss: 4.346, avg. samples / sec: 66030.55
Iteration:   2440, Loss function: 3.322, Average Loss: 4.320, avg. samples / sec: 65967.44
Iteration:   2440, Loss function: 4.338, Average Loss: 4.333, avg. samples / sec: 66072.47
Iteration:   2440, Loss function: 3.800, Average Loss: 4.325, avg. samples / sec: 65953.42
Iteration:   2440, Loss function: 4.128, Average Loss: 4.339, avg. samples / sec: 66040.39
Iteration:   2440, Loss function: 4.482, Average Loss: 4.318, avg. samples / sec: 65979.76
Iteration:   2440, Loss function: 3.912, Average Loss: 4.328, avg. samples / sec: 65842.25
:::MLL 1558651256.105 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1558651256.105 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.396, Average Loss: 4.332, avg. samples / sec: 65536.52
Iteration:   2460, Loss function: 4.195, Average Loss: 4.330, avg. samples / sec: 65461.90
Iteration:   2460, Loss function: 3.589, Average Loss: 4.336, avg. samples / sec: 65427.87
Iteration:   2460, Loss function: 3.422, Average Loss: 4.343, avg. samples / sec: 65604.00
Iteration:   2460, Loss function: 4.215, Average Loss: 4.330, avg. samples / sec: 65482.95
Iteration:   2460, Loss function: 3.353, Average Loss: 4.365, avg. samples / sec: 65554.41
Iteration:   2460, Loss function: 4.666, Average Loss: 4.349, avg. samples / sec: 65462.36
Iteration:   2460, Loss function: 4.866, Average Loss: 4.324, avg. samples / sec: 65524.27
Iteration:   2460, Loss function: 3.588, Average Loss: 4.305, avg. samples / sec: 65532.01
Iteration:   2460, Loss function: 4.463, Average Loss: 4.341, avg. samples / sec: 65460.14
Iteration:   2460, Loss function: 3.879, Average Loss: 4.348, avg. samples / sec: 65568.72
Iteration:   2460, Loss function: 5.198, Average Loss: 4.337, avg. samples / sec: 65462.39
Iteration:   2460, Loss function: 4.381, Average Loss: 4.312, avg. samples / sec: 65498.60
Iteration:   2460, Loss function: 3.951, Average Loss: 4.364, avg. samples / sec: 65508.34
Iteration:   2460, Loss function: 3.761, Average Loss: 4.324, avg. samples / sec: 65514.83
Iteration:   2460, Loss function: 3.589, Average Loss: 4.346, avg. samples / sec: 65437.44
Iteration:   2460, Loss function: 3.926, Average Loss: 4.324, avg. samples / sec: 65653.39
Iteration:   2460, Loss function: 3.645, Average Loss: 4.313, avg. samples / sec: 65548.62
Iteration:   2460, Loss function: 3.345, Average Loss: 4.349, avg. samples / sec: 65390.28
Iteration:   2460, Loss function: 3.485, Average Loss: 4.352, avg. samples / sec: 65410.92
Iteration:   2460, Loss function: 3.487, Average Loss: 4.328, avg. samples / sec: 65411.22
Iteration:   2460, Loss function: 6.063, Average Loss: 4.340, avg. samples / sec: 65455.28
Iteration:   2460, Loss function: 4.784, Average Loss: 4.335, avg. samples / sec: 65394.05
Iteration:   2460, Loss function: 4.670, Average Loss: 4.313, avg. samples / sec: 65388.61
Iteration:   2460, Loss function: 4.040, Average Loss: 4.325, avg. samples / sec: 65449.80
Iteration:   2460, Loss function: 2.734, Average Loss: 4.326, avg. samples / sec: 65414.02
Iteration:   2460, Loss function: 4.979, Average Loss: 4.329, avg. samples / sec: 65372.78
Iteration:   2460, Loss function: 4.191, Average Loss: 4.333, avg. samples / sec: 65384.28
Iteration:   2460, Loss function: 4.024, Average Loss: 4.318, avg. samples / sec: 65336.84
Iteration:   2460, Loss function: 4.948, Average Loss: 4.322, avg. samples / sec: 65362.87
Iteration:   2480, Loss function: 3.859, Average Loss: 4.330, avg. samples / sec: 66082.11
Iteration:   2480, Loss function: 4.342, Average Loss: 4.326, avg. samples / sec: 66105.63
Iteration:   2480, Loss function: 4.804, Average Loss: 4.339, avg. samples / sec: 65993.94
Iteration:   2480, Loss function: 3.146, Average Loss: 4.326, avg. samples / sec: 65964.07
Iteration:   2480, Loss function: 4.600, Average Loss: 4.301, avg. samples / sec: 66007.20
Iteration:   2480, Loss function: 5.038, Average Loss: 4.363, avg. samples / sec: 66055.28
Iteration:   2480, Loss function: 4.625, Average Loss: 4.306, avg. samples / sec: 66074.55
Iteration:   2480, Loss function: 4.595, Average Loss: 4.323, avg. samples / sec: 66080.87
Iteration:   2480, Loss function: 4.715, Average Loss: 4.348, avg. samples / sec: 65955.18
Iteration:   2480, Loss function: 4.724, Average Loss: 4.336, avg. samples / sec: 66040.15
Iteration:   2480, Loss function: 4.591, Average Loss: 4.320, avg. samples / sec: 66089.42
Iteration:   2480, Loss function: 4.017, Average Loss: 4.326, avg. samples / sec: 65823.40
Iteration:   2480, Loss function: 5.187, Average Loss: 4.349, avg. samples / sec: 66022.76
Iteration:   2480, Loss function: 3.272, Average Loss: 4.312, avg. samples / sec: 66160.03
Iteration:   2480, Loss function: 3.548, Average Loss: 4.333, avg. samples / sec: 65911.97
Iteration:   2480, Loss function: 4.036, Average Loss: 4.304, avg. samples / sec: 66046.83
Iteration:   2480, Loss function: 4.448, Average Loss: 4.301, avg. samples / sec: 65941.63
Iteration:   2480, Loss function: 4.451, Average Loss: 4.320, avg. samples / sec: 65991.50
Iteration:   2480, Loss function: 6.182, Average Loss: 4.326, avg. samples / sec: 66057.02
Iteration:   2480, Loss function: 3.828, Average Loss: 4.318, avg. samples / sec: 65899.30
Iteration:   2480, Loss function: 4.358, Average Loss: 4.345, avg. samples / sec: 65996.45
Iteration:   2480, Loss function: 3.150, Average Loss: 4.334, avg. samples / sec: 65919.70
Iteration:   2480, Loss function: 5.110, Average Loss: 4.326, avg. samples / sec: 66002.32
Iteration:   2480, Loss function: 4.488, Average Loss: 4.337, avg. samples / sec: 65906.57
Iteration:   2480, Loss function: 4.763, Average Loss: 4.341, avg. samples / sec: 65952.47
Iteration:   2480, Loss function: 3.856, Average Loss: 4.328, avg. samples / sec: 66048.44
Iteration:   2480, Loss function: 3.367, Average Loss: 4.323, avg. samples / sec: 66083.22
Iteration:   2480, Loss function: 4.009, Average Loss: 4.317, avg. samples / sec: 66086.78
Iteration:   2480, Loss function: 3.648, Average Loss: 4.321, avg. samples / sec: 65851.82
Iteration:   2480, Loss function: 3.633, Average Loss: 4.357, avg. samples / sec: 65716.52
Iteration:   2500, Loss function: 4.299, Average Loss: 4.347, avg. samples / sec: 66080.59
Iteration:   2500, Loss function: 3.410, Average Loss: 4.300, avg. samples / sec: 66097.29
Iteration:   2500, Loss function: 3.422, Average Loss: 4.328, avg. samples / sec: 65895.94
Iteration:   2500, Loss function: 2.833, Average Loss: 4.327, avg. samples / sec: 66062.68
Iteration:   2500, Loss function: 3.493, Average Loss: 4.320, avg. samples / sec: 66045.93
Iteration:   2500, Loss function: 4.140, Average Loss: 4.326, avg. samples / sec: 65846.83
Iteration:   2500, Loss function: 4.179, Average Loss: 4.312, avg. samples / sec: 66053.30
Iteration:   2500, Loss function: 5.318, Average Loss: 4.322, avg. samples / sec: 66037.39
Iteration:   2500, Loss function: 3.694, Average Loss: 4.295, avg. samples / sec: 65923.84
Iteration:   2500, Loss function: 4.414, Average Loss: 4.336, avg. samples / sec: 66010.17
Iteration:   2500, Loss function: 3.845, Average Loss: 4.323, avg. samples / sec: 65882.60
Iteration:   2500, Loss function: 3.669, Average Loss: 4.341, avg. samples / sec: 66000.80
Iteration:   2500, Loss function: 4.064, Average Loss: 4.307, avg. samples / sec: 66043.83
Iteration:   2500, Loss function: 4.359, Average Loss: 4.349, avg. samples / sec: 66166.65
Iteration:   2500, Loss function: 3.461, Average Loss: 4.320, avg. samples / sec: 66099.90
Iteration:   2500, Loss function: 3.875, Average Loss: 4.327, avg. samples / sec: 66006.00
Iteration:   2500, Loss function: 3.842, Average Loss: 4.335, avg. samples / sec: 65865.45
Iteration:   2500, Loss function: 2.819, Average Loss: 4.333, avg. samples / sec: 65968.61
Iteration:   2500, Loss function: 3.508, Average Loss: 4.325, avg. samples / sec: 65944.16
Iteration:   2500, Loss function: 3.649, Average Loss: 4.320, avg. samples / sec: 65954.63
Iteration:   2500, Loss function: 3.798, Average Loss: 4.356, avg. samples / sec: 65843.17
Iteration:   2500, Loss function: 4.834, Average Loss: 4.333, avg. samples / sec: 65922.54
Iteration:   2500, Loss function: 4.496, Average Loss: 4.299, avg. samples / sec: 65839.26
Iteration:   2500, Loss function: 4.240, Average Loss: 4.340, avg. samples / sec: 65887.13
Iteration:   2500, Loss function: 3.261, Average Loss: 4.319, avg. samples / sec: 65854.22
Iteration:   2500, Loss function: 3.651, Average Loss: 4.315, avg. samples / sec: 65859.48
Iteration:   2500, Loss function: 4.036, Average Loss: 4.319, avg. samples / sec: 65878.44
Iteration:   2500, Loss function: 4.146, Average Loss: 4.342, avg. samples / sec: 65871.33
Iteration:   2500, Loss function: 3.109, Average Loss: 4.316, avg. samples / sec: 65907.19
Iteration:   2500, Loss function: 5.916, Average Loss: 4.306, avg. samples / sec: 65826.87
:::MLL 1558651257.891 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1558651257.891 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 5.357, Average Loss: 4.316, avg. samples / sec: 65745.40
Iteration:   2520, Loss function: 4.799, Average Loss: 4.318, avg. samples / sec: 65671.84
Iteration:   2520, Loss function: 4.788, Average Loss: 4.343, avg. samples / sec: 65769.61
Iteration:   2520, Loss function: 2.982, Average Loss: 4.311, avg. samples / sec: 65778.85
Iteration:   2520, Loss function: 4.141, Average Loss: 4.331, avg. samples / sec: 65702.92
Iteration:   2520, Loss function: 4.061, Average Loss: 4.321, avg. samples / sec: 65594.72
Iteration:   2520, Loss function: 3.850, Average Loss: 4.316, avg. samples / sec: 65735.83
Iteration:   2520, Loss function: 4.109, Average Loss: 4.321, avg. samples / sec: 65542.37
Iteration:   2520, Loss function: 4.106, Average Loss: 4.335, avg. samples / sec: 65769.30
Iteration:   2520, Loss function: 3.037, Average Loss: 4.316, avg. samples / sec: 65580.10
Iteration:   2520, Loss function: 4.744, Average Loss: 4.338, avg. samples / sec: 65625.08
Iteration:   2520, Loss function: 5.425, Average Loss: 4.342, avg. samples / sec: 65484.47
Iteration:   2520, Loss function: 3.277, Average Loss: 4.326, avg. samples / sec: 65641.77
Iteration:   2520, Loss function: 3.374, Average Loss: 4.292, avg. samples / sec: 65607.67
Iteration:   2520, Loss function: 4.562, Average Loss: 4.318, avg. samples / sec: 65606.60
Iteration:   2520, Loss function: 3.890, Average Loss: 4.322, avg. samples / sec: 65665.87
Iteration:   2520, Loss function: 5.266, Average Loss: 4.300, avg. samples / sec: 65606.63
Iteration:   2520, Loss function: 3.472, Average Loss: 4.311, avg. samples / sec: 65712.35
Iteration:   2520, Loss function: 3.605, Average Loss: 4.318, avg. samples / sec: 65577.41
Iteration:   2520, Loss function: 4.458, Average Loss: 4.299, avg. samples / sec: 65429.78
Iteration:   2520, Loss function: 4.696, Average Loss: 4.293, avg. samples / sec: 65614.78
Iteration:   2520, Loss function: 4.290, Average Loss: 4.333, avg. samples / sec: 65604.80
Iteration:   2520, Loss function: 4.899, Average Loss: 4.310, avg. samples / sec: 65641.04
Iteration:   2520, Loss function: 3.667, Average Loss: 4.309, avg. samples / sec: 65568.75
Iteration:   2520, Loss function: 3.791, Average Loss: 4.327, avg. samples / sec: 65496.92
Iteration:   2520, Loss function: 3.420, Average Loss: 4.304, avg. samples / sec: 65387.01
Iteration:   2520, Loss function: 4.726, Average Loss: 4.307, avg. samples / sec: 65620.19
Iteration:   2520, Loss function: 3.891, Average Loss: 4.315, avg. samples / sec: 65494.85
Iteration:   2520, Loss function: 3.567, Average Loss: 4.351, avg. samples / sec: 65501.49
Iteration:   2520, Loss function: 3.374, Average Loss: 4.311, avg. samples / sec: 65418.63
Iteration:   2540, Loss function: 4.289, Average Loss: 4.320, avg. samples / sec: 65952.62
Iteration:   2540, Loss function: 3.459, Average Loss: 4.289, avg. samples / sec: 66051.66
Iteration:   2540, Loss function: 3.915, Average Loss: 4.316, avg. samples / sec: 65908.82
Iteration:   2540, Loss function: 3.514, Average Loss: 4.327, avg. samples / sec: 65841.05
Iteration:   2540, Loss function: 4.076, Average Loss: 4.296, avg. samples / sec: 66076.93
Iteration:   2540, Loss function: 2.184, Average Loss: 4.288, avg. samples / sec: 65932.50
Iteration:   2540, Loss function: 4.007, Average Loss: 4.309, avg. samples / sec: 66060.11
Iteration:   2540, Loss function: 4.061, Average Loss: 4.332, avg. samples / sec: 65883.65
Iteration:   2540, Loss function: 4.208, Average Loss: 4.311, avg. samples / sec: 65757.91
Iteration:   2540, Loss function: 4.593, Average Loss: 4.331, avg. samples / sec: 65854.62
Iteration:   2540, Loss function: 5.427, Average Loss: 4.295, avg. samples / sec: 65967.65
Iteration:   2540, Loss function: 4.294, Average Loss: 4.323, avg. samples / sec: 65871.39
Iteration:   2540, Loss function: 3.329, Average Loss: 4.344, avg. samples / sec: 66055.34
Iteration:   2540, Loss function: 3.647, Average Loss: 4.315, avg. samples / sec: 65789.23
Iteration:   2540, Loss function: 4.482, Average Loss: 4.312, avg. samples / sec: 65921.03
Iteration:   2540, Loss function: 2.942, Average Loss: 4.305, avg. samples / sec: 66003.03
Iteration:   2540, Loss function: 3.468, Average Loss: 4.313, avg. samples / sec: 65864.83
Iteration:   2540, Loss function: 3.746, Average Loss: 4.335, avg. samples / sec: 65699.48
Iteration:   2540, Loss function: 4.395, Average Loss: 4.304, avg. samples / sec: 65922.91
Iteration:   2540, Loss function: 2.812, Average Loss: 4.311, avg. samples / sec: 65670.34
Iteration:   2540, Loss function: 3.266, Average Loss: 4.287, avg. samples / sec: 65811.87
Iteration:   2540, Loss function: 3.056, Average Loss: 4.304, avg. samples / sec: 65737.24
Iteration:   2540, Loss function: 3.713, Average Loss: 4.318, avg. samples / sec: 65803.08
Iteration:   2540, Loss function: 3.339, Average Loss: 4.316, avg. samples / sec: 65952.84
Iteration:   2540, Loss function: 3.599, Average Loss: 4.304, avg. samples / sec: 65955.24
Iteration:   2540, Loss function: 3.360, Average Loss: 4.327, avg. samples / sec: 65873.02
Iteration:   2540, Loss function: 4.999, Average Loss: 4.333, avg. samples / sec: 65750.03
Iteration:   2540, Loss function: 3.566, Average Loss: 4.309, avg. samples / sec: 65727.83
Iteration:   2540, Loss function: 4.019, Average Loss: 4.312, avg. samples / sec: 65826.41
Iteration:   2540, Loss function: 3.690, Average Loss: 4.310, avg. samples / sec: 65546.64
Iteration:   2560, Loss function: 5.477, Average Loss: 4.311, avg. samples / sec: 66004.36
Iteration:   2560, Loss function: 4.274, Average Loss: 4.311, avg. samples / sec: 66147.99
Iteration:   2560, Loss function: 3.676, Average Loss: 4.305, avg. samples / sec: 66035.26
Iteration:   2560, Loss function: 4.220, Average Loss: 4.313, avg. samples / sec: 66079.53
Iteration:   2560, Loss function: 3.270, Average Loss: 4.313, avg. samples / sec: 66110.66
Iteration:   2560, Loss function: 4.018, Average Loss: 4.312, avg. samples / sec: 65951.48
Iteration:   2560, Loss function: 4.852, Average Loss: 4.309, avg. samples / sec: 66045.72
Iteration:   2560, Loss function: 3.751, Average Loss: 4.283, avg. samples / sec: 65878.10
Iteration:   2560, Loss function: 3.327, Average Loss: 4.305, avg. samples / sec: 66042.22
Iteration:   2560, Loss function: 4.750, Average Loss: 4.300, avg. samples / sec: 66047.88
Iteration:   2560, Loss function: 3.857, Average Loss: 4.304, avg. samples / sec: 65948.18
Iteration:   2560, Loss function: 3.130, Average Loss: 4.317, avg. samples / sec: 66036.62
Iteration:   2560, Loss function: 2.792, Average Loss: 4.316, avg. samples / sec: 65939.66
Iteration:   2560, Loss function: 3.942, Average Loss: 4.318, avg. samples / sec: 65890.70
Iteration:   2560, Loss function: 3.378, Average Loss: 4.294, avg. samples / sec: 65966.33
Iteration:   2560, Loss function: 3.059, Average Loss: 4.308, avg. samples / sec: 66011.72
Iteration:   2560, Loss function: 4.731, Average Loss: 4.285, avg. samples / sec: 65931.55
Iteration:   2560, Loss function: 4.733, Average Loss: 4.303, avg. samples / sec: 66197.76
Iteration:   2560, Loss function: 3.261, Average Loss: 4.328, avg. samples / sec: 66031.42
Iteration:   2560, Loss function: 4.848, Average Loss: 4.307, avg. samples / sec: 65954.32
Iteration:   2560, Loss function: 4.299, Average Loss: 4.309, avg. samples / sec: 66104.70
Iteration:   2560, Loss function: 4.038, Average Loss: 4.321, avg. samples / sec: 65879.40
Iteration:   2560, Loss function: 4.478, Average Loss: 4.301, avg. samples / sec: 65904.32
Iteration:   2560, Loss function: 4.587, Average Loss: 4.331, avg. samples / sec: 65851.02
Iteration:   2560, Loss function: 4.005, Average Loss: 4.292, avg. samples / sec: 65831.42
Iteration:   2560, Loss function: 3.828, Average Loss: 4.338, avg. samples / sec: 65855.57
Iteration:   2560, Loss function: 4.653, Average Loss: 4.279, avg. samples / sec: 65827.45
Iteration:   2560, Loss function: 3.872, Average Loss: 4.280, avg. samples / sec: 65902.81
Iteration:   2560, Loss function: 3.962, Average Loss: 4.305, avg. samples / sec: 66103.12
Iteration:   2560, Loss function: 3.855, Average Loss: 4.329, avg. samples / sec: 65862.93
Iteration:   2580, Loss function: 3.210, Average Loss: 4.301, avg. samples / sec: 66116.80
Iteration:   2580, Loss function: 3.680, Average Loss: 4.305, avg. samples / sec: 66117.11
Iteration:   2580, Loss function: 4.620, Average Loss: 4.301, avg. samples / sec: 66185.70
Iteration:   2580, Loss function: 4.403, Average Loss: 4.310, avg. samples / sec: 66104.49
Iteration:   2580, Loss function: 3.164, Average Loss: 4.309, avg. samples / sec: 66098.94
Iteration:   2580, Loss function: 4.596, Average Loss: 4.316, avg. samples / sec: 66217.30
Iteration:   2580, Loss function: 4.647, Average Loss: 4.281, avg. samples / sec: 66117.42
Iteration:   2580, Loss function: 3.773, Average Loss: 4.327, avg. samples / sec: 66231.70
Iteration:   2580, Loss function: 4.023, Average Loss: 4.299, avg. samples / sec: 66196.89
Iteration:   2580, Loss function: 4.750, Average Loss: 4.326, avg. samples / sec: 66181.81
Iteration:   2580, Loss function: 3.893, Average Loss: 4.281, avg. samples / sec: 66088.27
Iteration:   2580, Loss function: 2.622, Average Loss: 4.311, avg. samples / sec: 66077.74
Iteration:   2580, Loss function: 4.825, Average Loss: 4.337, avg. samples / sec: 66169.20
Iteration:   2580, Loss function: 3.871, Average Loss: 4.307, avg. samples / sec: 65870.44
Iteration:   2580, Loss function: 4.682, Average Loss: 4.301, avg. samples / sec: 66048.69
Iteration:   2580, Loss function: 5.228, Average Loss: 4.326, avg. samples / sec: 66192.07
Iteration:   2580, Loss function: 3.518, Average Loss: 4.297, avg. samples / sec: 66071.70
Iteration:   2580, Loss function: 3.545, Average Loss: 4.276, avg. samples / sec: 66154.38
Iteration:   2580, Loss function: 3.303, Average Loss: 4.299, avg. samples / sec: 66111.83
Iteration:   2580, Loss function: 4.049, Average Loss: 4.312, avg. samples / sec: 66029.81
Iteration:   2580, Loss function: 4.493, Average Loss: 4.311, avg. samples / sec: 65900.19
Iteration:   2580, Loss function: 4.471, Average Loss: 4.295, avg. samples / sec: 66084.03
Iteration:   2580, Loss function: 2.625, Average Loss: 4.309, avg. samples / sec: 65827.67
Iteration:   2580, Loss function: 5.065, Average Loss: 4.314, avg. samples / sec: 66017.28
Iteration:   2580, Loss function: 4.574, Average Loss: 4.300, avg. samples / sec: 66112.30
Iteration:   2580, Loss function: 5.391, Average Loss: 4.293, avg. samples / sec: 66083.10
Iteration:   2580, Loss function: 3.793, Average Loss: 4.306, avg. samples / sec: 66013.57
Iteration:   2580, Loss function: 2.412, Average Loss: 4.289, avg. samples / sec: 66026.69
Iteration:   2580, Loss function: 4.065, Average Loss: 4.277, avg. samples / sec: 66085.45
Iteration:   2580, Loss function: 5.137, Average Loss: 4.295, avg. samples / sec: 65895.94
:::MLL 1558651259.676 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1558651259.677 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2600, Loss function: 4.168, Average Loss: 4.300, avg. samples / sec: 65717.13
Iteration:   2600, Loss function: 3.827, Average Loss: 4.305, avg. samples / sec: 65572.93
Iteration:   2600, Loss function: 3.493, Average Loss: 4.302, avg. samples / sec: 65492.17
Iteration:   2600, Loss function: 2.794, Average Loss: 4.283, avg. samples / sec: 65559.44
Iteration:   2600, Loss function: 3.243, Average Loss: 4.319, avg. samples / sec: 65530.64
Iteration:   2600, Loss function: 4.485, Average Loss: 4.299, avg. samples / sec: 65490.62
Iteration:   2600, Loss function: 3.063, Average Loss: 4.308, avg. samples / sec: 65530.30
Iteration:   2600, Loss function: 5.152, Average Loss: 4.287, avg. samples / sec: 65670.31
Iteration:   2600, Loss function: 4.598, Average Loss: 4.285, avg. samples / sec: 65668.04
Iteration:   2600, Loss function: 2.951, Average Loss: 4.308, avg. samples / sec: 65636.85
Iteration:   2600, Loss function: 3.866, Average Loss: 4.305, avg. samples / sec: 65638.93
Iteration:   2600, Loss function: 4.429, Average Loss: 4.298, avg. samples / sec: 65600.34
Iteration:   2600, Loss function: 3.970, Average Loss: 4.311, avg. samples / sec: 65624.04
Iteration:   2600, Loss function: 4.503, Average Loss: 4.291, avg. samples / sec: 65715.02
Iteration:   2600, Loss function: 4.269, Average Loss: 4.334, avg. samples / sec: 65581.17
Iteration:   2600, Loss function: 3.528, Average Loss: 4.274, avg. samples / sec: 65483.74
Iteration:   2600, Loss function: 4.640, Average Loss: 4.292, avg. samples / sec: 65579.73
Iteration:   2600, Loss function: 4.751, Average Loss: 4.297, avg. samples / sec: 65544.75
Iteration:   2600, Loss function: 4.762, Average Loss: 4.321, avg. samples / sec: 65463.43
Iteration:   2600, Loss function: 4.045, Average Loss: 4.306, avg. samples / sec: 65527.68
Iteration:   2600, Loss function: 2.936, Average Loss: 4.297, avg. samples / sec: 65587.79
Iteration:   2600, Loss function: 3.718, Average Loss: 4.301, avg. samples / sec: 65398.60
Iteration:   2600, Loss function: 3.943, Average Loss: 4.305, avg. samples / sec: 65556.61
Iteration:   2600, Loss function: 4.952, Average Loss: 4.299, avg. samples / sec: 65376.48
Iteration:   2600, Loss function: 4.163, Average Loss: 4.270, avg. samples / sec: 65525.21
Iteration:   2600, Loss function: 3.505, Average Loss: 4.325, avg. samples / sec: 65494.91
Iteration:   2600, Loss function: 4.438, Average Loss: 4.296, avg. samples / sec: 65551.39
Iteration:   2600, Loss function: 3.502, Average Loss: 4.279, avg. samples / sec: 65471.33
Iteration:   2600, Loss function: 3.634, Average Loss: 4.286, avg. samples / sec: 65529.87
Iteration:   2600, Loss function: 5.228, Average Loss: 4.268, avg. samples / sec: 65552.49
Iteration:   2620, Loss function: 5.011, Average Loss: 4.301, avg. samples / sec: 65989.96
Iteration:   2620, Loss function: 4.474, Average Loss: 4.299, avg. samples / sec: 66019.20
Iteration:   2620, Loss function: 4.022, Average Loss: 4.283, avg. samples / sec: 66032.63
Iteration:   2620, Loss function: 4.733, Average Loss: 4.297, avg. samples / sec: 65981.12
Iteration:   2620, Loss function: 4.032, Average Loss: 4.300, avg. samples / sec: 66057.42
Iteration:   2620, Loss function: 3.372, Average Loss: 4.299, avg. samples / sec: 66037.14
Iteration:   2620, Loss function: 3.814, Average Loss: 4.296, avg. samples / sec: 66048.10
Iteration:   2620, Loss function: 5.057, Average Loss: 4.273, avg. samples / sec: 65982.82
Iteration:   2620, Loss function: 2.764, Average Loss: 4.297, avg. samples / sec: 65992.24
Iteration:   2620, Loss function: 4.074, Average Loss: 4.272, avg. samples / sec: 65884.48
Iteration:   2620, Loss function: 5.140, Average Loss: 4.297, avg. samples / sec: 65861.79
Iteration:   2620, Loss function: 4.093, Average Loss: 4.317, avg. samples / sec: 66018.21
Iteration:   2620, Loss function: 3.721, Average Loss: 4.299, avg. samples / sec: 65903.03
Iteration:   2620, Loss function: 4.062, Average Loss: 4.298, avg. samples / sec: 65876.50
Iteration:   2620, Loss function: 3.762, Average Loss: 4.292, avg. samples / sec: 65987.86
Iteration:   2620, Loss function: 3.885, Average Loss: 4.264, avg. samples / sec: 65988.35
Iteration:   2620, Loss function: 4.199, Average Loss: 4.289, avg. samples / sec: 65976.64
Iteration:   2620, Loss function: 4.212, Average Loss: 4.276, avg. samples / sec: 65965.37
Iteration:   2620, Loss function: 4.339, Average Loss: 4.299, avg. samples / sec: 65769.79
Iteration:   2620, Loss function: 2.963, Average Loss: 4.325, avg. samples / sec: 65853.23
Iteration:   2620, Loss function: 4.432, Average Loss: 4.296, avg. samples / sec: 65919.43
Iteration:   2620, Loss function: 3.391, Average Loss: 4.313, avg. samples / sec: 65896.49
Iteration:   2620, Loss function: 4.456, Average Loss: 4.285, avg. samples / sec: 65966.67
Iteration:   2620, Loss function: 5.015, Average Loss: 4.303, avg. samples / sec: 65849.60
Iteration:   2620, Loss function: 3.394, Average Loss: 4.315, avg. samples / sec: 65804.86
Iteration:   2620, Loss function: 4.906, Average Loss: 4.284, avg. samples / sec: 65817.46
Iteration:   2620, Loss function: 3.215, Average Loss: 4.285, avg. samples / sec: 65848.74
Iteration:   2620, Loss function: 3.443, Average Loss: 4.302, avg. samples / sec: 65812.79
Iteration:   2620, Loss function: 2.855, Average Loss: 4.263, avg. samples / sec: 65885.25
Iteration:   2620, Loss function: 4.958, Average Loss: 4.286, avg. samples / sec: 65708.43
Iteration:   2640, Loss function: 3.943, Average Loss: 4.276, avg. samples / sec: 65956.97
Iteration:   2640, Loss function: 4.264, Average Loss: 4.295, avg. samples / sec: 65918.62
Iteration:   2640, Loss function: 3.891, Average Loss: 4.296, avg. samples / sec: 65975.31
Iteration:   2640, Loss function: 4.951, Average Loss: 4.302, avg. samples / sec: 66079.01
Iteration:   2640, Loss function: 3.746, Average Loss: 4.310, avg. samples / sec: 65953.45
Iteration:   2640, Loss function: 5.366, Average Loss: 4.298, avg. samples / sec: 65822.44
Iteration:   2640, Loss function: 3.139, Average Loss: 4.266, avg. samples / sec: 66086.66
Iteration:   2640, Loss function: 4.007, Average Loss: 4.307, avg. samples / sec: 65989.93
Iteration:   2640, Loss function: 4.319, Average Loss: 4.301, avg. samples / sec: 65878.07
Iteration:   2640, Loss function: 3.716, Average Loss: 4.293, avg. samples / sec: 65904.85
Iteration:   2640, Loss function: 3.359, Average Loss: 4.309, avg. samples / sec: 65994.81
Iteration:   2640, Loss function: 4.443, Average Loss: 4.301, avg. samples / sec: 65854.15
Iteration:   2640, Loss function: 4.779, Average Loss: 4.284, avg. samples / sec: 65970.09
Iteration:   2640, Loss function: 3.610, Average Loss: 4.276, avg. samples / sec: 65988.04
Iteration:   2640, Loss function: 3.248, Average Loss: 4.288, avg. samples / sec: 65904.41
Iteration:   2640, Loss function: 4.329, Average Loss: 4.263, avg. samples / sec: 65903.92
Iteration:   2640, Loss function: 4.661, Average Loss: 4.300, avg. samples / sec: 65948.48
Iteration:   2640, Loss function: 3.914, Average Loss: 4.266, avg. samples / sec: 65859.66
Iteration:   2640, Loss function: 3.546, Average Loss: 4.299, avg. samples / sec: 65944.35
Iteration:   2640, Loss function: 3.916, Average Loss: 4.318, avg. samples / sec: 65934.32
Iteration:   2640, Loss function: 3.770, Average Loss: 4.296, avg. samples / sec: 65800.16
Iteration:   2640, Loss function: 3.499, Average Loss: 4.281, avg. samples / sec: 66054.38
Iteration:   2640, Loss function: 4.404, Average Loss: 4.295, avg. samples / sec: 65937.78
Iteration:   2640, Loss function: 3.729, Average Loss: 4.299, avg. samples / sec: 65661.28
Iteration:   2640, Loss function: 3.516, Average Loss: 4.294, avg. samples / sec: 65855.97
Iteration:   2640, Loss function: 3.603, Average Loss: 4.283, avg. samples / sec: 65898.16
Iteration:   2640, Loss function: 3.218, Average Loss: 4.270, avg. samples / sec: 65879.27
Iteration:   2640, Loss function: 5.092, Average Loss: 4.285, avg. samples / sec: 65704.57
Iteration:   2640, Loss function: 4.446, Average Loss: 4.291, avg. samples / sec: 65774.33
Iteration:   2640, Loss function: 3.530, Average Loss: 4.282, avg. samples / sec: 65871.91
:::MLL 1558651261.464 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1558651261.464 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2660, Loss function: 4.199, Average Loss: 4.294, avg. samples / sec: 65783.70
Iteration:   2660, Loss function: 3.246, Average Loss: 4.284, avg. samples / sec: 65720.93
Iteration:   2660, Loss function: 4.461, Average Loss: 4.287, avg. samples / sec: 65772.46
Iteration:   2660, Loss function: 4.248, Average Loss: 4.295, avg. samples / sec: 65648.80
Iteration:   2660, Loss function: 4.019, Average Loss: 4.297, avg. samples / sec: 65585.32
Iteration:   2660, Loss function: 4.588, Average Loss: 4.261, avg. samples / sec: 65592.64
Iteration:   2660, Loss function: 4.046, Average Loss: 4.288, avg. samples / sec: 65644.00
Iteration:   2660, Loss function: 5.118, Average Loss: 4.270, avg. samples / sec: 65502.52
Iteration:   2660, Loss function: 4.151, Average Loss: 4.266, avg. samples / sec: 65631.19
Iteration:   2660, Loss function: 3.909, Average Loss: 4.277, avg. samples / sec: 65593.80
Iteration:   2660, Loss function: 4.542, Average Loss: 4.282, avg. samples / sec: 65683.19
Iteration:   2660, Loss function: 4.535, Average Loss: 4.293, avg. samples / sec: 65512.85
Iteration:   2660, Loss function: 5.305, Average Loss: 4.294, avg. samples / sec: 65624.84
Iteration:   2660, Loss function: 4.625, Average Loss: 4.291, avg. samples / sec: 65520.70
Iteration:   2660, Loss function: 5.033, Average Loss: 4.299, avg. samples / sec: 65535.66
Iteration:   2660, Loss function: 2.615, Average Loss: 4.295, avg. samples / sec: 65558.59
Iteration:   2660, Loss function: 4.176, Average Loss: 4.298, avg. samples / sec: 65588.06
Iteration:   2660, Loss function: 4.050, Average Loss: 4.283, avg. samples / sec: 65575.55
Iteration:   2660, Loss function: 3.854, Average Loss: 4.311, avg. samples / sec: 65530.12
Iteration:   2660, Loss function: 3.945, Average Loss: 4.283, avg. samples / sec: 65587.51
Iteration:   2660, Loss function: 3.977, Average Loss: 4.308, avg. samples / sec: 65530.36
Iteration:   2660, Loss function: 4.453, Average Loss: 4.266, avg. samples / sec: 65617.17
Iteration:   2660, Loss function: 3.462, Average Loss: 4.308, avg. samples / sec: 65562.98
Iteration:   2660, Loss function: 4.018, Average Loss: 4.296, avg. samples / sec: 65473.70
Iteration:   2660, Loss function: 2.898, Average Loss: 4.270, avg. samples / sec: 65505.63
Iteration:   2660, Loss function: 3.664, Average Loss: 4.290, avg. samples / sec: 65604.77
Iteration:   2660, Loss function: 3.657, Average Loss: 4.273, avg. samples / sec: 65501.43
Iteration:   2660, Loss function: 4.622, Average Loss: 4.272, avg. samples / sec: 65524.88
Iteration:   2660, Loss function: 3.629, Average Loss: 4.275, avg. samples / sec: 65570.27
Iteration:   2660, Loss function: 3.880, Average Loss: 4.256, avg. samples / sec: 65355.56
Iteration:   2680, Loss function: 3.849, Average Loss: 4.290, avg. samples / sec: 65856.37
Iteration:   2680, Loss function: 4.189, Average Loss: 4.278, avg. samples / sec: 65856.77
Iteration:   2680, Loss function: 3.632, Average Loss: 4.262, avg. samples / sec: 65984.52
Iteration:   2680, Loss function: 4.960, Average Loss: 4.308, avg. samples / sec: 66002.78
Iteration:   2680, Loss function: 2.466, Average Loss: 4.294, avg. samples / sec: 65986.65
Iteration:   2680, Loss function: 4.934, Average Loss: 4.286, avg. samples / sec: 65937.56
Iteration:   2680, Loss function: 5.006, Average Loss: 4.305, avg. samples / sec: 65966.20
Iteration:   2680, Loss function: 3.391, Average Loss: 4.280, avg. samples / sec: 65920.14
Iteration:   2680, Loss function: 4.307, Average Loss: 4.292, avg. samples / sec: 65881.15
Iteration:   2680, Loss function: 4.996, Average Loss: 4.293, avg. samples / sec: 65795.95
Iteration:   2680, Loss function: 3.008, Average Loss: 4.289, avg. samples / sec: 65897.05
Iteration:   2680, Loss function: 4.421, Average Loss: 4.290, avg. samples / sec: 65937.75
Iteration:   2680, Loss function: 3.286, Average Loss: 4.261, avg. samples / sec: 65926.21
Iteration:   2680, Loss function: 3.325, Average Loss: 4.275, avg. samples / sec: 66007.02
Iteration:   2680, Loss function: 3.966, Average Loss: 4.293, avg. samples / sec: 65800.93
Iteration:   2680, Loss function: 4.231, Average Loss: 4.272, avg. samples / sec: 65832.87
Iteration:   2680, Loss function: 3.254, Average Loss: 4.283, avg. samples / sec: 65856.31
Iteration:   2680, Loss function: 3.875, Average Loss: 4.271, avg. samples / sec: 65988.38
Iteration:   2680, Loss function: 3.938, Average Loss: 4.256, avg. samples / sec: 65814.91
Iteration:   2680, Loss function: 5.405, Average Loss: 4.283, avg. samples / sec: 65714.68
Iteration:   2680, Loss function: 4.316, Average Loss: 4.262, avg. samples / sec: 65913.72
Iteration:   2680, Loss function: 3.011, Average Loss: 4.279, avg. samples / sec: 65822.20
Iteration:   2680, Loss function: 4.702, Average Loss: 4.280, avg. samples / sec: 65845.05
Iteration:   2680, Loss function: 4.796, Average Loss: 4.285, avg. samples / sec: 65781.12
Iteration:   2680, Loss function: 4.523, Average Loss: 4.287, avg. samples / sec: 65793.19
Iteration:   2680, Loss function: 5.474, Average Loss: 4.266, avg. samples / sec: 65769.85
Iteration:   2680, Loss function: 3.593, Average Loss: 4.257, avg. samples / sec: 66023.07
Iteration:   2680, Loss function: 3.858, Average Loss: 4.284, avg. samples / sec: 65864.37
Iteration:   2680, Loss function: 4.096, Average Loss: 4.268, avg. samples / sec: 65897.54
Iteration:   2680, Loss function: 3.950, Average Loss: 4.283, avg. samples / sec: 65724.30
Iteration:   2700, Loss function: 4.969, Average Loss: 4.254, avg. samples / sec: 65532.95
Iteration:   2700, Loss function: 4.960, Average Loss: 4.259, avg. samples / sec: 65678.30
Iteration:   2700, Loss function: 4.026, Average Loss: 4.275, avg. samples / sec: 65495.70
Iteration:   2700, Loss function: 3.589, Average Loss: 4.270, avg. samples / sec: 65597.34
Iteration:   2700, Loss function: 3.308, Average Loss: 4.283, avg. samples / sec: 65668.14
Iteration:   2700, Loss function: 5.553, Average Loss: 4.276, avg. samples / sec: 65636.76
Iteration:   2700, Loss function: 5.217, Average Loss: 4.257, avg. samples / sec: 65606.51
Iteration:   2700, Loss function: 3.234, Average Loss: 4.284, avg. samples / sec: 65395.26
Iteration:   2700, Loss function: 4.715, Average Loss: 4.262, avg. samples / sec: 65626.52
Iteration:   2700, Loss function: 3.826, Average Loss: 4.277, avg. samples / sec: 65622.54
Iteration:   2700, Loss function: 4.562, Average Loss: 4.298, avg. samples / sec: 65465.71
Iteration:   2700, Loss function: 3.632, Average Loss: 4.266, avg. samples / sec: 65539.99
Iteration:   2700, Loss function: 4.330, Average Loss: 4.294, avg. samples / sec: 65446.10
Iteration:   2700, Loss function: 4.200, Average Loss: 4.275, avg. samples / sec: 65541.97
Iteration:   2700, Loss function: 3.183, Average Loss: 4.303, avg. samples / sec: 65400.66
Iteration:   2700, Loss function: 4.802, Average Loss: 4.269, avg. samples / sec: 65527.38
Iteration:   2700, Loss function: 3.413, Average Loss: 4.262, avg. samples / sec: 65484.90
Iteration:   2700, Loss function: 4.862, Average Loss: 4.291, avg. samples / sec: 65504.87
Iteration:   2700, Loss function: 3.725, Average Loss: 4.274, avg. samples / sec: 65550.42
Iteration:   2700, Loss function: 3.917, Average Loss: 4.289, avg. samples / sec: 65458.68
Iteration:   2700, Loss function: 3.339, Average Loss: 4.282, avg. samples / sec: 65561.55
Iteration:   2700, Loss function: 3.593, Average Loss: 4.268, avg. samples / sec: 65483.62
Iteration:   2700, Loss function: 3.638, Average Loss: 4.289, avg. samples / sec: 65459.38
Iteration:   2700, Loss function: 3.470, Average Loss: 4.281, avg. samples / sec: 65376.27
Iteration:   2700, Loss function: 3.032, Average Loss: 4.261, avg. samples / sec: 65552.34
Iteration:   2700, Loss function: 4.494, Average Loss: 4.286, avg. samples / sec: 65427.41
Iteration:   2700, Loss function: 5.007, Average Loss: 4.288, avg. samples / sec: 65501.85
Iteration:   2700, Loss function: 4.760, Average Loss: 4.285, avg. samples / sec: 65348.74
Iteration:   2700, Loss function: 4.493, Average Loss: 4.254, avg. samples / sec: 65451.05
Iteration:   2700, Loss function: 4.333, Average Loss: 4.284, avg. samples / sec: 65374.54
Iteration:   2720, Loss function: 2.885, Average Loss: 4.284, avg. samples / sec: 66292.36
Iteration:   2720, Loss function: 4.658, Average Loss: 4.268, avg. samples / sec: 66100.49
Iteration:   2720, Loss function: 4.645, Average Loss: 4.285, avg. samples / sec: 66232.11
Iteration:   2720, Loss function: 3.992, Average Loss: 4.278, avg. samples / sec: 66344.98
Iteration:   2720, Loss function: 4.561, Average Loss: 4.271, avg. samples / sec: 66097.57
Iteration:   2720, Loss function: 4.318, Average Loss: 4.284, avg. samples / sec: 66347.20
Iteration:   2720, Loss function: 4.076, Average Loss: 4.274, avg. samples / sec: 66248.42
Iteration:   2720, Loss function: 4.261, Average Loss: 4.265, avg. samples / sec: 66162.18
Iteration:   2720, Loss function: 2.953, Average Loss: 4.269, avg. samples / sec: 66133.61
Iteration:   2720, Loss function: 4.226, Average Loss: 4.282, avg. samples / sec: 66089.20
Iteration:   2720, Loss function: 3.296, Average Loss: 4.295, avg. samples / sec: 66144.26
Iteration:   2720, Loss function: 3.770, Average Loss: 4.280, avg. samples / sec: 66037.45
Iteration:   2720, Loss function: 3.131, Average Loss: 4.250, avg. samples / sec: 65960.24
Iteration:   2720, Loss function: 4.368, Average Loss: 4.257, avg. samples / sec: 66027.15
Iteration:   2720, Loss function: 3.267, Average Loss: 4.274, avg. samples / sec: 66098.41
Iteration:   2720, Loss function: 2.716, Average Loss: 4.273, avg. samples / sec: 66124.93
Iteration:   2720, Loss function: 4.215, Average Loss: 4.284, avg. samples / sec: 66172.58
Iteration:   2720, Loss function: 4.707, Average Loss: 4.284, avg. samples / sec: 66177.59
Iteration:   2720, Loss function: 3.879, Average Loss: 4.262, avg. samples / sec: 66065.35
Iteration:   2720, Loss function: 2.790, Average Loss: 4.266, avg. samples / sec: 65940.80
Iteration:   2720, Loss function: 4.099, Average Loss: 4.255, avg. samples / sec: 65926.03
Iteration:   2720, Loss function: 4.599, Average Loss: 4.248, avg. samples / sec: 66194.28
Iteration:   2720, Loss function: 4.275, Average Loss: 4.290, avg. samples / sec: 66042.13
Iteration:   2720, Loss function: 5.114, Average Loss: 4.258, avg. samples / sec: 66112.83
Iteration:   2720, Loss function: 4.715, Average Loss: 4.260, avg. samples / sec: 65982.94
Iteration:   2720, Loss function: 2.994, Average Loss: 4.258, avg. samples / sec: 66045.07
Iteration:   2720, Loss function: 2.961, Average Loss: 4.261, avg. samples / sec: 66061.82
Iteration:   2720, Loss function: 5.455, Average Loss: 4.288, avg. samples / sec: 66004.39
Iteration:   2720, Loss function: 3.563, Average Loss: 4.293, avg. samples / sec: 65972.63
Iteration:   2720, Loss function: 3.365, Average Loss: 4.271, avg. samples / sec: 65901.49
:::MLL 1558651263.251 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1558651263.252 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2740, Loss function: 2.931, Average Loss: 4.281, avg. samples / sec: 65670.25
Iteration:   2740, Loss function: 4.643, Average Loss: 4.280, avg. samples / sec: 65727.58
Iteration:   2740, Loss function: 5.016, Average Loss: 4.271, avg. samples / sec: 65680.99
Iteration:   2740, Loss function: 3.323, Average Loss: 4.244, avg. samples / sec: 65709.29
Iteration:   2740, Loss function: 4.384, Average Loss: 4.260, avg. samples / sec: 65636.73
Iteration:   2740, Loss function: 4.592, Average Loss: 4.274, avg. samples / sec: 65551.42
Iteration:   2740, Loss function: 4.679, Average Loss: 4.254, avg. samples / sec: 65763.16
Iteration:   2740, Loss function: 4.911, Average Loss: 4.267, avg. samples / sec: 65656.88
Iteration:   2740, Loss function: 3.973, Average Loss: 4.289, avg. samples / sec: 65617.50
Iteration:   2740, Loss function: 3.459, Average Loss: 4.253, avg. samples / sec: 65677.93
Iteration:   2740, Loss function: 3.359, Average Loss: 4.273, avg. samples / sec: 65647.09
Iteration:   2740, Loss function: 3.163, Average Loss: 4.275, avg. samples / sec: 65616.65
Iteration:   2740, Loss function: 2.713, Average Loss: 4.277, avg. samples / sec: 65552.80
Iteration:   2740, Loss function: 4.285, Average Loss: 4.283, avg. samples / sec: 65685.92
Iteration:   2740, Loss function: 4.124, Average Loss: 4.260, avg. samples / sec: 65594.99
Iteration:   2740, Loss function: 3.572, Average Loss: 4.243, avg. samples / sec: 65688.46
Iteration:   2740, Loss function: 3.971, Average Loss: 4.256, avg. samples / sec: 65681.39
Iteration:   2740, Loss function: 3.884, Average Loss: 4.265, avg. samples / sec: 65481.16
Iteration:   2740, Loss function: 3.919, Average Loss: 4.259, avg. samples / sec: 65648.25
Iteration:   2740, Loss function: 4.424, Average Loss: 4.293, avg. samples / sec: 65735.89
Iteration:   2740, Loss function: 3.311, Average Loss: 4.252, avg. samples / sec: 65594.57
Iteration:   2740, Loss function: 4.277, Average Loss: 4.277, avg. samples / sec: 65493.82
Iteration:   2740, Loss function: 3.326, Average Loss: 4.253, avg. samples / sec: 65653.42
Iteration:   2740, Loss function: 4.128, Average Loss: 4.260, avg. samples / sec: 65790.42
Iteration:   2740, Loss function: 3.917, Average Loss: 4.285, avg. samples / sec: 65699.06
Iteration:   2740, Loss function: 3.308, Average Loss: 4.249, avg. samples / sec: 65618.24
Iteration:   2740, Loss function: 4.427, Average Loss: 4.285, avg. samples / sec: 65561.37
Iteration:   2740, Loss function: 4.252, Average Loss: 4.281, avg. samples / sec: 65524.39
Iteration:   2740, Loss function: 3.959, Average Loss: 4.255, avg. samples / sec: 65594.51
Iteration:   2740, Loss function: 3.989, Average Loss: 4.263, avg. samples / sec: 65454.36
Iteration:   2760, Loss function: 2.803, Average Loss: 4.285, avg. samples / sec: 66090.88
Iteration:   2760, Loss function: 4.925, Average Loss: 4.254, avg. samples / sec: 66099.77
Iteration:   2760, Loss function: 4.035, Average Loss: 4.250, avg. samples / sec: 66213.03
Iteration:   2760, Loss function: 4.120, Average Loss: 4.270, avg. samples / sec: 66099.15
Iteration:   2760, Loss function: 4.214, Average Loss: 4.247, avg. samples / sec: 66058.10
Iteration:   2760, Loss function: 3.685, Average Loss: 4.248, avg. samples / sec: 66031.79
Iteration:   2760, Loss function: 4.551, Average Loss: 4.266, avg. samples / sec: 65997.31
Iteration:   2760, Loss function: 3.483, Average Loss: 4.271, avg. samples / sec: 66192.45
Iteration:   2760, Loss function: 3.043, Average Loss: 4.257, avg. samples / sec: 66211.38
Iteration:   2760, Loss function: 4.109, Average Loss: 4.255, avg. samples / sec: 65969.91
Iteration:   2760, Loss function: 4.030, Average Loss: 4.274, avg. samples / sec: 65927.48
Iteration:   2760, Loss function: 4.762, Average Loss: 4.239, avg. samples / sec: 66070.95
Iteration:   2760, Loss function: 3.654, Average Loss: 4.240, avg. samples / sec: 65946.26
Iteration:   2760, Loss function: 3.326, Average Loss: 4.257, avg. samples / sec: 66047.42
Iteration:   2760, Loss function: 3.925, Average Loss: 4.278, avg. samples / sec: 65889.93
Iteration:   2760, Loss function: 4.153, Average Loss: 4.251, avg. samples / sec: 66003.68
Iteration:   2760, Loss function: 3.606, Average Loss: 4.279, avg. samples / sec: 65992.27
Iteration:   2760, Loss function: 3.903, Average Loss: 4.257, avg. samples / sec: 65978.28
Iteration:   2760, Loss function: 4.377, Average Loss: 4.257, avg. samples / sec: 66047.20
Iteration:   2760, Loss function: 2.403, Average Loss: 4.243, avg. samples / sec: 66035.10
Iteration:   2760, Loss function: 3.157, Average Loss: 4.281, avg. samples / sec: 66074.39
Iteration:   2760, Loss function: 3.218, Average Loss: 4.272, avg. samples / sec: 66023.04
Iteration:   2760, Loss function: 3.347, Average Loss: 4.269, avg. samples / sec: 65943.45
Iteration:   2760, Loss function: 2.584, Average Loss: 4.256, avg. samples / sec: 65965.71
Iteration:   2760, Loss function: 4.280, Average Loss: 4.265, avg. samples / sec: 65926.21
Iteration:   2760, Loss function: 3.772, Average Loss: 4.291, avg. samples / sec: 65946.66
Iteration:   2760, Loss function: 3.828, Average Loss: 4.272, avg. samples / sec: 65773.97
Iteration:   2760, Loss function: 3.866, Average Loss: 4.276, avg. samples / sec: 65976.09
Iteration:   2760, Loss function: 4.417, Average Loss: 4.245, avg. samples / sec: 65983.53
Iteration:   2760, Loss function: 4.328, Average Loss: 4.249, avg. samples / sec: 65947.68
Iteration:   2780, Loss function: 3.124, Average Loss: 4.270, avg. samples / sec: 66163.33
Iteration:   2780, Loss function: 3.977, Average Loss: 4.269, avg. samples / sec: 66123.40
Iteration:   2780, Loss function: 3.975, Average Loss: 4.283, avg. samples / sec: 66066.74
Iteration:   2780, Loss function: 4.322, Average Loss: 4.242, avg. samples / sec: 66118.88
Iteration:   2780, Loss function: 4.049, Average Loss: 4.253, avg. samples / sec: 66165.16
Iteration:   2780, Loss function: 4.500, Average Loss: 4.259, avg. samples / sec: 66117.54
Iteration:   2780, Loss function: 4.568, Average Loss: 4.250, avg. samples / sec: 66077.43
Iteration:   2780, Loss function: 4.360, Average Loss: 4.276, avg. samples / sec: 66118.63
Iteration:   2780, Loss function: 2.482, Average Loss: 4.260, avg. samples / sec: 66078.70
Iteration:   2780, Loss function: 4.211, Average Loss: 4.268, avg. samples / sec: 66162.89
Iteration:   2780, Loss function: 5.110, Average Loss: 4.253, avg. samples / sec: 66103.62
Iteration:   2780, Loss function: 3.837, Average Loss: 4.272, avg. samples / sec: 66173.45
Iteration:   2780, Loss function: 4.045, Average Loss: 4.265, avg. samples / sec: 66114.94
Iteration:   2780, Loss function: 4.011, Average Loss: 4.248, avg. samples / sec: 65951.08
Iteration:   2780, Loss function: 4.236, Average Loss: 4.247, avg. samples / sec: 65952.99
Iteration:   2780, Loss function: 3.879, Average Loss: 4.246, avg. samples / sec: 66170.78
Iteration:   2780, Loss function: 5.192, Average Loss: 4.253, avg. samples / sec: 66120.80
Iteration:   2780, Loss function: 4.068, Average Loss: 4.265, avg. samples / sec: 65941.97
Iteration:   2780, Loss function: 4.544, Average Loss: 4.245, avg. samples / sec: 65975.50
Iteration:   2780, Loss function: 4.831, Average Loss: 4.253, avg. samples / sec: 65997.37
Iteration:   2780, Loss function: 3.683, Average Loss: 4.274, avg. samples / sec: 66043.64
Iteration:   2780, Loss function: 3.689, Average Loss: 4.280, avg. samples / sec: 66052.74
Iteration:   2780, Loss function: 3.610, Average Loss: 4.243, avg. samples / sec: 66115.87
Iteration:   2780, Loss function: 3.988, Average Loss: 4.245, avg. samples / sec: 66005.69
Iteration:   2780, Loss function: 3.806, Average Loss: 4.237, avg. samples / sec: 65927.66
Iteration:   2780, Loss function: 4.744, Average Loss: 4.272, avg. samples / sec: 66092.02
Iteration:   2780, Loss function: 4.529, Average Loss: 4.261, avg. samples / sec: 66039.40
Iteration:   2780, Loss function: 4.062, Average Loss: 4.286, avg. samples / sec: 66013.79
Iteration:   2780, Loss function: 3.476, Average Loss: 4.242, avg. samples / sec: 65907.59
Iteration:   2780, Loss function: 3.309, Average Loss: 4.230, avg. samples / sec: 65808.27
:::MLL 1558651265.038 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1558651265.039 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2800, Loss function: 3.704, Average Loss: 4.233, avg. samples / sec: 65562.71
Iteration:   2800, Loss function: 2.429, Average Loss: 4.267, avg. samples / sec: 65572.84
Iteration:   2800, Loss function: 4.276, Average Loss: 4.263, avg. samples / sec: 65588.80
Iteration:   2800, Loss function: 4.676, Average Loss: 4.256, avg. samples / sec: 65501.25
Iteration:   2800, Loss function: 3.955, Average Loss: 4.243, avg. samples / sec: 65494.97
Iteration:   2800, Loss function: 3.567, Average Loss: 4.239, avg. samples / sec: 65605.62
Iteration:   2800, Loss function: 4.211, Average Loss: 4.265, avg. samples / sec: 65417.69
Iteration:   2800, Loss function: 3.911, Average Loss: 4.257, avg. samples / sec: 65626.91
Iteration:   2800, Loss function: 3.518, Average Loss: 4.256, avg. samples / sec: 65460.87
Iteration:   2800, Loss function: 4.118, Average Loss: 4.263, avg. samples / sec: 65531.03
Iteration:   2800, Loss function: 2.519, Average Loss: 4.242, avg. samples / sec: 65447.59
Iteration:   2800, Loss function: 3.781, Average Loss: 4.284, avg. samples / sec: 65402.57
Iteration:   2800, Loss function: 4.681, Average Loss: 4.273, avg. samples / sec: 65541.88
Iteration:   2800, Loss function: 5.373, Average Loss: 4.276, avg. samples / sec: 65432.45
Iteration:   2800, Loss function: 4.276, Average Loss: 4.243, avg. samples / sec: 65479.15
Iteration:   2800, Loss function: 4.346, Average Loss: 4.251, avg. samples / sec: 65497.87
Iteration:   2800, Loss function: 3.604, Average Loss: 4.268, avg. samples / sec: 65479.67
Iteration:   2800, Loss function: 4.352, Average Loss: 4.270, avg. samples / sec: 65478.21
Iteration:   2800, Loss function: 3.580, Average Loss: 4.267, avg. samples / sec: 65507.18
Iteration:   2800, Loss function: 3.722, Average Loss: 4.238, avg. samples / sec: 65574.27
Iteration:   2800, Loss function: 3.378, Average Loss: 4.229, avg. samples / sec: 65609.53
Iteration:   2800, Loss function: 4.801, Average Loss: 4.265, avg. samples / sec: 65253.22
Iteration:   2800, Loss function: 4.654, Average Loss: 4.243, avg. samples / sec: 65469.90
Iteration:   2800, Loss function: 3.376, Average Loss: 4.243, avg. samples / sec: 65417.72
Iteration:   2800, Loss function: 2.712, Average Loss: 4.249, avg. samples / sec: 65403.94
Iteration:   2800, Loss function: 4.462, Average Loss: 4.255, avg. samples / sec: 65362.23
Iteration:   2800, Loss function: 4.794, Average Loss: 4.247, avg. samples / sec: 65355.77
Iteration:   2800, Loss function: 4.170, Average Loss: 4.237, avg. samples / sec: 65377.36
Iteration:   2800, Loss function: 5.076, Average Loss: 4.283, avg. samples / sec: 65478.30
Iteration:   2800, Loss function: 3.027, Average Loss: 4.232, avg. samples / sec: 65397.47
Iteration:   2820, Loss function: 4.555, Average Loss: 4.260, avg. samples / sec: 66119.06
Iteration:   2820, Loss function: 4.036, Average Loss: 4.251, avg. samples / sec: 66025.60
Iteration:   2820, Loss function: 3.850, Average Loss: 4.274, avg. samples / sec: 66093.79
Iteration:   2820, Loss function: 3.362, Average Loss: 4.240, avg. samples / sec: 66146.53
Iteration:   2820, Loss function: 5.243, Average Loss: 4.276, avg. samples / sec: 66025.39
Iteration:   2820, Loss function: 4.504, Average Loss: 4.270, avg. samples / sec: 66080.43
Iteration:   2820, Loss function: 5.567, Average Loss: 4.229, avg. samples / sec: 65866.13
Iteration:   2820, Loss function: 4.410, Average Loss: 4.277, avg. samples / sec: 66182.19
Iteration:   2820, Loss function: 5.353, Average Loss: 4.237, avg. samples / sec: 66093.57
Iteration:   2820, Loss function: 4.416, Average Loss: 4.250, avg. samples / sec: 66106.72
Iteration:   2820, Loss function: 3.583, Average Loss: 4.259, avg. samples / sec: 66086.04
Iteration:   2820, Loss function: 3.929, Average Loss: 4.252, avg. samples / sec: 65975.41
Iteration:   2820, Loss function: 3.975, Average Loss: 4.234, avg. samples / sec: 65939.32
Iteration:   2820, Loss function: 4.063, Average Loss: 4.234, avg. samples / sec: 66133.02
Iteration:   2820, Loss function: 3.779, Average Loss: 4.233, avg. samples / sec: 65910.92
Iteration:   2820, Loss function: 3.939, Average Loss: 4.258, avg. samples / sec: 65952.10
Iteration:   2820, Loss function: 5.079, Average Loss: 4.263, avg. samples / sec: 65962.10
Iteration:   2820, Loss function: 4.475, Average Loss: 4.242, avg. samples / sec: 65987.36
Iteration:   2820, Loss function: 3.736, Average Loss: 4.236, avg. samples / sec: 65963.24
Iteration:   2820, Loss function: 3.344, Average Loss: 4.263, avg. samples / sec: 65802.62
Iteration:   2820, Loss function: 4.198, Average Loss: 4.269, avg. samples / sec: 65984.83
Iteration:   2820, Loss function: 4.079, Average Loss: 4.226, avg. samples / sec: 66020.81
Iteration:   2820, Loss function: 2.204, Average Loss: 4.253, avg. samples / sec: 65807.23
Iteration:   2820, Loss function: 4.169, Average Loss: 4.240, avg. samples / sec: 66041.17
Iteration:   2820, Loss function: 3.848, Average Loss: 4.260, avg. samples / sec: 65911.87
Iteration:   2820, Loss function: 2.964, Average Loss: 4.237, avg. samples / sec: 65874.53
Iteration:   2820, Loss function: 3.792, Average Loss: 4.228, avg. samples / sec: 66029.93
Iteration:   2820, Loss function: 3.683, Average Loss: 4.239, avg. samples / sec: 65944.20
Iteration:   2820, Loss function: 3.713, Average Loss: 4.251, avg. samples / sec: 65759.51
Iteration:   2820, Loss function: 4.563, Average Loss: 4.250, avg. samples / sec: 65906.26
Iteration:   2840, Loss function: 3.869, Average Loss: 4.227, avg. samples / sec: 66051.44
Iteration:   2840, Loss function: 3.939, Average Loss: 4.253, avg. samples / sec: 66067.85
Iteration:   2840, Loss function: 5.393, Average Loss: 4.247, avg. samples / sec: 65963.95
Iteration:   2840, Loss function: 4.183, Average Loss: 4.256, avg. samples / sec: 65953.52
Iteration:   2840, Loss function: 4.431, Average Loss: 4.218, avg. samples / sec: 66000.77
Iteration:   2840, Loss function: 4.081, Average Loss: 4.219, avg. samples / sec: 65905.65
Iteration:   2840, Loss function: 3.864, Average Loss: 4.258, avg. samples / sec: 65959.20
Iteration:   2840, Loss function: 3.307, Average Loss: 4.274, avg. samples / sec: 65872.22
Iteration:   2840, Loss function: 4.500, Average Loss: 4.237, avg. samples / sec: 65858.34
Iteration:   2840, Loss function: 4.639, Average Loss: 4.233, avg. samples / sec: 65897.45
Iteration:   2840, Loss function: 3.682, Average Loss: 4.217, avg. samples / sec: 66035.69
Iteration:   2840, Loss function: 4.510, Average Loss: 4.256, avg. samples / sec: 65719.09
Iteration:   2840, Loss function: 3.421, Average Loss: 4.242, avg. samples / sec: 65767.86
Iteration:   2840, Loss function: 4.372, Average Loss: 4.250, avg. samples / sec: 66074.86
Iteration:   2840, Loss function: 3.579, Average Loss: 4.252, avg. samples / sec: 65970.62
Iteration:   2840, Loss function: 3.279, Average Loss: 4.245, avg. samples / sec: 65857.57
Iteration:   2840, Loss function: 3.697, Average Loss: 4.266, avg. samples / sec: 65774.12
Iteration:   2840, Loss function: 3.139, Average Loss: 4.233, avg. samples / sec: 65958.52
Iteration:   2840, Loss function: 3.287, Average Loss: 4.248, avg. samples / sec: 66060.24
Iteration:   2840, Loss function: 3.239, Average Loss: 4.224, avg. samples / sec: 65867.33
Iteration:   2840, Loss function: 4.745, Average Loss: 4.262, avg. samples / sec: 65789.44
Iteration:   2840, Loss function: 3.709, Average Loss: 4.235, avg. samples / sec: 65875.92
Iteration:   2840, Loss function: 3.447, Average Loss: 4.235, avg. samples / sec: 65817.52
Iteration:   2840, Loss function: 2.721, Average Loss: 4.263, avg. samples / sec: 65861.60
Iteration:   2840, Loss function: 5.335, Average Loss: 4.249, avg. samples / sec: 65868.28
Iteration:   2840, Loss function: 4.269, Average Loss: 4.235, avg. samples / sec: 65902.07
Iteration:   2840, Loss function: 2.572, Average Loss: 4.274, avg. samples / sec: 65722.00
Iteration:   2840, Loss function: 3.791, Average Loss: 4.232, avg. samples / sec: 65759.88
Iteration:   2840, Loss function: 3.006, Average Loss: 4.250, avg. samples / sec: 65771.17
Iteration:   2840, Loss function: 5.799, Average Loss: 4.236, avg. samples / sec: 65813.74
Iteration:   2860, Loss function: 4.437, Average Loss: 4.233, avg. samples / sec: 66387.55
Iteration:   2860, Loss function: 4.622, Average Loss: 4.222, avg. samples / sec: 66080.49
Iteration:   2860, Loss function: 3.987, Average Loss: 4.239, avg. samples / sec: 66198.63
Iteration:   2860, Loss function: 3.822, Average Loss: 4.251, avg. samples / sec: 66183.43
Iteration:   2860, Loss function: 4.950, Average Loss: 4.250, avg. samples / sec: 66192.60
Iteration:   2860, Loss function: 4.688, Average Loss: 4.212, avg. samples / sec: 66133.37
Iteration:   2860, Loss function: 2.461, Average Loss: 4.250, avg. samples / sec: 66029.63
Iteration:   2860, Loss function: 3.952, Average Loss: 4.260, avg. samples / sec: 66180.38
Iteration:   2860, Loss function: 3.819, Average Loss: 4.225, avg. samples / sec: 66171.03
Iteration:   2860, Loss function: 4.522, Average Loss: 4.248, avg. samples / sec: 66059.96
Iteration:   2860, Loss function: 4.881, Average Loss: 4.212, avg. samples / sec: 66094.94
Iteration:   2860, Loss function: 4.294, Average Loss: 4.247, avg. samples / sec: 66129.18
Iteration:   2860, Loss function: 3.809, Average Loss: 4.260, avg. samples / sec: 66191.76
Iteration:   2860, Loss function: 3.397, Average Loss: 4.247, avg. samples / sec: 66153.02
Iteration:   2860, Loss function: 3.719, Average Loss: 4.269, avg. samples / sec: 66079.72
Iteration:   2860, Loss function: 4.919, Average Loss: 4.233, avg. samples / sec: 66103.59
Iteration:   2860, Loss function: 3.798, Average Loss: 4.249, avg. samples / sec: 66211.79
Iteration:   2860, Loss function: 3.294, Average Loss: 4.229, avg. samples / sec: 66055.81
Iteration:   2860, Loss function: 3.120, Average Loss: 4.251, avg. samples / sec: 66026.69
Iteration:   2860, Loss function: 3.278, Average Loss: 4.245, avg. samples / sec: 65993.63
Iteration:   2860, Loss function: 3.313, Average Loss: 4.255, avg. samples / sec: 66125.76
Iteration:   2860, Loss function: 4.391, Average Loss: 4.227, avg. samples / sec: 66111.71
Iteration:   2860, Loss function: 2.890, Average Loss: 4.228, avg. samples / sec: 66184.61
Iteration:   2860, Loss function: 3.550, Average Loss: 4.234, avg. samples / sec: 66235.10
Iteration:   2860, Loss function: 4.176, Average Loss: 4.269, avg. samples / sec: 66185.30
Iteration:   2860, Loss function: 4.480, Average Loss: 4.237, avg. samples / sec: 66037.05
Iteration:   2860, Loss function: 4.982, Average Loss: 4.244, avg. samples / sec: 66123.62
Iteration:   2860, Loss function: 3.928, Average Loss: 4.218, avg. samples / sec: 65988.69
Iteration:   2860, Loss function: 5.085, Average Loss: 4.229, avg. samples / sec: 66086.94
Iteration:   2860, Loss function: 4.178, Average Loss: 4.211, avg. samples / sec: 65877.40
:::MLL 1558651266.822 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1558651266.822 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 3.418, Average Loss: 4.242, avg. samples / sec: 65735.28
Iteration:   2880, Loss function: 2.301, Average Loss: 4.229, avg. samples / sec: 65647.15
Iteration:   2880, Loss function: 4.327, Average Loss: 4.214, avg. samples / sec: 65600.89
Iteration:   2880, Loss function: 3.362, Average Loss: 4.256, avg. samples / sec: 65671.26
Iteration:   2880, Loss function: 3.612, Average Loss: 4.210, avg. samples / sec: 65676.61
Iteration:   2880, Loss function: 3.455, Average Loss: 4.245, avg. samples / sec: 65613.71
Iteration:   2880, Loss function: 3.644, Average Loss: 4.240, avg. samples / sec: 65653.08
Iteration:   2880, Loss function: 4.078, Average Loss: 4.235, avg. samples / sec: 65677.23
Iteration:   2880, Loss function: 4.055, Average Loss: 4.245, avg. samples / sec: 65654.25
Iteration:   2880, Loss function: 5.282, Average Loss: 4.248, avg. samples / sec: 65668.17
Iteration:   2880, Loss function: 4.630, Average Loss: 4.213, avg. samples / sec: 65799.06
Iteration:   2880, Loss function: 4.025, Average Loss: 4.235, avg. samples / sec: 65468.32
Iteration:   2880, Loss function: 3.994, Average Loss: 4.248, avg. samples / sec: 65678.27
Iteration:   2880, Loss function: 3.734, Average Loss: 4.239, avg. samples / sec: 65611.06
Iteration:   2880, Loss function: 3.970, Average Loss: 4.264, avg. samples / sec: 65610.51
Iteration:   2880, Loss function: 4.619, Average Loss: 4.230, avg. samples / sec: 65651.89
Iteration:   2880, Loss function: 4.720, Average Loss: 4.224, avg. samples / sec: 65661.99
Iteration:   2880, Loss function: 3.295, Average Loss: 4.228, avg. samples / sec: 65617.63
Iteration:   2880, Loss function: 4.682, Average Loss: 4.221, avg. samples / sec: 65752.48
Iteration:   2880, Loss function: 4.556, Average Loss: 4.231, avg. samples / sec: 65666.33
Iteration:   2880, Loss function: 3.346, Average Loss: 4.243, avg. samples / sec: 65498.44
Iteration:   2880, Loss function: 3.424, Average Loss: 4.246, avg. samples / sec: 65520.98
Iteration:   2880, Loss function: 3.072, Average Loss: 4.207, avg. samples / sec: 65790.27
Iteration:   2880, Loss function: 4.283, Average Loss: 4.216, avg. samples / sec: 65517.99
Iteration:   2880, Loss function: 4.616, Average Loss: 4.254, avg. samples / sec: 65537.83
Iteration:   2880, Loss function: 3.698, Average Loss: 4.236, avg. samples / sec: 65651.13
Iteration:   2880, Loss function: 3.496, Average Loss: 4.228, avg. samples / sec: 65509.31
Iteration:   2880, Loss function: 2.720, Average Loss: 4.259, avg. samples / sec: 65576.77
Iteration:   2880, Loss function: 3.794, Average Loss: 4.207, avg. samples / sec: 65459.47
Iteration:   2880, Loss function: 3.483, Average Loss: 4.222, avg. samples / sec: 65520.00
Iteration:   2900, Loss function: 5.388, Average Loss: 4.212, avg. samples / sec: 66401.03
Iteration:   2900, Loss function: 4.567, Average Loss: 4.243, avg. samples / sec: 66393.55
Iteration:   2900, Loss function: 4.741, Average Loss: 4.240, avg. samples / sec: 66274.25
Iteration:   2900, Loss function: 2.724, Average Loss: 4.237, avg. samples / sec: 66176.47
Iteration:   2900, Loss function: 3.908, Average Loss: 4.250, avg. samples / sec: 66209.92
Iteration:   2900, Loss function: 3.868, Average Loss: 4.233, avg. samples / sec: 66279.83
Iteration:   2900, Loss function: 3.702, Average Loss: 4.205, avg. samples / sec: 66186.04
Iteration:   2900, Loss function: 5.179, Average Loss: 4.231, avg. samples / sec: 66369.16
Iteration:   2900, Loss function: 4.056, Average Loss: 4.223, avg. samples / sec: 66160.84
Iteration:   2900, Loss function: 5.043, Average Loss: 4.256, avg. samples / sec: 66242.76
Iteration:   2900, Loss function: 4.574, Average Loss: 4.205, avg. samples / sec: 66326.21
Iteration:   2900, Loss function: 3.952, Average Loss: 4.244, avg. samples / sec: 66274.72
Iteration:   2900, Loss function: 2.429, Average Loss: 4.231, avg. samples / sec: 66197.82
Iteration:   2900, Loss function: 4.841, Average Loss: 4.207, avg. samples / sec: 66262.32
Iteration:   2900, Loss function: 3.178, Average Loss: 4.220, avg. samples / sec: 66385.55
Iteration:   2900, Loss function: 4.832, Average Loss: 4.222, avg. samples / sec: 66322.97
Iteration:   2900, Loss function: 4.918, Average Loss: 4.247, avg. samples / sec: 66207.25
Iteration:   2900, Loss function: 4.744, Average Loss: 4.227, avg. samples / sec: 66203.55
Iteration:   2900, Loss function: 4.494, Average Loss: 4.211, avg. samples / sec: 66254.62
Iteration:   2900, Loss function: 5.134, Average Loss: 4.227, avg. samples / sec: 66223.99
Iteration:   2900, Loss function: 3.622, Average Loss: 4.237, avg. samples / sec: 66145.97
Iteration:   2900, Loss function: 4.640, Average Loss: 4.233, avg. samples / sec: 66146.68
Iteration:   2900, Loss function: 3.746, Average Loss: 4.216, avg. samples / sec: 66107.74
Iteration:   2900, Loss function: 4.521, Average Loss: 4.247, avg. samples / sec: 66102.04
Iteration:   2900, Loss function: 5.020, Average Loss: 4.220, avg. samples / sec: 66127.87
Iteration:   2900, Loss function: 3.770, Average Loss: 4.237, avg. samples / sec: 66095.56
Iteration:   2900, Loss function: 5.242, Average Loss: 4.251, avg. samples / sec: 66196.08
Iteration:   2900, Loss function: 4.756, Average Loss: 4.255, avg. samples / sec: 66213.90
Iteration:   2900, Loss function: 3.940, Average Loss: 4.227, avg. samples / sec: 66158.08
Iteration:   2900, Loss function: 2.648, Average Loss: 4.213, avg. samples / sec: 66138.98
Iteration:   2920, Loss function: 4.368, Average Loss: 4.209, avg. samples / sec: 66257.11
Iteration:   2920, Loss function: 3.909, Average Loss: 4.233, avg. samples / sec: 66095.56
Iteration:   2920, Loss function: 5.195, Average Loss: 4.211, avg. samples / sec: 66283.35
Iteration:   2920, Loss function: 4.590, Average Loss: 4.253, avg. samples / sec: 66056.68
Iteration:   2920, Loss function: 4.433, Average Loss: 4.235, avg. samples / sec: 66025.08
Iteration:   2920, Loss function: 3.812, Average Loss: 4.223, avg. samples / sec: 66068.10
Iteration:   2920, Loss function: 4.116, Average Loss: 4.223, avg. samples / sec: 66145.78
Iteration:   2920, Loss function: 3.646, Average Loss: 4.203, avg. samples / sec: 66066.55
Iteration:   2920, Loss function: 5.236, Average Loss: 4.213, avg. samples / sec: 65827.33
Iteration:   2920, Loss function: 5.222, Average Loss: 4.238, avg. samples / sec: 66211.26
Iteration:   2920, Loss function: 4.131, Average Loss: 4.206, avg. samples / sec: 66108.45
Iteration:   2920, Loss function: 3.322, Average Loss: 4.241, avg. samples / sec: 66136.07
Iteration:   2920, Loss function: 3.512, Average Loss: 4.222, avg. samples / sec: 66056.89
Iteration:   2920, Loss function: 3.536, Average Loss: 4.224, avg. samples / sec: 66105.97
Iteration:   2920, Loss function: 4.976, Average Loss: 4.239, avg. samples / sec: 66062.68
Iteration:   2920, Loss function: 3.729, Average Loss: 4.228, avg. samples / sec: 66174.98
Iteration:   2920, Loss function: 3.415, Average Loss: 4.230, avg. samples / sec: 65961.42
Iteration:   2920, Loss function: 4.276, Average Loss: 4.219, avg. samples / sec: 66054.76
Iteration:   2920, Loss function: 3.607, Average Loss: 4.211, avg. samples / sec: 66040.86
Iteration:   2920, Loss function: 2.722, Average Loss: 4.242, avg. samples / sec: 66127.41
Iteration:   2920, Loss function: 4.505, Average Loss: 4.255, avg. samples / sec: 66012.06
Iteration:   2920, Loss function: 4.145, Average Loss: 4.245, avg. samples / sec: 66010.08
Iteration:   2920, Loss function: 4.564, Average Loss: 4.248, avg. samples / sec: 66094.47
Iteration:   2920, Loss function: 3.344, Average Loss: 4.247, avg. samples / sec: 66068.88
Iteration:   2920, Loss function: 2.529, Average Loss: 4.213, avg. samples / sec: 66042.71
Iteration:   2920, Loss function: 3.031, Average Loss: 4.203, avg. samples / sec: 65922.32
Iteration:   2920, Loss function: 3.416, Average Loss: 4.240, avg. samples / sec: 65810.52
Iteration:   2920, Loss function: 3.309, Average Loss: 4.233, avg. samples / sec: 66002.29
Iteration:   2920, Loss function: 4.812, Average Loss: 4.228, avg. samples / sec: 65872.38
Iteration:   2920, Loss function: 3.740, Average Loss: 4.212, avg. samples / sec: 65919.36
:::MLL 1558651268.605 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1558651268.606 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 4.728, Average Loss: 4.209, avg. samples / sec: 65850.03
Iteration:   2940, Loss function: 2.654, Average Loss: 4.210, avg. samples / sec: 65861.82
Iteration:   2940, Loss function: 4.007, Average Loss: 4.232, avg. samples / sec: 65721.09
Iteration:   2940, Loss function: 4.404, Average Loss: 4.221, avg. samples / sec: 66050.24
Iteration:   2940, Loss function: 3.637, Average Loss: 4.222, avg. samples / sec: 65865.30
Iteration:   2940, Loss function: 4.167, Average Loss: 4.233, avg. samples / sec: 65841.36
Iteration:   2940, Loss function: 4.085, Average Loss: 4.250, avg. samples / sec: 65742.91
Iteration:   2940, Loss function: 4.048, Average Loss: 4.228, avg. samples / sec: 65760.09
Iteration:   2940, Loss function: 2.896, Average Loss: 4.250, avg. samples / sec: 65838.59
Iteration:   2940, Loss function: 2.765, Average Loss: 4.200, avg. samples / sec: 65703.65
Iteration:   2940, Loss function: 3.628, Average Loss: 4.242, avg. samples / sec: 65815.59
Iteration:   2940, Loss function: 4.649, Average Loss: 4.239, avg. samples / sec: 65812.42
Iteration:   2940, Loss function: 5.400, Average Loss: 4.235, avg. samples / sec: 65773.14
Iteration:   2940, Loss function: 3.063, Average Loss: 4.203, avg. samples / sec: 65624.56
Iteration:   2940, Loss function: 3.135, Average Loss: 4.200, avg. samples / sec: 65844.25
Iteration:   2940, Loss function: 3.438, Average Loss: 4.219, avg. samples / sec: 65653.08
Iteration:   2940, Loss function: 5.268, Average Loss: 4.220, avg. samples / sec: 65645.07
Iteration:   2940, Loss function: 4.995, Average Loss: 4.239, avg. samples / sec: 65649.72
Iteration:   2940, Loss function: 4.337, Average Loss: 4.209, avg. samples / sec: 65920.26
Iteration:   2940, Loss function: 4.937, Average Loss: 4.218, avg. samples / sec: 65662.38
Iteration:   2940, Loss function: 3.652, Average Loss: 4.228, avg. samples / sec: 65686.81
Iteration:   2940, Loss function: 4.210, Average Loss: 4.211, avg. samples / sec: 65685.12
Iteration:   2940, Loss function: 4.577, Average Loss: 4.203, avg. samples / sec: 65623.86
Iteration:   2940, Loss function: 4.278, Average Loss: 4.239, avg. samples / sec: 65738.80
Iteration:   2940, Loss function: 5.605, Average Loss: 4.230, avg. samples / sec: 65769.73
Iteration:   2940, Loss function: 3.784, Average Loss: 4.209, avg. samples / sec: 65463.03
Iteration:   2940, Loss function: 4.181, Average Loss: 4.234, avg. samples / sec: 65581.23
Iteration:   2940, Loss function: 2.914, Average Loss: 4.203, avg. samples / sec: 65726.97
Iteration:   2940, Loss function: 4.510, Average Loss: 4.206, avg. samples / sec: 65615.82
Iteration:   2940, Loss function: 3.641, Average Loss: 4.237, avg. samples / sec: 65681.76
Iteration:   2960, Loss function: 3.444, Average Loss: 4.193, avg. samples / sec: 66204.20
Iteration:   2960, Loss function: 3.361, Average Loss: 4.204, avg. samples / sec: 66061.78
Iteration:   2960, Loss function: 4.385, Average Loss: 4.201, avg. samples / sec: 65990.05
Iteration:   2960, Loss function: 3.636, Average Loss: 4.223, avg. samples / sec: 65994.19
Iteration:   2960, Loss function: 3.950, Average Loss: 4.236, avg. samples / sec: 66077.67
Iteration:   2960, Loss function: 3.660, Average Loss: 4.237, avg. samples / sec: 65993.79
Iteration:   2960, Loss function: 3.118, Average Loss: 4.208, avg. samples / sec: 66133.55
Iteration:   2960, Loss function: 4.764, Average Loss: 4.241, avg. samples / sec: 66006.43
Iteration:   2960, Loss function: 3.780, Average Loss: 4.226, avg. samples / sec: 65917.64
Iteration:   2960, Loss function: 3.713, Average Loss: 4.233, avg. samples / sec: 66156.09
Iteration:   2960, Loss function: 4.563, Average Loss: 4.196, avg. samples / sec: 66083.16
Iteration:   2960, Loss function: 4.010, Average Loss: 4.231, avg. samples / sec: 66241.42
Iteration:   2960, Loss function: 4.391, Average Loss: 4.198, avg. samples / sec: 66186.01
Iteration:   2960, Loss function: 3.641, Average Loss: 4.231, avg. samples / sec: 66026.13
Iteration:   2960, Loss function: 3.508, Average Loss: 4.213, avg. samples / sec: 65876.53
Iteration:   2960, Loss function: 3.470, Average Loss: 4.200, avg. samples / sec: 66169.60
Iteration:   2960, Loss function: 4.199, Average Loss: 4.233, avg. samples / sec: 66083.69
Iteration:   2960, Loss function: 3.438, Average Loss: 4.197, avg. samples / sec: 66001.24
Iteration:   2960, Loss function: 3.742, Average Loss: 4.205, avg. samples / sec: 66090.75
Iteration:   2960, Loss function: 3.365, Average Loss: 4.232, avg. samples / sec: 65969.94
Iteration:   2960, Loss function: 3.289, Average Loss: 4.218, avg. samples / sec: 65881.71
Iteration:   2960, Loss function: 3.607, Average Loss: 4.217, avg. samples / sec: 65855.60
Iteration:   2960, Loss function: 3.989, Average Loss: 4.234, avg. samples / sec: 65989.68
Iteration:   2960, Loss function: 3.948, Average Loss: 4.227, avg. samples / sec: 66023.44
Iteration:   2960, Loss function: 4.066, Average Loss: 4.205, avg. samples / sec: 66005.01
Iteration:   2960, Loss function: 4.627, Average Loss: 4.213, avg. samples / sec: 65984.95
Iteration:   2960, Loss function: 4.073, Average Loss: 4.198, avg. samples / sec: 65989.15
Iteration:   2960, Loss function: 4.331, Average Loss: 4.204, avg. samples / sec: 65949.07
Iteration:   2960, Loss function: 2.597, Average Loss: 4.214, avg. samples / sec: 65912.37
Iteration:   2960, Loss function: 3.709, Average Loss: 4.223, avg. samples / sec: 65998.42
Iteration:   2980, Loss function: 4.952, Average Loss: 4.212, avg. samples / sec: 66251.72
Iteration:   2980, Loss function: 3.042, Average Loss: 4.189, avg. samples / sec: 65945.03
Iteration:   2980, Loss function: 4.009, Average Loss: 4.208, avg. samples / sec: 66170.69
Iteration:   2980, Loss function: 4.300, Average Loss: 4.223, avg. samples / sec: 66123.81
Iteration:   2980, Loss function: 4.406, Average Loss: 4.217, avg. samples / sec: 66057.11
Iteration:   2980, Loss function: 4.079, Average Loss: 4.210, avg. samples / sec: 66185.64
Iteration:   2980, Loss function: 4.195, Average Loss: 4.200, avg. samples / sec: 65969.29
Iteration:   2980, Loss function: 4.044, Average Loss: 4.202, avg. samples / sec: 65904.01
Iteration:   2980, Loss function: 3.502, Average Loss: 4.235, avg. samples / sec: 66043.55
Iteration:   2980, Loss function: 3.275, Average Loss: 4.202, avg. samples / sec: 66054.88
Iteration:   2980, Loss function: 3.758, Average Loss: 4.230, avg. samples / sec: 66131.72
Iteration:   2980, Loss function: 3.927, Average Loss: 4.194, avg. samples / sec: 66049.71
Iteration:   2980, Loss function: 4.078, Average Loss: 4.223, avg. samples / sec: 66144.79
Iteration:   2980, Loss function: 4.891, Average Loss: 4.217, avg. samples / sec: 66134.51
Iteration:   2980, Loss function: 3.683, Average Loss: 4.198, avg. samples / sec: 66208.93
Iteration:   2980, Loss function: 4.242, Average Loss: 4.230, avg. samples / sec: 66119.65
Iteration:   2980, Loss function: 3.654, Average Loss: 4.230, avg. samples / sec: 66034.45
Iteration:   2980, Loss function: 4.303, Average Loss: 4.223, avg. samples / sec: 66052.09
Iteration:   2980, Loss function: 4.636, Average Loss: 4.223, avg. samples / sec: 66130.63
Iteration:   2980, Loss function: 2.850, Average Loss: 4.232, avg. samples / sec: 66002.60
Iteration:   2980, Loss function: 2.462, Average Loss: 4.209, avg. samples / sec: 66182.13
Iteration:   2980, Loss function: 3.601, Average Loss: 4.202, avg. samples / sec: 66073.15
Iteration:   2980, Loss function: 3.354, Average Loss: 4.198, avg. samples / sec: 66012.06
Iteration:   2980, Loss function: 3.814, Average Loss: 4.197, avg. samples / sec: 66111.00
Iteration:   2980, Loss function: 3.456, Average Loss: 4.231, avg. samples / sec: 65925.10
Iteration:   2980, Loss function: 4.035, Average Loss: 4.188, avg. samples / sec: 65959.57
Iteration:   2980, Loss function: 4.206, Average Loss: 4.196, avg. samples / sec: 66000.68
Iteration:   2980, Loss function: 3.650, Average Loss: 4.196, avg. samples / sec: 65976.43
Iteration:   2980, Loss function: 4.727, Average Loss: 4.223, avg. samples / sec: 66050.79
Iteration:   2980, Loss function: 3.940, Average Loss: 4.231, avg. samples / sec: 65865.08
Iteration:   3000, Loss function: 4.587, Average Loss: 4.218, avg. samples / sec: 66231.77
Iteration:   3000, Loss function: 3.921, Average Loss: 4.231, avg. samples / sec: 66262.69
Iteration:   3000, Loss function: 3.945, Average Loss: 4.197, avg. samples / sec: 66259.98
Iteration:   3000, Loss function: 3.288, Average Loss: 4.183, avg. samples / sec: 66192.45
Iteration:   3000, Loss function: 4.329, Average Loss: 4.190, avg. samples / sec: 66375.57
Iteration:   3000, Loss function: 4.589, Average Loss: 4.209, avg. samples / sec: 66248.11
Iteration:   3000, Loss function: 4.491, Average Loss: 4.217, avg. samples / sec: 66207.84
Iteration:   3000, Loss function: 4.752, Average Loss: 4.196, avg. samples / sec: 66294.98
Iteration:   3000, Loss function: 4.162, Average Loss: 4.196, avg. samples / sec: 66170.47
Iteration:   3000, Loss function: 3.662, Average Loss: 4.211, avg. samples / sec: 66153.23
Iteration:   3000, Loss function: 3.646, Average Loss: 4.219, avg. samples / sec: 66208.12
Iteration:   3000, Loss function: 4.807, Average Loss: 4.226, avg. samples / sec: 66205.85
Iteration:   3000, Loss function: 4.267, Average Loss: 4.199, avg. samples / sec: 66096.36
Iteration:   3000, Loss function: 3.292, Average Loss: 4.214, avg. samples / sec: 66209.49
Iteration:   3000, Loss function: 3.436, Average Loss: 4.227, avg. samples / sec: 66154.10
Iteration:   3000, Loss function: 3.787, Average Loss: 4.205, avg. samples / sec: 66092.52
Iteration:   3000, Loss function: 3.481, Average Loss: 4.196, avg. samples / sec: 66226.10
Iteration:   3000, Loss function: 3.997, Average Loss: 4.226, avg. samples / sec: 66238.05
Iteration:   3000, Loss function: 4.409, Average Loss: 4.221, avg. samples / sec: 66119.28
Iteration:   3000, Loss function: 2.664, Average Loss: 4.194, avg. samples / sec: 66101.63
Iteration:   3000, Loss function: 4.637, Average Loss: 4.203, avg. samples / sec: 66139.95
Iteration:   3000, Loss function: 4.082, Average Loss: 4.194, avg. samples / sec: 66234.66
Iteration:   3000, Loss function: 3.772, Average Loss: 4.194, avg. samples / sec: 66195.49
Iteration:   3000, Loss function: 4.022, Average Loss: 4.193, avg. samples / sec: 66086.54
Iteration:   3000, Loss function: 3.082, Average Loss: 4.221, avg. samples / sec: 66078.45
Iteration:   3000, Loss function: 3.389, Average Loss: 4.184, avg. samples / sec: 66202.77
Iteration:   3000, Loss function: 3.047, Average Loss: 4.220, avg. samples / sec: 66279.17
Iteration:   3000, Loss function: 2.875, Average Loss: 4.215, avg. samples / sec: 66210.36
Iteration:   3000, Loss function: 3.815, Average Loss: 4.206, avg. samples / sec: 65974.33
Iteration:   3000, Loss function: 4.434, Average Loss: 4.198, avg. samples / sec: 65981.34
:::MLL 1558651270.387 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1558651270.387 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   3020, Loss function: 4.481, Average Loss: 4.212, avg. samples / sec: 65773.04
Iteration:   3020, Loss function: 3.617, Average Loss: 4.190, avg. samples / sec: 65734.24
Iteration:   3020, Loss function: 3.369, Average Loss: 4.222, avg. samples / sec: 65731.81
Iteration:   3020, Loss function: 3.929, Average Loss: 4.177, avg. samples / sec: 65739.97
Iteration:   3020, Loss function: 5.295, Average Loss: 4.212, avg. samples / sec: 65751.07
Iteration:   3020, Loss function: 5.517, Average Loss: 4.218, avg. samples / sec: 65726.97
Iteration:   3020, Loss function: 4.397, Average Loss: 4.191, avg. samples / sec: 65719.61
Iteration:   3020, Loss function: 4.040, Average Loss: 4.196, avg. samples / sec: 65813.99
Iteration:   3020, Loss function: 4.934, Average Loss: 4.182, avg. samples / sec: 65823.43
Iteration:   3020, Loss function: 5.504, Average Loss: 4.203, avg. samples / sec: 65781.03
Iteration:   3020, Loss function: 3.191, Average Loss: 4.209, avg. samples / sec: 65712.50
Iteration:   3020, Loss function: 4.687, Average Loss: 4.192, avg. samples / sec: 65698.44
Iteration:   3020, Loss function: 3.189, Average Loss: 4.216, avg. samples / sec: 65811.13
Iteration:   3020, Loss function: 3.937, Average Loss: 4.225, avg. samples / sec: 65750.03
Iteration:   3020, Loss function: 4.146, Average Loss: 4.199, avg. samples / sec: 65645.96
Iteration:   3020, Loss function: 3.837, Average Loss: 4.213, avg. samples / sec: 65779.00
Iteration:   3020, Loss function: 4.218, Average Loss: 4.224, avg. samples / sec: 65709.87
Iteration:   3020, Loss function: 3.156, Average Loss: 4.194, avg. samples / sec: 65868.19
Iteration:   3020, Loss function: 3.268, Average Loss: 4.200, avg. samples / sec: 65701.84
Iteration:   3020, Loss function: 4.450, Average Loss: 4.196, avg. samples / sec: 65711.25
Iteration:   3020, Loss function: 3.541, Average Loss: 4.189, avg. samples / sec: 65712.14
Iteration:   3020, Loss function: 4.662, Average Loss: 4.187, avg. samples / sec: 65559.78
Iteration:   3020, Loss function: 4.037, Average Loss: 4.211, avg. samples / sec: 65621.96
Iteration:   3020, Loss function: 4.988, Average Loss: 4.218, avg. samples / sec: 65624.68
Iteration:   3020, Loss function: 4.191, Average Loss: 4.223, avg. samples / sec: 65655.62
Iteration:   3020, Loss function: 4.153, Average Loss: 4.204, avg. samples / sec: 65695.47
Iteration:   3020, Loss function: 3.393, Average Loss: 4.212, avg. samples / sec: 65705.18
Iteration:   3020, Loss function: 3.863, Average Loss: 4.187, avg. samples / sec: 65630.89
Iteration:   3020, Loss function: 3.834, Average Loss: 4.190, avg. samples / sec: 65645.29
Iteration:   3020, Loss function: 4.630, Average Loss: 4.206, avg. samples / sec: 65446.77
Iteration:   3040, Loss function: 3.684, Average Loss: 4.186, avg. samples / sec: 66232.98
Iteration:   3040, Loss function: 4.729, Average Loss: 4.185, avg. samples / sec: 66292.89
Iteration:   3040, Loss function: 4.979, Average Loss: 4.204, avg. samples / sec: 66352.88
Iteration:   3040, Loss function: 3.924, Average Loss: 4.182, avg. samples / sec: 66075.94
Iteration:   3040, Loss function: 3.590, Average Loss: 4.172, avg. samples / sec: 66062.90
Iteration:   3040, Loss function: 3.874, Average Loss: 4.214, avg. samples / sec: 66052.81
Iteration:   3040, Loss function: 3.367, Average Loss: 4.192, avg. samples / sec: 66219.38
Iteration:   3040, Loss function: 3.893, Average Loss: 4.217, avg. samples / sec: 66183.31
Iteration:   3040, Loss function: 4.232, Average Loss: 4.216, avg. samples / sec: 66104.21
Iteration:   3040, Loss function: 3.293, Average Loss: 4.196, avg. samples / sec: 66152.33
Iteration:   3040, Loss function: 3.992, Average Loss: 4.212, avg. samples / sec: 66117.36
Iteration:   3040, Loss function: 4.773, Average Loss: 4.217, avg. samples / sec: 66030.71
Iteration:   3040, Loss function: 4.663, Average Loss: 4.212, avg. samples / sec: 65906.85
Iteration:   3040, Loss function: 3.816, Average Loss: 4.200, avg. samples / sec: 66298.29
Iteration:   3040, Loss function: 4.681, Average Loss: 4.211, avg. samples / sec: 66175.75
Iteration:   3040, Loss function: 4.216, Average Loss: 4.201, avg. samples / sec: 66106.53
Iteration:   3040, Loss function: 3.466, Average Loss: 4.191, avg. samples / sec: 66075.13
Iteration:   3040, Loss function: 3.944, Average Loss: 4.211, avg. samples / sec: 66120.18
Iteration:   3040, Loss function: 3.046, Average Loss: 4.187, avg. samples / sec: 66239.14
Iteration:   3040, Loss function: 3.109, Average Loss: 4.221, avg. samples / sec: 66098.32
Iteration:   3040, Loss function: 4.370, Average Loss: 4.178, avg. samples / sec: 66049.31
Iteration:   3040, Loss function: 3.393, Average Loss: 4.196, avg. samples / sec: 66117.67
Iteration:   3040, Loss function: 3.880, Average Loss: 4.210, avg. samples / sec: 66153.73
Iteration:   3040, Loss function: 3.842, Average Loss: 4.181, avg. samples / sec: 66219.85
Iteration:   3040, Loss function: 4.268, Average Loss: 4.195, avg. samples / sec: 66109.88
Iteration:   3040, Loss function: 4.178, Average Loss: 4.207, avg. samples / sec: 66011.66
Iteration:   3040, Loss function: 3.829, Average Loss: 4.208, avg. samples / sec: 66107.74
Iteration:   3040, Loss function: 3.483, Average Loss: 4.191, avg. samples / sec: 65930.28
Iteration:   3040, Loss function: 4.222, Average Loss: 4.183, avg. samples / sec: 65942.07
Iteration:   3040, Loss function: 4.212, Average Loss: 4.220, avg. samples / sec: 65642.60
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
lr decay step #1
:::MLL 1558651271.368 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.45s)
DONE (t=0.45s)
DONE (t=0.46s)
DONE (t=0.45s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.46s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.47s)
DONE (t=0.48s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.54s)
DONE (t=2.63s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.16986
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31541
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.16442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04397
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18100
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.26290
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.17959
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.26371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27892
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07776
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30266
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.41954
Current AP: 0.16986 AP goal: 0.23000
:::MLL 1558651275.101 eval_accuracy: {"value": 0.16985799719901618, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1558651275.417 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1558651275.424 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1558651275.424 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3060, Loss function: 3.512, Average Loss: 4.208, avg. samples / sec: 7343.62
Iteration:   3060, Loss function: 3.683, Average Loss: 4.166, avg. samples / sec: 7343.66
Iteration:   3060, Loss function: 2.458, Average Loss: 4.179, avg. samples / sec: 7342.41
Iteration:   3060, Loss function: 4.313, Average Loss: 4.194, avg. samples / sec: 7344.78
Iteration:   3060, Loss function: 3.663, Average Loss: 4.179, avg. samples / sec: 7342.76
Iteration:   3060, Loss function: 3.756, Average Loss: 4.212, avg. samples / sec: 7344.02
Iteration:   3060, Loss function: 4.386, Average Loss: 4.177, avg. samples / sec: 7342.61
Iteration:   3060, Loss function: 4.410, Average Loss: 4.203, avg. samples / sec: 7343.31
Iteration:   3060, Loss function: 3.938, Average Loss: 4.214, avg. samples / sec: 7342.55
Iteration:   3060, Loss function: 3.209, Average Loss: 4.185, avg. samples / sec: 7343.26
Iteration:   3060, Loss function: 3.362, Average Loss: 4.213, avg. samples / sec: 7350.16
Iteration:   3060, Loss function: 3.071, Average Loss: 4.194, avg. samples / sec: 7341.73
Iteration:   3060, Loss function: 4.269, Average Loss: 4.212, avg. samples / sec: 7342.56
Iteration:   3060, Loss function: 3.189, Average Loss: 4.198, avg. samples / sec: 7342.99
Iteration:   3060, Loss function: 3.757, Average Loss: 4.195, avg. samples / sec: 7342.79
Iteration:   3060, Loss function: 4.472, Average Loss: 4.189, avg. samples / sec: 7345.21
Iteration:   3060, Loss function: 4.494, Average Loss: 4.210, avg. samples / sec: 7342.98
Iteration:   3060, Loss function: 3.961, Average Loss: 4.198, avg. samples / sec: 7343.67
Iteration:   3060, Loss function: 3.546, Average Loss: 4.203, avg. samples / sec: 7343.00
Iteration:   3060, Loss function: 3.945, Average Loss: 4.186, avg. samples / sec: 7342.92
Iteration:   3060, Loss function: 5.340, Average Loss: 4.193, avg. samples / sec: 7341.27
Iteration:   3060, Loss function: 4.537, Average Loss: 4.204, avg. samples / sec: 7343.97
Iteration:   3060, Loss function: 3.731, Average Loss: 4.206, avg. samples / sec: 7341.81
Iteration:   3060, Loss function: 3.678, Average Loss: 4.210, avg. samples / sec: 7342.59
Iteration:   3060, Loss function: 4.562, Average Loss: 4.179, avg. samples / sec: 7344.51
Iteration:   3060, Loss function: 3.781, Average Loss: 4.178, avg. samples / sec: 7341.85
Iteration:   3060, Loss function: 3.292, Average Loss: 4.175, avg. samples / sec: 7341.70
Iteration:   3060, Loss function: 4.829, Average Loss: 4.189, avg. samples / sec: 7340.88
Iteration:   3060, Loss function: 4.225, Average Loss: 4.209, avg. samples / sec: 7341.02
Iteration:   3060, Loss function: 3.213, Average Loss: 4.168, avg. samples / sec: 7341.33
:::MLL 1558651276.239 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1558651276.240 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   3080, Loss function: 4.259, Average Loss: 4.202, avg. samples / sec: 65599.27
Iteration:   3080, Loss function: 4.372, Average Loss: 4.185, avg. samples / sec: 65656.27
Iteration:   3080, Loss function: 3.383, Average Loss: 4.193, avg. samples / sec: 65795.18
Iteration:   3080, Loss function: 3.279, Average Loss: 4.201, avg. samples / sec: 65623.58
Iteration:   3080, Loss function: 3.545, Average Loss: 4.188, avg. samples / sec: 65607.30
Iteration:   3080, Loss function: 3.584, Average Loss: 4.166, avg. samples / sec: 65705.73
Iteration:   3080, Loss function: 3.171, Average Loss: 4.191, avg. samples / sec: 65557.13
Iteration:   3080, Loss function: 3.699, Average Loss: 4.176, avg. samples / sec: 65600.37
Iteration:   3080, Loss function: 2.878, Average Loss: 4.203, avg. samples / sec: 65516.41
Iteration:   3080, Loss function: 3.368, Average Loss: 4.171, avg. samples / sec: 65414.72
Iteration:   3080, Loss function: 3.230, Average Loss: 4.185, avg. samples / sec: 65410.59
Iteration:   3080, Loss function: 3.796, Average Loss: 4.187, avg. samples / sec: 65511.45
Iteration:   3080, Loss function: 3.330, Average Loss: 4.174, avg. samples / sec: 65563.04
Iteration:   3080, Loss function: 3.338, Average Loss: 4.154, avg. samples / sec: 65380.15
Iteration:   3080, Loss function: 3.696, Average Loss: 4.168, avg. samples / sec: 65420.06
Iteration:   3080, Loss function: 3.219, Average Loss: 4.167, avg. samples / sec: 65598.54
Iteration:   3080, Loss function: 4.476, Average Loss: 4.170, avg. samples / sec: 65453.60
Iteration:   3080, Loss function: 2.829, Average Loss: 4.189, avg. samples / sec: 65530.09
Iteration:   3080, Loss function: 3.227, Average Loss: 4.196, avg. samples / sec: 65376.69
Iteration:   3080, Loss function: 2.764, Average Loss: 4.196, avg. samples / sec: 65555.18
Iteration:   3080, Loss function: 2.524, Average Loss: 4.199, avg. samples / sec: 65465.31
Iteration:   3080, Loss function: 3.772, Average Loss: 4.193, avg. samples / sec: 65508.43
Iteration:   3080, Loss function: 5.561, Average Loss: 4.192, avg. samples / sec: 65475.23
Iteration:   3080, Loss function: 3.731, Average Loss: 4.193, avg. samples / sec: 65454.58
Iteration:   3080, Loss function: 3.873, Average Loss: 4.174, avg. samples / sec: 65399.30
Iteration:   3080, Loss function: 2.807, Average Loss: 4.163, avg. samples / sec: 65503.68
Iteration:   3080, Loss function: 4.827, Average Loss: 4.203, avg. samples / sec: 65316.85
Iteration:   3080, Loss function: 2.993, Average Loss: 4.182, avg. samples / sec: 65462.63
Iteration:   3080, Loss function: 4.147, Average Loss: 4.186, avg. samples / sec: 65378.03
Iteration:   3080, Loss function: 2.755, Average Loss: 4.159, avg. samples / sec: 65463.43
Iteration:   3100, Loss function: 3.528, Average Loss: 4.162, avg. samples / sec: 66275.34
Iteration:   3100, Loss function: 3.866, Average Loss: 4.153, avg. samples / sec: 66423.59
Iteration:   3100, Loss function: 3.516, Average Loss: 4.144, avg. samples / sec: 66262.60
Iteration:   3100, Loss function: 3.653, Average Loss: 4.184, avg. samples / sec: 66268.27
Iteration:   3100, Loss function: 3.393, Average Loss: 4.187, avg. samples / sec: 66284.72
Iteration:   3100, Loss function: 5.196, Average Loss: 4.182, avg. samples / sec: 66134.79
Iteration:   3100, Loss function: 4.294, Average Loss: 4.196, avg. samples / sec: 66183.52
Iteration:   3100, Loss function: 2.490, Average Loss: 4.153, avg. samples / sec: 66197.08
Iteration:   3100, Loss function: 3.348, Average Loss: 4.180, avg. samples / sec: 66061.29
Iteration:   3100, Loss function: 4.418, Average Loss: 4.152, avg. samples / sec: 66121.70
Iteration:   3100, Loss function: 2.748, Average Loss: 4.178, avg. samples / sec: 66178.92
Iteration:   3100, Loss function: 2.760, Average Loss: 4.188, avg. samples / sec: 66021.52
Iteration:   3100, Loss function: 3.232, Average Loss: 4.177, avg. samples / sec: 66388.30
Iteration:   3100, Loss function: 4.151, Average Loss: 4.169, avg. samples / sec: 66265.96
Iteration:   3100, Loss function: 3.828, Average Loss: 4.176, avg. samples / sec: 66145.91
Iteration:   3100, Loss function: 3.343, Average Loss: 4.156, avg. samples / sec: 66152.71
Iteration:   3100, Loss function: 2.846, Average Loss: 4.175, avg. samples / sec: 66147.92
Iteration:   3100, Loss function: 3.964, Average Loss: 4.154, avg. samples / sec: 66131.91
Iteration:   3100, Loss function: 2.687, Average Loss: 4.180, avg. samples / sec: 66192.91
Iteration:   3100, Loss function: 2.539, Average Loss: 4.167, avg. samples / sec: 66096.08
Iteration:   3100, Loss function: 3.606, Average Loss: 4.189, avg. samples / sec: 66004.51
Iteration:   3100, Loss function: 3.150, Average Loss: 4.184, avg. samples / sec: 66155.62
Iteration:   3100, Loss function: 5.021, Average Loss: 4.178, avg. samples / sec: 65985.72
Iteration:   3100, Loss function: 3.686, Average Loss: 4.187, avg. samples / sec: 66089.08
Iteration:   3100, Loss function: 2.818, Average Loss: 4.165, avg. samples / sec: 66269.39
Iteration:   3100, Loss function: 3.424, Average Loss: 4.193, avg. samples / sec: 66240.23
Iteration:   3100, Loss function: 4.800, Average Loss: 4.145, avg. samples / sec: 66275.87
Iteration:   3100, Loss function: 3.555, Average Loss: 4.175, avg. samples / sec: 65883.22
Iteration:   3100, Loss function: 4.369, Average Loss: 4.181, avg. samples / sec: 66115.31
Iteration:   3100, Loss function: 2.626, Average Loss: 4.163, avg. samples / sec: 65901.92
Iteration:   3120, Loss function: 5.855, Average Loss: 4.178, avg. samples / sec: 66069.40
Iteration:   3120, Loss function: 3.686, Average Loss: 4.133, avg. samples / sec: 65976.67
Iteration:   3120, Loss function: 3.492, Average Loss: 4.150, avg. samples / sec: 65932.44
Iteration:   3120, Loss function: 3.033, Average Loss: 4.172, avg. samples / sec: 66037.61
Iteration:   3120, Loss function: 3.250, Average Loss: 4.170, avg. samples / sec: 66146.00
Iteration:   3120, Loss function: 3.018, Average Loss: 4.165, avg. samples / sec: 66010.82
Iteration:   3120, Loss function: 3.028, Average Loss: 4.158, avg. samples / sec: 66151.65
Iteration:   3120, Loss function: 3.381, Average Loss: 4.157, avg. samples / sec: 66014.01
Iteration:   3120, Loss function: 2.542, Average Loss: 4.132, avg. samples / sec: 66050.02
Iteration:   3120, Loss function: 4.170, Average Loss: 4.174, avg. samples / sec: 66062.68
Iteration:   3120, Loss function: 3.398, Average Loss: 4.139, avg. samples / sec: 66088.74
Iteration:   3120, Loss function: 3.948, Average Loss: 4.140, avg. samples / sec: 65987.18
Iteration:   3120, Loss function: 3.130, Average Loss: 4.140, avg. samples / sec: 65853.32
Iteration:   3120, Loss function: 2.901, Average Loss: 4.168, avg. samples / sec: 66021.71
Iteration:   3120, Loss function: 4.791, Average Loss: 4.161, avg. samples / sec: 65955.34
Iteration:   3120, Loss function: 3.979, Average Loss: 4.173, avg. samples / sec: 65903.24
Iteration:   3120, Loss function: 5.036, Average Loss: 4.149, avg. samples / sec: 66128.40
Iteration:   3120, Loss function: 3.579, Average Loss: 4.163, avg. samples / sec: 65950.61
Iteration:   3120, Loss function: 3.523, Average Loss: 4.155, avg. samples / sec: 66015.68
Iteration:   3120, Loss function: 3.465, Average Loss: 4.166, avg. samples / sec: 66027.06
Iteration:   3120, Loss function: 2.908, Average Loss: 4.172, avg. samples / sec: 65841.17
Iteration:   3120, Loss function: 2.936, Average Loss: 4.153, avg. samples / sec: 66029.41
Iteration:   3120, Loss function: 3.221, Average Loss: 4.188, avg. samples / sec: 65858.37
Iteration:   3120, Loss function: 3.779, Average Loss: 4.139, avg. samples / sec: 65864.53
Iteration:   3120, Loss function: 4.111, Average Loss: 4.163, avg. samples / sec: 66046.92
Iteration:   3120, Loss function: 2.771, Average Loss: 4.178, avg. samples / sec: 65974.39
Iteration:   3120, Loss function: 3.384, Average Loss: 4.164, avg. samples / sec: 65856.22
Iteration:   3120, Loss function: 3.758, Average Loss: 4.175, avg. samples / sec: 65936.57
Iteration:   3120, Loss function: 2.806, Average Loss: 4.140, avg. samples / sec: 65794.23
Iteration:   3120, Loss function: 4.541, Average Loss: 4.177, avg. samples / sec: 65770.16
Iteration:   3140, Loss function: 3.042, Average Loss: 4.163, avg. samples / sec: 65714.71
Iteration:   3140, Loss function: 3.866, Average Loss: 4.137, avg. samples / sec: 65721.05
Iteration:   3140, Loss function: 2.721, Average Loss: 4.150, avg. samples / sec: 65716.12
Iteration:   3140, Loss function: 3.421, Average Loss: 4.149, avg. samples / sec: 65723.90
Iteration:   3140, Loss function: 3.598, Average Loss: 4.163, avg. samples / sec: 65558.04
Iteration:   3140, Loss function: 2.682, Average Loss: 4.124, avg. samples / sec: 65674.07
Iteration:   3140, Loss function: 3.687, Average Loss: 4.128, avg. samples / sec: 65643.27
Iteration:   3140, Loss function: 2.505, Average Loss: 4.149, avg. samples / sec: 65593.56
Iteration:   3140, Loss function: 4.379, Average Loss: 4.135, avg. samples / sec: 65520.16
Iteration:   3140, Loss function: 4.428, Average Loss: 4.165, avg. samples / sec: 65715.57
Iteration:   3140, Loss function: 4.858, Average Loss: 4.153, avg. samples / sec: 65692.90
Iteration:   3140, Loss function: 3.933, Average Loss: 4.149, avg. samples / sec: 65709.16
Iteration:   3140, Loss function: 3.315, Average Loss: 4.181, avg. samples / sec: 65636.24
Iteration:   3140, Loss function: 4.191, Average Loss: 4.159, avg. samples / sec: 65627.89
Iteration:   3140, Loss function: 4.997, Average Loss: 4.125, avg. samples / sec: 65480.12
Iteration:   3140, Loss function: 3.282, Average Loss: 4.120, avg. samples / sec: 65528.20
Iteration:   3140, Loss function: 3.439, Average Loss: 4.161, avg. samples / sec: 65520.61
Iteration:   3140, Loss function: 3.017, Average Loss: 4.153, avg. samples / sec: 65556.24
Iteration:   3140, Loss function: 3.038, Average Loss: 4.157, avg. samples / sec: 65449.59
Iteration:   3140, Loss function: 3.175, Average Loss: 4.159, avg. samples / sec: 65452.12
Iteration:   3140, Loss function: 3.836, Average Loss: 4.124, avg. samples / sec: 65603.42
Iteration:   3140, Loss function: 2.167, Average Loss: 4.170, avg. samples / sec: 65615.91
Iteration:   3140, Loss function: 3.539, Average Loss: 4.147, avg. samples / sec: 65480.25
Iteration:   3140, Loss function: 4.348, Average Loss: 4.144, avg. samples / sec: 65551.70
Iteration:   3140, Loss function: 4.491, Average Loss: 4.167, avg. samples / sec: 65648.74
Iteration:   3140, Loss function: 2.741, Average Loss: 4.148, avg. samples / sec: 65487.15
Iteration:   3140, Loss function: 3.523, Average Loss: 4.145, avg. samples / sec: 65444.24
Iteration:   3140, Loss function: 3.380, Average Loss: 4.128, avg. samples / sec: 65463.58
Iteration:   3140, Loss function: 3.576, Average Loss: 4.142, avg. samples / sec: 65462.42
Iteration:   3140, Loss function: 3.246, Average Loss: 4.128, avg. samples / sec: 65573.60
:::MLL 1558651278.028 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1558651278.028 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   3160, Loss function: 3.894, Average Loss: 4.126, avg. samples / sec: 65383.67
Iteration:   3160, Loss function: 3.266, Average Loss: 4.145, avg. samples / sec: 65453.82
Iteration:   3160, Loss function: 2.976, Average Loss: 4.138, avg. samples / sec: 65464.03
Iteration:   3160, Loss function: 4.930, Average Loss: 4.155, avg. samples / sec: 65310.46
Iteration:   3160, Loss function: 2.748, Average Loss: 4.145, avg. samples / sec: 65381.70
Iteration:   3160, Loss function: 3.185, Average Loss: 4.118, avg. samples / sec: 65279.18
Iteration:   3160, Loss function: 3.466, Average Loss: 4.112, avg. samples / sec: 65278.03
Iteration:   3160, Loss function: 3.033, Average Loss: 4.136, avg. samples / sec: 65247.18
Iteration:   3160, Loss function: 2.290, Average Loss: 4.111, avg. samples / sec: 65410.01
Iteration:   3160, Loss function: 3.122, Average Loss: 4.176, avg. samples / sec: 65341.99
Iteration:   3160, Loss function: 4.696, Average Loss: 4.153, avg. samples / sec: 65421.94
Iteration:   3160, Loss function: 2.996, Average Loss: 4.144, avg. samples / sec: 65372.93
Iteration:   3160, Loss function: 3.514, Average Loss: 4.138, avg. samples / sec: 65286.53
Iteration:   3160, Loss function: 2.931, Average Loss: 4.147, avg. samples / sec: 65213.33
Iteration:   3160, Loss function: 3.364, Average Loss: 4.115, avg. samples / sec: 65319.94
Iteration:   3160, Loss function: 3.563, Average Loss: 4.110, avg. samples / sec: 65332.75
Iteration:   3160, Loss function: 2.582, Average Loss: 4.113, avg. samples / sec: 65232.38
Iteration:   3160, Loss function: 3.504, Average Loss: 4.126, avg. samples / sec: 65392.07
Iteration:   3160, Loss function: 4.271, Average Loss: 4.150, avg. samples / sec: 65322.72
Iteration:   3160, Loss function: 4.656, Average Loss: 4.139, avg. samples / sec: 65270.05
Iteration:   3160, Loss function: 3.567, Average Loss: 4.142, avg. samples / sec: 65365.05
Iteration:   3160, Loss function: 3.789, Average Loss: 4.131, avg. samples / sec: 65345.20
Iteration:   3160, Loss function: 3.809, Average Loss: 4.122, avg. samples / sec: 65351.56
Iteration:   3160, Loss function: 4.251, Average Loss: 4.152, avg. samples / sec: 65186.79
Iteration:   3160, Loss function: 4.174, Average Loss: 4.158, avg. samples / sec: 65284.26
Iteration:   3160, Loss function: 3.239, Average Loss: 4.138, avg. samples / sec: 65231.32
Iteration:   3160, Loss function: 4.258, Average Loss: 4.132, avg. samples / sec: 65098.44
Iteration:   3160, Loss function: 4.950, Average Loss: 4.119, avg. samples / sec: 65356.29
Iteration:   3160, Loss function: 3.242, Average Loss: 4.140, avg. samples / sec: 65145.47
Iteration:   3160, Loss function: 3.463, Average Loss: 4.129, avg. samples / sec: 65273.89
Iteration:   3180, Loss function: 4.297, Average Loss: 4.135, avg. samples / sec: 65259.93
Iteration:   3180, Loss function: 3.713, Average Loss: 4.129, avg. samples / sec: 65245.45
Iteration:   3180, Loss function: 5.006, Average Loss: 4.114, avg. samples / sec: 65179.43
Iteration:   3180, Loss function: 3.936, Average Loss: 4.105, avg. samples / sec: 65244.12
Iteration:   3180, Loss function: 3.852, Average Loss: 4.126, avg. samples / sec: 65255.24
Iteration:   3180, Loss function: 3.595, Average Loss: 4.133, avg. samples / sec: 65195.44
Iteration:   3180, Loss function: 4.790, Average Loss: 4.121, avg. samples / sec: 65323.03
Iteration:   3180, Loss function: 3.078, Average Loss: 4.123, avg. samples / sec: 65238.33
Iteration:   3180, Loss function: 4.875, Average Loss: 4.138, avg. samples / sec: 65182.02
Iteration:   3180, Loss function: 5.440, Average Loss: 4.111, avg. samples / sec: 65291.91
Iteration:   3180, Loss function: 3.511, Average Loss: 4.144, avg. samples / sec: 65081.45
Iteration:   3180, Loss function: 3.109, Average Loss: 4.130, avg. samples / sec: 65266.24
Iteration:   3180, Loss function: 3.836, Average Loss: 4.101, avg. samples / sec: 65191.43
Iteration:   3180, Loss function: 2.780, Average Loss: 4.099, avg. samples / sec: 65151.77
Iteration:   3180, Loss function: 2.123, Average Loss: 4.122, avg. samples / sec: 65067.87
Iteration:   3180, Loss function: 4.187, Average Loss: 4.123, avg. samples / sec: 65133.07
Iteration:   3180, Loss function: 3.594, Average Loss: 4.163, avg. samples / sec: 65122.77
Iteration:   3180, Loss function: 4.068, Average Loss: 4.122, avg. samples / sec: 65177.50
Iteration:   3180, Loss function: 4.208, Average Loss: 4.103, avg. samples / sec: 65054.53
Iteration:   3180, Loss function: 3.517, Average Loss: 4.130, avg. samples / sec: 65249.26
Iteration:   3180, Loss function: 3.005, Average Loss: 4.137, avg. samples / sec: 65143.49
Iteration:   3180, Loss function: 4.989, Average Loss: 4.119, avg. samples / sec: 65144.21
Iteration:   3180, Loss function: 3.676, Average Loss: 4.140, avg. samples / sec: 65177.50
Iteration:   3180, Loss function: 6.559, Average Loss: 4.113, avg. samples / sec: 65130.21
Iteration:   3180, Loss function: 3.160, Average Loss: 4.139, avg. samples / sec: 65160.71
Iteration:   3180, Loss function: 3.678, Average Loss: 4.100, avg. samples / sec: 65014.74
Iteration:   3180, Loss function: 3.591, Average Loss: 4.140, avg. samples / sec: 65022.78
Iteration:   3180, Loss function: 3.826, Average Loss: 4.125, avg. samples / sec: 64977.90
Iteration:   3180, Loss function: 4.127, Average Loss: 4.121, avg. samples / sec: 65176.60
Iteration:   3180, Loss function: 3.257, Average Loss: 4.102, avg. samples / sec: 64971.25
Iteration:   3200, Loss function: 3.665, Average Loss: 4.118, avg. samples / sec: 65791.65
Iteration:   3200, Loss function: 3.202, Average Loss: 4.117, avg. samples / sec: 65834.16
Iteration:   3200, Loss function: 3.982, Average Loss: 4.092, avg. samples / sec: 65857.11
Iteration:   3200, Loss function: 2.396, Average Loss: 4.094, avg. samples / sec: 65786.98
Iteration:   3200, Loss function: 2.378, Average Loss: 4.100, avg. samples / sec: 65808.64
Iteration:   3200, Loss function: 3.708, Average Loss: 4.121, avg. samples / sec: 65823.92
Iteration:   3200, Loss function: 3.998, Average Loss: 4.085, avg. samples / sec: 65817.46
Iteration:   3200, Loss function: 4.314, Average Loss: 4.114, avg. samples / sec: 65758.68
Iteration:   3200, Loss function: 3.824, Average Loss: 4.111, avg. samples / sec: 65803.88
Iteration:   3200, Loss function: 2.856, Average Loss: 4.110, avg. samples / sec: 65811.99
Iteration:   3200, Loss function: 2.237, Average Loss: 4.131, avg. samples / sec: 65765.43
Iteration:   3200, Loss function: 3.993, Average Loss: 4.125, avg. samples / sec: 65883.71
Iteration:   3200, Loss function: 4.584, Average Loss: 4.116, avg. samples / sec: 65930.87
Iteration:   3200, Loss function: 3.533, Average Loss: 4.105, avg. samples / sec: 65812.45
Iteration:   3200, Loss function: 3.240, Average Loss: 4.091, avg. samples / sec: 65808.30
Iteration:   3200, Loss function: 3.983, Average Loss: 4.151, avg. samples / sec: 65763.87
Iteration:   3200, Loss function: 4.410, Average Loss: 4.110, avg. samples / sec: 65937.25
Iteration:   3200, Loss function: 3.818, Average Loss: 4.129, avg. samples / sec: 65803.51
Iteration:   3200, Loss function: 3.765, Average Loss: 4.117, avg. samples / sec: 65756.90
Iteration:   3200, Loss function: 4.246, Average Loss: 4.123, avg. samples / sec: 65554.69
Iteration:   3200, Loss function: 3.259, Average Loss: 4.085, avg. samples / sec: 65854.99
Iteration:   3200, Loss function: 2.652, Average Loss: 4.124, avg. samples / sec: 65688.74
Iteration:   3200, Loss function: 3.744, Average Loss: 4.105, avg. samples / sec: 65672.18
Iteration:   3200, Loss function: 3.043, Average Loss: 4.104, avg. samples / sec: 65601.13
Iteration:   3200, Loss function: 2.806, Average Loss: 4.120, avg. samples / sec: 65747.21
Iteration:   3200, Loss function: 3.743, Average Loss: 4.128, avg. samples / sec: 65773.20
Iteration:   3200, Loss function: 2.832, Average Loss: 4.108, avg. samples / sec: 65667.13
Iteration:   3200, Loss function: 3.476, Average Loss: 4.094, avg. samples / sec: 65853.17
Iteration:   3200, Loss function: 3.853, Average Loss: 4.125, avg. samples / sec: 65793.80
Iteration:   3200, Loss function: 4.431, Average Loss: 4.101, avg. samples / sec: 65766.51
:::MLL 1558651279.821 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1558651279.822 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   3220, Loss function: 3.128, Average Loss: 4.108, avg. samples / sec: 65881.28
Iteration:   3220, Loss function: 3.041, Average Loss: 4.077, avg. samples / sec: 65820.04
Iteration:   3220, Loss function: 3.159, Average Loss: 4.118, avg. samples / sec: 65817.43
Iteration:   3220, Loss function: 4.159, Average Loss: 4.080, avg. samples / sec: 65668.69
Iteration:   3220, Loss function: 2.868, Average Loss: 4.071, avg. samples / sec: 65714.31
Iteration:   3220, Loss function: 3.790, Average Loss: 4.113, avg. samples / sec: 65735.68
Iteration:   3220, Loss function: 3.096, Average Loss: 4.116, avg. samples / sec: 65715.78
Iteration:   3220, Loss function: 3.235, Average Loss: 4.107, avg. samples / sec: 65734.60
Iteration:   3220, Loss function: 3.567, Average Loss: 4.095, avg. samples / sec: 65708.06
Iteration:   3220, Loss function: 4.316, Average Loss: 4.137, avg. samples / sec: 65715.42
Iteration:   3220, Loss function: 2.886, Average Loss: 4.085, avg. samples / sec: 65631.68
Iteration:   3220, Loss function: 3.454, Average Loss: 4.106, avg. samples / sec: 65584.52
Iteration:   3220, Loss function: 2.352, Average Loss: 4.085, avg. samples / sec: 65593.35
Iteration:   3220, Loss function: 4.161, Average Loss: 4.102, avg. samples / sec: 65690.24
Iteration:   3220, Loss function: 3.826, Average Loss: 4.109, avg. samples / sec: 65474.47
Iteration:   3220, Loss function: 3.579, Average Loss: 4.097, avg. samples / sec: 65724.70
Iteration:   3220, Loss function: 3.363, Average Loss: 4.102, avg. samples / sec: 65593.96
Iteration:   3220, Loss function: 3.657, Average Loss: 4.111, avg. samples / sec: 65587.09
Iteration:   3220, Loss function: 4.658, Average Loss: 4.097, avg. samples / sec: 65677.62
Iteration:   3220, Loss function: 3.387, Average Loss: 4.110, avg. samples / sec: 65718.02
Iteration:   3220, Loss function: 4.055, Average Loss: 4.102, avg. samples / sec: 65570.64
Iteration:   3220, Loss function: 3.858, Average Loss: 4.073, avg. samples / sec: 65653.91
Iteration:   3220, Loss function: 4.128, Average Loss: 4.115, avg. samples / sec: 65631.62
Iteration:   3220, Loss function: 3.168, Average Loss: 4.083, avg. samples / sec: 65671.41
Iteration:   3220, Loss function: 3.513, Average Loss: 4.099, avg. samples / sec: 65600.73
Iteration:   3220, Loss function: 3.949, Average Loss: 4.097, avg. samples / sec: 65558.59
Iteration:   3220, Loss function: 3.480, Average Loss: 4.091, avg. samples / sec: 65630.64
Iteration:   3220, Loss function: 4.434, Average Loss: 4.108, avg. samples / sec: 65634.01
Iteration:   3220, Loss function: 3.574, Average Loss: 4.110, avg. samples / sec: 65572.87
Iteration:   3220, Loss function: 3.892, Average Loss: 4.092, avg. samples / sec: 65571.92
Iteration:   3240, Loss function: 3.371, Average Loss: 4.102, avg. samples / sec: 66081.70
Iteration:   3240, Loss function: 3.147, Average Loss: 4.069, avg. samples / sec: 66159.91
Iteration:   3240, Loss function: 2.807, Average Loss: 4.096, avg. samples / sec: 66270.57
Iteration:   3240, Loss function: 3.758, Average Loss: 4.094, avg. samples / sec: 66042.65
Iteration:   3240, Loss function: 3.676, Average Loss: 4.069, avg. samples / sec: 65941.45
Iteration:   3240, Loss function: 3.329, Average Loss: 4.093, avg. samples / sec: 65858.74
Iteration:   3240, Loss function: 3.313, Average Loss: 4.095, avg. samples / sec: 65991.75
Iteration:   3240, Loss function: 3.882, Average Loss: 4.090, avg. samples / sec: 66045.56
Iteration:   3240, Loss function: 3.902, Average Loss: 4.093, avg. samples / sec: 66079.38
Iteration:   3240, Loss function: 2.893, Average Loss: 4.092, avg. samples / sec: 66005.75
Iteration:   3240, Loss function: 3.379, Average Loss: 4.091, avg. samples / sec: 66067.08
Iteration:   3240, Loss function: 4.198, Average Loss: 4.056, avg. samples / sec: 65908.42
Iteration:   3240, Loss function: 3.292, Average Loss: 4.081, avg. samples / sec: 66196.83
Iteration:   3240, Loss function: 4.320, Average Loss: 4.073, avg. samples / sec: 65952.81
Iteration:   3240, Loss function: 2.874, Average Loss: 4.099, avg. samples / sec: 66022.67
Iteration:   3240, Loss function: 5.284, Average Loss: 4.067, avg. samples / sec: 65847.35
Iteration:   3240, Loss function: 2.185, Average Loss: 4.077, avg. samples / sec: 65997.34
Iteration:   3240, Loss function: 4.191, Average Loss: 4.065, avg. samples / sec: 66006.83
Iteration:   3240, Loss function: 3.317, Average Loss: 4.084, avg. samples / sec: 65886.88
Iteration:   3240, Loss function: 3.701, Average Loss: 4.104, avg. samples / sec: 65963.83
Iteration:   3240, Loss function: 2.901, Average Loss: 4.088, avg. samples / sec: 65971.55
Iteration:   3240, Loss function: 3.515, Average Loss: 4.080, avg. samples / sec: 65975.10
Iteration:   3240, Loss function: 4.377, Average Loss: 4.101, avg. samples / sec: 65828.56
Iteration:   3240, Loss function: 2.792, Average Loss: 4.103, avg. samples / sec: 65758.99
Iteration:   3240, Loss function: 2.910, Average Loss: 4.092, avg. samples / sec: 65870.13
Iteration:   3240, Loss function: 3.815, Average Loss: 4.074, avg. samples / sec: 65872.19
Iteration:   3240, Loss function: 3.007, Average Loss: 4.087, avg. samples / sec: 65981.46
Iteration:   3240, Loss function: 2.183, Average Loss: 4.099, avg. samples / sec: 65942.53
Iteration:   3240, Loss function: 3.315, Average Loss: 4.125, avg. samples / sec: 65804.37
Iteration:   3240, Loss function: 4.095, Average Loss: 4.101, avg. samples / sec: 65810.30
Iteration:   3260, Loss function: 3.094, Average Loss: 4.058, avg. samples / sec: 65933.52
Iteration:   3260, Loss function: 3.787, Average Loss: 4.093, avg. samples / sec: 65995.64
Iteration:   3260, Loss function: 3.631, Average Loss: 4.082, avg. samples / sec: 65940.96
Iteration:   3260, Loss function: 3.910, Average Loss: 4.086, avg. samples / sec: 65853.23
Iteration:   3260, Loss function: 3.582, Average Loss: 4.078, avg. samples / sec: 66060.98
Iteration:   3260, Loss function: 2.668, Average Loss: 4.078, avg. samples / sec: 65931.58
Iteration:   3260, Loss function: 4.524, Average Loss: 4.073, avg. samples / sec: 65980.53
Iteration:   3260, Loss function: 3.987, Average Loss: 4.086, avg. samples / sec: 66022.23
Iteration:   3260, Loss function: 3.714, Average Loss: 4.079, avg. samples / sec: 65980.01
Iteration:   3260, Loss function: 3.269, Average Loss: 4.058, avg. samples / sec: 65824.35
Iteration:   3260, Loss function: 3.325, Average Loss: 4.079, avg. samples / sec: 65905.43
Iteration:   3260, Loss function: 3.092, Average Loss: 4.056, avg. samples / sec: 65948.70
Iteration:   3260, Loss function: 2.909, Average Loss: 4.086, avg. samples / sec: 66206.50
Iteration:   3260, Loss function: 3.677, Average Loss: 4.092, avg. samples / sec: 65758.37
Iteration:   3260, Loss function: 2.435, Average Loss: 4.108, avg. samples / sec: 66054.42
Iteration:   3260, Loss function: 4.463, Average Loss: 4.068, avg. samples / sec: 65991.69
Iteration:   3260, Loss function: 3.086, Average Loss: 4.076, avg. samples / sec: 65849.85
Iteration:   3260, Loss function: 5.284, Average Loss: 4.080, avg. samples / sec: 65906.91
Iteration:   3260, Loss function: 3.942, Average Loss: 4.093, avg. samples / sec: 65995.49
Iteration:   3260, Loss function: 2.788, Average Loss: 4.088, avg. samples / sec: 65999.44
Iteration:   3260, Loss function: 3.073, Average Loss: 4.042, avg. samples / sec: 65866.25
Iteration:   3260, Loss function: 2.969, Average Loss: 4.082, avg. samples / sec: 65856.37
Iteration:   3260, Loss function: 2.982, Average Loss: 4.068, avg. samples / sec: 65875.33
Iteration:   3260, Loss function: 2.951, Average Loss: 4.086, avg. samples / sec: 65751.01
Iteration:   3260, Loss function: 3.860, Average Loss: 4.065, avg. samples / sec: 65940.99
Iteration:   3260, Loss function: 3.974, Average Loss: 4.057, avg. samples / sec: 65833.82
Iteration:   3260, Loss function: 3.785, Average Loss: 4.071, avg. samples / sec: 65925.25
Iteration:   3260, Loss function: 3.360, Average Loss: 4.069, avg. samples / sec: 65808.30
Iteration:   3260, Loss function: 2.649, Average Loss: 4.060, avg. samples / sec: 65779.00
Iteration:   3260, Loss function: 4.876, Average Loss: 4.090, avg. samples / sec: 65821.92
Iteration:   3280, Loss function: 3.184, Average Loss: 4.076, avg. samples / sec: 66363.32
Iteration:   3280, Loss function: 4.677, Average Loss: 4.074, avg. samples / sec: 66237.53
Iteration:   3280, Loss function: 2.989, Average Loss: 4.040, avg. samples / sec: 66294.89
Iteration:   3280, Loss function: 3.686, Average Loss: 4.058, avg. samples / sec: 66280.73
Iteration:   3280, Loss function: 3.230, Average Loss: 4.054, avg. samples / sec: 66216.83
Iteration:   3280, Loss function: 2.903, Average Loss: 4.096, avg. samples / sec: 66199.78
Iteration:   3280, Loss function: 2.766, Average Loss: 4.067, avg. samples / sec: 66183.90
Iteration:   3280, Loss function: 3.190, Average Loss: 4.043, avg. samples / sec: 66157.49
Iteration:   3280, Loss function: 4.303, Average Loss: 4.072, avg. samples / sec: 66157.05
Iteration:   3280, Loss function: 3.472, Average Loss: 4.050, avg. samples / sec: 66308.58
Iteration:   3280, Loss function: 3.102, Average Loss: 4.045, avg. samples / sec: 66055.65
Iteration:   3280, Loss function: 4.219, Average Loss: 4.047, avg. samples / sec: 66129.86
Iteration:   3280, Loss function: 4.215, Average Loss: 4.069, avg. samples / sec: 66145.84
Iteration:   3280, Loss function: 3.636, Average Loss: 4.072, avg. samples / sec: 66075.10
Iteration:   3280, Loss function: 3.563, Average Loss: 4.036, avg. samples / sec: 66146.50
Iteration:   3280, Loss function: 3.304, Average Loss: 4.071, avg. samples / sec: 66046.83
Iteration:   3280, Loss function: 2.821, Average Loss: 4.074, avg. samples / sec: 66083.78
Iteration:   3280, Loss function: 3.240, Average Loss: 4.068, avg. samples / sec: 66051.20
Iteration:   3280, Loss function: 4.334, Average Loss: 4.055, avg. samples / sec: 66162.77
Iteration:   3280, Loss function: 5.822, Average Loss: 4.066, avg. samples / sec: 66040.18
Iteration:   3280, Loss function: 4.310, Average Loss: 4.083, avg. samples / sec: 66058.72
Iteration:   3280, Loss function: 3.955, Average Loss: 4.076, avg. samples / sec: 66083.62
Iteration:   3280, Loss function: 2.791, Average Loss: 4.068, avg. samples / sec: 66043.15
Iteration:   3280, Loss function: 3.531, Average Loss: 4.065, avg. samples / sec: 66056.80
Iteration:   3280, Loss function: 3.530, Average Loss: 4.060, avg. samples / sec: 66093.26
Iteration:   3280, Loss function: 3.552, Average Loss: 4.082, avg. samples / sec: 65956.54
Iteration:   3280, Loss function: 3.738, Average Loss: 4.079, avg. samples / sec: 66024.15
Iteration:   3280, Loss function: 4.496, Average Loss: 4.059, avg. samples / sec: 66108.61
Iteration:   3280, Loss function: 4.014, Average Loss: 4.074, avg. samples / sec: 66053.21
Iteration:   3280, Loss function: 3.611, Average Loss: 4.082, avg. samples / sec: 66141.90
:::MLL 1558651281.605 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1558651281.606 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 2.846, Average Loss: 4.046, avg. samples / sec: 65646.97
Iteration:   3300, Loss function: 4.738, Average Loss: 4.074, avg. samples / sec: 65754.17
Iteration:   3300, Loss function: 2.458, Average Loss: 4.032, avg. samples / sec: 65674.90
Iteration:   3300, Loss function: 3.318, Average Loss: 4.057, avg. samples / sec: 65636.79
Iteration:   3300, Loss function: 2.629, Average Loss: 4.072, avg. samples / sec: 65749.08
Iteration:   3300, Loss function: 3.672, Average Loss: 4.065, avg. samples / sec: 65497.20
Iteration:   3300, Loss function: 2.696, Average Loss: 4.024, avg. samples / sec: 65647.61
Iteration:   3300, Loss function: 2.651, Average Loss: 4.043, avg. samples / sec: 65564.72
Iteration:   3300, Loss function: 3.491, Average Loss: 4.082, avg. samples / sec: 65540.21
Iteration:   3300, Loss function: 3.522, Average Loss: 4.059, avg. samples / sec: 65612.13
Iteration:   3300, Loss function: 3.411, Average Loss: 4.023, avg. samples / sec: 65508.22
Iteration:   3300, Loss function: 3.201, Average Loss: 4.060, avg. samples / sec: 65623.43
Iteration:   3300, Loss function: 4.268, Average Loss: 4.067, avg. samples / sec: 65686.78
Iteration:   3300, Loss function: 3.679, Average Loss: 4.052, avg. samples / sec: 65504.29
Iteration:   3300, Loss function: 3.316, Average Loss: 4.047, avg. samples / sec: 65619.83
Iteration:   3300, Loss function: 3.129, Average Loss: 4.063, avg. samples / sec: 65693.57
Iteration:   3300, Loss function: 2.538, Average Loss: 4.058, avg. samples / sec: 65595.33
Iteration:   3300, Loss function: 5.009, Average Loss: 4.049, avg. samples / sec: 65637.34
Iteration:   3300, Loss function: 4.844, Average Loss: 4.065, avg. samples / sec: 65532.22
Iteration:   3300, Loss function: 4.004, Average Loss: 4.065, avg. samples / sec: 65591.30
Iteration:   3300, Loss function: 3.287, Average Loss: 4.027, avg. samples / sec: 65499.02
Iteration:   3300, Loss function: 4.434, Average Loss: 4.045, avg. samples / sec: 65669.73
Iteration:   3300, Loss function: 4.145, Average Loss: 4.061, avg. samples / sec: 65534.26
Iteration:   3300, Loss function: 3.581, Average Loss: 4.058, avg. samples / sec: 65420.27
Iteration:   3300, Loss function: 3.582, Average Loss: 4.037, avg. samples / sec: 65520.06
Iteration:   3300, Loss function: 2.704, Average Loss: 4.072, avg. samples / sec: 65663.88
Iteration:   3300, Loss function: 2.644, Average Loss: 4.040, avg. samples / sec: 65434.03
Iteration:   3300, Loss function: 3.249, Average Loss: 4.058, avg. samples / sec: 65550.97
Iteration:   3300, Loss function: 3.316, Average Loss: 4.053, avg. samples / sec: 65504.23
Iteration:   3300, Loss function: 2.617, Average Loss: 4.070, avg. samples / sec: 65504.05
Iteration:   3320, Loss function: 3.927, Average Loss: 4.054, avg. samples / sec: 65933.46
Iteration:   3320, Loss function: 4.460, Average Loss: 4.016, avg. samples / sec: 65923.56
Iteration:   3320, Loss function: 4.149, Average Loss: 4.063, avg. samples / sec: 65967.01
Iteration:   3320, Loss function: 2.519, Average Loss: 4.017, avg. samples / sec: 65848.49
Iteration:   3320, Loss function: 5.318, Average Loss: 4.036, avg. samples / sec: 65972.47
Iteration:   3320, Loss function: 2.611, Average Loss: 4.045, avg. samples / sec: 65994.10
Iteration:   3320, Loss function: 4.180, Average Loss: 4.050, avg. samples / sec: 65925.29
Iteration:   3320, Loss function: 3.101, Average Loss: 4.013, avg. samples / sec: 65995.52
Iteration:   3320, Loss function: 3.234, Average Loss: 4.042, avg. samples / sec: 66021.89
Iteration:   3320, Loss function: 4.153, Average Loss: 4.071, avg. samples / sec: 65865.42
Iteration:   3320, Loss function: 4.338, Average Loss: 4.041, avg. samples / sec: 66046.21
Iteration:   3320, Loss function: 2.988, Average Loss: 4.052, avg. samples / sec: 65950.92
Iteration:   3320, Loss function: 3.414, Average Loss: 4.043, avg. samples / sec: 65784.68
Iteration:   3320, Loss function: 3.372, Average Loss: 4.052, avg. samples / sec: 65866.34
Iteration:   3320, Loss function: 3.117, Average Loss: 4.029, avg. samples / sec: 66003.96
Iteration:   3320, Loss function: 3.322, Average Loss: 4.062, avg. samples / sec: 65744.66
Iteration:   3320, Loss function: 3.647, Average Loss: 4.029, avg. samples / sec: 65920.17
Iteration:   3320, Loss function: 3.389, Average Loss: 4.062, avg. samples / sec: 65752.79
Iteration:   3320, Loss function: 3.355, Average Loss: 4.034, avg. samples / sec: 65699.45
Iteration:   3320, Loss function: 3.351, Average Loss: 4.042, avg. samples / sec: 65841.14
Iteration:   3320, Loss function: 5.203, Average Loss: 4.039, avg. samples / sec: 65871.95
Iteration:   3320, Loss function: 2.324, Average Loss: 4.058, avg. samples / sec: 66012.58
Iteration:   3320, Loss function: 4.027, Average Loss: 4.041, avg. samples / sec: 65772.31
Iteration:   3320, Loss function: 2.079, Average Loss: 4.051, avg. samples / sec: 65837.82
Iteration:   3320, Loss function: 2.752, Average Loss: 4.061, avg. samples / sec: 65875.67
Iteration:   3320, Loss function: 3.793, Average Loss: 4.056, avg. samples / sec: 65844.80
Iteration:   3320, Loss function: 2.823, Average Loss: 4.048, avg. samples / sec: 65804.00
Iteration:   3320, Loss function: 3.452, Average Loss: 4.007, avg. samples / sec: 65739.33
Iteration:   3320, Loss function: 4.524, Average Loss: 4.042, avg. samples / sec: 65739.42
Iteration:   3320, Loss function: 2.776, Average Loss: 4.046, avg. samples / sec: 65699.52
Iteration:   3340, Loss function: 4.608, Average Loss: 4.021, avg. samples / sec: 66193.56
Iteration:   3340, Loss function: 4.545, Average Loss: 4.007, avg. samples / sec: 66046.92
Iteration:   3340, Loss function: 3.922, Average Loss: 4.026, avg. samples / sec: 66160.72
Iteration:   3340, Loss function: 3.236, Average Loss: 4.057, avg. samples / sec: 66057.98
Iteration:   3340, Loss function: 2.935, Average Loss: 4.038, avg. samples / sec: 66049.03
Iteration:   3340, Loss function: 4.292, Average Loss: 4.047, avg. samples / sec: 65912.40
Iteration:   3340, Loss function: 3.042, Average Loss: 4.002, avg. samples / sec: 65982.17
Iteration:   3340, Loss function: 3.473, Average Loss: 4.015, avg. samples / sec: 66067.89
Iteration:   3340, Loss function: 3.146, Average Loss: 4.054, avg. samples / sec: 66022.39
Iteration:   3340, Loss function: 3.968, Average Loss: 4.027, avg. samples / sec: 66018.80
Iteration:   3340, Loss function: 3.273, Average Loss: 4.037, avg. samples / sec: 66153.79
Iteration:   3340, Loss function: 3.198, Average Loss: 4.023, avg. samples / sec: 65944.01
Iteration:   3340, Loss function: 3.802, Average Loss: 4.030, avg. samples / sec: 66186.79
Iteration:   3340, Loss function: 3.662, Average Loss: 4.033, avg. samples / sec: 65931.27
Iteration:   3340, Loss function: 2.834, Average Loss: 3.995, avg. samples / sec: 66137.62
Iteration:   3340, Loss function: 3.171, Average Loss: 4.038, avg. samples / sec: 65941.63
Iteration:   3340, Loss function: 3.972, Average Loss: 4.028, avg. samples / sec: 66039.77
Iteration:   3340, Loss function: 3.174, Average Loss: 4.039, avg. samples / sec: 66038.60
Iteration:   3340, Loss function: 2.353, Average Loss: 4.045, avg. samples / sec: 66010.30
Iteration:   3340, Loss function: 5.609, Average Loss: 4.043, avg. samples / sec: 66201.46
Iteration:   3340, Loss function: 3.519, Average Loss: 4.029, avg. samples / sec: 65938.12
Iteration:   3340, Loss function: 3.959, Average Loss: 4.049, avg. samples / sec: 66018.00
Iteration:   3340, Loss function: 4.560, Average Loss: 4.005, avg. samples / sec: 65837.76
Iteration:   3340, Loss function: 4.044, Average Loss: 4.052, avg. samples / sec: 65948.92
Iteration:   3340, Loss function: 2.545, Average Loss: 4.033, avg. samples / sec: 65877.77
Iteration:   3340, Loss function: 3.350, Average Loss: 4.040, avg. samples / sec: 65896.68
Iteration:   3340, Loss function: 2.612, Average Loss: 4.056, avg. samples / sec: 65801.51
Iteration:   3340, Loss function: 3.850, Average Loss: 4.043, avg. samples / sec: 65952.81
Iteration:   3340, Loss function: 3.190, Average Loss: 4.036, avg. samples / sec: 65901.42
Iteration:   3340, Loss function: 3.946, Average Loss: 4.020, avg. samples / sec: 65834.19
:::MLL 1558651283.392 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1558651283.392 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 3.583, Average Loss: 4.024, avg. samples / sec: 65856.99
Iteration:   3360, Loss function: 2.410, Average Loss: 4.020, avg. samples / sec: 65958.42
Iteration:   3360, Loss function: 3.380, Average Loss: 4.041, avg. samples / sec: 65830.74
Iteration:   3360, Loss function: 3.360, Average Loss: 4.001, avg. samples / sec: 65700.65
Iteration:   3360, Loss function: 3.746, Average Loss: 3.992, avg. samples / sec: 65900.50
Iteration:   3360, Loss function: 3.377, Average Loss: 4.029, avg. samples / sec: 65900.59
Iteration:   3360, Loss function: 3.376, Average Loss: 3.996, avg. samples / sec: 65741.44
Iteration:   3360, Loss function: 3.204, Average Loss: 3.992, avg. samples / sec: 65660.73
Iteration:   3360, Loss function: 3.014, Average Loss: 4.020, avg. samples / sec: 65768.75
Iteration:   3360, Loss function: 3.721, Average Loss: 4.018, avg. samples / sec: 65805.51
Iteration:   3360, Loss function: 2.100, Average Loss: 4.006, avg. samples / sec: 65728.53
Iteration:   3360, Loss function: 2.611, Average Loss: 4.010, avg. samples / sec: 65712.75
Iteration:   3360, Loss function: 3.868, Average Loss: 4.045, avg. samples / sec: 65828.81
Iteration:   3360, Loss function: 3.484, Average Loss: 4.014, avg. samples / sec: 65612.55
Iteration:   3360, Loss function: 4.864, Average Loss: 4.018, avg. samples / sec: 65677.10
Iteration:   3360, Loss function: 3.113, Average Loss: 4.038, avg. samples / sec: 65766.97
Iteration:   3360, Loss function: 2.927, Average Loss: 4.022, avg. samples / sec: 65635.93
Iteration:   3360, Loss function: 3.424, Average Loss: 4.029, avg. samples / sec: 65718.23
Iteration:   3360, Loss function: 3.770, Average Loss: 4.013, avg. samples / sec: 65832.77
Iteration:   3360, Loss function: 3.293, Average Loss: 4.034, avg. samples / sec: 65714.59
Iteration:   3360, Loss function: 3.261, Average Loss: 4.046, avg. samples / sec: 65572.56
Iteration:   3360, Loss function: 3.268, Average Loss: 4.026, avg. samples / sec: 65669.42
Iteration:   3360, Loss function: 2.690, Average Loss: 4.026, avg. samples / sec: 65622.21
Iteration:   3360, Loss function: 3.682, Average Loss: 4.019, avg. samples / sec: 65662.26
Iteration:   3360, Loss function: 2.553, Average Loss: 3.985, avg. samples / sec: 65633.15
Iteration:   3360, Loss function: 2.566, Average Loss: 4.025, avg. samples / sec: 65608.31
Iteration:   3360, Loss function: 2.974, Average Loss: 4.034, avg. samples / sec: 65542.86
Iteration:   3360, Loss function: 3.435, Average Loss: 4.026, avg. samples / sec: 65735.55
Iteration:   3360, Loss function: 5.480, Average Loss: 4.049, avg. samples / sec: 65692.20
Iteration:   3360, Loss function: 2.940, Average Loss: 4.023, avg. samples / sec: 65703.04
Iteration:   3380, Loss function: 3.334, Average Loss: 4.009, avg. samples / sec: 65887.62
Iteration:   3380, Loss function: 4.126, Average Loss: 3.987, avg. samples / sec: 65853.29
Iteration:   3380, Loss function: 2.920, Average Loss: 4.032, avg. samples / sec: 66002.10
Iteration:   3380, Loss function: 3.414, Average Loss: 4.024, avg. samples / sec: 66070.64
Iteration:   3380, Loss function: 2.176, Average Loss: 3.984, avg. samples / sec: 65855.26
Iteration:   3380, Loss function: 3.000, Average Loss: 4.016, avg. samples / sec: 65783.48
Iteration:   3380, Loss function: 3.718, Average Loss: 3.982, avg. samples / sec: 65792.05
Iteration:   3380, Loss function: 3.931, Average Loss: 4.009, avg. samples / sec: 65852.52
Iteration:   3380, Loss function: 4.052, Average Loss: 4.005, avg. samples / sec: 65936.91
Iteration:   3380, Loss function: 2.646, Average Loss: 4.006, avg. samples / sec: 66039.34
Iteration:   3380, Loss function: 4.042, Average Loss: 4.029, avg. samples / sec: 65713.76
Iteration:   3380, Loss function: 2.767, Average Loss: 4.037, avg. samples / sec: 65973.83
Iteration:   3380, Loss function: 2.966, Average Loss: 4.009, avg. samples / sec: 65698.81
Iteration:   3380, Loss function: 3.005, Average Loss: 4.013, avg. samples / sec: 65901.79
Iteration:   3380, Loss function: 2.932, Average Loss: 4.017, avg. samples / sec: 65744.42
Iteration:   3380, Loss function: 2.811, Average Loss: 4.004, avg. samples / sec: 65819.21
Iteration:   3380, Loss function: 3.913, Average Loss: 4.009, avg. samples / sec: 65832.13
Iteration:   3380, Loss function: 3.568, Average Loss: 3.994, avg. samples / sec: 65758.10
Iteration:   3380, Loss function: 2.780, Average Loss: 3.997, avg. samples / sec: 65789.87
Iteration:   3380, Loss function: 3.927, Average Loss: 4.019, avg. samples / sec: 65853.17
Iteration:   3380, Loss function: 3.623, Average Loss: 4.005, avg. samples / sec: 65804.16
Iteration:   3380, Loss function: 2.820, Average Loss: 3.991, avg. samples / sec: 65663.55
Iteration:   3380, Loss function: 2.665, Average Loss: 4.008, avg. samples / sec: 65865.08
Iteration:   3380, Loss function: 3.540, Average Loss: 4.035, avg. samples / sec: 65755.15
Iteration:   3380, Loss function: 4.067, Average Loss: 4.013, avg. samples / sec: 65839.54
Iteration:   3380, Loss function: 4.722, Average Loss: 4.031, avg. samples / sec: 65774.67
Iteration:   3380, Loss function: 3.726, Average Loss: 3.975, avg. samples / sec: 65855.97
Iteration:   3380, Loss function: 2.900, Average Loss: 4.022, avg. samples / sec: 65782.62
Iteration:   3380, Loss function: 3.189, Average Loss: 4.014, avg. samples / sec: 65842.46
Iteration:   3380, Loss function: 2.604, Average Loss: 4.015, avg. samples / sec: 65810.58
Iteration:   3400, Loss function: 4.640, Average Loss: 4.020, avg. samples / sec: 66116.98
Iteration:   3400, Loss function: 4.238, Average Loss: 3.974, avg. samples / sec: 66047.30
Iteration:   3400, Loss function: 4.873, Average Loss: 3.981, avg. samples / sec: 66026.81
Iteration:   3400, Loss function: 3.904, Average Loss: 4.024, avg. samples / sec: 66160.47
Iteration:   3400, Loss function: 3.104, Average Loss: 3.998, avg. samples / sec: 66023.84
Iteration:   3400, Loss function: 3.855, Average Loss: 4.023, avg. samples / sec: 66159.82
Iteration:   3400, Loss function: 2.628, Average Loss: 3.983, avg. samples / sec: 66112.08
Iteration:   3400, Loss function: 3.255, Average Loss: 4.003, avg. samples / sec: 66064.29
Iteration:   3400, Loss function: 3.031, Average Loss: 3.993, avg. samples / sec: 66019.08
Iteration:   3400, Loss function: 2.752, Average Loss: 4.017, avg. samples / sec: 65955.34
Iteration:   3400, Loss function: 4.170, Average Loss: 4.015, avg. samples / sec: 65915.05
Iteration:   3400, Loss function: 4.184, Average Loss: 4.005, avg. samples / sec: 66081.76
Iteration:   3400, Loss function: 4.212, Average Loss: 4.001, avg. samples / sec: 66077.83
Iteration:   3400, Loss function: 3.280, Average Loss: 3.976, avg. samples / sec: 65955.68
Iteration:   3400, Loss function: 3.954, Average Loss: 3.995, avg. samples / sec: 65991.72
Iteration:   3400, Loss function: 3.345, Average Loss: 3.992, avg. samples / sec: 65949.66
Iteration:   3400, Loss function: 2.410, Average Loss: 3.998, avg. samples / sec: 66053.42
Iteration:   3400, Loss function: 3.941, Average Loss: 4.004, avg. samples / sec: 66096.11
Iteration:   3400, Loss function: 3.290, Average Loss: 4.001, avg. samples / sec: 65896.59
Iteration:   3400, Loss function: 2.749, Average Loss: 4.006, avg. samples / sec: 66058.60
Iteration:   3400, Loss function: 3.843, Average Loss: 3.992, avg. samples / sec: 65981.40
Iteration:   3400, Loss function: 3.619, Average Loss: 4.003, avg. samples / sec: 65969.04
Iteration:   3400, Loss function: 3.376, Average Loss: 3.984, avg. samples / sec: 65982.39
Iteration:   3400, Loss function: 4.959, Average Loss: 4.009, avg. samples / sec: 66006.99
Iteration:   3400, Loss function: 3.036, Average Loss: 3.999, avg. samples / sec: 65814.76
Iteration:   3400, Loss function: 3.797, Average Loss: 3.961, avg. samples / sec: 66000.50
Iteration:   3400, Loss function: 2.928, Average Loss: 3.986, avg. samples / sec: 65953.95
Iteration:   3400, Loss function: 3.984, Average Loss: 4.025, avg. samples / sec: 65900.28
Iteration:   3400, Loss function: 3.880, Average Loss: 4.007, avg. samples / sec: 66004.36
Iteration:   3400, Loss function: 4.564, Average Loss: 4.001, avg. samples / sec: 65833.27
Iteration:   3420, Loss function: 3.158, Average Loss: 3.965, avg. samples / sec: 66057.95
Iteration:   3420, Loss function: 3.608, Average Loss: 3.992, avg. samples / sec: 66157.08
Iteration:   3420, Loss function: 2.319, Average Loss: 3.974, avg. samples / sec: 66054.04
Iteration:   3420, Loss function: 3.740, Average Loss: 4.006, avg. samples / sec: 65974.05
Iteration:   3420, Loss function: 2.431, Average Loss: 3.964, avg. samples / sec: 66076.13
Iteration:   3420, Loss function: 3.173, Average Loss: 3.984, avg. samples / sec: 66093.57
Iteration:   3420, Loss function: 3.175, Average Loss: 3.973, avg. samples / sec: 66141.06
Iteration:   3420, Loss function: 3.382, Average Loss: 4.010, avg. samples / sec: 65956.48
Iteration:   3420, Loss function: 3.563, Average Loss: 3.982, avg. samples / sec: 66108.14
Iteration:   3420, Loss function: 2.490, Average Loss: 3.986, avg. samples / sec: 66131.72
Iteration:   3420, Loss function: 2.885, Average Loss: 4.002, avg. samples / sec: 66008.78
Iteration:   3420, Loss function: 2.791, Average Loss: 3.983, avg. samples / sec: 66037.30
Iteration:   3420, Loss function: 3.514, Average Loss: 3.971, avg. samples / sec: 65920.57
Iteration:   3420, Loss function: 3.796, Average Loss: 4.010, avg. samples / sec: 65972.01
Iteration:   3420, Loss function: 3.281, Average Loss: 3.995, avg. samples / sec: 66058.56
Iteration:   3420, Loss function: 3.027, Average Loss: 3.984, avg. samples / sec: 66005.91
Iteration:   3420, Loss function: 3.462, Average Loss: 3.978, avg. samples / sec: 66100.70
Iteration:   3420, Loss function: 2.866, Average Loss: 4.010, avg. samples / sec: 65932.13
Iteration:   3420, Loss function: 2.614, Average Loss: 3.995, avg. samples / sec: 66024.92
Iteration:   3420, Loss function: 3.982, Average Loss: 3.982, avg. samples / sec: 65924.36
Iteration:   3420, Loss function: 3.721, Average Loss: 3.988, avg. samples / sec: 65900.68
Iteration:   3420, Loss function: 2.998, Average Loss: 4.010, avg. samples / sec: 66043.77
Iteration:   3420, Loss function: 3.881, Average Loss: 3.991, avg. samples / sec: 65915.57
Iteration:   3420, Loss function: 3.785, Average Loss: 3.992, avg. samples / sec: 66148.30
Iteration:   3420, Loss function: 2.974, Average Loss: 3.993, avg. samples / sec: 65980.10
Iteration:   3420, Loss function: 3.452, Average Loss: 3.993, avg. samples / sec: 65905.80
Iteration:   3420, Loss function: 3.236, Average Loss: 3.956, avg. samples / sec: 66017.84
Iteration:   3420, Loss function: 3.671, Average Loss: 4.001, avg. samples / sec: 65979.24
Iteration:   3420, Loss function: 3.153, Average Loss: 3.991, avg. samples / sec: 65852.37
Iteration:   3420, Loss function: 3.195, Average Loss: 3.996, avg. samples / sec: 65966.98
:::MLL 1558651285.160 eval_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.58 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.50s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=2.48s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22368
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38390
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22937
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23520
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36075
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21798
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31739
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.35903
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52466
Current AP: 0.22368 AP goal: 0.23000
:::MLL 1558651288.766 eval_accuracy: {"value": 0.2236775210726234, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 389}}
:::MLL 1558651288.804 eval_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 392}}
:::MLL 1558651288.810 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1558651288.811 block_start: {"value": null, "metadata": {"first_epoch_num": 49, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
:::MLL 1558651288.836 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1558651288.836 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.697, Average Loss: 3.951, avg. samples / sec: 8053.99
Iteration:   3440, Loss function: 4.732, Average Loss: 3.997, avg. samples / sec: 8056.96
Iteration:   3440, Loss function: 3.559, Average Loss: 3.955, avg. samples / sec: 8054.45
Iteration:   3440, Loss function: 3.728, Average Loss: 3.973, avg. samples / sec: 8054.69
Iteration:   3440, Loss function: 3.490, Average Loss: 3.983, avg. samples / sec: 8056.00
Iteration:   3440, Loss function: 3.129, Average Loss: 3.986, avg. samples / sec: 8054.71
Iteration:   3440, Loss function: 2.577, Average Loss: 3.991, avg. samples / sec: 8053.55
Iteration:   3440, Loss function: 2.033, Average Loss: 3.994, avg. samples / sec: 8054.22
Iteration:   3440, Loss function: 3.055, Average Loss: 4.003, avg. samples / sec: 8053.71
Iteration:   3440, Loss function: 4.099, Average Loss: 3.968, avg. samples / sec: 8054.38
Iteration:   3440, Loss function: 4.570, Average Loss: 3.971, avg. samples / sec: 8053.82
Iteration:   3440, Loss function: 4.154, Average Loss: 3.979, avg. samples / sec: 8052.41
Iteration:   3440, Loss function: 3.010, Average Loss: 3.964, avg. samples / sec: 8053.81
Iteration:   3440, Loss function: 2.670, Average Loss: 3.959, avg. samples / sec: 8052.70
Iteration:   3440, Loss function: 3.463, Average Loss: 3.971, avg. samples / sec: 8053.56
Iteration:   3440, Loss function: 3.553, Average Loss: 3.976, avg. samples / sec: 8052.68
Iteration:   3440, Loss function: 3.333, Average Loss: 3.987, avg. samples / sec: 8054.63
Iteration:   3440, Loss function: 4.004, Average Loss: 3.985, avg. samples / sec: 8056.23
Iteration:   3440, Loss function: 3.573, Average Loss: 3.979, avg. samples / sec: 8054.56
Iteration:   3440, Loss function: 3.547, Average Loss: 3.993, avg. samples / sec: 8055.01
Iteration:   3440, Loss function: 3.574, Average Loss: 3.947, avg. samples / sec: 8054.69
Iteration:   3440, Loss function: 4.206, Average Loss: 3.970, avg. samples / sec: 8053.34
Iteration:   3440, Loss function: 4.203, Average Loss: 3.965, avg. samples / sec: 8051.63
Iteration:   3440, Loss function: 2.678, Average Loss: 3.982, avg. samples / sec: 8052.86
Iteration:   3440, Loss function: 3.083, Average Loss: 3.971, avg. samples / sec: 8053.43
Iteration:   3440, Loss function: 4.007, Average Loss: 3.973, avg. samples / sec: 8053.08
Iteration:   3440, Loss function: 3.375, Average Loss: 3.986, avg. samples / sec: 8053.17
Iteration:   3440, Loss function: 3.810, Average Loss: 3.988, avg. samples / sec: 8052.38
Iteration:   3440, Loss function: 2.962, Average Loss: 3.973, avg. samples / sec: 8054.12
Iteration:   3440, Loss function: 3.374, Average Loss: 3.997, avg. samples / sec: 8052.17
Iteration:   3460, Loss function: 3.360, Average Loss: 3.981, avg. samples / sec: 66108.30
Iteration:   3460, Loss function: 3.366, Average Loss: 3.978, avg. samples / sec: 66041.29
Iteration:   3460, Loss function: 3.137, Average Loss: 3.985, avg. samples / sec: 65911.87
Iteration:   3460, Loss function: 3.904, Average Loss: 3.969, avg. samples / sec: 66046.06
Iteration:   3460, Loss function: 3.875, Average Loss: 3.981, avg. samples / sec: 66046.55
Iteration:   3460, Loss function: 4.108, Average Loss: 3.950, avg. samples / sec: 66090.04
Iteration:   3460, Loss function: 2.583, Average Loss: 3.959, avg. samples / sec: 66132.16
Iteration:   3460, Loss function: 3.753, Average Loss: 3.963, avg. samples / sec: 66097.91
Iteration:   3460, Loss function: 2.267, Average Loss: 3.970, avg. samples / sec: 66109.23
Iteration:   3460, Loss function: 2.934, Average Loss: 3.975, avg. samples / sec: 66053.98
Iteration:   3460, Loss function: 2.429, Average Loss: 3.980, avg. samples / sec: 65954.50
Iteration:   3460, Loss function: 3.684, Average Loss: 3.956, avg. samples / sec: 65987.08
Iteration:   3460, Loss function: 4.687, Average Loss: 3.963, avg. samples / sec: 65994.90
Iteration:   3460, Loss function: 3.927, Average Loss: 3.958, avg. samples / sec: 66032.41
Iteration:   3460, Loss function: 3.127, Average Loss: 3.947, avg. samples / sec: 65813.19
Iteration:   3460, Loss function: 4.062, Average Loss: 3.942, avg. samples / sec: 65845.35
Iteration:   3460, Loss function: 3.927, Average Loss: 3.967, avg. samples / sec: 65967.75
Iteration:   3460, Loss function: 2.982, Average Loss: 3.969, avg. samples / sec: 65923.96
Iteration:   3460, Loss function: 2.664, Average Loss: 3.986, avg. samples / sec: 66082.57
Iteration:   3460, Loss function: 6.187, Average Loss: 3.970, avg. samples / sec: 65860.56
Iteration:   3460, Loss function: 3.453, Average Loss: 3.974, avg. samples / sec: 66071.32
Iteration:   3460, Loss function: 4.133, Average Loss: 3.983, avg. samples / sec: 65967.44
Iteration:   3460, Loss function: 3.114, Average Loss: 3.967, avg. samples / sec: 65961.54
Iteration:   3460, Loss function: 3.585, Average Loss: 3.949, avg. samples / sec: 65919.89
Iteration:   3460, Loss function: 3.119, Average Loss: 3.963, avg. samples / sec: 66017.62
Iteration:   3460, Loss function: 2.609, Average Loss: 3.989, avg. samples / sec: 65880.78
Iteration:   3460, Loss function: 3.810, Average Loss: 3.975, avg. samples / sec: 66013.17
Iteration:   3460, Loss function: 2.870, Average Loss: 3.963, avg. samples / sec: 65805.35
Iteration:   3460, Loss function: 3.682, Average Loss: 3.959, avg. samples / sec: 65796.60
Iteration:   3460, Loss function: 5.136, Average Loss: 3.941, avg. samples / sec: 65834.25
Iteration:   3480, Loss function: 3.262, Average Loss: 3.944, avg. samples / sec: 65964.20
Iteration:   3480, Loss function: 3.041, Average Loss: 3.972, avg. samples / sec: 65825.21
Iteration:   3480, Loss function: 3.597, Average Loss: 3.968, avg. samples / sec: 65867.42
Iteration:   3480, Loss function: 3.805, Average Loss: 3.940, avg. samples / sec: 66030.89
Iteration:   3480, Loss function: 4.584, Average Loss: 3.945, avg. samples / sec: 65916.28
Iteration:   3480, Loss function: 2.317, Average Loss: 3.969, avg. samples / sec: 65900.01
Iteration:   3480, Loss function: 3.515, Average Loss: 3.960, avg. samples / sec: 65983.81
Iteration:   3480, Loss function: 3.126, Average Loss: 3.943, avg. samples / sec: 65922.20
Iteration:   3480, Loss function: 3.885, Average Loss: 3.931, avg. samples / sec: 65938.49
Iteration:   3480, Loss function: 2.898, Average Loss: 3.959, avg. samples / sec: 65851.48
Iteration:   3480, Loss function: 5.216, Average Loss: 3.948, avg. samples / sec: 65895.54
Iteration:   3480, Loss function: 3.703, Average Loss: 3.932, avg. samples / sec: 65890.42
Iteration:   3480, Loss function: 3.215, Average Loss: 3.951, avg. samples / sec: 65893.38
Iteration:   3480, Loss function: 2.924, Average Loss: 3.980, avg. samples / sec: 65940.00
Iteration:   3480, Loss function: 4.362, Average Loss: 3.961, avg. samples / sec: 65851.82
Iteration:   3480, Loss function: 2.854, Average Loss: 3.955, avg. samples / sec: 65983.75
Iteration:   3480, Loss function: 3.319, Average Loss: 3.973, avg. samples / sec: 65927.10
Iteration:   3480, Loss function: 4.940, Average Loss: 3.964, avg. samples / sec: 65854.68
Iteration:   3480, Loss function: 4.215, Average Loss: 3.980, avg. samples / sec: 65949.84
Iteration:   3480, Loss function: 3.643, Average Loss: 3.950, avg. samples / sec: 65820.69
Iteration:   3480, Loss function: 4.650, Average Loss: 3.972, avg. samples / sec: 65788.98
Iteration:   3480, Loss function: 2.690, Average Loss: 3.953, avg. samples / sec: 65856.55
Iteration:   3480, Loss function: 2.722, Average Loss: 3.929, avg. samples / sec: 66013.60
Iteration:   3480, Loss function: 3.376, Average Loss: 3.976, avg. samples / sec: 65742.73
Iteration:   3480, Loss function: 3.518, Average Loss: 3.959, avg. samples / sec: 65872.96
Iteration:   3480, Loss function: 3.882, Average Loss: 3.960, avg. samples / sec: 65839.85
Iteration:   3480, Loss function: 2.900, Average Loss: 3.955, avg. samples / sec: 65884.42
Iteration:   3480, Loss function: 4.034, Average Loss: 3.961, avg. samples / sec: 65875.27
Iteration:   3480, Loss function: 3.224, Average Loss: 3.957, avg. samples / sec: 65802.59
Iteration:   3480, Loss function: 3.305, Average Loss: 3.951, avg. samples / sec: 65898.50
:::MLL 1558651290.623 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1558651290.623 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 3.313, Average Loss: 3.920, avg. samples / sec: 65954.78
Iteration:   3500, Loss function: 4.042, Average Loss: 3.934, avg. samples / sec: 65824.13
Iteration:   3500, Loss function: 3.482, Average Loss: 3.970, avg. samples / sec: 65852.80
Iteration:   3500, Loss function: 4.655, Average Loss: 3.935, avg. samples / sec: 65744.29
Iteration:   3500, Loss function: 3.282, Average Loss: 3.925, avg. samples / sec: 65751.29
Iteration:   3500, Loss function: 3.070, Average Loss: 3.962, avg. samples / sec: 65721.94
Iteration:   3500, Loss function: 4.775, Average Loss: 3.958, avg. samples / sec: 65706.16
Iteration:   3500, Loss function: 3.038, Average Loss: 3.970, avg. samples / sec: 65779.86
Iteration:   3500, Loss function: 4.402, Average Loss: 3.943, avg. samples / sec: 65851.11
Iteration:   3500, Loss function: 4.821, Average Loss: 3.968, avg. samples / sec: 65850.58
Iteration:   3500, Loss function: 3.474, Average Loss: 3.947, avg. samples / sec: 65904.81
Iteration:   3500, Loss function: 2.634, Average Loss: 3.944, avg. samples / sec: 65739.11
Iteration:   3500, Loss function: 3.883, Average Loss: 3.944, avg. samples / sec: 65840.59
Iteration:   3500, Loss function: 3.344, Average Loss: 3.950, avg. samples / sec: 65692.01
Iteration:   3500, Loss function: 3.223, Average Loss: 3.948, avg. samples / sec: 65810.49
Iteration:   3500, Loss function: 3.068, Average Loss: 3.940, avg. samples / sec: 65716.27
Iteration:   3500, Loss function: 2.533, Average Loss: 3.965, avg. samples / sec: 65782.56
Iteration:   3500, Loss function: 3.536, Average Loss: 3.940, avg. samples / sec: 65759.85
Iteration:   3500, Loss function: 4.262, Average Loss: 3.949, avg. samples / sec: 65718.57
Iteration:   3500, Loss function: 2.636, Average Loss: 3.961, avg. samples / sec: 65717.81
Iteration:   3500, Loss function: 2.744, Average Loss: 3.952, avg. samples / sec: 65770.80
Iteration:   3500, Loss function: 2.805, Average Loss: 3.919, avg. samples / sec: 65671.20
Iteration:   3500, Loss function: 2.872, Average Loss: 3.922, avg. samples / sec: 65752.88
Iteration:   3500, Loss function: 3.188, Average Loss: 3.961, avg. samples / sec: 65626.58
Iteration:   3500, Loss function: 2.985, Average Loss: 3.951, avg. samples / sec: 65641.07
Iteration:   3500, Loss function: 5.044, Average Loss: 3.944, avg. samples / sec: 65809.20
Iteration:   3500, Loss function: 3.367, Average Loss: 3.949, avg. samples / sec: 65747.58
Iteration:   3500, Loss function: 3.427, Average Loss: 3.942, avg. samples / sec: 65628.29
Iteration:   3500, Loss function: 2.922, Average Loss: 3.952, avg. samples / sec: 65610.32
Iteration:   3500, Loss function: 3.710, Average Loss: 3.933, avg. samples / sec: 65457.04
Iteration:   3520, Loss function: 3.832, Average Loss: 3.929, avg. samples / sec: 66165.00
Iteration:   3520, Loss function: 3.490, Average Loss: 3.954, avg. samples / sec: 66024.21
Iteration:   3520, Loss function: 2.289, Average Loss: 3.909, avg. samples / sec: 66179.45
Iteration:   3520, Loss function: 4.052, Average Loss: 3.960, avg. samples / sec: 66046.65
Iteration:   3520, Loss function: 2.669, Average Loss: 3.929, avg. samples / sec: 66039.06
Iteration:   3520, Loss function: 2.531, Average Loss: 3.951, avg. samples / sec: 66002.26
Iteration:   3520, Loss function: 3.598, Average Loss: 3.912, avg. samples / sec: 65839.66
Iteration:   3520, Loss function: 2.383, Average Loss: 3.921, avg. samples / sec: 66223.11
Iteration:   3520, Loss function: 3.229, Average Loss: 3.912, avg. samples / sec: 66124.86
Iteration:   3520, Loss function: 3.689, Average Loss: 3.935, avg. samples / sec: 65993.48
Iteration:   3520, Loss function: 3.455, Average Loss: 3.958, avg. samples / sec: 66039.74
Iteration:   3520, Loss function: 3.716, Average Loss: 3.937, avg. samples / sec: 66138.49
Iteration:   3520, Loss function: 2.927, Average Loss: 3.940, avg. samples / sec: 66148.73
Iteration:   3520, Loss function: 2.902, Average Loss: 3.918, avg. samples / sec: 65939.54
Iteration:   3520, Loss function: 2.882, Average Loss: 3.944, avg. samples / sec: 65955.21
Iteration:   3520, Loss function: 2.995, Average Loss: 3.933, avg. samples / sec: 65962.41
Iteration:   3520, Loss function: 2.919, Average Loss: 3.932, avg. samples / sec: 65978.28
Iteration:   3520, Loss function: 3.425, Average Loss: 3.922, avg. samples / sec: 65854.74
Iteration:   3520, Loss function: 4.076, Average Loss: 3.937, avg. samples / sec: 65973.62
Iteration:   3520, Loss function: 4.410, Average Loss: 3.942, avg. samples / sec: 65968.80
Iteration:   3520, Loss function: 3.784, Average Loss: 3.939, avg. samples / sec: 66047.54
Iteration:   3520, Loss function: 3.583, Average Loss: 3.961, avg. samples / sec: 65916.84
Iteration:   3520, Loss function: 3.654, Average Loss: 3.933, avg. samples / sec: 65954.53
Iteration:   3520, Loss function: 2.662, Average Loss: 3.950, avg. samples / sec: 65998.64
Iteration:   3520, Loss function: 4.086, Average Loss: 3.942, avg. samples / sec: 65906.11
Iteration:   3520, Loss function: 3.390, Average Loss: 3.942, avg. samples / sec: 65939.54
Iteration:   3520, Loss function: 3.041, Average Loss: 3.937, avg. samples / sec: 65875.30
Iteration:   3520, Loss function: 2.843, Average Loss: 3.948, avg. samples / sec: 65906.45
Iteration:   3520, Loss function: 2.832, Average Loss: 3.934, avg. samples / sec: 65927.85
Iteration:   3520, Loss function: 4.158, Average Loss: 3.938, avg. samples / sec: 65926.36
Iteration:   3540, Loss function: 2.963, Average Loss: 3.931, avg. samples / sec: 66156.28
Iteration:   3540, Loss function: 2.418, Average Loss: 3.946, avg. samples / sec: 65973.77
Iteration:   3540, Loss function: 4.420, Average Loss: 3.932, avg. samples / sec: 65997.31
Iteration:   3540, Loss function: 3.025, Average Loss: 3.927, avg. samples / sec: 66045.07
Iteration:   3540, Loss function: 3.373, Average Loss: 3.942, avg. samples / sec: 65890.42
Iteration:   3540, Loss function: 3.568, Average Loss: 3.928, avg. samples / sec: 66139.79
Iteration:   3540, Loss function: 4.351, Average Loss: 3.952, avg. samples / sec: 66046.37
Iteration:   3540, Loss function: 2.890, Average Loss: 3.921, avg. samples / sec: 66048.04
Iteration:   3540, Loss function: 3.748, Average Loss: 3.902, avg. samples / sec: 65848.52
Iteration:   3540, Loss function: 2.471, Average Loss: 3.948, avg. samples / sec: 65931.11
Iteration:   3540, Loss function: 2.893, Average Loss: 3.930, avg. samples / sec: 66064.29
Iteration:   3540, Loss function: 3.383, Average Loss: 3.901, avg. samples / sec: 65885.47
Iteration:   3540, Loss function: 2.411, Average Loss: 3.924, avg. samples / sec: 65897.39
Iteration:   3540, Loss function: 3.038, Average Loss: 3.948, avg. samples / sec: 65836.93
Iteration:   3540, Loss function: 3.528, Average Loss: 3.913, avg. samples / sec: 65883.99
Iteration:   3540, Loss function: 2.638, Average Loss: 3.911, avg. samples / sec: 65958.27
Iteration:   3540, Loss function: 4.064, Average Loss: 3.920, avg. samples / sec: 66102.31
Iteration:   3540, Loss function: 2.827, Average Loss: 3.911, avg. samples / sec: 65924.42
Iteration:   3540, Loss function: 3.480, Average Loss: 3.932, avg. samples / sec: 65916.31
Iteration:   3540, Loss function: 2.828, Average Loss: 3.914, avg. samples / sec: 65949.01
Iteration:   3540, Loss function: 2.818, Average Loss: 3.902, avg. samples / sec: 65850.49
Iteration:   3540, Loss function: 3.606, Average Loss: 3.930, avg. samples / sec: 66107.37
Iteration:   3540, Loss function: 3.178, Average Loss: 3.936, avg. samples / sec: 65957.78
Iteration:   3540, Loss function: 3.202, Average Loss: 3.919, avg. samples / sec: 65832.53
Iteration:   3540, Loss function: 3.048, Average Loss: 3.941, avg. samples / sec: 66011.93
Iteration:   3540, Loss function: 3.160, Average Loss: 3.918, avg. samples / sec: 65744.78
Iteration:   3540, Loss function: 3.705, Average Loss: 3.933, avg. samples / sec: 65883.62
Iteration:   3540, Loss function: 4.808, Average Loss: 3.922, avg. samples / sec: 65888.30
Iteration:   3540, Loss function: 3.022, Average Loss: 3.937, avg. samples / sec: 65973.31
Iteration:   3540, Loss function: 3.966, Average Loss: 3.932, avg. samples / sec: 65951.97
:::MLL 1558651292.157 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1558651292.157 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 2.814, Average Loss: 3.916, avg. samples / sec: 65407.55
Iteration:   3560, Loss function: 3.532, Average Loss: 3.893, avg. samples / sec: 65411.71
Iteration:   3560, Loss function: 3.164, Average Loss: 3.902, avg. samples / sec: 65367.72
Iteration:   3560, Loss function: 3.370, Average Loss: 3.909, avg. samples / sec: 65339.62
Iteration:   3560, Loss function: 2.997, Average Loss: 3.926, avg. samples / sec: 65252.79
Iteration:   3560, Loss function: 2.857, Average Loss: 3.938, avg. samples / sec: 65323.45
Iteration:   3560, Loss function: 4.016, Average Loss: 3.925, avg. samples / sec: 65314.79
Iteration:   3560, Loss function: 2.762, Average Loss: 3.910, avg. samples / sec: 65252.64
Iteration:   3560, Loss function: 2.735, Average Loss: 3.906, avg. samples / sec: 65280.84
Iteration:   3560, Loss function: 2.238, Average Loss: 3.902, avg. samples / sec: 65296.09
Iteration:   3560, Loss function: 2.772, Average Loss: 3.931, avg. samples / sec: 65183.77
Iteration:   3560, Loss function: 3.686, Average Loss: 3.907, avg. samples / sec: 65307.19
Iteration:   3560, Loss function: 2.789, Average Loss: 3.892, avg. samples / sec: 65279.97
Iteration:   3560, Loss function: 3.487, Average Loss: 3.924, avg. samples / sec: 65401.48
Iteration:   3560, Loss function: 3.094, Average Loss: 3.889, avg. samples / sec: 65247.87
Iteration:   3560, Loss function: 3.772, Average Loss: 3.914, avg. samples / sec: 65267.57
Iteration:   3560, Loss function: 3.562, Average Loss: 3.908, avg. samples / sec: 65241.98
Iteration:   3560, Loss function: 3.861, Average Loss: 3.927, avg. samples / sec: 65046.01
Iteration:   3560, Loss function: 3.101, Average Loss: 3.931, avg. samples / sec: 65321.81
Iteration:   3560, Loss function: 3.349, Average Loss: 3.918, avg. samples / sec: 65229.84
Iteration:   3560, Loss function: 2.282, Average Loss: 3.913, avg. samples / sec: 65266.30
Iteration:   3560, Loss function: 3.271, Average Loss: 3.922, avg. samples / sec: 65212.58
Iteration:   3560, Loss function: 2.851, Average Loss: 3.941, avg. samples / sec: 65106.44
Iteration:   3560, Loss function: 2.358, Average Loss: 3.917, avg. samples / sec: 65081.78
Iteration:   3560, Loss function: 3.749, Average Loss: 3.925, avg. samples / sec: 65161.86
Iteration:   3560, Loss function: 4.118, Average Loss: 3.921, avg. samples / sec: 65147.10
Iteration:   3560, Loss function: 2.394, Average Loss: 3.923, avg. samples / sec: 65074.33
Iteration:   3560, Loss function: 2.049, Average Loss: 3.914, avg. samples / sec: 65132.35
Iteration:   3560, Loss function: 4.084, Average Loss: 3.933, avg. samples / sec: 65126.27
Iteration:   3560, Loss function: 3.891, Average Loss: 3.912, avg. samples / sec: 65042.25
Iteration:   3580, Loss function: 5.325, Average Loss: 3.885, avg. samples / sec: 65939.10
Iteration:   3580, Loss function: 2.968, Average Loss: 3.899, avg. samples / sec: 65885.53
Iteration:   3580, Loss function: 3.523, Average Loss: 3.922, avg. samples / sec: 65834.47
Iteration:   3580, Loss function: 3.184, Average Loss: 3.888, avg. samples / sec: 65823.67
Iteration:   3580, Loss function: 3.735, Average Loss: 3.921, avg. samples / sec: 65782.07
Iteration:   3580, Loss function: 3.848, Average Loss: 3.917, avg. samples / sec: 65800.71
Iteration:   3580, Loss function: 2.745, Average Loss: 3.918, avg. samples / sec: 65943.45
Iteration:   3580, Loss function: 3.899, Average Loss: 3.908, avg. samples / sec: 65893.38
Iteration:   3580, Loss function: 3.415, Average Loss: 3.913, avg. samples / sec: 65945.46
Iteration:   3580, Loss function: 3.932, Average Loss: 3.904, avg. samples / sec: 65860.62
Iteration:   3580, Loss function: 4.853, Average Loss: 3.883, avg. samples / sec: 65804.71
Iteration:   3580, Loss function: 4.413, Average Loss: 3.908, avg. samples / sec: 65960.12
Iteration:   3580, Loss function: 4.143, Average Loss: 3.918, avg. samples / sec: 65860.16
Iteration:   3580, Loss function: 2.493, Average Loss: 3.894, avg. samples / sec: 65734.94
Iteration:   3580, Loss function: 4.085, Average Loss: 3.899, avg. samples / sec: 65727.89
Iteration:   3580, Loss function: 2.940, Average Loss: 3.911, avg. samples / sec: 65750.52
Iteration:   3580, Loss function: 4.107, Average Loss: 3.907, avg. samples / sec: 65631.90
Iteration:   3580, Loss function: 4.705, Average Loss: 3.917, avg. samples / sec: 65795.89
Iteration:   3580, Loss function: 2.980, Average Loss: 3.901, avg. samples / sec: 65914.00
Iteration:   3580, Loss function: 3.733, Average Loss: 3.890, avg. samples / sec: 65675.51
Iteration:   3580, Loss function: 3.025, Average Loss: 3.908, avg. samples / sec: 65867.45
Iteration:   3580, Loss function: 3.218, Average Loss: 3.910, avg. samples / sec: 65846.86
Iteration:   3580, Loss function: 4.199, Average Loss: 3.882, avg. samples / sec: 65595.82
Iteration:   3580, Loss function: 3.120, Average Loss: 3.906, avg. samples / sec: 65789.63
Iteration:   3580, Loss function: 3.948, Average Loss: 3.916, avg. samples / sec: 65824.38
Iteration:   3580, Loss function: 3.484, Average Loss: 3.931, avg. samples / sec: 65638.16
Iteration:   3580, Loss function: 3.618, Average Loss: 3.901, avg. samples / sec: 65791.99
Iteration:   3580, Loss function: 3.057, Average Loss: 3.935, avg. samples / sec: 65789.26
Iteration:   3580, Loss function: 2.978, Average Loss: 3.902, avg. samples / sec: 65611.79
Iteration:   3580, Loss function: 2.466, Average Loss: 3.899, avg. samples / sec: 65670.03
Iteration:   3600, Loss function: 3.860, Average Loss: 3.869, avg. samples / sec: 66312.26
Iteration:   3600, Loss function: 3.005, Average Loss: 3.876, avg. samples / sec: 66075.01
Iteration:   3600, Loss function: 3.111, Average Loss: 3.908, avg. samples / sec: 66177.99
Iteration:   3600, Loss function: 3.365, Average Loss: 3.913, avg. samples / sec: 66181.57
Iteration:   3600, Loss function: 3.295, Average Loss: 3.898, avg. samples / sec: 66233.14
Iteration:   3600, Loss function: 3.403, Average Loss: 3.896, avg. samples / sec: 66165.56
Iteration:   3600, Loss function: 4.070, Average Loss: 3.889, avg. samples / sec: 66339.80
Iteration:   3600, Loss function: 2.527, Average Loss: 3.879, avg. samples / sec: 66104.80
Iteration:   3600, Loss function: 2.921, Average Loss: 3.921, avg. samples / sec: 66274.90
Iteration:   3600, Loss function: 3.272, Average Loss: 3.905, avg. samples / sec: 66239.27
Iteration:   3600, Loss function: 3.678, Average Loss: 3.896, avg. samples / sec: 66125.89
Iteration:   3600, Loss function: 3.504, Average Loss: 3.910, avg. samples / sec: 66121.98
Iteration:   3600, Loss function: 3.582, Average Loss: 3.895, avg. samples / sec: 66229.68
Iteration:   3600, Loss function: 2.998, Average Loss: 3.906, avg. samples / sec: 66131.32
Iteration:   3600, Loss function: 2.661, Average Loss: 3.881, avg. samples / sec: 66148.27
Iteration:   3600, Loss function: 4.118, Average Loss: 3.887, avg. samples / sec: 66163.51
Iteration:   3600, Loss function: 1.989, Average Loss: 3.901, avg. samples / sec: 66156.00
Iteration:   3600, Loss function: 4.010, Average Loss: 3.913, avg. samples / sec: 66061.54
Iteration:   3600, Loss function: 1.668, Average Loss: 3.925, avg. samples / sec: 66237.68
Iteration:   3600, Loss function: 3.414, Average Loss: 3.895, avg. samples / sec: 66145.25
Iteration:   3600, Loss function: 3.072, Average Loss: 3.893, avg. samples / sec: 66190.21
Iteration:   3600, Loss function: 3.271, Average Loss: 3.897, avg. samples / sec: 66209.42
Iteration:   3600, Loss function: 3.285, Average Loss: 3.891, avg. samples / sec: 66000.16
Iteration:   3600, Loss function: 2.993, Average Loss: 3.872, avg. samples / sec: 66061.04
Iteration:   3600, Loss function: 2.711, Average Loss: 3.897, avg. samples / sec: 66126.88
Iteration:   3600, Loss function: 3.269, Average Loss: 3.884, avg. samples / sec: 66109.73
Iteration:   3600, Loss function: 4.009, Average Loss: 3.890, avg. samples / sec: 66214.40
Iteration:   3600, Loss function: 3.644, Average Loss: 3.907, avg. samples / sec: 66064.36
Iteration:   3600, Loss function: 2.838, Average Loss: 3.908, avg. samples / sec: 65996.60
Iteration:   3600, Loss function: 2.515, Average Loss: 3.902, avg. samples / sec: 65922.14
Iteration:   3620, Loss function: 3.588, Average Loss: 3.865, avg. samples / sec: 66080.74
Iteration:   3620, Loss function: 3.994, Average Loss: 3.888, avg. samples / sec: 66072.19
Iteration:   3620, Loss function: 3.450, Average Loss: 3.911, avg. samples / sec: 66083.19
Iteration:   3620, Loss function: 2.787, Average Loss: 3.883, avg. samples / sec: 66171.34
Iteration:   3620, Loss function: 3.848, Average Loss: 3.891, avg. samples / sec: 66148.36
Iteration:   3620, Loss function: 3.039, Average Loss: 3.920, avg. samples / sec: 66134.95
Iteration:   3620, Loss function: 4.951, Average Loss: 3.901, avg. samples / sec: 66071.94
Iteration:   3620, Loss function: 3.272, Average Loss: 3.861, avg. samples / sec: 66007.42
Iteration:   3620, Loss function: 3.631, Average Loss: 3.893, avg. samples / sec: 66010.14
Iteration:   3620, Loss function: 3.819, Average Loss: 3.887, avg. samples / sec: 66040.02
Iteration:   3620, Loss function: 3.176, Average Loss: 3.904, avg. samples / sec: 66067.79
Iteration:   3620, Loss function: 2.676, Average Loss: 3.896, avg. samples / sec: 66040.98
Iteration:   3620, Loss function: 2.836, Average Loss: 3.897, avg. samples / sec: 66166.31
Iteration:   3620, Loss function: 2.298, Average Loss: 3.869, avg. samples / sec: 66019.57
Iteration:   3620, Loss function: 3.807, Average Loss: 3.898, avg. samples / sec: 66160.72
Iteration:   3620, Loss function: 2.900, Average Loss: 3.879, avg. samples / sec: 65984.49
Iteration:   3620, Loss function: 3.178, Average Loss: 3.885, avg. samples / sec: 66055.99
Iteration:   3620, Loss function: 4.140, Average Loss: 3.894, avg. samples / sec: 66218.79
Iteration:   3620, Loss function: 3.559, Average Loss: 3.873, avg. samples / sec: 66078.57
Iteration:   3620, Loss function: 2.573, Average Loss: 3.866, avg. samples / sec: 66074.73
Iteration:   3620, Loss function: 2.717, Average Loss: 3.884, avg. samples / sec: 65990.30
Iteration:   3620, Loss function: 3.208, Average Loss: 3.877, avg. samples / sec: 66010.45
Iteration:   3620, Loss function: 3.704, Average Loss: 3.880, avg. samples / sec: 66052.81
Iteration:   3620, Loss function: 3.915, Average Loss: 3.884, avg. samples / sec: 66003.12
Iteration:   3620, Loss function: 2.486, Average Loss: 3.892, avg. samples / sec: 65963.05
Iteration:   3620, Loss function: 2.127, Average Loss: 3.891, avg. samples / sec: 65962.81
Iteration:   3620, Loss function: 4.790, Average Loss: 3.887, avg. samples / sec: 65915.45
Iteration:   3620, Loss function: 4.267, Average Loss: 3.914, avg. samples / sec: 65927.29
Iteration:   3620, Loss function: 3.820, Average Loss: 3.871, avg. samples / sec: 65940.96
Iteration:   3620, Loss function: 2.896, Average Loss: 3.875, avg. samples / sec: 66008.44
:::MLL 1558651293.941 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1558651293.941 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3640, Loss function: 3.776, Average Loss: 3.861, avg. samples / sec: 65699.48
Iteration:   3640, Loss function: 2.740, Average Loss: 3.880, avg. samples / sec: 65916.44
Iteration:   3640, Loss function: 2.325, Average Loss: 3.876, avg. samples / sec: 65686.62
Iteration:   3640, Loss function: 3.576, Average Loss: 3.902, avg. samples / sec: 65862.06
Iteration:   3640, Loss function: 3.395, Average Loss: 3.856, avg. samples / sec: 65787.14
Iteration:   3640, Loss function: 3.030, Average Loss: 3.904, avg. samples / sec: 65669.85
Iteration:   3640, Loss function: 3.909, Average Loss: 3.873, avg. samples / sec: 65767.18
Iteration:   3640, Loss function: 3.750, Average Loss: 3.871, avg. samples / sec: 65766.23
Iteration:   3640, Loss function: 2.882, Average Loss: 3.889, avg. samples / sec: 65730.16
Iteration:   3640, Loss function: 2.636, Average Loss: 3.891, avg. samples / sec: 65674.04
Iteration:   3640, Loss function: 3.395, Average Loss: 3.877, avg. samples / sec: 65832.77
Iteration:   3640, Loss function: 2.997, Average Loss: 3.883, avg. samples / sec: 65669.39
Iteration:   3640, Loss function: 3.460, Average Loss: 3.858, avg. samples / sec: 65704.36
Iteration:   3640, Loss function: 3.800, Average Loss: 3.894, avg. samples / sec: 65688.25
Iteration:   3640, Loss function: 3.160, Average Loss: 3.864, avg. samples / sec: 65725.13
Iteration:   3640, Loss function: 2.812, Average Loss: 3.870, avg. samples / sec: 65733.44
Iteration:   3640, Loss function: 2.853, Average Loss: 3.853, avg. samples / sec: 65646.11
Iteration:   3640, Loss function: 4.158, Average Loss: 3.912, avg. samples / sec: 65617.75
Iteration:   3640, Loss function: 2.418, Average Loss: 3.880, avg. samples / sec: 65749.02
Iteration:   3640, Loss function: 2.918, Average Loss: 3.864, avg. samples / sec: 65811.13
Iteration:   3640, Loss function: 3.528, Average Loss: 3.881, avg. samples / sec: 65611.82
Iteration:   3640, Loss function: 4.586, Average Loss: 3.888, avg. samples / sec: 65737.64
Iteration:   3640, Loss function: 2.990, Average Loss: 3.884, avg. samples / sec: 65659.81
Iteration:   3640, Loss function: 2.562, Average Loss: 3.886, avg. samples / sec: 65674.90
Iteration:   3640, Loss function: 4.804, Average Loss: 3.879, avg. samples / sec: 65593.83
Iteration:   3640, Loss function: 3.288, Average Loss: 3.886, avg. samples / sec: 65647.30
Iteration:   3640, Loss function: 2.785, Average Loss: 3.878, avg. samples / sec: 65548.89
Iteration:   3640, Loss function: 2.610, Average Loss: 3.874, avg. samples / sec: 65648.31
Iteration:   3640, Loss function: 2.650, Average Loss: 3.860, avg. samples / sec: 65706.56
Iteration:   3640, Loss function: 3.740, Average Loss: 3.875, avg. samples / sec: 65610.81
Iteration:   3660, Loss function: 4.186, Average Loss: 3.856, avg. samples / sec: 66246.90
Iteration:   3660, Loss function: 2.480, Average Loss: 3.841, avg. samples / sec: 66303.84
Iteration:   3660, Loss function: 5.046, Average Loss: 3.882, avg. samples / sec: 66270.88
Iteration:   3660, Loss function: 3.323, Average Loss: 3.856, avg. samples / sec: 66317.23
Iteration:   3660, Loss function: 2.836, Average Loss: 3.891, avg. samples / sec: 66238.71
Iteration:   3660, Loss function: 2.550, Average Loss: 3.883, avg. samples / sec: 66302.56
Iteration:   3660, Loss function: 3.290, Average Loss: 3.877, avg. samples / sec: 66323.12
Iteration:   3660, Loss function: 3.472, Average Loss: 3.870, avg. samples / sec: 66274.28
Iteration:   3660, Loss function: 2.931, Average Loss: 3.868, avg. samples / sec: 66219.41
Iteration:   3660, Loss function: 4.449, Average Loss: 3.863, avg. samples / sec: 66278.89
Iteration:   3660, Loss function: 3.579, Average Loss: 3.894, avg. samples / sec: 66193.28
Iteration:   3660, Loss function: 3.544, Average Loss: 3.901, avg. samples / sec: 66243.50
Iteration:   3660, Loss function: 3.483, Average Loss: 3.879, avg. samples / sec: 66210.42
Iteration:   3660, Loss function: 2.421, Average Loss: 3.871, avg. samples / sec: 66205.47
Iteration:   3660, Loss function: 2.820, Average Loss: 3.852, avg. samples / sec: 66215.99
Iteration:   3660, Loss function: 3.025, Average Loss: 3.874, avg. samples / sec: 66242.63
Iteration:   3660, Loss function: 3.660, Average Loss: 3.881, avg. samples / sec: 66275.59
Iteration:   3660, Loss function: 2.693, Average Loss: 3.869, avg. samples / sec: 66280.83
Iteration:   3660, Loss function: 2.357, Average Loss: 3.866, avg. samples / sec: 66226.29
Iteration:   3660, Loss function: 2.958, Average Loss: 3.874, avg. samples / sec: 66255.74
Iteration:   3660, Loss function: 3.377, Average Loss: 3.877, avg. samples / sec: 66221.59
Iteration:   3660, Loss function: 3.899, Average Loss: 3.876, avg. samples / sec: 66054.14
Iteration:   3660, Loss function: 2.503, Average Loss: 3.853, avg. samples / sec: 66257.95
Iteration:   3660, Loss function: 2.183, Average Loss: 3.874, avg. samples / sec: 66199.63
Iteration:   3660, Loss function: 3.983, Average Loss: 3.848, avg. samples / sec: 66085.70
Iteration:   3660, Loss function: 4.143, Average Loss: 3.864, avg. samples / sec: 66173.89
Iteration:   3660, Loss function: 1.815, Average Loss: 3.859, avg. samples / sec: 66082.32
Iteration:   3660, Loss function: 2.765, Average Loss: 3.861, avg. samples / sec: 66158.42
Iteration:   3660, Loss function: 3.070, Average Loss: 3.866, avg. samples / sec: 66188.40
Iteration:   3660, Loss function: 3.857, Average Loss: 3.863, avg. samples / sec: 66046.99
Iteration:   3680, Loss function: 2.948, Average Loss: 3.829, avg. samples / sec: 65890.39
Iteration:   3680, Loss function: 3.570, Average Loss: 3.886, avg. samples / sec: 65904.38
Iteration:   3680, Loss function: 3.465, Average Loss: 3.865, avg. samples / sec: 65974.60
Iteration:   3680, Loss function: 3.824, Average Loss: 3.867, avg. samples / sec: 65849.48
Iteration:   3680, Loss function: 3.843, Average Loss: 3.855, avg. samples / sec: 66051.35
Iteration:   3680, Loss function: 2.417, Average Loss: 3.861, avg. samples / sec: 65900.56
Iteration:   3680, Loss function: 3.832, Average Loss: 3.851, avg. samples / sec: 66044.51
Iteration:   3680, Loss function: 3.449, Average Loss: 3.863, avg. samples / sec: 65933.71
Iteration:   3680, Loss function: 3.497, Average Loss: 3.844, avg. samples / sec: 65798.23
Iteration:   3680, Loss function: 3.684, Average Loss: 3.871, avg. samples / sec: 65913.54
Iteration:   3680, Loss function: 3.589, Average Loss: 3.849, avg. samples / sec: 66007.88
Iteration:   3680, Loss function: 3.669, Average Loss: 3.870, avg. samples / sec: 65868.77
Iteration:   3680, Loss function: 3.318, Average Loss: 3.885, avg. samples / sec: 65778.14
Iteration:   3680, Loss function: 5.015, Average Loss: 3.863, avg. samples / sec: 65886.67
Iteration:   3680, Loss function: 3.068, Average Loss: 3.857, avg. samples / sec: 65876.66
Iteration:   3680, Loss function: 3.440, Average Loss: 3.858, avg. samples / sec: 65879.80
Iteration:   3680, Loss function: 2.978, Average Loss: 3.839, avg. samples / sec: 65917.51
Iteration:   3680, Loss function: 3.847, Average Loss: 3.850, avg. samples / sec: 65706.68
Iteration:   3680, Loss function: 4.515, Average Loss: 3.873, avg. samples / sec: 65781.55
Iteration:   3680, Loss function: 3.617, Average Loss: 3.846, avg. samples / sec: 65842.03
Iteration:   3680, Loss function: 3.152, Average Loss: 3.875, avg. samples / sec: 65767.27
Iteration:   3680, Loss function: 2.562, Average Loss: 3.848, avg. samples / sec: 65894.77
Iteration:   3680, Loss function: 3.438, Average Loss: 3.864, avg. samples / sec: 65883.99
Iteration:   3680, Loss function: 2.911, Average Loss: 3.863, avg. samples / sec: 65870.44
Iteration:   3680, Loss function: 3.664, Average Loss: 3.855, avg. samples / sec: 65954.07
Iteration:   3680, Loss function: 5.054, Average Loss: 3.858, avg. samples / sec: 65744.48
Iteration:   3680, Loss function: 2.840, Average Loss: 3.892, avg. samples / sec: 65800.28
Iteration:   3680, Loss function: 3.476, Average Loss: 3.849, avg. samples / sec: 65820.97
Iteration:   3680, Loss function: 3.104, Average Loss: 3.855, avg. samples / sec: 65689.90
Iteration:   3680, Loss function: 5.292, Average Loss: 3.862, avg. samples / sec: 65668.08
:::MLL 1558651295.725 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1558651295.726 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3700, Loss function: 3.408, Average Loss: 3.849, avg. samples / sec: 65751.99
Iteration:   3700, Loss function: 3.817, Average Loss: 3.835, avg. samples / sec: 65707.94
Iteration:   3700, Loss function: 3.150, Average Loss: 3.847, avg. samples / sec: 65759.54
Iteration:   3700, Loss function: 3.619, Average Loss: 3.839, avg. samples / sec: 65827.82
Iteration:   3700, Loss function: 3.160, Average Loss: 3.820, avg. samples / sec: 65607.06
Iteration:   3700, Loss function: 3.249, Average Loss: 3.837, avg. samples / sec: 65707.33
Iteration:   3700, Loss function: 4.449, Average Loss: 3.842, avg. samples / sec: 65692.53
Iteration:   3700, Loss function: 2.824, Average Loss: 3.874, avg. samples / sec: 65578.21
Iteration:   3700, Loss function: 5.373, Average Loss: 3.857, avg. samples / sec: 65673.19
Iteration:   3700, Loss function: 3.747, Average Loss: 3.849, avg. samples / sec: 65648.10
Iteration:   3700, Loss function: 3.267, Average Loss: 3.877, avg. samples / sec: 65639.26
Iteration:   3700, Loss function: 2.348, Average Loss: 3.864, avg. samples / sec: 65638.25
Iteration:   3700, Loss function: 3.278, Average Loss: 3.834, avg. samples / sec: 65663.94
Iteration:   3700, Loss function: 2.766, Average Loss: 3.851, avg. samples / sec: 65664.28
Iteration:   3700, Loss function: 2.642, Average Loss: 3.856, avg. samples / sec: 65585.23
Iteration:   3700, Loss function: 3.211, Average Loss: 3.861, avg. samples / sec: 65626.03
Iteration:   3700, Loss function: 4.378, Average Loss: 3.861, avg. samples / sec: 65512.54
Iteration:   3700, Loss function: 3.750, Average Loss: 3.855, avg. samples / sec: 65504.20
Iteration:   3700, Loss function: 3.225, Average Loss: 3.847, avg. samples / sec: 65561.34
Iteration:   3700, Loss function: 2.380, Average Loss: 3.843, avg. samples / sec: 65474.89
Iteration:   3700, Loss function: 3.092, Average Loss: 3.852, avg. samples / sec: 65656.20
Iteration:   3700, Loss function: 3.832, Average Loss: 3.854, avg. samples / sec: 65496.68
Iteration:   3700, Loss function: 3.130, Average Loss: 3.848, avg. samples / sec: 65516.99
Iteration:   3700, Loss function: 3.447, Average Loss: 3.843, avg. samples / sec: 65491.38
Iteration:   3700, Loss function: 3.520, Average Loss: 3.844, avg. samples / sec: 65474.04
Iteration:   3700, Loss function: 3.550, Average Loss: 3.881, avg. samples / sec: 65536.34
Iteration:   3700, Loss function: 3.832, Average Loss: 3.832, avg. samples / sec: 65515.22
Iteration:   3700, Loss function: 2.690, Average Loss: 3.845, avg. samples / sec: 65553.25
Iteration:   3700, Loss function: 4.250, Average Loss: 3.846, avg. samples / sec: 65557.58
Iteration:   3700, Loss function: 3.119, Average Loss: 3.855, avg. samples / sec: 65395.32
Iteration:   3720, Loss function: 3.484, Average Loss: 3.858, avg. samples / sec: 65997.44
Iteration:   3720, Loss function: 3.032, Average Loss: 3.844, avg. samples / sec: 65895.14
Iteration:   3720, Loss function: 4.327, Average Loss: 3.832, avg. samples / sec: 65791.74
Iteration:   3720, Loss function: 3.383, Average Loss: 3.843, avg. samples / sec: 65941.54
Iteration:   3720, Loss function: 4.497, Average Loss: 3.842, avg. samples / sec: 65916.65
Iteration:   3720, Loss function: 3.737, Average Loss: 3.865, avg. samples / sec: 65812.64
Iteration:   3720, Loss function: 3.692, Average Loss: 3.836, avg. samples / sec: 65932.13
Iteration:   3720, Loss function: 3.782, Average Loss: 3.857, avg. samples / sec: 65842.62
Iteration:   3720, Loss function: 3.397, Average Loss: 3.836, avg. samples / sec: 65766.78
Iteration:   3720, Loss function: 3.871, Average Loss: 3.812, avg. samples / sec: 65726.27
Iteration:   3720, Loss function: 3.135, Average Loss: 3.819, avg. samples / sec: 65935.59
Iteration:   3720, Loss function: 3.120, Average Loss: 3.845, avg. samples / sec: 65778.66
Iteration:   3720, Loss function: 3.426, Average Loss: 3.836, avg. samples / sec: 65893.10
Iteration:   3720, Loss function: 2.684, Average Loss: 3.837, avg. samples / sec: 65902.44
Iteration:   3720, Loss function: 3.766, Average Loss: 3.820, avg. samples / sec: 65665.90
Iteration:   3720, Loss function: 2.933, Average Loss: 3.839, avg. samples / sec: 65763.84
Iteration:   3720, Loss function: 3.601, Average Loss: 3.842, avg. samples / sec: 65950.37
Iteration:   3720, Loss function: 2.597, Average Loss: 3.865, avg. samples / sec: 65746.72
Iteration:   3720, Loss function: 3.680, Average Loss: 3.842, avg. samples / sec: 65660.92
Iteration:   3720, Loss function: 4.234, Average Loss: 3.853, avg. samples / sec: 65821.24
Iteration:   3720, Loss function: 4.065, Average Loss: 3.841, avg. samples / sec: 65833.20
Iteration:   3720, Loss function: 3.740, Average Loss: 3.838, avg. samples / sec: 65715.23
Iteration:   3720, Loss function: 3.293, Average Loss: 3.833, avg. samples / sec: 65820.23
Iteration:   3720, Loss function: 3.770, Average Loss: 3.832, avg. samples / sec: 65629.85
Iteration:   3720, Loss function: 3.669, Average Loss: 3.844, avg. samples / sec: 65792.70
Iteration:   3720, Loss function: 3.299, Average Loss: 3.828, avg. samples / sec: 65731.48
Iteration:   3720, Loss function: 3.995, Average Loss: 3.849, avg. samples / sec: 65777.07
Iteration:   3720, Loss function: 3.916, Average Loss: 3.842, avg. samples / sec: 65499.24
Iteration:   3720, Loss function: 2.969, Average Loss: 3.870, avg. samples / sec: 65812.27
Iteration:   3720, Loss function: 3.513, Average Loss: 3.849, avg. samples / sec: 65836.74
Iteration:   3740, Loss function: 3.235, Average Loss: 3.848, avg. samples / sec: 65985.14
Iteration:   3740, Loss function: 3.083, Average Loss: 3.803, avg. samples / sec: 66078.88
Iteration:   3740, Loss function: 4.196, Average Loss: 3.830, avg. samples / sec: 66126.48
Iteration:   3740, Loss function: 2.127, Average Loss: 3.822, avg. samples / sec: 66018.12
Iteration:   3740, Loss function: 3.408, Average Loss: 3.832, avg. samples / sec: 66111.96
Iteration:   3740, Loss function: 1.927, Average Loss: 3.836, avg. samples / sec: 66218.07
Iteration:   3740, Loss function: 4.559, Average Loss: 3.830, avg. samples / sec: 66045.07
Iteration:   3740, Loss function: 3.425, Average Loss: 3.838, avg. samples / sec: 66139.39
Iteration:   3740, Loss function: 3.016, Average Loss: 3.836, avg. samples / sec: 66112.42
Iteration:   3740, Loss function: 4.115, Average Loss: 3.848, avg. samples / sec: 66074.92
Iteration:   3740, Loss function: 4.690, Average Loss: 3.831, avg. samples / sec: 66043.77
Iteration:   3740, Loss function: 4.398, Average Loss: 3.843, avg. samples / sec: 65966.20
Iteration:   3740, Loss function: 2.909, Average Loss: 3.838, avg. samples / sec: 66116.64
Iteration:   3740, Loss function: 3.619, Average Loss: 3.863, avg. samples / sec: 66153.57
Iteration:   3740, Loss function: 3.645, Average Loss: 3.838, avg. samples / sec: 65927.48
Iteration:   3740, Loss function: 5.562, Average Loss: 3.857, avg. samples / sec: 65987.15
Iteration:   3740, Loss function: 3.914, Average Loss: 3.859, avg. samples / sec: 66043.55
Iteration:   3740, Loss function: 3.025, Average Loss: 3.833, avg. samples / sec: 66130.14
Iteration:   3740, Loss function: 4.369, Average Loss: 3.839, avg. samples / sec: 65959.38
Iteration:   3740, Loss function: 2.770, Average Loss: 3.825, avg. samples / sec: 66060.24
Iteration:   3740, Loss function: 3.963, Average Loss: 3.835, avg. samples / sec: 66026.56
Iteration:   3740, Loss function: 4.064, Average Loss: 3.827, avg. samples / sec: 66038.44
Iteration:   3740, Loss function: 3.909, Average Loss: 3.838, avg. samples / sec: 65943.70
Iteration:   3740, Loss function: 3.969, Average Loss: 3.815, avg. samples / sec: 65956.60
Iteration:   3740, Loss function: 3.421, Average Loss: 3.816, avg. samples / sec: 65975.87
Iteration:   3740, Loss function: 2.705, Average Loss: 3.822, avg. samples / sec: 65916.03
Iteration:   3740, Loss function: 2.766, Average Loss: 3.822, avg. samples / sec: 65942.56
Iteration:   3740, Loss function: 3.018, Average Loss: 3.824, avg. samples / sec: 65854.12
Iteration:   3740, Loss function: 3.138, Average Loss: 3.815, avg. samples / sec: 65858.22
Iteration:   3740, Loss function: 3.021, Average Loss: 3.847, avg. samples / sec: 65786.46
Iteration:   3760, Loss function: 4.741, Average Loss: 3.832, avg. samples / sec: 66087.00
Iteration:   3760, Loss function: 3.327, Average Loss: 3.827, avg. samples / sec: 66059.68
Iteration:   3760, Loss function: 3.703, Average Loss: 3.807, avg. samples / sec: 66232.05
Iteration:   3760, Loss function: 4.498, Average Loss: 3.832, avg. samples / sec: 65973.03
Iteration:   3760, Loss function: 3.935, Average Loss: 3.813, avg. samples / sec: 66032.50
Iteration:   3760, Loss function: 4.454, Average Loss: 3.791, avg. samples / sec: 65930.65
Iteration:   3760, Loss function: 3.818, Average Loss: 3.817, avg. samples / sec: 65990.85
Iteration:   3760, Loss function: 4.039, Average Loss: 3.822, avg. samples / sec: 66014.72
Iteration:   3760, Loss function: 2.751, Average Loss: 3.846, avg. samples / sec: 65998.80
Iteration:   3760, Loss function: 3.068, Average Loss: 3.856, avg. samples / sec: 65977.69
Iteration:   3760, Loss function: 4.284, Average Loss: 3.841, avg. samples / sec: 65812.33
Iteration:   3760, Loss function: 2.508, Average Loss: 3.819, avg. samples / sec: 65944.53
Iteration:   3760, Loss function: 2.500, Average Loss: 3.816, avg. samples / sec: 66015.49
Iteration:   3760, Loss function: 2.131, Average Loss: 3.833, avg. samples / sec: 65968.33
Iteration:   3760, Loss function: 3.333, Average Loss: 3.816, avg. samples / sec: 65898.77
Iteration:   3760, Loss function: 4.399, Average Loss: 3.827, avg. samples / sec: 65972.75
Iteration:   3760, Loss function: 3.079, Average Loss: 3.812, avg. samples / sec: 66095.68
Iteration:   3760, Loss function: 4.027, Average Loss: 3.808, avg. samples / sec: 66067.33
Iteration:   3760, Loss function: 3.777, Average Loss: 3.824, avg. samples / sec: 65963.92
Iteration:   3760, Loss function: 3.564, Average Loss: 3.828, avg. samples / sec: 65937.19
Iteration:   3760, Loss function: 2.869, Average Loss: 3.829, avg. samples / sec: 65995.95
Iteration:   3760, Loss function: 3.875, Average Loss: 3.835, avg. samples / sec: 66140.75
Iteration:   3760, Loss function: 3.264, Average Loss: 3.845, avg. samples / sec: 65928.18
Iteration:   3760, Loss function: 3.426, Average Loss: 3.829, avg. samples / sec: 65902.47
Iteration:   3760, Loss function: 3.580, Average Loss: 3.841, avg. samples / sec: 65906.73
Iteration:   3760, Loss function: 4.138, Average Loss: 3.817, avg. samples / sec: 66044.23
Iteration:   3760, Loss function: 2.333, Average Loss: 3.811, avg. samples / sec: 66011.41
Iteration:   3760, Loss function: 4.397, Average Loss: 3.818, avg. samples / sec: 65812.48
Iteration:   3760, Loss function: 3.640, Average Loss: 3.812, avg. samples / sec: 65939.84
Iteration:   3760, Loss function: 3.960, Average Loss: 3.832, avg. samples / sec: 65804.00
:::MLL 1558651297.512 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1558651297.512 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3780, Loss function: 3.946, Average Loss: 3.782, avg. samples / sec: 65808.52
Iteration:   3780, Loss function: 3.529, Average Loss: 3.836, avg. samples / sec: 65855.45
Iteration:   3780, Loss function: 4.071, Average Loss: 3.825, avg. samples / sec: 65837.36
Iteration:   3780, Loss function: 3.064, Average Loss: 3.802, avg. samples / sec: 65703.44
Iteration:   3780, Loss function: 2.340, Average Loss: 3.808, avg. samples / sec: 65732.21
Iteration:   3780, Loss function: 3.131, Average Loss: 3.808, avg. samples / sec: 65691.06
Iteration:   3780, Loss function: 2.895, Average Loss: 3.815, avg. samples / sec: 65746.38
Iteration:   3780, Loss function: 4.539, Average Loss: 3.809, avg. samples / sec: 65728.81
Iteration:   3780, Loss function: 3.615, Average Loss: 3.800, avg. samples / sec: 65742.39
Iteration:   3780, Loss function: 3.135, Average Loss: 3.812, avg. samples / sec: 65668.53
Iteration:   3780, Loss function: 2.277, Average Loss: 3.802, avg. samples / sec: 65807.23
Iteration:   3780, Loss function: 3.237, Average Loss: 3.839, avg. samples / sec: 65655.41
Iteration:   3780, Loss function: 2.346, Average Loss: 3.817, avg. samples / sec: 65560.39
Iteration:   3780, Loss function: 3.379, Average Loss: 3.824, avg. samples / sec: 65810.24
Iteration:   3780, Loss function: 3.343, Average Loss: 3.822, avg. samples / sec: 65530.30
Iteration:   3780, Loss function: 3.205, Average Loss: 3.805, avg. samples / sec: 65702.82
Iteration:   3780, Loss function: 3.862, Average Loss: 3.820, avg. samples / sec: 65680.90
Iteration:   3780, Loss function: 2.053, Average Loss: 3.810, avg. samples / sec: 65613.44
Iteration:   3780, Loss function: 3.252, Average Loss: 3.817, avg. samples / sec: 65687.63
Iteration:   3780, Loss function: 3.321, Average Loss: 3.848, avg. samples / sec: 65607.88
Iteration:   3780, Loss function: 4.183, Average Loss: 3.813, avg. samples / sec: 65720.56
Iteration:   3780, Loss function: 3.564, Average Loss: 3.820, avg. samples / sec: 65651.31
Iteration:   3780, Loss function: 3.386, Average Loss: 3.828, avg. samples / sec: 65612.31
Iteration:   3780, Loss function: 2.565, Average Loss: 3.814, avg. samples / sec: 65644.92
Iteration:   3780, Loss function: 2.995, Average Loss: 3.799, avg. samples / sec: 65688.12
Iteration:   3780, Loss function: 5.092, Average Loss: 3.801, avg. samples / sec: 65626.98
Iteration:   3780, Loss function: 3.287, Average Loss: 3.828, avg. samples / sec: 65605.71
Iteration:   3780, Loss function: 3.030, Average Loss: 3.836, avg. samples / sec: 65636.70
Iteration:   3780, Loss function: 3.541, Average Loss: 3.800, avg. samples / sec: 65448.74
Iteration:   3780, Loss function: 4.243, Average Loss: 3.825, avg. samples / sec: 65492.48
Iteration:   3800, Loss function: 3.438, Average Loss: 3.802, avg. samples / sec: 66146.28
Iteration:   3800, Loss function: 2.931, Average Loss: 3.800, avg. samples / sec: 66022.88
Iteration:   3800, Loss function: 3.189, Average Loss: 3.824, avg. samples / sec: 66115.25
Iteration:   3800, Loss function: 1.701, Average Loss: 3.806, avg. samples / sec: 66011.69
Iteration:   3800, Loss function: 2.497, Average Loss: 3.806, avg. samples / sec: 66022.23
Iteration:   3800, Loss function: 2.794, Average Loss: 3.833, avg. samples / sec: 66046.83
Iteration:   3800, Loss function: 2.851, Average Loss: 3.816, avg. samples / sec: 66085.98
Iteration:   3800, Loss function: 4.306, Average Loss: 3.775, avg. samples / sec: 65889.69
Iteration:   3800, Loss function: 3.474, Average Loss: 3.799, avg. samples / sec: 65978.22
Iteration:   3800, Loss function: 2.932, Average Loss: 3.824, avg. samples / sec: 65883.80
Iteration:   3800, Loss function: 2.795, Average Loss: 3.806, avg. samples / sec: 66076.09
Iteration:   3800, Loss function: 4.968, Average Loss: 3.822, avg. samples / sec: 66088.49
Iteration:   3800, Loss function: 4.181, Average Loss: 3.821, avg. samples / sec: 66022.48
Iteration:   3800, Loss function: 3.741, Average Loss: 3.789, avg. samples / sec: 65987.52
Iteration:   3800, Loss function: 4.381, Average Loss: 3.841, avg. samples / sec: 66051.10
Iteration:   3800, Loss function: 3.297, Average Loss: 3.815, avg. samples / sec: 65886.73
Iteration:   3800, Loss function: 2.145, Average Loss: 3.799, avg. samples / sec: 66044.29
Iteration:   3800, Loss function: 2.912, Average Loss: 3.793, avg. samples / sec: 66084.12
Iteration:   3800, Loss function: 3.368, Average Loss: 3.792, avg. samples / sec: 66107.03
Iteration:   3800, Loss function: 4.898, Average Loss: 3.816, avg. samples / sec: 66128.59
Iteration:   3800, Loss function: 2.956, Average Loss: 3.807, avg. samples / sec: 66030.31
Iteration:   3800, Loss function: 2.813, Average Loss: 3.811, avg. samples / sec: 65972.50
Iteration:   3800, Loss function: 3.572, Average Loss: 3.815, avg. samples / sec: 66023.19
Iteration:   3800, Loss function: 2.456, Average Loss: 3.791, avg. samples / sec: 65929.17
Iteration:   3800, Loss function: 3.680, Average Loss: 3.793, avg. samples / sec: 65872.44
Iteration:   3800, Loss function: 3.227, Average Loss: 3.805, avg. samples / sec: 65984.27
Iteration:   3800, Loss function: 3.003, Average Loss: 3.791, avg. samples / sec: 65994.35
Iteration:   3800, Loss function: 4.102, Average Loss: 3.815, avg. samples / sec: 65916.31
Iteration:   3800, Loss function: 3.520, Average Loss: 3.828, avg. samples / sec: 65982.17
Iteration:   3800, Loss function: 3.391, Average Loss: 3.793, avg. samples / sec: 65848.46
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
lr decay step #2
:::MLL 1558651298.538 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.61 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=2.49s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22709
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39119
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23262
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05665
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23962
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33819
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10015
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36767
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53325
Current AP: 0.22709 AP goal: 0.23000
:::MLL 1558651302.202 eval_accuracy: {"value": 0.22708521725440062, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1558651302.314 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1558651302.321 block_stop: {"value": null, "metadata": {"first_epoch_num": 49, "file": "train.py", "lineno": 804}}
:::MLL 1558651302.322 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3820, Loss function: 2.811, Average Loss: 3.794, avg. samples / sec: 7810.89
Iteration:   3820, Loss function: 3.830, Average Loss: 3.792, avg. samples / sec: 7810.30
Iteration:   3820, Loss function: 3.616, Average Loss: 3.815, avg. samples / sec: 7811.13
Iteration:   3820, Loss function: 3.418, Average Loss: 3.823, avg. samples / sec: 7810.21
Iteration:   3820, Loss function: 2.470, Average Loss: 3.804, avg. samples / sec: 7811.12
Iteration:   3820, Loss function: 2.777, Average Loss: 3.816, avg. samples / sec: 7810.02
Iteration:   3820, Loss function: 2.904, Average Loss: 3.784, avg. samples / sec: 7810.13
Iteration:   3820, Loss function: 4.215, Average Loss: 3.796, avg. samples / sec: 7807.27
Iteration:   3820, Loss function: 3.075, Average Loss: 3.786, avg. samples / sec: 7810.70
Iteration:   3820, Loss function: 3.221, Average Loss: 3.786, avg. samples / sec: 7809.33
Iteration:   3820, Loss function: 4.227, Average Loss: 3.799, avg. samples / sec: 7809.83
Iteration:   3820, Loss function: 2.396, Average Loss: 3.784, avg. samples / sec: 7810.21
Iteration:   3820, Loss function: 4.136, Average Loss: 3.791, avg. samples / sec: 7809.18
Iteration:   3820, Loss function: 3.176, Average Loss: 3.829, avg. samples / sec: 7809.50
Iteration:   3820, Loss function: 3.947, Average Loss: 3.796, avg. samples / sec: 7809.98
Iteration:   3820, Loss function: 2.829, Average Loss: 3.816, avg. samples / sec: 7808.89
Iteration:   3820, Loss function: 3.933, Average Loss: 3.767, avg. samples / sec: 7808.39
Iteration:   3820, Loss function: 2.176, Average Loss: 3.819, avg. samples / sec: 7810.60
Iteration:   3820, Loss function: 2.666, Average Loss: 3.812, avg. samples / sec: 7808.09
Iteration:   3820, Loss function: 5.994, Average Loss: 3.787, avg. samples / sec: 7811.59
Iteration:   3820, Loss function: 2.557, Average Loss: 3.803, avg. samples / sec: 7808.44
Iteration:   3820, Loss function: 2.719, Average Loss: 3.808, avg. samples / sec: 7807.89
Iteration:   3820, Loss function: 4.222, Average Loss: 3.796, avg. samples / sec: 7807.91
Iteration:   3820, Loss function: 2.569, Average Loss: 3.804, avg. samples / sec: 7808.73
Iteration:   3820, Loss function: 3.792, Average Loss: 3.805, avg. samples / sec: 7810.05
Iteration:   3820, Loss function: 3.048, Average Loss: 3.788, avg. samples / sec: 7808.20
Iteration:   3820, Loss function: 5.079, Average Loss: 3.786, avg. samples / sec: 7807.80
Iteration:   3820, Loss function: 4.599, Average Loss: 3.781, avg. samples / sec: 7808.97
Iteration:   3820, Loss function: 2.742, Average Loss: 3.807, avg. samples / sec: 7807.37
Iteration:   3820, Loss function: 4.218, Average Loss: 3.811, avg. samples / sec: 7806.71
:::MLL 1558651303.091 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1558651303.091 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3840, Loss function: 3.744, Average Loss: 3.779, avg. samples / sec: 65679.98
Iteration:   3840, Loss function: 2.788, Average Loss: 3.756, avg. samples / sec: 65732.03
Iteration:   3840, Loss function: 3.397, Average Loss: 3.794, avg. samples / sec: 65745.86
Iteration:   3840, Loss function: 3.501, Average Loss: 3.780, avg. samples / sec: 65776.67
Iteration:   3840, Loss function: 2.764, Average Loss: 3.796, avg. samples / sec: 65692.38
Iteration:   3840, Loss function: 4.087, Average Loss: 3.804, avg. samples / sec: 65577.20
Iteration:   3840, Loss function: 3.733, Average Loss: 3.792, avg. samples / sec: 65581.53
Iteration:   3840, Loss function: 3.792, Average Loss: 3.780, avg. samples / sec: 65707.11
Iteration:   3840, Loss function: 3.949, Average Loss: 3.786, avg. samples / sec: 65446.52
Iteration:   3840, Loss function: 3.379, Average Loss: 3.794, avg. samples / sec: 65763.71
Iteration:   3840, Loss function: 4.011, Average Loss: 3.818, avg. samples / sec: 65572.74
Iteration:   3840, Loss function: 3.071, Average Loss: 3.800, avg. samples / sec: 65490.26
Iteration:   3840, Loss function: 3.418, Average Loss: 3.811, avg. samples / sec: 65584.95
Iteration:   3840, Loss function: 4.562, Average Loss: 3.778, avg. samples / sec: 65549.05
Iteration:   3840, Loss function: 4.637, Average Loss: 3.791, avg. samples / sec: 65565.00
Iteration:   3840, Loss function: 4.087, Average Loss: 3.771, avg. samples / sec: 65661.93
Iteration:   3840, Loss function: 2.720, Average Loss: 3.804, avg. samples / sec: 65415.78
Iteration:   3840, Loss function: 4.160, Average Loss: 3.799, avg. samples / sec: 65760.65
Iteration:   3840, Loss function: 3.038, Average Loss: 3.785, avg. samples / sec: 65391.25
Iteration:   3840, Loss function: 3.964, Average Loss: 3.774, avg. samples / sec: 65494.46
Iteration:   3840, Loss function: 3.095, Average Loss: 3.783, avg. samples / sec: 65571.68
Iteration:   3840, Loss function: 2.654, Average Loss: 3.801, avg. samples / sec: 65555.97
Iteration:   3840, Loss function: 3.644, Average Loss: 3.813, avg. samples / sec: 65409.04
Iteration:   3840, Loss function: 3.238, Average Loss: 3.796, avg. samples / sec: 65566.22
Iteration:   3840, Loss function: 3.411, Average Loss: 3.781, avg. samples / sec: 65502.34
Iteration:   3840, Loss function: 4.025, Average Loss: 3.794, avg. samples / sec: 65452.02
Iteration:   3840, Loss function: 2.534, Average Loss: 3.783, avg. samples / sec: 65450.75
Iteration:   3840, Loss function: 3.402, Average Loss: 3.782, avg. samples / sec: 65443.36
Iteration:   3840, Loss function: 3.781, Average Loss: 3.795, avg. samples / sec: 65503.28
Iteration:   3840, Loss function: 2.612, Average Loss: 3.811, avg. samples / sec: 65424.80
Iteration:   3860, Loss function: 3.031, Average Loss: 3.783, avg. samples / sec: 66372.51
Iteration:   3860, Loss function: 4.341, Average Loss: 3.805, avg. samples / sec: 66312.14
Iteration:   3860, Loss function: 3.994, Average Loss: 3.746, avg. samples / sec: 66126.10
Iteration:   3860, Loss function: 3.192, Average Loss: 3.782, avg. samples / sec: 66188.59
Iteration:   3860, Loss function: 3.081, Average Loss: 3.778, avg. samples / sec: 66329.31
Iteration:   3860, Loss function: 3.757, Average Loss: 3.784, avg. samples / sec: 66303.15
Iteration:   3860, Loss function: 1.934, Average Loss: 3.790, avg. samples / sec: 66129.86
Iteration:   3860, Loss function: 2.975, Average Loss: 3.771, avg. samples / sec: 66039.84
Iteration:   3860, Loss function: 3.062, Average Loss: 3.790, avg. samples / sec: 66179.45
Iteration:   3860, Loss function: 2.941, Average Loss: 3.772, avg. samples / sec: 66138.39
Iteration:   3860, Loss function: 3.353, Average Loss: 3.789, avg. samples / sec: 66296.35
Iteration:   3860, Loss function: 2.928, Average Loss: 3.799, avg. samples / sec: 66208.21
Iteration:   3860, Loss function: 1.761, Average Loss: 3.797, avg. samples / sec: 66081.95
Iteration:   3860, Loss function: 2.552, Average Loss: 3.793, avg. samples / sec: 66174.20
Iteration:   3860, Loss function: 3.105, Average Loss: 3.789, avg. samples / sec: 66160.56
Iteration:   3860, Loss function: 2.885, Average Loss: 3.784, avg. samples / sec: 66198.17
Iteration:   3860, Loss function: 3.878, Average Loss: 3.772, avg. samples / sec: 66026.59
Iteration:   3860, Loss function: 2.639, Average Loss: 3.768, avg. samples / sec: 66157.67
Iteration:   3860, Loss function: 3.308, Average Loss: 3.778, avg. samples / sec: 66239.46
Iteration:   3860, Loss function: 4.924, Average Loss: 3.808, avg. samples / sec: 66289.59
Iteration:   3860, Loss function: 4.055, Average Loss: 3.765, avg. samples / sec: 66118.44
Iteration:   3860, Loss function: 3.094, Average Loss: 3.809, avg. samples / sec: 66086.41
Iteration:   3860, Loss function: 3.558, Average Loss: 3.779, avg. samples / sec: 66094.56
Iteration:   3860, Loss function: 2.037, Average Loss: 3.774, avg. samples / sec: 66110.50
Iteration:   3860, Loss function: 4.104, Average Loss: 3.778, avg. samples / sec: 66100.05
Iteration:   3860, Loss function: 3.529, Average Loss: 3.791, avg. samples / sec: 66106.10
Iteration:   3860, Loss function: 3.766, Average Loss: 3.773, avg. samples / sec: 66153.33
Iteration:   3860, Loss function: 4.261, Average Loss: 3.789, avg. samples / sec: 66016.67
Iteration:   3860, Loss function: 3.570, Average Loss: 3.773, avg. samples / sec: 65970.40
Iteration:   3860, Loss function: 3.019, Average Loss: 3.784, avg. samples / sec: 65832.19
Iteration:   3880, Loss function: 2.913, Average Loss: 3.764, avg. samples / sec: 65784.44
Iteration:   3880, Loss function: 4.356, Average Loss: 3.762, avg. samples / sec: 65753.19
Iteration:   3880, Loss function: 2.092, Average Loss: 3.774, avg. samples / sec: 65580.80
Iteration:   3880, Loss function: 3.843, Average Loss: 3.770, avg. samples / sec: 65860.65
Iteration:   3880, Loss function: 3.293, Average Loss: 3.797, avg. samples / sec: 65579.15
Iteration:   3880, Loss function: 4.064, Average Loss: 3.781, avg. samples / sec: 65831.91
Iteration:   3880, Loss function: 4.206, Average Loss: 3.767, avg. samples / sec: 65794.36
Iteration:   3880, Loss function: 3.478, Average Loss: 3.770, avg. samples / sec: 65650.76
Iteration:   3880, Loss function: 4.598, Average Loss: 3.790, avg. samples / sec: 65743.40
Iteration:   3880, Loss function: 2.910, Average Loss: 3.778, avg. samples / sec: 65689.65
Iteration:   3880, Loss function: 4.020, Average Loss: 3.785, avg. samples / sec: 65710.15
Iteration:   3880, Loss function: 3.838, Average Loss: 3.802, avg. samples / sec: 65775.72
Iteration:   3880, Loss function: 4.428, Average Loss: 3.758, avg. samples / sec: 65761.44
Iteration:   3880, Loss function: 2.043, Average Loss: 3.785, avg. samples / sec: 65705.73
Iteration:   3880, Loss function: 2.599, Average Loss: 3.770, avg. samples / sec: 65733.81
Iteration:   3880, Loss function: 2.919, Average Loss: 3.781, avg. samples / sec: 65661.96
Iteration:   3880, Loss function: 3.752, Average Loss: 3.738, avg. samples / sec: 65592.22
Iteration:   3880, Loss function: 2.804, Average Loss: 3.758, avg. samples / sec: 65730.65
Iteration:   3880, Loss function: 3.977, Average Loss: 3.760, avg. samples / sec: 65799.33
Iteration:   3880, Loss function: 3.402, Average Loss: 3.784, avg. samples / sec: 65627.71
Iteration:   3880, Loss function: 2.649, Average Loss: 3.795, avg. samples / sec: 65697.19
Iteration:   3880, Loss function: 4.081, Average Loss: 3.781, avg. samples / sec: 65784.65
Iteration:   3880, Loss function: 3.073, Average Loss: 3.766, avg. samples / sec: 65676.92
Iteration:   3880, Loss function: 2.793, Average Loss: 3.772, avg. samples / sec: 65575.03
Iteration:   3880, Loss function: 3.390, Average Loss: 3.768, avg. samples / sec: 65738.80
Iteration:   3880, Loss function: 4.394, Average Loss: 3.778, avg. samples / sec: 65614.20
Iteration:   3880, Loss function: 3.516, Average Loss: 3.781, avg. samples / sec: 65613.87
Iteration:   3880, Loss function: 1.936, Average Loss: 3.771, avg. samples / sec: 65831.88
Iteration:   3880, Loss function: 3.259, Average Loss: 3.777, avg. samples / sec: 65550.60
Iteration:   3880, Loss function: 3.389, Average Loss: 3.772, avg. samples / sec: 65585.84
Iteration:   3900, Loss function: 3.487, Average Loss: 3.732, avg. samples / sec: 66079.13
Iteration:   3900, Loss function: 4.381, Average Loss: 3.753, avg. samples / sec: 65975.13
Iteration:   3900, Loss function: 3.454, Average Loss: 3.791, avg. samples / sec: 66013.08
Iteration:   3900, Loss function: 3.933, Average Loss: 3.763, avg. samples / sec: 66020.28
Iteration:   3900, Loss function: 2.847, Average Loss: 3.751, avg. samples / sec: 66028.39
Iteration:   3900, Loss function: 2.966, Average Loss: 3.775, avg. samples / sec: 66018.21
Iteration:   3900, Loss function: 3.226, Average Loss: 3.773, avg. samples / sec: 65983.62
Iteration:   3900, Loss function: 3.006, Average Loss: 3.757, avg. samples / sec: 65885.56
Iteration:   3900, Loss function: 4.430, Average Loss: 3.763, avg. samples / sec: 66083.84
Iteration:   3900, Loss function: 1.824, Average Loss: 3.764, avg. samples / sec: 65917.48
Iteration:   3900, Loss function: 3.242, Average Loss: 3.760, avg. samples / sec: 65961.63
Iteration:   3900, Loss function: 3.353, Average Loss: 3.767, avg. samples / sec: 66033.18
Iteration:   3900, Loss function: 2.191, Average Loss: 3.772, avg. samples / sec: 65991.10
Iteration:   3900, Loss function: 2.539, Average Loss: 3.775, avg. samples / sec: 65928.77
Iteration:   3900, Loss function: 2.618, Average Loss: 3.771, avg. samples / sec: 66031.98
Iteration:   3900, Loss function: 3.489, Average Loss: 3.794, avg. samples / sec: 65903.80
Iteration:   3900, Loss function: 2.577, Average Loss: 3.778, avg. samples / sec: 65919.95
Iteration:   3900, Loss function: 3.278, Average Loss: 3.757, avg. samples / sec: 65977.38
Iteration:   3900, Loss function: 3.146, Average Loss: 3.765, avg. samples / sec: 66027.80
Iteration:   3900, Loss function: 3.016, Average Loss: 3.750, avg. samples / sec: 65942.56
Iteration:   3900, Loss function: 3.940, Average Loss: 3.785, avg. samples / sec: 65948.30
Iteration:   3900, Loss function: 3.384, Average Loss: 3.774, avg. samples / sec: 66005.81
Iteration:   3900, Loss function: 2.512, Average Loss: 3.773, avg. samples / sec: 65871.98
Iteration:   3900, Loss function: 2.944, Average Loss: 3.763, avg. samples / sec: 65813.81
Iteration:   3900, Loss function: 2.562, Average Loss: 3.747, avg. samples / sec: 65883.71
Iteration:   3900, Loss function: 2.158, Average Loss: 3.758, avg. samples / sec: 65852.74
Iteration:   3900, Loss function: 2.821, Average Loss: 3.786, avg. samples / sec: 65825.79
Iteration:   3900, Loss function: 2.065, Average Loss: 3.766, avg. samples / sec: 66052.84
Iteration:   3900, Loss function: 3.840, Average Loss: 3.766, avg. samples / sec: 65918.41
Iteration:   3900, Loss function: 4.281, Average Loss: 3.779, avg. samples / sec: 65874.59
:::MLL 1558651304.877 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1558651304.877 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 3.960, Average Loss: 3.756, avg. samples / sec: 65885.22
Iteration:   3920, Loss function: 2.983, Average Loss: 3.728, avg. samples / sec: 65657.12
Iteration:   3920, Loss function: 3.248, Average Loss: 3.758, avg. samples / sec: 65672.33
Iteration:   3920, Loss function: 3.292, Average Loss: 3.760, avg. samples / sec: 65837.91
Iteration:   3920, Loss function: 1.787, Average Loss: 3.754, avg. samples / sec: 65715.69
Iteration:   3920, Loss function: 3.571, Average Loss: 3.766, avg. samples / sec: 65732.95
Iteration:   3920, Loss function: 3.169, Average Loss: 3.745, avg. samples / sec: 65781.83
Iteration:   3920, Loss function: 3.087, Average Loss: 3.782, avg. samples / sec: 65753.62
Iteration:   3920, Loss function: 3.989, Average Loss: 3.765, avg. samples / sec: 65726.05
Iteration:   3920, Loss function: 3.364, Average Loss: 3.760, avg. samples / sec: 65675.73
Iteration:   3920, Loss function: 2.418, Average Loss: 3.750, avg. samples / sec: 65685.28
Iteration:   3920, Loss function: 4.838, Average Loss: 3.762, avg. samples / sec: 65774.06
Iteration:   3920, Loss function: 2.588, Average Loss: 3.771, avg. samples / sec: 65614.08
Iteration:   3920, Loss function: 3.079, Average Loss: 3.759, avg. samples / sec: 65699.70
Iteration:   3920, Loss function: 2.851, Average Loss: 3.744, avg. samples / sec: 65542.71
Iteration:   3920, Loss function: 2.820, Average Loss: 3.749, avg. samples / sec: 65690.42
Iteration:   3920, Loss function: 3.422, Average Loss: 3.743, avg. samples / sec: 65701.60
Iteration:   3920, Loss function: 2.544, Average Loss: 3.784, avg. samples / sec: 65544.26
Iteration:   3920, Loss function: 3.384, Average Loss: 3.746, avg. samples / sec: 65579.15
Iteration:   3920, Loss function: 2.791, Average Loss: 3.762, avg. samples / sec: 65651.92
Iteration:   3920, Loss function: 2.926, Average Loss: 3.765, avg. samples / sec: 65570.27
Iteration:   3920, Loss function: 3.011, Average Loss: 3.766, avg. samples / sec: 65683.96
Iteration:   3920, Loss function: 1.968, Average Loss: 3.749, avg. samples / sec: 65593.83
Iteration:   3920, Loss function: 3.912, Average Loss: 3.769, avg. samples / sec: 65645.10
Iteration:   3920, Loss function: 2.515, Average Loss: 3.743, avg. samples / sec: 65547.49
Iteration:   3920, Loss function: 3.848, Average Loss: 3.776, avg. samples / sec: 65715.05
Iteration:   3920, Loss function: 4.529, Average Loss: 3.780, avg. samples / sec: 65678.88
Iteration:   3920, Loss function: 3.720, Average Loss: 3.751, avg. samples / sec: 65648.22
Iteration:   3920, Loss function: 4.056, Average Loss: 3.776, avg. samples / sec: 65619.86
Iteration:   3920, Loss function: 3.304, Average Loss: 3.754, avg. samples / sec: 65650.49
Iteration:   3940, Loss function: 3.463, Average Loss: 3.752, avg. samples / sec: 66202.99
Iteration:   3940, Loss function: 2.513, Average Loss: 3.773, avg. samples / sec: 66121.33
Iteration:   3940, Loss function: 3.082, Average Loss: 3.733, avg. samples / sec: 66123.56
Iteration:   3940, Loss function: 4.319, Average Loss: 3.758, avg. samples / sec: 66015.49
Iteration:   3940, Loss function: 3.024, Average Loss: 3.758, avg. samples / sec: 66084.31
Iteration:   3940, Loss function: 3.104, Average Loss: 3.739, avg. samples / sec: 66067.05
Iteration:   3940, Loss function: 3.079, Average Loss: 3.748, avg. samples / sec: 65941.23
Iteration:   3940, Loss function: 4.591, Average Loss: 3.759, avg. samples / sec: 66083.07
Iteration:   3940, Loss function: 2.147, Average Loss: 3.725, avg. samples / sec: 65910.70
Iteration:   3940, Loss function: 4.046, Average Loss: 3.751, avg. samples / sec: 65932.01
Iteration:   3940, Loss function: 3.562, Average Loss: 3.738, avg. samples / sec: 66036.99
Iteration:   3940, Loss function: 2.901, Average Loss: 3.734, avg. samples / sec: 66072.32
Iteration:   3940, Loss function: 2.621, Average Loss: 3.779, avg. samples / sec: 65961.76
Iteration:   3940, Loss function: 2.879, Average Loss: 3.733, avg. samples / sec: 66038.82
Iteration:   3940, Loss function: 2.604, Average Loss: 3.740, avg. samples / sec: 66043.24
Iteration:   3940, Loss function: 3.221, Average Loss: 3.768, avg. samples / sec: 66086.35
Iteration:   3940, Loss function: 2.069, Average Loss: 3.753, avg. samples / sec: 65958.52
Iteration:   3940, Loss function: 2.838, Average Loss: 3.736, avg. samples / sec: 65889.28
Iteration:   3940, Loss function: 3.085, Average Loss: 3.749, avg. samples / sec: 65813.90
Iteration:   3940, Loss function: 2.471, Average Loss: 3.754, avg. samples / sec: 65938.15
Iteration:   3940, Loss function: 3.134, Average Loss: 3.770, avg. samples / sec: 66011.41
Iteration:   3940, Loss function: 2.805, Average Loss: 3.768, avg. samples / sec: 65935.99
Iteration:   3940, Loss function: 2.479, Average Loss: 3.743, avg. samples / sec: 66031.39
Iteration:   3940, Loss function: 3.519, Average Loss: 3.755, avg. samples / sec: 65973.46
Iteration:   3940, Loss function: 3.274, Average Loss: 3.747, avg. samples / sec: 65837.17
Iteration:   3940, Loss function: 3.964, Average Loss: 3.757, avg. samples / sec: 65856.49
Iteration:   3940, Loss function: 3.295, Average Loss: 3.775, avg. samples / sec: 65952.31
Iteration:   3940, Loss function: 3.305, Average Loss: 3.752, avg. samples / sec: 65880.91
Iteration:   3940, Loss function: 4.691, Average Loss: 3.743, avg. samples / sec: 65863.54
Iteration:   3940, Loss function: 3.373, Average Loss: 3.742, avg. samples / sec: 65959.50
Iteration:   3960, Loss function: 3.138, Average Loss: 3.719, avg. samples / sec: 65988.01
Iteration:   3960, Loss function: 3.503, Average Loss: 3.725, avg. samples / sec: 65969.54
Iteration:   3960, Loss function: 3.260, Average Loss: 3.759, avg. samples / sec: 66028.73
Iteration:   3960, Loss function: 2.844, Average Loss: 3.757, avg. samples / sec: 66010.33
Iteration:   3960, Loss function: 3.514, Average Loss: 3.746, avg. samples / sec: 65780.08
Iteration:   3960, Loss function: 2.960, Average Loss: 3.767, avg. samples / sec: 65858.52
Iteration:   3960, Loss function: 3.008, Average Loss: 3.749, avg. samples / sec: 65891.26
Iteration:   3960, Loss function: 2.946, Average Loss: 3.741, avg. samples / sec: 65961.97
Iteration:   3960, Loss function: 3.312, Average Loss: 3.741, avg. samples / sec: 65991.87
Iteration:   3960, Loss function: 3.765, Average Loss: 3.745, avg. samples / sec: 65878.81
Iteration:   3960, Loss function: 3.159, Average Loss: 3.732, avg. samples / sec: 65898.25
Iteration:   3960, Loss function: 4.259, Average Loss: 3.752, avg. samples / sec: 65859.20
Iteration:   3960, Loss function: 2.600, Average Loss: 3.732, avg. samples / sec: 65975.38
Iteration:   3960, Loss function: 2.965, Average Loss: 3.735, avg. samples / sec: 65894.18
Iteration:   3960, Loss function: 3.986, Average Loss: 3.744, avg. samples / sec: 65835.94
Iteration:   3960, Loss function: 3.544, Average Loss: 3.740, avg. samples / sec: 65953.64
Iteration:   3960, Loss function: 4.321, Average Loss: 3.761, avg. samples / sec: 65905.34
Iteration:   3960, Loss function: 4.015, Average Loss: 3.770, avg. samples / sec: 65998.18
Iteration:   3960, Loss function: 3.637, Average Loss: 3.726, avg. samples / sec: 65870.62
Iteration:   3960, Loss function: 3.575, Average Loss: 3.742, avg. samples / sec: 65842.31
Iteration:   3960, Loss function: 3.658, Average Loss: 3.723, avg. samples / sec: 65795.86
Iteration:   3960, Loss function: 3.268, Average Loss: 3.773, avg. samples / sec: 65809.04
Iteration:   3960, Loss function: 3.536, Average Loss: 3.726, avg. samples / sec: 65968.21
Iteration:   3960, Loss function: 3.612, Average Loss: 3.740, avg. samples / sec: 65832.22
Iteration:   3960, Loss function: 3.411, Average Loss: 3.740, avg. samples / sec: 65925.96
Iteration:   3960, Loss function: 3.998, Average Loss: 3.745, avg. samples / sec: 65917.55
Iteration:   3960, Loss function: 3.674, Average Loss: 3.751, avg. samples / sec: 65835.36
Iteration:   3960, Loss function: 3.369, Average Loss: 3.726, avg. samples / sec: 65838.13
Iteration:   3960, Loss function: 3.228, Average Loss: 3.732, avg. samples / sec: 65700.25
Iteration:   3960, Loss function: 2.833, Average Loss: 3.748, avg. samples / sec: 65814.73
:::MLL 1558651306.662 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1558651306.662 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3980, Loss function: 3.870, Average Loss: 3.727, avg. samples / sec: 65820.23
Iteration:   3980, Loss function: 2.615, Average Loss: 3.744, avg. samples / sec: 65884.54
Iteration:   3980, Loss function: 3.299, Average Loss: 3.764, avg. samples / sec: 65698.87
Iteration:   3980, Loss function: 2.629, Average Loss: 3.740, avg. samples / sec: 65733.38
Iteration:   3980, Loss function: 2.341, Average Loss: 3.735, avg. samples / sec: 65780.66
Iteration:   3980, Loss function: 3.561, Average Loss: 3.733, avg. samples / sec: 65723.29
Iteration:   3980, Loss function: 3.006, Average Loss: 3.738, avg. samples / sec: 65735.16
Iteration:   3980, Loss function: 3.164, Average Loss: 3.721, avg. samples / sec: 65845.60
Iteration:   3980, Loss function: 4.161, Average Loss: 3.722, avg. samples / sec: 65630.80
Iteration:   3980, Loss function: 3.596, Average Loss: 3.731, avg. samples / sec: 65826.59
Iteration:   3980, Loss function: 3.358, Average Loss: 3.709, avg. samples / sec: 65626.18
Iteration:   3980, Loss function: 2.673, Average Loss: 3.738, avg. samples / sec: 65895.85
Iteration:   3980, Loss function: 3.459, Average Loss: 3.739, avg. samples / sec: 65652.81
Iteration:   3980, Loss function: 3.524, Average Loss: 3.725, avg. samples / sec: 65692.04
Iteration:   3980, Loss function: 3.215, Average Loss: 3.756, avg. samples / sec: 65607.33
Iteration:   3980, Loss function: 2.780, Average Loss: 3.723, avg. samples / sec: 65703.37
Iteration:   3980, Loss function: 4.095, Average Loss: 3.744, avg. samples / sec: 65653.51
Iteration:   3980, Loss function: 3.297, Average Loss: 3.768, avg. samples / sec: 65735.74
Iteration:   3980, Loss function: 4.564, Average Loss: 3.733, avg. samples / sec: 65625.66
Iteration:   3980, Loss function: 2.464, Average Loss: 3.762, avg. samples / sec: 65673.37
Iteration:   3980, Loss function: 2.654, Average Loss: 3.720, avg. samples / sec: 65706.35
Iteration:   3980, Loss function: 4.337, Average Loss: 3.726, avg. samples / sec: 65628.84
Iteration:   3980, Loss function: 3.370, Average Loss: 3.728, avg. samples / sec: 65771.88
Iteration:   3980, Loss function: 5.543, Average Loss: 3.717, avg. samples / sec: 65653.94
Iteration:   3980, Loss function: 3.658, Average Loss: 3.745, avg. samples / sec: 65554.23
Iteration:   3980, Loss function: 2.890, Average Loss: 3.729, avg. samples / sec: 65596.06
Iteration:   3980, Loss function: 3.880, Average Loss: 3.758, avg. samples / sec: 65585.53
Iteration:   3980, Loss function: 2.475, Average Loss: 3.738, avg. samples / sec: 65587.61
Iteration:   3980, Loss function: 1.843, Average Loss: 3.740, avg. samples / sec: 65665.35
Iteration:   3980, Loss function: 4.003, Average Loss: 3.735, avg. samples / sec: 65637.73
Iteration:   4000, Loss function: 4.635, Average Loss: 3.728, avg. samples / sec: 66221.00
Iteration:   4000, Loss function: 3.838, Average Loss: 3.738, avg. samples / sec: 66245.03
Iteration:   4000, Loss function: 3.680, Average Loss: 3.733, avg. samples / sec: 66166.15
Iteration:   4000, Loss function: 4.306, Average Loss: 3.720, avg. samples / sec: 66095.22
Iteration:   4000, Loss function: 4.702, Average Loss: 3.754, avg. samples / sec: 66341.79
Iteration:   4000, Loss function: 3.280, Average Loss: 3.754, avg. samples / sec: 66144.23
Iteration:   4000, Loss function: 2.810, Average Loss: 3.737, avg. samples / sec: 66131.01
Iteration:   4000, Loss function: 2.667, Average Loss: 3.731, avg. samples / sec: 66209.27
Iteration:   4000, Loss function: 3.292, Average Loss: 3.725, avg. samples / sec: 66147.64
Iteration:   4000, Loss function: 3.466, Average Loss: 3.732, avg. samples / sec: 66240.51
Iteration:   4000, Loss function: 3.505, Average Loss: 3.763, avg. samples / sec: 66232.39
Iteration:   4000, Loss function: 2.802, Average Loss: 3.714, avg. samples / sec: 66154.26
Iteration:   4000, Loss function: 3.595, Average Loss: 3.731, avg. samples / sec: 66152.98
Iteration:   4000, Loss function: 3.036, Average Loss: 3.716, avg. samples / sec: 66209.83
Iteration:   4000, Loss function: 3.250, Average Loss: 3.714, avg. samples / sec: 66158.64
Iteration:   4000, Loss function: 2.311, Average Loss: 3.717, avg. samples / sec: 66254.53
Iteration:   4000, Loss function: 2.817, Average Loss: 3.703, avg. samples / sec: 66098.16
Iteration:   4000, Loss function: 2.569, Average Loss: 3.755, avg. samples / sec: 66173.55
Iteration:   4000, Loss function: 3.419, Average Loss: 3.720, avg. samples / sec: 66188.65
Iteration:   4000, Loss function: 2.169, Average Loss: 3.711, avg. samples / sec: 66068.94
Iteration:   4000, Loss function: 3.407, Average Loss: 3.735, avg. samples / sec: 66239.74
Iteration:   4000, Loss function: 2.755, Average Loss: 3.734, avg. samples / sec: 66043.33
Iteration:   4000, Loss function: 3.644, Average Loss: 3.717, avg. samples / sec: 66138.70
Iteration:   4000, Loss function: 3.834, Average Loss: 3.732, avg. samples / sec: 66229.15
Iteration:   4000, Loss function: 3.258, Average Loss: 3.724, avg. samples / sec: 66042.44
Iteration:   4000, Loss function: 3.802, Average Loss: 3.715, avg. samples / sec: 66079.13
Iteration:   4000, Loss function: 3.446, Average Loss: 3.737, avg. samples / sec: 66144.60
Iteration:   4000, Loss function: 3.402, Average Loss: 3.747, avg. samples / sec: 66072.10
Iteration:   4000, Loss function: 2.914, Average Loss: 3.713, avg. samples / sec: 66115.15
Iteration:   4000, Loss function: 3.106, Average Loss: 3.728, avg. samples / sec: 66184.74
Iteration:   4020, Loss function: 3.452, Average Loss: 3.722, avg. samples / sec: 66119.93
Iteration:   4020, Loss function: 3.052, Average Loss: 3.740, avg. samples / sec: 66220.16
Iteration:   4020, Loss function: 3.826, Average Loss: 3.718, avg. samples / sec: 66073.28
Iteration:   4020, Loss function: 3.154, Average Loss: 3.705, avg. samples / sec: 66081.89
Iteration:   4020, Loss function: 3.582, Average Loss: 3.729, avg. samples / sec: 66159.63
Iteration:   4020, Loss function: 2.910, Average Loss: 3.704, avg. samples / sec: 66135.48
Iteration:   4020, Loss function: 2.361, Average Loss: 3.712, avg. samples / sec: 66187.22
Iteration:   4020, Loss function: 4.785, Average Loss: 3.731, avg. samples / sec: 65989.03
Iteration:   4020, Loss function: 2.877, Average Loss: 3.710, avg. samples / sec: 66082.35
Iteration:   4020, Loss function: 3.502, Average Loss: 3.720, avg. samples / sec: 66124.58
Iteration:   4020, Loss function: 4.050, Average Loss: 3.719, avg. samples / sec: 65905.68
Iteration:   4020, Loss function: 4.663, Average Loss: 3.742, avg. samples / sec: 65995.06
Iteration:   4020, Loss function: 2.269, Average Loss: 3.726, avg. samples / sec: 66005.16
Iteration:   4020, Loss function: 2.661, Average Loss: 3.751, avg. samples / sec: 65973.62
Iteration:   4020, Loss function: 3.709, Average Loss: 3.707, avg. samples / sec: 65947.65
Iteration:   4020, Loss function: 3.445, Average Loss: 3.703, avg. samples / sec: 66076.16
Iteration:   4020, Loss function: 3.729, Average Loss: 3.721, avg. samples / sec: 66127.78
Iteration:   4020, Loss function: 3.314, Average Loss: 3.727, avg. samples / sec: 65924.70
Iteration:   4020, Loss function: 2.748, Average Loss: 3.695, avg. samples / sec: 65971.95
Iteration:   4020, Loss function: 3.132, Average Loss: 3.728, avg. samples / sec: 66012.92
Iteration:   4020, Loss function: 2.950, Average Loss: 3.745, avg. samples / sec: 65909.10
Iteration:   4020, Loss function: 3.544, Average Loss: 3.735, avg. samples / sec: 65912.83
Iteration:   4020, Loss function: 3.595, Average Loss: 3.753, avg. samples / sec: 65989.62
Iteration:   4020, Loss function: 3.986, Average Loss: 3.709, avg. samples / sec: 66064.51
Iteration:   4020, Loss function: 3.447, Average Loss: 3.713, avg. samples / sec: 65934.04
Iteration:   4020, Loss function: 3.507, Average Loss: 3.712, avg. samples / sec: 65969.14
Iteration:   4020, Loss function: 2.896, Average Loss: 3.729, avg. samples / sec: 66020.01
Iteration:   4020, Loss function: 5.389, Average Loss: 3.733, avg. samples / sec: 65824.59
Iteration:   4020, Loss function: 3.578, Average Loss: 3.711, avg. samples / sec: 65863.20
Iteration:   4020, Loss function: 3.055, Average Loss: 3.723, avg. samples / sec: 65827.36
Iteration:   4040, Loss function: 3.542, Average Loss: 3.727, avg. samples / sec: 66149.63
Iteration:   4040, Loss function: 3.677, Average Loss: 3.737, avg. samples / sec: 66046.37
Iteration:   4040, Loss function: 3.338, Average Loss: 3.699, avg. samples / sec: 66052.77
Iteration:   4040, Loss function: 3.135, Average Loss: 3.743, avg. samples / sec: 66007.17
Iteration:   4040, Loss function: 3.321, Average Loss: 3.716, avg. samples / sec: 65876.13
Iteration:   4040, Loss function: 2.649, Average Loss: 3.698, avg. samples / sec: 65947.87
Iteration:   4040, Loss function: 3.137, Average Loss: 3.711, avg. samples / sec: 65888.85
Iteration:   4040, Loss function: 3.303, Average Loss: 3.743, avg. samples / sec: 66056.80
Iteration:   4040, Loss function: 3.844, Average Loss: 3.704, avg. samples / sec: 66081.80
Iteration:   4040, Loss function: 2.505, Average Loss: 3.711, avg. samples / sec: 65984.36
Iteration:   4040, Loss function: 3.741, Average Loss: 3.722, avg. samples / sec: 65950.49
Iteration:   4040, Loss function: 4.339, Average Loss: 3.721, avg. samples / sec: 66098.63
Iteration:   4040, Loss function: 3.447, Average Loss: 3.704, avg. samples / sec: 66141.09
Iteration:   4040, Loss function: 3.587, Average Loss: 3.703, avg. samples / sec: 65918.87
Iteration:   4040, Loss function: 2.622, Average Loss: 3.725, avg. samples / sec: 66059.00
Iteration:   4040, Loss function: 2.142, Average Loss: 3.697, avg. samples / sec: 65890.12
Iteration:   4040, Loss function: 3.021, Average Loss: 3.692, avg. samples / sec: 66031.76
Iteration:   4040, Loss function: 3.414, Average Loss: 3.700, avg. samples / sec: 66045.00
Iteration:   4040, Loss function: 2.746, Average Loss: 3.712, avg. samples / sec: 65962.47
Iteration:   4040, Loss function: 3.786, Average Loss: 3.719, avg. samples / sec: 65969.23
Iteration:   4040, Loss function: 2.994, Average Loss: 3.695, avg. samples / sec: 65956.85
Iteration:   4040, Loss function: 4.053, Average Loss: 3.723, avg. samples / sec: 66103.03
Iteration:   4040, Loss function: 2.724, Average Loss: 3.724, avg. samples / sec: 65986.03
Iteration:   4040, Loss function: 3.753, Average Loss: 3.719, avg. samples / sec: 65858.89
Iteration:   4040, Loss function: 3.893, Average Loss: 3.719, avg. samples / sec: 65919.64
Iteration:   4040, Loss function: 2.978, Average Loss: 3.729, avg. samples / sec: 65826.93
Iteration:   4040, Loss function: 3.138, Average Loss: 3.735, avg. samples / sec: 65983.81
Iteration:   4040, Loss function: 3.185, Average Loss: 3.719, avg. samples / sec: 66127.72
Iteration:   4040, Loss function: 3.488, Average Loss: 3.705, avg. samples / sec: 65796.57
Iteration:   4040, Loss function: 4.025, Average Loss: 3.707, avg. samples / sec: 65930.22
:::MLL 1558651308.445 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1558651308.445 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   4060, Loss function: 3.315, Average Loss: 3.711, avg. samples / sec: 65735.34
Iteration:   4060, Loss function: 1.618, Average Loss: 3.714, avg. samples / sec: 65793.65
Iteration:   4060, Loss function: 3.145, Average Loss: 3.718, avg. samples / sec: 65809.93
Iteration:   4060, Loss function: 3.817, Average Loss: 3.715, avg. samples / sec: 65797.03
Iteration:   4060, Loss function: 3.720, Average Loss: 3.685, avg. samples / sec: 65789.16
Iteration:   4060, Loss function: 3.986, Average Loss: 3.709, avg. samples / sec: 65718.82
Iteration:   4060, Loss function: 2.915, Average Loss: 3.732, avg. samples / sec: 65654.31
Iteration:   4060, Loss function: 3.287, Average Loss: 3.717, avg. samples / sec: 65783.45
Iteration:   4060, Loss function: 3.252, Average Loss: 3.696, avg. samples / sec: 65699.85
Iteration:   4060, Loss function: 3.834, Average Loss: 3.730, avg. samples / sec: 65698.60
Iteration:   4060, Loss function: 3.221, Average Loss: 3.692, avg. samples / sec: 65693.70
Iteration:   4060, Loss function: 3.220, Average Loss: 3.690, avg. samples / sec: 65695.29
Iteration:   4060, Loss function: 3.410, Average Loss: 3.694, avg. samples / sec: 65799.30
Iteration:   4060, Loss function: 1.940, Average Loss: 3.703, avg. samples / sec: 65661.07
Iteration:   4060, Loss function: 3.434, Average Loss: 3.719, avg. samples / sec: 65527.86
Iteration:   4060, Loss function: 3.186, Average Loss: 3.706, avg. samples / sec: 65662.48
Iteration:   4060, Loss function: 2.852, Average Loss: 3.714, avg. samples / sec: 65653.82
Iteration:   4060, Loss function: 3.030, Average Loss: 3.695, avg. samples / sec: 65651.40
Iteration:   4060, Loss function: 2.802, Average Loss: 3.691, avg. samples / sec: 65588.64
Iteration:   4060, Loss function: 3.851, Average Loss: 3.713, avg. samples / sec: 65625.60
Iteration:   4060, Loss function: 3.527, Average Loss: 3.690, avg. samples / sec: 65650.70
Iteration:   4060, Loss function: 3.435, Average Loss: 3.721, avg. samples / sec: 65654.19
Iteration:   4060, Loss function: 3.461, Average Loss: 3.716, avg. samples / sec: 65745.98
Iteration:   4060, Loss function: 3.410, Average Loss: 3.718, avg. samples / sec: 65645.62
Iteration:   4060, Loss function: 2.478, Average Loss: 3.691, avg. samples / sec: 65567.95
Iteration:   4060, Loss function: 3.489, Average Loss: 3.726, avg. samples / sec: 65633.88
Iteration:   4060, Loss function: 4.327, Average Loss: 3.740, avg. samples / sec: 65539.20
Iteration:   4060, Loss function: 2.400, Average Loss: 3.719, avg. samples / sec: 65540.48
Iteration:   4060, Loss function: 3.474, Average Loss: 3.697, avg. samples / sec: 65646.63
Iteration:   4060, Loss function: 3.136, Average Loss: 3.702, avg. samples / sec: 65501.00
Iteration:   4080, Loss function: 3.403, Average Loss: 3.692, avg. samples / sec: 66243.94
Iteration:   4080, Loss function: 3.742, Average Loss: 3.704, avg. samples / sec: 66144.94
Iteration:   4080, Loss function: 3.893, Average Loss: 3.688, avg. samples / sec: 66183.34
Iteration:   4080, Loss function: 1.546, Average Loss: 3.713, avg. samples / sec: 66342.17
Iteration:   4080, Loss function: 2.782, Average Loss: 3.710, avg. samples / sec: 66216.95
Iteration:   4080, Loss function: 3.145, Average Loss: 3.703, avg. samples / sec: 66139.63
Iteration:   4080, Loss function: 2.959, Average Loss: 3.717, avg. samples / sec: 66122.66
Iteration:   4080, Loss function: 2.853, Average Loss: 3.714, avg. samples / sec: 66185.51
Iteration:   4080, Loss function: 3.582, Average Loss: 3.683, avg. samples / sec: 66139.32
Iteration:   4080, Loss function: 3.611, Average Loss: 3.687, avg. samples / sec: 66310.92
Iteration:   4080, Loss function: 3.170, Average Loss: 3.694, avg. samples / sec: 66304.43
Iteration:   4080, Loss function: 2.283, Average Loss: 3.681, avg. samples / sec: 66161.56
Iteration:   4080, Loss function: 4.006, Average Loss: 3.711, avg. samples / sec: 66202.12
Iteration:   4080, Loss function: 2.326, Average Loss: 3.703, avg. samples / sec: 66167.52
Iteration:   4080, Loss function: 2.627, Average Loss: 3.734, avg. samples / sec: 66222.90
Iteration:   4080, Loss function: 4.571, Average Loss: 3.709, avg. samples / sec: 66164.79
Iteration:   4080, Loss function: 3.141, Average Loss: 3.718, avg. samples / sec: 66190.11
Iteration:   4080, Loss function: 3.975, Average Loss: 3.722, avg. samples / sec: 66046.24
Iteration:   4080, Loss function: 3.298, Average Loss: 3.687, avg. samples / sec: 66066.86
Iteration:   4080, Loss function: 2.919, Average Loss: 3.704, avg. samples / sec: 65987.98
Iteration:   4080, Loss function: 4.319, Average Loss: 3.683, avg. samples / sec: 66143.05
Iteration:   4080, Loss function: 2.046, Average Loss: 3.677, avg. samples / sec: 65994.10
Iteration:   4080, Loss function: 4.040, Average Loss: 3.690, avg. samples / sec: 66087.16
Iteration:   4080, Loss function: 3.568, Average Loss: 3.712, avg. samples / sec: 66004.61
Iteration:   4080, Loss function: 2.787, Average Loss: 3.687, avg. samples / sec: 66050.30
Iteration:   4080, Loss function: 2.472, Average Loss: 3.687, avg. samples / sec: 66067.64
Iteration:   4080, Loss function: 3.904, Average Loss: 3.706, avg. samples / sec: 66071.05
Iteration:   4080, Loss function: 2.438, Average Loss: 3.715, avg. samples / sec: 66077.49
Iteration:   4080, Loss function: 3.478, Average Loss: 3.699, avg. samples / sec: 65947.50
Iteration:   4080, Loss function: 3.276, Average Loss: 3.709, avg. samples / sec: 65924.30
Iteration:   4100, Loss function: 3.135, Average Loss: 3.705, avg. samples / sec: 66334.71
Iteration:   4100, Loss function: 4.373, Average Loss: 3.684, avg. samples / sec: 66268.70
Iteration:   4100, Loss function: 3.898, Average Loss: 3.697, avg. samples / sec: 66257.92
Iteration:   4100, Loss function: 3.338, Average Loss: 3.700, avg. samples / sec: 66440.72
Iteration:   4100, Loss function: 4.334, Average Loss: 3.676, avg. samples / sec: 66307.58
Iteration:   4100, Loss function: 3.026, Average Loss: 3.677, avg. samples / sec: 66315.82
Iteration:   4100, Loss function: 2.468, Average Loss: 3.670, avg. samples / sec: 66372.88
Iteration:   4100, Loss function: 3.033, Average Loss: 3.682, avg. samples / sec: 66332.93
Iteration:   4100, Loss function: 2.945, Average Loss: 3.710, avg. samples / sec: 66385.98
Iteration:   4100, Loss function: 4.395, Average Loss: 3.708, avg. samples / sec: 66228.68
Iteration:   4100, Loss function: 2.448, Average Loss: 3.677, avg. samples / sec: 66371.32
Iteration:   4100, Loss function: 2.667, Average Loss: 3.668, avg. samples / sec: 66292.39
Iteration:   4100, Loss function: 3.990, Average Loss: 3.703, avg. samples / sec: 66285.44
Iteration:   4100, Loss function: 2.620, Average Loss: 3.698, avg. samples / sec: 66349.79
Iteration:   4100, Loss function: 3.615, Average Loss: 3.694, avg. samples / sec: 66304.25
Iteration:   4100, Loss function: 3.909, Average Loss: 3.699, avg. samples / sec: 66167.55
Iteration:   4100, Loss function: 3.372, Average Loss: 3.713, avg. samples / sec: 66204.07
Iteration:   4100, Loss function: 3.625, Average Loss: 3.711, avg. samples / sec: 66279.14
Iteration:   4100, Loss function: 2.798, Average Loss: 3.682, avg. samples / sec: 66225.45
Iteration:   4100, Loss function: 2.847, Average Loss: 3.695, avg. samples / sec: 66329.31
Iteration:   4100, Loss function: 4.519, Average Loss: 3.714, avg. samples / sec: 66236.44
Iteration:   4100, Loss function: 3.829, Average Loss: 3.686, avg. samples / sec: 66099.40
Iteration:   4100, Loss function: 3.687, Average Loss: 3.691, avg. samples / sec: 66280.27
Iteration:   4100, Loss function: 3.211, Average Loss: 3.706, avg. samples / sec: 66113.29
Iteration:   4100, Loss function: 2.957, Average Loss: 3.725, avg. samples / sec: 66202.49
Iteration:   4100, Loss function: 3.090, Average Loss: 3.684, avg. samples / sec: 66261.13
Iteration:   4100, Loss function: 3.421, Average Loss: 3.680, avg. samples / sec: 66222.27
Iteration:   4100, Loss function: 3.150, Average Loss: 3.695, avg. samples / sec: 66141.90
Iteration:   4100, Loss function: 2.260, Average Loss: 3.703, avg. samples / sec: 66146.15
Iteration:   4100, Loss function: 3.421, Average Loss: 3.703, avg. samples / sec: 66262.63
:::MLL 1558651310.227 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1558651310.227 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   4120, Loss function: 2.170, Average Loss: 3.674, avg. samples / sec: 65724.49
Iteration:   4120, Loss function: 3.238, Average Loss: 3.678, avg. samples / sec: 65849.08
Iteration:   4120, Loss function: 2.984, Average Loss: 3.691, avg. samples / sec: 65684.82
Iteration:   4120, Loss function: 3.128, Average Loss: 3.660, avg. samples / sec: 65708.64
Iteration:   4120, Loss function: 2.330, Average Loss: 3.672, avg. samples / sec: 65682.40
Iteration:   4120, Loss function: 2.462, Average Loss: 3.693, avg. samples / sec: 65740.83
Iteration:   4120, Loss function: 2.782, Average Loss: 3.701, avg. samples / sec: 65786.09
Iteration:   4120, Loss function: 3.617, Average Loss: 3.694, avg. samples / sec: 65828.38
Iteration:   4120, Loss function: 3.481, Average Loss: 3.696, avg. samples / sec: 65579.49
Iteration:   4120, Loss function: 3.473, Average Loss: 3.676, avg. samples / sec: 65807.81
Iteration:   4120, Loss function: 3.575, Average Loss: 3.671, avg. samples / sec: 65659.11
Iteration:   4120, Loss function: 3.655, Average Loss: 3.704, avg. samples / sec: 65685.28
Iteration:   4120, Loss function: 3.320, Average Loss: 3.688, avg. samples / sec: 65765.49
Iteration:   4120, Loss function: 4.904, Average Loss: 3.676, avg. samples / sec: 65704.57
Iteration:   4120, Loss function: 3.712, Average Loss: 3.691, avg. samples / sec: 65783.88
Iteration:   4120, Loss function: 4.310, Average Loss: 3.678, avg. samples / sec: 65617.93
Iteration:   4120, Loss function: 3.062, Average Loss: 3.718, avg. samples / sec: 65718.73
Iteration:   4120, Loss function: 3.451, Average Loss: 3.688, avg. samples / sec: 65753.07
Iteration:   4120, Loss function: 2.948, Average Loss: 3.676, avg. samples / sec: 65715.57
Iteration:   4120, Loss function: 2.823, Average Loss: 3.702, avg. samples / sec: 65596.92
Iteration:   4120, Loss function: 4.700, Average Loss: 3.691, avg. samples / sec: 65620.74
Iteration:   4120, Loss function: 3.660, Average Loss: 3.709, avg. samples / sec: 65594.05
Iteration:   4120, Loss function: 2.866, Average Loss: 3.694, avg. samples / sec: 65505.26
Iteration:   4120, Loss function: 4.436, Average Loss: 3.709, avg. samples / sec: 65621.02
Iteration:   4120, Loss function: 2.644, Average Loss: 3.688, avg. samples / sec: 65553.86
Iteration:   4120, Loss function: 3.352, Average Loss: 3.698, avg. samples / sec: 65532.68
Iteration:   4120, Loss function: 3.247, Average Loss: 3.668, avg. samples / sec: 65512.24
Iteration:   4120, Loss function: 2.855, Average Loss: 3.709, avg. samples / sec: 65554.96
Iteration:   4120, Loss function: 3.205, Average Loss: 3.695, avg. samples / sec: 65560.05
Iteration:   4120, Loss function: 3.678, Average Loss: 3.669, avg. samples / sec: 65484.17
Iteration:   4140, Loss function: 3.172, Average Loss: 3.662, avg. samples / sec: 65722.80
Iteration:   4140, Loss function: 3.830, Average Loss: 3.683, avg. samples / sec: 65837.20
Iteration:   4140, Loss function: 3.113, Average Loss: 3.700, avg. samples / sec: 65922.82
Iteration:   4140, Loss function: 4.992, Average Loss: 3.687, avg. samples / sec: 65894.03
Iteration:   4140, Loss function: 3.856, Average Loss: 3.661, avg. samples / sec: 65936.64
Iteration:   4140, Loss function: 4.491, Average Loss: 3.688, avg. samples / sec: 65688.18
Iteration:   4140, Loss function: 2.589, Average Loss: 3.671, avg. samples / sec: 65811.62
Iteration:   4140, Loss function: 3.522, Average Loss: 3.684, avg. samples / sec: 65854.22
Iteration:   4140, Loss function: 3.814, Average Loss: 3.690, avg. samples / sec: 65740.09
Iteration:   4140, Loss function: 3.113, Average Loss: 3.696, avg. samples / sec: 65826.84
Iteration:   4140, Loss function: 4.181, Average Loss: 3.669, avg. samples / sec: 65933.06
Iteration:   4140, Loss function: 3.104, Average Loss: 3.672, avg. samples / sec: 65643.67
Iteration:   4140, Loss function: 3.941, Average Loss: 3.696, avg. samples / sec: 65724.95
Iteration:   4140, Loss function: 3.793, Average Loss: 3.671, avg. samples / sec: 65772.83
Iteration:   4140, Loss function: 2.633, Average Loss: 3.703, avg. samples / sec: 65823.24
Iteration:   4140, Loss function: 2.337, Average Loss: 3.653, avg. samples / sec: 65628.93
Iteration:   4140, Loss function: 3.927, Average Loss: 3.693, avg. samples / sec: 65674.62
Iteration:   4140, Loss function: 3.644, Average Loss: 3.686, avg. samples / sec: 65687.63
Iteration:   4140, Loss function: 3.139, Average Loss: 3.699, avg. samples / sec: 65863.14
Iteration:   4140, Loss function: 3.376, Average Loss: 3.666, avg. samples / sec: 65629.05
Iteration:   4140, Loss function: 2.802, Average Loss: 3.712, avg. samples / sec: 65706.90
Iteration:   4140, Loss function: 2.575, Average Loss: 3.683, avg. samples / sec: 65856.43
Iteration:   4140, Loss function: 4.495, Average Loss: 3.685, avg. samples / sec: 65605.01
Iteration:   4140, Loss function: 3.559, Average Loss: 3.677, avg. samples / sec: 65623.55
Iteration:   4140, Loss function: 2.587, Average Loss: 3.666, avg. samples / sec: 65610.72
Iteration:   4140, Loss function: 2.328, Average Loss: 3.661, avg. samples / sec: 65579.55
Iteration:   4140, Loss function: 3.112, Average Loss: 3.666, avg. samples / sec: 65628.29
Iteration:   4140, Loss function: 3.499, Average Loss: 3.692, avg. samples / sec: 65738.84
Iteration:   4140, Loss function: 2.859, Average Loss: 3.683, avg. samples / sec: 65598.60
Iteration:   4140, Loss function: 2.315, Average Loss: 3.677, avg. samples / sec: 65681.57
Iteration:   4160, Loss function: 3.216, Average Loss: 3.687, avg. samples / sec: 66355.98
Iteration:   4160, Loss function: 3.362, Average Loss: 3.696, avg. samples / sec: 66330.46
Iteration:   4160, Loss function: 3.022, Average Loss: 3.647, avg. samples / sec: 66310.61
Iteration:   4160, Loss function: 3.911, Average Loss: 3.689, avg. samples / sec: 66286.84
Iteration:   4160, Loss function: 3.405, Average Loss: 3.673, avg. samples / sec: 66373.16
Iteration:   4160, Loss function: 4.360, Average Loss: 3.692, avg. samples / sec: 66303.62
Iteration:   4160, Loss function: 3.782, Average Loss: 3.668, avg. samples / sec: 66366.01
Iteration:   4160, Loss function: 3.361, Average Loss: 3.685, avg. samples / sec: 66414.95
Iteration:   4160, Loss function: 2.998, Average Loss: 3.672, avg. samples / sec: 66446.27
Iteration:   4160, Loss function: 3.120, Average Loss: 3.684, avg. samples / sec: 66203.33
Iteration:   4160, Loss function: 3.070, Average Loss: 3.657, avg. samples / sec: 66099.37
Iteration:   4160, Loss function: 2.609, Average Loss: 3.682, avg. samples / sec: 66163.89
Iteration:   4160, Loss function: 4.324, Average Loss: 3.667, avg. samples / sec: 66171.99
Iteration:   4160, Loss function: 4.142, Average Loss: 3.660, avg. samples / sec: 66315.60
Iteration:   4160, Loss function: 2.804, Average Loss: 3.674, avg. samples / sec: 66289.46
Iteration:   4160, Loss function: 2.911, Average Loss: 3.663, avg. samples / sec: 66183.24
Iteration:   4160, Loss function: 3.827, Average Loss: 3.662, avg. samples / sec: 66127.03
Iteration:   4160, Loss function: 2.914, Average Loss: 3.693, avg. samples / sec: 66130.70
Iteration:   4160, Loss function: 3.851, Average Loss: 3.675, avg. samples / sec: 66329.09
Iteration:   4160, Loss function: 4.613, Average Loss: 3.674, avg. samples / sec: 66100.83
Iteration:   4160, Loss function: 1.812, Average Loss: 3.683, avg. samples / sec: 66106.00
Iteration:   4160, Loss function: 2.815, Average Loss: 3.675, avg. samples / sec: 66217.54
Iteration:   4160, Loss function: 4.070, Average Loss: 3.691, avg. samples / sec: 66137.40
Iteration:   4160, Loss function: 3.047, Average Loss: 3.657, avg. samples / sec: 66199.63
Iteration:   4160, Loss function: 3.453, Average Loss: 3.655, avg. samples / sec: 66236.19
Iteration:   4160, Loss function: 2.254, Average Loss: 3.661, avg. samples / sec: 66145.75
Iteration:   4160, Loss function: 3.506, Average Loss: 3.678, avg. samples / sec: 66106.87
Iteration:   4160, Loss function: 3.401, Average Loss: 3.703, avg. samples / sec: 66155.84
Iteration:   4160, Loss function: 3.463, Average Loss: 3.677, avg. samples / sec: 66015.89
Iteration:   4160, Loss function: 4.436, Average Loss: 3.666, avg. samples / sec: 66030.89
Iteration:   4180, Loss function: 3.408, Average Loss: 3.678, avg. samples / sec: 66085.58
Iteration:   4180, Loss function: 4.447, Average Loss: 3.675, avg. samples / sec: 65945.95
Iteration:   4180, Loss function: 4.615, Average Loss: 3.679, avg. samples / sec: 65962.07
Iteration:   4180, Loss function: 3.496, Average Loss: 3.694, avg. samples / sec: 65909.44
Iteration:   4180, Loss function: 3.363, Average Loss: 3.670, avg. samples / sec: 65979.08
Iteration:   4180, Loss function: 4.018, Average Loss: 3.653, avg. samples / sec: 66019.36
Iteration:   4180, Loss function: 2.686, Average Loss: 3.686, avg. samples / sec: 65844.92
Iteration:   4180, Loss function: 3.631, Average Loss: 3.673, avg. samples / sec: 66071.76
Iteration:   4180, Loss function: 2.806, Average Loss: 3.693, avg. samples / sec: 66043.15
Iteration:   4180, Loss function: 3.771, Average Loss: 3.668, avg. samples / sec: 65968.33
Iteration:   4180, Loss function: 3.558, Average Loss: 3.689, avg. samples / sec: 65842.71
Iteration:   4180, Loss function: 4.367, Average Loss: 3.640, avg. samples / sec: 65838.06
Iteration:   4180, Loss function: 2.682, Average Loss: 3.668, avg. samples / sec: 65936.14
Iteration:   4180, Loss function: 2.715, Average Loss: 3.681, avg. samples / sec: 65938.67
Iteration:   4180, Loss function: 3.886, Average Loss: 3.690, avg. samples / sec: 65900.19
Iteration:   4180, Loss function: 3.013, Average Loss: 3.655, avg. samples / sec: 65867.51
Iteration:   4180, Loss function: 2.978, Average Loss: 3.653, avg. samples / sec: 65945.46
Iteration:   4180, Loss function: 2.651, Average Loss: 3.657, avg. samples / sec: 65869.51
Iteration:   4180, Loss function: 3.652, Average Loss: 3.659, avg. samples / sec: 65875.15
Iteration:   4180, Loss function: 3.621, Average Loss: 3.673, avg. samples / sec: 65970.31
Iteration:   4180, Loss function: 3.284, Average Loss: 3.657, avg. samples / sec: 65854.40
Iteration:   4180, Loss function: 3.440, Average Loss: 3.676, avg. samples / sec: 65786.83
Iteration:   4180, Loss function: 3.956, Average Loss: 3.644, avg. samples / sec: 65799.24
Iteration:   4180, Loss function: 3.004, Average Loss: 3.670, avg. samples / sec: 65867.30
Iteration:   4180, Loss function: 4.055, Average Loss: 3.655, avg. samples / sec: 65893.81
Iteration:   4180, Loss function: 4.484, Average Loss: 3.668, avg. samples / sec: 65743.22
Iteration:   4180, Loss function: 3.630, Average Loss: 3.660, avg. samples / sec: 65958.24
Iteration:   4180, Loss function: 2.986, Average Loss: 3.679, avg. samples / sec: 65666.67
Iteration:   4180, Loss function: 2.809, Average Loss: 3.665, avg. samples / sec: 65717.38
Iteration:   4180, Loss function: 3.065, Average Loss: 3.664, avg. samples / sec: 65670.46
:::MLL 1558651312.013 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1558651312.013 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1558651312.063 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Parsing batch: 0/1Predicting Ended, total time: 0.62 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.52s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.55s)
DONE (t=0.56s)
DONE (t=2.51s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23036
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39424
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23733
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05669
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24304
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37101
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32456
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34071
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09850
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36800
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53714
Current AP: 0.23036 AP goal: 0.23000
:::MLL 1558651315.764 eval_accuracy: {"value": 0.23035934847176612, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1558651315.797 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1558651315.804 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1558651316.437 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-5,48-53', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-11,54-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-17,60-65', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-23,66-71', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-29,72-77', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-35,78-83', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=36-41,84-89', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=42-47,90-95', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '7', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '4', '--lr', '3.1e-3', '--wd', '2e-4', '--input-batch-multiplier', '10', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
ENDING TIMING RUN AT 2019-05-23 10:42:02 PM
RESULT,SINGLE_STAGE_DETECTOR,,163,nvidia,2019-05-23 10:39:19 PM
